<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:16:14Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|111001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08930</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep attractor network for single-microphone speaker separation</dc:title>
 <dc:creator>Chen, Zhuo</dc:creator>
 <dc:creator>Luo, Yi</dc:creator>
 <dc:creator>Mesgarani, Nima</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Despite the overwhelming success of deep learning in various speech
processing tasks, the problem of separating simultaneous speakers in a mixture
remains challenging. Two major difficulties in such systems are the arbitrary
source permutation and unknown number of sources in the mixture. We propose a
novel deep learning framework for single channel speech separation by creating
attractor points in high dimensional embedding space of the acoustic signals
which pull together the time-frequency bins corresponding to each source.
Attractor points in this study are created by finding the centroids of the
sources in the embedding space, which are subsequently used to determine the
similarity of each bin in the mixture to each source. The network is then
trained to minimize the reconstruction error of each source by optimizing the
embeddings. The proposed model is different from prior works in that it
implements an end-to-end training, and it does not depend on the number of
sources in the mixture. Two strategies are explored in the test time, K-means
and fixed attractor points, where the latter requires no post-processing and
can be implemented in real-time. We evaluated our system on Wall Street Journal
dataset and show 5.49\% improvement over the previous state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 2017 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08930</dc:identifier>
 <dc:identifier>doi:10.1109/ICASSP.2017.7952155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08936</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differential Private Noise Adding Mechanism and Its Application on
  Consensus</dc:title>
 <dc:creator>He, Jianping</dc:creator>
 <dc:creator>Cai, Lin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Differential privacy is a formal mathematical {stand-ard} for quantifying the
degree of that individual privacy in a statistical database is preserved. To
guarantee differential privacy, a typical method is adding random noise to the
original data for data release. In this paper, we investigate the conditions of
differential privacy considering the general random noise adding mechanism, and
then apply the obtained results for privacy analysis of the privacy-preserving
consensus algorithm. Specifically, we obtain a necessary and sufficient
condition of $\epsilon$-differential privacy, and the sufficient conditions of
$(\epsilon, \delta)$-differential privacy. We apply them to analyze various
random noises. For the special cases with known results, our theory matches
with the literature; for other cases that are unknown, our approach provides a
simple and effective tool for differential privacy analysis. Applying the
obtained theory, on privacy-preserving consensus algorithms, it is proved that
the average consensus and $\epsilon$-differential privacy cannot be guaranteed
simultaneously by any privacy-preserving consensus algorithm.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures, journal</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08938</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asynchronous Broadcasting with Bivalent Beeps</dc:title>
 <dc:creator>Hounkanli, Kokouvi</dc:creator>
 <dc:creator>Pelc, Andrzej</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In broadcasting, one node of a network has a message that must be learned by
all other nodes. We study deterministic algorithms for this fundamental
communication task in a very weak model of wireless communication. The only
signals sent by nodes are beeps. Moreover, they are delivered to neighbors of
the beeping node in an asynchronous way: the time between sending and reception
is finite but unpredictable. We first observe that under this scenario, no
communication is possible, if beeps are all of the same strength. Hence we
study broadcasting in the bivalent beeping model, where every beep can be
either soft or loud. At the receiving end, if exactly one soft beep is received
by a node in a round, it is heard as soft. Any other combination of beeps
received in a round is heard as a loud beep. The cost of a broadcasting
algorithm is the total number of beeps sent by all nodes.
  We consider four levels of knowledge that nodes may have about the network:
anonymity (no knowledge whatsoever), ad-hoc (all nodes have distinct labels and
every node knows only its own label), neighborhood awareness (every node knows
its label and labels of all neighbors), and full knowledge (every node knows
the entire labeled map of the network and the identity of the source). We first
show that in the anonymous case, broadcasting is impossible even for very
simple networks. For each of the other three knowledge levels we provide upper
and lower bounds on the minimum cost of a broadcasting algorithm. Our results
show separations between all these scenarios. Perhaps surprisingly, the jump in
broadcasting cost between the ad-hoc and neighborhood awareness levels is much
larger than between the neighborhood awareness and full knowledge levels,
although in the two former levels knowledge of nodes is local, and in the
latter it is global.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08942</identifier>
 <datestamp>2016-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The BIN_COUNTS Constraint: Filtering and Applications</dc:title>
 <dc:creator>Rossi, Roberto</dc:creator>
 <dc:creator>Akg&#xfc;n, &#xd6;zg&#xfc;r</dc:creator>
 <dc:creator>Prestwich, Steven</dc:creator>
 <dc:creator>Tarim, Armagan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Statistics - Other Statistics</dc:subject>
 <dc:description>  We introduce the BIN_COUNTS constraint, which deals with the problem of
counting the number of decision variables in a set which are assigned values
that lie in given bins. We illustrate a decomposition and a filtering algorithm
that achieves generalised arc consistency. We contrast the filtering power of
these two approaches and we discuss a number of applications. We show that
BIN_COUNTS can be employed to develop a decomposition for the $\chi^2$ test
constraint, a new statistical constraint that we introduce in this work. We
also show how this new constraint can be employed in the context of the
Balanced Academic Curriculum Problem and of the Balanced Nursing Workload
Problem. For both these problems we carry out numerical studies involving our
reformulations. Finally, we present a further application of the $\chi^2$ test
constraint in the context of confidence interval analysis.
</dc:description>
 <dc:description>Comment: 20 pages, working draft</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2016-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08944</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonparametric General Reinforcement Learning</dc:title>
 <dc:creator>Leike, Jan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Reinforcement learning (RL) problems are often phrased in terms of Markov
decision processes (MDPs). In this thesis we go beyond MDPs and consider RL in
environments that are non-Markovian, non-ergodic and only partially observable.
Our focus is not on practical algorithms, but rather on the fundamental
underlying problems: How do we balance exploration and exploitation? How do we
explore optimally? When is an agent optimal? We follow the nonparametric
realizable paradigm.
  We establish negative results on Bayesian RL agents, in particular AIXI. We
show that unlucky or adversarial choices of the prior cause the agent to
misbehave drastically. Therefore Legg-Hutter intelligence and balanced Pareto
optimality, which depend crucially on the choice of the prior, are entirely
subjective. Moreover, in the class of all computable environments every policy
is Pareto optimal. This undermines all existing optimality properties for AIXI.
However, there are Bayesian approaches to general RL that satisfy objective
optimality guarantees: We prove that Thompson sampling is asymptotically
optimal in stochastic environments in the sense that its value converges to the
value of the optimal policy. We connect asymptotic optimality to regret given a
recoverability assumption on the environment that allows the agent to recover
from mistakes. Hence Thompson sampling achieves sublinear regret in these
environments.
  Our results culminate in a formal solution to the grain of truth problem: A
Bayesian agent acting in a multi-agent environment learns to predict the other
agents' policies if its prior assigns positive probability to them (the prior
contains a grain of truth). We construct a large but limit computable class
containing a grain of truth and show that agents based on Thompson sampling
over this class converge to play Nash equilibria in arbitrary unknown
computable multi-agent environments.
</dc:description>
 <dc:description>Comment: PhD thesis</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08945</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a Natural Language Interface with Neural Programmer</dc:title>
 <dc:creator>Neelakantan, Arvind</dc:creator>
 <dc:creator>Le, Quoc V.</dc:creator>
 <dc:creator>Abadi, Martin</dc:creator>
 <dc:creator>McCallum, Andrew</dc:creator>
 <dc:creator>Amodei, Dario</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning a natural language interface for database tables is a challenging
task that involves deep language understanding and multi-step reasoning. The
task is often approached by mapping natural language queries to logical forms
or programs that provide the desired response when executed on the database. To
our knowledge, this paper presents the first weakly supervised, end-to-end
neural network model to induce such programs on a real-world dataset. We
enhance the objective function of Neural Programmer, a neural network with
built-in discrete operations, and apply it on WikiTableQuestions, a natural
language question-answering dataset. The model is trained end-to-end with weak
supervision of question-answer pairs, and does not require domain-specific
grammars, rules, or annotations that are key elements in previous approaches to
program induction. The main experimental result in this paper is that a single
Neural Programmer model achieves 34.2% accuracy using only 10,000 examples with
weak supervision. An ensemble of 15 models, with a trivial combination
technique, achieves 37.7% accuracy, which is competitive to the current
state-of-the-art accuracy of 37.1% obtained by a traditional natural language
semantic parser.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08946</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exponential Separation of Quantum Communication and Classical
  Information</dc:title>
 <dc:creator>Anshu, Anurag</dc:creator>
 <dc:creator>Touchette, Dave</dc:creator>
 <dc:creator>Yao, Penghui</dc:creator>
 <dc:creator>Yu, Nengkun</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We exhibit a Boolean function for which the quantum communication complexity
is exponentially larger than the classical information complexity. An
exponential separation in the other direction was already known from the work
of Kerenidis et. al. [SICOMP 44, pp. 1550-1572], hence our work implies that
these two complexity measures are incomparable. As classical information
complexity is an upper bound on quantum information complexity, which in turn
is equal to amortized quantum communication complexity, our work implies that a
tight direct sum result for distributional quantum communication complexity
cannot hold. The function we use to present such a separation is the Symmetric
k-ary Pointer Jumping function introduced by Rao and Sinha [ECCC TR15-057],
whose classical communication complexity is exponentially larger than its
classical information complexity. In this paper, we show that the quantum
communication complexity of this function is polynomially equivalent to its
classical communication complexity. The high-level idea behind our proof is
arguably the simplest so far for such an exponential separation between
information and communication, driven by a sequence of round-elimination
arguments, allowing us to simplify further the approach of Rao and Sinha.
  As another application of the techniques that we develop, we give a simple
proof for an optimal trade-off between Alice's and Bob's communication while
computing the related Greater-Than function on n bits: say Bob communicates at
most b bits, then Alice must send n/exp(O(b)) bits to Bob. This holds even when
allowing pre-shared entanglement. We also present a classical protocol
achieving this bound.
</dc:description>
 <dc:description>Comment: v1, 36 pages, 3 figures</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08946</dc:identifier>
 <dc:identifier>Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of
  Computing, STOC 2017</dc:identifier>
 <dc:identifier>doi:10.1145/3055399.3055401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08947</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Navigable videos for presenting scientific data on head-mounted displays</dc:title>
 <dc:creator>Chu, Jacqueline</dc:creator>
 <dc:creator>Ferrer, Leonardo</dc:creator>
 <dc:creator>Shih, Min</dc:creator>
 <dc:creator>Ma, Kwan-Liu</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Immersive, stereoscopic viewing enables scientists to better analyze the
spatial structures of visualized physical phenomena. However, their findings
cannot be properly presented in traditional media, which lack these core
attributes. Creating a presentation tool that captures this environment poses
unique challenges, namely related to poor viewing accessibility. Immersive
scientific renderings often require high-end equipment, which can be
impractical to obtain. We address these challenges with our authoring tool and
navigational interface, which is designed for affordable head-mounted displays.
With the authoring tool, scientists can show salient data features as connected
360{\deg} video paths, resulting in a &quot;choose-your-own-adventure&quot; experience.
Our navigational interface features bidirectional video playback for added
viewing control when users traverse the tailor-made content. We evaluate our
system's benefits by authoring case studies on several data sets and conducting
a usability study on the navigational interface's design. In summary, our
approach provides scientists an immersive medium to visually present their
research to the intended audience--spanning from students to colleagues--on
affordable virtual reality headsets.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08951</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Estimation for Adaptive Networks Based on Serial-Inspired
  Diffusion</dc:title>
 <dc:creator>Healy, C. T.</dc:creator>
 <dc:creator>de Lamare, R. C.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Distributed estimation and processing in networks modeled by graphs have
received a great deal of interest recently, due to the benefits of
decentralised processing in terms of performance and robustness to
communications link failure between nodes of the network. Diffusion-based
algorithms have been demonstrated to be among the most effective for
distributed signal processing problems, through the combination of local node
estimate updates and sharing of information with neighbour nodes through
diffusion. In this work, we develop a serial-inspired approach based on
message-passing strategies that provides a significant improvement in
performance over prior art. The concept of serial processing in the graph has
been successfully applied in sum-product based algorithms and here provides
inspiration for an algorithm which makes use of the most up-to-date information
in the graph in combination with the diffusion approach to offer improved
performance.
</dc:description>
 <dc:description>Comment: 8 figures</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08954</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Low-Space Differentially Private Low-rank Factorization in the
  Spectral Norm</dc:title>
 <dc:creator>Upadhyay, Jalaj</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Low-rank factorization is used in many areas of computer science where one
performs spectral analysis on large sensitive data stored in the form of
matrices. In this paper, we study differentially private low-rank factorization
of a matrix with respect to the spectral norm in the turnstile update model. In
this problem, given an input matrix $\mathbf{A} \in \mathbb{R}^{m \times n}$
updated in the turnstile manner and a target rank $k$, the goal is to find two
rank-$k$ orthogonal matrices $\mathbf{U}_k \in \mathbb{R}^{m \times k}$ and
$\mathbf{V}_k \in \mathbb{R}^{n \times k}$, and one positive semidefinite
diagonal matrix $\textbf{\Sigma}_k \in \mathbb{R}^{k \times k}$ such that
$\mathbf{A} \approx \mathbf{U}_k \textbf{\Sigma}_k \mathbf{V}_k^\mathsf{T}$
with respect to the spectral norm.
  Our main contributions are two computationally efficient and sub-linear space
algorithms for computing a differentially private low-rank factorization. We
consider two levels of privacy. In the first level of privacy, we consider two
matrices neighboring if their difference has a Frobenius norm at most $1$. In
the second level of privacy, we consider two matrices as neighboring if their
difference can be represented as an outer product of two unit vectors. Both
these privacy levels are stronger than those studied in the earlier papers such
as Dwork {\it et al.} (STOC 2014), Hardt and Roth (STOC 2013), and Hardt and
Price (NIPS 2014).
  As a corollary to our results, we get non-private algorithms that compute
low-rank factorization in the turnstile update model with respect to the
spectral norm. We note that, prior to this work, no algorithm that outputs
low-rank factorization with respect to the spectral norm in the turnstile
update model was known; i.e., our algorithm gives the first non-private
low-rank factorization with respect to the spectral norm in the turnstile
update mode.
</dc:description>
 <dc:description>Comment: 33 pages</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08959</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Searching with Measurement Dependent Noise</dc:title>
 <dc:creator>Kaspi, Yonatan</dc:creator>
 <dc:creator>Shayevitz, Ofer</dc:creator>
 <dc:creator>Javidi, Tara</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Consider a target moving at a constant velocity on a unit-circumference
circle, starting at an arbitrary location. To acquire the target, any region of
the circle can be probed to obtain a noisy measurement of the target's
presence, where the noise level increases with the size of the probed region.
We are interested in the expected time required to find the target to within
some given resolution and error probability. For a known velocity, we
characterize the optimal tradeoff between time and resolution, and show that in
contrast to the well studied case of constant measurement noise, measurement
dependent noise incurs a multiplicative gap in the targeting rate between
adaptive and non-adaptive search strategies. Moreover, our adaptive strategy
attains the optimal rate-reliability tradeoff. We further show that for optimal
non-adaptive search, accounting for an unknown velocity incurs a factor of at
least two in the targeting rate.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08973</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Impact of Adaptive and Cooperative Adaptive Cruise Control on
  Throughput of Signalized Intersections</dc:title>
 <dc:creator>Askari, Armin</dc:creator>
 <dc:creator>Farias, Daniel Albarnaz</dc:creator>
 <dc:creator>Kurzhanskiy, Alex A.</dc:creator>
 <dc:creator>Varaiya, Pravin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  To properly assess the impact of (cooperative) adaptive cruise control ACC
(CACC), one has to model vehicle dynamics. First of all, one has to choose the
car following model, as it determines the vehicle flow as vehicles accelerate
from standstill or decelerate because of the obstacle ahead. The other factor
significantly affecting the intersection throughput is the maximal vehicle
acceleration rate.
  In this paper, we analyze three car following behaviors: Gipps model,
Improved Intelligent Driver Model (IIDM) and Helly model. Gipps model exhibits
rather aggressive acceleration behavior. If used for the intersection
throughput estimation, this model would lead to overly optimistic results.
Helly model is convenient to analyze due to its linear nature, but its
deceleration behavior in the presence of obstacles ahead is unrealistically
abrupt. Showing the most realistic acceleration and deceleration behavior of
the three models, IIDM is suited for ACC/CACC impact evaluation better than the
other two.
  We discuss the influence of the maximal vehicle acceleration rate and
presence of different portions of ACC/CACC vehicles on intersection throughput
in the context of the three car following models. The analysis is done for two
cases: (1) free road downstream of the intersection; and (2) red light at some
distance downstream of the intersection.
  Finally, we introduce the platoon model and evaluate ACC and CACC with
platooning in terms of travel time ad network throughput using SUMO simulation
of the 4-mile stretch of Colorado Boulevard / Huntington Drive arterial with 13
signalized intersections in Arcadia, Southern California.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08974</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Scene Completion from a Single Depth Image</dc:title>
 <dc:creator>Song, Shuran</dc:creator>
 <dc:creator>Yu, Fisher</dc:creator>
 <dc:creator>Zeng, Andy</dc:creator>
 <dc:creator>Chang, Angel X.</dc:creator>
 <dc:creator>Savva, Manolis</dc:creator>
 <dc:creator>Funkhouser, Thomas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper focuses on semantic scene completion, a task for producing a
complete 3D voxel representation of volumetric occupancy and semantic labels
for a scene from a single-view depth map observation. Previous work has
considered scene completion and semantic labeling of depth maps separately.
However, we observe that these two problems are tightly intertwined. To
leverage the coupled nature of these two tasks, we introduce the semantic scene
completion network (SSCNet), an end-to-end 3D convolutional network that takes
a single depth image as input and simultaneously outputs occupancy and semantic
labels for all voxels in the camera view frustum. Our network uses a
dilation-based 3D context module to efficiently expand the receptive field and
enable 3D context learning. To train our network, we construct SUNCG - a
manually created large-scale dataset of synthetic 3D scenes with dense
volumetric annotations. Our experiments demonstrate that the joint model
outperforms methods addressing each task in isolation and outperforms
alternative approaches on the semantic scene completion task.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08976</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Range Loss for Deep Face Recognition with Long-tail</dc:title>
 <dc:creator>Zhang, Xiao</dc:creator>
 <dc:creator>Fang, Zhiyuan</dc:creator>
 <dc:creator>Wen, Yandong</dc:creator>
 <dc:creator>Li, Zhifeng</dc:creator>
 <dc:creator>Qiao, Yu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks have achieved great improvement on face
recognition in recent years because of its extraordinary ability in learning
discriminative features of people with different identities. To train such a
well-designed deep network, tremendous amounts of data is indispensable. Long
tail distribution specifically refers to the fact that a small number of
generic entities appear frequently while other objects far less existing.
Considering the existence of long tail distribution of the real world data,
large but uniform distributed data are usually hard to retrieve. Empirical
experiences and analysis show that classes with more samples will pose greater
impact on the feature learning process and inversely cripple the whole models
feature extracting ability on tail part data. Contrary to most of the existing
works that alleviate this problem by simply cutting the tailed data for uniform
distributions across the classes, this paper proposes a new loss function
called range loss to effectively utilize the whole long tailed data in training
process. More specifically, range loss is designed to reduce overall
intra-personal variations while enlarging inter-personal differences within one
mini-batch simultaneously when facing even extremely unbalanced data. The
optimization objective of range loss is the $k$ greatest range's harmonic mean
values in one class and the shortest inter-class distance within one batch.
Extensive experiments on two famous and challenging face recognition benchmarks
(Labeled Faces in the Wild (LFW) and YouTube Faces (YTF) not only demonstrate
the effectiveness of the proposed approach in overcoming the long tail effect
but also show the good generalization ability of the proposed approach.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures, Submitted to CVPR, 2017</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08981</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online tools for public engagement: case studies from Reykjavik</dc:title>
 <dc:creator>Bojic, Iva</dc:creator>
 <dc:creator>Marra, Giulia</dc:creator>
 <dc:creator>Naydenova, Vera</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  With the ubiquity of Internet technologies and growing demands for
transparency and open data policies, the role of social networking and online
deliberation tools for public engagement in decision-making has increased
substantially in the last decades. In this paper, we present the analysis of
how social media are used by different public bodies to enhance public
participation in deliberative democracy. We collected and reviewed published
information on the subject and carried out a field base assessment, involving
structured interviews with different government representatives and urban
policymakers. In order to compare collected data, we used a framework for
systematic analysis and comparison of e-participation platforms called the
participatory cube. The results we got were the following. Participatory
decision-making on matters of public concern justly consumes time and
resources, therefore online tools should be applied with consideration of scale
and efficiency, i.e. on burning issues for a majority of citizens or
small-scale local platforms, and in combination with meetings in real time and
space. The budget and workforce allocated to managing online engagement tools
should be proportionate to other political and administrative efforts to bring
to execution proposed ideas and act on collected feedback in order to satisfy
the needs expressed by the communities and not undermine their beliefs about
their power to influence decisions.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08983</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing the group sparsity based on the rank minimization methods</dc:title>
 <dc:creator>Zha, Zhiyuan</dc:creator>
 <dc:creator>Liu, Xin</dc:creator>
 <dc:creator>Huang, Xiaohua</dc:creator>
 <dc:creator>Shi, Henglin</dc:creator>
 <dc:creator>Xu, Yingyue</dc:creator>
 <dc:creator>Wang, Qiong</dc:creator>
 <dc:creator>Tang, Lan</dc:creator>
 <dc:creator>Zhang, Xinggan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sparse coding has achieved a great success in various image processing
studies. However, there is not any benchmark to measure the sparsity of image
patch/group because sparse discriminant conditions cannot keep unchanged. This
paper analyzes the sparsity of group based on the strategy of the rank
minimization. Firstly, an adaptive dictionary for each group is designed. Then,
we prove that group-based sparse coding is equivalent to the rank minimization
problem, and thus the sparse coefficient of each group is measured by
estimating the singular values of each group. Based on that measurement, the
weighted Schatten $p$-norm minimization (WSNM) has been found to be the closest
solution to the real singular values of each group. Thus, WSNM can be
equivalently transformed into a non-convex $\ell_p$-norm minimization problem
in group-based sparse coding. To make the proposed scheme tractable and robust,
the alternating direction method of multipliers (ADMM) is used to solve the
$\ell_p$-norm minimization problem. Experimental results on two applications:
image inpainting and image compressive sensing (CS) recovery have shown that
the proposed scheme outperforms many state-of-the-art methods.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1702.04463</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08986</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Fully Convolution Network for Semantic Segmentation</dc:title>
 <dc:creator>Shuai, Bing</dc:creator>
 <dc:creator>Liu, Ting</dc:creator>
 <dc:creator>Wang, Gang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Fully Convolution Networks (FCN) have achieved great success in dense
prediction tasks including semantic segmentation. In this paper, we start from
discussing FCN by understanding its architecture limitations in building a
strong segmentation network. Next, we present our Improved Fully Convolution
Network (IFCN). In contrast to FCN, IFCN introduces a context network that
progressively expands the receptive fields of feature maps. In addition, dense
skip connections are added so that the context network can be effectively
optimized. More importantly, these dense skip connections enable IFCN to fuse
rich-scale context to make reliable predictions. Empirically, those
architecture modifications are proven to be significant to enhance the
segmentation performance. Without engaging any contextual post-processing, IFCN
significantly advances the state-of-the-arts on ADE20K (ImageNet scene
parsing), Pascal Context, Pascal VOC 2012 and SUN-RGBD segmentation datasets.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08987</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Unlabeled Data for Neural Grammatical Error Detection</dc:title>
 <dc:creator>Liu, Zhuoran</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Identifying and correcting grammatical errors in the text written by
non-native writers has received increasing attention in recent years. Although
a number of annotated corpora have been established to facilitate data-driven
grammatical error detection and correction approaches, they are still limited
in terms of quantity and coverage because human annotation is labor-intensive,
time-consuming, and expensive. In this work, we propose to utilize unlabeled
data to train neural network based grammatical error detection models. The
basic idea is to cast error detection as a binary classification problem and
derive positive and negative training examples from unlabeled data. We
introduce an attention-based neural network to capture long-distance
dependencies that influence the word being detected. Experiments show that the
proposed approach significantly outperforms SVMs and convolutional networks
with fixed-size context window.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08991</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object Detection Free Instance Segmentation With Labeling
  Transformations</dc:title>
 <dc:creator>Jin, Long</dc:creator>
 <dc:creator>Chen, Zeyu</dc:creator>
 <dc:creator>Tu, Zhuowen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Instance segmentation has attracted recent attention in computer vision and
existing methods in this domain mostly have an object detection stage. In this
paper, we study the intrinsic challenge of the instance segmentation problem,
the presence of a quotient space (swapping the labels of different instances
leads to the same result), and propose new methods that are object proposal-
and object detection- free. We propose three alternative methods, namely
pixel-based affinity mapping, superpixel-based affinity learning, and
boundary-based component segmentation, all focusing on performing labeling
transformations to cope with the quotient space problem. By adopting fully
convolutional neural networks (FCN) like models, our framework attains
competitive results on both the PASCAL dataset (object-centric) and the Gland
dataset (texture-centric), which the existing methods are not able to do. Our
work also has the advantages in its transparency, simplicity, and being all
segmentation based.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08992</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relational Logic with Framing and Hypotheses: Technical Report</dc:title>
 <dc:creator>Banerjee, Anindya</dc:creator>
 <dc:creator>Naumann, David A.</dc:creator>
 <dc:creator>Nikouei, Mohammad</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Relational properties arise in many settings: relating two versions of a
program that use different data representations, noninterference properties for
security, etc. The main ingredient of relational verification, relating aligned
pairs of intermediate steps, has been used in numerous guises, but existing
relational program logics are narrow in scope. This paper introduces a logic
based on novel syntax that weaves together product programs to express
alignment of control flow points at which relational formulas are asserted.
Correctness judgments feature hypotheses with relational specifications,
discharged by a rule for the linking of procedure implementations. The logic
supports reasoning about program-pairs containing both similar and dissimilar
control and data structures. Reasoning about dynamically allocated objects is
supported by a frame rule based on frame conditions amenable to SMT provers. We
prove soundness and sketch how the logic can be used for data abstraction, loop
optimizations, and secure information flow.
</dc:description>
 <dc:description>Comment: Technical report to accompany a paper to appear in FSTTCS 2016</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08995</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Jolie Good Buildings: Internet of things for smart building
  infrastructure supporting concurrent apps utilizing distributed microservices</dc:title>
 <dc:creator>Gusmanov, Kamill</dc:creator>
 <dc:creator>Khanda, Kevin</dc:creator>
 <dc:creator>Salikhov, Dilshat</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:creator>Mavridis, Nikolaos</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  A large percentage of buildings, domestic or special-purpose, is expected to
become increasingly &quot;smarter&quot; in the future, due to the immense benefits in
terms of energy saving, safety, flexibility, and comfort, that relevant new
technologies offer. However, concerning the hardware, software, or platform
levels, no clearly dominant standard frameworks currently exist. Here, we will
present a prototype platform for supporting multiple concurrent applications
for smart buildings, which is utilizing an advanced sensor network as well as a
distributed micro services architecture, centrally featuring the Jolie
language. The architecture and benefits of our system are discussed, as well as
a prototype containing a number of nodes and a user interface, deployed in a
real-world academic building environment. Our results illustrate the promising
nature of our approach, as well as open avenues for future work towards it
wider and larger scale applicability.
</dc:description>
 <dc:description>Comment: In proceedings of the 1st International conference on Convergent
  Cognitive Information Technologies, 2016. arXiv admin note: substantial text
  overlap with arXiv:1610.09480</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08996</identifier>
 <datestamp>2017-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>JIGSAW-GEO (1.0): locally orthogonal staggered unstructured grid
  generation for general circulation modelling on the sphere</dc:title>
 <dc:creator>Engwirda, Darren</dc:creator>
 <dc:subject>Physics - Atmospheric and Oceanic Physics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  An algorithm for the generation of non-uniform, locally-orthogonal staggered
unstructured spheroidal grids is described. This technique is designed to
generate very high-quality staggered Voronoi/Delaunay meshes appropriate for
general circulation modelling on the sphere, including applications to
atmospheric simulation, ocean-modelling and numerical weather prediction. Using
a recently developed Frontal-Delaunay refinement technique, a method for the
construction of high-quality unstructured spheroidal Delaunay triangulations is
introduced. A locally-orthogonal polygonal grid, derived from the associated
Voronoi diagram, is computed as the staggered dual. It is shown that use of the
Frontal-Delaunay refinement technique allows for the generation of very
high-quality unstructured triangulations, satisfying a-priori bounds on element
size and shape. Grid-quality is further improved through the application of
hill-climbing type optimisation techniques. Overall, the algorithm is shown to
produce grids with very high element quality and smooth grading
characteristics, while imposing relatively low computational expense. A
selection of uniform and non-uniform spheroidal grids appropriate for
high-resolution, multi-scale general circulation modelling are presented. These
grids are shown to satisfy the geometric constraints associated with
contemporary unstructured C-grid type finite-volume models, including the Model
for Prediction Across Scales (MPAS-O). The use of user-defined mesh-spacing
functions to generate smoothly graded, non-uniform grids for multi-resolution
type studies is discussed in detail.
</dc:description>
 <dc:description>Comment: Final revisions, as per: Engwirda, D.: JIGSAW-GEO (1.0): locally
  orthogonal staggered unstructured grid generation for general circulation
  modelling on the sphere, Geosci. Model Dev., 10, 2117-2140,
  https://doi.org/10.5194/gmd-10-2117-2017, 2017</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-06-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08996</dc:identifier>
 <dc:identifier>doi:10.5194/gmd-10-2117-2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08998</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepSetNet: Predicting Sets with Deep Neural Networks</dc:title>
 <dc:creator>Rezatofighi, S. Hamid</dc:creator>
 <dc:creator>G, Vijay Kumar B</dc:creator>
 <dc:creator>Milan, Anton</dc:creator>
 <dc:creator>Abbasnejad, Ehsan</dc:creator>
 <dc:creator>Dick, Anthony</dc:creator>
 <dc:creator>Reid, Ian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper addresses the task of set prediction using deep learning. This is
important because the output of many computer vision tasks, including image
tagging and object detection, are naturally expressed as sets of entities
rather than vectors. As opposed to a vector, the size of a set is not fixed in
advance, and it is invariant to the ordering of entities within it. We define a
likelihood for a set distribution and learn its parameters using a deep neural
network. We also derive a loss for predicting a discrete distribution
corresponding to set cardinality. Set prediction is demonstrated on the problem
of multi-class image classification. Moreover, we show that the proposed
cardinality loss can also trivially be applied to the tasks of object counting
and pedestrian detection. Our approach outperforms existing methods in all
three cases on standard datasets.
</dc:description>
 <dc:description>Comment: Accepted in IEEE International Conference on Computer Vision (ICCV),
  Venice, 2017, (Spotlight)</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09003</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A vertex ordering characterization of simple-triangle graphs</dc:title>
 <dc:creator>Takaoka, Asahi</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Consider two horizontal lines in the plane. A pair of a point on the top line
and an interval on the bottom line defines a triangle between two lines. The
intersection graph of such triangles is called a simple-triangle graph. This
paper shows a vertex ordering characterization of simple-triangle graphs as
follows: a graph is a simple-triangle graph if and only if there is a linear
ordering of the vertices that contains both an alternating orientation of the
graph and a transitive orientation of the complement of the graph.
</dc:description>
 <dc:description>Comment: 6 pages, 14 figures, Keywords: Alternatly orientable graphs,
  Linear-interval orders, PI graphs, PI orders, Simple-triangle graphs, Vertex
  ordering characterization</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09007</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hyperspectral CNN Classification with Limited Training Samples</dc:title>
 <dc:creator>Windrim, Lloyd</dc:creator>
 <dc:creator>Ramakrishnan, Rishi</dc:creator>
 <dc:creator>Melkumyan, Arman</dc:creator>
 <dc:creator>Murphy, Richard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Hyperspectral imaging sensors are becoming increasingly popular in robotics
applications such as agriculture and mining, and allow per-pixel thematic
classification of materials in a scene based on their unique spectral
signatures. Recently, convolutional neural networks have shown remarkable
performance for classification tasks, but require substantial amounts of
labelled training data. This data must sufficiently cover the variability
expected to be encountered in the environment. For hyperspectral data, one of
the main variations encountered outdoors is due to incident illumination, which
can change in spectral shape and intensity depending on the scene geometry. For
example, regions occluded from the sun have a lower intensity and their
incident irradiance skewed towards shorter wavelengths.
  In this work, a data augmentation strategy based on relighting is used during
training of a hyperspectral convolutional neural network. It allows training to
occur in the outdoor environment given only a small labelled region, which does
not need to sufficiently represent the geometric variability of the entire
scene. This is important for applications where obtaining large amounts of
training data is labourious, hazardous or difficult, such as labelling pixels
within shadows. Radiometric normalisation approaches for pre-processing the
hyperspectral data are analysed and it is shown that methods based on the raw
pixel data are sufficient to be used as input for the classifier. This removes
the need for external hardware such as calibration boards, which can restrict
the application of hyperspectral sensors in robotics applications. Experiments
to evaluate the classification system are carried out on two datasets captured
from a field-based platform.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09009</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Self-Authentication and Deniable Efficient Group Key Agreement
  Protocol for VANET</dc:title>
 <dc:creator>Han, Mu</dc:creator>
 <dc:creator>Hua, Lei</dc:creator>
 <dc:creator>Ma, Shidian</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  With the rapid development of vehicular ad hoc Network (VANET), it is gaining
significant popularity and receiving increasing attentions from academics and
industry in security and efficiency. To address security and efficiency issues,
a self-authentication and deniable efficient group key agreement protocol is
proposed in this paper. This scheme establishes a group between road-side unit
(RSU) and vehicles by using self-authentication without certification
authority, and enhances certification efficiency by using group key (GK)
transmission method. At the same time, to avoid the attacker to attack the
legal vehicle by RSU, we adopt deniable group key agreement method to
negotiation session key (sk) and use it to transmit GK between RSU. In
addition, vehicles not only broadcast messages to other vehicles, but also
communicate with other members in the same group. So group communication is
necessary in VANET. Finally, the security and performance analysis shown that
our scheme is security, meanwhile the verification delay, transmission
overheard and message delay are more efficient than other related schemes in
authentication, transmission and communication.
</dc:description>
 <dc:description>Comment: 27 page, 7 figures,4 tables</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09010</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Human Pose Estimation from a Single Image via Distance Matrix
  Regression</dc:title>
 <dc:creator>Moreno-Noguer, Francesc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the problem of 3D human pose estimation from a single
image. We follow a standard two-step pipeline by first detecting the 2D
position of the $N$ body joints, and then using these observations to infer 3D
pose. For the first step, we use a recent CNN-based detector. For the second
step, most existing approaches perform 2$N$-to-3$N$ regression of the Cartesian
joint coordinates. We show that more precise pose estimates can be obtained by
representing both the 2D and 3D human poses using $N\times N$ distance
matrices, and formulating the problem as a 2D-to-3D distance matrix regression.
For learning such a regressor we leverage on simple Neural Network
architectures, which by construction, enforce positivity and symmetry of the
predicted matrices. The approach has also the advantage to naturally handle
missing observations and allowing to hypothesize the position of non-observed
joints. Quantitative results on Humaneva and Human3.6M datasets demonstrate
consistent performance gains over state-of-the-art. Qualitative evaluation on
the images in-the-wild of the LSP dataset, using the regressor learned on
Human3.6M, reveals very promising generalization results.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09011</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Fine-grained Path Control in Software Defined Networks</dc:title>
 <dc:creator>Luo, Long</dc:creator>
 <dc:creator>Yu, Hongfang</dc:creator>
 <dc:creator>Luo, Shouxi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The OpenFlow-based SDN is widely studied to better network performance
through planning fine-grained paths. However, being designed to configure path
hop-by-hop, it faces the scalability issue that both the flow table overhead
and path setup delay are unacceptable for large-scale networks. In this paper,
we propose PACO, a framework based on Source Routing to address that problem
through quickly pushing paths into the packet header at network edges and
pre-installing few rules at the network core. The straightforward
implementation of SR is inefficient as it would incur too many path labels;
other efficient approaches would sacrifice path flexibility (e.g., DEFO). To
implement SR efficiently and flexibly, PACO presents each path as a
concatenation of pathlets and introduces algorithms to compute pathlets and
concatenate paths with minimum path labels. Our extensive simulations confirm
the scalability of PACO as it saves the flow table overhead up to 94% compared
with OpenFlow-SDN solutions and show that PACO outperforms SR-SDN solutions by
supporting more than 40% paths with few label overhead.
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09012</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Knapsack Problem and Budgeted Truthful Bipartite Matching</dc:title>
 <dc:creator>Vaze, Rahul</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Two related online problems: knapsack and truthful bipartite matching are
considered. For these two problems, the common theme is how to `match' an
arriving left vertex in an online fashion with any of the available right
vertices, if at all, so as to maximize the sum of the value of the matched
edges, subject to satisfying a sum-weight constraint on the matched left
vertices. Assuming that the left vertices arrive in an uniformly random order
(secretary model), two almost similar algorithms are proposed for the two
problems, that are $2e$ competitive and $24$ competitive, respectively. The
proposed online bipartite matching algorithm is also shown to be truthful:
there is no incentive for any left vertex to misreport its bid/weight. Direct
applications of these problems include job allocation with load balancing,
generalized adwords, crowdsourcing auctions, and matching wireless users to
cooperative relays in device-to-device communication enabled cellular network.
</dc:description>
 <dc:description>Comment: To appear in IEEE INFOCOM 2017, May 1-4, 2017</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09014</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blocking and Other Enhancements for Bottom-Up Model Generation Methods</dc:title>
 <dc:creator>Baumgartner, Peter</dc:creator>
 <dc:creator>Schmidt, Renate A.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Model generation is a problem complementary to theorem proving and is
important for fault analysis and debugging of formal specifications of security
protocols, programs and terminological definitions. This paper discusses
several ways of enhancing the paradigm of bottom-up model generation. The two
main contributions are new, generalized blocking techniques and a new
range-restriction transformation. The blocking techniques are based on simple
transformations of the input set together with standard equality reasoning and
redundancy elimination techniques. These provide general methods for finding
small, finite models. The range-restriction transformation refines existing
transformations to range-restricted clauses by carefully limiting the creation
of domain terms. All possible combinations of the introduced techniques and
classical range-restriction were tested on the clausal problems of the TPTP
Version 6.0.0 with an implementation based on the SPASS theorem prover using a
hyperresolution-like refinement. Unrestricted domain blocking gave best results
for satisfiable problems showing it is a powerful technique indispensable for
bottom-up model generation methods. Both in combination with the new
range-restricting transformation, and the classical range-restricting
transformation, good results have been obtained. Limiting the creation of terms
during the inference process by using the new range restricting transformation
has paid off, especially when using it together with a shifting transformation.
The experimental results also show that classical range restriction with
unrestricted blocking provides a useful complementary method. Overall, the
results showed bottom-up model generation methods were good for disproving
theorems and generating models for satisfiable problems, but less efficient
than SPASS in auto mode for unsatisfiable problems.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09017</identifier>
 <datestamp>2017-01-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Prefix Normal Words and Prefix Normal Forms</dc:title>
 <dc:creator>Burcsi, P&#xe9;ter</dc:creator>
 <dc:creator>Fici, Gabriele</dc:creator>
 <dc:creator>Lipt&#xe1;k, Zsuzsanna</dc:creator>
 <dc:creator>Ruskey, Frank</dc:creator>
 <dc:creator>Sawada, Joe</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A $1$-prefix normal word is a binary word with the property that no factor
has more $1$s than the prefix of the same length; a $0$-prefix normal word is
defined analogously. These words arise in the context of indexed binary jumbled
pattern matching, where the aim is to decide whether a word has a factor with a
given number of $1$s and $0$s (a given Parikh vector). Each binary word has an
associated set of Parikh vectors of the factors of the word. Using prefix
normal words, we provide a characterization of the equivalence class of binary
words having the same set of Parikh vectors of their factors.
  We prove that the language of prefix normal words is not context-free and is
strictly contained in the language of pre-necklaces, which are prefixes of
powers of Lyndon words. We give enumeration results on $\textit{pnw}(n)$, the
number of prefix normal words of length $n$, showing that, for sufficiently
large $n$, \[ 2^{n-4 \sqrt{n \lg n}} \le \textit{pnw}(n) \le 2^{n - \lg n + 1}.
\]
  For fixed density (number of $1$s), we show that the ordinary generating
function of the number of prefix normal words of length $n$ and density $d$ is
a rational function. Finally, we give experimental results on
$\textit{pnw}(n)$, discuss further properties, and state open problems.
</dc:description>
 <dc:description>Comment: To appear in Theoretical Computer Science</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09017</dc:identifier>
 <dc:identifier>Theoretical Computer Science, 659: 1-13, 2017</dc:identifier>
 <dc:identifier>doi:10.1016/j.tcs.2016.10.015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09020</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Developing a cardiovascular disease risk factor annotated corpus of
  Chinese electronic medical records</dc:title>
 <dc:creator>Su, Jia</dc:creator>
 <dc:creator>He, Bin</dc:creator>
 <dc:creator>Guan, Yi</dc:creator>
 <dc:creator>Jiang, Jingchi</dc:creator>
 <dc:creator>Yang, Jinfeng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Cardiovascular disease (CVD) has become the leading cause of death in China,
and most of the cases can be prevented by controlling risk factors. The goal of
this study was to build a corpus of CVD risk factor annotations based on
Chinese electronic medical records (CEMRs). This corpus is intended to be used
to develop a risk factor information extraction system that, in turn, can be
applied as a foundation for the further study of the progress of risk factors
and CVD. We designed a light annotation task to capture CVD risk factors with
indicators, temporal attributes and assertions that were explicitly or
implicitly displayed in the records. The task included: 1) preparing data; 2)
creating guidelines for capturing annotations (these were created with the help
of clinicians); 3) proposing an annotation method including building the
guidelines draft, training the annotators and updating the guidelines, and
corpus construction. Then, a risk factor annotated corpus based on
de-identified discharge summaries and progress notes from 600 patients was
developed. Built with the help of clinicians, this corpus has an
inter-annotator agreement (IAA) F1-measure of 0.968, indicating a high
reliability. To the best of our knowledge, this is the first annotated corpus
concerning CVD risk factors in CEMRs and the guidelines for capturing CVD risk
factor annotations from CEMRs were proposed. The obtained document-level
annotations can be applied in future studies to monitor risk factors and CVD
over the long term.
</dc:description>
 <dc:description>Comment: 32 pages, 3 figures, 3 tables</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09026</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Awesome Typography: Statistics-Based Text Effects Transfer</dc:title>
 <dc:creator>Yang, Shuai</dc:creator>
 <dc:creator>Liu, Jiaying</dc:creator>
 <dc:creator>Lian, Zhouhui</dc:creator>
 <dc:creator>Guo, Zongming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we explore the problem of generating fantastic special-effects
for the typography. It is quite challenging due to the model diversities to
illustrate varied text effects for different characters. To address this issue,
our key idea is to exploit the analytics on the high regularity of the spatial
distribution for text effects to guide the synthesis process. Specifically, we
characterize the stylized patches by their normalized positions and the optimal
scales to depict their style elements. Our method first estimates these two
features and derives their correlation statistically. They are then converted
into soft constraints for texture transfer to accomplish adaptive multi-scale
texture synthesis and to make style element distribution uniform. It allows our
algorithm to produce artistic typography that fits for both local texture
patterns and the global spatial distribution in the example. Experimental
results demonstrate the superiority of our method for various text effects over
conventional style transfer methods. In addition, we validate the effectiveness
of our algorithm with extensive artistic typography library generation.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09028</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing Features for the Detection of Happy Endings in German Novels</dc:title>
 <dc:creator>Jannidis, Fotis</dc:creator>
 <dc:creator>Reger, Isabella</dc:creator>
 <dc:creator>Zehe, Albin</dc:creator>
 <dc:creator>Becker, Martin</dc:creator>
 <dc:creator>Hettinger, Lena</dc:creator>
 <dc:creator>Hotho, Andreas</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  With regard to a computational representation of literary plot, this paper
looks at the use of sentiment analysis for happy ending detection in German
novels. Its focus lies on the investigation of previously proposed sentiment
features in order to gain insight about the relevance of specific features on
the one hand and the implications of their performance on the other hand.
Therefore, we study various partitionings of novels, considering the highly
variable concept of &quot;ending&quot;. We also show that our approach, even though still
rather simple, can potentially lead to substantial findings relevant to
literary studies.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09030</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An exact method for computing the frustration index in signed networks
  using binary programming</dc:title>
 <dc:creator>Aref, Samin</dc:creator>
 <dc:creator>Mason, Andrew J.</dc:creator>
 <dc:creator>Wilson, Mark C.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>90C10, 90C20, 90C35, 90C57, 90C90, 05C15, 11E16, 65K05</dc:subject>
 <dc:description>  Computing the frustration index of a signed graph is a key to solving
problems in different fields of research including social networks, physics,
material science, and biology. In social networks the frustration index
determines network distance from a state of structural balance. Although the
definition of frustration index goes back to 1960, an exact algorithmic
computation method has not yet been proposed. The main reason seems to be the
complexity of computing the frustration index which is closely related to
well-known NP-hard problems such as MAXCUT.
  New quadratic and linear binary programming models are developed to compute
the frustration index exactly. We introduce several speed-up techniques
involving prioritised branching, local search heuristics, and valid
inequalities inferred from graph structural properties. The computational
improvements achieved by implementing the speed-up techniques allow us to
calculate the exact values of the frustration index by running the optimisation
models in Gurobi solver.
  The speed-up techniques make our models capable of processing graphs with
thousands of nodes and edges in seconds on inexpensive hardware. The solve time
and solution quality comparison against the literature shows the superiority of
our models in both random and real signed networks.
</dc:description>
 <dc:description>Comment: 24 pages, 2 figures, 4 tables</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09035</identifier>
 <datestamp>2017-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algebraic Laws for True Concurrency</dc:title>
 <dc:creator>Wang, Yong</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We find the algebraic laws for true concurrency. Eventually, we establish a
whole axiomatization for true concurrency called $APTC$ (Algebra for
Parallelism in True Concurrency). The theory $APTC$ has four modules: $BATC$
(Basic Algebra for True Concurrency), $APTC$ (Algebra for Parallelism in True
Concurrency), recursion and abstraction. And also, we show the applications and
extensions of $APTC$.
</dc:description>
 <dc:description>Comment: 74 pages,2 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09048</identifier>
 <datestamp>2017-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In situ, steerable, hardware-independent and data-structure agnostic
  visualization with ISAAC</dc:title>
 <dc:creator>Matthes, Alexander</dc:creator>
 <dc:creator>Huebl, Axel</dc:creator>
 <dc:creator>Widera, Ren&#xe9;</dc:creator>
 <dc:creator>Grottel, Sebastian</dc:creator>
 <dc:creator>Gumhold, Stefan</dc:creator>
 <dc:creator>Bussmann, Michael</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The computation power of supercomputers grows faster than the bandwidth of
their storage and network. Especially applications using hardware accelerators
like Nvidia GPUs cannot save enough data to be analyzed in a later step. There
is a high risk of loosing important scientific information. We introduce the in
situ template library ISAAC which enables arbitrary applications like
scientific simulations to live visualize their data without the need of deep
copy operations or data transformation using the very same compute node and
hardware accelerator the data is already residing on. Arbitrary meta data can
be added to the renderings and user defined steering commands can be
asynchronously sent back to the running application. Using an aggregating
server, ISAAC streams the interactive visualization video and enables user to
access their applications from everywhere.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09048</dc:identifier>
 <dc:identifier>Supercomputing Frontiers and Innovations, [S.l.], v. 3, n. 4, p.
  30-48, oct. 2016</dc:identifier>
 <dc:identifier>doi:10.14529/jsfi160403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09051</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep, Dense, and Low-Rank Gaussian Conditional Random Fields</dc:title>
 <dc:creator>Chandra, Siddhartha</dc:creator>
 <dc:creator>Kokkinos, Iasonas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work we introduce a fully-connected graph structure in the Deep
Gaussian Conditional Random Field (G-CRF) model. For this we express the
pairwise interactions between pixels as the inner-products of low-dimensional
embeddings, delivered by a new subnetwork of a deep architecture. We
efficiently minimize the resulting energy by solving the resulting low-rank
linear system with conjugate gradients, and derive an analytic expression for
the gradient of our embeddings which allows us to train them end-to-end with
backpropagation.
  We demonstrate the merit of our approach by achieving state of the art
results on three challenging Computer Vision benchmarks, namely semantic
segmentation, human parts segmentation, and saliency estimation. Our
implementation is fully GPU based, built on top of the Caffe library, and will
be made publicly available.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09053</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidirectional Multirate Reconstruction for Temporal Modeling in Videos</dc:title>
 <dc:creator>Zhu, Linchao</dc:creator>
 <dc:creator>Xu, Zhongwen</dc:creator>
 <dc:creator>Yang, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite the recent success of neural networks in image feature learning, a
major problem in the video domain is the lack of sufficient labeled data for
learning to model temporal information. In this paper, we propose an
unsupervised temporal modeling method that learns from untrimmed videos. The
speed of motion varies constantly, e.g., a man may run quickly or slowly. We
therefore train a Multirate Visual Recurrent Model (MVRM) by encoding frames of
a clip with different intervals. This learning process makes the learned model
more capable of dealing with motion speed variance. Given a clip sampled from a
video, we use its past and future neighboring clips as the temporal context,
and reconstruct the two temporal transitions, i.e., present$\rightarrow$past
transition and present$\rightarrow$future transition, reflecting the temporal
information in different views. The proposed method exploits the two
transitions simultaneously by incorporating a bidirectional reconstruction
which consists of a backward reconstruction and a forward reconstruction. We
apply the proposed method to two challenging video tasks, i.e., complex event
detection and video captioning, in which it achieves state-of-the-art
performance. Notably, our method generates the best single feature for event
detection with a relative improvement of 10.4% on the MEDTest-13 dataset and
achieves the best performance in video captioning across all evaluation metrics
on the YouTube2Text dataset.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09058</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on the Singleton bounds for codes over finite rings</dc:title>
 <dc:creator>Tang, Yongsheng</dc:creator>
 <dc:creator>Xu, Heqian</dc:creator>
 <dc:creator>Sun, Zhonghua</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we give a notation on the Singleton bounds for linear codes
over a finite commutative quasi-Frobenius ring in the work of Shiromoto [5]. We
show that there exists a class of finite commutative quasi-Frobenius rings. The
Singleton bounds for linear codes over such rings satisfy
  \[ \frac{d(C)-1}{A}\leq n-\log_{|R|}|C|. \]
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09065</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DrivingStyles: A mobile platform for driving styles and fuel consumption
  characterization</dc:title>
 <dc:creator>Meseguer, Javier E.</dc:creator>
 <dc:creator>Toh, C. K.</dc:creator>
 <dc:creator>Calafate, Carlos T.</dc:creator>
 <dc:creator>Cano, Juan Carlos</dc:creator>
 <dc:creator>Manzoni, Pietro</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Intelligent Transportation Systems (ITS) rely on connected vehicle
applications to address real-world problems. Research is currently being
conducted to support safety, mobility and environmental applications. This
paper presents the DrivingStyles architecture, which adopts data mining
techniques and neural networks to analyze and generate a classification of
driving styles and fuel consumption based on driver characterization. In
particular, we have implemented an algorithm that is able to characterize the
degree of aggressiveness of each driver. We have also developed a methodology
to calculate, in real-time, the consumption and environmental impact of spark
ignition and diesel vehicles from a set of variables obtained from the
vehicle's Electronic Control Unit (ECU). In this paper, we demonstrate the
impact of the driving style on fuel consumption, as well as its correlation
with the greenhouse gas emissions generated by each vehicle. Overall, our
platform is able to assist drivers in correcting their bad driving habits,
while offering helpful tips to improve fuel economy and driving safety.
</dc:description>
 <dc:description>Comment: Journal of Communications and Networks</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09067</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Choreographies: Theory And Implementation</dc:title>
 <dc:creator>Preda, Mila Dalla</dc:creator>
 <dc:creator>Gabbrielli, Maurizio</dc:creator>
 <dc:creator>Giallorenzo, Saverio</dc:creator>
 <dc:creator>Lanese, Ivan</dc:creator>
 <dc:creator>Mauro, Jacopo</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Programming distributed applications free from communication deadlocks and
race conditions is complex. Preserving these properties when applications are
updated at runtime is even harder. We present a choreographic approach for
programming updatable, distributed applications. We define a choreography
language, called Dynamic Interaction-Oriented Choreography (AIOC), that allows
the programmer to specify, from a global viewpoint, which parts of the
application can be updated. At runtime, these parts may be replaced by new AIOC
fragments from outside the application. AIOC programs are compiled, generating
code for each participant in a process-level language called Dynamic
Process-Oriented Choreographies (APOC). We prove that APOC distributed
applications generated from AIOC specifications are deadlock free and race free
and that these properties hold also after any runtime update. We instantiate
the theoretical model above into a programming framework called Adaptable
Interaction-Oriented Choreographies in Jolie (AIOCJ) that comprises an
integrated development environment, a compiler from an extension of AIOCs to
distributed Jolie programs, and a runtime environment to support their
execution.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1407.0970</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09067</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 2 (April 10,
  2017) lmcs:3263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09072</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster Randomized Worst-Case Update Time for Dynamic Subgraph
  Connectivity</dc:title>
 <dc:creator>Duan, Ran</dc:creator>
 <dc:creator>Zhang, Le</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Real-world networks are prone to breakdowns. Typically in the underlying
graph $G$, besides the insertion or deletion of edges, the set of active
vertices changes overtime. A vertex might work actively, or it might fail, and
gets isolated temporarily. The active vertices are grouped as a set $S$. $S$ is
subjected to updates, i.e., a failed vertex restarts, or an active vertex
fails, and gets deleted from $S$. Dynamic subgraph connectivity answers the
queries on connectivity between any two active vertices in the subgraph of $G$
induced by $S$. The problem is solved by a dynamic data structure, which
supports the updates and answers the connectivity queries. In the general
undirected graph, the best results for it include $\widetilde{O}(m^{2/3})$
deterministic amortized update time, $\widetilde{O}(m^{4/5})$ and
$\widetilde{O}(\sqrt{mn})$ deterministic worst-case update time. In the paper,
we propose a randomized data structure, which has $\widetilde{O}(m^{3/4})$
worst-case update time.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09073</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Unique Decoding from Insertions and Deletions</dc:title>
 <dc:creator>Mazooji, Kayvon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study how often unique decoding from $t$ insertions or $t$
deletions occurs for error correcting codes. Insertions and deletions
frequently occur in synchronization problems and DNA, a medium which is
beginning to be used for long term data storage.
  We define natural probabilistic channels that make $t$ insertions or $t$
deletions, and study the probability of unique decoding. Our most substantial
contribution is the derivation of tight upper bounds on the probability of
unique decoding for messages passed though these channels. We also consider
other aspects of the problem, and derive improved upper bounds for linear codes
and VT-codes.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures, study of deletion channel added (upper bounds,
  asymptotics, ect.), tight upper bound on probability of unique decoding for
  uniform t-insertion channel added (conjecture from previous version proved
  true), improved upper bounds for VT codes and linear codes added, improved
  asymptotic analysis</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09078</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Scene Understanding: End-to-End Multi-Person Action Localization
  and Collective Activity Recognition</dc:title>
 <dc:creator>Bagautdinov, Timur</dc:creator>
 <dc:creator>Alahi, Alexandre</dc:creator>
 <dc:creator>Fleuret, Fran&#xe7;ois</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:creator>Savarese, Silvio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a unified framework for understanding human social behaviors in
raw image sequences. Our model jointly detects multiple individuals, infers
their social actions, and estimates the collective actions with a single
feed-forward pass through a neural network. We propose a single architecture
that does not rely on external detection algorithms but rather is trained
end-to-end to generate dense proposal maps that are refined via a novel
inference scheme. The temporal consistency is handled via a person-level
matching Recurrent Neural Network. The complete model takes as input a sequence
of frames and outputs detections along with the estimates of individual actions
and collective activities. We demonstrate state-of-the-art performance of our
algorithm on multiple publicly available benchmarks.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09083</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction of Video Popularity in the Absence of Reliable Data from
  Video Hosting Services: Utility of Traces Left by Users on the Web</dc:title>
 <dc:creator>Drutsa, Alexey</dc:creator>
 <dc:creator>Gusev, Gleb</dc:creator>
 <dc:creator>Serdyukov, Pavel</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68T05, 62F07</dc:subject>
 <dc:subject>H.3, H.3.3, H.5.1, H.3.5, H.1.2</dc:subject>
 <dc:description>  With the growth of user-generated content, we observe the constant rise of
the number of companies, such as search engines, content aggregators, etc.,
that operate with tremendous amounts of web content not being the services
hosting it. Thus, aiming to locate the most important content and promote it to
the users, they face the need of estimating the current and predicting the
future content popularity.
  In this paper, we approach the problem of video popularity prediction not
from the side of a video hosting service, as done in all previous studies, but
from the side of an operating company, which provides a popular video search
service that aggregates content from different video hosting websites. We
investigate video popularity prediction based on features from three primary
sources available for a typical operating company: first, the content hosting
provider may deliver its data via its API, second, the operating company makes
use of its own search and browsing logs, third, the company crawls information
about embeds of a video and links to a video page from publicly available
resources on the Web. We show that video popularity prediction based on the
embed and link data coupled with the internal search and browsing data
significantly improves video popularity prediction based only on the data
provided by the video hosting and can even adequately replace the API data in
the cases when it is partly or completely unavailable.
</dc:description>
 <dc:description>Comment: 23 pages, 4 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09084</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Hyperlink Prediction for the WWW</dc:title>
 <dc:creator>Garcia-Gasulla, Dario</dc:creator>
 <dc:creator>Ayguad&#xe9;, Eduard</dc:creator>
 <dc:creator>Labarta, Jes&#xfa;s</dc:creator>
 <dc:creator>Cort&#xe9;s, Ulises</dc:creator>
 <dc:creator>Suzumura, Toyotaro</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The hyperlink prediction task, that of proposing new links between webpages,
can be used to improve search engines, expand the visibility of web pages, and
increase the connectivity and navigability of the web. Hyperlink prediction is
typically performed on webgraphs composed by thousands or millions of vertices,
where on average each webpage contains less than fifty links. Algorithms
processing graphs so large and sparse require to be both scalable and precise,
a challenging combination. Similarity-based algorithms are among the most
scalable solutions within the link prediction field, due to their parallel
nature and computational simplicity. These algorithms independently explore the
nearby topological features of every missing link from the graph in order to
determine its likelihood. Unfortunately, the precision of similarity-based
algorithms is limited, which has prevented their broad application so far. In
this work we explore the performance of similarity-based algorithms for the
particular problem of hyperlink prediction on large webgraphs, and propose a
novel method which assumes the existence of hierarchical properties. We
evaluate this new approach on several webgraphs and compare its performance
with that of the current best similarity-based algorithms. Its remarkable
performance leads us to argue on the applicability of the proposal, identifying
several use cases of hyperlink prediction. We also describes the approach we
took for the computation of large-scale graphs from the perspective of
high-performance computing, providing details on the implementation and
parallelization of code.
</dc:description>
 <dc:description>Comment: Submitted to Transactions on Internet Technology journal</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09099</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Role and the Importance of Features for Background Modeling and
  Foreground Detection</dc:title>
 <dc:creator>Bouwmans, Thierry</dc:creator>
 <dc:creator>Silva, Caroline</dc:creator>
 <dc:creator>Marghes, Cristina</dc:creator>
 <dc:creator>Zitouni, Mohammed Sami</dc:creator>
 <dc:creator>Bhaskar, Harish</dc:creator>
 <dc:creator>Frelicot, Carl</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Background modeling has emerged as a popular foreground detection technique
for various applications in video surveillance. Background modeling methods
have become increasing efficient in robustly modeling the background and hence
detecting moving objects in any visual scene. Although several background
subtraction and foreground detection have been proposed recently, no
traditional algorithm today still seem to be able to simultaneously address all
the key challenges of illumination variation, dynamic camera motion, cluttered
background and occlusion. This limitation can be attributed to the lack of
systematic investigation concerning the role and importance of features within
background modeling and foreground detection. With the availability of a rather
large set of invariant features, the challenge is in determining the best
combination of features that would improve accuracy and robustness in
detection. The purpose of this study is to initiate a rigorous and
comprehensive survey of features used within background modeling and foreground
detection. Further, this paper presents a systematic experimental and
statistical analysis of techniques that provide valuable insight on the trends
in background modeling and use it to draw meaningful recommendations for
practitioners. In this paper, a preliminary review of the key characteristics
of features based on the types and sizes is provided in addition to
investigating their intrinsic spectral, spatial and temporal properties.
Furthermore, improvements using statistical and fuzzy tools are examined and
techniques based on multiple features are benchmarked against reliability and
selection criterion. Finally, a description of the different resources
available such as datasets and codes is provided.
</dc:description>
 <dc:description>Comment: To be submitted to Computer Science Review</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09100</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Compose Words into Sentences with Reinforcement Learning</dc:title>
 <dc:creator>Yogatama, Dani</dc:creator>
 <dc:creator>Blunsom, Phil</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:creator>Grefenstette, Edward</dc:creator>
 <dc:creator>Ling, Wang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We use reinforcement learning to learn tree-structured neural networks for
computing representations of natural language sentences. In contrast with prior
work on tree-structured models in which the trees are either provided as input
or predicted using supervision from explicit treebank annotations, the tree
structures in this work are optimized to improve performance on a downstream
task. Experiments demonstrate the benefit of learning task-specific composition
orders, outperforming both sequential encoders and recursive encoders based on
treebank annotations. We analyze the induced trees and show that while they
discover some linguistically intuitive structures (e.g., noun phrases, simple
verb phrases), they are different than conventional English syntactic
structures.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09104</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alphabet Size Reduction for Secure Network Coding: A Graph Theoretic
  Approach</dc:title>
 <dc:creator>Guang, Xuan</dc:creator>
 <dc:creator>Yeung, Raymond W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We consider a communication network where there exist wiretappers who can
access a subset of channels, called a wiretap set, which is chosen from a given
collection of wiretap sets. The collection of wiretap sets can be arbitrary.
Secure network coding is applied to prevent the source information from being
leaked to the wiretappers. In secure network coding, the required alphabet size
is an open problem not only of theoretical interest but also of practical
importance, because it is closely related to the implementation of such coding
schemes in terms of computational complexity and storage requirement. In this
paper, we develop a systematic graph-theoretic approach for improving Cai and
Yeung's lower bound on the required alphabet size for the existence of secure
network codes. The new lower bound thus obtained, which depends only on the
network topology and the collection of wiretap sets, can be significantly
smaller than Cai and Yeung's lower bound. A polynomial-time algorithm is
devised for efficient computation of the new lower bound.
</dc:description>
 <dc:description>Comment: 35 pages</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09116</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tool Support for Continuous Quality Control</dc:title>
 <dc:creator>Deissenboeck, Florian</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:creator>Pizka, Markus</dc:creator>
 <dc:creator>Hummel, Benjamin</dc:creator>
 <dc:creator>Juergens, Elmar</dc:creator>
 <dc:creator>Parareda, Benedikt Mas y</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Over time, software systems suffer gradual quality decay and therefore costs
can rise if organizations fail to take proactive countermeasures. Quality
control is the first step to avoiding this cost trap. Continuous quality
assessments help users identify quality problems early, when their removal is
still inexpensive; they also aid decision making by providing an integrated
view of a software system's current status. As a side effect, continuous and
timely feedback helps developers and maintenance personnel improve their skills
and thereby decreases the likelihood of future quality defects. To make regular
quality control feasible, it must be highly automated, and assessment results
must be presented in an aggregated manner to avoid overwhelming users with
data. This article offers an overview of tools that aim to address these
issues. The authors also discuss their own flexible, open-source toolkit, which
supports the creation of dashboards for quality control.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09116</dc:identifier>
 <dc:identifier>IEEE Software, vol. 25, no. 5, pp. 60-67, Sept.-Oct. 2008</dc:identifier>
 <dc:identifier>doi:10.1109/MS.2008.129</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09119</identifier>
 <datestamp>2017-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Deep Representations Using Convolutional Auto-encoders with
  Symmetric Skip Connections</dc:title>
 <dc:creator>Dong, Jianfeng</dc:creator>
 <dc:creator>Mao, Xiao-Jiao</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Yang, Yu-Bin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unsupervised pre-training was a critical technique for training deep neural
networks years ago. With sufficient labeled data and modern training
techniques, it is possible to train very deep neural networks from scratch in a
purely supervised manner nowadays. However, unlabeled data is easier to obtain
and usually of very large scale. How to make use of them better to help
supervised learning is still a well-valued topic. In this paper, we investigate
convolutional denoising auto-encoders to show that unsupervised pre-training
can still improve the performance of high-level image related tasks such as
image classification and semantic segmentation. The architecture we use is a
convolutional auto-encoder network with symmetric shortcut connections. We
empirically show that symmetric shortcut connections are very important for
learning abstract representations via image reconstruction. When no extra
unlabeled data are available, unsupervised pre-training with our network can
regularize the supervised training and therefore lead to better generalization
performance. With the help of unsupervised pre-training, our method achieves
very competitive results in image classification using very simple
all-convolution networks. When labeled data are limited but extra unlabeled
data are available, our method achieves good results in several semi-supervised
learning tasks.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09121</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance enhancement of non-minimum phase feedback systems by
  fractional-order cancellation of non-minimum phase zero on the Riemann
  surface: New theoretical and experimental results</dc:title>
 <dc:creator>Merrikh-Bayat, Farshad</dc:creator>
 <dc:creator>Salimi, Aliakbar</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The non-minimum phase (NMP) zero of a linear process located in the feedback
connection cannot be cancelled by the same pole of controller according to the
internal instability problem. However, such a zero can partly be cancelled by
the same fractional-order pole of a pre-compensator located in series with
process without facing internal instability. This paper first presents new
theoretical results on the properties of this method of cancellation, and
provides design techniques for the pre-compensator. It is especially shown that
by appropriate design of pre-compensator this method can simultaneously
increase the gain and phase margin of the system under control without a
considerable reduction of open-loop bandwidth, and consequently, it can make
the control problem easier to solve. Then, a method for realization of such a
pre-compensator is proposed and performance of the resulted closed-loop system
is studied through an experimental setup.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09122</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Properties of European Languages and Voynich Manuscript
  Analysis</dc:title>
 <dc:creator>Arutyunov, Andronik</dc:creator>
 <dc:creator>Borisov, Leonid</dc:creator>
 <dc:creator>Fedorov, Sergey</dc:creator>
 <dc:creator>Ivchenko, Anastasiya</dc:creator>
 <dc:creator>Kirina-Lilinskaya, Elizabeth</dc:creator>
 <dc:creator>Orlov, Yurii</dc:creator>
 <dc:creator>Osminin, Konstantin</dc:creator>
 <dc:creator>Shilin, Sergey</dc:creator>
 <dc:creator>Zeniuk, Dmitriy</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The statistical properties of letters frequencies in European literature
texts are investigated. The determination of logarithmic dependence of letters
sequence for one-language and two-language texts are examined. The pare of
languages is suggested for Voynich Manuscript. The internal structure of
Manuscript is considered. The spectral portraits of two-letters distribution
are constructed.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09130</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalizing the Kelly strategy</dc:title>
 <dc:creator>Viswanathan, Arjun</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>62C05 (Primary), 91G60 (Secondary)</dc:subject>
 <dc:description>  Prompted by a recent experiment by Victor Haghani and Richard Dewey, this
note generalises the Kelly strategy (optimal for simple investment games with
log utility) to a large class of practical utility functions and including the
effect of extraneous wealth.
  A counterintuitive result is proved : for any continuous, concave,
differentiable utility function, the optimal choice at every point depends only
on the probability of reaching that point.
  The practical calculation of the optimal action at every stage is made
possible through use of the binomial expansion, reducing the problem size from
exponential to quadratic.
  Applications include (better) automatic investing and risk taking under
uncertainty.
</dc:description>
 <dc:description>Comment: 8 pages pdf, working note v2 29th nov. current version v4 (latex
  typeset, added upper bound on domain of H)</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09131</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development of a data model to facilitate rapid Watershed Delineation</dc:title>
 <dc:creator>Haag, Scott</dc:creator>
 <dc:creator>Shokoufandeh, Ali</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  A data model to store and retrieve surface watershed boundaries using graph
theoretic approaches is proposed. This data model integrates output from a
standard digital elevation models (DEM) derived stream catchment boundaries,
and vector representation of stream centerlines then applies them to three
novel algorithms. The first is called Modified Nested Set (MNS), which is a
depth first graph traversal algorithm that searches across stream reaches
(vertices) and stream junctions (edges) labeling vertices by their discovery
time, finish time, and distance from the root. The second is called Log Reduced
Graphs (LRG), which creates a set S of logarithmically reduced graphs from the
original data, to store the watershed boundaries. The final algorithm is called
Stitching Watershed, which provides a technique to merge watershed boundaries
across the set of graphs created in the LRG algorithm.
  This technique was applied to the ~ 30,600 km2 Delaware River Watershed and
compared to hypothetical data storage models in terms of prep-processing, data
storage, and query complexity costs. Results show that the proposed technique
provides significant benefits vs. the hypothetical methods with a 99-98%
reduction in prepossessing, 96-80% reduction in query complexity and a 76%
reduction in storage costs. The increasing availability of high resolution
elevation data within the United States and the internationally provides an
opportunity to extend these results to other watersheds through the world.
</dc:description>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09132</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Naming the Pain in Requirements Engineering: Comparing Practices in
  Brazil and Germany</dc:title>
 <dc:creator>Fern&#xe1;ndez, Daniel M&#xe9;ndez</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:creator>Kalinowski, Marcos</dc:creator>
 <dc:creator>Schekelmann, Andr&#xe9;</dc:creator>
 <dc:creator>Tuzcu, Ahmet</dc:creator>
 <dc:creator>Conte, Tayana</dc:creator>
 <dc:creator>Spinola, Rodrigo</dc:creator>
 <dc:creator>Prikladnicki, Rafael</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  As part of the Naming the Pain in Requirements Engineering (NaPiRE)
initiative, researchers compared problems that companies in Brazil and Germany
encountered during requirements engineering (RE). The key takeaway was that in
RE, human interaction is necessary for eliciting and specifying high-quality
requirements, regardless of country, project type, or company size.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09132</dc:identifier>
 <dc:identifier>IEEE Software, vol. 32, no. 5, pp. 16-23, Sept.-Oct. 2015</dc:identifier>
 <dc:identifier>doi:10.1109/MS.2015.122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09143</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate Adaptation for Secure HARQ Protocols</dc:title>
 <dc:creator>Treust, Ma&#xeb;l Le</dc:creator>
 <dc:creator>Szczecinski, Leszek</dc:creator>
 <dc:creator>Labeau, Fabrice</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the hybrid-automatic repeat request (HARQ)
transmission over block fading channel in the presence of an eavesdropper,
where the secrecy of the transmis- sion is ensured via introduction of
dummy-messages. Since the encoder only knows the statistics of the
channel-state, the secrecy and the reliability are defined in a probabilistic
framework. Unlike the previous works on this subject, we design a coding
strategy tailored to HARQ by splitting the dummy-message rate over several rate
parameters. These additional degrees of freedom improve the match between the
dummy-message rates and the realizations of the eavesdropper channels. We
evaluate the performance in terms of secrecy outage probability, connection
outage probability and the throughput. Numerical examples illustrate that,
comparing to existing alternatives, splitting of the dummy-message rate
provides higher throughput and lower expected duration/average delay.
</dc:description>
 <dc:description>Comment: submitted to IEEE Transactions on Information Forensics and Security,
  november 28th, 2016</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09149</identifier>
 <datestamp>2017-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic landscape models of coevolutionary games</dc:title>
 <dc:creator>Richter, Hendrik</dc:creator>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:description>  Players of coevolutionary games may update not only their strategies but also
their networks of interaction. Based on interpreting the payoff of players as
fitness, dynamic landscape models are proposed. The modeling procedure is
carried out for Prisoner's Dilemma (PD) and Snowdrift (SD) games that both use
either birth--death (BD) or death--birth (DB) strategy updating. The main focus
is on using dynamic fitness landscapes as a mathematical model of
coevolutionary game dynamics. Hence, an alternative tool for analyzing
coevolutionary games becomes available, and landscape measures such as
modality, ruggedness and information content can be computed and analyzed. In
addition, fixation properties of the games and quantifiers characterizing the
interaction networks are calculated numerically. Relations are established
between landscape properties expressed by landscape measures and quantifiers of
coevolutionary game dynamics such as fixation probabilities, fixation times and
network properties.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1603.06374</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09149</dc:identifier>
 <dc:identifier>BioSystems 153-154, 26-44, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09152</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pilot Contamination is Not a Fundamental Asymptotic Limitation in
  Massive MIMO</dc:title>
 <dc:creator>Bj&#xf6;rnson, Emil</dc:creator>
 <dc:creator>Hoydis, Jakob</dc:creator>
 <dc:creator>Sanguinetti, Luca</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Massive MIMO (multiple-input multiple-output) provides great improvements in
spectral efficiency over legacy cellular networks, by coherent combining of the
signals over a large antenna array and by spatial multiplexing of many users.
Since its inception, the coherent interference caused by pilot contamination
has been believed to be an impairment that does not vanish, even with an
unlimited number of antennas. In this work, we show that this belief is
incorrect and an artifact from using simplistic channel models and suboptimal
signal processing schemes. We focus on the uplink and prove that with multicell
MMSE combining, the spectral efficiency grows without bound as the number of
antennas increases, even under pilot contamination, under a condition of linear
independence between the channel covariance matrices. This condition is
generally satisfied, except in special cases that are hardly found in practice.
</dc:description>
 <dc:description>Comment: IEEE ICC 2017, 6 pages, 5 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09159</identifier>
 <datestamp>2017-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Shape Retrieval with Sparse 3D Convolutional Neural Networks</dc:title>
 <dc:creator>Notchenko, Alexandr</dc:creator>
 <dc:creator>Kapushev, Ermek</dc:creator>
 <dc:creator>Burnaev, Evgeny</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we present results of performance evaluation of S3DCNN - a
Sparse 3D Convolutional Neural Network - on a large-scale 3D Shape benchmark
ModelNet40, and measure how it is impacted by voxel resolution of input shape.
We demonstrate comparable classification and retrieval performance to
state-of-the-art models, but with much less computational costs in training and
inference phases. We also notice that benefits of higher input resolution can
be limited by an ability of a neural network to generalize high level features.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures, 2 tables, accepted to 3D Deep Learning Workshop
  at NIPS 2016</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09162</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Who's that Actor? Automatic Labelling of Actors in TV series starting
  from IMDB Images</dc:title>
 <dc:creator>Aljundi, Rahaf</dc:creator>
 <dc:creator>Chakravarty, Punarjay</dc:creator>
 <dc:creator>Tuytelaars, Tinne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we aim at automatically labeling actors in a TV series. Rather
than relying on transcripts and subtitles, as has been demonstrated in the
past, we show how to achieve this goal starting from a set of example images of
each of the main actors involved, collected from the Internet Movie Database
(IMDB). The problem then becomes one of domain adaptation: actors' IMDB photos
are typically taken at awards ceremonies and are quite different from their
appearances in TV series. In each series as well, there is considerable change
in actor appearance due to makeup, lighting, ageing, etc. To bridge this gap,
we propose a graph-matching based self-labelling algorithm, which we coin HSL
(Hungarian Self Labeling). Further, we propose a new edge cost to be used in
this context, as well as an extension that is more robust to outliers, where
prototypical faces for each of the actors are selected based on a hierarchical
clustering procedure. We conduct experiments with 15 episodes from 3 different
TV series and demonstrate automatic annotation with an accuracy of 90% and up.
</dc:description>
 <dc:description>Comment: ACCV 2016 accepted paper</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09168</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A duality-based approach for distributed min-max optimization</dc:title>
 <dc:creator>Notarnicola, Ivano</dc:creator>
 <dc:creator>Franceschelli, Mauro</dc:creator>
 <dc:creator>Notarstefano, Giuseppe</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper we consider a distributed optimization scenario in which a set
of processors aims at cooperatively solving a class of min-max optimization
problems. This set-up is motivated by peak-demand minimization problems in
smart grids. Here, the goal is to minimize the peak value over a finite horizon
with: (i) the demand at each time instant being the sum of contributions from
different devices, and (ii) the device states at different time instants being
coupled through local constraints (e.g., the dynamics). The min-max structure
and the double coupling (through the devices and over the time horizon) makes
this problem challenging in a distributed set-up (e.g., existing distributed
dual decomposition approaches cannot be applied). We propose a distributed
algorithm based on the combination of duality methods and properties from
min-max optimization. Specifically, we repeatedly apply duality theory and
properly introduce ad-hoc slack variables in order to derive a series of
equivalent problems. On the resulting problem we apply a dual subgradient
method, which turns out to be a distributed algorithm consisting of a
minimization on the original primal variables and a suitable dual update. We
prove the convergence of the proposed algorithm in objective value. Moreover,
we show that every limit point of the primal sequence is an optimal (feasible)
solution. Finally, we provide numerical computations for a peak-demand
optimization problem in a network of thermostatically controlled loads.
</dc:description>
 <dc:description>Comment: Submitted to journal</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09169</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Objective Service Composition in Ubiquitous Environments with
  Service Dependencies</dc:title>
 <dc:creator>Mabrouk, Nebil Ben</dc:creator>
 <dc:creator>Georgantas, Nikolaos</dc:creator>
 <dc:creator>Issarny, Val&#xe9;rie</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Service composition is a widely used method in ubiquitous computing that
enables accomplishing complex tasks required by users based on elementary
(hardware and software) services available in ubiquitous environments. To
ensure that users experience the best Quality of Service (QoS) with respect to
their quality needs, service composition has to be QoS-aware. Establishing
QoS-aware service compositions entails efficient service selection taking into
account the QoS requirements of users. A challenging issue towards this purpose
is to consider service selection under global QoS requirements (i.e.,
requirements imposed by the user on the whole task), which is of high
computational cost. This challenge is even more relevant when we consider the
dynamics, limited computational resources and timeliness constraints of
ubiquitous environments. To cope with the above challenge, we present QASSA, an
efficient service selection algorithm that provides the appropriate ground for
QoS-aware service composition in ubiquitous environments. QASSA formulates
service selection under global QoS requirements as a set-based optimisation
problem, and solves this problem by combining local and global selection
techniques. In particular, it introduces a novel way of using clustering
techniques to enable fine-grained management of trade-offs between QoS
objectives. QASSA further considers: (i) dependencies between services, (ii)
adaptation at run-time, and (iii) both centralised and distributed design
fashions. Results of experimental studies performed using real QoS data are
presented to illustrate the timeliness and optimality of QASSA.
</dc:description>
 <dc:description>Comment: International Journal of Services Computing (IJSC), 2016, 4</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09170</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DESP-C++: A Discrete-Event Simulation Package for C++</dc:title>
 <dc:creator>Darmont, J&#xe9;r&#xf4;me</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  DESP-C++ is a C++ discrete-event random simulation engine that has been
designed to be fast, very easy to use and expand, and valid. DESP-C++ is based
on the resource view. Its complete architecture is presented in detail, as well
as a short &quot; user manual &quot;. The validity of DESP-C++ is demonstrated by the
simulation of three significant models. In each case, the simulation results
obtained with DESP-C++ match those obtained with a validated simulation
software: QNAP2. The versatility of DESP-C++ is also illustrated this way,
since the modelled systems are very different from each other: a simple
production system, the dining philosopher classical deadlock problem, and a
complex object-oriented database management system.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09170</dc:identifier>
 <dc:identifier>Software: Practice and Experience, Wiley, 2000, 30 (1), pp.37-60</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09172</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmarking OODBs with a Generic Tool</dc:title>
 <dc:creator>Darmont, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Schneider, Michel</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We present in this paper a generic object-oriented benchmark (OCB: the Object
Clustering Benchmark) that has been designed to evaluate the performances of
Object-Oriented Data-bases (OODBs), and more specifically the performances of
clustering policies within OODBs. OCB is generic because its sample database
may be customized to fit any of the databases in-troduced by the main existing
benchmarks, e.g., OO1 (Object Operation 1) or OO7. The first version of OCB was
purposely clustering-oriented due to a clustering-oriented workload, but OCB
has been thoroughly extended to be able to suit other purposes. Eventually,
OCB's code is compact and easily portable. OCB has been validated through two
implementations: one within the O2 OODB and another one within the Texas
persistent object store. The perfor-mances of a specific clustering policy
called DSTC (Dynamic, Statistical, Tunable Clustering) have also been evaluated
with OCB.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09172</dc:identifier>
 <dc:identifier>Journal of Database Management, IGI Global, 2000, 11 (3), pp.16-27</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09176</identifier>
 <datestamp>2017-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation of clustering algorithms in OODBs in order to evaluate their
  performances</dc:title>
 <dc:creator>Darmont, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Attoui, Amar</dc:creator>
 <dc:creator>Gourgand, Michel</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  A good object clustering is critical to the performance of object-oriented
databases. However, it always involves some kind of overhead for the system.
The aim of this paper is to propose a modelling methodology in order to
evaluate the performances of different clustering policies. This methodology
has been used to compare the performances of three clustering algorithms found
in the literature (Cactis, CK and ORION) that we considered representative of
the current research in the field of object clustering. The actual performance
evaluation was performed using simulation. Simulation experiments showed that
the Cactis algorithm is better than the ORION algorithm and that the CK
algorithm totally outperforms both other algorithms in terms of response time
and clustering overhead.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:0705.0454,
  arXiv:1611.09177</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09176</dc:identifier>
 <dc:identifier>Simulation Practice and Theory, Elsevier, 1997, 5 (3), pp.269-287</dc:identifier>
 <dc:identifier>doi:10.1016/S0928-4869(96)00013-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09177</identifier>
 <datestamp>2017-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A comparison study of object-oriented database clustering techniques</dc:title>
 <dc:creator>Darmont, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Gruenwald, Le</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  It is widely acknowledged that a good object clustering is critical to the
performance of OODBs. Clustering means storing related objects close together
on secondary storage so that when one object is accessed from disk, all its
related objects are also brought into memory. Then access to these related
objects is a main memory access that is much faster than a disk access. The aim
of this paper is to compare the performance of three clustering algorithms:
Cactis, CK and ORION. Simulation experiments we performed showed that the
Cactis algorithm is better than the ORION algorithm and that the CK algorithm
totally out-performs both other algorithms in terms of response time and
clustering overhead.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1611.09176</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09177</dc:identifier>
 <dc:identifier>Information Sciences, Elsevier, 1996, 94 (1-4), pp.55-86</dc:identifier>
 <dc:identifier>doi:10.1016/0020-0255(96)00119-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09180</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Based Appraisal of Real Estate Properties</dc:title>
 <dc:creator>You, Quanzeng</dc:creator>
 <dc:creator>Pang, Ran</dc:creator>
 <dc:creator>Cao, Liangliang</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Real estate appraisal, which is the process of estimating the price for real
estate properties, is crucial for both buys and sellers as the basis for
negotiation and transaction. Traditionally, the repeat sales model has been
widely adopted to estimate real estate price. However, it depends the design
and calculation of a complex economic related index, which is challenging to
estimate accurately. Today, real estate brokers provide easy access to detailed
online information on real estate properties to their clients. We are
interested in estimating the real estate price from these large amounts of
easily accessed data. In particular, we analyze the prediction power of online
house pictures, which is one of the key factors for online users to make a
potential visiting decision. The development of robust computer vision
algorithms makes the analysis of visual content possible. In this work, we
employ a Recurrent Neural Network (RNN) to predict real estate price using the
state-of-the-art visual features. The experimental results indicate that our
model outperforms several of other state-of-the-art baseline algorithms in
terms of both mean absolute error (MAE) and mean absolute percentage error
(MAPE).
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09180</dc:identifier>
 <dc:identifier>doi:10.1109/TMM.2017.2710804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09187</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correctness Attraction: A Study of Stability of Software Behavior Under
  Runtime Perturbation</dc:title>
 <dc:creator>Danglot, Benjamin</dc:creator>
 <dc:creator>Preux, Philippe</dc:creator>
 <dc:creator>Baudry, Benoit</dc:creator>
 <dc:creator>Monperrus, Martin</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Can the execution of a software be perturbed without breaking the correctness
of the output? In this paper, we devise a novel protocol to answer this rarely
investigated question. In an experimental study, we observe that many
perturbations do not break the correctness in ten subject programs. We call
this phenomenon ``correctness attraction''. The uniqueness of this protocol is
that it considers a systematic exploration of the perturbation space as well as
perfect oracles to determine the correctness of the output. To this extent, our
findings on the stability of software under execution perturbations have a
level of validity that has never been reported before in the scarce related
work. A qualitative manual analysis enables us to set up the first taxonomy
ever of the reasons behind correctness attraction.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09189</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Mixing in Pairwise Markov Random Fields with Application to Social
  Networks</dc:title>
 <dc:creator>Avrachenkov, Konstantin</dc:creator>
 <dc:creator>Iskhakov, Lenar</dc:creator>
 <dc:creator>Mironov, Maksim</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We consider pairwise Markov random fields which have a number of important
applications in statistical physics, image processing and machine learning such
as Ising model and labeling problem to name a couple. Our own motivation comes
from the need to produce synthetic models for social networks with attributes.
First, we give conditions for rapid mixing of the associated Glauber dynamics
and consider interesting particular cases. Then, for pairwise Markov random
fields with submodular energy functions we construct monotone perfect
simulation.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09189</dc:identifier>
 <dc:identifier>Anthony Bonato ; Fan Chung Graham; Pawel Pralat. Algorithms and
  Models for the Web Graph, Dec 2016, Montreal, Canada. 10088, pp.127-139,
  2016, Lecture Notes in Computer Science</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-49787-7_11</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09193</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What is a Fog Node A Tutorial on Current Concepts towards a Common
  Definition</dc:title>
 <dc:creator>Tordera, Eva Marin</dc:creator>
 <dc:creator>Masip-Bruin, Xavi</dc:creator>
 <dc:creator>Garcia-Alminana, Jordi</dc:creator>
 <dc:creator>Jukan, Admela</dc:creator>
 <dc:creator>Ren, Guang-Jie</dc:creator>
 <dc:creator>Zhu, Jiafeng</dc:creator>
 <dc:creator>Farre, Josep</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Fog computing has emerged as a promising technology that can bring the cloud
applications closer to the physical IoT devices at the network edge. While it
is widely known what cloud computing is, and how data centers can build the
cloud infrastructure and how applications can make use of this infrastructure,
there is no common picture on what fog computing and a fog node, as its main
building block, really is. One of the first attempts to define a fog node was
made by Cisco, qualifying a fog computing system as a mini-cloud, located at
the edge of the network and implemented through a variety of edge devices,
interconnected by a variety, mostly wireless, communication technologies. Thus,
a fog node would be the infrastructure implementing the said mini-cloud. Other
proposals have their own definition of what a fog node is, usually in relation
to a specific edge device, a specific use case or an application. In this
paper, we first survey the state of the art in technologies for fog computing
nodes as building blocks of fog computing, paying special attention to the
contributions that analyze the role edge devices play in the fog node
definition. We summarize and compare the concepts, lessons learned from their
implementation, and show how a conceptual framework is emerging towards a
unifying fog node definition. We focus on core functionalities of a fog node as
well as in the accompanying opportunities and challenges towards their
practical realization in the near future.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09194</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Times series averaging and denoising from a probabilistic perspective on
  time-elastic kernels</dc:title>
 <dc:creator>Marteau, Pierre-Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In the light of regularized dynamic time warping kernels, this paper
re-considers the concept of time elastic centroid for a setof time series. We
derive a new algorithm based on a probabilistic interpretation of kernel
alignment matrices. This algorithm expressesthe averaging process in terms of a
stochastic alignment automata. It uses an iterative agglomerative heuristic
method for averagingthe aligned samples, while also averaging the times of
occurrence of the aligned samples. By comparing classification accuracies for45
heterogeneous time series datasets obtained by first nearest centroid/medoid
classifiers we show that: i) centroid-basedapproaches significantly outperform
medoid-based approaches, ii) for the considered datasets, our algorithm that
combines averagingin the sample space and along the time axes, emerges as the
most significantly robust model for time-elastic averaging with apromising
noise reduction capability. We also demonstrate its benefit in an isolated
gesture recognition experiment and its ability tosignificantly reduce the size
of training instance sets. Finally we highlight its denoising capability using
demonstrative synthetic data:we show that it is possible to retrieve, from few
noisy instances, a signal whose components are scattered in a wide spectral
band.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1505.06897</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09203</identifier>
 <datestamp>2017-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Mapping of the Ground Reflectivity with Laser Scanners</dc:title>
 <dc:creator>Castorena, Juan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this investigation we focus on the problem of mapping the ground
reflectivity with multiple laser scanners mounted on mobile robots/vehicles.
The problem originates because regions of the ground become populated with a
varying number of reflectivity measurements whose value depends on the observer
and its corresponding perspective. Here, we propose a novel automatic,
data-driven computational mapping framework specifically aimed at preserving
edge sharpness in the map reconstruction process and that considers the sources
of measurement variation. Our new formulation generates map-perspective
gradients and applies sub-set selection fusion and de-noising operators to
these through iterative algorithms that minimize an $\ell_1$ sparse regularized
least squares formulation. Reconstruction of the ground reflectivity is then
carried out based on Poisson's formulation posed as an $\ell_2$ term promoting
consistency with the fused gradient of map-perspectives and a term that ensures
equality constraints with reference measurement data. We demonstrate our new
framework outperforms the capabilities of existing ones with experiments
realized on Ford's fleet of autonomous vehicles. For example, we show we can
achieve map enhancement (i.e., contrast enhancement), artifact removal,
de-noising and map-stitching without requiring an additional reflectivity
adjustment to calibrate sensors to the specific mounting and robot/vehicle
motion.
</dc:description>
 <dc:description>Comment: Submitted to TIP</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09207</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AutoMOS: Learning a non-intrusive assessor of naturalness-of-speech</dc:title>
 <dc:creator>Patton, Brian</dc:creator>
 <dc:creator>Agiomyrgiannakis, Yannis</dc:creator>
 <dc:creator>Terry, Michael</dc:creator>
 <dc:creator>Wilson, Kevin</dc:creator>
 <dc:creator>Saurous, Rif A.</dc:creator>
 <dc:creator>Sculley, D.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Developers of text-to-speech synthesizers (TTS) often make use of human
raters to assess the quality of synthesized speech. We demonstrate that we can
model human raters' mean opinion scores (MOS) of synthesized speech using a
deep recurrent neural network whose inputs consist solely of a raw waveform.
Our best models provide utterance-level estimates of MOS only moderately
inferior to sampled human ratings, as shown by Pearson and Spearman
correlations. When multiple utterances are scored and averaged, a scenario
common in synthesizer quality assessment, AutoMOS achieves correlations
approaching those of human raters. The AutoMOS model has a number of
applications, such as the ability to explore the parameter space of a speech
synthesizer without requiring a human-in-the-loop.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, 2 tables, NIPS 2016 End-to-end Learning for
  Speech and Audio Processing Workshop</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09212</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a new quantum cognition model</dc:title>
 <dc:creator>Franco, Riccardo</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  This article presents a new quantum-like model for cognition explicitly based
on knowledge. It is shown that this model, called QKT (quantum knowledge-based
theory), is able to coherently describe some experimental results that are
problematic for the prior quantum-like decision models. In particular, I
consider the experimental results relevant to the post-decision cognitive
dissonance, the problems relevant to the question order effect and response
replicability, and those relevant to the grand-reciprocity equations. A new set
of postulates is proposed, which evidence the different meaning given to the
projectors and to the quantum states. In the final part, I show that the use of
quantum gates can help to better describe and understand the evolution of
quantum-like models.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09219</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequential Peer Prediction: Learning to Elicit Effort using Posted
  Prices</dc:title>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Chen, Yiling</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Peer prediction mechanisms are often adopted to elicit truthful contributions
from crowd workers when no ground-truth verification is available. Recently,
mechanisms of this type have been developed to incentivize effort exertion, in
addition to truthful elicitation. In this paper, we study a sequential peer
prediction problem where a data requester wants to dynamically determine the
reward level to optimize the trade-off between the quality of information
elicited from workers and the total expected payment. In this problem, workers
have homogeneous expertise and heterogeneous cost for exerting effort, both
unknown to the requester. We propose a sequential posted-price mechanism to
dynamically learn the optimal reward level from workers' contributions and to
incentivize effort exertion and truthful reporting. We show that (1) in our
mechanism, workers exerting effort according to a non-degenerate threshold
policy and then reporting truthfully is an equilibrium that returns highest
utility for each worker, and (2) The regret of our learning mechanism w.r.t.
offering the optimal reward (price) is upper bounded by $\tilde{O}(T^{3/4})$
where $T$ is the learning horizon. We further show the power of our learning
approach when the reports of workers do not necessarily follow the
game-theoretic equilibrium.
</dc:description>
 <dc:description>Comment: AAAI'17</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09224</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ECO: Efficient Convolution Operators for Tracking</dc:title>
 <dc:creator>Danelljan, Martin</dc:creator>
 <dc:creator>Bhat, Goutam</dc:creator>
 <dc:creator>Khan, Fahad Shahbaz</dc:creator>
 <dc:creator>Felsberg, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In recent years, Discriminative Correlation Filter (DCF) based methods have
significantly advanced the state-of-the-art in tracking. However, in the
pursuit of ever increasing tracking performance, their characteristic speed and
real-time capability have gradually faded. Further, the increasingly complex
models, with massive number of trainable parameters, have introduced the risk
of severe over-fitting. In this work, we tackle the key causes behind the
problems of computational complexity and over-fitting, with the aim of
simultaneously improving both speed and performance.
  We revisit the core DCF formulation and introduce: (i) a factorized
convolution operator, which drastically reduces the number of parameters in the
model; (ii) a compact generative model of the training sample distribution,
that significantly reduces memory and time complexity, while providing better
diversity of samples; (iii) a conservative model update strategy with improved
robustness and reduced complexity. We perform comprehensive experiments on four
benchmarks: VOT2016, UAV123, OTB-2015, and TempleColor. When using expensive
deep features, our tracker provides a 20-fold speedup and achieves a 13.0%
relative gain in Expected Average Overlap compared to the top ranked method in
the VOT2016 challenge. Moreover, our fast variant, using hand-crafted features,
operates at 60 Hz on a single CPU, while obtaining 65.0% AUC on OTB-2015.
</dc:description>
 <dc:description>Comment: Accepted at CVPR 2017. Includes supplementary material</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09226</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Variational Inference</dc:title>
 <dc:creator>Figurnov, Michael</dc:creator>
 <dc:creator>Struminsky, Kirill</dc:creator>
 <dc:creator>Vetrov, Dmitry</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Variational inference is a powerful tool for approximate inference. However,
it mainly focuses on the evidence lower bound as variational objective and the
development of other measures for variational inference is a promising area of
research. This paper proposes a robust modification of evidence and a lower
bound for the evidence, which is applicable when the majority of the training
set samples are random noise objects. We provide experiments for variational
autoencoders to show advantage of the objective over the evidence lower bound
on synthetic datasets obtained by adding uninformative noise objects to MNIST
and OMNIGLOT. Additionally, for the original MNIST and OMNIGLOT datasets we
observe a small improvement over the non-robust evidence lower bound.
</dc:description>
 <dc:description>Comment: NIPS 2016 Workshop, Advances in Approximate Bayesian Inference</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09230</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Operationalised product quality models and assessment: The Quamoco
  approach</dc:title>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:creator>Goeb, Andreas</dc:creator>
 <dc:creator>Heinemann, Lars</dc:creator>
 <dc:creator>Kl&#xe4;s, Michael</dc:creator>
 <dc:creator>Lampasona, Constanza</dc:creator>
 <dc:creator>Lochmann, Klaus</dc:creator>
 <dc:creator>Mayr, Alois</dc:creator>
 <dc:creator>Pl&#xf6;sch, Reinhold</dc:creator>
 <dc:creator>Seidl, Andreas</dc:creator>
 <dc:creator>Streit, Jonathan</dc:creator>
 <dc:creator>Trendowicz, Adam</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Software quality models provide either abstract quality characteristics or
concrete quality measurements; there is no seamless integration of these two
aspects. Reasons for this include the complexity of quality and the various
quality profiles in different domains which make it difficult to build
operationalised quality models. In the project Quamoco, we developed a
comprehensive approach for closing this gap. It combined constructive research,
which involved quality experts from academia and industry in workshops, sprint
work and reviews, with empirical studies. All deliverables within the project
were peer-reviewed by two project members from a different area. Most
deliverables were developed in two or three iterations and underwent an
evaluation. We contribute a comprehensive quality modelling and assessment
approach: (1) A meta quality model defines the structure of operationalised
quality models. It includes the concept of a product factor, which bridges the
gap between concrete measurements and abstract quality aspects, and allows
modularisation to create modules for specific domains. (2) A largely
technology-independent base quality model reduces the effort and complexity of
building quality models for specific domains. For Java and C# systems, we
refined it with about 300 concrete product factors and 500 measures. (3) A
concrete and comprehensive quality assessment approach makes use of the
concepts in the meta-model. (4) An empirical evaluation of the above results
using real-world software systems. (5) The extensive, open-source tool support
is in a mature state. (6) The model for embedded software systems is a
proof-of-concept for domain-specific quality models. We provide a broad basis
for the development and application of quality models in industrial practice as
well as a basis for further extension, validation and comparison with other
approaches in research.
</dc:description>
 <dc:description>Comment: 41 pages, 14 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09230</dc:identifier>
 <dc:identifier>Information and Software Technology, Volume 62, June 2015, pages
  101-123</dc:identifier>
 <dc:identifier>doi:10.1016/j.infsof.2015.02.009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09232</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Convolutional Auto-Encoding via Random Convexification and
  Frequency-Domain Minimization</dc:title>
 <dc:creator>Oveneke, Meshia C&#xe9;dric</dc:creator>
 <dc:creator>Aliosha-Perez, Mitchel</dc:creator>
 <dc:creator>Zhao, Yong</dc:creator>
 <dc:creator>Jiang, Dongmei</dc:creator>
 <dc:creator>Sahli, Hichem</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The omnipresence of deep learning architectures such as deep convolutional
neural networks (CNN)s is fueled by the synergistic combination of
ever-increasing labeled datasets and specialized hardware. Despite the
indisputable success, the reliance on huge amounts of labeled data and
specialized hardware can be a limiting factor when approaching new
applications. To help alleviating these limitations, we propose an efficient
learning strategy for layer-wise unsupervised training of deep CNNs on
conventional hardware in acceptable time. Our proposed strategy consists of
randomly convexifying the reconstruction contractive auto-encoding (RCAE)
learning objective and solving the resulting large-scale convex minimization
problem in the frequency domain via coordinate descent (CD). The main
advantages of our proposed learning strategy are: (1) single tunable
optimization parameter; (2) fast and guaranteed convergence; (3) possibilities
for full parallelization. Numerical experiments show that our proposed learning
strategy scales (in the worst case) linearly with image size, number of filters
and filter size.
</dc:description>
 <dc:description>Comment: Accepted at NIPS 2016 Workshop on Efficient Methods for Deep Neural
  Networks (EMDNN)</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09235</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Copying and Restricted Generation for Paraphrase</dc:title>
 <dc:creator>Cao, Ziqiang</dc:creator>
 <dc:creator>Luo, Chuwei</dc:creator>
 <dc:creator>Li, Wenjie</dc:creator>
 <dc:creator>Li, Sujian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Many natural language generation tasks, such as abstractive summarization and
text simplification, are paraphrase-orientated. In these tasks, copying and
rewriting are two main writing modes. Most previous sequence-to-sequence
(Seq2Seq) models use a single decoder and neglect this fact. In this paper, we
develop a novel Seq2Seq model to fuse a copying decoder and a restricted
generative decoder. The copying decoder finds the position to be copied based
on a typical attention model. The generative decoder produces words limited in
the source-specific vocabulary. To combine the two decoders and determine the
final output, we develop a predictor to predict the mode of copying or
rewriting. This predictor can be guided by the actual writing mode in the
training data. We conduct extensive experiments on two different paraphrase
datasets. The result shows that our model outperforms the state-of-the-art
approaches in terms of both informativeness and language quality.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure, AAAI-17</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09238</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Multi-Document Summarization via Text Classification</dc:title>
 <dc:creator>Cao, Ziqiang</dc:creator>
 <dc:creator>Li, Wenjie</dc:creator>
 <dc:creator>Li, Sujian</dc:creator>
 <dc:creator>Wei, Furu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Developed so far, multi-document summarization has reached its bottleneck due
to the lack of sufficient training data and diverse categories of documents.
Text classification just makes up for these deficiencies. In this paper, we
propose a novel summarization system called TCSum, which leverages plentiful
text classification data to improve the performance of multi-document
summarization. TCSum projects documents onto distributed representations which
act as a bridge between text classification and summarization. It also utilizes
the classification results to produce summaries of different styles. Extensive
experiments on DUC generic multi-document summarization datasets show that,
TCSum can achieve the state-of-the-art performance without using any
hand-crafted features and has the capability to catch the variations of summary
styles with respect to different text categories.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures, AAAI-17</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09240</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear vs Nonlinear MPC for Trajectory Tracking Applied to Rotary Wing
  Micro Aerial Vehicles</dc:title>
 <dc:creator>Kamel, Mina</dc:creator>
 <dc:creator>Burri, Michael</dc:creator>
 <dc:creator>Siegwart, Roland</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Precise trajectory tracking is a crucial property for \acp{MAV} to operate in
cluttered environment or under disturbances. In this paper we present a
detailed comparison between two state-of-the-art model-based control techniques
for \ac{MAV} trajectory tracking. A classical \ac{LMPC} is presented and
compared against a more advanced \ac{NMPC} that considers the full system
model. In a careful analysis we show the advantages and disadvantages of the
two implementations in terms of speed and tracking performance. This is
achieved by evaluating hovering performance, step response, and aggressive
trajectory tracking under nominal conditions and under external wind
disturbances.
</dc:description>
 <dc:description>Comment: Paper submitted to IFAC2017</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09243</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient Resource Allocation for Mobile Edge Computing-Based
  Augmented Reality Applications</dc:title>
 <dc:creator>Al-Shuwaili, Ali</dc:creator>
 <dc:creator>Simeone, Osvaldo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Mobile edge computing is a provisioning solution to enable Augmented Reality
(AR) applications on mobile devices. AR mobile applications have inherent
collaborative properties in terms of data collection in the uplink, computing
at the edge, and data delivery in the downlink. In this letter, these features
are leveraged to propose a novel resource allocation approach over both
communication and computation resources. The approach, implemented via
Successive Convex Approximation (SCA), is seen to yield considerable gains in
mobile energy consumption as compared to conventional independent offloading
across users.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures. Submitted</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09259</identifier>
 <datestamp>2017-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Do be do be do</dc:title>
 <dc:creator>Lindley, Sam</dc:creator>
 <dc:creator>McBride, Conor</dc:creator>
 <dc:creator>McLaughlin, Craig</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We explore the design and implementation of Frank, a strict functional
programming language with a bidirectional effect type system designed from the
ground up around a novel variant of Plotkin and Pretnar's effect handler
abstraction.
  Effect handlers provide an abstraction for modular effectful programming: a
handler acts as an interpreter for a collection of commands whose interfaces
are statically tracked by the type system. However, Frank eliminates the need
for an additional effect handling construct by generalising the basic mechanism
of functional abstraction itself. A function is simply the special case of a
Frank operator that interprets no commands. Moreover, Frank's operators can be
multihandlers which simultaneously interpret commands from several sources at
once, without disturbing the direct style of functional programming with
values.
  Effect typing in Frank employs a novel form of effect polymorphism which
avoid mentioning effect variables in source code. This is achieved by
propagating an ambient ability inwards, rather than accumulating unions of
potential effects outwards.
  We introduce Frank by example, and then give a formal account of the Frank
type system and its semantics. We introduce Core Frank by elaborating Frank
operators into functions, case expressions, and unary handlers, and then give a
sound small-step operational semantics for Core Frank.
  Programming with effects and handlers is in its infancy. We contribute an
exploration of future possibilities, particularly in combination with other
forms of rich type system.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures, fixing typos and an error in the pattern
  matching elaboration algorithm</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09261</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Technique to Share Multiple Secret Images</dc:title>
 <dc:creator>Rajput, Mohit</dc:creator>
 <dc:creator>Deshmukh, Maroti</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Visual Cryptography comes under cryptography domain. It deals with encrypting
and decrypting of visual information like pictures, texts, videos $ etc.$ Multi
Secret Image Sharing (MSIS) scheme is a part of visual cryptography that
provides a protected method to transmit more than one secret images over a
communication channel. Conventionally, transmission of a single secret image is
possible over a channel at a time. But as technology grows, there emerge a need
for sharing more than one secret image. An $(n, n)$-MSIS scheme is used to
encrypt $n$ secret images into $n$ meaningless noisy images that are stored
over different servers. To recover $n$ secret images all $n$ noisy images are
required. At earlier time, the main problem with secret sharing schemes was
that attacker can partially figure out secret images, even by getting access of
$n-1$ or fewer noisy images. To tackle with this security issue, there arises a
need of secure MSIS scheme, so that attacker can not retrieve any information
by using less than $n-1$ noisy images. In this paper, we propose a secure $(n,
n+1)$-MSIS scheme using additive modulo operation for grayscale and colored
images. For checking the effectiveness of proposed scheme; Correlation, MSE and
PSNR techniques are used. The experimental results show that the proposed
scheme is highly secured and altering of noisy images will not reveal any
partial information about secret images. The proposed $(n, n+1)$-MSIS scheme
outperforms the existing MSIS schemes in terms of security.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09261</dc:identifier>
 <dc:identifier>International Journal of Information Processing, 10(3), 35-44,
  2016 ISSN : 0973-8215 IK International Publishing House Pvt. Ltd., New Delhi,
  India</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09263</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guarded Cubical Type Theory</dc:title>
 <dc:creator>Birkedal, Lars</dc:creator>
 <dc:creator>Bizjak, Ale&#x161;</dc:creator>
 <dc:creator>Clouston, Ranald</dc:creator>
 <dc:creator>Grathwohl, Hans Bugge</dc:creator>
 <dc:creator>Spitters, Bas</dc:creator>
 <dc:creator>Vezzosi, Andrea</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>03B70, 03B15, 55U35</dc:subject>
 <dc:subject>F.3.3</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  This paper improves the treatment of equality in guarded dependent type
theory (GDTT), by combining it with cubical type theory (CTT). GDTT is an
extensional type theory with guarded recursive types, which are useful for
building models of program logics, and for programming and reasoning with
coinductive types. We wish to implement GDTT with decidable type checking,
while still supporting non-trivial equality proofs that reason about the
extensions of guarded recursive constructions. CTT is a variation of
Martin-L\&quot;of type theory in which the identity type is replaced by abstract
paths between terms. CTT provides a computational interpretation of functional
extensionality, enjoys canonicity for the natural numbers type, and is
conjectured to support decidable type-checking. Our new type theory, guarded
cubical type theory (GCTT), provides a computational interpretation of
extensionality for guarded recursive types. This further expands the
foundations of CTT as a basis for formalisation in mathematics and computer
science. We present examples to demonstrate the expressivity of our type
theory, all of which have been checked using a prototype type-checker
implementation. We show that CTT can be given semantics in presheaves on the
product of the cube category and a small category with an initial object. We
then show that the category of presheaves on the product of the cube category
and omega provides semantics for GCTT.
</dc:description>
 <dc:description>Comment: Final version; Special Issue on Homotopy Type Theory and Univalent
  Foundations, Journal of Automated Reasoning, 2017</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09268</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</dc:title>
 <dc:creator>Nguyen, Tri</dc:creator>
 <dc:creator>Rosenberg, Mir</dc:creator>
 <dc:creator>Song, Xia</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Tiwary, Saurabh</dc:creator>
 <dc:creator>Majumder, Rangan</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This paper presents our recent work on the design and development of a new,
large scale dataset, which we name MS MARCO, for MAchine Reading
COmprehension.This new dataset is aimed to overcome a number of well-known
weaknesses of previous publicly available datasets for the same task of reading
comprehension and question answering. In MS MARCO, all questions are sampled
from real anonymized user queries. The context passages, from which answers in
the dataset are derived, are extracted from real web documents using the most
advanced version of the Bing search engine. The answers to the queries are
human generated. Finally, a subset of these queries has multiple answers. We
aim to release one million queries and the corresponding answers in the
dataset, which, to the best of our knowledge, is the most comprehensive
real-world dataset of its kind in both quantity and quality. We are currently
releasing 100,000 queries with their corresponding answers to inspire work in
reading comprehension and question answering along with gathering feedback from
the research community.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09274</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Normalizer Circuits and Quantum Computation</dc:title>
 <dc:creator>Bermejo-Vega, Juan</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:description>  (Abridged abstract.) In this thesis we introduce new models of quantum
computation to study the emergence of quantum speed-up in quantum computer
algorithms.
  Our first contribution is a formalism of restricted quantum operations, named
normalizer circuit formalism, based on algebraic extensions of the qubit
Clifford gates (CNOT, Hadamard and $\pi/4$-phase gates): a normalizer circuit
consists of quantum Fourier transforms (QFTs), automorphism gates and quadratic
phase gates associated to a set $G$, which is either an abelian group or
abelian hypergroup. Though Clifford circuits are efficiently classically
simulable, we show that normalizer circuit models encompass Shor's celebrated
factoring algorithm and the quantum algorithms for abelian Hidden Subgroup
Problems. We develop classical-simulation techniques to characterize under
which scenarios normalizer circuits provide quantum speed-ups. Finally, we
devise new quantum algorithms for finding hidden hyperstructures. The results
offer new insights into the source of quantum speed-ups for several algebraic
problems.
  Our second contribution is an algebraic (group- and hypergroup-theoretic)
framework for describing quantum many-body states and classically simulating
quantum circuits. Our framework extends Gottesman's Pauli Stabilizer Formalism
(PSF), wherein quantum states are written as joint eigenspaces of stabilizer
groups of commuting Pauli operators: while the PSF is valid for qubit/qudit
systems, our formalism can be applied to discrete- and continuous-variable
systems, hybrid settings, and anyonic systems. These results enlarge the known
families of quantum processes that can be efficiently classically simulated.
  This thesis also establishes a precise connection between Shor's quantum
algorithm and the stabilizer formalism, revealing a common mathematical
structure in several quantum speed-ups and error-correcting codes.
</dc:description>
 <dc:description>Comment: PhD thesis, Technical University of Munich (2016). Please cite
  original papers if possible. Appendix E contains unpublished work on Gaussian
  unitaries. If you spot typos/omissions please email me at JLastNames at
  posteo dot net. Source: http://bit.ly/2gMdHn3. Related video talk:
  https://www.perimeterinstitute.ca/videos/toy-theory-quantum-speed-ups-based-stabilizer-formalism
  Posted on my birthday</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09274</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09288</identifier>
 <datestamp>2016-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dense Prediction on Sequences with Time-Dilated Convolutions for Speech
  Recognition</dc:title>
 <dc:creator>Sercu, Tom</dc:creator>
 <dc:creator>Goel, Vaibhava</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In computer vision pixelwise dense prediction is the task of predicting a
label for each pixel in the image. Convolutional neural networks achieve good
performance on this task, while being computationally efficient. In this paper
we carry these ideas over to the problem of assigning a sequence of labels to a
set of speech frames, a task commonly known as framewise classification. We
show that dense prediction view of framewise classification offers several
advantages and insights, including computational efficiency and the ability to
apply batch normalization. When doing dense prediction we pay specific
attention to strided pooling in time and introduce an asymmetric dilated
convolution, called time-dilated convolution, that allows for efficient and
elegant implementation of pooling in time. We show results using time-dilated
convolutions in a very deep VGG-style CNN with batch normalization on the Hub5
Switchboard-2000 benchmark task. With a big n-gram language model, we achieve
7.7% WER which is the best single model single-pass performance reported so
far.
</dc:description>
 <dc:description>Comment: Appeared at NIPS 2016 End-to-end Learning for Speech and Audio
  Processing Workshop</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2016-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09288</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09296</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Congestion-Free Rerouting of Flows on DAGs</dc:title>
 <dc:creator>Amiri, Saeed Akhoondian</dc:creator>
 <dc:creator>Dudycz, Szymon</dc:creator>
 <dc:creator>Schmid, Stefan</dc:creator>
 <dc:creator>Wiederrecht, Sebastian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Changing a given configuration in a graph into another one is known as a re-
configuration problem. Such problems have recently received much interest in
the context of algorithmic graph theory. We initiate the theoretical study of
the following reconfiguration problem: How to reroute $k$ unsplittable flows of
a certain demand in a capacitated network from their current paths to their
respective new paths, in a congestion-free manner? This problem finds immediate
applications, e.g., in traffic engineering in computer networks. We show that
the problem is generally NP-hard already for $k = 2$ flows, which motivates us
to study rerouting on a most basic class of flow graphs, namely DAGs.
Interestingly, we find that for general $k$, deciding whether an unsplittable
multi-commodity flow rerouting schedule exists, is NP-hard even on DAGs. Both
NP-hardness proofs are non-trivial. Our main contribution is a polynomial-time
(fixed parameter tractable) algorithm to solve the route update problem for a
bounded number of flows on DAGs. At the heart of our algorithm lies a novel
decomposition of the flow network that allows us to express and resolve
reconfiguration dependencies among flows.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09304</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimizing Multimodular Functions and Allocating Capacity in
  Bike-Sharing Systems</dc:title>
 <dc:creator>Freund, Daniel</dc:creator>
 <dc:creator>Henderson, Shane G.</dc:creator>
 <dc:creator>Shmoys, David B.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The growing popularity of bike-sharing systems around the world has motivated
recent attention to models and algorithms for the effective operation of these
systems. Most of this literature focuses on their daily operation for managing
asymmetric demand. In this work, we consider the more strategic question of how
to (re-)allocate dock-capacity in such systems. We develop mathematical
formulations for variations of this problem (service performance over the
course of one day, long-run- average performance) and exhibit discrete convex
properties in associated optimization problems. This allows us to design a
practically fast polynomial-time allocation algorithm to compute optimal
solutions for this problem, which can also handle practically motivated
constraints, such as a limit on the number of docks moved in the system.
  We apply our algorithm to data sets from Boston, New York City, and Chicago
to investigate how different dock allocations can yield better service in these
systems. Recommendations based on our analysis have been adopted by system
operators in Boston and New York City. Beyond optimizing for improved quality
of service through better allocations, our results also quantify the reduction
in rebalancing achievable through strategically reallocating docks.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-10-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09304</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09309</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaze Embeddings for Zero-Shot Image Classification</dc:title>
 <dc:creator>Karessli, Nour</dc:creator>
 <dc:creator>Akata, Zeynep</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:creator>Bulling, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Zero-shot image classification using auxiliary information, such as
attributes describing discriminative object properties, requires time-consuming
annotation by domain experts. We instead propose a method that relies on human
gaze as auxiliary information, exploiting that even non-expert users have a
natural ability to judge class membership. We present a data collection
paradigm that involves a discrimination task to increase the information
content obtained from gaze data. Our method extracts discriminative descriptors
from the data and learns a compatibility function between image and gaze using
three novel gaze embeddings: Gaze Histograms (GH), Gaze Features with Grid
(GFG) and Gaze Features with Sequence (GFS). We introduce two new
gaze-annotated datasets for fine-grained image classification and show that
human gaze data is indeed class discriminative, provides a competitive
alternative to expert-annotated attributes, and outperforms other baselines for
zero-shot image classification.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09312</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Boundary-Aware Neural Encoder for Video Captioning</dc:title>
 <dc:creator>Baraldi, Lorenzo</dc:creator>
 <dc:creator>Grana, Costantino</dc:creator>
 <dc:creator>Cucchiara, Rita</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The use of Recurrent Neural Networks for video captioning has recently gained
a lot of attention, since they can be used both to encode the input video and
to generate the corresponding description. In this paper, we present a
recurrent video encoding scheme which can discover and leverage the
hierarchical structure of the video. Unlike the classical encoder-decoder
approach, in which a video is encoded continuously by a recurrent layer, we
propose a novel LSTM cell, which can identify discontinuity points between
frames or segments and modify the temporal connections of the encoding layer
accordingly. We evaluate our approach on three large-scale datasets: the
Montreal Video Annotation dataset, the MPII Movie Description dataset and the
Microsoft Video Description Corpus. Experiments show that our approach can
discover appropriate hierarchical representations of input videos and improve
the state of the art results on movie description datasets.
</dc:description>
 <dc:description>Comment: CVPR 2017</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09316</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forward Backward Similarity Search in Knowledge Networks</dc:title>
 <dc:creator>Shi, Baoxu</dc:creator>
 <dc:creator>Yang, Lin</dc:creator>
 <dc:creator>Weninger, Tim</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Similarity search is a fundamental problem in social and knowledge networks
like GitHub, DBLP, Wikipedia, etc. Existing network similarity measures are
limited because they only consider similarity from the perspective of the query
node. However, due to the complicated topology of real-world networks, ignoring
the preferences of target nodes often results in odd or unintuitive
performance. In this work, we propose a dual perspective similarity metric
called Forward Backward Similarity (FBS) that efficiently computes topological
similarity from the perspective of both the query node and the perspective of
candidate nodes. The effectiveness of our method is evaluated by traditional
quantitative ranking metrics and large-scale human judgement on four large real
world networks. The proposed method matches human preference and outperforms
other similarity search algorithms on community overlap and link prediction.
Finally, we demonstrate top-5 rankings for five famous researchers on an
academic collaboration network to illustrate how our approach captures
semantics more intuitively than other approaches.
</dc:description>
 <dc:description>Comment: Accepted for publication in Knowledge-Based Systems</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09317</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Locality-Sensitive Hashing without False Negatives for l_p</dc:title>
 <dc:creator>Pacuk, Andrzej</dc:creator>
 <dc:creator>Sankowski, Piotr</dc:creator>
 <dc:creator>Wegrzycki, Karol</dc:creator>
 <dc:creator>Wygocki, Piotr</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  In this paper, we show a construction of locality-sensitive hash functions
without false negatives, i.e., which ensure collision for every pair of points
within a given radius $R$ in $d$ dimensional space equipped with $l_p$ norm
when $p \in [1,\infty]$. Furthermore, we show how to use these hash functions
to solve the $c$-approximate nearest neighbor search problem without false
negatives. Namely, if there is a point at distance $R$, we will certainly
report it and points at distance greater than $cR$ will not be reported for
$c=\Omega(\sqrt{d},d^{1-\frac{1}{p}})$. The constructed algorithms work: - with
preprocessing time $\mathcal{O}(n \log(n))$ and sublinear expected query time,
- with preprocessing time $\mathcal{O}(\mathrm{poly}(n))$ and expected query
time $\mathcal{O}(\log(n))$. Our paper reports progress on answering the open
problem presented by Pagh [8] who considered the nearest neighbor search
without false negatives for the Hamming distance.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures, COCOON 2016</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09317</dc:identifier>
 <dc:identifier>Computing and Combinatorics - 22nd International Conference,
  {COCOON} 2016, Ho Chi Minh City, Vietnam, August 2-4, 2016, Proceedings,
  pages 105--118</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-42634-1_9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09318</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Reductions for Model Checking Concurrent Software</dc:title>
 <dc:creator>G&#xfc;nther, Henning</dc:creator>
 <dc:creator>Laarman, Alfons</dc:creator>
 <dc:creator>Sokolova, Ana</dc:creator>
 <dc:creator>Weissenbacher, Georg</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Symbolic model checking of parallel programs stands and falls with effective
methods of dealing with the explosion of interleavings. We propose a dynamic
reduction technique to avoid unnecessary interleavings. By extending Lipton's
original work with a notion of bisimilarity, we accommodate dynamic
transactions, and thereby reduce dependence on the accuracy of static analysis,
which is a severe bottleneck in other reduction techniques.
  The combination of symbolic model checking and dynamic reduction techniques
has proven to be challenging in the past. Our generic reduction theorem
nonetheless enables us to derive an efficient symbolic encoding, which we
implemented for IC3 and BMC. The experiments demonstrate the power of dynamic
reduction on several case studies and a large set of SVCOMP benchmarks.
</dc:description>
 <dc:description>Comment: 38 pages</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09321</identifier>
 <datestamp>2017-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Policy Gradient by Exploring Under-appreciated Rewards</dc:title>
 <dc:creator>Nachum, Ofir</dc:creator>
 <dc:creator>Norouzi, Mohammad</dc:creator>
 <dc:creator>Schuurmans, Dale</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper presents a novel form of policy gradient for model-free
reinforcement learning (RL) with improved exploration properties. Current
policy-based methods use entropy regularization to encourage undirected
exploration of the reward landscape, which is ineffective in high dimensional
spaces with sparse rewards. We propose a more directed exploration strategy
that promotes exploration of under-appreciated reward regions. An action
sequence is considered under-appreciated if its log-probability under the
current policy under-estimates its resulting reward. The proposed exploration
strategy is easy to implement, requiring small modifications to an
implementation of the REINFORCE algorithm. We evaluate the approach on a set of
algorithmic tasks that have long challenged RL methods. Our approach reduces
hyper-parameter sensitivity and demonstrates significant improvements over
baseline methods. Our algorithm successfully solves a benchmark multi-digit
addition task and generalizes to long sequences. This is, to our knowledge, the
first time that a pure RL method has solved addition using only reward
feedback.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09325</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Is Around The Camera?</dc:title>
 <dc:creator>Georgoulis, Stamatios</dc:creator>
 <dc:creator>Rematas, Konstantinos</dc:creator>
 <dc:creator>Ritschel, Tobias</dc:creator>
 <dc:creator>Fritz, Mario</dc:creator>
 <dc:creator>Tuytelaars, Tinne</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  How much does a single image reveal about the environment it was taken in? In
this paper, we investigate how much of that information can be retrieved from a
foreground object, combined with the background (i.e. the visible part of the
environment). Assuming it is not perfectly diffuse, the foreground object acts
as a complexly shaped and far-from-perfect mirror. An additional challenge is
that its appearance confounds the light coming from the environment with the
unknown materials it is made of. We propose a learning-based approach to
predict the environment from multiple reflectance maps that are computed from
approximate surface normals. The proposed method allows us to jointly model the
statistics of environments and material properties. We train our system from
synthesized training data, but demonstrate its applicability to real-world
data. Interestingly, our analysis shows that the information obtained from
objects made out of multiple materials often is complementary and leads to
better performance.
</dc:description>
 <dc:description>Comment: Accepted to ICCV. Project:
  http://homes.esat.kuleuven.be/~sgeorgou/multinatillum/</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09326</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for
  Semantic Segmentation</dc:title>
 <dc:creator>J&#xe9;gou, Simon</dc:creator>
 <dc:creator>Drozdzal, Michal</dc:creator>
 <dc:creator>Vazquez, David</dc:creator>
 <dc:creator>Romero, Adriana</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  State-of-the-art approaches for semantic image segmentation are built on
Convolutional Neural Networks (CNNs). The typical segmentation architecture is
composed of (a) a downsampling path responsible for extracting coarse semantic
features, followed by (b) an upsampling path trained to recover the input image
resolution at the output of the model and, optionally, (c) a post-processing
module (e.g. Conditional Random Fields) to refine the model predictions.
  Recently, a new CNN architecture, Densely Connected Convolutional Networks
(DenseNets), has shown excellent results on image classification tasks. The
idea of DenseNets is based on the observation that if each layer is directly
connected to every other layer in a feed-forward fashion then the network will
be more accurate and easier to train.
  In this paper, we extend DenseNets to deal with the problem of semantic
segmentation. We achieve state-of-the-art results on urban scene benchmark
datasets such as CamVid and Gatech, without any further post-processing module
nor pretraining. Moreover, due to smart construction of the model, our approach
has much less parameters than currently published best entries for these
datasets.
  Code to reproduce the experiments is available here :
https://github.com/SimJeg/FC-DenseNet/blob/master/train.py
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09328</identifier>
 <datestamp>2017-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerated Gradient Temporal Difference Learning</dc:title>
 <dc:creator>Pan, Yangchen</dc:creator>
 <dc:creator>White, Adam</dc:creator>
 <dc:creator>White, Martha</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The family of temporal difference (TD) methods span a spectrum from
computationally frugal linear methods like TD({\lambda}) to data efficient
least squares methods. Least square methods make the best use of available data
directly computing the TD solution and thus do not require tuning a typically
highly sensitive learning rate parameter, but require quadratic computation and
storage. Recent algorithmic developments have yielded several sub-quadratic
methods that use an approximation to the least squares TD solution, but incur
bias. In this paper, we propose a new family of accelerated gradient TD (ATD)
methods that (1) provide similar data efficiency benefits to least-squares
methods, at a fraction of the computation and storage (2) significantly reduce
parameter sensitivity compared to linear TD methods, and (3) are asymptotically
unbiased. We illustrate these claims with a proof of convergence in expectation
and experiments on several benchmark domains and a large-scale industrial
energy allocation domain.
</dc:description>
 <dc:description>Comment: AAAI Conference on Artificial Intelligence (AAAI), 2017</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09332</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cryptographically verifiable anonymous voting using pan-european e-IDs</dc:title>
 <dc:creator>Preziosi, Alessandro</dc:creator>
 <dc:creator>Berbecaru, Diana</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper we explore a method to create anonymous services on top of the
STORK framework, to be used for electronic surveys or elections.
  The STORK project aims to realize a single electronic identification and
authentication area across Europe. For verifiable and anonymous voting, users
should be authenticated with their e-id (to prevent repeated voting) but the
votes should also be anonymous. This is achieved using blind signatures and an
onion routing system similar to the one used in TOR.
  In the paper we describe the anonymous voting protocol in detail, we analyze
a reference implementation and, finally, we highlight potential weaknesses and
propose some improvements.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09332</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09333</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dictionary Learning with Equiprobable Matching Pursuit</dc:title>
 <dc:creator>Sandin, Fredrik</dc:creator>
 <dc:creator>Martin-del-Campo, Sergio</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Sparse signal representations based on linear combinations of learned atoms
have been used to obtain state-of-the-art results in several practical signal
processing applications. Approximation methods are needed to process
high-dimensional signals in this way because the problem to calculate optimal
atoms for sparse coding is NP-hard. Here we study greedy algorithms for
unsupervised learning of dictionaries of shift-invariant atoms and propose a
new method where each atom is selected with the same probability on average,
which corresponds to the homeostatic regulation of a recurrent convolutional
neural network. Equiprobable selection can be used with several greedy
algorithms for dictionary learning to ensure that all atoms adapt during
training and that no particular atom is more likely to take part in the linear
combination on average. We demonstrate via simulation experiments that
dictionary learning with equiprobable selection results in higher entropy of
the sparse representation and lower reconstruction and denoising errors, both
in the case of ordinary matching pursuit and orthogonal matching pursuit with
shift-invariant dictionaries. Furthermore, we show that the computational costs
of the matching pursuits are lower with equiprobable selection, leading to
faster and more accurate dictionary learning algorithms.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09335</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ViFi: Virtual Fingerprinting WiFi-based Indoor Positioning via
  Multi-Wall Multi-Floor Propagation Model</dc:title>
 <dc:creator>Caso, Giuseppe</dc:creator>
 <dc:creator>De Nardis, Luca</dc:creator>
 <dc:creator>Lemic, Filip</dc:creator>
 <dc:creator>Handziski, Vlado</dc:creator>
 <dc:creator>Wolisz, Adam</dc:creator>
 <dc:creator>Di Benedetto, Maria-Gabriella</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Widespread adoption of indoor positioning systems based on WiFi
fingerprinting is at present hindered by the large efforts required for
measurements collection during the offline phase. Two approaches were recently
proposed to address such issue: crowdsourcing and RSS radiomap prediction based
on either interpolation or propagation channel model fitting from a small set
of measurements. RSS prediction promises better positioning accuracy when
compared to crowdsourcing but no systematic analysis of the impact of system
parameters on positioning accuracy is available. This paper fills this gap by
introducing ViFi, an indoor positioning system that relies on RSS prediction
based on Multi-Wall Multi-Floor (MWMF) propagation model to generate a discrete
RSS radiomap (virtual fingerprints). The ViFi system is subject to an extensive
experimental analysis in order to address the role of all relevant system
parameters. Experimental results obtained in two different testbeds show that
the introduction of virtual fingerprints allows reduction by a factor of 10 of
the number of measurements, without significant loss in positioning accuracy.
The use of two testbeds also allows to derive general guidelines for the design
and the implementation of a virtual fingerprinting system.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09340</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diet Networks: Thin Parameters for Fat Genomics</dc:title>
 <dc:creator>Romero, Adriana</dc:creator>
 <dc:creator>Carrier, Pierre Luc</dc:creator>
 <dc:creator>Erraqabi, Akram</dc:creator>
 <dc:creator>Sylvain, Tristan</dc:creator>
 <dc:creator>Auvolat, Alex</dc:creator>
 <dc:creator>Dejoie, Etienne</dc:creator>
 <dc:creator>Legault, Marc-Andr&#xe9;</dc:creator>
 <dc:creator>Dub&#xe9;, Marie-Pierre</dc:creator>
 <dc:creator>Hussin, Julie G.</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning tasks such as those involving genomic data often poses a serious
challenge: the number of input features can be orders of magnitude larger than
the number of training examples, making it difficult to avoid overfitting, even
when using the known regularization techniques. We focus here on tasks in which
the input is a description of the genetic variation specific to a patient, the
single nucleotide polymorphisms (SNPs), yielding millions of ternary inputs.
Improving the ability of deep learning to handle such datasets could have an
important impact in precision medicine, where high-dimensional data regarding a
particular patient is used to make predictions of interest. Even though the
amount of data for such tasks is increasing, this mismatch between the number
of examples and the number of inputs remains a concern. Naive implementations
of classifier neural networks involve a huge number of free parameters in their
first layer: each input feature is associated with as many parameters as there
are hidden units. We propose a novel neural network parametrization which
considerably reduces the number of free parameters. It is based on the idea
that we can first learn or provide a distributed representation for each input
feature (e.g. for each position in the genome where variations are observed),
and then learn (with another neural network called the parameter prediction
network) how to map a feature's distributed representation to the vector of
parameters specific to that feature in the classifier neural network (the
weights which link the value of the feature to each of the hidden units). We
show experimentally on a population stratification task of interest to medical
studies that the proposed approach can significantly reduce both the number of
parameters and the error rate of the classifier.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-03-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09340</dc:identifier>
 <dc:identifier>ICLR 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09345</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unifying Multi-Domain Multi-Task Learning: Tensor and Neural Network
  Perspectives</dc:title>
 <dc:creator>Yang, Yongxin</dc:creator>
 <dc:creator>Hospedales, Timothy M.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Multi-domain learning aims to benefit from simultaneously learning across
several different but related domains. In this chapter, we propose a single
framework that unifies multi-domain learning (MDL) and the related but better
studied area of multi-task learning (MTL). By exploiting the concept of a
\emph{semantic descriptor} we show how our framework encompasses various
classic and recent MDL/MTL algorithms as special cases with different semantic
descriptor encodings. As a second contribution, we present a higher order
generalisation of this framework, capable of simultaneous
multi-task-multi-domain learning. This generalisation has two mathematically
equivalent views in multi-linear algebra and gated neural networks
respectively. Moreover, by exploiting the semantic descriptor, it provides
neural networks the capability of zero-shot learning (ZSL), where a classifier
is generated for an unseen class without any training data; as well as
zero-shot domain adaptation (ZSDA), where a model is generated for an unseen
domain without any training data. In practice, this framework provides a
powerful yet easy to implement method that can be flexibly applied to MTL, MDL,
ZSL and ZSDA.
</dc:description>
 <dc:description>Comment: Invited book chapter</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09351</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adams Conditioning and Likelihood Ratio Transfer Mediated Inference</dc:title>
 <dc:creator>Bergstra, Jan A.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Forensic science advocates the use of inference mechanisms which may be
viewed as simple multi-agent protocols. An important protocol of this kind
involves an agent FE (forensic expert) who communicates to a second agent TOF
(trier of fact) first its value of a certain likelihood ratio with respect to
its own belief state which is supposed to be captured by a probability function
on FE's proposition space. Subsequently FE communicates its recently acquired
confirmation that a certain evidence proposition is true. The inference part of
this sort of reasoning, here referred to as likelihood ratio transfer mediated
reasoning, involves TOF's revision of its own belief state, and in particular
an evaluation of the resulting belief in the hypothesis proposition.
  Different realizations of likelihood ratio transfer mediated reasoning are
distinguished: if the evidence hypothesis is included in the prior proposition
space of TOF then a comparison is made between understanding the TOF side of a
belief revision step as a composition of two successive steps of single
likelihood Adams conditioning followed by a Bayes conditioning step, and as a
single step of double likelihood Adams conditioning followed by Bayes
conditioning; if, however the evidence hypothesis is initially outside the
proposition space of TOF an application of proposition kinetics for the
introduction of the evidence proposition precedes Bayesian conditioning, which
is followed by Jeffrey conditioning on the hypothesis proposition.
</dc:description>
 <dc:description>Comment: In this revision, besides the improvement of several details, an
  embarrassing miscalculation with implications in several Sections has been
  detected and (hopefully) repaired. A description of the Taxi Color Case (TCC)
  has been included. A transition system of credal states is proposed as a
  standard model of proposition and belief kinetics. (Extension from 50 to 57
  pages)</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2016-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09379</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Multipole Method based filtering of non-uniformly sampled data</dc:title>
 <dc:creator>Gumerov, Nail A.</dc:creator>
 <dc:creator>Duraiswami, Ramani</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Non-uniform fast Fourier Transform (NUFFT) and inverse NUFFT (INUFFT)
algorithms, based on the Fast Multipole Method (FMM) are developed and tested.
Our algorithms are based on a novel factorization of the FFT kernel, and are
implemented with attention to data structures and error analysis.
  Note: This unpublished manuscript was available on our web pages and has been
referred to by others in the literature. To provide a proper archival reference
we are placing it on arXiv.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures, unpublished report from 2003</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09384</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Emergence of Organizing Structure in Conceptual Representation</dc:title>
 <dc:creator>Lake, Brenden M.</dc:creator>
 <dc:creator>Lawrence, Neil D.</dc:creator>
 <dc:creator>Tenenbaum, Joshua B.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Both scientists and children make important structural discoveries, yet their
computational underpinnings are not well understood. Structure discovery has
previously been formalized as probabilistic inference about the right
structural form --- where form could be a tree, ring, chain, grid, etc. [Kemp &amp;
Tenenbaum (2008). The discovery of structural form. PNAS, 105(3), 10687-10692].
While this approach can learn intuitive organizations, including a tree for
animals and a ring for the color circle, it assumes a strong inductive bias
that considers only these particular forms, and each form is explicitly
provided as initial knowledge. Here we introduce a new computational model of
how organizing structure can be discovered, utilizing a broad hypothesis space
with a preference for sparse connectivity. Given that the inductive bias is
more general, the model's initial knowledge shows little qualitative
resemblance to some of the discoveries it supports. As a consequence, the model
can also learn complex structures for domains that lack intuitive description,
as well as predict human property induction judgments without explicit
structural forms. By allowing form to emerge from sparsity, our approach
clarifies how both the richness and flexibility of human conceptual
organization can coexist.
</dc:description>
 <dc:description>Comment: In press at Cognitive Science</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09387</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>There is Something Beyond the Twitter Network</dc:title>
 <dc:creator>Pacuk, Andrzej</dc:creator>
 <dc:creator>Sankowski, Piotr</dc:creator>
 <dc:creator>Wegrzycki, Karol</dc:creator>
 <dc:creator>Wygocki, Piotr</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>I.6</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:description>  How information spreads through a social network? Can we assume, that the
information is spread only through a given social network graph? What is the
correct way to compare the models of information flow? These are the basic
questions we address in this work.
  We focus on meticulous comparison of various, well-known models of rumor
propagation in the social network. We introduce the model incorporating mass
media and effects of absent nodes. In this model the information appears
spontaneously in the graph. Using the most conservative metric, we showed that
the distribution of cascades sizes generated by this model fits the real data
much better than the previously considered models.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, Hypertext 2016</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09387</dc:identifier>
 <dc:identifier>Proceedings of the 27th {ACM} Conference on Hypertext and Social
  Media, {HT} 2016, Halifax, NS, Canada, July 10-13, 2016, pages 279--284</dc:identifier>
 <dc:identifier>doi:10.1145/2914586.2914623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09392</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Holistic 3D Scene Abstractions for Text-based Image Retrieval</dc:title>
 <dc:creator>Li, Ang</dc:creator>
 <dc:creator>Sun, Jin</dc:creator>
 <dc:creator>Ng, Joe Yue-Hei</dc:creator>
 <dc:creator>Yu, Ruichi</dc:creator>
 <dc:creator>Morariu, Vlad I.</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Spatial relationships between objects provide important information for
text-based image retrieval. As users are more likely to describe a scene from a
real world perspective, using 3D spatial relationships rather than 2D
relationships that assume a particular viewing direction, one of the main
challenges is to infer the 3D structure that bridges images with users' text
descriptions. However, direct inference of 3D structure from images requires
learning from large scale annotated data. Since interactions between objects
can be reduced to a limited set of atomic spatial relations in 3D, we study the
possibility of inferring 3D structure from a text description rather than an
image, applying physical relation models to synthesize holistic 3D abstract
object layouts satisfying the spatial constraints present in a textual
description. We present a generic framework for retrieving images from a
textual description of a scene by matching images with these generated abstract
object layouts. Images are ranked by matching object detection outputs
(bounding boxes) to 2D layout candidates (also represented by bounding boxes)
which are obtained by projecting the 3D scenes with sampled camera directions.
We validate our approach using public indoor scene datasets and show that our
method outperforms baselines built upon object occurrence histograms and
learned 2D pairwise relations.
</dc:description>
 <dc:description>Comment: CVPR 2017</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09394</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Material Recognition from Local Appearance in Global Context</dc:title>
 <dc:creator>Schwartz, Gabriel</dc:creator>
 <dc:creator>Nishino, Ko</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recognition of materials has proven to be a challenging problem due to the
wide variation in appearance within and between categories. Global image
context, such as where the material is or what object it makes up, can be
crucial to recognizing the material. Existing methods, however, operate on an
implicit fusion of materials and context by using large receptive fields as
input (i.e., large image patches). Many recent material recognition methods
treat materials as yet another set of labels like objects. Materials are,
however, fundamentally different from objects as they have no inherent shape or
defined spatial extent. Approaches that ignore this can only take advantage of
limited implicit context as it appears during training. We instead show that
recognizing materials purely from their local appearance and integrating
separately recognized global contextual cues including objects and places leads
to superior dense, per-pixel, material recognition. We achieve this by training
a fully-convolutional material recognition network end-to-end with only
material category supervision. We integrate object and place estimates to this
network from independent CNNs. This approach avoids the necessity of preparing
an impractically-large amount of training data to cover the product space of
materials, objects, and scenes, while fully leveraging contextual cues for
dense material recognition. Furthermore, we perform a detailed analysis of the
effects of context granularity, spatial resolution, and the network level at
which we introduce context. On a recently introduced comprehensive and diverse
material database \cite{Schwartz2016}, we confirm that our method achieves
state-of-the-art accuracy with significantly less training data compared to
past methods.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09400</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalization of the de Bruijn's identity to general $\phi$-entropies
  and $\phi$-Fisher informations</dc:title>
 <dc:creator>Toranzo, Irene Valero</dc:creator>
 <dc:creator>Zozor, Steeve</dc:creator>
 <dc:creator>Brossier, Jean-Marc</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose generalizations of the de Bruijn's identities based
on extensions of the Shannon entropy, Fisher information and their associated
divergences or relative measures. The foundation of these generalizations are
the $\phi$-entropies and divergences of the Csisz\'a's class (or Salicr\'u's
class) considered within a multidimensional context, included the
monodimensional case, and for several type of noisy channels characterized by a
more general probability distribution beyond the well-known Gaussian noise. It
is found that the gradient and/or the hessian of these entropies or divergences
with respect to the noise parameters give naturally rise to generalized
versions of the Fisher information or divergence, which are named as the
$\phi$-Fisher information (divergence). The obtained identities can be viewed
as further extensions of the classical de Bruijn's identity. Analogously, it is
shown that a similar relation holds between the $\phi$-divergence and a
extended mean-square error, named $\phi$-mean square error, for the Gaussian
channel.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09405</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An End-to-End Architecture for Keyword Spotting and Voice Activity
  Detection</dc:title>
 <dc:creator>Lengerich, Chris</dc:creator>
 <dc:creator>Hannun, Awni</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose a single neural network architecture for two tasks: on-line
keyword spotting and voice activity detection. We develop novel inference
algorithms for an end-to-end Recurrent Neural Network trained with the
Connectionist Temporal Classification loss function which allow our model to
achieve high accuracy on both keyword spotting and voice activity detection
without retraining. In contrast to prior voice activity detection models, our
architecture does not require aligned training data and uses the same
parameters as the keyword spotting model. This allows us to deploy a high
quality voice activity detector with no additional memory or maintenance
requirements.
</dc:description>
 <dc:description>Comment: NIPS 2016 End-to-End Learning for Speech and Audio Processing
  Workshop</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09414</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Split-door criterion for causal identification: Automatic search for
  natural experiments</dc:title>
 <dc:creator>Sharma, Amit</dc:creator>
 <dc:creator>Hofman, Jake M.</dc:creator>
 <dc:creator>Watts, Duncan J.</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Unobserved or unknown confounders complicate even the simplest attempts to
estimate the effect of one variable on another using observational data. When
cause and effect are both affected by unobserved confounders, methods based on
identifying natural experiments have been proposed to eliminate confounds.
However, their validity is hard to verify because they depend on assumptions
about the independence of variables, that by definition, cannot be measured. In
this paper we investigate a particular scenario in time series data that
permits causal identification in the presence of unobserved confounders and
present an algorithm to automatically find such scenarios. Specifically, we
examine what we call the split-door setting, when the effect variable can be
split up into two parts: one that is potentially affected by the cause, and
another that is independent of it. We show that when both of these variables
are caused by the same (unobserved) confounders, the problem of identification
reduces to that of testing for independence among observed variables. We
discuss various situations in which split-door variables are commonly recorded
in both online and offline settings, and demonstrate the method by estimating
the causal impact of Amazon's recommender system, obtaining more than 23,000
natural experiments that provide similar---but more precise---estimates than
past studies.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09418</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Online Intrusion Detection for SCADA Networks</dc:title>
 <dc:creator>Wang, Hongrui</dc:creator>
 <dc:creator>Lu, Tao</dc:creator>
 <dc:creator>Dong, Xiaodai</dc:creator>
 <dc:creator>Li, Peixue</dc:creator>
 <dc:creator>Xie, Michael</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We propose a novel hierarchical online intrusion detection system (HOIDS) for
supervisory control and data acquisition (SCADA) networks based on machine
learning algorithms. By utilizing the server-client topology while keeping
clients distributed for global protection, high detection rate is achieved with
minimum network impact. We implement accurate models of normal-abnormal binary
detection and multi-attack identification based on logistic regression and
quasi-Newton optimization algorithm using the Broyden-Fletcher-Goldfarb-Shanno
approach. The detection system is capable of accelerating detection by
information gain based feature selection or principle component analysis based
dimension reduction. By evaluating our system using the KDD99 dataset and the
industrial control system dataset, we demonstrate that HOIDS is highly
scalable, efficient and cost effective for securing SCADA infrastructures.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09419</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safety-Aware Robot Damage Recovery Using Constrained Bayesian
  Optimization and Simulated Priors</dc:title>
 <dc:creator>Papaspyros, Vaios</dc:creator>
 <dc:creator>Chatzilygeroudis, Konstantinos</dc:creator>
 <dc:creator>Vassiliades, Vassilis</dc:creator>
 <dc:creator>Mouret, Jean-Baptiste</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The recently introduced Intelligent Trial-and-Error (IT&amp;E) algorithm showed
that robots can adapt to damage in a matter of a few trials. The success of
this algorithm relies on two components: prior knowledge acquired through
simulation with an intact robot, and Bayesian optimization (BO) that operates
on-line, on the damaged robot. While IT&amp;E leads to fast damage recovery, it
does not incorporate any safety constraints that prevent the robot from
attempting harmful behaviors. In this work, we address this limitation by
replacing the BO component with a constrained BO procedure. We evaluate our
approach on a simulated damaged humanoid robot that needs to crawl as fast as
possible, while performing as few unsafe trials as possible. We compare our new
&quot;safety-aware IT&amp;E&quot; algorithm to IT&amp;E and a multi-objective version of IT&amp;E in
which the safety constraints are dealt as separate objectives. Our results show
that our algorithm outperforms the other approaches, both in crawling speed
within the safe regions and number of unsafe trials.
</dc:description>
 <dc:description>Comment: Accepted at the BayesOpt 2016 NIPS workshop, 5 pages, 2 figures, 1
  algorithm</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09424</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development of a multi-sensor perceptual system for mobile robot and
  EKF-based localization</dc:title>
 <dc:creator>Hoang, T. T.</dc:creator>
 <dc:creator>Duong, P. M.</dc:creator>
 <dc:creator>Van, N. T. T.</dc:creator>
 <dc:creator>Viet, D. A.</dc:creator>
 <dc:creator>Vinh, T. Q.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents the design and implementation of a perceptual system for
the mobile robot using modern sensors and multi-point communication channels.
The data extracted from the perceptual system is processed by a sensor fusion
model to obtain meaningful information for the robot localization and control.
Due to the uncertainties of acquiring data, an extended Kalman filter was
applied to get optimal states of the system. Several experiments have been
conducted and the results confirmed the functioning operation of the perceptual
system and the efficiency of the Kalman filter approach.
</dc:description>
 <dc:description>Comment: In 2012 International Conference on Systems and Informatics (ICSAI).
  arXiv admin note: substantial text overlap with arXiv:1611.07112,
  arXiv:1611.07114</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09424</dc:identifier>
 <dc:identifier>doi:10.1109/ICSAI.2012.6223050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09427</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Easy-setup eye movement recording system for human-computer interaction</dc:title>
 <dc:creator>Phung, Manh Duong</dc:creator>
 <dc:creator>Tran, Quang Vinh</dc:creator>
 <dc:creator>Hara, Kenji</dc:creator>
 <dc:creator>Inagaki, Hirohito</dc:creator>
 <dc:creator>Abe, Masanobu</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Tracking the movement of human eyes is expected to yield natural and
convenient applications based on human-computer interaction (HCI). To implement
an effective eye-tracking system, eye movements must be recorded without
placing any restriction on the user's behavior or user discomfort. This paper
describes an eye movement recording system that offers free-head, simple
configuration. It does not require the user to wear anything on her head, and
she can move her head freely. Instead of using a computer, the system uses a
visual digital signal processor (DSP) camera to detect the position of eye
corner, the center of pupil and then calculate the eye movement. Evaluation
tests show that the sampling rate of the system can be 300 Hz and the accuracy
is about 1.8 degree/s.
</dc:description>
 <dc:description>Comment: In IEEE International Conference on Research, Innovation and Vision
  for the Future (RIVF), 2008</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09427</dc:identifier>
 <dc:identifier>doi:10.1109/RIVF.2008.4586369</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09430</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emergence of foveal image sampling from learning to attend in visual
  scenes</dc:title>
 <dc:creator>Cheung, Brian</dc:creator>
 <dc:creator>Weiss, Eric</dc:creator>
 <dc:creator>Olshausen, Bruno</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We describe a neural attention model with a learnable retinal sampling
lattice. The model is trained on a visual search task requiring the
classification of an object embedded in a visual scene amidst background
distractors using the smallest number of fixations. We explore the tiling
properties that emerge in the model's retinal sampling lattice after training.
Specifically, we show that this lattice resembles the eccentricity dependent
sampling lattice of the primate retina, with a high resolution region in the
fovea surrounded by a low resolution periphery. Furthermore, we find conditions
where these emergent properties are amplified or eliminated providing clues to
their function.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-10-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09431</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localization of a unicycle-like mobile robot using LRF and
  omni-directional camera</dc:title>
 <dc:creator>Dinh, Tran Hiep</dc:creator>
 <dc:creator>Phung, Manh Duong</dc:creator>
 <dc:creator>Tran, Thuan Hoang</dc:creator>
 <dc:creator>Tran, Quang Vinh</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper addresses the localization problem. The extended Kalman filter
(EKF) is employed to localize a unicycle-like mobile robot equipped with a
laser range finder (LRF) sensor and an omni-directional camera. The LRF is used
to scan the environment which is described with line segments. The segments are
extracted by a modified least square quadratic method in which a dynamic
threshold is injected. The camera is employed to determine the robot's
orientation. The prediction step of the EKF is performed by extracting
parameters from the kinematic model and input signal of the robot. The
correction step is conducted with the implementation of a line matching
algorithm and the comparison between line's parameters of the local and global
maps. In the line matching algorithm, a conversion matrix is introduced to
reduce the computation cost. Experiments have been carried out in a real mobile
robot system and the results prove the applicability of the method for the
purpose of localization.
</dc:description>
 <dc:description>Comment: In 2012 IEEE International Conference on Control System, Computing
  and Engineering (ICCSCE)</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09431</dc:identifier>
 <dc:identifier>doi:10.1109/ICCSCE.2012.6487193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09433</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel platform for internet-based mobile robot systems</dc:title>
 <dc:creator>Duong, P. M.</dc:creator>
 <dc:creator>Hoang, T. T.</dc:creator>
 <dc:creator>Van, N. T. T.</dc:creator>
 <dc:creator>Viet, D. A.</dc:creator>
 <dc:creator>Vinh, T. Q.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we introduce a software and hardware structure for on-line
mobile robotic systems. The hardware mainly consists of a Multi-Sensor Smart
Robot connected to the Internet through 3G mobile network. The system employs a
client-server software architecture in which the exchanged data between the
client and the server is transmitted through different transport protocols.
Autonomous mechanisms such as obstacle avoidance and safe-point achievement are
implemented to ensure the robot safety. This architecture is put into operation
on the real Internet and the preliminary result is promising. By adopting this
structure, it will be very easy to construct an experimental platform for the
research on diverse tele-operation topics such as remote control algorithms,
interface designs, network protocols and applications etc.
</dc:description>
 <dc:description>Comment: In 2012 7th IEEE Conference on Industrial Electronics and
  Applications (ICIEA)</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09433</dc:identifier>
 <dc:identifier>doi:10.1109/ICIEA.2012.6361052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09434</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Input Switched Affine Networks: An RNN Architecture Designed for
  Interpretability</dc:title>
 <dc:creator>Foerster, Jakob N.</dc:creator>
 <dc:creator>Gilmer, Justin</dc:creator>
 <dc:creator>Chorowski, Jan</dc:creator>
 <dc:creator>Sohl-Dickstein, Jascha</dc:creator>
 <dc:creator>Sussillo, David</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  There exist many problem domains where the interpretability of neural network
models is essential for deployment. Here we introduce a recurrent architecture
composed of input-switched affine transformations - in other words an RNN
without any explicit nonlinearities, but with input-dependent recurrent
weights. This simple form allows the RNN to be analyzed via straightforward
linear methods: we can exactly characterize the linear contribution of each
input to the model predictions; we can use a change-of-basis to disentangle
input, output, and computational hidden unit subspaces; we can fully
reverse-engineer the architecture's solution to a simple task. Despite this
ease of interpretation, the input switched affine network achieves reasonable
performance on a text modeling tasks, and allows greater computational
efficiency than networks with standard nonlinearities.
</dc:description>
 <dc:description>Comment: ICLR 2107 submission: https://openreview.net/forum?id=H1MjAnqxg</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09436</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proposal of algorithms for navigation and obstacles avoidance of
  autonomous mobile robot</dc:title>
 <dc:creator>Hoang, T. T.</dc:creator>
 <dc:creator>Hiep, D. T.</dc:creator>
 <dc:creator>Duong, P. M.</dc:creator>
 <dc:creator>Van, N. T. T.</dc:creator>
 <dc:creator>Duong, B. G.</dc:creator>
 <dc:creator>Vinh, T. Q.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents algorithms to navigate and avoid obstacles for an in-door
autonomous mobile robot. A laser range finder is used to obtain 3D images of
the environment. A new algorithm, namely 3D-to-2D image pressure and barriers
detection (IPaBD), is proposed to create a 2D global map from the 3D images.
This map is basic to design the trajectory. A tracking controller is developed
to control the robot to follow the trajectory. The obstacle avoidance is
addressed with the use of sonar sensors. An improved vector field histogram
(Improved-VFH) algorithm is presented with improvements to overcome some
limitations of the original VFH. Experiments have been conducted and the result
is encouraged.
</dc:description>
 <dc:description>Comment: In 2013 8th IEEE Conference on Industrial Electronics and
  Applications (ICIEA)</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09436</dc:identifier>
 <dc:identifier>doi:10.1109/ICIEA.2013.6566569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09441</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sentiment Analysis for Twitter : Going Beyond Tweet Text</dc:title>
 <dc:creator>Poddar, Lahari</dc:creator>
 <dc:creator>Halder, Kishaloy</dc:creator>
 <dc:creator>Jia, Xianyan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Analysing sentiment of tweets is important as it helps to determine the
users' opinion. Knowing people's opinion is crucial for several purposes
starting from gathering knowledge about customer base, e-governance,
campaigning and many more. In this report, we aim to develop a system to detect
the sentiment from tweets. We employ several linguistic features along with
some other external sources of information to detect the sentiment of a tweet.
We show that augmenting the 140 character-long tweet with information harvested
from external urls shared in the tweet as well as Social Media features
enhances the sentiment prediction accuracy significantly.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09444</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The empirical size of trained neural networks</dc:title>
 <dc:creator>Chen, Kevin K.</dc:creator>
 <dc:creator>Gamst, Anthony</dc:creator>
 <dc:creator>Walker, Alden</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  ReLU neural networks define piecewise linear functions of their inputs.
However, initializing and training a neural network is very different from
fitting a linear spline. In this paper, we expand empirically upon previous
theoretical work to demonstrate features of trained neural networks. Standard
network initialization and training produce networks vastly simpler than a
naive parameter count would suggest and can impart odd features to the trained
network. However, we also show the forced simplicity is beneficial and, indeed,
critical for the wide success of these networks.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09446</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FPGA Based Implementation of Distributed Minority and Majority Voting
  Based Redundancy for Mission and Safety-Critical Applications</dc:title>
 <dc:creator>Balasubramanian, P</dc:creator>
 <dc:creator>Mastorakis, N E</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Electronic circuits and systems used in mission and safety-critical
applications usually employ redundancy in the design to overcome arbitrary
fault(s) or failure(s) and guarantee the correct operation. In this context,
the distributed minority and majority voting based redundancy (DMMR) scheme
forms an efficient alternative to the conventional N-modular redundancy (NMR)
scheme for implementing mission and safety-critical circuits and systems by
significantly minimizing their weight and design cost and also their design
metrics whilst providing a similar degree of fault tolerance. This article
presents the first FPGAs based implementation of example DMMR circuits and
compares it with counterpart NMR circuits on the basis of area occupancy and
critical path delay viz. area-delay product (ADP). The example DMMR circuits
and counterpart NMR circuits are able to accommodate the faulty or failure
states of 2, 3 and 4 function modules. For physical synthesis, two commercial
Xilinx FPGAs viz. Spartan 3E and Virtex 5 corresponding to 90nm and 65nm CMOS
processes, and two radiation-tolerant and military grade Xilinx FPGAs viz. QPro
Virtex 2 and QPro Virtex E corresponding to 150nm and 180nm CMOS processes were
considered for the NMR and DMMR circuit realizations which employ the 4-by-4
array multiplier as a representative function module. To achieve a fault
tolerance of 2 function modules, both the DMMR and the NMR schemes provide near
similar mean ADPs across all the four FPGAs. But while achieving a fault
tolerance of 3 function modules the DMMR features reduced ADP by 44.5% on
average compared to the NMR, and in achieving a fault tolerance of 4 function
modules the DMMR reports reduced ADP by 56.5% on average compared to the NMR
with respect to all the four FPGAs considered.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09446</dc:identifier>
 <dc:identifier>International Journal of Circuits and Electronics, 2016, vol. 1,
  pp. 185-190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09448</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Upper Bound on Knots in Neural Networks</dc:title>
 <dc:creator>Chen, Kevin K.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Neural networks with rectified linear unit activations are essentially
multivariate linear splines. As such, one of many ways to measure the
&quot;complexity&quot; or &quot;expressivity&quot; of a neural network is to count the number of
knots in the spline model. We study the number of knots in fully-connected
feedforward neural networks with rectified linear unit activation functions. We
intentionally keep the neural networks very simple, so as to make theoretical
analyses more approachable. An induction on the number of layers $l$ reveals a
tight upper bound on the number of knots in $\mathbb{R} \to \mathbb{R}^p$ deep
neural networks. With $n_i \gg 1$ neurons in layer $i = 1, \dots, l$, the upper
bound is approximately $n_1 \dots n_l$. We then show that the exact upper bound
is tight, and we demonstrate the upper bound with an example. The purpose of
these analyses is to pave a path for understanding the behavior of general
$\mathbb{R}^q \to \mathbb{R}^p$ neural networks.
</dc:description>
 <dc:description>Comment: 19 pages, 8 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09452</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Partial Sums Generator for Constituent Code based
  Successive Cancellation Decoding of Polar Codes</dc:title>
 <dc:creator>Che, Tiben</dc:creator>
 <dc:creator>Choi, Gwan</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  This paper proposes the architecture of partial sum generator for constituent
codes based polar code decoder. Constituent codes based polar code decoder has
the advantage of low latency. However, no purposefully designed partial sum
generator design exists that can yield desired timing for the decoder. We first
derive the mathematical presentation with the partial sums set $\bm{\beta^c}$
which is corresponding to each constituent codes. From this, we concoct a
shift-register based partial sum generator. Next, the overall architecture and
design details are described, and the overhead compared with conventional
partial sum generator is evaluated. Finally, the implementation results with
both ASIC and FPGA technology and relevant discussions are presented.
</dc:description>
 <dc:description>Comment: submitted to TCAS II</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09461</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cost-Sensitive Reference Pair Encoding for Multi-Label Learning</dc:title>
 <dc:creator>Yang, Yao-Yuan</dc:creator>
 <dc:creator>Huang, Kuan-Hao</dc:creator>
 <dc:creator>Chang, Chih-Wei</dc:creator>
 <dc:creator>Lin, Hsuan-Tien</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A general framework for multi-label classification(MLC) called multi-label
error-correcting code (ML-ECC) utilizes coding schemes in communication to
improve MLC performance. The framework includes some key algorithms for some
special cases of MLC, such as binary relevance and random k-labelsets.
Nevertheless, current ML-ECC algorithms are usually designed for one or a few
evaluation criteria, and thus may suffer from bad performance with respect to
other criteria. In this paper, we propose a ML-ECC algorithm that takes the
evaluation criteria into account within the error-correcting code.This
algorithm, named cost-sensitive reference pair encoding(CSRPE), first
transforms the MLC problem into exponentially many binary classification
problems based on the criterion information and a series of reduction steps
from MLC to multi-class classification and then to binary classification. The
exponentially many binary classifiers cause training and prediction
challenges.We resolve the training challenge by random sampling and the
prediction challenge by nearest-neighbor decoding. Extensive experimental
results show that CSRPE achieves stable convergence, and performs better than
other ML-ECC algorithms and the state-of-the-art cost-sensitive MLC algorithms
across different criteria. Furthermore, we demonstrate the potential of CSRPE
in preserving the criterion information by extending it to a novel multi-label
active learning algorithm. The algorithm calculates the uncertainty of each
unlabeled example in the coding space of CSRPE and queries the most uncertain
one. Experimental results demonstrate that the proposed algorithm is superior
to existing multi-label active learning algorithms.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09461</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09464</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Behavior Prediction from First Person Videos</dc:title>
 <dc:creator>Su, Shan</dc:creator>
 <dc:creator>Hong, Jung Pyo</dc:creator>
 <dc:creator>Shi, Jianbo</dc:creator>
 <dc:creator>Park, Hyun Soo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a method to predict the future movements (location and
gaze direction) of basketball players as a whole from their first person
videos. The predicted behaviors reflect an individual physical space that
affords to take the next actions while conforming to social behaviors by
engaging to joint attention. Our key innovation is to use the 3D reconstruction
of multiple first person cameras to automatically annotate each other's the
visual semantics of social configurations.
  We leverage two learning signals uniquely embedded in first person videos.
Individually, a first person video records the visual semantics of a spatial
and social layout around a person that allows associating with past similar
situations. Collectively, first person videos follow joint attention that can
link the individuals to a group. We learn the egocentric visual semantics of
group movements using a Siamese neural network to retrieve future trajectories.
We consolidate the retrieved trajectories from all players by maximizing a
measure of social compatibility---the gaze alignment towards joint attention
predicted by their social formation, where the dynamics of joint attention is
learned by a long-term recurrent convolutional network. This allows us to
characterize which social configuration is more plausible and predict future
group trajectories.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09470</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Teaching Functional Patterns through Robotic Applications</dc:title>
 <dc:creator>Boender, J.</dc:creator>
 <dc:creator>Currie, E.</dc:creator>
 <dc:creator>Loomes, M.</dc:creator>
 <dc:creator>Primiero, G.</dc:creator>
 <dc:creator>Raimondi, F.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present our approach to teaching functional programming to First Year
Computer Science students at Middlesex University through projects in robotics.
A holistic approach is taken to the curriculum, emphasising the connections
between different subject areas. A key part of the students' learning is
through practical projects that draw upon and integrate the taught material. To
support these, we developed the Middlesex Robotic plaTfOrm (MIRTO), an
open-source platform built using Raspberry Pi, Arduino, HUB-ee wheels and
running Racket (a LISP dialect). In this paper we present the motivations for
our choices and explain how a number of concepts of functional programming may
be employed when programming robotic applications. We present some students'
work with robotics projects: we consider the use of robotics projects to have
been a success, both for their value in reinforcing students' understanding of
programming concepts and for their value in motivating the students.
</dc:description>
 <dc:description>Comment: In Proceedings TFPIE 2015/6, arXiv:1611.08651</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09470</dc:identifier>
 <dc:identifier>EPTCS 230, 2016, pp. 17-29</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.230.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09471</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learn Quantum Mechanics with Haskell</dc:title>
 <dc:creator>Walck, Scott N.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  To learn quantum mechanics, one must become adept in the use of various
mathematical structures that make up the theory; one must also become familiar
with some basic laboratory experiments that the theory is designed to explain.
The laboratory ideas are naturally expressed in one language, and the
theoretical ideas in another. We present a method for learning quantum
mechanics that begins with a laboratory language for the description and
simulation of simple but essential laboratory experiments, so that students can
gain some intuition about the phenomena that a theory of quantum mechanics
needs to explain. Then, in parallel with the introduction of the mathematical
framework on which quantum mechanics is based, we introduce a calculational
language for describing important mathematical objects and operations, allowing
students to do calculations in quantum mechanics, including calculations that
cannot be done by hand. Finally, we ask students to use the calculational
language to implement a simplified version of the laboratory language, bringing
together the theoretical and laboratory ideas.
</dc:description>
 <dc:description>Comment: In Proceedings TFPIE 2015/6, arXiv:1611.08651</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09471</dc:identifier>
 <dc:identifier>EPTCS 230, 2016, pp. 31-46</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.230.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09472</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Bricklayer Ecosystem - Art, Math, and Code</dc:title>
 <dc:creator>Winter, Victor</dc:creator>
 <dc:creator>Love, Betty</dc:creator>
 <dc:creator>Corritore, Cindy</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>D.1.1</dc:subject>
 <dc:subject>I.3.4</dc:subject>
 <dc:subject>J.1</dc:subject>
 <dc:subject>J.5</dc:subject>
 <dc:subject>K.3.2</dc:subject>
 <dc:description>  This paper describes the Bricklayer Ecosystem - a freely-available online
educational ecosystem created for people of all ages and coding backgrounds.
Bricklayer is designed in accordance with a &quot;low-threshold infinite ceiling&quot;
philosophy and has been successfully used to teach coding to primary school
students, middle school students, university freshmen, and in-service secondary
math teachers. Bricklayer programs are written in the functional programming
language SML and, when executed, create 2D and 3D artifacts. These artifacts
can be viewed using a variety of third-party tools such as LEGO Digital
Designer (LDD), LDraw, Minecraft clients, Brickr, as well as STereoLithography
viewers.
</dc:description>
 <dc:description>Comment: In Proceedings TFPIE 2015/6, arXiv:1611.08651</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09472</dc:identifier>
 <dc:identifier>EPTCS 230, 2016, pp. 47-61</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.230.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09473</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proust: A Nano Proof Assistant</dc:title>
 <dc:creator>Ragde, Prabhakar</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Proust is a small Racket program offering rudimentary interactive assistance
in the development of verified proofs for propositional and predicate logic. It
is constructed in stages, some of which are done by students before using it to
complete proof exercises, and in parallel with the study of its theoretical
underpinnings, including elements of Martin-Lof type theory. The goal is
twofold: to demystify some of the machinery behind full-featured proof
assistants such as Coq and Agda, and to better integrate the study of formal
logic with other core elements of an undergraduate computer science curriculum.
</dc:description>
 <dc:description>Comment: In Proceedings TFPIE 2015/6, arXiv:1611.08651</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09473</dc:identifier>
 <dc:identifier>EPTCS 230, 2016, pp. 63-75</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.230.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09474</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximizing Non-Monotone DR-Submodular Functions with Cardinality
  Constraints</dc:title>
 <dc:creator>Khodabakhsh, Ali</dc:creator>
 <dc:creator>Nikolova, Evdokia</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We consider the problem of maximizing a non-monotone DR-submodular function
subject to a cardinality constraint. Diminishing returns (DR) submodularity is
a generalization of the diminishing returns property for functions defined over
the integer lattice. This generalization can be used to solve many machine
learning or combinatorial optimization problems such as optimal budget
allocation, revenue maximization, etc. In this work we propose the first
polynomial-time approximation algorithms for non-monotone constrained
maximization. We implement our algorithms for a revenue maximization problem
with a real-world dataset to check their efficiency and performance.
</dc:description>
 <dc:description>Comment: Error description: The proposed algorithms have running time issues,
  in particular they are pseudo-polynomial and not fully polynomial-time</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09475</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domain-Specific Languages of Mathematics: Presenting Mathematical
  Analysis Using Functional Programming</dc:title>
 <dc:creator>Ionescu, Cezar</dc:creator>
 <dc:creator>Jansson, Patrik</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present the approach underlying a course on &quot;Domain-Specific Languages of
Mathematics&quot;, currently being developed at Chalmers in response to difficulties
faced by third-year students in learning and applying classical mathematics
(mainly real and complex analysis). The main idea is to encourage the students
to approach mathematical domains from a functional programming perspective: to
identify the main functions and types involved and, when necessary, to
introduce new abstractions; to give calculational proofs; to pay attention to
the syntax of the mathematical expressions; and, finally, to organise the
resulting functions and types in domain-specific languages.
</dc:description>
 <dc:description>Comment: In Proceedings TFPIE 2015/6, arXiv:1611.08651</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09475</dc:identifier>
 <dc:identifier>EPTCS 230, 2016, pp. 1-15</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.230.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09480</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wearable Assistive Devices for the Blind</dc:title>
 <dc:creator>Velazquez, Ramiro</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Assistive devices are a key aspect in wearable systems for biomedical
applications, as they represent potential aids for people with physical and
sensory disabilities that might lead to improvements in the quality of life.
This chapter focuses on wearable assistive devices for the blind. It intends to
review the most significant work done in this area, to present the latest
approaches for assisting this population and to understand universal design
concepts for the development of wearable assistive devices and systems for the
blind.
</dc:description>
 <dc:description>Comment: Book Chapter</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09480</dc:identifier>
 <dc:identifier>LNEE 75, Springer, pp 331-349, 2010</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-642-15687-8_17</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09482</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Wavenet Generation Algorithm</dc:title>
 <dc:creator>Paine, Tom Le</dc:creator>
 <dc:creator>Khorrami, Pooya</dc:creator>
 <dc:creator>Chang, Shiyu</dc:creator>
 <dc:creator>Zhang, Yang</dc:creator>
 <dc:creator>Ramachandran, Prajit</dc:creator>
 <dc:creator>Hasegawa-Johnson, Mark A.</dc:creator>
 <dc:creator>Huang, Thomas S.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents an efficient implementation of the Wavenet generation
process called Fast Wavenet. Compared to a naive implementation that has
complexity O(2^L) (L denotes the number of layers in the network), our proposed
approach removes redundant convolution operations by caching previous
calculations, thereby reducing the complexity to O(L) time. Timing experiments
show significant advantages of our fast implementation over a naive one. While
this method is presented for Wavenet, the same scheme can be applied anytime
one wants to perform autoregressive generation or online prediction using a
model with dilated convolution layers. The code for our method is publicly
available.
</dc:description>
 <dc:description>Comment: Technical Report</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09485</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dispersing Points on Intervals</dc:title>
 <dc:creator>Li, Shimin</dc:creator>
 <dc:creator>Wang, Haitao</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We consider a problem of dispersing points on disjoint intervals on a line.
Given n pairwise disjoint intervals sorted on a line, we want to find a point
in each interval such that the minimum pairwise distance of these points is
maximized. Based on a greedy strategy, we present a linear time algorithm for
the problem. Further, we also solve in linear time the cycle version of the
problem where the intervals are given on a cycle.
</dc:description>
 <dc:description>Comment: A preliminary version to appear in ISAAC 2016</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09490</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Shared Control versus Classical Shared Control: Illustrative
  Examples</dc:title>
 <dc:creator>Trautman, Pete</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Shared control fuses operator inputs and autonomy inputs into a single
command. However, if environmental or operator predictions are multimodal,
state of the art approaches are suboptimal with respect to safety, efficiency,
and operator-autonomy agreement: even under mildly challenging conditions,
existing approaches can fuse two safe inputs into an unsafe shared control
[13]. Multi-modal conditions are common to many real world applications, such
as search and rescue robots navigating disaster zones, teleoperated robots
facing communication degradation, and assistive driving technologies. In [11,
13], we introduced a novel approach called generalized shared control (GSC)
that simultaneously optimizes autonomy objectives (e.g., safety and efficiency)
and operator-autonomy agreement under multimodal conditions; this optimality
prevents such unsafe shared control. In this paper, we describe those results
in more user friendly language by using illustrations and text.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-05-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09496</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Graph-based Push Service Platform</dc:title>
 <dc:creator>Guo, Huifeng</dc:creator>
 <dc:creator>Tang, Ruiming</dc:creator>
 <dc:creator>Ye, Yunming</dc:creator>
 <dc:creator>Li, Zhenguo</dc:creator>
 <dc:creator>He, Xiuqiang</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  It is well known that learning customers' preference and making
recommendations to them from today's information-exploded environment is
critical and non-trivial in an on-line system. There are two different modes of
recommendation systems, namely pull-mode and push-mode. The majority of the
recommendation systems are pull-mode, which recommend items to users only when
and after users enter Application Market. While push-mode works more actively
to enhance or re-build connection between Application Market and users. As one
of the most successful phone manufactures,both the number of users and apps
increase dramatically in Huawei Application Store (also named Hispace Store),
which has approximately 0.3 billion registered users and 1.2 million apps until
2016 and whose number of users is growing with high-speed. For the needs of
real scenario, we establish a Push Service Platform (shortly, PSP) to discover
the target user group automatically from web-scale user operation log data with
an additional small set of labelled apps (usually around 10 apps),in Hispace
Store. As presented in this work,PSP includes distributed storage layer,
application layer and evaluation layer. In the application layer, we design a
practical graph-based algorithm (named A-PARW) for user group discovery, which
is an approximate version of partially absorbing random walk. Based on I mode
of A-PARW, the effectiveness of our system is significantly improved, compared
to the predecessor to presented system, which uses Personalized Pagerank in its
application layer.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09498</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inertial-Based Scale Estimation for Structure from Motion on Mobile
  Devices</dc:title>
 <dc:creator>Mustaniemi, Janne</dc:creator>
 <dc:creator>Kannala, Juho</dc:creator>
 <dc:creator>S&#xe4;rkk&#xe4;, Simo</dc:creator>
 <dc:creator>Matas, Jiri</dc:creator>
 <dc:creator>Heikkil&#xe4;, Janne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Structure from motion algorithms have an inherent limitation that the
reconstruction can only be determined up to the unknown scale factor. Modern
mobile devices are equipped with an inertial measurement unit (IMU), which can
be used for estimating the scale of the reconstruction. We propose a method
that recovers the metric scale given inertial measurements and camera poses. In
the process, we also perform a temporal and spatial alignment of the camera and
the IMU. Therefore, our solution can be easily combined with any existing
visual reconstruction software. The method can cope with noisy camera pose
estimates, typically caused by motion blur or rolling shutter artifacts, via
utilizing a Rauch-Tung-Striebel (RTS) smoother. Furthermore, the scale
estimation is performed in the frequency domain, which provides more robustness
to inaccurate sensor time stamps and noisy IMU samples than the previously used
time domain representation. In contrast to previous methods, our approach has
no parameters that need to be tuned for achieving a good performance. In the
experiments, we show that the algorithm outperforms the state-of-the-art in
both accuracy and convergence speed of the scale estimate. The accuracy of the
scale is around $1\%$ from the ground truth depending on the recording. We also
demonstrate that our method can improve the scale accuracy of the Project
Tango's build-in motion tracking.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09501</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transmit design for MIMO wiretap channel with a malicious jammer</dc:title>
 <dc:creator>Zhang, Duo</dc:creator>
 <dc:creator>Mei, Weidong</dc:creator>
 <dc:creator>Li, Lingxiang</dc:creator>
 <dc:creator>Chen, Zhi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider the transmit design for multi-input multi-output
(MIMO) wiretap channel including a malicious jammer. We first transform the
system model into the traditional three-node wiretap channel by whitening the
interference at the legitimate user. Additionally, the eavesdropper channel
state information (ECSI) may be fully or statistically known, even unknown to
the transmitter. Hence, some strategies are proposed in terms of different
levels of ECSI available to the transmitter in our paper. For the case of
unknown ECSI, a target rate for the legitimate user is first specified. And
then an inverse water-filling algorithm is put forward to find the optimal
power allocation for each information symbol, with a stepwise search being used
to adjust the spatial dimension allocated to artificial noise (AN) such that
the target rate is achievable. As for the case of statistical ECSI, several
simulated channels are randomly generated according to the distribution of
ECSI. We show that the ergodic secrecy capacity can be approximated as the
average secrecy capacity of these simulated channels. Through maximizing this
average secrecy capacity, we can obtain a feasible power and spatial dimension
allocation scheme by using one dimension search. Finally, numerical results
reveal the effectiveness and computational efficiency of our algorithms.
</dc:description>
 <dc:description>Comment: 2015 IEEE 81st Vehicular Technology Conference (VTC Spring)</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09501</dc:identifier>
 <dc:identifier>doi:10.1109/VTCSpring.2015.7146141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09502</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Quantization: Encoding Convolutional Activations with Deep
  Generative Model</dc:title>
 <dc:creator>Qiu, Zhaofan</dc:creator>
 <dc:creator>Yao, Ting</dc:creator>
 <dc:creator>Mei, Tao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep convolutional neural networks (CNNs) have proven highly effective for
visual recognition, where learning a universal representation from activations
of convolutional layer plays a fundamental problem. In this paper, we present
Fisher Vector encoding with Variational Auto-Encoder (FV-VAE), a novel deep
architecture that quantizes the local activations of convolutional layer in a
deep generative model, by training them in an end-to-end manner. To incorporate
FV encoding strategy into deep generative models, we introduce Variational
Auto-Encoder model, which steers a variational inference and learning in a
neural network which can be straightforwardly optimized using standard
stochastic gradient method. Different from the FV characterized by conventional
generative models (e.g., Gaussian Mixture Model) which parsimoniously fit a
discrete mixture model to data distribution, the proposed FV-VAE is more
flexible to represent the natural property of data for better generalization.
Extensive experiments are conducted on three public datasets, i.e., UCF101,
ActivityNet, and CUB-200-2011 in the context of video action recognition and
fine-grained image classification, respectively. Superior results are reported
when compared to state-of-the-art representations. Most remarkably, our
proposed FV-VAE achieves to-date the best published accuracy of 94.2% on
UCF101.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09510</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-Based Manifold Frequency Analysis for Denoising</dc:title>
 <dc:creator>Deutsch, Shay</dc:creator>
 <dc:creator>Ortega, Antonio</dc:creator>
 <dc:creator>Medioni, Gerard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new framework for manifold denoising based on processing in the
graph Fourier frequency domain, derived from the spectral decomposition of the
discrete graph Laplacian. Our approach uses the Spectral Graph Wavelet
transform in order to per- form non-iterative denoising directly in the graph
frequency domain, an approach inspired by conventional wavelet-based signal
denoising methods. We theoretically justify our approach, based on the fact
that for smooth manifolds the coordinate information energy is localized in the
low spectral graph wavelet sub-bands, while the noise affects all frequency
bands in a similar way. Experimental results show that our proposed manifold
frequency denoising (MFD) approach significantly outperforms the state of the
art denoising meth- ods, and is robust to a wide range of parameter selections,
e.g., the choice of k nearest neighbor connectivity of the graph.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09511</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Naming the Pain in Requirements Engineering: A Design for a Global
  Family of Surveys and First Results from Germany</dc:title>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:creator>Wagner, S.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  For many years, we have observed industry struggling in defining a high
quality requirements engineering (RE) and researchers trying to understand
industrial expectations and problems. Although we are investigating the
discipline with a plethora of empirical studies, they still do not allow for
empirical generalisations. To lay an empirical and externally valid foundation
about the state of the practice in RE, we aim at a series of open and
reproducible surveys that allow us to steer future research in a problem-driven
manner. We designed a globally distributed family of surveys in joint
collaborations with different researchers and completed the first run in
Germany. The instrument is based on a theory in the form of a set of hypotheses
inferred from our experiences and available studies. We test each hypothesis in
our theory and identify further candidates to extend the theory by correlation
and Grounded Theory analysis. In this article, we report on the design of the
family of surveys, its underlying theory, and the full results obtained from
Germany with participants from 58 companies. The results reveal, for example, a
tendency to improve RE via internally defined qualitative methods rather than
relying on normative approaches like CMMI. We also discovered various RE
problems that are statistically significant in practice. For instance, we could
corroborate communication flaws or moving targets as problems in practice. Our
results are not yet fully representative but already give first insights into
current practices and problems in RE, and they allow us to draw lessons learnt
for future replications. Our results obtained from this first run in Germany
make us confident that the survey design and instrument are well-suited to be
replicated and, thereby, to create a generalisable empirical basis of RE in
practice.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09511</dc:identifier>
 <dc:identifier>Information and Software Technology, 2014</dc:identifier>
 <dc:identifier>doi:10.1016/j.infsof.2014.05.008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09512</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fair Relay Selection Scheme for a DF Cooperative Network With
  Spatially Random Relays</dc:title>
 <dc:creator>Sadeghi, Masoumeh</dc:creator>
 <dc:creator>Rabiei, Amirmasoud</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  A new, fair relay selection scheme is proposed for a dual-hop
decode-and-forward network with randomly-distributed relays. Most of the
reported works in the literature achieve fairness at the expense of degrading
the outage probability performance. In addition, they often assume that the
number and locations of the relays are known. In contrast, the proposed scheme
achieves fairness in a random field of relays without deteriorating the outage
probability performance. In this scheme, each relay maintains a countdown timer
whose initial value is a function of the relay location and a tunable parameter
which controls the level of fairness. The optimum value of this parameter is
evaluated in an offline manner so as to achieve fairness by making the average
powers consumed by the relays as close as possible. An exact analytical
expression is derived for the average power consumed by each relay. This
expression is then used to show the superiority of the proposed scheme over
opportunistic relaying and random relay selection schemes.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09515</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constrained Pure Nash Equilibria in Polymatrix Games</dc:title>
 <dc:creator>Simon, Sunil</dc:creator>
 <dc:creator>Wojtczak, Dominik</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study the problem of checking for the existence of constrained pure Nash
equilibria in a subclass of polymatrix games defined on weighted directed
graphs. The payoff of a player is defined as the sum of nonnegative rational
weights on incoming edges from players who picked the same strategy augmented
by a fixed integer bonus for picking a given strategy. These games capture the
idea of coordination within a local neighbourhood in the absence of globally
common strategies. We study the decision problem of checking whether a given
set of strategy choices for a subset of the players is consistent with some
pure Nash equilibrium or, alternatively, with all pure Nash equilibria. We
identify the most natural tractable cases and show NP or coNP-completness of
these problems already for unweighted DAGs.
</dc:description>
 <dc:description>Comment: Extended version of a paper accepted to AAAI17</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09524</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Audio Pattern Using Convolutional Neural Network From Raw
  Waveforms</dc:title>
 <dc:creator>Qu, Shuhui</dc:creator>
 <dc:creator>Li, Juncheng</dc:creator>
 <dc:creator>Dai, Wei</dc:creator>
 <dc:creator>Das, Samarjit</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  One key step in audio signal processing is to transform the raw signal into
representations that are efficient for encoding the original information.
Traditionally, people transform the audio into spectral representations, as a
function of frequency, amplitude and phase transformation. In this work, we
take a purely data-driven approach to understand the temporal dynamics of audio
at the raw signal level. We maximize the information extracted from the raw
signal through a deep convolutional neural network (CNN) model. Our CNN model
is trained on the urbansound8k dataset. We discover that salient audio patterns
embedded in the raw waveforms can be efficiently extracted through a
combination of nonlinear filters learned by the CNN model.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09526</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Filter Banks Using Deep Learning For Acoustic Signals</dc:title>
 <dc:creator>Qu, Shuhui</dc:creator>
 <dc:creator>Li, Juncheng</dc:creator>
 <dc:creator>Dai, Wei</dc:creator>
 <dc:creator>Das, Samarjit</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Designing appropriate features for acoustic event recognition tasks is an
active field of research. Expressive features should both improve the
performance of the tasks and also be interpret-able. Currently, heuristically
designed features based on the domain knowledge requires tremendous effort in
hand-crafting, while features extracted through deep network are difficult for
human to interpret. In this work, we explore the experience guided learning
method for designing acoustic features. This is a novel hybrid approach
combining both domain knowledge and purely data driven feature designing. Based
on the procedure of log Mel-filter banks, we design a filter bank learning
layer. We concatenate this layer with a convolutional neural network (CNN)
model. After training the network, the weight of the filter bank learning layer
is extracted to facilitate the design of acoustic features. We smooth the
trained weight of the learning layer and re-initialize it in filter bank
learning layer as audio feature extractor. For the environmental sound
recognition task based on the Urban- sound8K dataset, the experience guided
learning leads to a 2% accuracy improvement compared with the fixed feature
extractors (the log Mel-filter bank). The shape of the new filter banks are
visualized and explained to prove the effectiveness of the feature design
process.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09528</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible Scheduling of Distributed Analytic Applications</dc:title>
 <dc:creator>Pace, Francesco</dc:creator>
 <dc:creator>Venzano, Daniele</dc:creator>
 <dc:creator>Carra, Damiano</dc:creator>
 <dc:creator>Michiardi, Pietro</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This work addresses the problem of scheduling user-defined analytic
applications, which we define as high-level compositions of frameworks, their
components, and the logic necessary to carry out work. The key idea in our
application definition, is to distinguish classes of components, including
rigid and elastic types: the first being required for an application to make
progress, the latter contributing to reduced execution times. We show that the
problem of scheduling such applications poses new challenges, which existing
approaches address inefficiently.
  Thus, we present the design and evaluation of a novel, flexible heuristic to
schedule analytic applications, that aims at high system responsiveness, by
allocating resources efficiently. Our algorithm is evaluated using trace-driven
simulations, with large-scale real system traces: our flexible scheduler
outperforms a baseline approach across a variety of metrics, including
application turnaround times, and resource allocation efficiency.
  We also present the design and evaluation of a full-fledged system, which we
have called Zoe, that incorporates the ideas presented in this paper, and
report concrete improvements in terms of efficiency and performance, with
respect to prior generations of our system.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09534</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is a picture worth a thousand words? A Deep Multi-Modal Fusion
  Architecture for Product Classification in e-commerce</dc:title>
 <dc:creator>Zahavy, Tom</dc:creator>
 <dc:creator>Magnani, Alessandro</dc:creator>
 <dc:creator>Krishnan, Abhinandan</dc:creator>
 <dc:creator>Mannor, Shie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Classifying products into categories precisely and efficiently is a major
challenge in modern e-commerce. The high traffic of new products uploaded daily
and the dynamic nature of the categories raise the need for machine learning
models that can reduce the cost and time of human editors. In this paper, we
propose a decision level fusion approach for multi-modal product classification
using text and image inputs. We train input specific state-of-the-art deep
neural networks for each input source, show the potential of forging them
together into a multi-modal architecture and train a novel policy network that
learns to choose between them. Finally, we demonstrate that our multi-modal
network improves the top-1 accuracy % over both networks on a real-world
large-scale product classification dataset that we collected fromWalmart.com.
While we focus on image-text fusion that characterizes e-commerce domains, our
algorithms can be easily applied to other modalities such as audio, video,
physical sensors, etc.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09541</identifier>
 <datestamp>2017-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Complexity of the Word Problem for Automaton Semigroups and
  Automaton Groups</dc:title>
 <dc:creator>D'Angeli, Daniele</dc:creator>
 <dc:creator>Rodaro, Emanuele</dc:creator>
 <dc:creator>W&#xe4;chter, Jan Philipp</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>20E08, 20F10, 20M05, 20M18, 68Q17, 68Q45, 20M30</dc:subject>
 <dc:subject>F.4.m</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  In this paper, we study the word problem for automaton semigroups and
automaton groups from a complexity point of view. As an intermediate concept
between automaton semigroups and automaton groups, we introduce
automaton-inverse semigroups, which are generated by partial, yet invertible
automata. We show that there is an automaton-inverse semigroup and, thus, an
automaton semigroup with a PSPACE-complete word problem. We also show that
there is an automaton group for which the word problem with a single rational
constraint is PSPACE-complete. Additionally, we provide simpler constructions
for the uniform word problems of these classes. For the uniform word problem
for automaton groups (without rational constraints), we show NL-hardness.
Finally, we investigate a question asked by Cain about a better upper bound for
the length of a word on which two distinct elements of an automaton semigroup
must act differently.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09541</dc:identifier>
 <dc:identifier>Advances in Applied Mathematics, Volume 90, September 2017, Pages
  160-187, ISSN 0196-8858</dc:identifier>
 <dc:identifier>doi:10.1016/j.aam.2017.05.008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09559</identifier>
 <datestamp>2017-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lens Distortion Rectification using Triangulation based Interpolation</dc:title>
 <dc:creator>Benligiray, Burak</dc:creator>
 <dc:creator>Topal, Cihan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Nonlinear lens distortion rectification is a common first step in image
processing applications where the assumption of a linear camera model is
essential. For rectifying the lens distortion, forward distortion model needs
to be known. However, many self-calibration methods estimate the inverse
distortion model. In the literature, the inverse of the estimated model is
approximated for image rectification, which introduces additional error to the
system. We propose a novel distortion rectification method that uses the
inverse distortion model directly. The method starts by mapping the distorted
pixels to the rectified image using the inverse distortion model. The resulting
set of points with subpixel locations are triangulated. The pixel values of the
rectified image are linearly interpolated based on this triangulation. The
method is applicable to all camera calibration methods that estimate the
inverse distortion model and performs well across a large range of parameters.
</dc:description>
 <dc:description>Comment: International Symposium on Visual Computing, 2015</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09559</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-27863-6_4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09564</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward a new mobile cloud forensic framework</dc:title>
 <dc:creator>Faheem, Muhammad</dc:creator>
 <dc:creator>Kechadi, M-Tahar</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Smartphones have created a significant impact on the day to day activities of
every individual. Now a days a wide range of Smartphone applications are
available and it necessitates high computing resources in order to build these
applications. Cloud computing offers enormous resources and extends services to
resource-constrained mobile devices. Mobile Cloud Computing is emerging as a
key technology to utilize virtually unlimited resources over the Internet using
Smartphones. Offloading data and computations to improve productivity, enhance
performance, save energy, and improve user experience. Social network
applications largely utilize Mobile Cloud Computing to reap the benefits. The
social network has witnessed unprecedented growth in the recent years, and
millions of registered users access it using Smartphones. The mobile cloud
social network applications introduce not only convenience but also various
issues related to criminal and illegal activities. Despite being primarily used
to communicate and socialize with contacts, the multifarious and anonymous
nature of social networking websites increases susceptibility to cybercrimes.
Taking into account, the advantage of mobile cloud computing and popularity of
social network applications, it is essential to establish a forensic framework
based on mobile cloud platform that solves the problems of today forensic
requirements. In this paper we present a mobile cloud forensic framework that
allows the forensic investigator to collect the automated synchronized copies
of data on both mobile and cloud servers to prove the evidence of cloud usage.
We also show our preliminary results of this study.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09566</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The State of the Art Forensic Techniques in Mobile Cloud Environment: A
  Survey, Challenges and Current Trends</dc:title>
 <dc:creator>Faheem, Muhammad</dc:creator>
 <dc:creator>Kechadi, M-Tahar</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Smartphones have become popular in recent days due to the accessibility of a
wide range of applications. These sophisticated applications demand more
computing resources in a resource constraint smartphone. Cloud computing is the
motivating factor for the progress of these applications. The emerging mobile
cloud computing introduces a new architecture to offload smartphone and utilize
cloud computing technology to solve resource requirements. The popularity of
mobile cloud computing is an opportunity for misuse and unlawful activities.
Therefore, it is a challenging platform for digital forensic investigations due
to the non-availability of methodologies, tools and techniques. The aim of this
work is to analyze the forensic tools and methodologies for crime investigation
in a mobile cloud platform as it poses challenges in proving the evidence. The
advancement of forensic tools and methodologies are much slower than the
current technology development in mobile cloud computing. Thus, forces the
available tools, and techniques become increasingly obsolete. Therefore, it
opens up the door for the new forensic tools and techniques to cope up with
recent developments. Hence, this work presents a detailed survey of forensic
methodology and corresponding issues in a mobile device, cloud environment, and
mobile cloud applications. It mainly focuses on digital forensic issues related
to mobile cloud applications and also analyze the scope, challenges and
opportunities. Finally, this work reviewed the forensic procedures of two cloud
storage services used for mobile cloud applications such as Dropbox and
SkyDrive.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09567</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Moore: Interval Arithmetic in Modern C++</dc:title>
 <dc:creator>Mascarenhas, Walter F.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  We present the library Moore, which implements Interval Arithmetic in modern
C++. This library is based on a new feature in the C++ language called
concepts, which reduces the problems caused by template meta programming, and
leads to a new approach for implementing interval arithmetic libraries in C++.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09569</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Server Structure Proposal and Automatic Verification Technology on IaaS
  Cloud of Plural Type Servers</dc:title>
 <dc:creator>Yamato, Yoji</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper, we propose a server structure proposal and automatic
performance verification technology which proposes and verifies an appropriate
server structure on Infrastructure as a Service (IaaS) cloud with baremetal
servers, container based virtual servers and virtual machines. Recently, cloud
services have been progressed and providers provide not only virtual machines
but also baremetal servers and container based virtual servers. However, users
need to design an appropriate server structure for their requirements based on
3 types quantitative performances and users need much technical knowledge to
optimize their system performances. Therefore, we study a technology which
satisfies users' performance requirements on these 3 types IaaS cloud. Firstly,
we measure performances of a baremetal server, Docker containers, KVM (Kernel
based Virtual Machine) virtual machines on OpenStack with virtual server number
changing. Secondly, we propose a server structure proposal technology based on
the measured quantitative data. A server structure proposal technology receives
an abstract template of OpenStack Heat and function/performance requirements
and then creates a concrete template with server specification information.
Thirdly, we propose an automatic performance verification technology which
executes necessary performance tests automatically on provisioned user
environments according to the template.
</dc:description>
 <dc:description>Comment: 13 pages, 9 figures, International Conference on Internet Studies
  (NETs2015), July 2015</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09569</dc:identifier>
 <dc:identifier>International Conference on Internet Studies (NETs2015), July 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09570</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proposal of Optimum Application Deployment Technology for Heterogeneous
  IaaS Cloud</dc:title>
 <dc:creator>Yamato, Yoji</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Recently, cloud systems composed of heterogeneous hardware have been
increased to utilize progressed hardware power. However, to program
applications for heterogeneous hardware to achieve high performance needs much
technical skill and is difficult for users. Therefore, to achieve high
performance easily, this paper proposes a PaaS which analyzes application
logics and offloads computations to GPU and FPGA automatically when users
deploy applications to clouds.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure, 2016 6th International Workshop on Computer
  Science and Engineering (WCSE 2016), June 2016</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09570</dc:identifier>
 <dc:identifier>2016 6th International Workshop on Computer Science and
  Engineering (WCSE 2016), pp.34-37, June 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09571</identifier>
 <datestamp>2017-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Human Eye Fixations via an LSTM-based Saliency Attentive
  Model</dc:title>
 <dc:creator>Cornia, Marcella</dc:creator>
 <dc:creator>Baraldi, Lorenzo</dc:creator>
 <dc:creator>Serra, Giuseppe</dc:creator>
 <dc:creator>Cucchiara, Rita</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Data-driven saliency has recently gained a lot of attention thanks to the use
of Convolutional Neural Networks for predicting gaze fixations. In this paper
we go beyond standard approaches to saliency prediction, in which gaze maps are
computed with a feed-forward network, and we present a novel model which can
predict accurate saliency maps by incorporating neural attentive mechanisms.
The core of our solution is a Convolutional LSTM that focuses on the most
salient regions of the input image to iteratively refine the predicted saliency
map. Additionally, to tackle the center bias present in human eye fixations,
our model can learn a set of prior maps generated with Gaussian functions. We
show, through an extensive evaluation, that the proposed architecture overcomes
the current state of the art on two public saliency prediction datasets. We
further study the contribution of each key components to demonstrate their
robustness on different scenarios.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09572</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Occlusion-Aware Video Deblurring with a New Layered Blur Model</dc:title>
 <dc:creator>Ahn, Byeongjoo</dc:creator>
 <dc:creator>Kim, Tae Hyun</dc:creator>
 <dc:creator>Kim, Wonsik</dc:creator>
 <dc:creator>Lee, Kyoung Mu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a deblurring method for scenes with occluding objects using a
carefully designed layered blur model. Layered blur model is frequently used in
the motion deblurring problem to handle locally varying blurs, which is caused
by object motions or depth variations in a scene. However, conventional models
have a limitation in representing the layer interactions occurring at occlusion
boundaries. In this paper, we address this limitation in both theoretical and
experimental ways, and propose a new layered blur model reflecting actual blur
generation process. Based on this model, we develop an occlusion-aware
deblurring method that can estimate not only the clear foreground and
background, but also the object motion more accurately. We also provide a novel
analysis on the blur kernel at object boundaries, which shows the distinctive
characteristics of the blur kernel that cannot be captured by conventional blur
models. Experimental results on synthetic and real blurred videos demonstrate
that the proposed method yields superior results, especially at object
boundaries.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09573</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Concept Hierarchies through Probabilistic Topic Modeling</dc:title>
 <dc:creator>Anoop, V. S.</dc:creator>
 <dc:creator>Asharaf, S.</dc:creator>
 <dc:creator>Deepak, P.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  With the advent of semantic web, various tools and techniques have been
introduced for presenting and organizing knowledge. Concept hierarchies are one
such technique which gained significant attention due to its usefulness in
creating domain ontologies that are considered as an integral part of semantic
web. Automated concept hierarchy learning algorithms focus on extracting
relevant concepts from unstructured text corpus and connect them together by
identifying some potential relations exist between them. In this paper, we
propose a novel approach for identifying relevant concepts from plain text and
then learns hierarchy of concepts by exploiting subsumption relation between
them. To start with, we model topics using a probabilistic topic model and then
make use of some lightweight linguistic process to extract semantically rich
concepts. Then we connect concepts by identifying an &quot;is-a&quot; relationship
between pair of concepts. The proposed method is completely unsupervised and
there is no need for a domain specific training corpus for concept extraction
and learning. Experiments on large and real-world text corpora such as BBC News
dataset and Reuters News corpus shows that the proposed method outperforms some
of the existing methods for concept extraction and efficient concept hierarchy
learning is possible if the overall task is guided by a probabilistic topic
modeling algorithm.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09573</dc:identifier>
 <dc:identifier>International Journal of Information Processing (IJIP), Volume 10,
  Issue 3, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09577</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Face-swap Using Convolutional Neural Networks</dc:title>
 <dc:creator>Korshunova, Iryna</dc:creator>
 <dc:creator>Shi, Wenzhe</dc:creator>
 <dc:creator>Dambre, Joni</dc:creator>
 <dc:creator>Theis, Lucas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We consider the problem of face swapping in images, where an input identity
is transformed into a target identity while preserving pose, facial expression,
and lighting. To perform this mapping, we use convolutional neural networks
trained to capture the appearance of the target identity from an unstructured
collection of his/her photographs.This approach is enabled by framing the face
swapping problem in terms of style transfer, where the goal is to render an
image in the style of another one. Building on recent advances in this area, we
devise a new loss function that enables the network to produce highly
photorealistic results. By combining neural networks with simple pre- and
post-processing steps, we aim at making face swap work in real-time with no
input from the user.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09580</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Large-scale Distributed Video Parsing and Evaluation Platform</dc:title>
 <dc:creator>Yu, Kai</dc:creator>
 <dc:creator>Zhou, Yang</dc:creator>
 <dc:creator>Li, Da</dc:creator>
 <dc:creator>Zhang, Zhang</dc:creator>
 <dc:creator>Huang, Kaiqi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual surveillance systems have become one of the largest data sources of
Big Visual Data in real world. However, existing systems for video analysis
still lack the ability to handle the problems of scalability, expansibility and
error-prone, though great advances have been achieved in a number of visual
recognition tasks and surveillance applications, e.g., pedestrian/vehicle
detection, people/vehicle counting. Moreover, few algorithms explore the
specific values/characteristics in large-scale surveillance videos. To address
these problems in large-scale video analysis, we develop a scalable video
parsing and evaluation platform through combining some advanced techniques for
Big Data processing, including Spark Streaming, Kafka and Hadoop Distributed
Filesystem (HDFS). Also, a Web User Interface is designed in the system, to
collect users' degrees of satisfaction on the recognition tasks so as to
evaluate the performance of the whole system. Furthermore, the highly
extensible platform running on the long-term surveillance videos makes it
possible to develop more intelligent incremental algorithms to enhance the
performance of various visual recognition tasks.
</dc:description>
 <dc:description>Comment: Accepted by Chinese Conference on Intelligent Visual Surveillance
  2016</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09587</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Surveillance Video Parsing with Single Frame Supervision</dc:title>
 <dc:creator>Liu, Si</dc:creator>
 <dc:creator>Wang, Changhu</dc:creator>
 <dc:creator>Qian, Ruihe</dc:creator>
 <dc:creator>Yu, Han</dc:creator>
 <dc:creator>Bao, Renda</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Surveillance video parsing, which segments the video frames into several
labels, e.g., face, pants, left-leg, has wide applications.
However,pixel-wisely annotating all frames is tedious and inefficient. In this
paper, we develop a Single frame Video Parsing (SVP) method which requires only
one labeled frame per video in training stage. To parse one particular frame,
the video segment preceding the frame is jointly considered. SVP (1) roughly
parses the frames within the video segment, (2) estimates the optical flow
between frames and (3) fuses the rough parsing results warped by optical flow
to produce the refined parsing result. The three components of SVP, namely
frame parsing, optical flow estimation and temporal fusion are integrated in an
end-to-end manner. Experimental results on two surveillance video datasets show
the superiority of SVP over state-of-the-arts.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09590</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implicant based parallel all solution solver for Boolean satisfiability</dc:title>
 <dc:creator>Sule, Virendra</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03G05, 06E30, 94C10</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2</dc:subject>
 <dc:description>  This paper develops a parallel computational solver for computing all
satifying assignments of a Boolean system of equations defined by Boolean
functions of several variables. While there are we known solvers for
satisfiability of Boolean formulas in CNF form, these are designed primarily
for deciding satisfiability of the formula and do not address the problem of
finding all satisfying solutions. Moreover development of parallel solvers for
satisfiability problems is still an unfinished problem of Computer Science. The
solver proposed in this paper is aimed at representing all solutions of Boolean
formulas even without the CNF form with a parallel algorithm. Algorithm
proposed is applied to Boolean functions in algebraic normal form (ANF). The
algorithm is based on the idea to represent the satisfying assignments in terms
of a complete set of implicants of the Boolean functions appearing as factors
of a Boolean formula. The algorithm is effective mainly in the case when the
factors of the formula are sparse (i.e. have a small fraction of the total
number of variables). This allows small computation of a complete set of
implicants of individual factors one at a time and reduce the formula at each
step. An algorithm is also proposed for finding a complete set of orthogonal
implicants of functions in ANF. An advantages of this algorithm is that all
solutions can be represented compactly in terms of implicants. Finally due to
small and distributed computation at every step as well as computation in terms
of independent threads, the solver proposed in this paper is expected to be
useful for developing heuristics for a well scalable parallel solver for large
size problems of Boolean satisfiability over large number of processors.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09606</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Inductive Proof Method for Simulation-based Compiler Correctness</dc:title>
 <dc:creator>Schneider, Sigurd</dc:creator>
 <dc:creator>Smolka, Gert</dc:creator>
 <dc:creator>Hack, Sebastian</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We study induction on the program structure as a proof method for
bisimulation-based compiler correctness. We consider a first-order language
with mutually recursive function definitions, system calls, and an environment
semantics. The proof method relies on a generalization of compatibility of
function definition with the bisimulation. We use the inductive method to show
correctness of a form of dead code elimination. This is an interesting case
study because the transformation removes function, variable, and parameter
definitions from the program. While such transformations require modification
of the simulation in a coinductive proof, the inductive method deals with them
naturally. All our results are formalized in Coq.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09613</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on the Ratio of Revenues Between Selling in a Bundle and
  Separately</dc:title>
 <dc:creator>Kupfer, Ron</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider the problem of maximizing revenue when selling k items to a
single buyer with known valuation distributions. We show that for a single,
additive buyer whose valuations for for the items are distributed according to
i.i.d. distributions which are known to the seller, the ratio of revenue from
selling in a bundle to selling separately is at least 55.9% and this gap is
attainable.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09621</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Associative Memory using Dictionary Learning and Expander Decoding</dc:title>
 <dc:creator>Mazumdar, Arya</dc:creator>
 <dc:creator>Rawat, Ankit Singh</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  An associative memory is a framework of content-addressable memory that
stores a collection of message vectors (or a dataset) over a neural network
while enabling a neurally feasible mechanism to recover any message in the
dataset from its noisy version. Designing an associative memory requires
addressing two main tasks: 1) learning phase: given a dataset, learn a concise
representation of the dataset in the form of a graphical model (or a neural
network), 2) recall phase: given a noisy version of a message vector from the
dataset, output the correct message vector via a neurally feasible algorithm
over the network learnt during the learning phase. This paper studies the
problem of designing a class of neural associative memories which learns a
network representation for a large dataset that ensures correction against a
large number of adversarial errors during the recall phase. Specifically, the
associative memories designed in this paper can store dataset containing
$\exp(n)$ $n$-length message vectors over a network with $O(n)$ nodes and can
tolerate $\Omega(\frac{n}{{\rm polylog} n})$ adversarial errors. This paper
carries out this memory design by mapping the learning phase and recall phase
to the tasks of dictionary learning with a square dictionary and iterative
error correction in an expander code, respectively.
</dc:description>
 <dc:description>Comment: To appear in AAAI 2017</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09621</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09623</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noise and Disturbance Compensation Approach for Linear Time-Invariant
  Plants</dc:title>
 <dc:creator>Furtat, Igor B.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>93C73 (Primary), 93D09 (Secondary)</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  The algorithm with compensation of parametric uncertainties, external
disturbances and measurement noises for linear time-invariant plants is
designed. It is assumed, that the dimension of the noise can be equaled to the
state vector dimension and the disturbance can be presented in any equation of
the plant model. Analytical condition for algorithm feasibility is proposed.
Simulation results show the efficiency of the proposed algorithm.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09626</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Environmental Bisimulations for Delimited-Control Operators with Dynamic
  Prompt Generation</dc:title>
 <dc:creator>Aristiz&#xe1;bal, Andr&#xe9;s</dc:creator>
 <dc:creator>Biernacki, Dariusz</dc:creator>
 <dc:creator>Lenglet, Sergue&#xef;</dc:creator>
 <dc:creator>Polesiuk, Piotr</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present sound and complete environmental bisimilarities for a variant of
Dybvig et al.'s calculus of multi-prompted delimited-control operators with
dynamic prompt generation. The reasoning principles that we obtain generalize
and advance the existing techniques for establishing program equivalence in
calculi with single-prompted delimited control. The basic theory that we
develop is presented using Madiot et al.'s framework that allows for smooth
integration and composition of up-to techniques facilitating bisimulation
proofs. We also generalize the framework in order to express environmental
bisimulations that support equivalence proofs of evaluation contexts
representing continuations. This change leads to a novel and powerful up-to
technique enhancing bisimulation proofs in the presence of control operators.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09626</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 3 (September
  19, 2017) lmcs:3942</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-13(3:27)2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09630</identifier>
 <datestamp>2017-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Variational Auto-Encoders using Householder Flow</dc:title>
 <dc:creator>Tomczak, Jakub M.</dc:creator>
 <dc:creator>Welling, Max</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Variational auto-encoders (VAE) are scalable and powerful generative models.
However, the choice of the variational posterior determines tractability and
flexibility of the VAE. Commonly, latent variables are modeled using the normal
distribution with a diagonal covariance matrix. This results in computational
efficiency but typically it is not flexible enough to match the true posterior
distribution. One fashion of enriching the variational posterior distribution
is application of normalizing flows, i.e., a series of invertible
transformations to latent variables with a simple posterior. In this paper, we
follow this line of thinking and propose a volume-preserving flow that uses a
series of Householder transformations. We show empirically on MNIST dataset and
histopathology data that the proposed flow allows to obtain more flexible
variational posterior and competitive results comparing to other normalizing
flows.
</dc:description>
 <dc:description>Comment: A corrected version of the paper submitted to Bayesian Deep Learning
  Workshop (NIPS 2016)</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09633</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Languages, Formally and Coinductively</dc:title>
 <dc:creator>Traytel, Dmitriy</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Traditionally, formal languages are defined as sets of words. More recently,
the alternative coalgebraic or coinductive representation as infinite tries,
i.e., prefix trees branching over the alphabet, has been used to obtain compact
and elegant proofs of classic results in language theory. In this article, we
study this representation in the Isabelle proof assistant. We define regular
operations on infinite tries and prove the axioms of Kleene algebra for those
operations. Thereby, we exercise corecursion and coinduction and confirm the
coinductive view being profitable in formalizations, as it improves over the
set-of-words view with respect to proof automation.
</dc:description>
 <dc:description>Comment: Extended version of homonymous FSCD 2016 paper</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09633</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 3 (September
  19, 2017) lmcs:3943</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-13(3:28)2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09646</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to overcome the Courant-Friedrichs-Lewy condition of explicit
  discretizations?</dc:title>
 <dc:creator>Dutykh, Denys</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  This manuscript contains some thoughts on the discretization of the classical
heat equation. Namely, we discuss the advantages and disadvantages of explicit
and implicit schemes. Then, we show how to overcome some disadvantages while
preserving some advantages. However, since there is no free lunch, there is a
price to pay for any improvement in the numerical scheme. This price will be
thoroughly discussed below.In particular, we like explicit discretizations for
the ease of their implementation even for nonlinear problems. Unfortunately,
when these schemes are applied to parabolic equations, severe stability limits
appear for the time step magnitude making the explicit simulations
prohibitively expensive. Implicit schemes remove the stability limit, but each
time step requires now the solution of linear (at best) or even nonlinear
systems of equations. However, there exists a number of tricks to overcome (or
at least to relax) severe stability limitations of explicit schemes without
going into the trouble of fully implicit ones. The purpose of this manuscript
is just to inform the readers about these alternative techniques to extend the
stability limits. It was not written for classical scientific publication
purposes.
</dc:description>
 <dc:description>Comment: 21 pages, 7 figures, 8 references. Other author's papers can be found
  at http://www.denys-dutykh.com/</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09663</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum Weight Stable Set in ($P_7$, bull)-free graphs and ($S_{1,2,3}$,
  bull)-free graphs</dc:title>
 <dc:creator>Maffray, Fr&#xe9;d&#xe9;ric</dc:creator>
 <dc:creator>Pastor, Lucas</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We give a polynomial time algorithm that finds the maximum weight stable set
in a graph that does not contain an induced path on seven vertices or a bull
(the graph with vertices $a$, $b$, $c$, $d$, $e$ and edges $ab$, $bc$, $cd$,
$be$, $ce$). With the same arguments with also give a polynomial algorithm for
any graph that does not contain $S_{1,2,3}$ or a bull.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09664</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing run-length algorithm using octonary repetition tree</dc:title>
 <dc:creator>Haghighi, Kaveh Geyratmand</dc:creator>
 <dc:creator>Mirnia, Mirkamal</dc:creator>
 <dc:creator>Navin, Ahmad Habibizad</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Compression is beneficial because it helps detract resource usage. It reduces
data storage space as well as transmission traffic and improves web pages
loading. Run-length coding (RLC) is a lossless data compression algorithm. Data
are stored as a data value and counts. This is useful on data that contains
many consecutive runs. This paper proposes a compression algorithm using
octonary repetition tree (ORT), based on RLC. ORT is used to overcome the
duplication problem in primary RLC algorithms, instead of using flag or
codeword. It's the first method of run-length encoding which has the
compression ratio greater than one in all tested cases. Experimental results,
show average improvement of roughly 3 times, 3 times and 2 times in compression
ratio field of study comparing to PRLC1, PRLC2, DF-RLC respectively. By using
this approach of run-length encoding we can compress wider types of data, such
as multimedia, document, executive files, etc.
</dc:description>
 <dc:description>Comment: 7pages</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09664</dc:identifier>
 <dc:identifier>International Journal of Computer Science and Information Security
  (IJCSIS) Vol. 14, No. 8, August 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09666</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generic and Efficient Solution Solves the Shortest Paths Problem in
  Square Runtime</dc:title>
 <dc:creator>Tan, Yong</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>68T20, 68U35, 90B20, 90B40</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>H.4.2</dc:subject>
 <dc:description>  We study a group of new methods to solve an open problem that is the shortest
paths problem on a given fix-weighted instance. It is the real significance at
a considerable altitude to reach our aim to meet these qualities of generic,
efficiency, precision which we generally require to a methodology. Besides our
proof to guarantee our measures might work normally, we pay more interest to
root out the vital theory about calculation and logic in favor of our extension
to range over a wide field about decision, operator, economy, management,
robot, AI and etc.
</dc:description>
 <dc:description>Comment: 26 pages, 11,100 words, 2 pictures</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09671</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sub 100nW volatile nano-metal-oxide memristor as synaptic-like encoder
  of neuronal spikes</dc:title>
 <dc:creator>Gupta, Isha</dc:creator>
 <dc:creator>Serb, Alexantrou</dc:creator>
 <dc:creator>Khiat, Ali</dc:creator>
 <dc:creator>Zeitler, Ralf</dc:creator>
 <dc:creator>Vassanelli, Stefano</dc:creator>
 <dc:creator>Prodromakis, Themistoklis</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Advanced neural interfaces mediate a bio-electronic link between the nervous
system and microelectronic devices, bearing great potential as innovative
therapy for various diseases. Spikes from a large number of neurons are
recorded leading to creation of big data that require on-line processing under
most stringent conditions, such as minimal power dissipation and on-chip space
occupancy. Here, we present a new concept where the inherent volatile
properties of a nano-scale memristive device are used to detect and compress
information on neural spikes as recorded by a multi-electrode array.
Simultaneously, and similarly to a biological synapse, information on spike
amplitude and frequency is transduced in metastable resistive state transitions
of the device, which is inherently capable of self-resetting and of continuous
encoding of spiking activity. Furthermore, operating the memristor in a very
high resistive state range reduces its average in-operando power dissipation to
less than 100 nW, demonstrating the potential to build highly scalable, yet
energy-efficient on-node processors for advanced neural interfaces.
</dc:description>
 <dc:description>Comment: 15 pages main article, 15 pages supplementary information, 2 pages
  supplementary notes</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09671</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09691</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Partitioning View of Mining Big Data</dc:title>
 <dc:creator>Zhang, Shichao</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  There are two main approximations of mining big data in memory. One is to
partition a big dataset to several subsets, so as to mine each subset in
memory. By this way, global patterns can be obtained by synthesizing all local
patterns discovered from these subsets. Another is the statistical sampling
method. This indicates that data partitioning should be an important strategy
for mining big data. This paper recalls our work on mining big data with a data
partitioning and shows some interesting findings among the local patterns
discovered from subsets of a dataset.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09701</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computationally Efficient Unscented Kalman Filtering Techniques for
  Launch Vehicle Navigation using a Space-borne GPS Receiver</dc:title>
 <dc:creator>Biswas, Sanat</dc:creator>
 <dc:creator>Qiao, Li</dc:creator>
 <dc:creator>Dempster, Andrew</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The Extended Kalman Filter (EKF) is a well established technique for position
and velocity estimation. However, the performance of the EKF degrades
considerably in highly non-linear system applications as it requires local
linearisation in its prediction stage. The Unscented Kalman Filter (UKF) was
developed to address the non-linearity in the system by deterministic sampling.
The UKF provides better estimation accuracy than the EKF for highly non-linear
systems. However, the UKF requires multiple propagations of sampled state
vectors in the measurement interval, which results in higher processing time
than for the EKF. This paper proposes an application of two newly developed UKF
variants in launch vehicle navigation. These two algorithms called the Single
Propagation Unscented Kalman Filter (SPUKF) and the Extrapolated Single
Propagation Unscented Kalman Filter (ESPUKF), reduce the processing time of the
original UKF significantly and provide estimation accuracies comparable to the
UKF. The estimation performance of the SPUKF and the ESPUKF is demonstrated
using Falcon 9 V1.1 launch vehicle in CRS-5 mission scenario. The launch
vehicle trajectory for the mission is generated using publicly available
mission parameters. A SPIRENT GNSS simulator is used to generate the received
GPS signal on the trajectory. Pseudo-range observations are used in the EKF,
UKF, SPUKF and the ESPUKF separately and the estimation accuracies are
compared. The results show that the estimation errors of the SPUKF and the
ESPUKF are 15.44% and 10.52% higher than the UKF respectively. The processing
time reduces by 83% for the SPUKF and 69.14% for the ESPUKF compared to the
UKF.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09701</dc:identifier>
 <dc:identifier>Proc. ION GNSS+ 2016, Institute of Navigation, Portland, Oregon,
  USA, September 14, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09702</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Position and Velocity estimation of Re-entry Vehicles using Fast
  Unscented Kalman Filters</dc:title>
 <dc:creator>Biswas, Sanat</dc:creator>
 <dc:creator>Qiao, Li</dc:creator>
 <dc:creator>Dempster, Andrew</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Application of two new UKF based estimation techniques with reduced
processing time in re-entry vehicle position and velocity estimation problem
using ground-based range and elevation measurements is presented. The first
method is called the Single Propagation Unscented Kalman Filter (SPUKF) where,
the a postiriori state is propagated only once and then the sampled sigma
points at the next time state are approximated by the first-order Taylor Series
terms. In the second method called the Extrapolated Single Propagation
Unscented Kalman Filter (ESPUKF), the sigma points are approximated to the
second-order Taylor Series terms using the Richardson Extrapolation. The EKF,
SPUKF, ESPUKF and the UKF are utilized in a re-entry vehicle navigation
scenario using range and elevation measurements. The estimation accuracies and
the processing times for different algorithms are compared for the scenario.
The result demonstrates that the UKF provides better accuracy than the EKF but
requires more processing time. The SPUKF accuracy is better than the EKF and
the processing time is significantly less than the UKF. However, the accuracy
of the SPUKF is less than the UKF. The ESPUKF provides estimation accuracy
comparable to the UKF and the processing time is also significantly reduced.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09702</dc:identifier>
 <dc:identifier>Proc. 16th Australian Space Research Conference, Melbourne,
  Australia, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09703</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Parsing of Mathematics by Context-based Learning from Aligned
  Corpora and Theorem Proving</dc:title>
 <dc:creator>Kaliszyk, Cezary</dc:creator>
 <dc:creator>Urban, Josef</dc:creator>
 <dc:creator>Vysko&#x10d;il, Ji&#x159;&#xed;</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We study methods for automated parsing of informal mathematical expressions
into formal ones, a main prerequisite for deep computer understanding of
informal mathematical texts. We propose a context-based parsing approach that
combines efficient statistical learning of deep parse trees with their semantic
pruning by type checking and large-theory automated theorem proving. We show
that the methods very significantly improve on previous results in parsing
theorems from the Flyspeck corpus.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09714</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CoMET: Composite-Input Magnetoelectric-based Logic Technology</dc:title>
 <dc:creator>Mankalale, Meghna G.</dc:creator>
 <dc:creator>Liang, Zhaoxin</dc:creator>
 <dc:creator>Zhao, Zhengyang</dc:creator>
 <dc:creator>Kim, Chris</dc:creator>
 <dc:creator>Wang, Jian-Ping</dc:creator>
 <dc:creator>Sapatnekar, Sachin S.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:description>  This work proposes CoMET, a fast and energy-efficient spintronics device for
logic applications. An input voltage is applied to a ferroelectric (FE)
material, in contact with a composite structure - a ferromagnet (FM) with
in-plane magnetic anisotropy (IMA) placed on top of an intra-gate FM
interconnect with perpendicular magnetic anisotropy (PMA). Through the
magnetoelectric (ME) effect, the input voltage nucleates a domain wall (DW) at
the input end of the PMA-FM interconnect. An applied current then rapidly
propagates the DW towards the output FE structure, where the inverse-ME effect
generates an output voltage. This voltage is propagated to the input of the
next CoMET device using a novel circuit structure that enables efficient device
cascading. The material parameters for CoMET are optimized by systematically
exploring the impact of parameter choices on device performance. Simulations on
a 7nm CoMET device show fast, low-energy operation, with a delay/energy of
98ps/68aJ for INV and 135ps/85aJ for MAJ3.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09718</identifier>
 <datestamp>2017-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Linear Programming for Dense CRFs</dc:title>
 <dc:creator>Ajanthan, Thalaiyasingam</dc:creator>
 <dc:creator>Desmaison, Alban</dc:creator>
 <dc:creator>Bunel, Rudy</dc:creator>
 <dc:creator>Salzmann, Mathieu</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:creator>Kumar, M. Pawan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>I.4.6</dc:subject>
 <dc:description>  The fully connected conditional random field (CRF) with Gaussian pairwise
potentials has proven popular and effective for multi-class semantic
segmentation. While the energy of a dense CRF can be minimized accurately using
a linear programming (LP) relaxation, the state-of-the-art algorithm is too
slow to be useful in practice. To alleviate this deficiency, we introduce an
efficient LP minimization algorithm for dense CRFs. To this end, we develop a
proximal minimization framework, where the dual of each proximal problem is
optimized via block coordinate descent. We show that each block of variables
can be efficiently optimized. Specifically, for one block, the problem
decomposes into significantly smaller subproblems, each of which is defined
over a single pixel. For the other block, the problem is optimized via
conditional gradient descent. This has two advantages: 1) the conditional
gradient can be computed in a time linear in the number of pixels and labels;
and 2) the optimal step size can be computed analytically. Our experiments on
standard datasets provide compelling evidence that our approach outperforms all
existing baselines including the previous LP based approach for dense CRFs.
</dc:description>
 <dc:description>Comment: 24 pages, 10 figures and 4 tables</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09726</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gossip training for deep learning</dc:title>
 <dc:creator>Blot, Michael</dc:creator>
 <dc:creator>Picard, David</dc:creator>
 <dc:creator>Cord, Matthieu</dc:creator>
 <dc:creator>Thome, Nicolas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We address the issue of speeding up the training of convolutional networks.
Here we study a distributed method adapted to stochastic gradient descent
(SGD). The parallel optimization setup uses several threads, each applying
individual gradient descents on a local variable. We propose a new way to share
information between different threads inspired by gossip algorithms and showing
good consensus convergence properties. Our method called GoSGD has the
advantage to be fully asynchronous and decentralized. We compared our method to
the recent EASGD in \cite{elastic} on CIFAR-10 show encouraging results.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09733</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Getting Closer to the Essence of Music: The Con Espressione Manifesto</dc:title>
 <dc:creator>Widmer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This text offers a personal and very subjective view on the current situation
of Music Information Research (MIR). Motivated by the desire to build systems
with a somewhat deeper understanding of music than the ones we currently have,
I try to sketch a number of challenges for the next decade of MIR research,
grouped around six simple truths about music that are probably generally agreed
on, but often ignored in everyday research.
</dc:description>
 <dc:description>Comment: Preprint (author's accepted manuscript) of a journal article (see
  &quot;Journal Reference&quot;)</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09733</dc:identifier>
 <dc:identifier>ACM Transactions on Intelligent Systems and Technology (TIST)
  8(2), Article No. 19, November 2016</dc:identifier>
 <dc:identifier>doi:10.1145/2899004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09738</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Rates and post-FEC BER Prediction in Optical Fiber
  Communications</dc:title>
 <dc:creator>Alvarado, Alex</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Information-theoretic metrics to analyze optical fiber communications systems
with binary and nonbinary soft-decision FEC are reviewed. The numerical
evaluation of these metrics in both simulations and experiments is also
discussed. Ready-to-use closed-form approximations are presented.
</dc:description>
 <dc:description>Comment: Invited paper, OFC 2017</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09742</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perturbation-Based Regularization for Signal Estimation in Linear
  Discrete Ill-posed Problems</dc:title>
 <dc:creator>Suliman, Mohamed</dc:creator>
 <dc:creator>Ballal, Tarig</dc:creator>
 <dc:creator>Al-Naffouri, Tareq Y.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Estimating the values of unknown parameters from corrupted measured data
faces a lot of challenges in ill-posed problems. In such problems, many
fundamental estimation methods fail to provide a meaningful stabilized
solution. In this work, we propose a new regularization approach and a new
regularization parameter selection approach for linear least-squares discrete
ill-posed problems. The proposed approach is based on enhancing the
singular-value structure of the ill-posed model matrix to acquire a better
solution. Unlike many other regularization algorithms that seek to minimize the
estimated data error, the proposed approach is developed to minimize the
mean-squared error of the estimator which is the objective in many typical
estimation scenarios. The performance of the proposed approach is demonstrated
by applying it to a large set of real-world discrete ill-posed problems.
Simulation results demonstrate that the proposed approach outperforms a set of
benchmark regularization methods in most cases. In addition, the approach also
enjoys the lowest runtime and offers the highest level of robustness amongst
all the tested benchmark regularization methods.
</dc:description>
 <dc:description>Comment: 13 pages, Journal</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09751</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Effects of Communication Burstiness on Consensus Formation and
  Tipping Points in Social Dynamics</dc:title>
 <dc:creator>Doyle, Casey</dc:creator>
 <dc:creator>Szymanski, Boleslaw</dc:creator>
 <dc:creator>Korniss, Gyorgy</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Current models for opinion dynamics typically utilize a Poisson process for
speaker selection, making the waiting time between events exponentially
distributed. Human interaction tends to be bursty, though, having higher
probabilities of either extremely short waiting times or long periods of
silence. To quantify the burstiness effects on the dynamics of social models,
we place in competition two groups exhibiting different speakers' waiting-time
distributions. These competitions are implemented in the binary Naming Game,
and show that the relevant aspect of the waiting-time distribution is the
density of the head rather than that of the tail. We show that even with
identical mean waiting times, a group with a higher density of short waiting
times is favored in competition over the other group. This effect remains in
the presence of nodes holding a single opinion that never changes, as the
fraction of such committed individuals necessary for achieving consensus
decreases dramatically when they have a higher head density than the holders of
the competing opinion. Finally, to quantify differences in burstiness, we
introduce the expected number of small-time activations and use it to
characterize the early-time regime of the system.
</dc:description>
 <dc:description>Comment: 14 pages, 12 figures</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09751</dc:identifier>
 <dc:identifier>Phys. Rev. E 95, 062303 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.95.062303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09754</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Scenario Aggregation to Approximate Robust Optimization Problems</dc:title>
 <dc:creator>Goerigk, Marc</dc:creator>
 <dc:creator>Chassein, Andr&#xe9;</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  As most robust combinatorial min-max and min-max regret problems with
discrete uncertainty sets are NP-hard, research into approximation algorithm
and approximability bounds has been a fruitful area of recent work. A simple
and well-known approximation algorithm is the midpoint method, where one takes
the average over all scenarios, and solves a problem of nominal type. Despite
its simplicity, this method still gives the best-known bound on a wide range of
problems, such as robust shortest path, or robust assignment problems.
  In this paper we present a simple extension of the midpoint method based on
scenario aggregation, which improves the current best $K$-approximation result
to an $(\varepsilon K)$-approximation for any desired $\varepsilon &gt; 0$. Our
method can be applied to min-max as well as min-max regret problems.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09755</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fractional Order AGC for Distributed Energy Resources Using Robust
  Optimization</dc:title>
 <dc:creator>Pan, Indranil</dc:creator>
 <dc:creator>Das, Saptarshi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The applicability of fractional order (FO) automatic generation control (AGC)
for power system frequency oscillation damping is investigated in this paper,
employing distributed energy generation. The hybrid power system employs
various autonomous generation systems like wind turbine, solar photovoltaic,
diesel engine, fuel-cell and aqua electrolyzer along with other energy storage
devices like the battery and flywheel. The controller is placed in a remote
location while receiving and sending signals over an unreliable communication
network with stochastic delay. The controller parameters are tuned using robust
optimization techniques employing different variants of Particle Swarm
Optimization (PSO) and are compared with the corresponding optimal solutions.
An archival based strategy is used for reducing the number of function
evaluations for the robust optimization methods. The solutions obtained through
the robust optimization are able to handle higher variation in the controller
gains and orders without significant decrease in the system performance. This
is desirable from the FO controller implementation point of view, as the design
is able to accommodate variations in the system parameter which may result due
to the approximation of FO operators, using different realization methods and
order of accuracy. Also a comparison is made between the FO and the integer
order (IO) controllers to highlight the merits and demerits of each scheme.
</dc:description>
 <dc:description>Comment: 12 pages, 16 figures, 5 tables</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09755</dc:identifier>
 <dc:identifier>IEEE Transactions on Smart Grid, Volume 7, Issue 5, Pages 2175 -
  2186, Sept 2016</dc:identifier>
 <dc:identifier>doi:10.1109/TSG.2015.2459766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09763</identifier>
 <datestamp>2017-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Reputation-Based Contract for Repeated Crowdsensing with Costly
  Verification</dc:title>
 <dc:creator>Dobakhshari, Donya G.</dc:creator>
 <dc:creator>Naghizadeh, Parinaz</dc:creator>
 <dc:creator>Liu, Mingyan</dc:creator>
 <dc:creator>Gupta, Vijay</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study a setup in which a system operator hires a sensor to exert costly
effort to collect accurate measurements of a value of interest over time. At
each time, the sensor is asked to report his observation to the operator, and
is compensated based on the accuracy of this observation. Since both the effort
and observation are private information for the sensor, a naive payment scheme
which compensates the sensor based only on his self-reported values will lead
to both shirking and falsification of outcomes by the sensor. We consider the
problem of designing an appropriate compensation scheme to incentivize the
sensor to at once exert costly effort and truthfully reveal the resulting
observation.
  To this end, we formulate the problem as a repeated game and propose a
compensation scheme that employs stochastic verification by the operator
coupled with a system of assigning reputation to the sensor. In particular, our
proposed payment scheme compensates the sensor based on both the effort in the
current period as well as the history of past behavior. We show that by using
past behavior in determining present payments, the operator can both
incentivize higher effort as well as more frequent truthtelling by the sensor
and decrease the required verification frequency.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09766</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Drift Removal in Plant Electrical Signals via IIR Filtering Using
  Wavelet Energy</dc:title>
 <dc:creator>Das, Saptarshi</dc:creator>
 <dc:creator>Ajiwibawa, Barry Juans</dc:creator>
 <dc:creator>Chatterjee, Shre Kumar</dc:creator>
 <dc:creator>Ghosh, Sanmitra</dc:creator>
 <dc:creator>Maharatna, Koushik</dc:creator>
 <dc:creator>Dasmahapatra, Srinandan</dc:creator>
 <dc:creator>Vitaletti, Andrea</dc:creator>
 <dc:creator>Masi, Elisa</dc:creator>
 <dc:creator>Mancuso, Stefano</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:description>  Plant electrical signals often contains low frequency drifts with or without
the application of external stimuli. Quantification of the randomness in plant
signals in a stimulus-specific way is hindered because the knowledge of vital
frequency information in the actual biological response is not known yet. Here
we design an optimum Infinite Impulse Response (IIR) filter which removes the
low frequency drifts and preserves the frequency spectrum corresponding to the
random component of the unstimulated plant signals by bringing the bias due to
unknown artifacts and drifts to a minimum. We use energy criteria of wavelet
packet transform (WPT) for optimization based tuning of the IIR filter
parameters. Such an optimum filter enforces that the energy distribution of the
pre-stimulus parts in different experiments are almost overlapped but under
different stimuli the distributions of the energy get changed. The reported
research may popularize plant signal processing, as a separate field, besides
other conventional bioelectrical signal processing paradigms.
</dc:description>
 <dc:description>Comment: 12 pages, 9 figures, 1 table</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09766</dc:identifier>
 <dc:identifier>Computers and Electronics in Agriculture, Volume 118, October
  2015, Pages 15-23</dc:identifier>
 <dc:identifier>doi:10.1016/j.compag.2015.08.013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09769</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer Aided Detection of Oral Lesions on CT Images</dc:title>
 <dc:creator>Galib, Shaikat</dc:creator>
 <dc:creator>Islam, Fahima</dc:creator>
 <dc:creator>Abir, Muhammad</dc:creator>
 <dc:creator>Lee, Hyoung-Koo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Oral lesions are important findings on computed tomography (CT) images. In
this study, a fully automatic method to detect oral lesions in mandibular
region from dental CT images is proposed. Two methods were developed to
recognize two types of lesions namely (1) Close border (CB) lesions and (2)
Open border (OB) lesions, which cover most of the lesion types that can be
found on CT images. For the detection of CB lesions, fifteen features were
extracted from each initial lesion candidates and multi layer perceptron (MLP)
neural network was used to classify suspicious regions. Moreover, OB lesions
were detected using a rule based image processing method, where no feature
extraction or classification algorithm were used. The results were validated
using a CT dataset of 52 patients, where 22 patients had abnormalities and 30
patients were normal. Using non-training dataset, CB detection algorithm
yielded 71% sensitivity with 0.31 false positives per patient. Furthermore, OB
detection algorithm achieved 100% sensitivity with 0.13 false positives per
patient. Results suggest that, the proposed framework, which consists of two
methods, has the potential to be used in clinical context, and assist
radiologists for better diagnosis.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09769</dc:identifier>
 <dc:identifier>doi:10.1088/1748-0221-10-12-C12030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09774</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Serving the Grid: an Experimental Study of Server Clusters as Real-Time
  Demand Response Resources</dc:title>
 <dc:creator>McClurg, Josiah</dc:creator>
 <dc:creator>Mudumbai, Raghuraman</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:subject>C.5.5</dc:subject>
 <dc:subject>D.4.8</dc:subject>
 <dc:subject>K.6.2</dc:subject>
 <dc:description>  Demand response is a crucial technology to allow large-scale penetration of
intermittent renewable energy sources in the electric grid. This paper is based
on the thesis that datacenters represent especially attractive candidates for
providing flexible, real-time demand response services to the grid; they are
capable of finely-controllable power consumption, fast power ramp-rates, and
large dynamic range. This paper makes two main contributions: (a) it provides
detailed experimental evidence justifying this thesis, and (b) it presents a
comparative investigation of three candidate software interfaces for power
control within the servers. All of these results are based on a series of
experiments involving real-time power measurements on a lab-scale server
cluster. This cluster was specially instrumented for accurate and fast power
measurements on a time-scale of 100 ms or less. Our results provide preliminary
evidence for the feasibility of large scale demand response using datacenters,
and motivates future work on exploiting this capability.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09774</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09778</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-objective LQR with Optimum Weight Selection to Design FOPID
  Controllers for Delayed Fractional Order Processes</dc:title>
 <dc:creator>Das, Saptarshi</dc:creator>
 <dc:creator>Pan, Indranil</dc:creator>
 <dc:creator>Das, Shantanu</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  An optimal trade-off design for fractional order (FO)-PID controller is
proposed in this paper with a Linear Quadratic Regulator (LQR) based technique
using two conflicting time domain control objectives. The deviation of the
state trajectories and control signal are automatically enforced by the LQR. A
class of delayed FO systems with single non-integer order element has been
controlled here which exhibit both sluggish and oscillatory open loop
responses. The FO time delay processes are controlled within a multi-objective
optimization (MOO) formulation of LQR based FOPID design. The time delays in
the FO models are handled by two analytical formulations of designing optimal
quadratic regulator for delayed systems. A comparison is made between the two
approaches of LQR design for the stabilization of time-delay systems in the
context of FOPID controller tuning. The MOO control design methodology yields
the Pareto optimal trade-off solutions between the tracking performance for
unit set-point change and total variation (TV) of the control signal. Numerical
simulations are provided to compare the merits of the two delay handling
techniques in the multi-objective LQR-FOPID design, while also showing the
capability of load disturbance suppression using these optimal controllers.
Tuning rules are then formed for the optimal LQR-FOPID controller knobs, using
the median of the non-dominated Pareto solution to handle delays FO processes.
</dc:description>
 <dc:description>Comment: 29 pages, 9 figures, 6 tables</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09778</dc:identifier>
 <dc:identifier>ISA Transactions, Volume 58, September 2015, Pages 35-49</dc:identifier>
 <dc:identifier>doi:10.1016/j.isatra.2015.06.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09791</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Existence of Synchrostates in Multichannel EEG Signals during
  Face-perception Tasks</dc:title>
 <dc:creator>Jamal, Wasifa</dc:creator>
 <dc:creator>Das, Saptarshi</dc:creator>
 <dc:creator>Maharatna, Koushik</dc:creator>
 <dc:creator>Apicella, Fabio</dc:creator>
 <dc:creator>Chronaki, Georgia</dc:creator>
 <dc:creator>Sicca, Federico</dc:creator>
 <dc:creator>Cohen, David</dc:creator>
 <dc:creator>Muratori, Filippo</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Phase synchronisation in multichannel EEG is known as the manifestation of
functional brain connectivity. Traditional phase synchronisation studies are
mostly based on time average synchrony measures hence do not preserve the
temporal evolution of the phase difference. Here we propose a new method to
show the existence of a small set of unique phase synchronised patterns or
&quot;states&quot; in multi-channel EEG recordings, each &quot;state&quot; being stable of the
order of ms, from typical and pathological subjects during face perception
tasks. The proposed methodology bridges the concepts of EEG microstates and
phase synchronisation in time and frequency domain respectively. The analysis
is reported for four groups of children including typical, Autism Spectrum
Disorder (ASD), low and high anxiety subjects - a total of 44 subjects. In all
cases, we observe consistent existence of these states - termed as
synchrostates - within specific cognition related frequency bands (beta and
gamma bands), though the topographies of these synchrostates differ for
different subject groups with different pathological conditions. The
inter-synchrostate switching follows a well-defined sequence capturing the
underlying inter-electrode phase relation dynamics in stimulus- and
person-centric manner. Our study is motivated from the well-known EEG
microstate exhibiting stable potential maps over the scalp. However, here we
report a similar observation of quasi-stable phase synchronised states in
multichannel EEG. The existence of the synchrostates coupled with their unique
switching sequence characteristics could be considered as a potentially new
field over contemporary EEG phase synchronisation studies.
</dc:description>
 <dc:description>Comment: 30 pages, 22 figures, 2 tables</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09791</dc:identifier>
 <dc:identifier>Biomedical Physics &amp; Engineering Express, vol. 1, no. 1, pp.
  015002, 2015</dc:identifier>
 <dc:identifier>doi:10.1088/2057-1976/1/1/015002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09795</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symbolic Representation for Analog Realization of A Family of Fractional
  Order Controller Structures via Continued Fraction Expansion</dc:title>
 <dc:creator>Pakhira, Anindya</dc:creator>
 <dc:creator>Das, Saptarshi</dc:creator>
 <dc:creator>Pan, Indranil</dc:creator>
 <dc:creator>Das, Shantanu</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  This paper uses the Continued Fraction Expansion (CFE) method for analog
realization of fractional order differ-integrator and few special classes of
fractional order (FO) controllers viz. Fractional Order
Proportional-Integral-Derivative (FOPID) controller, FO[PD] controller and FO
lead-lag compensator. Contemporary researchers have given several formulations
for rational approximation of fractional order elements. However, approximation
of the controllers studied in this paper, due to having fractional power of a
rational transfer function, is not available in analog domain; although its
digital realization already exists. This motivates us for applying CFE based
analog realization technique for complicated FO controller structures to get
equivalent rational transfer functions in terms of the controller tuning
parameters. The symbolic expressions for rationalized transfer function in
terms of the controller tuning parameters are especially important as ready
references, without the need of running CFE algorithm every time and also helps
in the synthesis of analog circuits for such FO controllers.
</dc:description>
 <dc:description>Comment: 21 pages, 11 figures</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09795</dc:identifier>
 <dc:identifier>ISA Transactions, Volume 57, July 2015, Pages 390-402</dc:identifier>
 <dc:identifier>doi:10.1016/j.isatra.2015.01.007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09799</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometry of Compositionality</dc:title>
 <dc:creator>Gong, Hongyu</dc:creator>
 <dc:creator>Bhat, Suma</dc:creator>
 <dc:creator>Viswanath, Pramod</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper proposes a simple test for compositionality (i.e., literal usage)
of a word or phrase in a context-specific way. The test is computationally
simple, relying on no external resources and only uses a set of trained word
vectors. Experiments show that the proposed method is competitive with state of
the art and displays high accuracy in context-specific compositionality
detection of a variety of natural language phenomena (idiomaticity, sarcasm,
metaphor) for different datasets in multiple languages. The key insight is to
connect compositionality to a curious geometric property of word embeddings,
which is of independent interest.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09802</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fractional Order Load-Frequency Control of Interconnected Power Systems
  Using Chaotic Multi-objective Optimization</dc:title>
 <dc:creator>Pan, Indranil</dc:creator>
 <dc:creator>Das, Saptarshi</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Fractional order proportional-integral-derivative (FOPID) controllers are
designed for load frequency control (LFC) of two interconnected power systems.
Conflicting time domain design objectives are considered in a multi objective
optimization (MOO) based design framework to design the gains and the
fractional differ-integral orders of the FOPID controllers in the two areas.
Here, we explore the effect of augmenting two different chaotic maps along with
the uniform random number generator (RNG) in the popular MOO algorithm - the
Non-dominated Sorting Genetic Algorithm-II (NSGA-II). Different measures of
quality for MOO e.g. hypervolume indicator, moment of inertia based diversity
metric, total Pareto spread, spacing metric are adopted to select the best set
of controller parameters from multiple runs of all the NSGA-II variants (i.e.
nominal and chaotic versions). The chaotic versions of the NSGA-II algorithm
are compared with the standard NSGA-II in terms of solution quality and
computational time. In addition, the Pareto optimal fronts showing the
trade-off between the two conflicting time domain design objectives are
compared to show the advantage of using the FOPID controller over that with
simple PID controller. The nature of fast/slow and high/low noise amplification
effects of the FOPID structure or the four quadrant operation in the two
inter-connected areas of the power system is also explored. A fuzzy logic based
method has been adopted next to select the best compromise solution from the
best Pareto fronts corresponding to each MOO comparison criteria. The time
domain system responses are shown for the fuzzy best compromise solutions under
nominal operating conditions. Comparative analysis on the merits and de-merits
of each controller structure is reported then. A robustness analysis is also
done for the PID and the FOPID controllers.
</dc:description>
 <dc:description>Comment: 31 pages, 19 figures, 2 tables</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09802</dc:identifier>
 <dc:identifier>Applied Soft Computing, Volume 29, April 2015, Pages 328-344</dc:identifier>
 <dc:identifier>doi:10.1016/j.asoc.2014.12.032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09803</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>InterpoNet, A brain inspired neural network for optical flow dense
  interpolation</dc:title>
 <dc:creator>Zweig, Shay</dc:creator>
 <dc:creator>Wolf, Lior</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sparse-to-dense interpolation for optical flow is a fundamental phase in the
pipeline of most of the leading optical flow estimation algorithms. The current
state-of-the-art method for interpolation, EpicFlow, is a local average method
based on an edge aware geodesic distance. We propose a new data-driven
sparse-to-dense interpolation algorithm based on a fully convolutional network.
We draw inspiration from the filling-in process in the visual cortex and
introduce lateral dependencies between neurons and multi-layer supervision into
our learning process. We also show the importance of the image contour to the
learning process. Our method is robust and outperforms EpicFlow on competitive
optical flow benchmarks with several underlying matching algorithms. This leads
to state-of-the-art performance on the Sintel and KITTI 2012 benchmarks.
</dc:description>
 <dc:description>Comment: 16 pages, 11 figures, 8 tables</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09809</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fractional Order Fuzzy Control of Hybrid Power System with Renewable
  Generation Using Chaotic PSO</dc:title>
 <dc:creator>Pan, Indranil</dc:creator>
 <dc:creator>Das, Saptarshi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  This paper investigates the operation of a hybrid power system through a
novel fuzzy control scheme. The hybrid power system employs various autonomous
generation systems like wind turbine, solar photovoltaic, diesel engine,
fuel-cell, aqua electrolyzer etc. Other energy storage devices like the
battery, flywheel and ultra-capacitor are also present in the network. A novel
fractional order (FO) fuzzy control scheme is employed and its parameters are
tuned with a particle swarm optimization (PSO) algorithm augmented with two
chaotic maps for achieving an improved performance. This FO fuzzy controller
shows better performance over the classical PID, and the integer order fuzzy
PID controller in both linear and nonlinear operating regimes. The FO fuzzy
controller also shows stronger robustness properties against system parameter
variation and rate constraint nonlinearity, than that with the other controller
structures. The robustness is a highly desirable property in such a scenario
since many components of the hybrid power system may be switched on/off or may
run at lower/higher power output, at different time instants.
</dc:description>
 <dc:description>Comment: 21 pages, 12 figures, 4 tables</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09809</dc:identifier>
 <dc:identifier>ISA Transactions, Volume 62, May 2016, Pages 19-29</dc:identifier>
 <dc:identifier>doi:10.1016/j.isatra.2015.03.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09811</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Ultrasound image segmentation: A Survey</dc:title>
 <dc:creator>Mozaffari, Mohammad Hamed</dc:creator>
 <dc:creator>Lee, WonSook</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Three-dimensional Ultrasound image segmentation methods are surveyed in this
paper. The focus of this report is to investigate applications of these
techniques and a review of the original ideas and concepts. Although many
two-dimensional image segmentation in the literature have been considered as a
three-dimensional approach by mistake but we review them as a three-dimensional
technique. We select the studies that have addressed the problem of medical
three-dimensional Ultrasound image segmentation utilizing their proposed
techniques. The evaluation methods and comparison between them are presented
and tabulated in terms of evaluation techniques, interactivity, and robustness.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09813</identifier>
 <datestamp>2017-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monocular 3D Human Pose Estimation In The Wild Using Improved CNN
  Supervision</dc:title>
 <dc:creator>Mehta, Dushyant</dc:creator>
 <dc:creator>Rhodin, Helge</dc:creator>
 <dc:creator>Casas, Dan</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:creator>Sotnychenko, Oleksandr</dc:creator>
 <dc:creator>Xu, Weipeng</dc:creator>
 <dc:creator>Theobalt, Christian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a CNN-based approach for 3D human body pose estimation from single
RGB images that addresses the issue of limited generalizability of models
trained solely on the starkly limited publicly available 3D pose data. Using
only the existing 3D pose data and 2D pose data, we show state-of-the-art
performance on established benchmarks through transfer of learned features,
while also generalizing to in-the-wild scenes. We further introduce a new
training set for human body pose estimation from monocular images of real
humans that has the ground truth captured with a multi-camera marker-less
motion capture system. It complements existing corpora with greater diversity
in pose, human appearance, clothing, occlusion, and viewpoints, and enables an
increased scope of augmentation. We also contribute a new benchmark that covers
outdoor and indoor scenes, and demonstrate that our 3D pose dataset shows
better in-the-wild performance than existing annotated data, which is further
improved in conjunction with transfer learning from 2D pose data. All in all,
we argue that the use of transfer learning of representations in tandem with
algorithmic and data contributions is crucial for general 3D body pose
estimation.
</dc:description>
 <dc:description>Comment: Accepted at the International Conference on 3D Vision (3DV) 2017</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09814</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Global Controller Design for Guaranteed Synchronization of
  Switched Chaotic Systems</dc:title>
 <dc:creator>Pan, Indranil</dc:creator>
 <dc:creator>Das, Saptarshi</dc:creator>
 <dc:creator>Routh, Avijit</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Classical Analysis and ODEs</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  In this paper, synchronization of identical switched chaotic systems is
explored based on Lyapunov theory of guaranteed stability. Concepts from robust
control principles and switched linear systems are merged together to derive a
sufficient condition for synchronization of identical master-slave switched
nonlinear chaotic systems and are expressed in the form of bilinear matrix
inequalities (BMIs). The nonlinear controller design problem is then recast in
the form of linear matrix inequalities (LMIs) to facilitate numerical
computation by standard LMI solvers and is illustrated by appropriate examples.
</dc:description>
 <dc:description>Comment: 32 pages, 20 figures</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09814</dc:identifier>
 <dc:identifier>Applied Mathematical Modelling, Volume 39, Issue 8, 15 April 2015,
  Pages 2311-2331</dc:identifier>
 <dc:identifier>doi:10.1016/j.apm.2014.10.039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09816</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Co-adaptive learning over a countable space</dc:title>
 <dc:creator>Rabadi, Michael</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Co-adaptation is a special form of on-line learning where an algorithm
$\mathcal{A}$ must assist an unknown algorithm $\mathcal{B}$ to perform some
task. This is a general framework and has applications in recommendation
systems, search, education, and much more. Today, the most common use of
co-adaptive algorithms is in brain-computer interfacing (BCI), where algorithms
help patients gain and maintain control over prosthetic devices. While previous
studies have shown strong empirical results Kowalski et al. (2013); Orsborn et
al. (2014) or have been studied in specific examples Merel et al. (2013, 2015),
there is no general analysis of the co-adaptive learning problem. Here we will
study the co-adaptive learning problem in the online, closed-loop setting. We
will prove that, with high probability, co-adaptive learning is guaranteed to
outperform learning with a fixed decoder as long as a particular condition is
met.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, NIPS 2016 Time Series Workshop</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09816</dc:identifier>
 <dc:identifier>In NIPS 2016 Time Series Workshop. Barcelona, Spain</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09819</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring and modeling the perception of natural and unconstrained gaze
  in humans and machines</dc:title>
 <dc:creator>Harari, Daniel</dc:creator>
 <dc:creator>Gao, Tao</dc:creator>
 <dc:creator>Kanwisher, Nancy</dc:creator>
 <dc:creator>Tenenbaum, Joshua</dc:creator>
 <dc:creator>Ullman, Shimon</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Humans are remarkably adept at interpreting the gaze direction of other
individuals in their surroundings. This skill is at the core of the ability to
engage in joint visual attention, which is essential for establishing social
interactions. How accurate are humans in determining the gaze direction of
others in lifelike scenes, when they can move their heads and eyes freely, and
what are the sources of information for the underlying perceptual processes?
These questions pose a challenge from both empirical and computational
perspectives, due to the complexity of the visual input in real-life
situations. Here we measure empirically human accuracy in perceiving the gaze
direction of others in lifelike scenes, and study computationally the sources
of information and representations underlying this cognitive capacity. We show
that humans perform better in face-to-face conditions compared with recorded
conditions, and that this advantage is not due to the availability of input
dynamics. We further show that humans are still performing well when only the
eyes-region is visible, rather than the whole face. We develop a computational
model, which replicates the pattern of human performance, including the finding
that the eyes-region contains on its own, the required information for
estimating both head orientation and direction of gaze. Consistent with
neurophysiological findings on task-specific face regions in the brain, the
learned computational representations reproduce perceptual effects such as the
Wollaston illusion, when trained to estimate direction of gaze, but not when
trained to recognize objects or faces.
</dc:description>
 <dc:description>Comment: Daniel Harari and Tao Gao contributed equally to this work</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09823</identifier>
 <datestamp>2017-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dialogue Learning With Human-In-The-Loop</dc:title>
 <dc:creator>Li, Jiwei</dc:creator>
 <dc:creator>Miller, Alexander H.</dc:creator>
 <dc:creator>Chopra, Sumit</dc:creator>
 <dc:creator>Ranzato, Marc'Aurelio</dc:creator>
 <dc:creator>Weston, Jason</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  An important aspect of developing conversational agents is to give a bot the
ability to improve through communicating with humans and to learn from the
mistakes that it makes. Most research has focused on learning from fixed
training sets of labeled data rather than interacting with a dialogue partner
in an online fashion. In this paper we explore this direction in a
reinforcement learning setting where the bot improves its question-answering
ability from feedback a teacher gives following its generated responses. We
build a simulator that tests various aspects of such learning in a synthetic
environment, and introduce models that work in this regime. Finally, real
experiments with Mechanical Turk validate the approach.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09827</identifier>
 <datestamp>2017-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Features of Music from Scratch</dc:title>
 <dc:creator>Thickstun, John</dc:creator>
 <dc:creator>Harchaoui, Zaid</dc:creator>
 <dc:creator>Kakade, Sham</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This paper introduces a new large-scale music dataset, MusicNet, to serve as
a source of supervision and evaluation of machine learning methods for music
research. MusicNet consists of hundreds of freely-licensed classical music
recordings by 10 composers, written for 11 instruments, together with
instrument/note annotations resulting in over 1 million temporal labels on 34
hours of chamber music performances under various studio and microphone
conditions.
  The paper defines a multi-label classification task to predict notes in
musical recordings, along with an evaluation protocol, and benchmarks several
machine learning architectures for this task: i) learning from spectrogram
features; ii) end-to-end learning with a neural net; iii) end-to-end learning
with a convolutional neural net. These experiments show that end-to-end models
trained for note prediction learn frequency selective filters as a low-level
representation of audio.
</dc:description>
 <dc:description>Comment: 14 pages; camera-ready version; updated experiments and related
  works; additional MIR metrics (Appendix C)</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09830</identifier>
 <datestamp>2017-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NewsQA: A Machine Comprehension Dataset</dc:title>
 <dc:creator>Trischler, Adam</dc:creator>
 <dc:creator>Wang, Tong</dc:creator>
 <dc:creator>Yuan, Xingdi</dc:creator>
 <dc:creator>Harris, Justin</dc:creator>
 <dc:creator>Sordoni, Alessandro</dc:creator>
 <dc:creator>Bachman, Philip</dc:creator>
 <dc:creator>Suleman, Kaheer</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We present NewsQA, a challenging machine comprehension dataset of over
100,000 human-generated question-answer pairs. Crowdworkers supply questions
and answers based on a set of over 10,000 news articles from CNN, with answers
consisting of spans of text from the corresponding articles. We collect this
dataset through a four-stage process designed to solicit exploratory questions
that require reasoning. A thorough analysis confirms that NewsQA demands
abilities beyond simple word matching and recognizing textual entailment. We
measure human performance on the dataset and compare it to several strong
neural models. The performance gap between humans and machines (0.198 in F1)
indicates that significant progress can be made on NewsQA through future
research. The dataset is freely available at
https://datasets.maluuba.com/NewsQA.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09835</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-objective Active Control Policy Design for Commensurate and
  Incommensurate Fractional Order Chaotic Financial Systems</dc:title>
 <dc:creator>Pan, Indranil</dc:creator>
 <dc:creator>Das, Saptarshi</dc:creator>
 <dc:creator>Das, Shantanu</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  In this paper, an active control policy design for a fractional order (FO)
financial system is attempted, considering multiple conflicting objectives. An
active control template as a nonlinear state feedback mechanism is developed
and the controller gains are chosen within a multi-objective optimization (MOO)
framework to satisfy the conditions of asymptotic stability, derived
analytically. The MOO gives a set of solutions on the Pareto optimal front for
the multiple conflicting objectives that are considered. It is shown that there
is a trade-off between the multiple design objectives and a better performance
in one objective can only be obtained at the cost of performance deterioration
in the other objectives. The multi-objective controller design has been
compared using three different MOO techniques viz. Non Dominated Sorting
Genetic Algorithm-II (NSGA-II), epsilon variable Multi-Objective Genetic
Algorithm (ev-MOGA), and Multi Objective Evolutionary Algorithm with
Decomposition (MOEA/D). The robustness of the same control policy designed with
the nominal system settings have been investigated also for gradual decrease in
the commensurate and incommensurate fractional orders of the financial system.
</dc:description>
 <dc:description>Comment: 26 pages, 8 figures, 2 tables</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09835</dc:identifier>
 <dc:identifier>Applied Mathematical Modelling, Volume 39, Issue 2, 15 January
  2015, Pages 500-514</dc:identifier>
 <dc:identifier>doi:10.1016/j.apm.2014.06.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09842</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel
  Prediction</dc:title>
 <dc:creator>Zhang, Richard</dc:creator>
 <dc:creator>Isola, Phillip</dc:creator>
 <dc:creator>Efros, Alexei A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose split-brain autoencoders, a straightforward modification of the
traditional autoencoder architecture, for unsupervised representation learning.
The method adds a split to the network, resulting in two disjoint sub-networks.
Each sub-network is trained to perform a difficult task -- predicting one
subset of the data channels from another. Together, the sub-networks extract
features from the entire input signal. By forcing the network to solve
cross-channel prediction tasks, we induce a representation within the network
which transfers well to other, unseen tasks. This method achieves
state-of-the-art performance on several large-scale transfer learning
benchmarks.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09844</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation studies on the design of optimum PID controllers to suppress
  chaotic oscillations in a family of Lorenz-like multi-wing attractors</dc:title>
 <dc:creator>Das, Saptarshi</dc:creator>
 <dc:creator>Acharya, Anish</dc:creator>
 <dc:creator>Pan, Indranil</dc:creator>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Multi-wing chaotic attractors are highly complex nonlinear dynamical systems
with higher number of index-2 equilibrium points. Due to the presence of
several equilibrium points, randomness and hence the complexity of the state
time series for these multi-wing chaotic systems is much higher than that of
the conventional double-wing chaotic attractors. A real-coded Genetic Algorithm
(GA) based global optimization framework has been adopted in this paper as a
common template for designing optimum Proportional-Integral-Derivative (PID)
controllers in order to control the state trajectories of four different
multi-wing chaotic systems among the Lorenz family viz. Lu system, Chen system,
Rucklidge (or Shimizu Morioka) system and Sprott-1 system. Robustness of the
control scheme for different initial conditions of the multi-wing chaotic
systems has also been shown.
</dc:description>
 <dc:description>Comment: 21 pages, 20 figures, 1 table</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09844</dc:identifier>
 <dc:identifier>Mathematics and Computers in Simulation, Volume 100, June 2014,
  Pages 72-87</dc:identifier>
 <dc:identifier>doi:10.1016/j.matcom.2014.03.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09850</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotically Good Convolutional Codes</dc:title>
 <dc:creator>La Guardia, Giuliano Gadioli</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we construct new sequences of asymptotically good
convolutional codes. These sequences are obtained from sequences of transitive,
self-orthogonal and self-dual block codes that attain the Tsfasman-Vladut-Zink
bound. Furthermore, by applying the techniques of expanding, extending,
puncturing, direct sum, the |u|u+v| construction and the product code
construction to these block codes, we construct more new sequences of
asymptotically good convolutional codes. Additionally, we show that the
proposed construction method presented here also works when applied for all
sequences of good block codes where lim kj/nj and lim dj/nj exist.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:date>2017-04-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09875</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Missile Attitude Control via a Hybrid LQG-LTR-LQI Control Scheme with
  Optimum Weight Selection</dc:title>
 <dc:creator>Das, Saptarshi</dc:creator>
 <dc:creator>Halder, Kaushik</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper proposes a new strategy for missile attitude control using a
hybridization of Linear Quadratic Gaussian (LQG), Loop Transfer Recovery (LTR),
and Linear Quadratic Integral (LQI) control techniques. The LQG control design
is carried out in two steps i.e. firstly applying Kalman filter for state
estimation in noisy environment and then using the estimated states for an
optimal state feedback control via Linear Quadratic Regulator (LQR). As further
steps of performance improvement of the missile attitude control system, the
LTR and LQI schemes are applied to increase the stability margins and guarantee
set-point tracking performance respectively, while also preserving the
optimality of the LQG. The weighting matrix (Q) and weighting factor (R) of LQG
and the LTR fictitious noise coefficient (q) are tuned using Nelder-Mead
Simplex optimization technique to make the closed-loop system act faster.
Simulations are given to illustrate the validity of the proposed technique.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09875</dc:identifier>
 <dc:identifier>Automation, Control, Energy and Systems (ACES), 2014 First
  International Conference on, Feb. 2014, Kolkata</dc:identifier>
 <dc:identifier>doi:10.1109/ACES.2014.6807996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09878</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identity-sensitive Word Embedding through Heterogeneous Networks</dc:title>
 <dc:creator>Tang, Jian</dc:creator>
 <dc:creator>Qu, Meng</dc:creator>
 <dc:creator>Mei, Qiaozhu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Most existing word embedding approaches do not distinguish the same words in
different contexts, therefore ignoring their contextual meanings. As a result,
the learned embeddings of these words are usually a mixture of multiple
meanings. In this paper, we acknowledge multiple identities of the same word in
different contexts and learn the \textbf{identity-sensitive} word embeddings.
Based on an identity-labeled text corpora, a heterogeneous network of words and
word identities is constructed to model different-levels of word
co-occurrences. The heterogeneous network is further embedded into a
low-dimensional space through a principled network embedding approach, through
which we are able to obtain the embeddings of words and the embeddings of word
identities. We study three different types of word identities including topics,
sentiments and categories. Experimental results on real-world data sets show
that the identity-sensitive word embeddings learned by our approach indeed
capture different meanings of words and outperforms competitive methods on
tasks including text classification and word similarity computation.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09881</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control Strategy for Anaesthetic Drug Dosage with Interaction Among
  Human Physiological Organs Using Optimal Fractional Order PID Controller</dc:title>
 <dc:creator>Das, Saptarshi</dc:creator>
 <dc:creator>Das, Sourav</dc:creator>
 <dc:creator>Maharatna, Koushik</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:description>  In this paper, an efficient control strategy for physiological interaction
based anaesthetic drug infusion model is explored using the fractional order
(FO) proportional integral derivative (PID) controllers. The dynamic model is
composed of several human organs by considering the brain response to the
anaesthetic drug as output and the drug infusion rate as the control input.
Particle Swarm Optimisation (PSO) is employed to obtain the optimal set of
parameters for PID/FOPID controller structures. With the proposed FOPID control
scheme much less amount of drug-infusion system can be designed to attain a
specific anaesthetic target and also shows high robustness for +/-50%
parametric uncertainty in the patient's brain model.
</dc:description>
 <dc:description>Comment: 5 pages, 1 table, 6 figures</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09881</dc:identifier>
 <dc:identifier>Control, Instrumentation, Energy and Communication (CIEC),
  International Conference on, pp. 66-70, Feb. 2014, Kolkata</dc:identifier>
 <dc:identifier>doi:10.1109/CIEC.2014.6959051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09893</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring the Uncharted Export: an Analysis of Tourism-Related Foreign
  Expenditure with International Spend Data</dc:title>
 <dc:creator>Coscia, Michele</dc:creator>
 <dc:creator>Hausmann, Ricardo</dc:creator>
 <dc:creator>Neffke, Frank</dc:creator>
 <dc:subject>Quantitative Finance - General Finance</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Tourism is one of the most important economic activities in the world: for
many countries it represents the single largest product in their export basket.
However, it is a product difficult to chart: &quot;exporters&quot; of tourism do not ship
it abroad, but they welcome importers inside the country. Current research uses
social accounting matrices and general equilibrium models, but the standard
industry classifications they use make it hard to identify which domestic
industries cater to foreign visitors. In this paper, we make use of open source
data and of anonymized and aggregated transaction data giving us insights about
the spend behavior of foreigners inside two countries, Colombia and the
Netherlands, to inform our research. With this data, we are able to describe
what constitutes the tourism sector, and to map the most attractive
destinations for visitors. In particular, we find that countries might observe
different geographical tourists' patterns -- concentration versus
decentralization --; we show the importance of distance, a country's reported
wealth and cultural affinity in informing tourism; and we show the potential of
combining open source data and anonymized and aggregated transaction data on
foreign spend patterns in gaining insight as to the evolution of tourism from
one year to another.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09894</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploration for Multi-task Reinforcement Learning with Deep Generative
  Models</dc:title>
 <dc:creator>Bangaru, Sai Praveen</dc:creator>
 <dc:creator>Suhas, JS</dc:creator>
 <dc:creator>Ravindran, Balaraman</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:description>  Exploration in multi-task reinforcement learning is critical in training
agents to deduce the underlying MDP. Many of the existing exploration
frameworks such as $E^3$, $R_{max}$, Thompson sampling assume a single
stationary MDP and are not suitable for system identification in the multi-task
setting. We present a novel method to facilitate exploration in multi-task
reinforcement learning using deep generative models. We supplement our method
with a low dimensional energy model to learn the underlying MDP distribution
and provide a resilient and adaptive exploration signal to the agent. We
evaluate our method on a new set of environments and provide intuitive
interpretation of our results.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures; NIPS Deep Reinforcement Learning Workshop 2016,
  Barcelona</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09897</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autism Spectrum Disorder Classification using Graph Kernels on
  Multidimensional Time Series</dc:title>
 <dc:creator>Anirudh, Rushil</dc:creator>
 <dc:creator>Thiagarajan, Jayaraman J.</dc:creator>
 <dc:creator>Kim, Irene</dc:creator>
 <dc:creator>Polonik, Wolfgang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present an approach to model time series data from resting state fMRI for
autism spectrum disorder (ASD) severity classification. We propose to adopt
kernel machines and employ graph kernels that define a kernel dot product
between two graphs. This enables us to take advantage of spatio-temporal
information to capture the dynamics of the brain network, as opposed to
aggregating them in the spatial or temporal dimension. In addition to the
conventional similarity graphs, we explore the use of L1 graph using sparse
coding, and the persistent homology of time delay embeddings, in the proposed
pipeline for ASD classification. In our experiments on two datasets from the
ABIDE collection, we demonstrate a consistent and significant advantage in
using graph kernels over traditional linear or non linear kernels for a variety
of time series features.
</dc:description>
 <dc:description>Comment: Under review as a conference paper to BHI '17</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09900</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-aware Natural Language Generation with Recurrent Neural Networks</dc:title>
 <dc:creator>Tang, Jian</dc:creator>
 <dc:creator>Yang, Yifan</dc:creator>
 <dc:creator>Carton, Sam</dc:creator>
 <dc:creator>Zhang, Ming</dc:creator>
 <dc:creator>Mei, Qiaozhu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper studied generating natural languages at particular contexts or
situations. We proposed two novel approaches which encode the contexts into a
continuous semantic representation and then decode the semantic representation
into text sequences with recurrent neural networks. During decoding, the
context information are attended through a gating mechanism, addressing the
problem of long-range dependency caused by lengthy sequences. We evaluate the
effectiveness of the proposed approaches on user review data, in which rich
contexts are available and two informative contexts, sentiments and products,
are selected for evaluation. Experiments show that the fake reviews generated
by our approaches are very natural. Results of fake review detection with human
judges show that more than 50\% of the fake reviews are misclassified as the
real reviews, and more than 90\% are misclassified by existing state-of-the-art
fake review detection algorithm.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09904</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>C-RNN-GAN: Continuous recurrent neural networks with adversarial
  training</dc:title>
 <dc:creator>Mogren, Olof</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative adversarial networks have been proposed as a way of efficiently
training deep generative neural networks. We propose a generative adversarial
model that works on continuous sequential data, and apply it by training it on
a collection of classical music. We conclude that it generates music that
sounds better and better as the model is trained, report statistics on
generated music, and let the reader judge the quality by downloading the
generated songs.
</dc:description>
 <dc:description>Comment: Accepted to Constructive Machine Learning Workshop (CML) at NIPS 2016
  in Barcelona, Spain, December 10</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09906</identifier>
 <datestamp>2017-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting the Futamura Projections: A Visual Analysis</dc:title>
 <dc:creator>Williams, Brandon M.</dc:creator>
 <dc:creator>Perugini, Saverio</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  The advent of language implementation tools such as PyPy have broadened
interest in topics related to automatic compiler generation and optimization.
Given this broader interest, we revisit the Futamura Projections using a
diagram scheme. Through these diagrams we emphasize the recurring patterns in
the Futamura Projections while addressing their complexity and abstract nature.
We anticipate that this approach will improve the accessibility of the Futamura
Projections and help foster analysis of those new tools through the lens of
partial evaluation.
</dc:description>
 <dc:description>Comment: 18 pages, 9 figures, 3 tables; reoriented focus of paper and expanded
  discussion section</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09906</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09907</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On rank-width of even-hole-free graphs</dc:title>
 <dc:creator>Adler, Isolde</dc:creator>
 <dc:creator>Le, Ngoc Khang</dc:creator>
 <dc:creator>M&#xfc;ller, Haiko</dc:creator>
 <dc:creator>Radovanovi&#x107;, Marko</dc:creator>
 <dc:creator>Trotignon, Nicolas</dc:creator>
 <dc:creator>Vu&#x161;kovi&#x107;, Kristina</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C85</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We present a class of (diamond, even hole)-free graphs with no clique cutset
that has unbounded rank-width. In general, even-hole-free graphs have unbounded
rank-width, because chordal graphs are even-hole-free. A.A. da Silva, A. Silva
and C. Linhares-Sales (2010) showed that planar even-hole-free graphs have
bounded rank-width, and N.K. Le (2016) showed that even-hole-free graphs with
no star cutset have bounded rank-width. A natural question is to ask, whether
even-hole-free graphs with no clique cutsets have bounded rank-width. Our
result gives a negative answer. Hence we cannot apply Courcelle and Makowsky's
meta-theorem which would provide efficient algorithms for a large number of
problems, including the maximum independent set problem, whose complexity
remains open for (diamond, even hole)-free graphs.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09907</dc:identifier>
 <dc:identifier>Discrete Mathematics &amp; Theoretical Computer Science, Vol 19 no. 1,
  Graph Theory (October 5, 2017) dmtcs:3827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09913</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity and Trainability in Recurrent Neural Networks</dc:title>
 <dc:creator>Collins, Jasmine</dc:creator>
 <dc:creator>Sohl-Dickstein, Jascha</dc:creator>
 <dc:creator>Sussillo, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Two potential bottlenecks on the expressiveness of recurrent neural networks
(RNNs) are their ability to store information about the task in their
parameters, and to store information about the input history in their units. We
show experimentally that all common RNN architectures achieve nearly the same
per-task and per-unit capacity bounds with careful training, for a variety of
tasks and stacking depths. They can store an amount of task information which
is linear in the number of parameters, and is approximately 5 bits per
parameter. They can additionally store approximately one real number from their
input history per hidden unit. We further find that for several tasks it is the
per-task parameter capacity bound that determines performance. These results
suggest that many previous results comparing RNN architectures are driven
primarily by differences in training effectiveness, rather than differences in
capacity. Supporting this observation, we compare training difficulty for
several architectures, and show that vanilla RNNs are far more difficult to
train, yet have slightly higher capacity. Finally, we propose two novel RNN
architectures, one of which is easier to train than the LSTM or GRU for deeply
stacked architectures.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09914</identifier>
 <datestamp>2017-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Batch and PIR Codes and Their Connections to Locally Repairable Codes</dc:title>
 <dc:creator>Skachek, Vitaly</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this survey, two related families of codes are discussed: batch codes and
codes for private information retrieval. These two families can be viewed as
natural generalizations of locally repairable codes, which were extensively
studied in the context of coding for fault tolerance in distributed data
storage systems. Bounds on the parameters of the codes, as well as basic
constructions, are presented. Connections between different code families are
discussed.
</dc:description>
 <dc:description>Comment: Survey</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09915</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stub Wireless Multi-hop Networks using Self-configurable Wi-Fi Basic
  Service Set Cascading</dc:title>
 <dc:creator>J&#xfa;lio, Pedro</dc:creator>
 <dc:creator>Ribeiro, Filipe</dc:creator>
 <dc:creator>Dias, Jaime</dc:creator>
 <dc:creator>Mamede, Jorge</dc:creator>
 <dc:creator>Campos, Rui</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The increasing trend in wireless Internet access has been boosted by IEEE
802.11. However, the application scenarios are still limited by its short radio
range. Stub Wireless Multi-hop Networks (WMNs) are a robust, flexible, and
cost-effective solution to the problem. Yet, typically they are formed by
single radio mesh nodes and suffer from hidden node, unfairness, and
scalability problems.
  We propose a simple multi-radio, multi-channel WMN solution, named Wi-Fi
network Infrastructure eXtension - Dual-Radio (WiFIX-DR), to overcome these
problems. WiFIX-DR reuses IEEE 802.11 built-in mechanisms and beacons to form a
Stub WMN as a set of self-configurable interconnected Basic Service Sets
(BSSs). Experimental results show the improved scalability enabled by the
proposed solution when compared to single-radio WMNs.
</dc:description>
 <dc:description>Comment: Submitted to IEEE/IFIP Wireless Days 2017, 6 pages, 7 figures</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09921</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Less is More: Learning Prominent and Diverse Topics for Data
  Summarization</dc:title>
 <dc:creator>Tang, Jian</dc:creator>
 <dc:creator>Li, Cheng</dc:creator>
 <dc:creator>Zhang, Ming</dc:creator>
 <dc:creator>Mei, Qiaozhu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Statistical topic models efficiently facilitate the exploration of
large-scale data sets. Many models have been developed and broadly used to
summarize the semantic structure in news, science, social media, and digital
humanities. However, a common and practical objective in data exploration tasks
is not to enumerate all existing topics, but to quickly extract representative
ones that broadly cover the content of the corpus, i.e., a few topics that
serve as a good summary of the data. Most existing topic models fit exactly the
same number of topics as a user specifies, which have imposed an unnecessary
burden to the users who have limited prior knowledge. We instead propose new
models that are able to learn fewer but more representative topics for the
purpose of data summarization. We propose a reinforced random walk that allows
prominent topics to absorb tokens from similar and smaller topics, thus
enhances the diversity among the top topics extracted. With this reinforced
random walk as a general process embedded in classical topic models, we obtain
\textit{diverse topic models} that are able to extract the most prominent and
diverse topics from data. The inference procedures of these diverse topic
models remain as simple and efficient as the classical models. Experimental
results demonstrate that the diverse topic models not only discover topics that
better summarize the data, but also require minimal prior knowledge of the
users.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09926</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Choquet integral in decision analysis - lessons from the axiomatization</dc:title>
 <dc:creator>Timonin, Mikhail</dc:creator>
 <dc:subject>Quantitative Finance - Economics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The Choquet integral is a powerful aggregation operator which lists many
well-known models as its special cases. We look at these special cases and
provide their axiomatic analysis. In cases where an axiomatization has been
previously given in the literature, we connect the existing results with the
framework that we have developed. Next we turn to the question of learning,
which is especially important for the practical applications of the model. So
far, learning of the Choquet integral has been mostly confined to the learning
of the capacity. Such an approach requires making a powerful assumption that
all dimensions (e.g. criteria) are evaluated on the same scale, which is rarely
justified in practice. Too often categorical data is given arbitrary numerical
labels (e.g. AHP), and numerical data is considered cardinally and ordinally
commensurate, sometimes after a simple normalization. Such approaches clearly
lack scientific rigour, and yet they are commonly seen in all kinds of
applications. We discuss the pros and cons of making such an assumption and
look at the consequences which axiomatization uniqueness results have for the
learning problems. Finally, we review some of the applications of the Choquet
integral in decision analysis. Apart from MCDA, which is the main area of
interest for our results, we also discuss how the model can be interpreted in
the social choice context. We look in detail at the state-dependent utility,
and show how comonotonicity, central to the previous axiomatizations, actually
implies state-independency in the Choquet integral model. We also discuss the
conditions required to have a meaningful state-dependent utility representation
and show the novelty of our results compared to the previous methods of
building state-dependent models.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09928</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proportional Justified Representation</dc:title>
 <dc:creator>S&#xe1;nchez-Fern&#xe1;ndez, Luis</dc:creator>
 <dc:creator>Elkind, Edith</dc:creator>
 <dc:creator>Lackner, Martin</dc:creator>
 <dc:creator>Fern&#xe1;ndez, Norberto</dc:creator>
 <dc:creator>Fisteus, Jes&#xfa;s A.</dc:creator>
 <dc:creator>Val, Pablo Basanta</dc:creator>
 <dc:creator>Skowron, Piotr</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The goal of multi-winner elections is to choose a fixed-size committee based
on voters' preferences. An important concern in this setting is representation:
large groups of voters with cohesive preferences should be adequately
represented by the election winners. Recently, Aziz et al. (2015a;2017)
proposed two axioms that aim to capture this idea: justified representation
(JR) and its strengthening extended justified representation (EJR). In this
paper, we extend the work of Aziz et al. in several directions. First, we
answer an open question of Aziz et al., by showing that Reweighted Approval
Voting satisfies JR for $k=3, 4, 5$, but fails it for $k\ge 6$. Second, we
observe that EJR is incompatible with the Perfect Representation criterion,
which is important for many applications of multi-winner voting, and propose a
relaxation of EJR, which we call Proportional Justified Representation (PJR).
PJR is more demanding than JR, but, unlike EJR, it is compatible with perfect
representation, and a committee that provides PJR can be computed in polynomial
time if the committee size divides the number of voters. Moreover, just like
EJR, PJR can be used to characterize the classic PAV rule in the class of
weighted PAV rules. On the other hand, we show that EJR provides stronger
guarantees with respect to average voter satisfaction than PJR does.
</dc:description>
 <dc:description>Comment: Accepted at the 31st AAAI Conference on Artificial Intelligence
  (AAAI-17)</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09932</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly-supervised Discriminative Patch Learning via CNN for Fine-grained
  Recognition</dc:title>
 <dc:creator>Wang, Yaming</dc:creator>
 <dc:creator>Morariu, Vlad I.</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Research on fine-grained recognition has recently shifted from multistage
frameworks to convolutional neural networks (CNN) that are trained end-to-end.
Many previous end-to-end deep approaches typically consist of a recognition
network and an auxiliary localization network trained with additional part
annotations to detect semantic parts shared across classes. To avoid the cost
of extra semantic part annotations, we learn class-specific discriminative
patches within the CNN framework. We achieve this by designing a novel
asymmetric two-stream network architecture with supervision on convolutional
filters and a non-random way of layer initialization. Experimental results show
that our approach is able to find high-quality discriminative patches and
achieves state-of-the-art on two publicly available fine-grained recognition
datasets.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09934</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Network Models for Software Development Effort Estimation: A
  Comparative Study</dc:title>
 <dc:creator>Nassif, Ali Bou</dc:creator>
 <dc:creator>Azzeh, Mohammad</dc:creator>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:creator>Ho, Danny</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Software development effort estimation (SDEE) is one of the main tasks in
software project management. It is crucial for a project manager to efficiently
predict the effort or cost of a software project in a bidding process, since
overestimation will lead to bidding loss and underestimation will cause the
company to lose money. Several SDEE models exist; machine learning models,
especially neural network models, are among the most prominent in the field. In
this study, four different neural network models: Multilayer Perceptron,
General Regression Neural Network, Radial Basis Function Neural Network, and
Cascade Correlation Neural Network are compared with each other based on: (1)
predictive accuracy centered on the Mean Absolute Error criterion, (2) whether
such a model tends to overestimate or underestimate, and (3) how each model
classifies the importance of its inputs. Industrial datasets from the
International Software Benchmarking Standards Group (ISBSG) are used to train
and validate the four models. The main ISBSG dataset was filtered and then
divided into five datasets based on the productivity value of each project.
Results show that the four models tend to overestimate in 80percent of the
datasets, and the significance of the model inputs varies based on the selected
model. Furthermore, the Cascade Correlation Neural Network outperforms the
other three models in the majority of the datasets constructed on the Mean
Absolute Residual criterion.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09934</dc:identifier>
 <dc:identifier>Neural Computing &amp; Applications, Volume 27, Issue 8, pp.
  2369-2381, 2016</dc:identifier>
 <dc:identifier>doi:10.1007/s00521-015-2127-1,</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09940</identifier>
 <datestamp>2017-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Combinatorial Optimization with Reinforcement Learning</dc:title>
 <dc:creator>Bello, Irwan</dc:creator>
 <dc:creator>Pham, Hieu</dc:creator>
 <dc:creator>Le, Quoc V.</dc:creator>
 <dc:creator>Norouzi, Mohammad</dc:creator>
 <dc:creator>Bengio, Samy</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents a framework to tackle combinatorial optimization problems
using neural networks and reinforcement learning. We focus on the traveling
salesman problem (TSP) and train a recurrent network that, given a set of city
coordinates, predicts a distribution over different city permutations. Using
negative tour length as the reward signal, we optimize the parameters of the
recurrent network using a policy gradient method. We compare learning the
network parameters on a set of training graphs against learning them on
individual test graphs. Despite the computational expense, without much
engineering and heuristic designing, Neural Combinatorial Optimization achieves
close to optimal results on 2D Euclidean graphs with up to 100 nodes. Applied
to the KnapSack, another NP-hard problem, the same method obtains optimal
solutions for instances with up to 200 items.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09942</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Photographic home styles in Congress: a computer vision approach</dc:title>
 <dc:creator>Anastasopoulos, L. Jason</dc:creator>
 <dc:creator>Badani, Dhruvil</dc:creator>
 <dc:creator>Lee, Crystal</dc:creator>
 <dc:creator>Ginosar, Shiry</dc:creator>
 <dc:creator>Williams, Jake</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While members of Congress now routinely communicate with constituents using
images on a variety of internet platforms, little is known about how images are
used as a means of strategic political communication. This is due primarily to
computational limitations which have prevented large-scale, systematic analyses
of image features. New developments in computer vision, however, are bringing
the systematic study of images within reach. Here, we develop a framework for
understanding visual political communication by extending Fenno's analysis of
home style (Fenno 1978) to images and introduce &quot;photographic&quot; home styles.
Using approximately 192,000 photographs collected from MCs Facebook profiles,
we build machine learning software with convolutional neural networks and
conduct an image manipulation experiment to explore how the race of people that
MCs pose with shape photographic home styles. We find evidence that electoral
pressures shape photographic home styles and demonstrate that Democratic and
Republican members of Congress use images in very different ways.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09944</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proposal of Real Time Predictive Maintenance Platform with 3D Printer
  for Business Vehicles</dc:title>
 <dc:creator>Yamato, Yoji</dc:creator>
 <dc:creator>Fukumoto, Yoshifumi</dc:creator>
 <dc:creator>Kumazaki, Hiroki</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This paper proposes a maintenance platform for business vehicles which
detects failure sign using IoT data on the move, orders to create repair parts
by 3D printers and to deliver them to the destination. Recently, IoT and 3D
printer technologies have been progressed and application cases to
manufacturing and maintenance have been increased. Especially in air flight
industry, various sensing data are collected during flight by IoT technologies
and parts are created by 3D printers. And IoT platforms which improve
development/operation of IoT applications also have been appeared. However,
existing IoT platforms mainly targets to visualize &quot;things&quot; statuses by batch
processing of collected sensing data, and 3 factors of real-time, automatic
orders of repair parts and parts stock cost are insufficient to accelerate
businesses. This paper targets maintenance of business vehicles such as
airplane or high-speed bus. We propose a maintenance platform with real-time
analysis, automatic orders of repair parts and minimum stock cost of parts. The
proposed platform collects data via closed VPN, analyzes stream data and
predicts failures in real-time by online machine learning framework Jubatus,
coordinates ERP or SCM via in memory DB to order repair parts and also
distributes repair parts data to 3D printers to create repair parts near the
destination.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, 5th International Conference on Software and
  Information Engineering (ICSIE 2016), May 2016</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09944</dc:identifier>
 <dc:identifier>5th International Conference on Software and Information
  Engineering (ICSIE 2016), pp.6-10, May 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09946</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vector-Valued Optimal Mass Transport</dc:title>
 <dc:creator>Chen, Yongxin</dc:creator>
 <dc:creator>Georgiou, Tryphon T.</dc:creator>
 <dc:creator>Tannenbaum, Allen</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>52B55, 47L90, 47A63, 49J20, 49J15, 90B06, 94A08, 49M30</dc:subject>
 <dc:description>  We introduce the problem of transporting vector-valued distributions. In
this, a salient feature is that mass may flow between vectorial entries as well
as across space (discrete or continuous). The theory relies on a first step
taken to define an appropriate notion of optimal transport on a graph. The
corresponding distance between distributions is readily computable via convex
optimization and provides a suitable generalization of Wasserstein-type
metrics. Building on this, we define Wasserstein-type metrics on vector-valued
distributions supported on continuous spaces as well as graphs. Motivation for
developing vector-valued mass transport is provided by applications such as
multi-color image processing, polarimetric radar, as well as network problems
where resources may be vectorial.
</dc:description>
 <dc:description>Comment: 16 pages, 8 figures</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09948</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextualizing Geometric Data Analysis and Related Data Analytics: A
  Virtual Microscope for Big Data Analytics</dc:title>
 <dc:creator>Murtagh, Fionn</dc:creator>
 <dc:creator>Farid, Mohsen</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>62H30, 68P01, 6207</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>I.2.1</dc:subject>
 <dc:description>  The relevance and importance of contextualizing data analytics is described.
Qualitative characteristics might form the context of quantitative analysis.
Topics that are at issue include: contrast, baselining, secondary data sources,
supplementary data sources, dynamic and heterogeneous data. In geometric data
analysis, especially with the Correspondence Analysis platform, various case
studies are both experimented with, and are reviewed. In such aspects as
paradigms followed, and technical implementation, implicitly and explicitly, an
important point made is the major relevance of such work for both burgeoning
analytical needs and for new analytical areas including Big Data analytics, and
so on. For the general reader, it is aimed to display and describe, first of
all, the analytical outcomes that are subject to analysis here, and then
proceed to detail the more quantitative outcomes that fully support the
analytics carried out.
</dc:description>
 <dc:description>Comment: 19 pages, 8 figures, 2 tables, Journal of Interdisciplinary
  Methodologies and Issues in Science, vol. 3, 2017. This version contains DOI,
  ISSN</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09948</dc:identifier>
 <dc:identifier>Journal of Interdisciplinary Methodologies and Issues in Sciences,
  Digital Contextualization (September 19, 2017) jimis:3936</dc:identifier>
 <dc:identifier>doi:10.18713/JIMIS-010917-3-1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09956</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Likelihood Bayesian Constrained Local Model</dc:title>
 <dc:creator>Li, Hailiang</dc:creator>
 <dc:creator>Lam, Kin-Man</dc:creator>
 <dc:creator>Chiu, Man-Yau</dc:creator>
 <dc:creator>Wu, Kangheng</dc:creator>
 <dc:creator>Lei, Zhibin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The constrained local model (CLM) proposes a paradigm that the locations of a
set of local landmark detectors are constrained to lie in a subspace, spanned
by a shape point distribution model (PDM). Fitting the model to an object
involves two steps. A response map, which represents the likelihood of the
location of a landmark, is first computed for each landmark using local-texture
detectors. Then, an optimal PDM is determined by jointly maximizing all the
response maps simultaneously, with a global shape constraint. This global
optimization can be considered as a Bayesian inference problem, where the
posterior distribution of the shape parameters, as well as the pose parameters,
can be inferred using maximum a posteriori (MAP). In this paper, we present a
cascaded face-alignment approach, which employs random-forest regressors to
estimate the positions of each landmark, as a likelihood term, efficiently in
the CLM model. Interpretation from CLM framework, this algorithm is named as an
efficient likelihood Bayesian constrained local model (elBCLM). Furthermore, in
each stage of the regressors, the PDM non-rigid parameters of previous stage
can work as shape clues for training each stage regressors. Experimental
results on benchmarks show our approach achieve about 3 to 5 times speed-up
compared with CLM models and improve around 10% on fitting quality compare with
the same setting regression models.
</dc:description>
 <dc:description>Comment: 6 pages, for submitting to ICME-2017</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09957</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-dimensional Data Embedding via Robust Ranking</dc:title>
 <dc:creator>Amid, Ehsan</dc:creator>
 <dc:creator>Vlassis, Nikos</dc:creator>
 <dc:creator>Warmuth, Manfred K.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We describe a new method called t-ETE for finding a low-dimensional embedding
of a set of objects in Euclidean space. We formulate the embedding problem as a
joint ranking problem over a set of triplets, where each triplet captures the
relative similarities between three objects in the set. By exploiting recent
advances in robust ranking, t-ETE produces high-quality embeddings even in the
presence of a significant amount of noise and better preserves local scale than
known methods, such as t-STE and t-SNE. In particular, our method produces
significantly better results than t-SNE on signature datasets while also being
faster to compute.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09957</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09958</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning for Dental Image Analysis</dc:title>
 <dc:creator>Yu, Young-jun</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In order to study the application of artificial intelligence (AI) to dental
imaging, we applied AI technology to classify a set of panoramic radiographs
using (a) a convolutional neural network (CNN) which is a form of an artificial
neural network (ANN), (b) representative image cognition algorithms that
implement scale-invariant feature transform (SIFT), and (c) histogram of
oriented gradients (HOG).
</dc:description>
 <dc:description>Comment: This study was reviewed and approved by the institutional review
  board of the Pusan National University Dental Hospital (PNUPH-2015-034)</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09960</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attend in groups: a weakly-supervised deep learning framework for
  learning from web data</dc:title>
 <dc:creator>Zhuang, Bohan</dc:creator>
 <dc:creator>Liu, Lingqiao</dc:creator>
 <dc:creator>Li, Yao</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Reid, Ian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Large-scale datasets have driven the rapid development of deep neural
networks for visual recognition. However, annotating a massive dataset is
expensive and time-consuming. Web images and their labels are, in comparison,
much easier to obtain, but direct training on such automatically harvested
images can lead to unsatisfactory performance, because the noisy labels of Web
images adversely affect the learned recognition models. To address this
drawback we propose an end-to-end weakly-supervised deep learning framework
which is robust to the label noise in Web images. The proposed framework relies
on two unified strategies -- random grouping and attention -- to effectively
reduce the negative impact of noisy web image annotations. Specifically, random
grouping stacks multiple images into a single training instance and thus
increases the labeling accuracy at the instance level. Attention, on the other
hand, suppresses the noisy signals from both incorrectly labeled images and
less discriminative image regions. By conducting intensive experiments on two
challenging datasets, including a newly collected fine-grained dataset with Web
images of different car models, the superior performance of the proposed
methods over competitive baselines is clearly demonstrated.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09961</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Facial Expression Editing using Autoencoded Flow</dc:title>
 <dc:creator>Yeh, Raymond</dc:creator>
 <dc:creator>Liu, Ziwei</dc:creator>
 <dc:creator>Goldman, Dan B</dc:creator>
 <dc:creator>Agarwala, Aseem</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  High-level manipulation of facial expressions in images --- such as changing
a smile to a neutral expression --- is challenging because facial expression
changes are highly non-linear, and vary depending on the appearance of the
face. We present a fully automatic approach to editing faces that combines the
advantages of flow-based face manipulation with the more recent generative
capabilities of Variational Autoencoders (VAEs). During training, our model
learns to encode the flow from one expression to another over a low-dimensional
latent space. At test time, expression editing can be done simply using latent
vector arithmetic. We evaluate our methods on two applications: 1) single-image
facial expression editing, and 2) facial expression interpolation between two
images. We demonstrate that our method generates images of higher perceptual
quality than previous VAE and flow-based methods.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09964</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Limits of Energy Detection Systems with Massive Receiver
  Arrays</dc:title>
 <dc:creator>Jing, Lishuai</dc:creator>
 <dc:creator>Utkovski, Zoran</dc:creator>
 <dc:creator>de Carvalho, Elisabeth</dc:creator>
 <dc:creator>Popovski, Petar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Energy detection (ED) is an attractive technique for symbol detection at
receivers equipped with a large number of antennas, for example in millimeter
wave communication systems. This paper investigates the performance bounds of
ED with pulse amplitude modulation (PAM) in large antenna arrays under single
stream transmission and fast fading assumptions. The analysis leverages
information-theoretic tools and semi-numerical approach to provide bounds on
the information rate, which are shown to be tight in the low and high
signal-to-noise ratio (SNR) regimes, respectively. For a fixed constellation
size, the impact of the number of antennas and SNR on the achievable
information rate is investigated. Based on the results, heuristics are provided
for the choice of the cardinality of the adaptive modulation scheme as a
function of the SNR and the number of antennas.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09967</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequential Person Recognition in Photo Albums with a Recurrent Network</dc:title>
 <dc:creator>Li, Yao</dc:creator>
 <dc:creator>Lin, Guosheng</dc:creator>
 <dc:creator>Zhuang, Bohan</dc:creator>
 <dc:creator>Liu, Lingqiao</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Hengel, Anton van den</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recognizing the identities of people in everyday photos is still a very
challenging problem for machine vision, due to non-frontal faces, changes in
clothing, location, lighting and similar. Recent studies have shown that rich
relational information between people in the same photo can help in recognizing
their identities. In this work, we propose to model the relational information
between people as a sequence prediction task. At the core of our work is a
novel recurrent network architecture, in which relational information between
instances' labels and appearance are modeled jointly. In addition to relational
cues, scene context is incorporated in our sequence prediction model with no
additional cost. In this sense, our approach is a unified framework for
modeling both contextual cues and visual appearance of person instances. Our
model is trained end-to-end with a sequence of annotated instances in a photo
as inputs, and a sequence of corresponding labels as targets. We demonstrate
that this simple but elegant formulation achieves state-of-the-art performance
on the newly released People In Photo Albums (PIPA) dataset.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09968</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cauchy MDS Array Codes With Efficient Decoding Method</dc:title>
 <dc:creator>Hou, Hanxu</dc:creator>
 <dc:creator>Han, Yunghsiang S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Array codes have been widely used in communication and storage systems. To
reduce computational complexity, one important property of the array codes is
that only XOR operation is used in the encoding and decoding process. In this
work, we present a novel family of maximal-distance separable (MDS) array codes
based on Cauchy matrix, which can correct up to any number of failures. We also
propose an efficient decoding method for the new codes to recover the failures.
We show that the encoding/decoding complexities of the proposed approach are
lower than those of existing Cauchy MDS array codes, such as Rabin-Like codes
and CRS codes. Thus, the proposed MDS array codes are attractive for
distributed storage systems.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09969</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Resolution Image Inpainting using Multi-Scale Neural Patch
  Synthesis</dc:title>
 <dc:creator>Yang, Chao</dc:creator>
 <dc:creator>Lu, Xin</dc:creator>
 <dc:creator>Lin, Zhe</dc:creator>
 <dc:creator>Shechtman, Eli</dc:creator>
 <dc:creator>Wang, Oliver</dc:creator>
 <dc:creator>Li, Hao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent advances in deep learning have shown exciting promise in filling large
holes in natural images with semantically plausible and context aware details,
impacting fundamental image manipulation tasks such as object removal. While
these learning-based methods are significantly more effective in capturing
high-level features than prior techniques, they can only handle very
low-resolution inputs due to memory limitations and difficulty in training.
Even for slightly larger images, the inpainted regions would appear blurry and
unpleasant boundaries become visible. We propose a multi-scale neural patch
synthesis approach based on joint optimization of image content and texture
constraints, which not only preserves contextual structures but also produces
high-frequency details by matching and adapting patches with the most similar
mid-layer feature correlations of a deep classification network. We evaluate
our method on the ImageNet and Paris Streetview datasets and achieved
state-of-the-art inpainting accuracy. We show our approach produces sharper and
more coherent results than prior methods, especially for high-resolution
images.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09978</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Relationships in Referential Expressions with Compositional
  Modular Networks</dc:title>
 <dc:creator>Hu, Ronghang</dc:creator>
 <dc:creator>Rohrbach, Marcus</dc:creator>
 <dc:creator>Andreas, Jacob</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:creator>Saenko, Kate</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  People often refer to entities in an image in terms of their relationships
with other entities. For example, &quot;the black cat sitting under the table&quot;
refers to both a &quot;black cat&quot; entity and its relationship with another &quot;table&quot;
entity. Understanding these relationships is essential for interpreting and
grounding such natural language expressions. Most prior work focuses on either
grounding entire referential expressions holistically to one region, or
localizing relationships based on a fixed set of categories. In this paper we
instead present a modular deep architecture capable of analyzing referential
expressions into their component parts, identifying entities and relationships
mentioned in the input expression and grounding them all in the scene. We call
this approach Compositional Modular Networks (CMNs): a novel architecture that
learns linguistic analysis and visual inference end-to-end. Our approach is
built around two types of neural modules that inspect local regions and
pairwise interactions between regions. We evaluate CMNs on multiple referential
expression datasets, outperforming state-of-the-art approaches on all tasks.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09978</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09981</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoding from Pooled Data: Sharp Information-Theoretic Bounds</dc:title>
 <dc:creator>Alaoui, Ahmed El</dc:creator>
 <dc:creator>Ramdas, Aaditya</dc:creator>
 <dc:creator>Krzakala, Florent</dc:creator>
 <dc:creator>Zdeborova, Lenka</dc:creator>
 <dc:creator>Jordan, Michael I.</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Consider a population consisting of n individuals, each of whom has one of d
types (e.g. their blood type, in which case d=4). We are allowed to query this
database by specifying a subset of the population, and in response we observe a
noiseless histogram (a d-dimensional vector of counts) of types of the pooled
individuals. This measurement model arises in practical situations such as
pooling of genetic data and may also be motivated by privacy considerations. We
are interested in the number of queries one needs to unambiguously determine
the type of each individual. In this paper, we study this information-theoretic
question under the random, dense setting where in each query, a random subset
of individuals of size proportional to n is chosen. This makes the problem a
particular example of a random constraint satisfaction problem (CSP) with a
&quot;planted&quot; solution. We establish almost matching upper and lower bounds on the
minimum number of queries m such that there is no solution other than the
planted one with probability tending to 1 as n tends to infinity. Our proof
relies on the computation of the exact &quot;annealed free energy&quot; of this model in
the thermodynamic limit, which corresponds to the exponential rate of decay of
the expected number of solution to this planted CSP. As a by-product of the
analysis, we show an identity of independent interest relating the Gaussian
integral over the space of Eulerian flows of a graph to its spanning tree
polynomial.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09983</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anticipating Moves to Prevent Botnet Generated DDoS Flooding Attacks</dc:title>
 <dc:creator>Nogueira, Michele</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Volumetric Distributed Denial of Service (DDoS) attacks have been a recurrent
issue on the Internet. These attacks generate a flooding of fake network
traffic to interfere with targeted servers or network links. Despite many
efforts to detect and mitigate them, attackers have played a game always
circumventing countermeasures. Today, there is an increase in the number of
infected devices, even more with the advent of the Internet of Things and
flexible communication technologies. Leveraging device-to-device short range
wireless communications and others, infected devices can coordinate
sophisticated botnets, which can be employed to intensify DDoS attacks. The new
generation of botnets is even harder to detect because of their adaptive and
dynamic behavior yielded by infected mobile portable devices. Additionally,
because there can be a large number of geographically distributed devices,
botnets increase DDoS traffic significantly. In face of their new behavior and
the increasing volume of DDoS traffic, novel and intelligent-driven approaches
are required. Specifically, we advocate for {\em anticipating} trends of DDoS
attacks in the early stages as much as possible. This work provides an overview
of approaches that can be employed to anticipate trends of DDoS attacks
generated by botnets in their early stages and brings an insightful discussion
about the advantages of each kind of approach and open issues.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09984</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the optimal control problem for a class of monotone bilinear systems</dc:title>
 <dc:creator>Dhingra, Neil K.</dc:creator>
 <dc:creator>Colombino, Marcello</dc:creator>
 <dc:creator>Jovanovi&#x107;, Mihailo R.</dc:creator>
 <dc:creator>Rantzer, Anders</dc:creator>
 <dc:creator>Smith, Roy S.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  We consider a class of monotone systems in which the control signal
multiplies the state. Among other applications, such bilinear systems can be
used to model the evolutionary dynamics of HIV in the presence of combination
drug therapy. For this class of systems, we formulate an infinite horizon
optimal control problem, prove that the optimal control signal is constant over
time, and show that it can be computed by solving a finite-dimensional
non-smooth convex optimization problem. We provide an explicit expression for
the subdifferential set of the objective function and use a subgradient
algorithm to design the optimal controller. We further extend our results to
characterize the optimal robust controller for systems with uncertain dynamics
and show that computing the robust controller is no harder than computing the
nominal controller. We illustrate our results with an example motivated by
combination drug therapy.
</dc:description>
 <dc:description>Comment: 15 pages, 2 figures</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09984</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09985</identifier>
 <datestamp>2017-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gowers norms for the Thue-Morse and Rudin-Shapiro sequences</dc:title>
 <dc:creator>Konieczny, Jakub</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We estimate Gowers uniformity norms for some classical automatic sequences,
such as the Thue-Morse and Rudin-Shapiro sequences. The methods can also be
extended to other automatic sequences. As an application, we asymptotically
count arithmetic progressions in the set of integers $\leq N$ where the
Thue-Morse (resp. Rudin-Shapiro) sequence takes the value $+1$.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09987</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Digraphs with Distinguishable Dynamics under the Multi-Agent Agreement
  Protocol</dc:title>
 <dc:creator>Rahimian, M. Amin</dc:creator>
 <dc:creator>Ajorlou, Amir</dc:creator>
 <dc:creator>Aghdam, Amir G.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  In this work, the ability to distinguish digraphs from the output response of
some observing agents in a multi-agent network under the agreement protocol has
been studied. Given a fixed observation point, it is desired to find sufficient
graphical conditions under which the failure of a set of edges in the network
information flow digraph is distinguishable from another set. When the latter
is empty, this corresponds to the detectability of the former link set given
the response of the observing agent. In developing the results, a powerful
extension of the all-minors matrix tree theorem in algebraic graph theory is
proved which relates the minors of the transformed Laplacian of a directed
graph to the number and length of the shortest paths between its vertices. The
results reveal an intricate relationship between the ability to distinguish the
responses of a healthy and a faulty multi-agent network and the inter-nodal
paths in their information flow digraphs. The results have direct implications
for the operation and design of multi-agent systems subject to multiple link
losses. Simulations and examples are presented to illustrate the analytic
findings.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09987</dc:identifier>
 <dc:identifier>Asian Journal of Control, Volume 16, Issue 5, 2014, Pages
  1300-1311</dc:identifier>
 <dc:identifier>doi:10.1002/asjc.868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.09988</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Buddy-RAM: Improving the Performance and Efficiency of Bulk Bitwise
  Operations Using DRAM</dc:title>
 <dc:creator>Seshadri, Vivek</dc:creator>
 <dc:creator>Lee, Donghyuk</dc:creator>
 <dc:creator>Mullins, Thomas</dc:creator>
 <dc:creator>Hassan, Hasan</dc:creator>
 <dc:creator>Boroumand, Amirali</dc:creator>
 <dc:creator>Kim, Jeremie</dc:creator>
 <dc:creator>Kozuch, Michael A.</dc:creator>
 <dc:creator>Mutlu, Onur</dc:creator>
 <dc:creator>Gibbons, Phillip B.</dc:creator>
 <dc:creator>Mowry, Todd C.</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Bitwise operations are an important component of modern day programming. Many
widely-used data structures (e.g., bitmap indices in databases) rely on fast
bitwise operations on large bit vectors to achieve high performance.
Unfortunately, in existing systems, regardless of the underlying architecture
(e.g., CPU, GPU, FPGA), the throughput of such bulk bitwise operations is
limited by the available memory bandwidth.
  We propose Buddy, a new mechanism that exploits the analog operation of DRAM
to perform bulk bitwise operations completely inside the DRAM chip. Buddy
consists of two components. First, simultaneous activation of three DRAM rows
that are connected to the same set of sense amplifiers enables us to perform
bitwise AND and OR operations. Second, the inverters present in each sense
amplifier enables us to perform bitwise NOT operations, with modest changes to
the DRAM array. These two components make Buddy functionally complete. Our
implementation of Buddy largely exploits the existing DRAM structure and
interface, and incurs low overhead (1% of DRAM chip area).
  Our evaluations based on SPICE simulations show that, across seven
commonly-used bitwise operations, Buddy provides between 10.9X---25.6X
improvement in raw throughput and 25.1X---59.5X reduction in energy
consumption. We evaluate three real-world data-intensive applications that
exploit bitwise operations: 1) bitmap indices, 2) BitWeaving, and 3)
bitvector-based implementation of sets. Our evaluations show that Buddy
significantly outperforms the state-of-the-art.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1605.06483</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.09988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10007</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural Controllability of Multi-Agent Networks: Robustness against
  Simultaneous Failures</dc:title>
 <dc:creator>Rahimian, M. Amin</dc:creator>
 <dc:creator>Aghdam, Amir G.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  In this paper, structural controllability of a leader-follower multi-agent
system with multiple leaders is studied from a graph-theoretic point of view.
The problem of preservation of structural controllability under simultaneous
failures in both the communication links and the agents is investigated. The
effects of the loss of agents and communication links on the controllability of
an information flow graph are previously studied. In this work, the
corresponding results are exploited to introduce some useful indices and
importance measures that help characterize and quantify the role of individual
links and agents in the controllability of the overall network. Existing
results are then extended by considering the effects of losses in both links
and agents at the same time. To this end, the concepts of joint
(r,s)-controllability and joint t-controllability are introduced as
quantitative measures of reliability for a multi-agent system, and their
important properties are investigated. Lastly, the class of jointly critical
digraphs is introduced and it is stated that if a digraph is jointly critical,
then joint t-controllability is a necessary and sufficient condition for
remaining controllable following the failure of any set of links and agents,
with cardinality less than t. Various examples are exploited throughout the
paper to elaborate on the analytical findings.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10007</dc:identifier>
 <dc:identifier>Automatica, Volume 49, Issue 11, 2013, Pages 3149-3157</dc:identifier>
 <dc:identifier>doi:10.1016/j.automatica.2013.06.023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10010</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Cuboid Detection: Beyond 2D Bounding Boxes</dc:title>
 <dc:creator>Dwibedi, Debidatta</dc:creator>
 <dc:creator>Malisiewicz, Tomasz</dc:creator>
 <dc:creator>Badrinarayanan, Vijay</dc:creator>
 <dc:creator>Rabinovich, Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a Deep Cuboid Detector which takes a consumer-quality RGB image of
a cluttered scene and localizes all 3D cuboids (box-like objects). Contrary to
classical approaches which fit a 3D model from low-level cues like corners,
edges, and vanishing points, we propose an end-to-end deep learning system to
detect cuboids across many semantic categories (e.g., ovens, shipping boxes,
and furniture). We localize cuboids with a 2D bounding box, and simultaneously
localize the cuboid's corners, effectively producing a 3D interpretation of
box-like objects. We refine keypoints by pooling convolutional features
iteratively, improving the baseline method significantly. Our deep learning
cuboid detector is trained in an end-to-end fashion and is suitable for
real-time applications in augmented reality (AR) and robotics.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10012</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Speed/accuracy trade-offs for modern convolutional object detectors</dc:title>
 <dc:creator>Huang, Jonathan</dc:creator>
 <dc:creator>Rathod, Vivek</dc:creator>
 <dc:creator>Sun, Chen</dc:creator>
 <dc:creator>Zhu, Menglong</dc:creator>
 <dc:creator>Korattikara, Anoop</dc:creator>
 <dc:creator>Fathi, Alireza</dc:creator>
 <dc:creator>Fischer, Ian</dc:creator>
 <dc:creator>Wojna, Zbigniew</dc:creator>
 <dc:creator>Song, Yang</dc:creator>
 <dc:creator>Guadarrama, Sergio</dc:creator>
 <dc:creator>Murphy, Kevin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The goal of this paper is to serve as a guide for selecting a detection
architecture that achieves the right speed/memory/accuracy balance for a given
application and platform. To this end, we investigate various ways to trade
accuracy for speed and memory usage in modern convolutional object detection
systems. A number of successful systems have been proposed in recent years, but
apples-to-apples comparisons are difficult due to different base feature
extractors (e.g., VGG, Residual Networks), different default image resolutions,
as well as different hardware and software platforms. We present a unified
implementation of the Faster R-CNN [Ren et al., 2015], R-FCN [Dai et al., 2016]
and SSD [Liu et al., 2015] systems, which we view as &quot;meta-architectures&quot; and
trace out the speed/accuracy trade-off curve created by using alternative
feature extractors and varying other critical parameters such as image size
within each of these meta-architectures. On one extreme end of this spectrum
where speed and memory are critical, we present a detector that achieves real
time speeds and can be deployed on a mobile device. On the opposite end in
which accuracy is critical, we present a detector that achieves
state-of-the-art performance measured on the COCO detection task.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10014</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterization and Efficient Exhaustive Search Algorithm for
  Elementary Trapping Sets of Irregular LDPC Codes</dc:title>
 <dc:creator>Hashemi, Yoones</dc:creator>
 <dc:creator>Banihashemi, Amir H.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a characterization of elementary trapping sets
(ETSs) for irregular low-density parity-check (LDPC) codes. These sets are
known to be the main culprits in the error floor region of such codes. The
characterization of ETSs for irregular codes has been known to be a challenging
problem due to the large variety of non-isomorphic ETS structures that can
exist within the Tanner graph of these codes. This is a direct consequence of
the variety of the degrees of the variable nodes that can participate in such
structures. The proposed characterization is based on a hierarchical graphical
representation of ETSs, starting from simple cycles of the graph, or from
single variable nodes, and involves three simple expansion techniques:
degree-one tree ($dot$), $path$ and $lollipop$, thus, the terminology {\em dpl
characterization}. A similar dpl characterization was proposed in an earlier
work by the authors for the leafless ETSs (LETSs) of variable-regular LDPC
codes. The present paper generalizes the prior work to codes with a variety of
variable node degrees and to ETSs that are not leafless. The proposed dpl
characterization corresponds to an efficient search algorithm that, for a given
irregular LDPC code, can find all the instances of $(a,b)$ ETSs with size $a$
and with the number of unsatisfied check nodes $b$ within any range of interest
$a \leq a_{max}$ and $b \leq b_{max}$, exhaustively. Although, (brute force)
exhaustive search algorithms for ETSs of irregular LDPC codes exist, to the
best of our knowledge, the proposed search algorithm is the first of its kind,
in that, it is devised based on a characterization of ETSs that makes the
search process efficient. Extensive simulation results are presented to show
the versatility of the search algorithm, and to demonstrate that, compared to
the literature, significant improvement in search speed can be obtained.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1510.04954</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10017</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Supervised Discrete Hashing and its Analysis</dc:title>
 <dc:creator>Koutaki, Gou</dc:creator>
 <dc:creator>Shirai, Keiichiro</dc:creator>
 <dc:creator>Ambai, Mitsuru</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  In this paper, we propose a learning-based supervised discrete hashing
method. Binary hashing is widely used for large-scale image retrieval as well
as video and document searches because the compact representation of binary
code is essential for data storage and reasonable for query searches using
bit-operations. The recently proposed Supervised Discrete Hashing (SDH)
efficiently solves mixed-integer programming problems by alternating
optimization and the Discrete Cyclic Coordinate descent (DCC) method. We show
that the SDH model can be simplified without performance degradation based on
some preliminary experiments; we call the approximate model for this the &quot;Fast
SDH&quot; (FSDH) model. We analyze the FSDH model and provide a mathematically exact
solution for it. In contrast to SDH, our model does not require an alternating
optimization algorithm and does not depend on initial values. FSDH is also
easier to implement than Iterative Quantization (ITQ). Experimental results
involving a large-scale database showed that FSDH outperforms conventional SDH
in terms of precision, recall, and computation time.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10021</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Field study on requirements engineering: Investigation of artefacts,
  project parameters, and execution strategies</dc:title>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:creator>Wagner, S.</dc:creator>
 <dc:creator>Lochmann, K.</dc:creator>
 <dc:creator>Baumann, A.</dc:creator>
 <dc:creator>de Carne, H.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Requirements Engineering (RE) is a critical discipline mostly driven by
uncertainty, since it is influenced by the customer domain or by the
development process model used. We aim to investigate RE processes in
successful project environments to discover characteristics and strategies that
allow us to elaborate RE tailoring approaches in the future. We perform a field
study on a set of projects at one company. First, we investigate by content
analysis which RE artefacts were produced in each project and to what extent
they were produced. Second, we perform qualitative analysis of semi-structured
interviews to discover project parameters that relate to the produced
artefacts. Third, we use cluster analysis to infer artefact patterns and
probable RE execution strategies, which are the responses to specific project
parameters. Fourth, we investigate by statistical tests the effort spent in
each strategy in relation to the effort spent in change requests to evaluate
the efficiency of execution strategies. Our results show no statistically
significant difference between the efficiency of the strategies. In addition,
it turned out that many parameters considered as the main causes for project
failures can be successfully handled. Hence, practitioners can apply the
artefact patterns and related project parameters to tailor the RE process
according to individual project characteristics.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10021</dc:identifier>
 <dc:identifier>Information and Software Technology, 2011</dc:identifier>
 <dc:identifier>doi:10.1016/j.infsof.2011.09.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10022</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Case Study on Artefact-based RE Improvement in Practice</dc:title>
 <dc:creator>Fer&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:creator>Wagner, S.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Most requirements engineering (RE) process improvement approaches are
solution-driven and activity-based. They focus on the assessment of the RE of a
company against an external norm of best practices. A consequence is that
practitioners often have to rely on an improvement approach that skips a
profound problem analysis and that results in an RE approach that might be
alien to the organisational needs. In recent years, we have developed an RE
improvement approach (called \emph{ArtREPI}) that guides a holistic RE
improvement against individual goals of a company putting primary attention to
the quality of the artefacts. In this paper, we aim at exploring ArtREPI's
benefits and limitations. We contribute an industrial evaluation of ArtREPI by
relying on a case study research. Our results suggest that ArtREPI is
well-suited for the establishment of an RE that reflects a specific
organisational culture but to some extent at the cost of efficiency resulting
from intensive discussions on a terminology that suits all involved
stakeholders. Our results reveal first benefits and limitations, but we can
also conclude the need of longitudinal and independent investigations for which
we herewith lay the foundation.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10022</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on Product-Focused
  Software Process Improvement, 2015</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-26844-6_9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10023</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Field Study on the Elicitation and Classification of Defects for
  Defect Models</dc:title>
 <dc:creator>Holling, D.</dc:creator>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:creator>Pretschner, A.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Defect models capture faults and methods to provoke failures. To integrate
such defect models into existing quality assurance processes, we developed a
defect model lifecycle framework, in which the elicitation and classification
of context-specific defects forms a crucial step. Although we could gather
first insights from its practical application, we still have little knowledge
about its benefits and limitations. We aim at qualitatively analyzing the
context-specific elicitation and classification of defects to explore the
suitability of our approach for practical application. We apply case study
research in multiple contexts and analyze (1) what kind of defects we can
elicit and the degree to which the defects matter to a context only, (2) the
extent to which it leads to results useful enough for describing and
operationalizing defect models, and (3) if there is a perceived additional
immediate benefit from a practitioner's perspective. Our results strengthen our
confidence on the suitability of our approach to elicit defects that are
context-specific as well as context-independent. We conclude so far that our
approach is suitable to provide a blueprint on how to elicit and classify
defects for specific contexts to be used for the improvement of quality
assurance techniques.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10023</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on Product-Focused
  Software Process Improvement, 2015</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-26844-6_9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10024</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artefact-based Requirements Engineering: The AMDiRE Approach</dc:title>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:creator>Penzenstadler, B.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The various influences in the processes and application domains make
Requirements Engineering (RE) inherently complex and difficult to implement. In
general, we have two options for establishing an RE approach: we can either
establish an activity-based RE approach or we can establish an artefact-based
one where project participants concentrate on the RE artefacts rather than on
the way of creating them. While a number of activity-based RE approaches have
been proposed in recent years, we have gained much empirical evidence and
experiences about the advantages of the artefact-based paradigm for RE.
However, artefact orientation is still a young paradigm with various
interpretations and practical manifestations whereby we need a clear
understanding of its basic concepts and a consolidated and evaluated view on
the paradigm.
  In this article, we contribute an artefact-based approach to RE (AMDiRE) that
emerges from six years of experiences in fundamental and evidence-based
research. To this end, we first discuss the basic notion of artefact
orientation and its evolution in recent years. We briefly introduce a set of
artefact-based RE models we developed in industrial research cooperations for
different application domains, show their empirical evaluations, and their
dissemination into academia and practice, eventually leading to the AMDiRE
approach. We conclude with a discussion of experiences we made during the
development and different industrial evaluations, and lessons learnt.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10024</dc:identifier>
 <dc:identifier>Requirements Engineering Journal, 2014</dc:identifier>
 <dc:identifier>doi:10.1007/s00766-014-0206-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10031</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Deep Learning for Classification of Hyperspectral Images</dc:title>
 <dc:creator>Liu, Peng</dc:creator>
 <dc:creator>Zhang, Hui</dc:creator>
 <dc:creator>Eom, Kie B.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Active deep learning classification of hyperspectral images is considered in
this paper. Deep learning has achieved success in many applications, but
good-quality labeled samples are needed to construct a deep learning network.
It is expensive getting good labeled samples in hyperspectral images for remote
sensing applications. An active learning algorithm based on a weighted
incremental dictionary learning is proposed for such applications. The proposed
algorithm selects training samples that maximize two selection criteria, namely
representative and uncertainty. This algorithm trains a deep network
efficiently by actively selecting training samples at each iteration. The
proposed algorithm is applied for the classification of hyperspectral images,
and compared with other classification algorithms employing active learning. It
is shown that the proposed algorithm is efficient and effective in classifying
hyperspectral images.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10038</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Accurate Word Segmentation for Chinese Patents</dc:title>
 <dc:creator>Li, Si</dc:creator>
 <dc:creator>Xue, Nianwen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A patent is a property right for an invention granted by the government to
the inventor. An invention is a solution to a specific technological problem.
So patents often have a high concentration of scientific and technical terms
that are rare in everyday language. The Chinese word segmentation model trained
on currently available everyday language data sets performs poorly because it
cannot effectively recognize these scientific and technical terms. In this
paper we describe a pragmatic approach to Chinese word segmentation on patents
where we train a character-based semi-supervised sequence labeling model by
extracting features from a manually segmented corpus of 142 patents, enhanced
with information extracted from the Chinese TreeBank. Experiments show that the
accuracy of our model reached 95.08% (F1 score) on a held-out test set and
96.59% on development set, compared with an F1 score of 91.48% on development
set if the model is trained on the Chinese TreeBank. We also experimented with
some existing domain adaptation techniques, the results show that the amount of
target domain data and the selected features impact the performance of the
domain adaptation techniques.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10041</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subsampled online matrix factorization with convergence guarantees</dc:title>
 <dc:creator>Mensch, Arthur</dc:creator>
 <dc:creator>Mairal, Julien</dc:creator>
 <dc:creator>Varoquaux, Ga&#xeb;l</dc:creator>
 <dc:creator>Thirion, Bertrand</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a matrix factorization algorithm that scales to input matrices
that are large in both dimensions (i.e., that contains morethan 1TB of data).
The algorithm streams the matrix columns while subsampling them, resulting in
low complexity per iteration andreasonable memory footprint. In contrast to
previous online matrix factorization methods, our approach relies on
low-dimensional statistics from past iterates to control the extra variance
introduced by subsampling. We present a convergence analysis that guarantees us
to reach a stationary point of the problem. Large speed-ups can be obtained
compared to previous online algorithms that do not perform subsampling, thanks
to the feature redundancy that often exists in high-dimensional settings.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10041</dc:identifier>
 <dc:identifier>9th NIPS Workshop on Optimization for Machine Learning, Dec 2016,
  Barcelone, Spain</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10045</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Similarity Search for Molecular Descriptors</dc:title>
 <dc:creator>Tabei, Yasuo</dc:creator>
 <dc:creator>Puglisi, Simon J.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Similarity search over chemical compound databases is a fundamental task in
the discovery and design of novel drug-like molecules. Such databases often
encode molecules as non-negative integer vectors, called molecular descriptors,
which represent rich information on various molecular properties. While there
exist efficient indexing structures for searching databases of binary vectors,
solutions for more general integer vectors are in their infancy. In this paper
we present a time- and space- efficient index for the problem that we call the
succinct intervals-splitting tree algorithm for molecular descriptors (SITAd).
Our approach extends efficient methods for binary-vector databases, and uses
ideas from succinct data structures. Our experiments, on a large database of
over 40 million compounds, show SITAd significantly outperforms alternative
approaches in practice.
</dc:description>
 <dc:description>Comment: To be appeared in the Proceedings of SISAP'17</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10052</identifier>
 <datestamp>2016-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Tuning of Hadoop MapReduce: A Noisy Gradient Approach</dc:title>
 <dc:creator>Kumar, Sandeep</dc:creator>
 <dc:creator>Padakandla, Sindhu</dc:creator>
 <dc:creator>L, Chandrashekar</dc:creator>
 <dc:creator>Parihar, Priyank</dc:creator>
 <dc:creator>Gopinath, K</dc:creator>
 <dc:creator>Bhatnagar, Shalabh</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Hadoop MapReduce is a framework for distributed storage and processing of
large datasets that is quite popular in big data analytics. It has various
configuration parameters (knobs) which play an important role in deciding the
performance i.e., the execution time of a given big data processing job.
Default values of these parameters do not always result in good performance and
hence it is important to tune them. However, there is inherent difficulty in
tuning the parameters due to two important reasons - firstly, the parameter
search space is large and secondly, there are cross-parameter interactions.
Hence, there is a need for a dimensionality-free method which can automatically
tune the configuration parameters by taking into account the cross-parameter
dependencies. In this paper, we propose a novel Hadoop parameter tuning
methodology, based on a noisy gradient algorithm known as the simultaneous
perturbation stochastic approximation (SPSA). The SPSA algorithm tunes the
parameters by directly observing the performance of the Hadoop MapReduce
system. The approach followed is independent of parameter dimensions and
requires only $2$ observations per iteration while tuning. We demonstrate the
effectiveness of our methodology in achieving good performance on popular
Hadoop benchmarks namely \emph{Grep}, \emph{Bigram}, \emph{Inverted Index},
\emph{Word Co-occurrence} and \emph{Terasort}. Our method, when tested on a 25
node Hadoop cluster shows 66\% decrease in execution time of Hadoop jobs on an
average, when compared to the default configuration. Further, we also observe a
reduction of 45\% in execution times, when compared to prior methods.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2016-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10053</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Temporal and Semantic Developer-Level Information to Predict
  Maintenance Activity Profiles</dc:title>
 <dc:creator>Levin, Stanislav</dc:creator>
 <dc:creator>Yehudai, Amiram</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Predictive models for software projects' characteristics have been
traditionally based on project-level metrics, employing only little
developer-level information, or none at all. In this work we suggest novel
metrics that capture temporal and semantic developer-level information
collected on a per developer basis. To address the scalability challenges
involved in computing these metrics for each and every developer for a large
number of source code repositories, we have built a designated repository
mining platform. This platform was used to create a metrics dataset based on
processing nearly 1000 highly popular open source GitHub repositories,
consisting of 147 million LOC, and maintained by 30,000 developers. The
computed metrics were then employed to predict the corrective, perfective, and
adaptive maintenance activity profiles identified in previous works. Our
results show both strong correlation and promising predictive power with
R-squared values of 0.83, 0.64, and 0.75. We also show how these results may
help project managers to detect anomalies in the development process and to
build better development teams. In addition, the platform we built has the
potential to yield further predictive models leveraging developer-level metrics
at scale.
</dc:description>
 <dc:description>Comment: Postprint, ICSME 2016 proceedings</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10059</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Algorithm for Vertex Enumeration of Two-Dimensional
  Projection of Polytopes</dc:title>
 <dc:creator>Gurung, Amit</dc:creator>
 <dc:creator>Ray, Rajarshi</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  An efficient algorithm to enumerate the vertices of a two-dimensional (2D)
projection of a polytope, is presented in this paper. The proposed algorithm
uses the support function of the polytope to be projected and enumerated for
vertices. The complexity of our algorithm is linear in the number of vertices
of the projected polytope and we show empirically that the performance is
significantly better in comparison to some known efficient algorithms of
projection and enumeration.
</dc:description>
 <dc:description>Comment: 9 pages content, 10 figures</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10061</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Data Fusion System to Study Synchronization in Social Activities</dc:title>
 <dc:creator>Sevrin, Lo&#xef;c</dc:creator>
 <dc:creator>Massot, Bertrand</dc:creator>
 <dc:creator>Noury, Norbert</dc:creator>
 <dc:creator>Abouchi, Nacer</dc:creator>
 <dc:creator>Jumel, Fabrice</dc:creator>
 <dc:creator>Saraydaryan, Jacques</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  As the world population gets older, the healthcare system must be adapted,
among others by providing continuous health monitoring at home and in the city.
The social activities have a significant role in everyone health status. Hence,
this paper proposes a system to perform a data fusion of signals sampled on
several subjects during social activities. This study implies the time
synchronization of data coming from several sensors whether these are embedded
on people or integrated in the environment. The data fusion is applied to
several experiments including physical, cognitive and rest activities, with
social aspects. The simultaneous and continuous analysis of four subjects
cardiac activity and GPS coordinates provides a new way to distinguish
different collaborative activities comparing the measurements between the
subjects and along time.
</dc:description>
 <dc:description>Comment: Healthcom 2016</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10061</dc:identifier>
 <dc:identifier>doi:10.1109/HealthCom.2016.7749486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10068</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stateless Computation</dc:title>
 <dc:creator>Dolev, Danny</dc:creator>
 <dc:creator>Erdmann, Michael</dc:creator>
 <dc:creator>Lutz, Neil</dc:creator>
 <dc:creator>Schapira, Michael</dc:creator>
 <dc:creator>Zair, Adva</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present and explore a model of stateless and self-stabilizing distributed
computation, inspired by real-world applications such as routing on today's
Internet. Processors in our model do not have an internal state, but rather
interact by repeatedly mapping incoming messages (&quot;labels&quot;) to outgoing
messages and output values. While seemingly too restrictive to be of interest,
stateless computation encompasses both classical game-theoretic notions of
strategic interaction and a broad range of practical applications (e.g.,
Internet protocols, circuits, diffusion of technologies in social networks). We
embark on a holistic exploration of stateless computation. We tackle two
important questions: (1) Under what conditions is self-stabilization, i.e.,
guaranteed &quot;convergence&quot; to a &quot;legitimate&quot; global configuration, achievable for
stateless computation? and (2) What is the computational power of stateless
computation? Our results for self-stabilization include a general necessary
condition for self-stabilization and hardness results for verifying that a
stateless protocol is self-stabilizing. Our main results for the power of
stateless computation show that labels of logarithmic length in the number of
processors yield substantial computational power even on ring topologies. We
present a separation between unidirectional and bidirectional rings (L/poly vs.
P/poly), reflecting the sequential nature of computation on a unidirectional
ring, as opposed to the parallelism afforded by the bidirectional ring. We
leave the reader with many exciting directions for future research.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10076</identifier>
 <datestamp>2017-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Android Inter-App Communication Threats and Detection Techniques</dc:title>
 <dc:creator>Bhandari, Shweta</dc:creator>
 <dc:creator>Jaballah, Wafa Ben</dc:creator>
 <dc:creator>Jain, Vineeta</dc:creator>
 <dc:creator>Laxmi, Vijay</dc:creator>
 <dc:creator>Zemmari, Akka</dc:creator>
 <dc:creator>Gaur, Manoj Singh</dc:creator>
 <dc:creator>Mosbah, Mohamed</dc:creator>
 <dc:creator>Conti, Mauro</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  With the digital breakthrough, smart phones have become very essential
component. Mobile devices are very attractive attack surface for cyber thieves
as they hold personal details (accounts, locations, contacts, photos) and have
potential capabilities for eavesdropping (with cameras/microphone, wireless
connections). Android, being the most popular, is the target of malicious
hackers who are trying to use Android app as a tool to break into and control
device. Android malware authors use many anti-analysis techniques to hide from
analysis tools. Academic researchers and commercial anti-malware companies are
putting great effort to detect such malicious apps. They are making use of the
combinations of static, dynamic and behavior based analysis techniques. Despite
of all the security mechanisms provided by Android, apps can carry out
malicious actions through collusion. In collusion malicious functionality is
divided across multiple apps. Each participating app accomplish its part and
communicate information to another app through Inter Component Communication
(ICC). ICC do not require any special permissions. Also, there is no compulsion
to inform user about the communication. Each participating app needs to request
a minimal set of privileges, which may make it appear benign to current
state-of-the-art techniques that analyze one app at a time. There are many
surveys on app analysis techniques in Android; however they focus on single-app
analysis. This survey augments this through focusing only on collusion among
multiple-apps. In this paper, we present Android vulnerabilities that may be
exploited for a possible collusion attack. We cover the existing threat
analysis, scenarios, and a detailed comparison of tools for intra and inter-app
analysis. To the best of our knowledge this is the first survey on app
collusion and state-of-the-art detection tools in Android.
</dc:description>
 <dc:description>Comment: 83 pages, 4 figures, This is a survey paper</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10076</dc:identifier>
 <dc:identifier>computers &amp; security 70 (2017) 392-421</dc:identifier>
 <dc:identifier>doi:10.1016/j.cose.2017.07.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10078</identifier>
 <datestamp>2017-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to measure the topological quality of protein grammars?</dc:title>
 <dc:creator>Dyrka, Witold</dc:creator>
 <dc:creator>Coste, Fran&#xe7;ois</dc:creator>
 <dc:creator>Unold, Olgierd</dc:creator>
 <dc:creator>Culer, &#x141;ukasz</dc:creator>
 <dc:creator>Kaczmarek, Agnieszka</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:description>  Context-free and context-sensitive formal grammars are often regarded as more
appropriate to model proteins than regular level models such as finite state
automata and Hidden Markov Models. In theory, the claim is well founded in the
fact that many biologically relevant interactions between residues of protein
sequences have a character of nested or crossed dependencies. In practice,
there is hardly any evidence that grammars of higher expressiveness have an
edge over old good HMMs in typical applications including recognition and
classification of protein sequences. This is in contrast to RNA modeling, where
CFG power some of the most successful tools. There have been proposed several
explanations of this phenomenon. On the biology side, one difficulty is that
interactions in proteins are often less specific and more &quot;collective&quot; in
comparison to RNA. On the modeling side, a difficulty is the larger alphabet
which combined with high complexity of CF and CS grammars imposes considerable
trade-offs consisting on information reduction or learning sub-optimal
solutions. Indeed, some studies hinted that CF level of expressiveness brought
an added value in protein modeling when CF and regular grammars where
implemented in the same framework. However, there have been no systematic study
of explanatory power provided by various grammatical models. The first step to
this goal is define objective criteria of such evaluation. Intuitively, a
decent explanatory grammar should generate topology, or the parse tree,
consistent with topology of the protein, or its secondary and/or tertiary
structure. In this piece of research we build on this intuition and propose a
set of measures to compare topology of the parse tree of a grammar with
topology of the protein structure.
</dc:description>
 <dc:description>Comment: The 13th International Conference on Grammatical Inference (ICGI
  2016), Delft, The Netherlands, 5-7 Oct 2016</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10080</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wider or Deeper: Revisiting the ResNet Model for Visual Recognition</dc:title>
 <dc:creator>Wu, Zifeng</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Hengel, Anton van den</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The trend towards increasingly deep neural networks has been driven by a
general observation that increasing depth increases the performance of a
network. Recently, however, evidence has been amassing that simply increasing
depth may not be the best way to increase performance, particularly given other
limitations. Investigations into deep residual networks have also suggested
that they may not in fact be operating as a single deep network, but rather as
an ensemble of many relatively shallow networks. We examine these issues, and
in doing so arrive at a new interpretation of the unravelled view of deep
residual networks which explains some of the behaviours that have been observed
experimentally. As a result, we are able to derive a new, shallower,
architecture of residual networks which significantly outperforms much deeper
models such as ResNet-200 on the ImageNet classification dataset. We also show
that this performance is transferable to other problem domains by developing a
semantic segmentation approach which outperforms the state-of-the-art by a
remarkable margin on datasets including PASCAL VOC, PASCAL Context, and
Cityscapes. The architecture that we propose thus outperforms its comparators,
including very deep ResNets, and yet is more efficient in memory use and
sometimes also in training time. The code and models are available at
https://github.com/itijyou/ademxapp
</dc:description>
 <dc:description>Comment: Code available at: https://github.com/itijyou/ademxapp</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10087</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>1-out-of-2 Oblivious transfer using flawed Bit-string quantum protocol</dc:title>
 <dc:creator>Plesch, Martin</dc:creator>
 <dc:creator>Pawlowski, Marcin</dc:creator>
 <dc:creator>Pivoluska, Matej</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Oblivious transfer (OT) is an important tool in cryptography. It serves as a
subroutine to other complex procedures of both theoretical and practical
significance. Common attribute of OT protocols is that one party (Alice) has to
send a message to another party (Bob) and has to stay oblivious on whether Bob
did receive the message. Specific (OT) protocols vary by exact definition of
the task - in the all-or-nothing protocol Alice sends a single bit-string
message, which Bob is able to read only with 50% probability, whereas in
1-out-of-2 OT protocol Bob reads one out of two messages sent by Alice. These
two flavours of protocol are known to be equivalent. Recently a computationally
secure all-or-nothing OT protocol based on quantum states was developed in [A.
Souto et. al., PRA 91, 042306], which however cannot be reduced to 1-out-of-2
OT protocol by standard means. Here we present an elaborated reduction of this
protocol which retains the security of the original.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10087</dc:identifier>
 <dc:identifier>PRA 95, 042324 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevA.95.042324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10088</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Binary de Bruijn Sequences from LFSRs with Arbitrary Characteristic
  Polynomials</dc:title>
 <dc:creator>Chang, Zuling</dc:creator>
 <dc:creator>Ezerman, Martianus Frederic</dc:creator>
 <dc:creator>Ling, San</dc:creator>
 <dc:creator>Wang, Huaxiong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We propose a construction of de Bruijn sequences by the cycle joining method
from linear feedback shift registers (LFSRs) with arbitrary characteristic
polynomial $f(x)$. We study in detail the cycle structure of the set
$\Omega(f(x))$ that contains all sequences produced by a specific LFSR on
distinct inputs and provide an efficient way to find a state of each cycle. Our
structural results lead to an efficient algorithm to find all conjugate pairs
between any two cycles, yielding the adjacency graph. The approach provides a
practical method to generate a large class of de Bruijn sequences. Many
recently-proposed constructions of de Bruijn sequences are shown to be special
cases of our construction.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10094</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The influence of the network topology on the agility of a supply chain</dc:title>
 <dc:creator>Hern&#xe1;ndez, Juan M.</dc:creator>
 <dc:creator>Pedroza, Carmen</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The right performance of a supply chain depends on the pattern of
relationships among firms. Although there is not a general consensus among
researchers yet, many studies point that scale-free topologies, where few
highly related firms are combined with many low-related firms, assure the
highest efficiency of a supply chain. This paper studies the network topology
that leads to the highest agility of the supply chain when sudden demand
changes occur. To do this, an agent-based model of a supply chain with
restricted relationship between agents is built. The model includes three
tiers, where the flow of material is distributed from the bottom supplier to
the final customer passing necessarily through firms in every tier. Agility is
measured in the model simulations through the order fulfillment rate. Unlike to
previous theoretical and lab results, the simulation of the model shows that
the highest levels of agility are not obtained with a scale-free topology.
Instead, homogeneous distribution of links, such as those induced by regular or
Poisson probability laws, shows higher agility values than heterogeneous
distributions. Other previous recommendations, such as redundancy or having
multiple suppliers, are confirmed by the simulations. The general conclusion is
that the most suitable network topology in terms of agility depends on the
specific conditions of the supply chain and the aspects of the performance to
be analyzed.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10094</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10095</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>System-Generated Requests for Rewriting Proposals</dc:title>
 <dc:creator>di Fenizio, Pietro Speroni</dc:creator>
 <dc:creator>Velikanov, Cyril</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  We present an online deliberation system using mutual evaluation in order to
collaboratively develop solutions. Participants submit their proposals and
evaluate each other's proposals; some of them may then be invited by the system
to rewrite 'problematic' proposals. Two cases are discussed: a proposal
supported by many, but not by a given person, who is then invited to rewrite it
for making yet more acceptable; and a poorly presented but presumably
interesting proposal. The first of these cases has been successfully
implemented. Proposals are evaluated along two axes-understandability (or
clarity, or, more generally, quality), and agreement. The latter is used by the
system to cluster proposals according to their ideas, while the former is used
both to present the best proposals on top of their clusters, and to find poorly
written proposals candidates for rewriting. These functionalities may be
considered as important components of a large scale online deliberation system.
</dc:description>
 <dc:description>Comment: 9 pages, 1 figure, presented at e-Part 2011 conference</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10097</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ontologies for Privacy Requirements Engineering: A Systematic Literature
  Review</dc:title>
 <dc:creator>Gharib, Mohamad</dc:creator>
 <dc:creator>Giorgini, Paolo</dc:creator>
 <dc:creator>Mylopoulos, John</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Privacy has been frequently identified as a main concern for system
developers while dealing with/managing personal information. Despite this, most
existing work on privacy requirements deals with them as a special case of
security requirements. Therefore, key aspects of privacy are, usually,
overlooked. In this context, wrong design decisions might be made due to
insufficient understanding of privacy concerns. In this paper, we address this
problem with a systematic literature review whose main purpose is to identify
the main concepts/relations for capturing privacy requirements. In addition,
the identified concepts/relations are further analyzed to propose a novel
privacy ontology to be used by software engineers when dealing with privacy
requirements.
</dc:description>
 <dc:description>Comment: 74 pages</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10104</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User Dependent Features in Online Signature Verification</dc:title>
 <dc:creator>Guru, D. S.</dc:creator>
 <dc:creator>Manjunatha, K. S.</dc:creator>
 <dc:creator>Manjunath, S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel approach for verification of on-line
signatures based on user dependent feature selection and symbolic
representation. Unlike other signature verification methods, which work with
same features for all users, the proposed approach introduces the concept of
user dependent features. It exploits the typicality of each and every user to
select different features for different users. Initially all possible features
are extracted for all users and a method of feature selection is employed for
selecting user dependent features. The selected features are clustered using
Fuzzy C means algorithm. In order to preserve the intra-class variation within
each user, we recommend to represent each cluster in the form of an interval
valued symbolic feature vector. A method of signature verification based on the
proposed cluster based symbolic representation is also presented. Extensive
experimentations are conducted on MCYT-100 User (DB1) and MCYT-330 User (DB2)
online signature data sets to demonstrate the effectiveness of the proposed
novel approach.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10107</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private quantum computation: An introduction to blind quantum computing
  and related protocols</dc:title>
 <dc:creator>Fitzsimons, Joseph F.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Quantum technologies hold the promise of not only faster algorithmic
processing of data, via quantum computation, but also of more secure
communications, in the form of quantum cryptography. In recent years, a number
of protocols have emerged which seek to marry these concepts for the purpose of
securing computation rather than communication. These protocols address the
task of securely delegating quantum computation to an untrusted device while
maintaining the privacy, and in some instances the integrity, of the
computation. We present a review of the progress to date in this emerging area.
</dc:description>
 <dc:description>Comment: 14 pages, 8 figures. Comments welcome</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10120</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fusion of EEG and Musical Features in Continuous Music-emotion
  Recognition</dc:title>
 <dc:creator>Thammasan, Nattapong</dc:creator>
 <dc:creator>Fukui, Ken-ichi</dc:creator>
 <dc:creator>Numao, Masayuki</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Emotion estimation in music listening is confronting challenges to capture
the emotion variation of listeners. Recent years have witnessed attempts to
exploit multimodality fusing information from musical contents and
physiological signals captured from listeners to improve the performance of
emotion recognition. In this paper, we present a study of fusion of signals of
electroencephalogram (EEG), a tool to capture brainwaves at a high-temporal
resolution, and musical features at decision level in recognizing the
time-varying binary classes of arousal and valence. Our empirical results
showed that the fusion could outperform the performance of emotion recognition
using only EEG modality that was suffered from inter-subject variability, and
this suggested the promise of multimodal fusion in improving the accuracy of
music-emotion recognition.
</dc:description>
 <dc:description>Comment: The short version of this paper is accepted to appear as an abstract
  in the proceedings of AAAI-17 (student abstract and poster program)</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10122</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep encoding of etymological information in TEI</dc:title>
 <dc:creator>Bowers, Jack</dc:creator>
 <dc:creator>Romary, Laurent</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper aims to provide a comprehensive modeling and representation of
etymological data in digital dictionaries. The purpose is to integrate in one
coherent framework both digital representations of legacy dictionaries, and
also born-digital lexical databases that are constructed manually or
semi-automatically. We want to propose a systematic and coherent set of
modeling principles for a variety of etymological phenomena that may contribute
to the creation of a continuum between existing and future lexical constructs,
where anyone interested in tracing the history of words and their meanings will
be able to seamlessly query lexical resources.Instead of designing an ad hoc
model and representation language for digital etymological data, we will focus
on identifying all the possibilities offered by the TEI guidelines for the
representation of lexical information.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10130</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ADMM-based Fast Algorithm for Multi-group Multicast Beamforming in
  Large-Scale Wireless Systems</dc:title>
 <dc:creator>Chen, Erkai</dc:creator>
 <dc:creator>Tao, Meixia</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Multi-group multicast beamforming in wireless systems with large antenna
arrays and massive audience is investigated in this paper. Multicast
beamforming design is a well-known non-convex quadratically constrained
quadratic programming (QCQP) problem. A conventional method to tackle this
problem is to approximate it as a semi-definite programming problem via
semi-definite relaxation, whose performance, however, deteriorates considerably
as the number of per-group users goes large. A recent attempt is to apply
convex-concave procedure (CCP) to find a stationary solution by treating it as
a difference of convex programming problem, whose complexity, however,
increases dramatically as the problem size increases. In this paper, we propose
a low-complexity high-performance algorithm for multi-group multicast
beamforming design in large-scale wireless systems by leveraging the
alternating direction method of multipliers (ADMM) together with CCP. In
specific, the original non-convex QCQP problem is first approximated as a
sequence of convex subproblems via CCP. Each convex subproblem is then
reformulated as a novel ADMM form. Our ADMM reformulation enables that each
updating step is performed by solving multiple small-size subproblems with
closed-form solutions in parallel. Numerical results show that our fast
algorithm maintains the same favorable performance as state-of-the-art
algorithms but reduces the complexity by orders of magnitude.
</dc:description>
 <dc:description>Comment: This paper is to appear in IEEE Trans. on Communications</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10133</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rounds in a combinatorial search problem</dc:title>
 <dc:creator>Gerbner, D&#xe1;niel</dc:creator>
 <dc:creator>Vizer, M&#xe1;t&#xe9;</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the following combinatorial search problem: we are given some
excellent elements of $[n]$ and we should find at least one, asking questions
of the following type: &quot;Is there an excellent element in $A \subset [n]$?&quot;.
G.O.H. Katona proved sharp results for the number of questions needed to ask in
the adaptive, non-adaptive and two-round versions of this problem.
  We verify a conjecture of Katona by proving that in the $r$-round version we
need to ask $rn^{1/r}+O(1)$ queries for fixed $r$ and this is sharp.
  We also prove bounds for the queries needed to ask if we want to find at
least $d$ excellent elements.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10136</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Methods for Sparse Signal Reconstruction from Level Crossings</dc:title>
 <dc:creator>Mashhadi, Mahdi Boloursaz</dc:creator>
 <dc:creator>Marvasti, Farokh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter considers the problem of sparse signal reconstruction from the
timing of its Level Crossings (LC)s. We formulate the sparse Zero Crossing (ZC)
reconstruction problem in terms of a single 1-bit Compressive Sensing (CS)
model. We also extend the Smoothed L0 (SL0) sparse reconstruction algorithm to
the 1-bit CS framework and propose the Binary SL0 (BSL0) algorithm for
iterative reconstruction of the sparse signal from ZCs in cases where the
number of sparse coefficients is not known to the reconstruction algorithm a
priori. Similar to the ZC case, we propose a system of simultaneously
constrained signed-CS problems to reconstruct a sparse signal from its Level
Crossings (LC)s and modify both the Binary Iterative Hard Thresholding (BIHT)
and BSL0 algorithms to solve this problem. Simulation results demonstrate
superior performance of the proposed LC reconstruction techniques in comparison
with the literature.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Signal Processing Letters</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10146</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matching Multiplications in Bit-Vector Formulas</dc:title>
 <dc:creator>Chakraborty, Supratik</dc:creator>
 <dc:creator>Gupta, Ashutosh</dc:creator>
 <dc:creator>Jain, Rahul</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Bit-vector formulas arising from hardware verification problems often contain
word-level arithmetic operations. Empirical evidence shows that
state-of-the-art SMT solvers are not very efficient at reasoning about
bit-vector formulas with multiplication. This is particularly true when
multiplication operators are decomposed and represented in alternative ways in
the formula.We present a pre-processing heuristic that identifies certain types
of decomposed multipliers, and adds special assertions to the input formula
encoding the equivalence of sub-terms to word-level multiplication. The
pre-processed formulas are then solved using an SMT solver. Our experiments
with three SMT solvers show that our heuristic allows several formulas to be
solved quickly, while the same formulas time out without the pre-processing
step.
</dc:description>
 <dc:description>Comment: Accepted in VMCAI 2017</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2016-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10152</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Data-driven and Model-driven Methods for Robust Facial
  Landmark Detection</dc:title>
 <dc:creator>Zhang, Hongwen</dc:creator>
 <dc:creator>Li, Qi</dc:creator>
 <dc:creator>Sun, Zhenan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Facial landmark detection is an important but challenging task for real-world
computer vision applications. This paper proposes an accurate and robust
approach for facial landmark detection by combining data-driven and
model-driven methods. Firstly, a fully convolutional network (FCN) is trained
to generate response maps of all facial landmark points. Such a data-driven
method can make full use of holistic information in a facial image for global
estimation of facial landmarks. Secondly, the maximum points in the response
maps are fitted with a pre-trained point distribution model (PDM) to generate
initial facial landmark shape. Such a model-driven method can correct the
location errors of outliers by considering shape prior information. Thirdly, a
weighted version of Regularized Landmark Mean-Shift (RLMS) is proposed to
fine-tune facial landmark shapes iteratively. The weighting strategy is based
on the confidence of convolutional response maps so that FCN is integrated into
the framework of Constrained Local Model (CLM). Such an
Estimation-Correction-Tuning process perfectly combines the global robustness
advantage of data-driven method (FCN), outlier correction advantage of
model-driven method (PDM) and non-parametric optimization advantage of RLMS.
The experimental results demonstrate that the proposed approach outperforms
state-of-the-art solutions on the 300-W dataset. Our approach is well-suited
for face images with large poses, exaggerated expression, and occlusions.
</dc:description>
 <dc:description>Comment: Submitted to CVPR 2017</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10154</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Majoritarian Representative Voting System</dc:title>
 <dc:creator>di Fenizio, Pietro Speroni</dc:creator>
 <dc:creator>Gewurz, Daniele A.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We present an alternative voting system that aims at bridging the gap between
proportional representative systems and majoritarian, single winner election
systems. The system lets people vote for multiple parties, but then assigns
each ballot to a single party. This opens a whole range of possible systems,
all representative. We show theoretically that this space is convex. Then among
the possible parliaments we present an algorithm to produce the most
majoritarian result. We then test the system and compare the results with a
pure proportional and a majoritarian voting system showing how the results are
comparable with the majoritarian system. Then we simulate the system and show
how it tends to produce parties of exponentially decreasing size with always a
first, major party. Finally we describe how the system can be used in a context
of a parliament made up of two separate houses.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures, was presented at the 2016 Computational Social
  Choice (COMSOC) Workshop</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10159</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bridges in Complex Networks</dc:title>
 <dc:creator>Wu, Ang-Kun</dc:creator>
 <dc:creator>Tian, Liang</dc:creator>
 <dc:creator>Liu, Yang-Yu</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  A bridge in a graph is an edge whose removal disconnects the graph and
increases the number of connected components. We calculate the fraction of
bridges in a wide range of real-world networks and their randomized
counterparts. We find that real networks typically have more bridges than their
completely randomized counterparts, but very similar fraction of bridges as
their degree-preserving randomizations. We define a new edge centrality
measure, called bridgeness, to quantify the importance of a bridge in damaging
a network. We find that certain real networks have very large average and
variance of bridgeness compared to their degree-preserving randomizations and
other real networks. Finally, we offer an analytical framework to calculate the
bridge fraction , the average and variance of bridgeness for uncorrelated
random networks with arbitrary degree distributions.
</dc:description>
 <dc:description>Comment: 18 pages, 10 figures</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10159</dc:identifier>
 <dc:identifier>Phys. Rev. E 97, 012307 (2018)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.97.012307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10160</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Students Choose to Use Event-B in their Software Engineering
  Projects</dc:title>
 <dc:creator>Gibson, Paul</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  Students often learn formal methods as part of a software engineering degree
programme, without applying these formal methods outside of the specific
module(s) dedicated to this subject. In particular, software engineering
students often have to build a significant application/program/system in a
substantial project at the end of their programme (in order to demonstrate the
application of the things they have learned during the previous taught
modules). Our experience shows that the majority of students do not use formal
methods in this project work. We report on feedback from the minority of
students who did choose to use formal methods in their projects, and give
examples of where this was a help and where it was a hindrance.
</dc:description>
 <dc:description>Comment: Event-B day 2016, Tokyo</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10161</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sovereignty of the Apps: There's more to Relevance than Downloads</dc:title>
 <dc:creator>Sigg, Stephan</dc:creator>
 <dc:creator>Lagerspetz, Eemil</dc:creator>
 <dc:creator>Peltonen, Ella</dc:creator>
 <dc:creator>Nurmi, Petteri</dc:creator>
 <dc:creator>Tarkoma, Sasu</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The value of mobile apps is traditionally measured by metrics such as the
number of downloads, installations, or user ratings. A problem with these
measures is that they reflect actual usage at most indirectly. Indeed, analytic
companies have suggested that retention rates, i.e., the number of days users
continue to interact with an installed app are low. We conduct the first
independent and large-scale study of retention rates and usage behavior trends
in the wild. We study their impact on a large-scale database of app-usage data
from a community of 339,842 users and more than 213,667 apps. Our analysis
shows that, on average, applications lose 70% of their users in the first week,
while very popular applications (top 100) lose only 45%. It also reveals,
however, that many applications have more complex usage behavior patterns due
to seasonality, marketing, or other factors. To capture such effects, we
develop a novel app-usage behavior trend measure which provides instantaneous
information about the &quot;hotness&quot; of an application. We identify typical trends
in app popularity and classify applications into archetypes. From these, we can
distinguish, for instance, trendsetters from copycat apps. In our results,
roughly 40% of all apps never gain more than a handful of users. Less than 0.4%
of the remaining 60% are constantly popular, 1% flop after an initial steep
rise, and 7% continuously rise in popularity. We conclude by demonstrating that
usage behavior trend information can be used to develop better mobile app
recommendations. With the proposed usage-based measures (retention and trend),
we are able to shift sovereignty in app recommendations back to where it really
matters: actual usage statistics, in contrast to download count and user
ratings which are prone to manipulation by people.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10162</identifier>
 <datestamp>2017-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting the Category and Attributes of Visual Search Targets Using
  Deep Gaze Pooling</dc:title>
 <dc:creator>Sattar, Hosnieh</dc:creator>
 <dc:creator>Bulling, Andreas</dc:creator>
 <dc:creator>Fritz, Mario</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Predicting the target of visual search from eye fixation (gaze) data is a
challenging problem with many applications in human-computer interaction. In
contrast to previous work that has focused on individual instances as a search
target, we propose the first approach to predict categories and attributes of
search targets based on gaze data. However, state of the art models for
categorical recognition, in general, require large amounts of training data,
which is prohibitive for gaze data. To address this challenge, we propose a
novel Gaze Pooling Layer that integrates gaze information into CNN-based
architectures as an attention mechanism - incorporating both spatial and
temporal aspects of human gaze behavior. We show that our approach is effective
even when the gaze pooling layer is added to an already trained CNN, thus
eliminating the need for expensive joint data collection of visual and gaze
data. We propose an experimental setup and data set and demonstrate the
effectiveness of our method for search target prediction based on gaze
behavior. We further study how to integrate temporal and spatial gaze
information most effectively, and indicate directions for future research in
the gaze-based prediction of mental states.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10169</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Links between the personalities, styles and performance in computer
  programming</dc:title>
 <dc:creator>Karimia, Zahra</dc:creator>
 <dc:creator>Baraani-Dastjerdia, Ahmad</dc:creator>
 <dc:creator>Ghasem-Aghaeea, Nasser</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  There are repetitive patterns in strategies of manipulating source code. For
example, modifying source code before acquiring knowledge of how a code works
is a depth-first style and reading and understanding before modifying source
code is a breadth-first style. To the extent we know there is no study on the
influence of personality on them. The objective of this study is to understand
the influence of personality on programming styles. We did a correlational
study with 65 programmers at the University of Stuttgart. Academic achievement,
programming experience, attitude towards programming and five personality
factors were measured via self-assessed survey. The programming styles were
asked in the survey or mined from the software repositories. Performance in
programming was composed of bug-proneness of programmers which was mined from
software repositories, the grades they got in a software project course and
their estimate of their own programming ability. We did statistical analysis
and found that Openness to Experience has a positive association with
breadth-first style and Conscientiousness has a positive association with
depth-first style. We also found that in addition to having more programming
experience and better academic achievement, the styles of working depth-first
and saving coarse-grained revisions improve performance in programming.
</dc:description>
 <dc:description>Comment: 27 pages, 6 figures</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10169</dc:identifier>
 <dc:identifier>Journal of Systems and Software, Volume 111, January 2016, Pages
  228-241</dc:identifier>
 <dc:identifier>doi:10.1016/j.jss.2015.09.011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10176</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective Quantization Methods for Recurrent Neural Networks</dc:title>
 <dc:creator>He, Qinyao</dc:creator>
 <dc:creator>Wen, He</dc:creator>
 <dc:creator>Zhou, Shuchang</dc:creator>
 <dc:creator>Wu, Yuxin</dc:creator>
 <dc:creator>Yao, Cong</dc:creator>
 <dc:creator>Zhou, Xinyu</dc:creator>
 <dc:creator>Zou, Yuheng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Reducing bit-widths of weights, activations, and gradients of a Neural
Network can shrink its storage size and memory usage, and also allow for faster
training and inference by exploiting bitwise operations. However, previous
attempts for quantization of RNNs show considerable performance degradation
when using low bit-width weights and activations. In this paper, we propose
methods to quantize the structure of gates and interlinks in LSTM and GRU
cells. In addition, we propose balanced quantization methods for weights to
further reduce performance degradation. Experiments on PTB and IMDB datasets
confirm effectiveness of our methods as performances of our models match or
surpass the previous state-of-the-art of quantized RNN.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10181</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bayesian Network Approach to Assess and Predict Software Quality Using
  Activity-Based Quality Models</dc:title>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Context: Software quality is a complex concept. Therefore, assessing and
predicting it is still challenging in practice as well as in research.
Activity-based quality models break down this complex concept into concrete
definitions, more precisely facts about the system, process, and environment as
well as their impact on activities performed on and with the system. However,
these models lack an operationalisation that would allow them to be used in
assessment and prediction of quality. Bayesian networks have been shown to be a
viable means for this task incorporating variables with uncertainty. Objective:
The qualitative knowledge contained in activity-based quality models are an
abundant basis for building Bayesian networks for quality assessment. This
paper describes a four-step approach for deriving systematically a Bayesian
network from an assessment goal and a quality model. Method: The four steps of
the approach are explained in detail and with running examples. Furthermore, an
initial evaluation is performed, in which data from NASA projects and an open
source system is obtained. The approach is applied to this data and its
applicability is analysed. Results: The approach is applicable to the data from
the NASA projects and the open source system. However, the predictive results
vary depending on the availability and quality of the data, especially the
underlying general distributions. Conclusion: The approach is viable in a
realistic context but needs further investigation in case studies in order to
analyse its predictive validity.
</dc:description>
 <dc:description>Comment: 32 pages, 6 figures</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10181</dc:identifier>
 <dc:identifier>Information and Software Technology, Volume 52, Issue 11, November
  2010, Pages 1230-1241</dc:identifier>
 <dc:identifier>doi:10.1016/j.infsof.2010.03.016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10182</identifier>
 <datestamp>2016-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deriving a Generalized, Actuator Position-Independent Expression for the
  Force Output of a Scissor Lift</dc:title>
 <dc:creator>Saxena, Amay</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Scissor lifts, a staple of mechanical design, especially in competitive
robotics, are a type of linkage that can be used to raise a load to some
height, when acted upon by some force, usually exerted by an actuator. The
position of this actuator, however, can affect the mechanical advantage and
velocity ratio of the system. Hence, there needs to be a concrete way to
analytically compare different actuator positions. However, all current
research into the analysis of scissor lifts either focusses only on the screw
jack configuration, or derives separate force expressions for different
actuator positions. This, once again, leaves the decision between different
actuator positions to trial and error, since the expression to test the potency
of the position can only be derived once the position is chosen. This paper
proposes a derivation for a general force expression, in terms of a few
carefully chosen position variables, which can be used to generate the force
expression for any actuator position. Hence, this expression illustrates
exactly how each of the position variables (called a, b and i in this paper, as
defined later) affect the force output, and hence can be used to pick an
appropriate actuator position, by choosing values for the position variables
that give the desired result.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2016-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10187</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bayesian Network Approach to Assess and Predict Software Quality Using
  Activity-Based Quality Models (Conference Version)</dc:title>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.8</dc:subject>
 <dc:subject>D.2.9</dc:subject>
 <dc:description>  Assessing and predicting the complex concept of software quality is still
challenging in practice as well as research. Activity-based quality models
break down this complex con- cept into more concrete definitions, more
precisely facts about the system, process and environment and their impact on
ac- tivities performed on and with the system. However, these models lack an
operationalisation that allows to use them in assessment and prediction of
quality. Bayesian Networks (BN) have been shown to be a viable means for
assessment and prediction incorporating variables with uncertainty. This paper
describes how activity-based quality models can be used to derive BN models for
quality assessment and pre- diction. The proposed approach is demonstrated in a
proof of concept using publicly available data.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10187</dc:identifier>
 <dc:identifier>Proceedings of the 5th International Conference on Predictor
  Models in Software Engineering (PROMISE '09). ACM, 2009</dc:identifier>
 <dc:identifier>doi:10.1145/1540438.1540447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10191</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is Non-Neutrality Profitable for the Stakeholders of the Internet
  Market? - Part I</dc:title>
 <dc:creator>Lotfi, Mohammad Hassan</dc:creator>
 <dc:creator>Sarkar, Saswati</dc:creator>
 <dc:creator>Kesidis, George</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Net neutrality on the Internet is perceived as the policy that mandates
Internet Service Providers (ISPs) to treat all data equally, regardless of the
source, destination, or type of transmitted data. In this work, we consider a
scheme in which the decision makers of the market are two ISPs, one ``big&quot;
Content Provider (CP), and a continuum of end-users. One of the ISPs is neutral
and the other is non-neutral, i.e. she offers a premium quality to a CP in
exchange for a side-payment. In addition, we assume that the CP can
differentiate between ISPs by controlling the quality of the content she is
offering on each one. In this part of the paper, we consider a scenario in
which end-users are not locked in with the ISPs and can switch between ISPs
easily. We formulate a sequential game, and show that there exists a unique
Sub-game Perfect Nash Equilibrium (SPNE) for the game, where the CP pays the
side-payment to the non-neutral ISP and offers her content with the premium
quality. In addition, the CP does not offer her content on the neutral ISP.
Thus, driving this ISP out of the market.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transaction on Networking, split into 2 parts at
  the requirement of the journal</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10195</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>POSEidon: Face-from-Depth for Driver Pose Estimation</dc:title>
 <dc:creator>Borghi, Guido</dc:creator>
 <dc:creator>Venturelli, Marco</dc:creator>
 <dc:creator>Vezzani, Roberto</dc:creator>
 <dc:creator>Cucchiara, Rita</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Fast and accurate upper-body and head pose estimation is a key task for
automatic monitoring of driver attention, a challenging context characterized
by severe illumination changes, occlusions and extreme poses. In this work, we
present a new deep learning framework for head localization and pose estimation
on depth images. The core of the proposal is a regression neural network,
called POSEidon, which is composed of three independent convolutional nets
followed by a fusion layer, specially conceived for understanding the pose by
depth. In addition, to recover the intrinsic value of face appearance for
understanding head position and orientation, we propose a new Face-from-Depth
approach for learning image faces from depth. Results in face reconstruction
are qualitatively impressive. We test the proposed framework on two public
datasets, namely Biwi Kinect Head Pose and ICT-3DHP, and on Pandora, a new
challenging dataset mainly inspired by the automotive setup. Results show that
our method overcomes all recent state-of-art works, running in real time at
more than 30 frames per second.
</dc:description>
 <dc:description>Comment: Accepted in Computer Vision and Pattern Recognition (CVPR 2017)</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10204</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison of Multi Criteria Decision Making Algorithms for Ranking
  Cloud Renderfarm Services</dc:title>
 <dc:creator>Ruby, Annette J</dc:creator>
 <dc:creator>Aisha, Banu W</dc:creator>
 <dc:creator>Subash, Chandran P</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Cloud services that provide a complete environment for the animators to
render their files using the resources in the cloud are called Cloud Renderfarm
Services. The objective of this work is to rank and compare the performance of
these services using two popular Multi Criteria Decision Making (MCDM)
Algorithms namely the Analytical Hierarchical Processing (AHP) and SAW (Simple
Additive Weighting) methods. The performance of three real time cloud
renderfarm services are ranked and compared based on five Quality of Service
(QoS) attributes that are important to these services namely the Render Node
Cost, File Upload Time, Availability, Elasticity and Service Response Time. The
performance of these cloud renderfarm services are ranked in four different
simulations by varying the weights assigned for each QoS attribute and the
ranking obtained are compared. The results show that AHP and SAW assigned
similar ranks to all three cloud renderfarm services for all simulations.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10204</dc:identifier>
 <dc:identifier>Indian Journal of Science and Technology, Vol. 9, No.31, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10208</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Search-and-Fetch with 2 Robots on a Disk: Wireless and Face-to-Face
  Communication Models</dc:title>
 <dc:creator>Georgiou, Konstantinos</dc:creator>
 <dc:creator>Karakostas, George</dc:creator>
 <dc:creator>Kranakis, Evangelos</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We initiate the study of a new problem on {\em searching and fetching} in a
distributed environment concerning \emph{treasure-evacuation} from a unit disk.
A treasure and an exit are located at unknown positions on the perimeter of a
disk and at known arc distance. A team of two robots start from the center of
the disk, and their goal is to fetch the treasure to the exit. At any time the
robots can move anywhere they choose on the disk, independently of each other,
with the same speed. A robot detects an interesting point (treasure or exit)
only if it passes over the exact location of that point. We are interested in
designing distributed algorithms that minimize the worst-case
treasure-evacuation time, i.e. the time it takes for the treasure to be
discovered and brought (fetched) to the exit by any of the robots.
  The communication protocol between the robots is either {\em wireless}, where
information is shared at any time, or {\em face-to-face} (i.e. non-wireless),
where information can be shared only if the robots meet. For both models we
obtain upper bounds for fetching the treasure to the exit. Our main technical
contribution pertains to the face-to-face model. More specifically, we
demonstrate how robots can exchange information without meeting, effectively
achieving a highly efficient treasure-evacuation protocol which is minimally
affected by the lack of distant communication. Finally, we complement our
positive results above by providing a lower bound in the face-to-face model.
</dc:description>
 <dc:description>Comment: 23 Pages, 7 Figures. This is the full version of the paper with the
  same title which will appear in the proceedings of the 6th International
  Conference on Operations Research and Enterprise Systems (ICORES), February
  23-25, 2017, Porto, Portugal</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10210</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RenderSelect: a Cloud Broker Framework for Cloud Renderfarm Services</dc:title>
 <dc:creator>Ruby, Annette J</dc:creator>
 <dc:creator>Aisha, Banu W</dc:creator>
 <dc:creator>Subash, Chandran P</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In the 3D studios the animation scene files undergo a process called as
rendering, where the 3D wire frame models are converted into 3D photorealistic
images. As the rendering process is both a computationally intensive and a time
consuming task, the cloud services based rendering in cloud render farms is
gaining popularity among the animators. Though cloud render farms offer many
benefits, the animators hesitate to move from their traditional offline
rendering to cloud services based render farms as they lack the knowledge,
expertise and the time to compare the render farm service providers based on
the Quality of Service (QoS) offered by them, negotiate the QoS and monitor
whether the agreed upon QoS is actually offered by the renderfarm service
providers. In this paper we propose a Cloud Service Broker (CSB) framework
called the RenderSelect that helps in the dynamic ranking, selection,
negotiation and monitoring of the cloud based render farm services. The cloud
services based renderfarms are ranked and selected services based on multi
criteria QoS requirements. Analytical Hierarchical Process (AHP), the popular
Multi Criteria Decision Making (MCDM) method is used for ranking and selecting
the cloud services based renderfarms. The AHP method of ranking is illustrated
in detail with an example. It could be verified that AHP method ranks the cloud
services effectively with less time and complexity.
</dc:description>
 <dc:description>Comment: 13 pages, 10 figures</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10210</dc:identifier>
 <dc:identifier>International Journal of Applied Engineering Research ,Vol.10,
  No.20 ,2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10211</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bandlimited Field Reconstruction from Samples Obtained at Unknown Random
  Locations on a Grid</dc:title>
 <dc:creator>Mallick, Ankur</dc:creator>
 <dc:creator>Kumar, Animesh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the sampling of spatial fields using sensors that are
location-unaware but deployed according to a known statistical distribution. It
has been shown that uniformly distributed location-unaware sensors cannot infer
bandlimited fields due to the symmetry and shift-invariance of the field.
  This work studies asymmetric (nonuniform) distributions on location-unaware
sensors that will enable bandlimited field inference. For the sake of
analytical tractability, location-unaware sensors are restricted to a discrete
grid. Oversampling followed by clustering of the samples using the probability
distribution that governs sensor placement on the grid is used to infer the
field . Based on this clustering algorithm, the main result of this work is to
find the optimal probability distribution on sensor locations that minimizes
the detection error-probability of the underlying spatial field. The proposed
clustering algorithm is also extended to include the case of signal
reconstruction in the presence of sensor noise by treating the distribution of
the noisy samples as a mixture model and using clustering to estimate the
mixture model parameters.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures, submitted to IEEE Trans on Signal Processing for
  review</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10212</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Determinizing Monitors for HML with Recursion</dc:title>
 <dc:creator>Aceto, Luca</dc:creator>
 <dc:creator>Achilleos, Antonis</dc:creator>
 <dc:creator>Francalanza, Adrian</dc:creator>
 <dc:creator>Ing&#xf3;lfsd&#xf3;ttir, Anna</dc:creator>
 <dc:creator>Kjartansson, S&#xe6;var &#xd6;rn</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We examine the determinization of monitors for HML with recursion. We
demonstrate that every monitor is equivalent to a deterministic one, which is
at most doubly exponential in size with respect to the original monitor. When
monitors are described as CCS-like processes, this doubly exponential bound is
optimal. When (deterministic) monitors are described as finite automata (as
their LTS), then they can be exponentially more succinct than their CCS process
form.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10215</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unit Commitment using Nearest Neighbor as a Short-Term Proxy</dc:title>
 <dc:creator>Dalal, Gal</dc:creator>
 <dc:creator>Gilboa, Elad</dc:creator>
 <dc:creator>Mannor, Shie</dc:creator>
 <dc:creator>Wehenkel, Louis</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We devise the Unit Commitment Nearest Neighbor (UCNN) algorithm to be used as
a proxy for quickly approximating outcomes of short-term decisions, to make
tractable hierarchical long-term assessment and planning for large power
systems. Experimental results on an updated versions of IEEE-RTS79 and
IEEE-RTS96 show high accuracy measured on operational cost, achieved in
run-times that are lower in several orders of magnitude than the traditional
approach.
</dc:description>
 <dc:description>Comment: Package contains both original article, and its supplementary
  material, in two separate files</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10228</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Behavior-Based Machine-Learning: A Hybrid Approach for Predicting Human
  Decision Making</dc:title>
 <dc:creator>Noti, Gali</dc:creator>
 <dc:creator>Levi, Effi</dc:creator>
 <dc:creator>Kolumbus, Yoav</dc:creator>
 <dc:creator>Daniely, Amit</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:description>  A large body of work in behavioral fields attempts to develop models that
describe the way people, as opposed to rational agents, make decisions. A
recent Choice Prediction Competition (2015) challenged researchers to suggest a
model that captures 14 classic choice biases and can predict human decisions
under risk and ambiguity. The competition focused on simple decision problems,
in which human subjects were asked to repeatedly choose between two gamble
options.
  In this paper we present our approach for predicting human decision behavior:
we suggest to use machine learning algorithms with features that are based on
well-established behavioral theories. The basic idea is that these
psychological features are essential for the representation of the data and are
important for the success of the learning process. We implement a vanilla model
in which we train SVM models using behavioral features that rely on the
psychological properties underlying the competition baseline model. We show
that this basic model captures the 14 choice biases and outperforms all the
other learning-based models in the competition. The preliminary results suggest
that such hybrid models can significantly improve the prediction of human
decision making, and are a promising direction for future research.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10229</identifier>
 <datestamp>2017-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Training of Hybrid CNN-CRF Models for Stereo</dc:title>
 <dc:creator>Kn&#xf6;belreiter, Patrick</dc:creator>
 <dc:creator>Reinbacher, Christian</dc:creator>
 <dc:creator>Shekhovtsov, Alexander</dc:creator>
 <dc:creator>Pock, Thomas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel and principled hybrid CNN+CRF model for stereo estimation.
Our model allows to exploit the advantages of both, convolutional neural
networks (CNNs) and conditional random fields (CRFs) in an unified approach.
The CNNs compute expressive features for matching and distinctive color edges,
which in turn are used to compute the unary and binary costs of the CRF. For
inference, we apply a recently proposed highly parallel dual block descent
algorithm which only needs a small fixed number of iterations to compute a
high-quality approximate minimizer. As the main contribution of the paper, we
propose a theoretically sound method based on the structured output support
vector machine (SSVM) to train the hybrid CNN+CRF model on large-scale data
end-to-end. Our trained models perform very well despite the fact that we are
using shallow CNNs and do not apply any kind of post-processing to the final
output of the CRF. We evaluate our combined models on challenging stereo
benchmarks such as Middlebury 2014 and Kitti 2015 and also investigate the
performance of each individual component.
</dc:description>
 <dc:description>Comment: To appear at CVPR 2017</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10231</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Android Code Protection via Obfuscation Techniques: Past, Present and
  Future Directions</dc:title>
 <dc:creator>Faruki, Parvez</dc:creator>
 <dc:creator>Fereidooni, Hossein</dc:creator>
 <dc:creator>Laxmi, Vijay</dc:creator>
 <dc:creator>Conti, Mauro</dc:creator>
 <dc:creator>and</dc:creator>
 <dc:creator>Gaur, Manoj</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Mobile devices have become ubiquitous due to centralization of private user
information, contacts, messages and multiple sensors. Google Android, an
open-source mobile Operating System (OS), is currently the market leader.
Android popularity has motivated the malware authors to employ set of cyber
attacks leveraging code obfuscation techniques. Obfuscation is an action that
modifies an application (app) code, preserving the original semantics and
functionality to evade anti-malware. Code obfuscation is a contentious issue.
Theoretical code analysis techniques indicate that, attaining a verifiable and
secure obfuscation is impossible. However, obfuscation tools and techniques are
popular both among malware developers (to evade anti-malware) and commercial
software developers (protect intellectual rights). We conducted a survey to
uncover answers to concrete and relevant questions concerning Android code
obfuscation and protection techniques. The purpose of this paper is to review
code obfuscation and code protection practices, and evaluate efficacy of
existing code de-obfuscation tools. In particular, we discuss Android code
obfuscation methods, custom app protection techniques, and various
de-obfuscation methods. Furthermore, we review and analyse the obfuscation
techniques used by malware authors to evade analysis efforts. We believe that,
there is a need to investigate efficiency of the defense techniques used for
code protection. This survey would be beneficial to the researchers and
practitioners, to understand obfuscation and de-obfuscation techniques to
propose novel solutions on Android.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10248</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assessing pattern recognition or labeling in streams of temporal data</dc:title>
 <dc:creator>Marteau, Pierre-Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In the data deluge context, pattern recognition or labeling in streams is
becoming quite an essential and pressing task as data flows inside always
bigger streams. The assessment of such tasks is not so easy when dealing with
temporal data, namely patterns that have a duration (a beginning and an end
time-stamp). This paper details an approach based on an editing distance to
first align a sequence of labeled temporal segments with a ground truth
sequence, and then, by back-tracing an optimal alignment path, to provide a
confusion matrix at the label level. From this confusion matrix, standard
evaluation measures can easily be derived as well as other measures such as the
&quot;latency&quot; that can be quite important in (early) pattern detection
applications.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10248</dc:identifier>
 <dc:identifier>2nd ECML/PKDD Workshop on Advanced Analytics and Learning on
  Temporal Data, Sep 2016, Riva del Garda, Italy. 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10252</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SeDMiD for Confusion Detection: Uncovering Mind State from Time Series
  Brain Wave Data</dc:title>
 <dc:creator>Yang, Jingkang</dc:creator>
 <dc:creator>Wang, Haohan</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:creator>Xing, Eric P.</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Understanding how brain functions has been an intriguing topic for years.
With the recent progress on collecting massive data and developing advanced
technology, people have become interested in addressing the challenge of
decoding brain wave data into meaningful mind states, with many machine
learning models and algorithms being revisited and developed, especially the
ones that handle time series data because of the nature of brain waves.
However, many of these time series models, like HMM with hidden state in
discrete space or State Space Model with hidden state in continuous space, only
work with one source of data and cannot handle different sources of information
simultaneously. In this paper, we propose an extension of State Space Model to
work with different sources of information together with its learning and
inference algorithms. We apply this model to decode the mind state of students
during lectures based on their brain waves and reach a significant better
results compared to traditional methods.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures, NIPS 2016 Time Series Workshop</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10253</identifier>
 <datestamp>2017-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Radio Resource Management in 5G Networks: Framework,
  Opportunities and Challenges</dc:title>
 <dc:creator>Calabrese, Francesco Davide</dc:creator>
 <dc:creator>Wang, Li</dc:creator>
 <dc:creator>Ghadimi, Euhanna</dc:creator>
 <dc:creator>Peters, Gunnar</dc:creator>
 <dc:creator>Soldati, Pablo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  With the fifth generation (5G) of mobile broadband systems, Radio Resources
Management (RRM) will reach unprecedented levels of complexity. To cope with
the higher complexity of RRM functionalities, while retaining the fast
execution required in 5G, this manuscript presents a lean 5G RRM architecture
that capitalizes on the most recent advances in the field of machine learning
in combination with the large amount of data readily available in the network
from measurements and system observations. The result is a general-purpose
learning framework capable of generating algorithms specialized to RRM
functionalities directly from data gathered in the network. The potential of
this approach is verified in three study cases and future directions on
applications of machine learning to RRM are discussed.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10258</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reliably Learning the ReLU in Polynomial Time</dc:title>
 <dc:creator>Goel, Surbhi</dc:creator>
 <dc:creator>Kanade, Varun</dc:creator>
 <dc:creator>Klivans, Adam</dc:creator>
 <dc:creator>Thaler, Justin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We give the first dimension-efficient algorithms for learning Rectified
Linear Units (ReLUs), which are functions of the form $\mathbf{x} \mapsto
\max(0, \mathbf{w} \cdot \mathbf{x})$ with $\mathbf{w} \in \mathbb{S}^{n-1}$.
Our algorithm works in the challenging Reliable Agnostic learning model of
Kalai, Kanade, and Mansour (2009) where the learner is given access to a
distribution $\cal{D}$ on labeled examples but the labeling may be arbitrary.
We construct a hypothesis that simultaneously minimizes the false-positive rate
and the loss on inputs given positive labels by $\cal{D}$, for any convex,
bounded, and Lipschitz loss function.
  The algorithm runs in polynomial-time (in $n$) with respect to any
distribution on $\mathbb{S}^{n-1}$ (the unit sphere in $n$ dimensions) and for
any error parameter $\epsilon = \Omega(1/\log n)$ (this yields a PTAS for a
question raised by F. Bach on the complexity of maximizing ReLUs). These
results are in contrast to known efficient algorithms for reliably learning
linear threshold functions, where $\epsilon$ must be $\Omega(1)$ and strong
assumptions are required on the marginal distribution. We can compose our
results to obtain the first set of efficient algorithms for learning
constant-depth networks of ReLUs.
  Our techniques combine kernel methods and polynomial approximations with a
&quot;dual-loss&quot; approach to convex programming. As a byproduct we obtain a number
of applications including the first set of efficient algorithms for &quot;convex
piecewise-linear fitting&quot; and the first efficient algorithms for noisy
polynomial reconstruction of low-weight polynomials on the unit sphere.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10259</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Oriented Bipartite Graphs and the Goldbach Graph</dc:title>
 <dc:creator>Das, Sandip</dc:creator>
 <dc:creator>Ghosh, Shamik</dc:creator>
 <dc:creator>Ghosh, Prantar</dc:creator>
 <dc:creator>Sen, Sagnik</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>05C20, 05C63, 11A41</dc:subject>
 <dc:description>  In this paper we study oriented bipartite graphs. In particular, several
characterizations of bitournaments are obtained. We introduce the concept of
odd-even graphs and show that any (oriented) bipartite graph can be represented
by some (oriented) odd-even graph. We show that the famous Goldbach's
conjecture is equivalent to the connectedness of certain odd-even graphs.
</dc:description>
 <dc:description>Comment: 14 pages, 3 figures, 1 table</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10268</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum Likelihood Criteria for Binary Asymmetric Channels</dc:title>
 <dc:creator>Qureshi, Claudio</dc:creator>
 <dc:creator>Costa, Sueli I. R.</dc:creator>
 <dc:creator>Rodrigues, Christiane B.</dc:creator>
 <dc:creator>Firer, Marcelo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work concerns with the $n$-fold binary asymmetric channels
($\mbox{BAC}^n$). An equivalence relation between two channels can be
characterized by both having the same decision criterion when maximum
likelihood is considered. We introduce here a function $\mathcal{S}$ (the
BAC-function) such that the parameters $(p,q)$ of the binary channel which
determine equivalent channels belong to certain region delimited by its level
curves. Explicit equations determining these regions are given and the number
of different $\mbox{BAC}^{n}$ classes is determined. A discusion on the size of
these regions is also presented.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10270</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum a posteriori learning in demand competition games</dc:title>
 <dc:creator>Rakhshan, Mohsen</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider an inventory competition game between two firms. The question we
address is this: If players do not know the opponent's action and opponent's
utility function can they learn to play the Nash policy in a repeated game by
observing their own sales? In this work it is proven that by means of Maximum A
Posteriori (MAP) estimation, players can learn the Nash policy. It is proven
that players' actions and beliefs do converge to the Nash equilibrium.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10276</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some Subclasses of Linear Languages based on Nondeterministic Linear
  Automata</dc:title>
 <dc:creator>Bedregal, Benjam&#xed;n</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  In this paper we consider the class of lambda-nondeterministic linear
automata as a model of the class of linear languages. As usual in other
automata models, lambda-moves do not increase the acceptance power. The main
contribution of this paper is to introduce the deterministic linear automata
and even linear automata, i.e. the natural restriction of nondeterministic
linear automata for the deterministic and even linear language classes,
respectively. In particular, there are different, but not equivalents,
proposals for the class of &quot;deterministic&quot; linear languages. We proved here
that the class of languages accepted by the deterministic linear automata are
not contained in any of the these classes and in fact they properly contain
these classes. Another, contribution is the generation of an infinite hierarchy
of formal languages, going from the class of languages accepted by
deterministic linear automata and achieved, in the limit, the class of linear
languages.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10277</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anchored Correlation Explanation: Topic Modeling with Minimal Domain
  Knowledge</dc:title>
 <dc:creator>Gallagher, Ryan J.</dc:creator>
 <dc:creator>Reing, Kyle</dc:creator>
 <dc:creator>Kale, David</dc:creator>
 <dc:creator>Steeg, Greg Ver</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  While generative models such as Latent Dirichlet Allocation (LDA) have proven
fruitful in topic modeling, they often require detailed assumptions and careful
specification of hyperparameters. Such model complexity issues only compound
when trying to generalize generative models to incorporate human input. We
introduce Correlation Explanation (CorEx), an alternative approach to topic
modeling that does not assume an underlying generative model, and instead
learns maximally informative topics through an information-theoretic framework.
This framework naturally generalizes to hierarchical and semi-supervised
extensions with no additional modeling assumptions. In particular, word-level
domain knowledge can be flexibly incorporated within CorEx through anchor
words, allowing topic separability and representation to be promoted with
minimal human intervention. Across a variety of datasets, metrics, and
experiments, we demonstrate that CorEx produces topics that are comparable in
quality to those produced by unsupervised and semi-supervised variants of LDA.
</dc:description>
 <dc:description>Comment: 21 pages, 7 figures</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10277</dc:identifier>
 <dc:identifier>Transactions of the Association for Computational Linguistics
  (TACL), Vol. 5, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10283</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weighted bandits or: How bandits learn distorted values that are not
  expected</dc:title>
 <dc:creator>Gopalan, Aditya</dc:creator>
 <dc:creator>Prashanth, L. A.</dc:creator>
 <dc:creator>Fu, Michael</dc:creator>
 <dc:creator>Marcus, Steve</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Motivated by models of human decision making proposed to explain commonly
observed deviations from conventional expected value preferences, we formulate
two stochastic multi-armed bandit problems with distorted probabilities on the
cost distributions: the classic $K$-armed bandit and the linearly parameterized
bandit. In both settings, we propose algorithms that are inspired by Upper
Confidence Bound (UCB), incorporate cost distortions, and exhibit sublinear
regret assuming \holder continuous weight distortion functions. For the
$K$-armed setting, we show that the algorithm, called W-UCB, achieves
problem-dependent regret $O(L^2 M^2 \log n/ \Delta^{\frac{2}{\alpha}-1})$,
where $n$ is the number of plays, $\Delta$ is the gap in distorted expected
value between the best and next best arm, $L$ and $\alpha$ are the H\&quot;{o}lder
constants for the distortion function, and $M$ is an upper bound on costs, and
a problem-independent regret bound of
$O((KL^2M^2)^{\alpha/2}n^{(2-\alpha)/2})$. We also present a matching lower
bound on the regret, showing that the regret of W-UCB is essentially
unimprovable over the class of H\&quot;{o}lder-continuous weight distortions. For
the linearly parameterized setting, we develop a new algorithm, a variant of
the Optimism in the Face of Uncertainty Linear bandit (OFUL) algorithm called
WOFUL (Weight-distorted OFUL), and show that it has regret $O(d\sqrt{n} \;
\mbox{polylog}(n))$ with high probability, for sub-Gaussian cost distributions.
Finally, numerical examples demonstrate the advantages resulting from using
distortion-aware learning algorithms.
</dc:description>
 <dc:description>Comment: Longer version of the paper to be published as part of the
  proceedings of AAAI 2017</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10288</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Naming the Pain in Requirements Engineering: Contemporary Problems,
  Causes, and Effects in Practice</dc:title>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:creator>Wagner, S.</dc:creator>
 <dc:creator>Kalinowski, M.</dc:creator>
 <dc:creator>Felderer, M.</dc:creator>
 <dc:creator>Mafra, P.</dc:creator>
 <dc:creator>Vetr&#xf2;, A.</dc:creator>
 <dc:creator>Conte, T.</dc:creator>
 <dc:creator>Christiansson, M. -T.</dc:creator>
 <dc:creator>Greer, D.</dc:creator>
 <dc:creator>Lassenius, C.</dc:creator>
 <dc:creator>M&#xe4;nnist&#xf6;, T.</dc:creator>
 <dc:creator>Nayabi, M.</dc:creator>
 <dc:creator>Oivo, M.</dc:creator>
 <dc:creator>Penzenstadler, B.</dc:creator>
 <dc:creator>Pfahl, D.</dc:creator>
 <dc:creator>Prikladnicki, R.</dc:creator>
 <dc:creator>Ruhe, G.</dc:creator>
 <dc:creator>Schekelmann, A.</dc:creator>
 <dc:creator>Sen, S.</dc:creator>
 <dc:creator>Spinola, R.</dc:creator>
 <dc:creator>Tuzcu, A.</dc:creator>
 <dc:creator>de la Vara, J. L.</dc:creator>
 <dc:creator>Wieringa, R.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Requirements Engineering (RE) has received much attention in research and
practice due to its importance to software project success. Its
interdisciplinary nature, the dependency to the customer, and its inherent
uncertainty still render the discipline difficult to investigate. This results
in a lack of empirical data. These are necessary, however, to demonstrate which
practically relevant RE problems exist and to what extent they matter.
Motivated by this situation, we initiated the Naming the Pain in Requirements
Engineering (NaPiRE) initiative which constitutes a globally distributed,
bi-yearly replicated family of surveys on the status quo and problems in
practical RE. In this article, we report on the qualitative analysis of data
obtained from 228 companies working in 10 countries in various domains and we
reveal which contemporary problems practitioners encounter. To this end, we
analyse 21 problems derived from the literature with respect to their relevance
and criticality in dependency to their context, and we complement this picture
with a cause-effect analysis showing the causes and effects surrounding the
most critical problems. Our results give us a better understanding of which
problems exist and how they manifest themselves in practical environments.
Thus, we provide a first step to ground contributions to RE on empirical
observations which, until now, were dominated by conventional wisdom only.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10288</dc:identifier>
 <dc:identifier>Empirical Software Engineering, 2016</dc:identifier>
 <dc:identifier>doi:10.1007/s10664-016-9451-7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10302</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opportunistic Scheduling for Network Coded Data in Wireless Multicast
  Networks</dc:title>
 <dc:creator>Moghadam, Nadieh</dc:creator>
 <dc:creator>Mohebbi, Mohammad</dc:creator>
 <dc:creator>Li, Hongxiang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper queue stability in a single-hop wireless multicast networks
over erasure channels is analyzed. First, a queuing model consisting of several
sub-queues is introduced. Under the queueing stability constraint, we adopt
Lyapunov optimization model and define decision variables to derive a network
coding based packet scheduling algorithm, which has significantly less
complexity and shorter queue size compared with the existing solutions.
Further, the proposed algorithm is modified to meet the requirements of
time-critical data. Finally, the simulation results verify the effectiveness of
our proposed algorithm.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10305</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Influential Node Detection in Implicit Social Networks using Multi-task
  Gaussian Copula Models</dc:title>
 <dc:creator>Li, Qunwei</dc:creator>
 <dc:creator>Kailkhura, Bhavya</dc:creator>
 <dc:creator>Thiagarajan, Jayaraman J.</dc:creator>
 <dc:creator>Zhang, Zhenliang</dc:creator>
 <dc:creator>Varshney, Pramod K.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Influential node detection is a central research topic in social network
analysis. Many existing methods rely on the assumption that the network
structure is completely known \textit{a priori}. However, in many applications,
network structure is unavailable to explain the underlying information
diffusion phenomenon. To address the challenge of information diffusion
analysis with incomplete knowledge of network structure, we develop a
multi-task low rank linear influence model. By exploiting the relationships
between contagions, our approach can simultaneously predict the volume (i.e.
time series prediction) for each contagion (or topic) and automatically
identify the most influential nodes for each contagion. The proposed model is
validated using synthetic data and an ISIS twitter dataset. In addition to
improving the volume prediction performance significantly, we show that the
proposed approach can reliably infer the most influential users for specific
contagions.
</dc:description>
 <dc:description>Comment: NIPS 2016 Workshop, JMLR: Workshop and Conference Proceedings</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10309</identifier>
 <datestamp>2017-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity limit for faster-than-Nyquist non-orthogonal frequency-division
  multiplexing signaling</dc:title>
 <dc:creator>Zhou, Ji</dc:creator>
 <dc:creator>Qiao, Yaojun</dc:creator>
 <dc:creator>Yang, Zhanyu</dc:creator>
 <dc:creator>Guo, Mengqi</dc:creator>
 <dc:creator>Tang, Xizi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Faster-than-Nyquist (FTN) signal achieves higher spectral efficiency and
capacity compared to Nyquist signal due to its smaller pulse interval or
narrower subcarrier spacing. Shannon limit typically defines the upper-limit
capacity of Nyquist signal. To the best of our knowledge, the mathematical
expression for the capacity limit of FTN non-orthogonal frequency-division
multiplexing (NOFDM) signal is first demonstrated in this paper. The
mathematical expression shows that FTN NOFDM signal has the potential to
achieve a higher capacity limit compared to Nyquist signal. In this paper, we
demonstrate the principle of FTN NOFDM by taking fractional cosine
transform-based NOFDM (FrCT-NOFDM) for instance. FrCT-NOFDM is first proposed
and implemented by both simulation and experiment. When the bandwidth
compression factor $\alpha$ is set to $0.8$ in FrCT-NOFDM, the subcarrier
spacing is equal to $40\%$ of the symbol rate per subcarrier, thus the
transmission rate is about $25\%$ faster than Nyquist rate. FTN NOFDM with
higher capacity would be promising in the future communication systems,
especially in the bandwidth-limited applications.
</dc:description>
 <dc:description>Comment: 11 pages, 11 figures</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10309</dc:identifier>
 <dc:identifier>Scientific Reports 7, Article number: 3380 (2017)</dc:identifier>
 <dc:identifier>doi:10.1038/s41598-017-03571-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10312</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cognitive hierarchy theory and two-person games</dc:title>
 <dc:creator>Gracia-L&#xe1;zaro, Carlos</dc:creator>
 <dc:creator>Flor&#xed;a, Luis M.</dc:creator>
 <dc:creator>Moreno, Yamir</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The outcome of many social and economic interactions, such as stock-market
transactions, is strongly determined by the predictions that agents make about
the behavior of other individuals. Cognitive Hierarchy Theory provides a
framework to model the consequences of forecasting accuracy that has proven to
fit data from certain types of game theory experiments, such as Keynesian
Beauty Contests and Entry Games. Here, we focus on symmetric
two-players-two-actions games and establish an algorithm to find the players'
strategies according to the Cognitive Hierarchy Approach. We show that the
Snowdrift Game exhibits a pattern of behavior whose complexity grows as the
cognitive levels of players increases. In addition to finding the solutions up
to the third cognitive level, we demonstrate, in this theoretical frame, two
new properties of snowdrift games: i) any snowdrift game can be characterized
by only a parameter -- its class, ii) they are anti-symmetric with respect to
the diagonal of the pay-off's space. Finally, we propose a model based on an
evolutionary dynamics that captures the main features of the Cognitive
Hierarchy Theory.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures. Submitted for publication</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10314</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sync-DRAW: Automatic Video Generation using Deep Recurrent Attentive
  Architectures</dc:title>
 <dc:creator>Mittal, Gaurav</dc:creator>
 <dc:creator>Marwah, Tanya</dc:creator>
 <dc:creator>Balasubramanian, Vineeth N.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces a novel approach for generating videos called
Synchronized Deep Recurrent Attentive Writer (Sync-DRAW). Sync-DRAW can also
perform text-to-video generation which, to the best of our knowledge, makes it
the first approach of its kind. It combines a Variational Autoencoder~(VAE)
with a Recurrent Attention Mechanism in a novel manner to create a temporally
dependent sequence of frames that are gradually formed over time. The recurrent
attention mechanism in Sync-DRAW attends to each individual frame of the video
in sychronization, while the VAE learns a latent distribution for the entire
video at the global level. Our experiments with Bouncing MNIST, KTH and UCF-101
suggest that Sync-DRAW is efficient in learning the spatial and temporal
information of the videos and generates frames with high structural integrity,
and can generate videos from simple captions on these datasets. (Accepted as
oral paper in ACM-Multimedia 2017)
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-10-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10314</dc:identifier>
 <dc:identifier>doi:10.1145/3123266.3123309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10316</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory Controller Design Under Cloud Workloads</dc:title>
 <dc:creator>Mahmoud, Mostafa</dc:creator>
 <dc:creator>Moshovos, Andreas</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  This work studies the behavior of state-of-the-art memory controller designs
when executing scale-out workloads. It considers memory scheduling techniques,
memory page management policies, the number of memory channels, and the address
mapping scheme used. Experimental measurements demonstrate: 1)~Several recently
proposed memory scheduling policies are not a good match for these scale-out
workloads. 2)~The relatively simple First-Ready-First-Come-First-Served
(FR-FCFS) policy performs consistently better, and 3)~for most of the studied
workloads, the even simpler First-Come-First-Served scheduling policy is within
1\% of FR-FCFS. 4)~Increasing the number of memory channels offers negligible
performance benefits, e.g., performance improves by 1.7\% on average for
4-channels vs. 1-channel. 5)~77\%-90\% of DRAM rows activations are accessed
only once before closure. These observation can guide future development and
optimization of memory controllers for scale-out workloads.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10316</dc:identifier>
 <dc:identifier>2016 IEEE International Symposium on Workload Characterization
  (IISWC)</dc:identifier>
 <dc:identifier>doi:10.1109/IISWC.2016.7581279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10319</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Computational Complexity of Portal and Other 3D Video Games</dc:title>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Lockhart, Joshua</dc:creator>
 <dc:creator>Lynch, Jayson</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We classify the computational complexity of the popular video games Portal
and Portal 2. We isolate individual mechanics of the game and prove
NP-hardness, PSPACE-completeness, or (pseudo)polynomiality depending on the
specific game mechanics allowed. One of our proofs generalizes to prove
NP-hardness of many other video games such as Half-Life 2, Halo, Doom, Elder
Scrolls, Fallout, Grand Theft Auto, Left 4 Dead, Mass Effect, Deus Ex, Metal
Gear Solid, and Resident Evil.
  These results build on the established literature on the complexity of video
games.
</dc:description>
 <dc:description>Comment: 24 pages. Based on and overlaps with work in the MEng thesis of
  Jayson Lynch</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10328</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The observer-assisted method for adjusting hyper-parameters in deep
  learning algorithms</dc:title>
 <dc:creator>Wielgosz, Maciej</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper presents a concept of a novel method for adjusting
hyper-parameters in Deep Learning (DL) algorithms. An external agent-observer
monitors a performance of a selected Deep Learning algorithm. The observer
learns to model the DL algorithm using a series of random experiments.
Consequently, it may be used for predicting a response of the DL algorithm in
terms of a selected quality measurement to a set of hyper-parameters. This
allows to construct an ensemble composed of a series of evaluators which
constitute an observer-assisted architecture. The architecture may be used to
gradually iterate towards to the best achievable quality score in tiny steps
governed by a unit of progress. The algorithm is stopped when the maximum
number of steps is reached or no further progress is made.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10331</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparing Apples and Oranges: Two Examples of the Limits of Statistical
  Inference, With an Application to Google Advertising Markets</dc:title>
 <dc:creator>Mount, John</dc:creator>
 <dc:creator>Zumel, Nina</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We show how the classic Cramer-Rao bound limits how accurately one can
simultaneously estimate values of a large number of Google Ad campaigns (or
similarly limit the measurement rate of many confounding A/B tests).
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10334</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complexity Hierarchies and Higher-order Cons-free Term Rewriting</dc:title>
 <dc:creator>Kop, Cynthia</dc:creator>
 <dc:creator>Simonsen, Jakob Grue</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Constructor rewriting systems are said to be cons-free if, roughly,
constructor terms in the right-hand sides of rules are subterms of the
left-hand sides; the computational intuition is that rules cannot build new
data structures. In programming language research, cons-free languages have
been used to characterize hierarchies of computational complexity classes; in
term rewriting, cons-free first-order TRSs have been used to characterize the
class PTIME.
  We investigate cons-free higher-order term rewriting systems, the complexity
classes they characterize, and how these depend on the type order of the
systems. We prove that, for every K $\geq$ 1, left-linear cons-free systems
with type order K characterize E$^K$TIME if unrestricted evaluation is used
(i.e., the system does not have a fixed reduction strategy).
  The main difference with prior work in implicit complexity is that (i) our
results hold for non-orthogonal term rewriting systems with no assumptions on
reduction strategy, (ii) we consequently obtain much larger classes for each
type order (E$^K$TIME versus EXP$^{K-1}$TIME), and (iii) results for cons-free
term rewriting systems have previously only been obtained for K = 1, and with
additional syntactic restrictions besides cons-freeness and left-linearity.
  Our results are among the first implicit characterizations of the hierarchy E
= E$^1$TIME $\subsetneq$ E$^2$TIME $\subsetneq$ ... Our work confirms prior
results that having full non-determinism (via overlapping rules) does not
directly allow for characterization of non-deterministic complexity classes
like NE. We also show that non-determinism makes the classes characterized
highly sensitive to minor syntactic changes like admitting product types or
non-left-linear rules.
</dc:description>
 <dc:description>Comment: extended version of a paper submitted to FSCD 2016. arXiv admin note:
  substantial text overlap with arXiv:1604.08936</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10334</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 3 (August 7,
  2017) lmcs:3847</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-13(3:8)2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10336</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Artificial Agent for Robust Image Registration</dc:title>
 <dc:creator>Liao, Rui</dc:creator>
 <dc:creator>Miao, Shun</dc:creator>
 <dc:creator>de Tournemire, Pierre</dc:creator>
 <dc:creator>Grbic, Sasa</dc:creator>
 <dc:creator>Kamen, Ali</dc:creator>
 <dc:creator>Mansi, Tommaso</dc:creator>
 <dc:creator>Comaniciu, Dorin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  3-D image registration, which involves aligning two or more images, is a
critical step in a variety of medical applications from diagnosis to therapy.
Image registration is commonly performed by optimizing an image matching metric
as a cost function. However, this task is challenging due to the non-convex
nature of the matching metric over the plausible registration parameter space
and insufficient approaches for a robust optimization. As a result, current
approaches are often customized to a specific problem and sensitive to image
quality and artifacts. In this paper, we propose a completely different
approach to image registration, inspired by how experts perform the task. We
first cast the image registration problem as a &quot;strategy learning&quot; process,
where the goal is to find the best sequence of motion actions (e.g. up, down,
etc.) that yields image alignment. Within this approach, an artificial agent is
learned, modeled using deep convolutional neural networks, with 3D raw image
data as the input, and the next optimal action as the output. To cope with the
dimensionality of the problem, we propose a greedy supervised approach for an
end-to-end training, coupled with attention-driven hierarchical strategy. The
resulting registration approach inherently encodes both a data-driven matching
metric and an optimal registration strategy (policy). We demonstrate, on two
3-D/3-D medical image registration examples with drastically different nature
of challenges, that the artificial agent outperforms several state-of-art
registration methods by a large margin in terms of both accuracy and
robustness.
</dc:description>
 <dc:description>Comment: To appear in AAAI Conference 2017</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10338</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SLA Violation Prediction In Cloud Computing: A Machine Learning
  Perspective</dc:title>
 <dc:creator>Hemmat, Reyhane Askari</dc:creator>
 <dc:creator>Hafid, Abdelhakim</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Service level agreement (SLA) is an essential part of cloud systems to ensure
maximum availability of services for customers. With a violation of SLA, the
provider has to pay penalties. In this paper, we explore two machine learning
models: Naive Bayes and Random Forest Classifiers to predict SLA violations.
Since SLA violations are a rare event in the real world (~0.2 %), the
classification task becomes more challenging. In order to overcome these
challenges, we use several re-sampling methods. We find that random forests
with SMOTE-ENN re-sampling have the best performance among other methods with
the accuracy of 99.88 % and F_1 score of 0.9980.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10346</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Right Invariant Nonlinear Complementary Filter for Low Cost Attitude
  and Heading Estimation of Platforms</dc:title>
 <dc:creator>De Silva, Oscar</dc:creator>
 <dc:creator>Mann, George K. I.</dc:creator>
 <dc:creator>Gosine, Raymond G.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a novel filter with low computational demand to address
the problem of orientation estimation of a robotic platform. This is
conventionally addressed by extended Kalman filtering of measurements from a
sensor suit which mainly includes accelerometers, gyroscopes, and a digital
compass. Low cost robotic platforms demand simpler and computationally more
efficient methods to address this filtering problem. Hence nonlinear observers
with constant gains have emerged to assume this role. The nonlinear
complementary filter is a popular choice in this domain which does not require
covariance matrix propagation and associated computational overhead in its
filtering algorithm. However, the gain tuning procedure of the complementary
filter is not optimal, where it is often hand picked by trial and error. This
process is counter intuitive to system noise based tuning capability offered by
a stochastic filter like the Kalman filter. This paper proposes the right
invariant formulation of the complementary filter, which preserves Kalman like
system noise based gain tuning capability for the filter. The resulting filter
exhibits efficient operation in elementary embedded hardware, intuitive system
noise based gain tuning capability and accurate attitude estimation. The
performance of the filter is validated using numerical simulations and by
experimentally implementing the filter on an ARDrone 2.0 micro aerial vehicle
platform.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10351</identifier>
 <datestamp>2017-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Causal Inference from Observational and Experimental Datasets</dc:title>
 <dc:creator>Magliacane, Sara</dc:creator>
 <dc:creator>Claassen, Tom</dc:creator>
 <dc:creator>Mooij, Joris M.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce Joint Causal Inference (JCI), a powerful formulation of causal
discovery from multiple datasets that allows to jointly learn both the causal
structure and targets of interventions from statistical independences in pooled
data. Compared with existing constraint-based approaches for causal discovery
from multiple data sets, JCI offers several advantages: it allows for several
different types of interventions in a unified fashion, it can learn
intervention targets, it systematically pools data across different datasets
which improves the statistical power of independence tests, and most
importantly, it improves on the accuracy and identifiability of the predicted
causal relations. A technical complication that arises in JCI is the occurrence
of faithfulness violations due to deterministic relations. We propose a simple
but effective strategy for dealing with this type of faithfulness violations.
We implement it in ACID, a determinism-tolerant extension of Ancestral Causal
Inference (ACI) (Magliacane et al., 2016), a recently proposed logic-based
causal discovery method that improves reliability of the output by exploiting
redundant information in the data. We illustrate the benefits of JCI with ACID
with an evaluation on a simulated dataset.
</dc:description>
 <dc:description>Comment: Under submission in JMLR</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.10357</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achieving &quot;space of physics journals&quot;: topological structure and the
  Journal Impact Factor</dc:title>
 <dc:creator>Katchanov, Yurij L.</dc:creator>
 <dc:creator>Markova, Yulia V.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>91D30, 91D99</dc:subject>
 <dc:description>  The empirical distribution function of citations to journal articles (EDF for
short) can become the fundamental tool for analyzing the scientific journals.
Endeavors at making bibliometric analysis independent of the intuition of
average citation levels have led us to the study of qualitative properties of
physics journals in the functional space of EDFs. We show that the structure of
this space establishes the connections and relationships that determine the
essential features of physics journals. The research provides an analysis of
240 physics journals indexed in Journal Citation Reports 2015. The relevance of
EDFs clustering is discussed. Our findings reveal four-cluster space of physics
journals. The space brings to light the essential distinctions between physics
journals and shows different level of influence of scientific publishers
belonging to different types (professional physics societies, transnational and
local publishers). The study of EDFs grouped by publishers reveals two binary
oppositions that structure relations between them: &quot;global\,--- local&quot;
publishers and &quot;high cited\,--- low cited&quot; publishers.
</dc:description>
 <dc:description>Comment: 18 pages, 5 figures</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-05-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.10357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00005</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Plug &amp; Play Generative Networks: Conditional Iterative Generation of
  Images in Latent Space</dc:title>
 <dc:creator>Nguyen, Anh</dc:creator>
 <dc:creator>Clune, Jeff</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:creator>Dosovitskiy, Alexey</dc:creator>
 <dc:creator>Yosinski, Jason</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Generating high-resolution, photo-realistic images has been a long-standing
goal in machine learning. Recently, Nguyen et al. (2016) showed one interesting
way to synthesize novel images by performing gradient ascent in the latent
space of a generator network to maximize the activations of one or multiple
neurons in a separate classifier network. In this paper we extend this method
by introducing an additional prior on the latent code, improving both sample
quality and sample diversity, leading to a state-of-the-art generative model
that produces high quality images at higher resolutions (227x227) than previous
generative models, and does so for all 1000 ImageNet categories. In addition,
we provide a unified probabilistic interpretation of related activation
maximization methods and call the general class of models &quot;Plug and Play
Generative Networks&quot;. PPGNs are composed of 1) a generator network G that is
capable of drawing a wide range of image types and 2) a replaceable &quot;condition&quot;
network C that tells the generator what to draw. We demonstrate the generation
of images conditioned on a class (when C is an ImageNet or MIT Places
classification network) and also conditioned on a caption (when C is an image
captioning network). Our method also improves the state of the art of
Multifaceted Feature Visualization, which generates the set of synthetic inputs
that activate a neuron in order to better understand how deep neural networks
operate. Finally, we show that our model performs reasonably well at the task
of image inpainting. While image models are used in this paper, the approach is
modality-agnostic and can be applied to many types of data.
</dc:description>
 <dc:description>Comment: CVPR camera-ready</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00007</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the number of maximum independent sets in Doob graphs</dc:title>
 <dc:creator>Krotov, Denis</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05B15, 05E30</dc:subject>
 <dc:description>  The Doob graph $D(m,n)$ is a distance-regular graph with the same parameters
as the Hamming graph $H(2m+n,4)$. The maximum independent sets in the Doob
graphs are analogs of the distance-$2$ MDS codes in the Hamming graphs. We
prove that the logarithm of the number of the maximum independent sets in
$D(m,n)$ grows as $2^{2m+n-1}(1+o(1))$. The main tool for the upper estimation
is constructing an injective map from the class of maximum independent sets in
$D(m,n)$ to the class of distance-$2$ MDS codes in $H(2m+n,4)$.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00007</dc:identifier>
 <dc:identifier>Sib. Elektron. Mat. Izv. (Siberian Electronic Mathematical
  Reports) 12, 2015, 508-512</dc:identifier>
 <dc:identifier>doi:10.17377/semi.2015.12.043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00028</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-Dimensional Oscillatory Neural Network Based on Charge-Density-Wave
  Devices Operating at Room Temperature</dc:title>
 <dc:creator>Khitun, Alexander</dc:creator>
 <dc:creator>Liu, Guanxiong</dc:creator>
 <dc:creator>Balandin, Alexander A.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:description>  We propose an oscillatory neural network implemented with two-dimensional
tantalum disulfide devices operating in the change density wave regime at room
temperature. An elementary cell of the network consists of two 1T-TaS2 devices
connected in series. Such a cell has constant output and oscillatory states.
All cells have the same bias voltage. There is constant current flowing through
the cell in the constant output mode. The oscillations occur at a certain bias
voltage due to the electrical-field driven metal-to-insulator transition owing
to the changes in the charge density wave phase in the 1T-TaS2 channel. Two
1T-TaS2 devices oscillate out-of-phase where one of the devices is in the
insulator phase while the other one is in the metallic state. The
nearest-neighbor cells are coupled via graphene transistors. The cells are
resistively coupled if the graphene transistor is in the On state while they
are capacitively coupled if the transistor is in the Off state. The operation
of the oscillatory neural network is simulated numerically for the 30x30 node
network. The results of our numerical modeling show the formation of artificial
vortexes and cellular-automata type data processing. The two-dimensional
1T-TaS2 devices, utilized in the network, offer a unique combination of
properties such as scalability, high operational frequency, fast
synchronization speed, and radiation hardness, which makes them promising for
both consumer electronic and defense applications.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00034</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient quantum tomography II</dc:title>
 <dc:creator>O'Donnell, Ryan</dc:creator>
 <dc:creator>Wright, John</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Following [OW16], we continue our analysis of: (1) &quot;Quantum tomography&quot;,
i.e., learning a quantum state, i.e., the quantum generalization of learning a
discrete probability distribution; (2) The distribution of Young diagrams
output by the RSK algorithm on random words. Regarding (2), we introduce two
powerful new tools: (i) A precise upper bound on the expected length of the
longest union of $k$ disjoint increasing subsequences in a random length-$n$
word with letter distribution $\alpha_1 \geq \alpha_2 \geq \cdots \geq
\alpha_d$; (ii) A new majorization property of the RSK algorithm that allows
one to analyze the Young diagram formed by the lower rows $\lambda_k,
\lambda_{k+1}, \dots$ of its output.
  These tools allow us to prove several new theorems concerning the
distribution of random Young diagrams in the nonasymptotic regime, giving
concrete error bounds that are optimal, or nearly so, in all parameters. As one
example, we give a fundamentally new proof of the fact that the expected length
of the longest increasing sequence in a random length-$n$ permutation is
bounded by $2\sqrt{n}$. This is the $k = 1$, $\alpha_i \equiv \frac1d$, $d \to
\infty$ special case of a much more general result we prove: the expected
length of the $k$th Young diagram row produced by an $\alpha$-random word is
$\alpha_k n \pm 2\sqrt{\alpha_kd n}$.
  From our new analyses of random Young diagrams we derive several new results
in quantum tomography, including: (i) Learning the eigenvalues of an unknown
state to $\epsilon$-accuracy in Hellinger-squared, chi-squared, or KL distance,
using $n = O(d^2/\epsilon)$ copies; (ii) Learning the optimal rank-$k$
approximation of an unknown state to $\epsilon$-fidelity (Hellinger-squared
distance) using $n = \widetilde{O}(kd/\epsilon)$ copies.
</dc:description>
 <dc:description>Comment: 35 pages</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00053</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Propulsion Method of Flexible Underwater Robots</dc:title>
 <dc:creator>Shintake, Jun</dc:creator>
 <dc:creator>Ming, Aiguo</dc:creator>
 <dc:creator>Shimojo, Makoto</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>68T40</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:description>  This paper presents aims at mobility improvement of flexible underwater
robots. For this purpose, a novel propulsion method using planar structural
vibration pattern is proposed, and tested on two kinds of prototypes. The
result of experiments showed the possibility of the movements for multiple
directions: forward, backward, turn, rotation, drift, and their combination.
These movements are achieved by only one structure with two actuators. The
results also indicated the possibility of driving using eigenmodes since
movements were concentrated on low driving frequency area. To investigate the
relation between movement and structural vibration pattern, we established a
simulation model.
</dc:description>
 <dc:description>Comment: 8 pages, 21 figures in 2011 IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS)</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00053</dc:identifier>
 <dc:identifier>doi:10.1109/IROS.2011.6094693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00056</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Fourier-Bessel operator and almost-periodic interpolation
  and approximation</dc:title>
 <dc:creator>Gauthier, Jean-Paul</dc:creator>
 <dc:creator>Prandi, Dario</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:description>  We consider functions $f$ of two real variables, given as trigonometric
functions over a finite set $F$ of frequencies. This set is assumed to be
closed under rotations in the frequency plane of angle $\frac{2k\pi}{M}$ for
some integer $M$. Firstly, we address the problem of evaluating these functions
over a similar finite set $E$ in the space plane and, secondly, we address the
problems of interpolating or approximating a function $g$ of two variables by
such an $f$ over the grid $E.$ In particular, for this aim, we establish an
abstract factorization theorem for the evaluation function, which is a key
point for an efficient numerical solution to these problems. This result is
based on the very special structure of the group $SE(2,N)$, subgroup of the
group $SE(2)$ of motions of the plane corresponding to discrete rotations,
which is a maximally almost periodic group.
  Although the motivation of this paper comes from our previous works on
biomimetic image reconstruction and pattern recognition, where these questions
appear naturally, this topic is related with several classical problems: the
FFT in polar coordinates, the Non Uniform FFT, the evaluation of general
trigonometric polynomials, and so on.
</dc:description>
 <dc:description>Comment: 15 pages, 2 figures</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00071</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phenomenological theory of collective decision-making</dc:title>
 <dc:creator>Zafeiris, Anna</dc:creator>
 <dc:creator>Koman, Zsombor</dc:creator>
 <dc:creator>Mones, Enys</dc:creator>
 <dc:creator>Vicsek, Tam&#xe1;s</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  An essential task of groups is to provide efficient solutions for the complex
problems they face. Indeed, considerable efforts have been devoted to the
question of collective decision-making related to problems involving a single
dominant feature. Here we introduce a quantitative formalism for finding the
optimal distribution of the group members' competences in the more typical case
when the underlying problem is complex, i.e., multidimensional. Thus, we
consider teams that are aiming at obtaining the best possible answer to a
problem having a number of independent sub-problems. Our approach is based on a
generic scheme for the process of evaluating the proposed solutions (i.e.,
negotiation). We demonstrate that the best performing groups have at least one
specialist for each sub-problem -- but a far less intuitive result is that
finding the optimal solution by the interacting group members requires that the
specialists also have some insight into the sub-problems beyond their unique
field(s). We present empirical results obtained by using a large-scale database
of citations being in good agreement with the above theory. The framework we
have developed can easily be adapted to a variety of realistic situations since
taking into account the weights of the sub-problems, the opinions or the
relations of the group is straightforward. Consequently, our method can be used
in several contexts, especially when the optimal composition of a group of
decision-makers is designed.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2016-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00071</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2017.02.026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00085</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Texture Enhancement via High-Resolution Style Transfer for Single-Image
  Super-Resolution</dc:title>
 <dc:creator>Ahn, Il Jun</dc:creator>
 <dc:creator>Nam, Woo Hyun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, various deep-neural-network (DNN)-based approaches have been
proposed for single-image super-resolution (SISR). Despite their promising
results on major structure regions such as edges and lines, they still suffer
from limited performance on texture regions that consist of very complex and
fine patterns. This is because, during the acquisition of a low-resolution (LR)
image via down-sampling, these regions lose most of the high frequency
information necessary to represent the texture details. In this paper, we
present a novel texture enhancement framework for SISR to effectively improve
the spatial resolution in the texture regions as well as edges and lines. We
call our method, high-resolution (HR) style transfer algorithm. Our framework
consists of three steps: (i) generate an initial HR image from an interpolated
LR image via an SISR algorithm, (ii) generate an HR style image from the
initial HR image via down-scaling and tiling, and (iii) combine the HR style
image with the initial HR image via a customized style transfer algorithm.
Here, the HR style image is obtained by down-scaling the initial HR image and
then repetitively tiling it into an image of the same size as the HR image.
This down-scaling and tiling process comes from the idea that texture regions
are often composed of small regions that similar in appearance albeit sometimes
different in scale. This process creates an HR style image that is rich in
details, which can be used to restore high-frequency texture details back into
the initial HR image via the style transfer algorithm. Experimental results on
a number of texture datasets show that our proposed HR style transfer algorithm
provides more visually pleasing results compared with competitive methods.
</dc:description>
 <dc:description>Comment: Il Jun Ahn and Woo Hyun Nam contributed equally to this work.
  Submitted to IEEE Transactions on Consumer Electronics</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00086</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised Kernel Metric Learning Using Relative Comparisons</dc:title>
 <dc:creator>Amid, Ehsan</dc:creator>
 <dc:creator>Gionis, Aristides</dc:creator>
 <dc:creator>Ukkonen, Antti</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of metric learning subject to a set of constraints on
relative-distance comparisons between the data items. Such constraints are
meant to reflect side-information that is not expressed directly in the feature
vectors of the data items. The relative-distance constraints used in this work
are particularly effective in expressing structures at finer level of detail
than must-link (ML) and cannot-link (CL) constraints, which are most commonly
used for semi-supervised clustering. Relative-distance constraints are thus
useful in settings where providing an ML or a CL constraint is difficult
because the granularity of the true clustering is unknown.
  Our main contribution is an efficient algorithm for learning a kernel matrix
using the log determinant divergence --- a variant of the Bregman divergence
--- subject to a set of relative-distance constraints. The learned kernel
matrix can then be employed by many different kernel methods in a wide range of
applications. In our experimental evaluations, we consider a semi-supervised
clustering setting and show empirically that kernels found by our algorithm
yield clusterings of higher quality than existing approaches that either use
ML/CL constraints or a different means to implement the supervision using
relative comparisons.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00089</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond standard benchmarks: Parameterizing performance evaluation in
  visual object tracking</dc:title>
 <dc:creator>Zajc, Luka &#x10c;ehovin</dc:creator>
 <dc:creator>Luke&#x17e;i&#x10d;, Alan</dc:creator>
 <dc:creator>Leonardis, Ale&#x161;</dc:creator>
 <dc:creator>Kristan, Matej</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object-to-camera motion produces a variety of apparent motion patterns that
significantly affect performance of short-term visual trackers. Despite being
crucial for designing robust trackers, their influence is poorly explored in
standard benchmarks due to weakly defined, biased and overlapping attribute
annotations. In this paper we propose to go beyond pre-recorded benchmarks with
post-hoc annotations by presenting an approach that utilizes omnidirectional
videos to generate realistic, consistently annotated, short-term tracking
scenarios with exactly parameterized motion patterns. We have created an
evaluation system, constructed a fully annotated dataset of omnidirectional
videos and the generators for typical motion patterns. We provide an in-depth
analysis of major tracking paradigms which is complementary to the standard
benchmarks and confirms the expressiveness of our evaluation approach.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00092</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer Assisted Composition with Recurrent Neural Networks</dc:title>
 <dc:creator>Walder, Christian</dc:creator>
 <dc:creator>Kim, Dongwoo</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Sequence modeling with neural networks has lead to powerful models of
symbolic music data. We address the problem of exploiting these models to reach
creative musical goals, by combining with human input. To this end we
generalise previous work, which sampled Markovian sequence models under the
constraint that the sequence belong to the language of a given finite state
machine provided by the human. We consider more expressive non-Markov models,
thereby requiring approximate sampling which we provide in the form of an
efficient sequential Monte Carlo method. In addition we provide and compare
with a beam search strategy for conditional probability maximisation.
  Our algorithms are capable of convincingly re-harmonising famous musical
works. To demonstrate this we provide visualisations, quantitative experiments,
a human listening test and audio examples. We find both the sampling and
optimisation procedures to be effective, yet complementary in character. For
the case of highly permissive constraint sets, we find that sampling is to be
preferred due to the overly regular nature of the optimisation based results.
The generality of our algorithms permits countless other creative applications.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-09-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00094</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Quantiles in Preference-based Markov Decision Processes</dc:title>
 <dc:creator>Gilbert, Hugo</dc:creator>
 <dc:creator>Weng, Paul</dc:creator>
 <dc:creator>Xu, Yan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In the Markov decision process model, policies are usually evaluated by
expected cumulative rewards. As this decision criterion is not always suitable,
we propose in this paper an algorithm for computing a policy optimal for the
quantile criterion. Both finite and infinite horizons are considered. Finally
we experimentally evaluate our approach on random MDPs and on a data center
control problem.
</dc:description>
 <dc:description>Comment: Long version of AAAI 2017 paper. arXiv admin note: text overlap with
  arXiv:1611.00862</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00094</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00100</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noise-Tolerant Life-Long Matrix Completion via Adaptive Sampling</dc:title>
 <dc:creator>Balcan, Maria-Florina</dc:creator>
 <dc:creator>Zhang, Hongyang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>15-06</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>G.1.3</dc:subject>
 <dc:description>  We study the problem of recovering an incomplete $m\times n$ matrix of rank
$r$ with columns arriving online over time. This is known as the problem of
life-long matrix completion, and is widely applied to recommendation system,
computer vision, system identification, etc. The challenge is to design
provable algorithms tolerant to a large amount of noises, with small sample
complexity. In this work, we give algorithms achieving strong guarantee under
two realistic noise models. In bounded deterministic noise, an adversary can
add any bounded yet unstructured noise to each column. For this problem, we
present an algorithm that returns a matrix of a small error, with sample
complexity almost as small as the best prior results in the noiseless case. For
sparse random noise, where the corrupted columns are sparse and drawn randomly,
we give an algorithm that exactly recovers an $\mu_0$-incoherent matrix by
probability at least $1-\delta$ with sample complexity as small as
$O\left(\mu_0rn\log (r/\delta)\right)$. This result advances the
state-of-the-art work and matches the lower bound in a worst case. We also
study the scenario where the hidden matrix lies on a mixture of subspaces and
show that the sample complexity can be even smaller. Our proposed algorithms
perform well experimentally in both synthetic and real-world datasets.
</dc:description>
 <dc:description>Comment: 24 pages, 5 figures in NIPS 2016</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00101</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shape Completion using 3D-Encoder-Predictor CNNs and Shape Synthesis</dc:title>
 <dc:creator>Dai, Angela</dc:creator>
 <dc:creator>Qi, Charles Ruizhongtai</dc:creator>
 <dc:creator>Nie&#xdf;ner, Matthias</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a data-driven approach to complete partial 3D shapes through a
combination of volumetric deep neural networks and 3D shape synthesis. From a
partially-scanned input shape, our method first infers a low-resolution -- but
complete -- output. To this end, we introduce a 3D-Encoder-Predictor Network
(3D-EPN) which is composed of 3D convolutional layers. The network is trained
to predict and fill in missing data, and operates on an implicit surface
representation that encodes both known and unknown space. This allows us to
predict global structure in unknown areas at high accuracy. We then correlate
these intermediary results with 3D geometry from a shape database at test time.
In a final pass, we propose a patch-based 3D shape synthesis method that
imposes the 3D geometry from these retrieved shapes as constraints on the
coarsely-completed mesh. This synthesis process enables us to reconstruct
fine-scale detail and generate high-resolution output while respecting the
global mesh structure obtained by the 3D-EPN. Although our 3D-EPN outperforms
state-of-the-art completion method, the main contribution in our work lies in
the combination of a data-driven shape predictor and analytic 3D shape
synthesis. In our results, we show extensive evaluations on a newly-introduced
shape completion benchmark for both real-world and synthetic data.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00104</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Optimization for Tree-Structured Stochastic Network Design</dc:title>
 <dc:creator>Wu, Xiaojian</dc:creator>
 <dc:creator>Kumar, Akshat</dc:creator>
 <dc:creator>Sheldon, Daniel</dc:creator>
 <dc:creator>Zilberstein, Shlomo</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Stochastic network design is a general framework for optimizing network
connectivity. It has several applications in computational sustainability
including spatial conservation planning, pre-disaster network preparation, and
river network optimization. A common assumption in previous work has been made
that network parameters (e.g., probability of species colonization) are
precisely known, which is unrealistic in real- world settings. We therefore
address the robust river network design problem where the goal is to optimize
river connectivity for fish movement by removing barriers. We assume that fish
passability probabilities are known only imprecisely, but are within some
interval bounds. We then develop a planning approach that computes the policies
with either high robust ratio or low regret. Empirically, our approach scales
well to large river networks. We also provide insights into the solutions
generated by our robust approach, which has significantly higher robust ratio
than the baseline solution with mean parameter estimates.
</dc:description>
 <dc:description>Comment: AAAI 2017</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00106</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Menu-Based Pricing for Charging of Electric Vehicles with
  Vehicle-to-Grid Service</dc:title>
 <dc:creator>Ghosh, Arnob</dc:creator>
 <dc:creator>Aggarwal, Vaneet</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The paper considers a bidirectional power flow model of the electric vehicles
(EVs) in a charging station. The EVs can inject energies by discharging via a
Vehicle-to-Grid (V2G) service which can enhance the profits of the charging
station. However, frequent charging and discharging degrade battery life. A
proper compensation needs to be paid to the users to participate in the V2G
service. We propose a menu-based pricing scheme, where the charging station
selects a price for each arriving user for the amount of battery utilization,
the total energy, and the time (deadline) that the EV will stay. The user can
accept one of the contracts or rejects all depending on their utilities. The
charging station can serve users using a combination of the renewable energy
and the conventional energy bought from the grid. We show that though there
exists a profit maximizing price which maximizes the social welfare, it
provides no surplus to the users if the charging station is aware of the
utilities of the users. If the charging station is not aware of the exact
utilities, the social welfare maximizing price may not maximize the expected
profit. In fact, it can give a zero profit. We propose a pricing strategy which
provides a guaranteed fixed profit to the charging station and it also
maximizes the expected profit for a wide range of utility functions. Our
analysis shows that when the harvested renewable energy is small the users have
higher incentives for the V2G service. We, numerically, show that the charging
station's profit and the user's surplus both increase as V2G service is
efficiently utilized by the pricing mechanism.
</dc:description>
 <dc:description>Comment: Submitted in IEEE Transactions on Automatic Control. arXiv admin
  note: substantial text overlap with arXiv:1609.09037</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00108</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When to Reset Your Keys: Optimal Timing of Security Updates via Learning</dc:title>
 <dc:creator>Zheng, Zizhan</dc:creator>
 <dc:creator>Shroff, Ness B.</dc:creator>
 <dc:creator>Mohapatra, Prasant</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Cybersecurity is increasingly threatened by advanced and persistent attacks.
As these attacks are often designed to disable a system (or a critical
resource, e.g., a user account) repeatedly, it is crucial for the defender to
keep updating its security measures to strike a balance between the risk of
being compromised and the cost of security updates. Moreover, these decisions
often need to be made with limited and delayed feedback due to the stealthy
nature of advanced attacks. In addition to targeted attacks, such an optimal
timing policy under incomplete information has broad applications in
cybersecurity. Examples include key rotation, password change, application of
patches, and virtual machine refreshing. However, rigorous studies of optimal
timing are rare. Further, existing solutions typically rely on a pre-defined
attack model that is known to the defender, which is often not the case in
practice. In this work, we make an initial effort towards achieving optimal
timing of security updates in the face of unknown stealthy attacks. We consider
a variant of the influential FlipIt game model with asymmetric feedback and
unknown attack time distribution, which provides a general model to consecutive
security updates. The defender's problem is then modeled as a time associative
bandit problem with dependent arms. We derive upper confidence bound based
learning policies that achieve low regret compared with optimal periodic
defense strategies that can only be derived when attack time distributions are
known.
</dc:description>
 <dc:description>Comment: 9 pages, 2 figures; accepted by the Thirty-First AAAI Conference on
  Artificial Intelligence (AAAI-17), San Francisco, CA, USA, Feb. 2017</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00118</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-weight and three-weight codes from trace codes over
  $\mathbb{F}_p+u\mathbb{F}_p+v\mathbb{F}_p+uv\mathbb{F}_p$</dc:title>
 <dc:creator>Liu, Yan</dc:creator>
 <dc:creator>Shi, Minjia</dc:creator>
 <dc:creator>Sol&#xe9;, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We construct an infinite family of two-Lee-weight and three-Lee-weight codes
over the non-chain ring
$\mathbb{F}_p+u\mathbb{F}_p+v\mathbb{F}_p+uv\mathbb{F}_p,$ where
$u^2=0,v^2=0,uv=vu.$ These codes are defined as trace codes. They have the
algebraic structure of abelian codes. Their Lee weight distribution is computed
by using Gauss sums. With a linear Gray map, we obtain a class of abelian
three-weight codes and two-weight codes over $\mathbb{F}_p$. In particular, the
two-weight codes we describe are shown to be optimal by application of the
Griesmer bound. We also discuss their dual Lee distance. Finally, an
application to secret sharing schemes is given.
</dc:description>
 <dc:description>Comment: 11 pages, submitted on 29 November,2016</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00119</identifier>
 <datestamp>2016-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Scene Parsing with Predictive Feature Learning</dc:title>
 <dc:creator>Jin, Xiaojie</dc:creator>
 <dc:creator>Li, Xin</dc:creator>
 <dc:creator>Xiao, Huaxin</dc:creator>
 <dc:creator>Shen, Xiaohui</dc:creator>
 <dc:creator>Lin, Zhe</dc:creator>
 <dc:creator>Yang, Jimei</dc:creator>
 <dc:creator>Chen, Yunpeng</dc:creator>
 <dc:creator>Dong, Jian</dc:creator>
 <dc:creator>Liu, Luoqi</dc:creator>
 <dc:creator>Jie, Zequn</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we address the challenging video scene parsing problem by
developing effective representation learning methods given limited parsing
annotations. In particular, we contribute two novel methods that constitute a
unified parsing framework. (1) \textbf{Predictive feature learning}} from
nearly unlimited unlabeled video data. Different from existing methods learning
features from single frame parsing, we learn spatiotemporal discriminative
features by enforcing a parsing network to predict future frames and their
parsing maps (if available) given only historical frames. In this way, the
network can effectively learn to capture video dynamics and temporal context,
which are critical clues for video scene parsing, without requiring extra
manual annotations. (2) \textbf{Prediction steering parsing}} architecture that
effectively adapts the learned spatiotemporal features to scene parsing tasks
and provides strong guidance for any off-the-shelf parsing model to achieve
better video scene parsing performance. Extensive experiments over two
challenging datasets, Cityscapes and Camvid, have demonstrated the
effectiveness of our methods by showing significant improvement over
well-established baselines.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures, 5 tables, currently v2</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2016-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00122</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Hierarchical Mobile Edge Computing: An Auction-Based Profit
  Maximization Approach</dc:title>
 <dc:creator>Kiani, Abbas</dc:creator>
 <dc:creator>Ansari, Nirwan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The multi-tiered concept of Internet of Things (IoT) devices, cloudlets and
clouds is facilitating a user-centric IoT. However, in such three tier network,
it is still desirable to investigate efficient strategies to offer the
computing, storage and communications resources to the users. To this end, this
paper proposes a new hierarchical model by introducing the concept of field,
shallow, and deep cloudlets where the cloudlet tier itself is designed in three
hierarchical levels based on the principle of LTE-Advanced backhaul network.
Accordingly, we explore a two time scale approach in which the computing
resources are offered in an auction-based profit maximization manner and then
the communications resources are allocated to satisfy the users' QoS.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00122</dc:identifier>
 <dc:identifier>doi:10.1109/JIOT.2017.2750030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00123</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal three-weight cubic codes</dc:title>
 <dc:creator>Shi, Minjia</dc:creator>
 <dc:creator>Zhu, Hongwei</dc:creator>
 <dc:creator>Sol&#xe9;, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we construct an infinite family of three-weight binary codes
from linear codes over the ring $R=\mathbb{F}_2+v\mathbb{F}_2+v^2\mathbb{F}_2$,
where $v^3=1.$ These codes are defined as trace codes. They have the algebraic
structure of abelian codes. Their Lee weight distributions are computed by
employing character sums. The three-weight binary linear codes which we
construct are shown to be optimal when $m$ is odd and $m&gt;1$. They are cubic,
that is to say quasi-cyclic of co-index three. An application to secret sharing
schemes is given.
</dc:description>
 <dc:description>Comment: 12 pages, submitted on 28 November, 2016</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00125</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Artificial Fish Swarm Algorithm for Pattern Recognition with
  Convex Optimization</dc:title>
 <dc:creator>Shi, Lei</dc:creator>
 <dc:creator>Guo, Rui</dc:creator>
 <dc:creator>Ma, Yuchen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image pattern recognition is an important area in digital image processing.
An efficient pattern recognition algorithm should be able to provide correct
recognition at a reduced computational time. Off late amongst the machine
learning pattern recognition algorithms, Artificial fish swarm algorithm is one
of the swarm intelligence optimization algorithms that works based on
population and stochastic search. In order to achieve acceptable result, there
are many parameters needs to be adjusted in AFSA. Among these parameters,
visual and step are very significant in view of the fact that artificial fish
basically move based on these parameters. In standard AFSA, these two
parameters remain constant until the algorithm termination. Large values of
these parameters increase the capability of algorithm in global search, while
small values improve the local search ability of the algorithm. In this paper,
we empirically study the performance of the AFSA and different approaches to
balance between local and global exploration have been tested based on the
adaptive modification of visual and step during algorithm execution. The
proposed approaches have been evaluated based on the four well-known benchmark
functions. Experimental results show considerable positive impact on the
performance of AFSA. A Convex optimization has been integrated into the
proposed work to have an ideal segmentation of the input image which is a MR
brain image.
</dc:description>
 <dc:description>Comment: arXiv admin note: submission has been withdrawn by arXiv
  administrators due to inappropriate text reuse from external sources</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00126</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Three-weight codes and the quintic construction</dc:title>
 <dc:creator>Liu, Yan</dc:creator>
 <dc:creator>Shi, Minjia</dc:creator>
 <dc:creator>Sol&#xe9;, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We construct a class of three-Lee-weight and two infinite families of
five-Lee-weight codes over the ring $R=\mathbb{F}_2 +v\mathbb{F}_2
+v^2\mathbb{F}_2 +v^3\mathbb{F}_2 +v^4\mathbb{F}_2,$ where $v^5=1.$ The same
ring occurs in the quintic construction of binary quasi-cyclic codes. %The
length of these codes depends on the degree $m$ of ring extension. They have
the algebraic structure of abelian codes. Their Lee weight distribution is
computed by using character sums. Given a linear Gray map, we obtain three
families of binary abelian codes with few weights. In particular, we obtain a
class of three-weight codes which are optimal. Finally, an application to
secret sharing schemes is given.
</dc:description>
 <dc:description>Comment: 15 pages, submitted on 21 November, 2016. arXiv admin note: text
  overlap with arXiv:1612.00118</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00126</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00128</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trace Codes with Few Weights over $\mathbb{F}_p+u\mathbb{F}_p$</dc:title>
 <dc:creator>Shi, Minjia</dc:creator>
 <dc:creator>Liu, Yan</dc:creator>
 <dc:creator>Sol&#xe9;, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We construct an infinite family of two-Lee-weight and three-Lee-weight codes
over the chain ring $\mathbb{F}_p+u\mathbb{F}_p.$ They have the algebraic
structure of abelian codes. Their Lee weight distribution is computed by using
Gauss sums. Then by using a linear Gray map, we obtain an infinite family of
abelian codes with few weights over $\mathbb{F}_p$. In particular, we obtain an
infinite family of two-weight codes which meets the Griesmer bound with
equality. Finally, an application to secret sharing schemes is given.
</dc:description>
 <dc:description>Comment: 12 pages, submitted on 27 October, 2016. arXiv admin note: text
  overlap with arXiv:1612.00126, arXiv:1612.00118</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00130</identifier>
 <datestamp>2017-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Polar Coding for the Two-Way Wiretap Channel</dc:title>
 <dc:creator>Zheng, Mengfan</dc:creator>
 <dc:creator>Tao, Meixia</dc:creator>
 <dc:creator>Chen, Wen</dc:creator>
 <dc:creator>Ling, Cong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of polar coding for secure communications over the
two-way wiretap channel, where two legitimate users communicate with each other
simultaneously while a passive eavesdropper overhears a combination of their
exchanged signals. The legitimate users wish to design a cooperative jamming
code such that the interference between their codewords can jam the
eavesdropper. In this paper, we design a polar coded cooperative jamming scheme
that achieves the whole secrecy rate region of the general two-way wiretap
channel under the strong secrecy criterion. The chaining method is used to make
proper alignment of polar indices. The randomness required to be shared between
two legitimate users is treated as a limited resource and we show that its rate
can be made negligible by increasing the blocklength and the number of chained
blocks. For the special case when the eavesdropper channel is degraded with
respect to the legitimate ones, a simplified scheme is proposed which can
simultaneously ensure reliability and weak secrecy within a single transmission
block. An example of the binary erasure channel case is given to demonstrate
the performance of our scheme.
</dc:description>
 <dc:description>Comment: 28 pages, 7 figures</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00131</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blind Estimation of Sparse Multi-User Massive MIMO Channels</dc:title>
 <dc:creator>Mezghani, Amine</dc:creator>
 <dc:creator>Swindlehurst, A. Lee</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We provide a maximum likelihood formulation for the blind estimation of
massive mmWave MIMO channels while taking into account their underlying sparse
structure. The main advantage of this approach is the fact that the overhead
due to pilot sequences can be reduced dramatically especially when operating at
low SNR per antenna. Thereby, the sparsity in the angular domain is exploited
as a key property to enable the unambiguous blind separation between user's
channels. On the other hand, as only the sparsity is assumed, the proposed
method is robust with respect to the statistical properties of the channel and
data and allows the estimation in rapidly time-varying scenarios and eventually
the separation of interfering users from adjacent base stations. Additionally,
a performance limit is derived based on the clairvoyant Cram\'er Rao lower
bound. Simulation results demonstrate that this maximum likelihood formulation
yields superior estimation accuracy with reasonable computational complexity
and limited model assumptions.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, submitted to the International ITG Workshop on
  Smart Antennas (WSA 2017)</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00132</identifier>
 <datestamp>2017-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CDVAE: Co-embedding Deep Variational Auto Encoder for Conditional
  Variational Generation</dc:title>
 <dc:creator>Lu, Jiajun</dc:creator>
 <dc:creator>Deshpande, Aditya</dc:creator>
 <dc:creator>Forsyth, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Problems such as predicting a new shading field (Y) for an image (X) are
ambiguous: many very distinct solutions are good. Representing this ambiguity
requires building a conditional model P(Y|X) of the prediction, conditioned on
the image. Such a model is difficult to train, because we do not usually have
training data containing many different shadings for the same image. As a
result, we need different training examples to share data to produce good
models. This presents a danger we call &quot;code space collapse&quot; - the training
procedure produces a model that has a very good loss score, but which
represents the conditional distribution poorly. We demonstrate an improved
method for building conditional models by exploiting a metric constraint on
training data that prevents code space collapse. We demonstrate our model on
two example tasks using real data: image saturation adjustment, image
relighting. We describe quantitative metrics to evaluate ambiguous generation
results. Our results quantitatively and qualitatively outperform different
strong baselines.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00137</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RMPE: Regional Multi-person Pose Estimation</dc:title>
 <dc:creator>Fang, Hao-Shu</dc:creator>
 <dc:creator>Xie, Shuqin</dc:creator>
 <dc:creator>Tai, Yu-Wing</dc:creator>
 <dc:creator>Lu, Cewu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Multi-person pose estimation in the wild is challenging. Although
state-of-the-art human detectors have demonstrated good performance, small
errors in localization and recognition are inevitable. These errors can cause
failures for a single-person pose estimator (SPPE), especially for methods that
solely depend on human detection results. In this paper, we propose a novel
regional multi-person pose estimation (RMPE) framework to facilitate pose
estimation in the presence of inaccurate human bounding boxes. Our framework
consists of three components: Symmetric Spatial Transformer Network (SSTN),
Parametric Pose Non-Maximum-Suppression (NMS), and Pose-Guided Proposals
Generator (PGPG). Our method is able to handle inaccurate bounding boxes and
redundant detections, allowing it to achieve a 17% increase in mAP over the
state-of-the-art methods on the MPII (multi person) dataset.Our model and
source codes are publicly available.
</dc:description>
 <dc:description>Comment: Models &amp; Codes available at https://github.com/MVIG-SJTU/RMPE or
  https://github.com/Fang-Haoshu/RMPE</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00138</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Robust Deep Neural Networks with BANG</dc:title>
 <dc:creator>Rozsa, Andras</dc:creator>
 <dc:creator>Gunther, Manuel</dc:creator>
 <dc:creator>Boult, Terrance E.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Machine learning models, including state-of-the-art deep neural networks, are
vulnerable to small perturbations that cause unexpected classification errors.
This unexpected lack of robustness raises fundamental questions about their
generalization properties and poses a serious concern for practical
deployments. As such perturbations can remain imperceptible - commonly called
adversarial examples that demonstrate an inherent inconsistency between
vulnerable machine learning models and human perception - some prior work casts
this problem as a security issue as well. Despite the significance of the
discovered instabilities and ensuing research, their cause is not well
understood, and no effective method has been developed to address the problem
highlighted by adversarial examples. In this paper, we present a novel theory
to explain why this unpleasant phenomenon exists in deep neural networks. Based
on that theory, we introduce a simple, efficient and effective training
approach, Batch Adjusted Network Gradients (BANG), which significantly improves
the robustness of machine learning models. While the BANG technique does not
rely on any form of data augmentation or the application of adversarial images
for training, the resultant classifiers are more resistant to adversarial
perturbations while maintaining or even enhancing classification performance
overall.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00143</identifier>
 <datestamp>2017-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounding the Dimension of Points on a Line</dc:title>
 <dc:creator>Lutz, Neil</dc:creator>
 <dc:creator>Stull, D. M.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Classical Analysis and ODEs</dc:subject>
 <dc:description>  We use Kolmogorov complexity methods to give a lower bound on the effective
Hausdorff dimension of the point (x, ax+b), given real numbers a, b, and x. We
apply our main theorem to a problem in fractal geometry, giving an improved
lower bound on the (classical) Hausdorff dimension of generalized sets of
Furstenberg type.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00144</identifier>
 <datestamp>2017-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BASS Net: Band-Adaptive Spectral-Spatial Feature Learning Neural Network
  for Hyperspectral Image Classification</dc:title>
 <dc:creator>Santara, Anirban</dc:creator>
 <dc:creator>Mani, Kaustubh</dc:creator>
 <dc:creator>Hatwar, Pranoot</dc:creator>
 <dc:creator>Singh, Ankit</dc:creator>
 <dc:creator>Garg, Ankur</dc:creator>
 <dc:creator>Padia, Kirti</dc:creator>
 <dc:creator>Mitra, Pabitra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning based landcover classification algorithms have recently been
proposed in literature. In hyperspectral images (HSI) they face the challenges
of large dimensionality, spatial variability of spectral signatures and
scarcity of labeled data. In this article we propose an end-to-end deep
learning architecture that extracts band specific spectral-spatial features and
performs landcover classification. The architecture has fewer independent
connection weights and thus requires lesser number of training data. The method
is found to outperform the highest reported accuracies on popular hyperspectral
image data sets.
</dc:description>
 <dc:description>Comment: 8 pages, 10 figures, Submitted to IEEE TGRS, Code available at:
  https://github.com/kaustubh0mani/BASS-Net</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00144</dc:identifier>
 <dc:identifier>doi:10.1109/TGRS.2017.2705073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00147</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Deep Reinforcement Learning and Safety Based Control for
  Autonomous Driving</dc:title>
 <dc:creator>Xiong, Xi</dc:creator>
 <dc:creator>Wang, Jianqiang</dc:creator>
 <dc:creator>Zhang, Fang</dc:creator>
 <dc:creator>Li, Keqiang</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  With the development of state-of-art deep reinforcement learning, we can
efficiently tackle continuous control problems. But the deep reinforcement
learning method for continuous control is based on historical data, which would
make unpredicted decisions in unfamiliar scenarios. Combining deep
reinforcement learning and safety based control can get good performance for
self-driving and collision avoidance. In this passage, we use the Deep
Deterministic Policy Gradient algorithm to implement autonomous driving without
vehicles around. The vehicle can learn the driving policy in a stable and
familiar environment, which is efficient and reliable. Then we use the
artificial potential field to design collision avoidance algorithm with
vehicles around. The path tracking method is also taken into consideration. The
combination of deep reinforcement learning and safety based control performs
well in most scenarios.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00148</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domain Adaptation for Named Entity Recognition in Online Media with Word
  Embeddings</dc:title>
 <dc:creator>Kulkarni, Vivek</dc:creator>
 <dc:creator>Mehdad, Yashar</dc:creator>
 <dc:creator>Chevalier, Troy</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Content on the Internet is heterogeneous and arises from various domains like
News, Entertainment, Finance and Technology. Understanding such content
requires identifying named entities (persons, places and organizations) as one
of the key steps. Traditionally Named Entity Recognition (NER) systems have
been built using available annotated datasets (like CoNLL, MUC) and demonstrate
excellent performance. However, these models fail to generalize onto other
domains like Sports and Finance where conventions and language use can differ
significantly. Furthermore, several domains do not have large amounts of
annotated labeled data for training robust Named Entity Recognition models. A
key step towards this challenge is to adapt models learned on domains where
large amounts of annotated training data are available to domains with scarce
annotated data.
  In this paper, we propose methods to effectively adapt models learned on one
domain onto other domains using distributed word representations. First we
analyze the linguistic variation present across domains to identify key
linguistic insights that can boost performance across domains. We propose
methods to capture domain specific semantics of word usage in addition to
global semantics. We then demonstrate how to effectively use such domain
specific knowledge to learn NER models that outperform previous baselines in
the domain adaptation setting.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figures, 8 tables arxiv preprint</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00150</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decentralized Consensus Optimization with Asynchrony and Delays</dc:title>
 <dc:creator>Wu, Tianyu</dc:creator>
 <dc:creator>Yuan, Kun</dc:creator>
 <dc:creator>Ling, Qing</dc:creator>
 <dc:creator>Yin, Wotao</dc:creator>
 <dc:creator>Sayed, Ali H.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  We propose an asynchronous, decentralized algorithm for consensus
optimization. The algorithm runs over a network in which the agents communicate
with their neighbors and perform local computation. In the proposed algorithm,
each agent can compute and communicate independently at different times, for
different durations, with the information it has even if the latest information
from its neighbors is not yet available. Such an asynchronous algorithm reduces
the time that agents would otherwise waste idle because of communication delays
or because their neighbors are slower. It also eliminates the need for a global
clock for synchronization. Mathematically, the algorithm involves both primal
and dual variables, uses fixed step-size parameters, and provably converges to
the exact solution under a bounded delay assumption and a random agent
assumption. When running synchronously, the algorithm performs just as well as
existing competitive synchronous algorithms such as PG-EXTRA, which diverges
without synchronization. Numerical experiments confirm the theoretical findings
and illustrate the performance of the proposed algorithm.
</dc:description>
 <dc:description>Comment: added a table for comparison between related algorithms; added a
  numerical comparison with asynchronous decentralized ADMM</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00151</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Method for Classification of Datasets for Data Mining</dc:title>
 <dc:creator>Vijendra, Singh</dc:creator>
 <dc:creator>Parashar, Hemjyotsana</dc:creator>
 <dc:creator>Vasudeva, Nisha</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Decision tree is an important method for both induction research and data
mining, which is mainly used for model classification and prediction. ID3
algorithm is the most widely used algorithm in the decision tree so far. In
this paper, the shortcoming of ID3's inclining to choose attributes with many
values is discussed, and then a new decision tree algorithm which is improved
version of ID3. In our proposed algorithm attributes are divided into groups
and then we apply the selection measure 5 for these groups. If information gain
is not good then again divide attributes values into groups. These steps are
done until we get good classification/misclassification ratio. The proposed
algorithms classify the data sets more accurately and efficiently.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00155</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Images for Variational Autoencoders</dc:title>
 <dc:creator>Tabacof, Pedro</dc:creator>
 <dc:creator>Tavares, Julia</dc:creator>
 <dc:creator>Valle, Eduardo</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We investigate adversarial attacks for autoencoders. We propose a procedure
that distorts the input image to mislead the autoencoder in reconstructing a
completely different target image. We attack the internal latent
representations, attempting to make the adversarial input produce an internal
representation as similar as possible as the target's. We find that
autoencoders are much more robust to the attack than classifiers: while some
examples have tolerably small input distortion, and reasonable similarity to
the target image, there is a quasi-linear trade-off between those aims. We
report results on MNIST and SVHN datasets, and also test regular deterministic
autoencoders, reaching similar conclusions in all cases. Finally, we show that
the usual adversarial attack for classifiers, while being much easier, also
presents a direct proportion between distortion on the input, and misdirection
on the output. That proportionality however is hidden by the normalization of
the output, which maps a linear layer into non-linear probabilities.
</dc:description>
 <dc:description>Comment: Workshop on Adversarial Training, NIPS 2016, Barcelona, Spain</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00156</identifier>
 <datestamp>2017-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global and fixed-terminal cuts in digraphs</dc:title>
 <dc:creator>B&#xe9;rczi, Krist&#xf3;f</dc:creator>
 <dc:creator>Chandrasekaran, Karthekeyan</dc:creator>
 <dc:creator>Kir&#xe1;ly, Tam&#xe1;s</dc:creator>
 <dc:creator>Lee, Euiwoong</dc:creator>
 <dc:creator>Xu, Chao</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The computational complexity of multicut-like problems may vary significantly
depending on whether the terminals are fixed or not. In this work we present a
comprehensive study of this phenomenon in two types of cut problems in directed
graphs: double cut and bicut.
  1. The fixed-terminal edge-weighted double cut is known to be solvable
efficiently. We show a tight approximability factor of $2$ for the
fixed-terminal node-weighted double cut. We show that the global node-weighted
double cut cannot be approximated to a factor smaller than $3/2$ under the
Unique Games Conjecture (UGC).
  2. The fixed-terminal edge-weighted bicut is known to have a tight
approximability factor of $2$. We show that the global edge-weighted bicut is
approximable to a factor strictly better than $2$, and that the global
node-weighted bicut cannot be approximated to a factor smaller than $3/2$ under
UGC.
  3. In relation to these investigations, we also prove two results on
undirected graphs which are of independent interest. First, we show
NP-completeness and a tight inapproximability bound of $4/3$ for the
node-weighted $3$-cut problem. Second, we show that for constant $k$, there
exists an efficient algorithm to solve the minimum $\{s,t\}$-separating $k$-cut
problem.
  Our techniques for the algorithms are combinatorial, based on LPs and based
on enumeration of approximate min-cuts. Our hardness results are based on
combinatorial reductions and integrality gap instances.
</dc:description>
 <dc:description>Comment: 37 pages, 5 figures, APPROX 2017</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00156</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00163</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preventing Incomplete/Hidden Requirements: Reflections on Survey Data
  from Austria and Brazil</dc:title>
 <dc:creator>Kalinowski, M.</dc:creator>
 <dc:creator>Felderer, M.</dc:creator>
 <dc:creator>Conte, T.</dc:creator>
 <dc:creator>Sp&#xed;nola, R.</dc:creator>
 <dc:creator>Prikladnicki, R.</dc:creator>
 <dc:creator>Winkler, D.</dc:creator>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:creator>Wagner, S.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Many software projects fail due to problems in requirements engineering (RE).
The goal of this paper is analyzing a specific and relevant RE problem in
detail: incomplete/hidden requirements. We replicated a global family of RE
surveys with representatives of software organizations in Austria and Brazil.
We used the data to (a) characterize the criticality of the selected RE
problem, and to (b) analyze the reported main causes and mitigation actions.
Based on the analysis, we discuss how to prevent the problem. The survey
includes 14 different organizations in Austria and 74 in Brazil, including
small, medium and large sized companies, conducting both, plan-driven and agile
development processes. Respondents from both countries cited the
incomplete/hidden requirements problem as one of the most critical RE problems.
We identified and graphically represented the main causes and documented
solution options to address these causes. Further, we compiled a list of
reported mitigation actions. From a practical point of view, this paper
provides further insights into common causes of incomplete/hidden requirements
and on how to prevent this problem.
</dc:description>
 <dc:description>Comment: in Proceedings of the Software Quality Days, 2015</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00163</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-27033-3_5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00164</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysing Text in Software Projects</dc:title>
 <dc:creator>Wagner, S.</dc:creator>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Most of the data produced in software projects is of textual nature: source
code, specifications, or documentations. The advances in quantitative analysis
methods drove a lot of data analytics in software engineering. This has
overshadowed to some degree the importance of texts and their qualitative
analysis. Such analysis has, however, merits for researchers and practitioners
as well.
  In this chapter, we describe the basics of analysing text in software
projects. We first describe how to manually analyse and code textual data.
Next, we give an overview of mixed methods to automatic text analysis including
N-Grams and clone detection as well as more sophisticated natural language
processing identifying syntax and contexts of words. Those methods and tools
are of critical importance to aid in the challenges in today's huge amounts of
textual data.
  We illustrate the introduced methods via a running example and conclude by
presenting two industrial studies.
</dc:description>
 <dc:description>Comment: in The Art and Science of Analyzing Software Data, 2015</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00164</dc:identifier>
 <dc:identifier>doi:10.1016/B978-0-12-411519-4.00003-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00171</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Non Linear Multifractal Study to Illustrate the Evolution of Tagore
  Songs Over a Century</dc:title>
 <dc:creator>Sanyal, Shankha</dc:creator>
 <dc:creator>Banerjee, Archi</dc:creator>
 <dc:creator>Guhathakurata, Tarit</dc:creator>
 <dc:creator>Sengupta, Ranjan</dc:creator>
 <dc:creator>Ghosh, Dipak</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  The works of Rabindranath Tagore have been sung by various artistes over
generations spanning over almost 100 years. there are few songs which were
popular in the early years and have been able to retain their popularity over
the years while some others have faded away. In this study we look to find cues
for the singing style of these songs which have kept them alive for all these
years. For this we took 3 min clip of four Tagore songs which have been sung by
five generation of artistes over 100 years and analyze them with the help of
latest nonlinear techniques Multifractal Detrended Fluctuation Analysis
(MFDFA). The multifractal spectral width is a manifestation of the inherent
complexity of the signal and may prove to be an important parameter to identify
the singing style of particular generation of singers and how this style varies
over different generations. The results are discussed in detail.
</dc:description>
 <dc:description>Comment: 6 PAGES, 5 FIGURES, Presented in International Symposium on Frontiers
  of Research in Speech and Music (FRSM)2016 held in North Orissa University,
  11-12 November 2016. arXiv admin note: text overlap with arXiv:1601.07709</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00172</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Non Linear Approach towards Automated Emotion Analysis in Hindustani
  Music</dc:title>
 <dc:creator>Sanyal, Shankha</dc:creator>
 <dc:creator>Banerjee, Archi</dc:creator>
 <dc:creator>Guhathakurata, Tarit</dc:creator>
 <dc:creator>Sengupta, Ranjan</dc:creator>
 <dc:creator>Ghosh, Dipak</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  In North Indian Classical Music, raga forms the basic structure over which
individual improvisations is performed by an artist based on his/her
creativity. The Alap is the opening section of a typical Hindustani Music (HM)
performance, where the raga is introduced and the paths of its development are
revealed using all the notes used in that particular raga and allowed
transitions between them with proper distribution over time. In India,
corresponding to each raga, several emotional flavors are listed, namely erotic
love, pathetic, devotional, comic, horrific, repugnant, heroic, fantastic,
furious, peaceful. The detection of emotional cues from Hindustani Classical
music is a demanding task due to the inherent ambiguity present in the
different ragas, which makes it difficult to identify any particular emotion
from a certain raga. In this study we took the help of a high resolution
mathematical microscope (MFDFA or Multifractal Detrended Fluctuation Analysis)
to procure information about the inherent complexities and time series
fluctuations that constitute an acoustic signal. With the help of this
technique, 3 min alap portion of six conventional ragas of Hindustani classical
music namely, Darbari Kanada, Yaman, Mian ki Malhar, Durga, Jay Jayanti and
Hamswadhani played in three different musical instruments were analyzed. The
results are discussed in detail.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures; Presented in International Symposium on Frontiers
  of Research in Speech and Music (FRSM)2016 held in North Orissa University,
  11-12 November 2016</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00179</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Offering Strategies for Storage-Assisted Renewable Power Producer
  in Hour-Ahead Market</dc:title>
 <dc:creator>Yang, Lin</dc:creator>
 <dc:creator>Hajiesmaili, Mohammad H.</dc:creator>
 <dc:creator>Yi, Hanling</dc:creator>
 <dc:creator>Chen, Minghua</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  A promising approach to hedge against the inherent uncertainty of renewable
generation is to equip the renewable plants with energy storage systems. This
paper focuses on designing profit maximization offering strategies, i.e., the
strategies that determine the offering price and volume, for a storage-assisted
renewable power producer that participates in hour-ahead electricity market.
Designing the strategies is challenging since (i) the underlying problem is
coupled across time due to the evolution of the storage level, and (ii) inputs
to the problem including the renewable output and market clearing price are
unknown when submitting offers. Following the competitive online algorithm
design approach, we first study a basic setting where the renewable output and
the clearing price are known for the next hour. We propose sOffer, a simple
online offering strategy that achieves the best possible competitive ratio of
O(log \theta), where $\theta$ is the ratio between the maximum and the minimum
clearing prices. Then, we consider the case where the clearing price is
unknown. By exploiting the idea of submitting multiple offers to combat price
uncertainty, we propose mOffer, and demonstrate that the competitive ratio of
mOffer converges to that of sOffer as the number of offers grows. Finally, we
extend our approach to the scenario where the renewable output has forecasting
error. We propose gOffer as the generalized offering strategy and characterize
its competitive ratio as a function of the forecasting error. Our trace-driven
experiments demonstrate that our algorithms achieve performance close to the
offline optimal and outperform a baseline alternative significantly.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00181</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monge's Optimal Transport Distance with Applications for Nearest
  Neighbour Image Classification</dc:title>
 <dc:creator>Miller, Michael</dc:creator>
 <dc:creator>Van lent, Jan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65N06</dc:subject>
 <dc:description>  This paper focuses on a similarity measure, known as the Wasserstein
distance, with which to compare images. The Wasserstein distance results from a
partial differential equation (PDE) formulation of Monge's optimal transport
problem. We present an efficient numerical solution method for solving Monge's
problem. To demonstrate the measure's discriminatory power when comparing
images, we use it within the architecture of the $k$-Nearest Neighbour ($k$-NN)
machine learning algorithm to illustrate the measure's potential benefits over
other more traditional distance metrics and also the state-of-the-art Tangent
Space distance on the well-known MNIST dataset. To our knowledge, the PDE
formulation of the Wasserstein metric has not been presented for dealing with
image comparison, nor has the Wasserstein distance been used within the
$k$-nearest neighbour architecture.
</dc:description>
 <dc:description>Comment: 15 pages, 14 figures</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00185</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection of collaborative activity with Kinect depth cameras</dc:title>
 <dc:creator>Sevrin, Lo&#xef;c</dc:creator>
 <dc:creator>Noury, Norbert</dc:creator>
 <dc:creator>Abouchi, Nacer</dc:creator>
 <dc:creator>Jumel, Fabrice</dc:creator>
 <dc:creator>Massot, Bertrand</dc:creator>
 <dc:creator>Saraydaryan, Jacques</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The health status of elderly subjects is highly correlated to their
activities together with their social interactions. Thus, the long term
monitoring in home of their health status, shall also address the analysis of
collaborative activities. This paper proposes a preliminary approach of such a
system which can detect the simultaneous presence of several subjects in a
common area using Kinect depth cameras. Most areas in home being dedicated to
specific tasks, the localization enables the classification of tasks, whether
collaborative or not. A scenario of a 24 hours day shrunk into 24 minutes was
used to validate our approach. It pointed out the need of artifacts removal to
reach high specificity and good sensitivity.
</dc:description>
 <dc:description>Comment: Engineering in Medicine and Biology Society (EMBC), 2016</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00185</dc:identifier>
 <dc:identifier>doi:10.1109/EMBC.2016.7592089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00186</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An impossibility theorem for paired comparisons</dc:title>
 <dc:creator>Csat&#xf3;, L&#xe1;szl&#xf3;</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>15A06, 91B14</dc:subject>
 <dc:description>  In several decision-making problems, alternatives should be ranked on the
basis of paired comparisons between them. We present an axiomatic approach for
the universal ranking problem with arbitrary preference intensities, incomplete
and multiple comparisons. In particular, two basic properties - independence of
irrelevant matches and self-consistency - are considered. It is revealed that
there exists no ranking method satisfying both requirements at the same time.
The impossibility result holds under various restrictions on the set of ranking
problems, however, it does not emerge in the case of round-robin tournaments.
An interesting and more general possibility result is obtained by restricting
the domain of independence of irrelevant matches through the concept of
macrovertex.
</dc:description>
 <dc:description>Comment: 16 pages, 4 figures</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00188</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Orthogonal Parametrisation of Recurrent Neural Networks Using
  Householder Reflections</dc:title>
 <dc:creator>Mhammedi, Zakaria</dc:creator>
 <dc:creator>Hellicar, Andrew</dc:creator>
 <dc:creator>Rahman, Ashfaqur</dc:creator>
 <dc:creator>Bailey, James</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The problem of learning long-term dependencies in sequences using Recurrent
Neural Networks (RNNs) is still a major challenge. Recent methods have been
suggested to solve this problem by constraining the transition matrix to be
unitary during training which ensures that its norm is equal to one and
prevents exploding gradients. These methods either have limited expressiveness
or scale poorly with the size of the network when compared with the simple RNN
case, especially when using stochastic gradient descent with a small mini-batch
size. Our contributions are as follows; we first show that constraining the
transition matrix to be unitary is a special case of an orthogonal constraint.
Then we present a new parametrisation of the transition matrix which allows
efficient training of an RNN while ensuring that the matrix is always
orthogonal. Our results show that the orthogonal constraint on the transition
matrix applied through our parametrisation gives similar benefits to the
unitary constraint, without the time complexity limitations.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00190</identifier>
 <datestamp>2016-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Equilibrium Computation in Atomic Splittable Singleton Congestion Games</dc:title>
 <dc:creator>Timmermans, Veerle</dc:creator>
 <dc:creator>Harks, Tobias</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We devise the first polynomial time algorithm computing a pure Nash
equilibrium for atomic splittable congestion games with singleton strategies
and player-specific affine cost functions. Our algorithm is purely
combinatorial and computes the exact equilibrium assuming rational input. The
idea is to reduce equilibrium computation to the problem of computing an
equilibrium for an associated integrally-splittable singleton congestion game
in which the players can only split their demands in integral multiples of a
common packet size. While these integral games have been considered in the
literature before, no polynomial time algorithm computing an equilibrium was
known. Also for this class, we devise the first polynomial time algorithm and
use it as a building block for our main algorithm.
</dc:description>
 <dc:description>Comment: Corrected choice of minimum required packet size</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2016-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00192</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flight Dynamics-based Recovery of a UAV Trajectory using Ground Cameras</dc:title>
 <dc:creator>Rozantsev, Artem</dc:creator>
 <dc:creator>Sinha, Sudipta N.</dc:creator>
 <dc:creator>Dey, Debadeepta</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We propose a new method to estimate the 6-dof trajectory of a flying object
such as a quadrotor UAV within a 3D airspace monitored using multiple fixed
ground cameras. It is based on a new structure from motion formulation for the
3D reconstruction of a single moving point with known motion dynamics. Our main
contribution is a new bundle adjustment procedure which in addition to
optimizing the camera poses, regularizes the point trajectory using a prior
based on motion dynamics (or specifically flight dynamics). Furthermore, we can
infer the underlying control input sent to the UAV's autopilot that determined
its flight trajectory.
  Our method requires neither perfect single-view tracking nor appearance
matching across views. For robustness, we allow the tracker to generate
multiple detections per frame in each video. The true detections and the data
association across videos is estimated using robust multi-view triangulation
and subsequently refined during our bundle adjustment procedure. Quantitative
evaluation on simulated data and experiments on real videos from indoor and
outdoor scenes demonstrates the effectiveness of our method.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00192</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2017.266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00193</identifier>
 <datestamp>2017-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning molecular energies using localized graph kernels</dc:title>
 <dc:creator>Ferr&#xe9;, G.</dc:creator>
 <dc:creator>Haut, T.</dc:creator>
 <dc:creator>Barros, K.</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent machine learning methods make it possible to model potential energy of
atomic configurations with chemical-level accuracy (as calculated from
ab-initio calculations) and at speeds suitable for molecular dynam- ics
simulation. Best performance is achieved when the known physical constraints
are encoded in the machine learning models. For example, the atomic energy is
invariant under global translations and rotations, it is also invariant to
permutations of same-species atoms. Although simple to state, these symmetries
are complicated to encode into machine learning algorithms. In this paper, we
present a machine learning approach based on graph theory that naturally
incorporates translation, rotation, and permutation symmetries. Specifically,
we use a random walk graph kernel to measure the similarity of two adjacency
matrices, each of which represents a local atomic environment. This Graph
Approximated Energy (GRAPE) approach is flexible and admits many possible
extensions. We benchmark a simple version of GRAPE by predicting atomization
energies on a standard dataset of organic molecules.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00193</dc:identifier>
 <dc:identifier>The Journal of Chemical Physics, 146(11), 114107 (2017)</dc:identifier>
 <dc:identifier>doi:10.1063/1.4978623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00197</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning in an Uncertain World: Representing Ambiguity Through Multiple
  Hypotheses</dc:title>
 <dc:creator>Rupprecht, Christian</dc:creator>
 <dc:creator>Laina, Iro</dc:creator>
 <dc:creator>DiPietro, Robert</dc:creator>
 <dc:creator>Baust, Maximilian</dc:creator>
 <dc:creator>Tombari, Federico</dc:creator>
 <dc:creator>Navab, Nassir</dc:creator>
 <dc:creator>Hager, Gregory D.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many prediction tasks contain uncertainty. In some cases, uncertainty is
inherent in the task itself. In future prediction, for example, many distinct
outcomes are equally valid. In other cases, uncertainty arises from the way
data is labeled. For example, in object detection, many objects of interest
often go unlabeled, and in human pose estimation, occluded joints are often
labeled with ambiguous values. In this work we focus on a principled approach
for handling such scenarios. In particular, we propose a framework for
reformulating existing single-prediction models as multiple hypothesis
prediction (MHP) models and an associated meta loss and optimization procedure
to train them. To demonstrate our approach, we consider four diverse
applications: human pose estimation, future prediction, image classification
and segmentation. We find that MHP models outperform their single-hypothesis
counterparts in all cases, and that MHP models simultaneously expose valuable
insights into the variability of predictions.
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00203</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of the Human-Computer Interaction on the Example of Image-based
  CAPTCHA by Association Rule Mining</dc:title>
 <dc:creator>Brodi&#x107;, Darko</dc:creator>
 <dc:creator>Amelio, Alessia</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The paper analyzes the interaction between humans and computers in terms of
response time in solving the image-based CAPTCHA. In particular, the analysis
focuses on the attitude of the different Internet users in easily solving four
different types of image-based CAPTCHAs which include facial expressions like:
animated character, old woman, surprised face, worried face. To pursue this
goal, an experiment is realized involving 100 Internet users in solving the
four types of CAPTCHAs, differentiated by age, Internet experience, and
education level. The response times are collected for each user. Then,
association rules are extracted from user data, for evaluating the dependence
of the response time in solving the CAPTCHA from age, education level and
experience in internet usage by statistical analysis. The results implicitly
capture the users' psychological states showing in what states the users are
more sensible. It reveals to be a novelty and a meaningful analysis in the
state-of-the-art.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures, 6 tables, 5th International Workshop on
  Symbiotic Interaction (Symbiotic), Padua, Italy, 29-30 September 2016</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00204</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forensics Acquisition and Analysis of instant messaging and VoIP
  applications</dc:title>
 <dc:creator>Sgaras, Christos</dc:creator>
 <dc:creator>Kechadi, M-Tahar</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The advent of the Internet has significantly transformed the daily activities
of millions of people, with one of them being the way people communicate where
Instant Messaging (IM) and Voice over IP (VoIP) communications have become
prevalent. Although IM applications are ubiquitous communication tools
nowadays, it was observed that the relevant research on the topic of evidence
collection from IM services was limited. The reason is an IM can serve as a
very useful yet very dangerous platform for the victim and the suspect to
communicate. Indeed, the increased use of Instant Messengers on smart phones
has turned to be the goldmine for mobile and computer forensic experts. Traces
and Evidence left by applications can be held on smart phones and retrieving
those potential evidences with right forensic technique is strongly required.
Recently, most research on IM forensics focus on applications such as WhatsApp,
Viber and Skype. However, in the literature, there are very few forensic
analysis and comparison related to IM applications such as WhatsApp, Viber and
Skype and Tango on both iOS and Android platforms, even though the total users
of this application already exceeded 1 billion. Therefore, in this paper we
present forensic acquisition and analysis of these four IMs and VoIPs for both
iOS and Android platforms. We try to answer on how evidence can be collected
when IM communications are used. We also define taxonomy of target artefacts in
order to guide and structure the subsequent forensic analysis. Finally, a
review of the information that can become available via the IM vendor was
conducted. The achieved results of this research provided elaborative answers
on the types of artifacts that can be identified by these IM and VoIP
applications. We compare moreover the forensics analysis of these popular
applications: WhatApp, Skype, Viber and Tango.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00211</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mismatched Multi-Letter Successive Decoding for the Multiple-Access
  Channel</dc:title>
 <dc:creator>Scarlett, Jonathan</dc:creator>
 <dc:creator>Martinez, Alfonso</dc:creator>
 <dc:creator>F&#xe0;bregas, Albert Guill&#xe9;n i</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies channel coding for the discrete memoryless multiple-access
channel with a given (possibly suboptimal) decoding rule. A multi-letter
successive decoding rule depending on an arbitrary non-negative decoding metric
is considered, and achievable rate regions and error exponents are derived both
for the standard MAC (independent codebooks), and for the cognitive MAC (one
user knows both messages) with superposition coding. In the cognitive case, the
rate region and error exponent are shown to be tight with respect to the
ensemble average. The rate regions are compared with those of the
commonly-considered decoder that chooses the message pair maximizing the
decoding metric, and numerical examples are given for which successive decoding
yields a strictly higher sum rate for a given pair of input distributions.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00212</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Bit Fully Convolutional Network for Fast Semantic Segmentation</dc:title>
 <dc:creator>Wen, He</dc:creator>
 <dc:creator>Zhou, Shuchang</dc:creator>
 <dc:creator>Liang, Zhe</dc:creator>
 <dc:creator>Zhang, Yuxiang</dc:creator>
 <dc:creator>Feng, Dieqiao</dc:creator>
 <dc:creator>Zhou, Xinyu</dc:creator>
 <dc:creator>Yao, Cong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Fully convolutional neural networks give accurate, per-pixel prediction for
input images and have applications like semantic segmentation. However, a
typical FCN usually requires lots of floating point computation and large
run-time memory, which effectively limits its usability. We propose a method to
train Bit Fully Convolution Network (BFCN), a fully convolutional neural
network that has low bit-width weights and activations. Because most of its
computation-intensive convolutions are accomplished between low bit-width
numbers, a BFCN can be accelerated by an efficient bit-convolution
implementation. On CPU, the dot product operation between two bit vectors can
be reduced to bitwise operations and popcounts, which can offer much higher
throughput than 32-bit multiplications and additions.
  To validate the effectiveness of BFCN, we conduct experiments on the PASCAL
VOC 2012 semantic segmentation task and Cityscapes. Our BFCN with 1-bit weights
and 2-bit activations, which runs 7.8x faster on CPU or requires less than 1\%
resources on FPGA, can achieve comparable performance as the 32-bit
counterpart.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00215</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Generate Images of Outdoor Scenes from Attributes and
  Semantic Layouts</dc:title>
 <dc:creator>Karacan, Levent</dc:creator>
 <dc:creator>Akata, Zeynep</dc:creator>
 <dc:creator>Erdem, Aykut</dc:creator>
 <dc:creator>Erdem, Erkut</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic image synthesis research has been rapidly growing with deep
networks getting more and more expressive. In the last couple of years, we have
observed images of digits, indoor scenes, birds, chairs, etc. being
automatically generated. The expressive power of image generators have also
been enhanced by introducing several forms of conditioning variables such as
object names, sentences, bounding box and key-point locations. In this work, we
propose a novel deep conditional generative adversarial network architecture
that takes its strength from the semantic layout and scene attributes
integrated as conditioning variables. We show that our architecture is able to
generate realistic outdoor scene images under different conditions, e.g.
day-night, sunny-foggy, with clear object boundaries.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00220</identifier>
 <datestamp>2017-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully Convolutional Crowd Counting On Highly Congested Scenes</dc:title>
 <dc:creator>Marsden, Mark</dc:creator>
 <dc:creator>McGuinness, Kevin</dc:creator>
 <dc:creator>Little, Suzanne</dc:creator>
 <dc:creator>O'Connor, Noel E.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we advance the state-of-the-art for crowd counting in high
density scenes by further exploring the idea of a fully convolutional crowd
counting model introduced by (Zhang et al., 2016). Producing an accurate and
robust crowd count estimator using computer vision techniques has attracted
significant research interest in recent years. Applications for crowd counting
systems exist in many diverse areas including city planning, retail, and of
course general public safety. Developing a highly generalised counting model
that can be deployed in any surveillance scenario with any camera perspective
is the key objective for research in this area. Techniques developed in the
past have generally performed poorly in highly congested scenes with several
thousands of people in frame (Rodriguez et al., 2011). Our approach, influenced
by the work of (Zhang et al., 2016), consists of the following contributions:
(1) A training set augmentation scheme that minimises redundancy among training
samples to improve model generalisation and overall counting performance; (2) a
deep, single column, fully convolutional network (FCN) architecture; (3) a
multi-scale averaging step during inference. The developed technique can
analyse images of any resolution or aspect ratio and achieves state-of-the-art
counting performance on the Shanghaitech Part B and UCF CC 50 datasets as well
as competitive performance on Shanghaitech Part A.
</dc:description>
 <dc:description>Comment: 7 pages , VISAPP 2017</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00221</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Coconut Model with Heterogeneous Strategies and Learning</dc:title>
 <dc:creator>Banisch, Sven</dc:creator>
 <dc:creator>Olbrich, Eckehard</dc:creator>
 <dc:subject>Quantitative Finance - Economics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>91-08, 68T05, 60J10</dc:subject>
 <dc:description>  In this paper, we develop an agent-based version of the Diamond search
equilibrium model - also called Coconut Model. In this model, agents are faced
with production decisions that have to be evaluated based on their expectations
about the future utility of the produced entity which in turn depends on the
global production level via a trading mechanism. While the original dynamical
systems formulation assumes an infinite number of homogeneously adapting agents
obeying strong rationality conditions, the agent-based setting allows to
discuss the effects of heterogeneous and adaptive expectations and enables the
analysis of non-equilibrium trajectories. Starting from a baseline
implementation that matches the asymptotic behavior of the original model, we
show how agent heterogeneity can be accounted for in the aggregate dynamical
equations. We then show that when agents adapt their strategies by a simple
temporal difference learning scheme, the system converges to one of the fixed
points of the original system. Systematic simulations reveal that this is the
only stable equilibrium solution.
</dc:description>
 <dc:description>Comment: Accepted for publication in the Journal of Artificial Societies and
  Social Simulation (JASSS)</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00222</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interaction Networks for Learning about Objects, Relations and Physics</dc:title>
 <dc:creator>Battaglia, Peter W.</dc:creator>
 <dc:creator>Pascanu, Razvan</dc:creator>
 <dc:creator>Lai, Matthew</dc:creator>
 <dc:creator>Rezende, Danilo</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Reasoning about objects, relations, and physics is central to human
intelligence, and a key goal of artificial intelligence. Here we introduce the
interaction network, a model which can reason about how objects in complex
systems interact, supporting dynamical predictions, as well as inferences about
the abstract properties of the system. Our model takes graphs as input,
performs object- and relation-centric reasoning in a way that is analogous to a
simulation, and is implemented using deep neural networks. We evaluate its
ability to reason about several challenging physical domains: n-body problems,
rigid-body collision, and non-rigid dynamics. Our results show it can be
trained to accurately simulate the physical trajectories of dozens of objects
over thousands of time steps, estimate abstract quantities such as energy, and
generalize automatically to systems with different numbers and configurations
of objects and relations. Our interaction network implementation is the first
general-purpose, learnable physics engine, and a powerful general framework for
reasoning about object and relations in a wide variety of complex real-world
domains.
</dc:description>
 <dc:description>Comment: Published in NIPS 2016</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00227</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Coreferring Text-extracted Event Descriptions with the aid of
  Ontological Reasoning</dc:title>
 <dc:creator>Borgo, Stefano</dc:creator>
 <dc:creator>Bozzato, Loris</dc:creator>
 <dc:creator>Aprosio, Alessio Palmero</dc:creator>
 <dc:creator>Rospocher, Marco</dc:creator>
 <dc:creator>Serafini, Luciano</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  Systems for automatic extraction of semantic information about events from
large textual resources are now available: these tools are capable to generate
RDF datasets about text extracted events and this knowledge can be used to
reason over the recognized events. On the other hand, text based tasks for
event recognition, as for example event coreference (i.e. recognizing whether
two textual descriptions refer to the same event), do not take into account
ontological information of the extracted events in their process. In this
paper, we propose a method to derive event coreference on text extracted event
data using semantic based rule reasoning. We demonstrate our method considering
a limited (yet representative) set of event types: we introduce a formal
analysis on their ontological properties and, on the base of this, we define a
set of coreference criteria. We then implement these criteria as RDF-based
reasoning rules to be applied on text extracted event data. We evaluate the
effectiveness of our approach over a standard coreference benchmark dataset.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00234</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Captioning with Multi-Faceted Attention</dc:title>
 <dc:creator>Long, Xiang</dc:creator>
 <dc:creator>Gan, Chuang</dc:creator>
 <dc:creator>de Melo, Gerard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, video captioning has been attracting an increasing amount of
interest, due to its potential for improving accessibility and information
retrieval. While existing methods rely on different kinds of visual features
and model structures, they do not fully exploit relevant semantic information.
We present an extensible approach to jointly leverage several sorts of visual
features and semantic attributes. Our novel architecture builds on LSTMs for
sentence generation, with several attention layers and two multimodal layers.
The attention mechanism learns to automatically select the most salient visual
features or semantic attributes, and the multimodal layer yields overall
representations for the input and outputs of the sentence generation component.
Experimental results on the challenging MSVD and MSR-VTT datasets show that our
framework outperforms the state-of-the-art approaches, while ground truth based
semantic attributes are able to further elevate the output quality to a
near-human level.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00240</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Evaluation of Models for Runtime Approximation in Link Discovery</dc:title>
 <dc:creator>Georgala, Kleanthi</dc:creator>
 <dc:creator>Hoffmann, Micheal</dc:creator>
 <dc:creator>Ngomo, Axel-Cyrille Ngonga</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Time-efficient link discovery is of central importance to implement the
vision of the Semantic Web. Some of the most rapid Link Discovery approaches
rely internally on planning to execute link specifications. In newer works,
linear models have been used to estimate the runtime the fastest planners.
However, no other category of models has been studied for this purpose so far.
In this paper, we study non-linear runtime estimation functions for runtime
estimation. In particular, we study exponential and mixed models for the
estimation of the runtimes of planners. To this end, we evaluate three
different models for runtime on six datasets using 400 link specifications. We
show that exponential and mixed models achieve better fits when trained but are
only to be preferred in some cases. Our evaluation also shows that the use of
better runtime approximation models has a positive impact on the overall
execution of link specifications.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00241</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A biology journal that can teach physicists a lesson in peer review</dc:title>
 <dc:creator>Goldstein, Raymond E.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Quantitative Biology - Cell Behavior</dc:subject>
 <dc:description>  This is a Commentary in $Physics~Today$ on the novel review process developed
by the biology journal $eLife$, with the suggestion that it be adopted by
physics journals.
</dc:description>
 <dc:description>Comment: 3 pages</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00241</dc:identifier>
 <dc:identifier>Physics Today 69(12), 10 (2016)</dc:identifier>
 <dc:identifier>doi:10.1063/PT.3.3378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00246</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilingual Multiword Expressions</dc:title>
 <dc:creator>Poddar, Lahari</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The project aims to provide a semi-supervised approach to identify Multiword
Expressions in a multilingual context consisting of English and most of the
major Indian languages. Multiword expressions are a group of words which refers
to some conventional or regional way of saying things. If they are literally
translated from one language to another the expression will lose its inherent
meaning.
  To automatically extract multiword expressions from a corpus, an extraction
pipeline have been constructed which consist of a combination of rule based and
statistical approaches. There are several types of multiword expressions which
differ from each other widely by construction. We employ different methods to
detect different types of multiword expressions. Given a POS tagged corpus in
English or any Indian language the system initially applies some regular
expression filters to narrow down the search space to certain patterns (like,
reduplication, partial reduplication, compound nouns, compound verbs, conjunct
verbs etc.). The word sequences matching the required pattern are subjected to
a series of linguistic tests which include verb filtering, named entity
filtering and hyphenation filtering test to exclude false positives. The
candidates are then checked for semantic relationships among themselves (using
Wordnet). In order to detect partial reduplication we make use of Wordnet as a
lexical database as well as a tool for lemmatising. We detect complex
predicates by investigating the features of the constituent words. Statistical
methods are applied to detect collocations. Finally, lexicographers examine the
list of automatically extracted candidates to validate whether they are true
multiword expressions or not and add them to the multiword dictionary
accordingly.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00252</identifier>
 <datestamp>2017-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disjoint-union partial algebras</dc:title>
 <dc:creator>Hirsch, Robin</dc:creator>
 <dc:creator>McLean, Brett</dc:creator>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  Disjoint union is a partial binary operation returning the union of two sets
if they are disjoint and undefined otherwise. A disjoint-union partial algebra
of sets is a collection of sets closed under disjoint unions, whenever they are
defined. We provide a recursive first-order axiomatisation of the class of
partial algebras isomorphic to a disjoint-union partial algebra of sets but
prove that no finite axiomatisation exists. We do the same for other signatures
including one or both of disjoint union and subset complement, another partial
binary operation we define.
  Domain-disjoint union is a partial binary operation on partial functions,
returning the union if the arguments have disjoint domains and undefined
otherwise. For each signature including one or both of domain-disjoint union
and subset complement and optionally including composition, we consider the
class of partial algebras isomorphic to a collection of partial functions
closed under the operations. Again the classes prove to be axiomatisable, but
not finitely axiomatisable, in first-order logic.
  We define the notion of pairwise combinability. For each of the previously
considered signatures, we examine the class isomorphic to a partial algebra of
sets/partial functions under an isomorphism mapping arbitrary suprema of
pairwise combinable sets to the corresponding disjoint unions. We prove that
for each case the class is not closed under elementary equivalence.
  However, when intersection is added to any of the signatures considered, the
isomorphism class of the partial algebras of sets is finitely axiomatisable and
in each case we give such an axiomatisation.
</dc:description>
 <dc:description>Comment: 30 pages</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00252</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 2 (June 22,
  2017) lmcs:3730</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-13(2:10)2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00260</identifier>
 <datestamp>2017-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Factory of realities: on the emergence of virtual spatiotemporal
  structures</dc:title>
 <dc:creator>Zapatrin, Roman</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The ubiquitous nature of modern Information Retrieval and Virtual World give
rise to new realities. To what extent are these &quot;realities&quot; real? Which
&quot;physics&quot; should be applied to quantitatively describe them? In this essay I
dwell on few examples. The first is Adaptive neural networks, which are not
networks and not neural, but still provide service similar to classical ANNs in
extended fashion. The second is the emergence of objects looking like
Einsteinian spacetime, which describe the behavior of an Internet surfer like
geodesic motion. The third is the demonstration of nonclassical and even
stronger-than-quantum probabilities in Information Retrieval, their use.
  Immense operable datasets provide new operationalistic environments, which
become to greater and greater extent &quot;realities&quot;. In this essay, I consider the
overall Information Retrieval process as an objective physical process,
representing it according to Melucci metaphor in terms of physical-like
experiments. Various semantic environments are treated as analogs of various
realities. The readers' attention is drawn to topos approach to physical
theories, which provides a natural conceptual and technical framework to cope
with the new emerging realities.
</dc:description>
 <dc:description>Comment: 21 pp</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00260</dc:identifier>
 <dc:identifier>doi:10.1142/9781783268320_0008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00271</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mitigation of relative intensity noise of Quantum Dash mode-locked
  lasers for PAM4 based optical interconnects using encoding techniques</dc:title>
 <dc:creator>Vujicic, Vidak</dc:creator>
 <dc:creator>Anthur, Aravind P.</dc:creator>
 <dc:creator>Saljoghei, Arsalan</dc:creator>
 <dc:creator>Panapakkam, Vivek</dc:creator>
 <dc:creator>Zhou, Rui</dc:creator>
 <dc:creator>Gaimard, Quentin</dc:creator>
 <dc:creator>Merghem, Ramel</dc:creator>
 <dc:creator>Lelarge, Francois</dc:creator>
 <dc:creator>Ramdane, Abderrahi</dc:creator>
 <dc:creator>Barry, Liam P.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Quantum Dash (Q-Dash) Passively Mode-Locked Lasers (PMLLs) exhibit
significant low frequency Relative Intensity Noise (RIN), due to the high Mode
Partition Noise (MPN), which prevents the implementation of multilevel
amplitude modulation formats such as PAM4. The authors demonstrate low
frequency RIN mitigation by employing 8B/10B and Manchester encoding with PAM4
modulation format. These encoding techniques reduce the overlap between the
modulation spectral content and the low-frequency RIN of the Q-Dash devices, at
the expense of increased overhead. The RIN of the 33.6 GHz free spectral range
Q-Dash PMLL was characterized, and the results obtained show very high levels
of RIN from DC to 4 GHz, but low levels for higher frequencies. The performance
improvement for 28 GBaud 8B/10B and Manchester encoded PAM4 signal has been
demonstrated compared to the case when no encoding is used. Finally, the effect
of RIN on the system performance was demonstrated by comparing the Bit Error
Rate (BER) performance of the PAM4 signaling obtained with an External Cavity
Laser (ECL) to those obtained with Q-Dash PMLL.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00271</dc:identifier>
 <dc:identifier>doi:10.1364/OE.25.000020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00272</identifier>
 <datestamp>2017-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software-Defined Silicon Photonics based Metro Node for Spatial and
  Wavelength Superchannel Switching</dc:title>
 <dc:creator>Vujicic, Vidak</dc:creator>
 <dc:creator>Anthur, Aravind P.</dc:creator>
 <dc:creator>Gazman, Alexander</dc:creator>
 <dc:creator>Browning, Colm</dc:creator>
 <dc:creator>Pascual, M. Deseada Gutierrez</dc:creator>
 <dc:creator>Zhu, Ziyi</dc:creator>
 <dc:creator>Bergman, Keren</dc:creator>
 <dc:creator>Barry, Liam P.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Due to the growing popularity of optical superchannels and software defined
networking, reconfigurable optical add-drop multiplexer (ROADM) architectures
for superchannel switching have recently attracted significant attention.
ROADMs based on micro electro-mechanical system (MEMS) and liquid
crystal-on-silicon (LCoS) technologies are predominantly used. Motivated by
requirements for low power, high-speed, small area footprint and compact
switching solutions, we propose and demonstrate spatial and wavelength flexible
superchannel switching using monolithically integrated silicon photonics (SiP)
micro-ring resonators (MRR). We demonstrate the MRRs capabilities and potential
to be used as a fundamental building block in ROADMs. Unicast and multicast
switching operation of an entire superchannel is demonstrated after
transmission over 50 km of standard single mode fiber. The performance of each
sub-channel from the 120 Gb/s QPSK Nyquist superchannel is analyzed and
degradation in error vector magnitude performance was observed for outer
sub-channels due to the 3-dB bandwidth of the MRRs, which is comparable with
the superchannel bandwidth. However, all sub-channels for all switching cases
(unicast, multicast and bi-directional operation) exhibit performance far below
the 7% FEC limit. The switching time of the SiP MRR chip is such that high
capacity superchannel interconnects between users can be setup and reconfigured
on the microsecond timescale.
</dc:description>
 <dc:date>2016-11-29</dc:date>
 <dc:date>2017-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00276</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Hat Game and covering codes</dc:title>
 <dc:creator>van Uem, Theo</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The Hat Game (Ebert's Hat Problem) got much attention in the beginning of
this century; not in the last place by it's connections to coding theory and
computer science. There were publications in The New York Times, Die Zeit and
abcNews. Exact solutions with two colors are only known in the symmetric case
(equal probabilities for the two players) when N=2^k-1 (using Hamming codes),
N=2^k (extended Hamming codes) and up to N=9 (using bounds on covering codes of
radius 1), where N is the number of players. How the probabilities and
strategies behave when the two colors are not equally likely (asymmetric case),
is an open problem. Where the symmetric case is hard, both mathematically and
from the point of view of computational complexity, we may expect the
asymmetric case to be harder and perhaps beyond the capabilities of
contemporary mathematics and computer science. However there is a surprising
answer to the open problem: elementary mathematics in combination with adequate
computer programs suffices to do the job and the new approach gives also new
insights in the classical symmetric case. Where the standard theory in the
symmetric case works with Hamming codes and covering sets of radius 1, the new
approach deals with adequate sets of radius N-1. Our main results in this paper
are: a simple and effective way to analyze N-person two color hat problems,
and: a dramatically decrease of computational complexity.
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00277</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparsity Preserving Algorithms for Octagons</dc:title>
 <dc:creator>Jourdan, Jacques-Henri</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Known algorithms for manipulating octagons do not preserve their sparsity,
leading typically to quadratic or cubic time and space complexities even if no
relation among variables is known when they are all bounded. In this paper, we
present new algorithms, which use and return octagons represented as weakly
closed difference bound matrices, preserve the sparsity of their input and have
better performance in the case their inputs are sparse. We prove that these
algorithms are as precise as the known ones.
</dc:description>
 <dc:description>Comment: in Isabella Mastroeni. Numerical and symbolic abstract domains, Sep
  2016, Edinburgh, United Kingdom. Elsevier, Numerical and symbolic abstract
  domains, pp.14, 2016</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00291</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aggressive Quadrotor Flight through Narrow Gaps with Onboard Sensing and
  Computing using Active Vision</dc:title>
 <dc:creator>Falanga, Davide</dc:creator>
 <dc:creator>Mueggler, Elias</dc:creator>
 <dc:creator>Faessler, Matthias</dc:creator>
 <dc:creator>Scaramuzza, Davide</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We address one of the main challenges towards autonomous quadrotor flight in
complex environments, which is flight through narrow gaps. While previous works
relied on off-board localization systems or on accurate prior knowledge of the
gap position and orientation, we rely solely on onboard sensing and computing
and estimate the full state by fusing gap detection from a single onboard
camera with an IMU. This problem is challenging for two reasons: (i) the
quadrotor pose uncertainty with respect to the gap increases quadratically with
the distance from the gap; (ii) the quadrotor has to actively control its
orientation towards the gap to enable state estimation (i.e., active vision).
We solve this problem by generating a trajectory that considers geometric,
dynamic, and perception constraints: during the approach maneuver, the
quadrotor always faces the gap to allow state estimation, while respecting the
vehicle dynamics; during the traverse through the gap, the distance of the
quadrotor to the edges of the gap is maximized. Furthermore, we replan the
trajectory during its execution to cope with the varying uncertainty of the
state estimate. We successfully evaluate and demonstrate the proposed approach
in many real experiments. To the best of our knowledge, this is the first work
that addresses and achieves autonomous, aggressive flight through narrow gaps
using only onboard sensing and computing and without prior knowledge of the
pose of the gap.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00305</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Body Schema Estimation using Tactile Information obtained
  through Coordinated Random Movements</dc:title>
 <dc:creator>Mimura, Tomohiro</dc:creator>
 <dc:creator>Hagiwara, Yoshinobu</dc:creator>
 <dc:creator>Taniguchi, Tadahiro</dc:creator>
 <dc:creator>Inamura, Tetsunari</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper describes a computational model, called the Dirichlet process
Gaussian mixture model with latent joints (DPGMM-LJ), that can find latent tree
structure embedded in data distribution in an unsupervised manner. By combining
DPGMM-LJ and a pre-existing body map formation method, we propose a method that
enables an agent having multi-link body structure to discover its kinematic
structure, i.e., body schema, from tactile information alone. The DPGMM-LJ is a
probabilistic model based on Bayesian nonparametrics and an extension of
Dirichlet process Gaussian mixture model (DPGMM). In a simulation experiment,
we used a simple fetus model that had five body parts and performed structured
random movements in a womb-like environment. It was shown that the method could
estimate the number of body parts and kinematic structures without any
pre-existing knowledge in many cases. Another experiment showed that the degree
of motor coordination in random movements affects the result of body schema
formation strongly. It is confirmed that the accuracy rate for body schema
estimation had the highest value 84.6% when the ratio of motor coordination was
0.9 in our setting. These results suggest that kinematic structure can be
estimated from tactile information obtained by a fetus moving randomly in a
womb without any visual information even though its accuracy was not so high.
They also suggest that a certain degree of motor coordination in random
movements and the sufficient dimension of state space that represents the body
map are important to estimate body schema correctly.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00309</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison Between IPv4 to IPv6 Transition Techniques</dc:title>
 <dc:creator>Cordeiro, Edwin</dc:creator>
 <dc:creator>Carnier, Rodrigo</dc:creator>
 <dc:creator>Zucchi, Wagner L</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  The IPv4 addresses exhaustion demands a protocol transition from IPv4 to
IPv6. The original transition technique, the dual stack, is not widely deployed
yet and it demanded the creation of new transition techniques to extend the
transition period. This work makes an experimental comparison of techniques
that use dual stack with a limited IPv4 address. This limited address might be
a RFC 1918 address with a NAT at the Internet Service Provider (ISP) gateway,
also known as Carrier Grade NAT (CGN), or an Address Plus Port (A+P) shared
IPv4 address. The chosen techniques also consider an IPv6 only ISP network. The
transport of the IPv4 packets through the IPv6 only networks may use IPv4
packets encapsulated on IPv6 packets or a double translation, by making one
IPv4 to IPv6 translation to enter the IPv6 only network and one IPv6 to IPv4
translation to return to the IPv4 network. The chosen techniques were DS-Lite,
464XLAT, MAP-E and MAP-T. The first part of the test is to check some of the
most common usages of the Internet by a home user and the impacts of the
transition techniques on the user experience. The second part is a measured
comparison considering bandwidth, jitter and latency introduced by the
techniques and processor usage on the network equipment.
</dc:description>
 <dc:description>Comment: 11 pages, 8 figures</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00323</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Tyranny of Data? The Bright and Dark Sides of Data-Driven
  Decision-Making for Social Good</dc:title>
 <dc:creator>Lepri, Bruno</dc:creator>
 <dc:creator>Staiano, Jacopo</dc:creator>
 <dc:creator>Sangokoya, David</dc:creator>
 <dc:creator>Letouz&#xe9;, Emmanuel</dc:creator>
 <dc:creator>Oliver, Nuria</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The unprecedented availability of large-scale human behavioral data is
profoundly changing the world we live in. Researchers, companies, governments,
financial institutions, non-governmental organizations and also citizen groups
are actively experimenting, innovating and adapting algorithmic decision-making
tools to understand global patterns of human behavior and provide decision
support to tackle problems of societal importance. In this chapter, we focus
our attention on social good decision-making algorithms, that is algorithms
strongly influencing decision-making and resource optimization of public goods,
such as public health, safety, access to finance and fair employment. Through
an analysis of specific use cases and approaches, we highlight both the
positive opportunities that are created through data-driven algorithmic
decision-making, and the potential negative consequences that practitioners
should be aware of and address in order to truly realize the potential of this
emergent field. We elaborate on the need for these algorithms to provide
transparency and accountability, preserve privacy and be tested and evaluated
in context, by means of living lab approaches involving citizens. Finally, we
turn to the requirements which would make it possible to leverage the
predictive power of data-driven human behavior analysis while ensuring
transparency, accountability, and civic participation.
</dc:description>
 <dc:description>Comment: preprint version; book chapter to appear in &quot;Transparent Data Mining
  for Big and Small Data&quot;, Studies in Big Data Series, Springer</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00330</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A controlled experiment for the empirical evaluation of safety analysis
  techniques for safety-critical software</dc:title>
 <dc:creator>Abdulkhaleq, Asim</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Context: Today's safety critical systems are increasingly reliant on
software. Software becomes responsible for most of the critical functions of
systems. Many different safety analysis techniques have been developed to
identify hazards of systems. FTA and FMEA are most commonly used by safety
analysts. Recently, STPA has been proposed with the goal to better cope with
complex systems including software. Objective: This research aimed at comparing
quantitatively these three safety analysis techniques with regard to their
effectiveness, applicability, understandability, ease of use and efficiency in
identifying software safety requirements at the system level. Method: We
conducted a controlled experiment with 21 master and bachelor students applying
these three techniques to three safety-critical systems: train door control,
anti-lock braking and traffic collision and avoidance. Results: The results
showed that there is no statistically significant difference between these
techniques in terms of applicability, understandability and ease of use, but a
significant difference in terms of effectiveness and efficiency is obtained.
Conclusion: We conclude that STPA seems to be an effective method to identify
software safety requirements at the system level. In particular, STPA addresses
more different software safety requirements than the traditional techniques FTA
and FMEA, but STPA needs more time to carry out by safety analysts with little
or no prior experience.
</dc:description>
 <dc:description>Comment: 10 pages, 1 figure in Proceedings of the 19th International
  Conference on Evaluation and Assessment in Software Engineering (EASE '15).
  ACM, 2015</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00330</dc:identifier>
 <dc:identifier>doi:10.1145/2745802.2745817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00334</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Theoretical Framework for Robustness of (Deep) Classifiers against
  Adversarial Examples</dc:title>
 <dc:creator>Wang, Beilun</dc:creator>
 <dc:creator>Gao, Ji</dc:creator>
 <dc:creator>Qi, Yanjun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most machine learning classifiers, including deep neural networks, are
vulnerable to adversarial examples. Such inputs are typically generated by
adding small but purposeful modifications that lead to incorrect outputs while
imperceptible to human eyes. The goal of this paper is not to introduce a
single method, but to make theoretical steps towards fully understanding
adversarial examples. By using concepts from topology, our theoretical analysis
brings forth the key reasons why an adversarial example can fool a classifier
($f_1$) and adds its oracle ($f_2$, like human eyes) in such analysis. By
investigating the topological relationship between two (pseudo)metric spaces
corresponding to predictor $f_1$ and oracle $f_2$, we develop necessary and
sufficient conditions that can determine if $f_1$ is always robust
(strong-robust) against adversarial examples according to $f_2$. Interestingly
our theorems indicate that just one unnecessary feature can make $f_1$ not
strong-robust, and the right feature representation learning is the key to
getting a classifier that is both accurate and strong-robust.
</dc:description>
 <dc:description>Comment: 38 pages , ICLR 2017 Workshop Track</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00338</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hippocampus Temporal Lobe Epilepsy Detection using a Combination of
  Shape-based Features and Spherical Harmonics Representation</dc:title>
 <dc:creator>Kohan, Zohreh</dc:creator>
 <dc:creator>Farhidzadeh, Hamidreza</dc:creator>
 <dc:creator>Azmi, Reza</dc:creator>
 <dc:creator>Gholizadeh, Behrouz</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most of the temporal lobe epilepsy detection approaches are based on
hippocampus deformation and use complicated features, resulting, detection is
done with complicated features extraction and pre-processing task. In this
paper, a new detection method based on shape-based features and spherical
harmonics is proposed which can analysis the hippocampus shape anomaly and
detection asymmetry. This method consisted of two main parts; (1) shape feature
extraction, and (2) image classification. For evaluation, HFH database is used
which is publicly available in this field. Nine different geometry and 256
spherical harmonic features are introduced then selected Eighteen of them that
detect the asymmetry in hippocampus significantly in a randomly selected subset
of the dataset. Then a support vector machine (SVM) classifier was employed to
classify the remaining images of the dataset to normal and epileptic images
using our selected features. On a dataset of 25 images, 12 images were used for
feature extraction and the rest 13 for classification. The results show that
the proposed method has accuracy, specificity and sensitivity of, respectively,
84%, 100%, and 80%. Therefore, the proposed approach shows acceptable result
and is straightforward also; complicated pre-processing steps were omitted
compared to other methods.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2016-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00341</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Compositional Object-Based Approach to Learning Physical Dynamics</dc:title>
 <dc:creator>Chang, Michael B.</dc:creator>
 <dc:creator>Ullman, Tomer</dc:creator>
 <dc:creator>Torralba, Antonio</dc:creator>
 <dc:creator>Tenenbaum, Joshua B.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present the Neural Physics Engine (NPE), a framework for learning
simulators of intuitive physics that naturally generalize across variable
object count and different scene configurations. We propose a factorization of
a physical scene into composable object-based representations and a neural
network architecture whose compositional structure factorizes object dynamics
into pairwise interactions. Like a symbolic physics engine, the NPE is endowed
with generic notions of objects and their interactions; realized as a neural
network, it can be trained via stochastic gradient descent to adapt to specific
object properties and dynamics of different worlds. We evaluate the efficacy of
our approach on simple rigid body dynamics in two-dimensional worlds. By
comparing to less structured architectures, we show that the NPE's
compositional representation of the structure in physical interactions improves
its ability to predict movement, generalize across variable object count and
different scene configurations, and infer latent properties of objects such as
mass.
</dc:description>
 <dc:description>Comment: Published as a conference paper for ICLR 2017. 15 pages, 6 figures</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00343</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Minimum for a Finsler Elastica Minimal Path Approach</dc:title>
 <dc:creator>Chen, Da</dc:creator>
 <dc:creator>Mirebeau, Jean-Marie</dc:creator>
 <dc:creator>Cohen, Laurent D.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel curvature-penalized minimal path model via
an orientation-lifted Finsler metric and the Euler elastica curve. The original
minimal path model computes the globally minimal geodesic by solving an Eikonal
partial differential equation (PDE). Essentially, this first-order model is
unable to penalize curvature which is related to the path rigidity property in
the classical active contour models. To solve this problem, we present an
Eikonal PDE-based Finsler elastica minimal path approach to address the
curvature-penalized geodesic energy minimization problem. We were successful at
adding the curvature penalization to the classical geodesic energy. The basic
idea of this work is to interpret the Euler elastica bending energy via a novel
Finsler elastica metric that embeds a curvature penalty. This metric is
non-Riemannian, anisotropic and asymmetric, and is defined over an
orientation-lifted space by adding to the image domain the orientation as an
extra space dimension. Based on this orientation lifting, the proposed minimal
path model can benefit from both the curvature and orientation of the paths.
Thanks to the fast marching method, the global minimum of the
curvature-penalized geodesic energy can be computed efficiently. We introduce
two anisotropic image data-driven speed functions that are computed by
steerable filters. Based on these orientation-dependent speed functions, we can
apply the proposed Finsler elastica minimal path model to the applications of
closed contour detection, perceptual grouping and tubular structure extraction.
Numerical experiments on both synthetic and real images show that these
applications of the proposed model indeed obtain promising results.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00343</dc:identifier>
 <dc:identifier>International Journal of Computer Vision, Volume 122, Issue 3, pp
  458-483, 2017</dc:identifier>
 <dc:identifier>doi:10.1007/s11263-016-0975-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00347</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bootstrapping incremental dialogue systems: using linguistic knowledge
  to learn from minimal data</dc:title>
 <dc:creator>Kalatzis, Dimitrios</dc:creator>
 <dc:creator>Eshghi, Arash</dc:creator>
 <dc:creator>Lemon, Oliver</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We present a method for inducing new dialogue systems from very small amounts
of unannotated dialogue data, showing how word-level exploration using
Reinforcement Learning (RL), combined with an incremental and semantic grammar
- Dynamic Syntax (DS) - allows systems to discover, generate, and understand
many new dialogue variants. The method avoids the use of expensive and
time-consuming dialogue act annotations, and supports more natural
(incremental) dialogues than turn-based systems. Here, language generation and
dialogue management are treated as a joint decision/optimisation problem, and
the MDP model for RL is constructed automatically. With an implemented system,
we show that this method enables a wide range of dialogue variations to be
automatically captured, even when the system is trained from only a single
dialogue. The variants include question-answer pairs, over- and
under-answering, self- and other-corrections, clarification interaction,
split-utterances, and ellipsis. This generalisation property results from the
structural knowledge and constraints present within the DS grammar, and
highlights some limitations of recent systems built using machine learning
techniques only.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00352</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Evaluation of Caching Policies in NDN - an ICN Architecture</dc:title>
 <dc:creator>Shailendra, Samar</dc:creator>
 <dc:creator>Sengottuvelan, Senthilmurugan</dc:creator>
 <dc:creator>Rath, Hemant Kumar</dc:creator>
 <dc:creator>Panigrahi, Bighnaraj</dc:creator>
 <dc:creator>Simha, Anantha</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Information Centric Networking (ICN) advocates the philosophy of accessing
the content independent of its location. Owing to this location independence in
ICN, the routers en-route can be enabled to cache the content to serve the
future requests for the same content locally. Several ICN architectures have
been proposed in the literature along with various caching algorithms for
caching and cache replacement at the routers en-route. The aim of this paper is
to critically evaluate various caching policies using Named Data Networking
(NDN), an ICN architecture proposed in literature. We have presented the
performance comparison of different caching policies naming First In First Out
(FIFO), Least Recently Used (LRU), and Universal Caching (UC) in two network
models; Watts-Strogatz (WS) model (suitable for dense short link networks such
as sensor networks) and Sprint topology (better suited for large Internet
Service Provider (ISP) networks) using ndnSIM, an ns3 based discrete event
simulator for NDN architecture. Our results indicate that UC outperforms other
caching policies such as LRU and FIFO and makes UC a better alternative for
both sensor networks and ISP networks.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00356</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Large Deformation Diffeomorphic Approach to Registration of CLARITY
  Images via Mutual Information</dc:title>
 <dc:creator>Kutten, Kwame S.</dc:creator>
 <dc:creator>Charon, Nicolas</dc:creator>
 <dc:creator>Miller, Michael I.</dc:creator>
 <dc:creator>Ratnanather, J. T.</dc:creator>
 <dc:creator>Matelsky, Jordan</dc:creator>
 <dc:creator>Baden, Alexander D.</dc:creator>
 <dc:creator>Lillaney, Kunal</dc:creator>
 <dc:creator>Deisseroth, Karl</dc:creator>
 <dc:creator>Ye, Li</dc:creator>
 <dc:creator>Vogelstein, Joshua T.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  CLARITY is a method for converting biological tissues into translucent and
porous hydrogel-tissue hybrids. This facilitates interrogation with light sheet
microscopy and penetration of molecular probes while avoiding physical slicing.
In this work, we develop a pipeline for registering CLARIfied mouse brains to
an annotated brain atlas. Due to the novelty of this microscopy technique it is
impractical to use absolute intensity values to align these images to existing
standard atlases. Thus we adopt a large deformation diffeomorphic approach for
registering images via mutual information matching. Furthermore we show how a
cascaded multi-resolution approach can improve registration quality while
reducing algorithm run time. As acquired image volumes were over a terabyte in
size, they were far too large for work on personal computers. Therefore the
NeuroData computational infrastructure was deployed for multi-resolution
storage and visualization of these images and aligned annotations on the web.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00367</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-scale Validation of Counterfactual Learning Methods: A Test-Bed</dc:title>
 <dc:creator>Lefortier, Damien</dc:creator>
 <dc:creator>Swaminathan, Adith</dc:creator>
 <dc:creator>Gu, Xiaotao</dc:creator>
 <dc:creator>Joachims, Thorsten</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The ability to perform effective off-policy learning would revolutionize the
process of building better interactive systems, such as search engines and
recommendation systems for e-commerce, computational advertising and news.
Recent approaches for off-policy evaluation and learning in these settings
appear promising. With this paper, we provide real-world data and a
standardized test-bed to systematically investigate these algorithms using data
from display advertising. In particular, we consider the problem of filling a
banner ad with an aggregate of multiple products the user may want to purchase.
This paper presents our test-bed, the sanity checks we ran to ensure its
validity, and shows results comparing state-of-the-art off-policy learning
methods like doubly robust optimization, POEM, and reductions to supervised
learning using regression baselines. Our results show experimental evidence
that recent off-policy learning methods can improve upon state-of-the-art
supervised learning techniques on a large-scale real-world data set.
</dc:description>
 <dc:description>Comment: 10 pages, What If workshop NIPS 2016</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00369</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Ideas for Brain Modelling 3</dc:title>
 <dc:creator>Greer, Kieran</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This paper considers a process for the creation and subsequent firing of
sequences of neuronal patterns, as might be found in the human brain. The scale
is one of larger patterns emerging from an ensemble mass, possibly through some
type of energy equation and a reduction procedure. The links between the
patterns can be formed naturally, as a residual effect of the pattern creation
itself. This paper follows-on closely from the earlier research, including two
earlier papers in the series and uses the ideas of entropy and cohesion. With a
small addition, it is possible to show how the inter-pattern links can be
determined. A new compact Grid form of an earlier Counting Mechanism is also
demonstrated. It is possible to explain how a very basic repeating structure
can form the arbitrary patterns and activation sequences between them, and a
key question of how nodes synchronise may even be answerable. The paper
finishes with an implementation architecture, for the realisation and storage
of knowledge and memory, as part of a general design, based on distributed
neural components.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00369</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00370</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Image Captioning via Policy Gradient optimization of SPIDEr</dc:title>
 <dc:creator>Liu, Siqi</dc:creator>
 <dc:creator>Zhu, Zhenhai</dc:creator>
 <dc:creator>Ye, Ning</dc:creator>
 <dc:creator>Guadarrama, Sergio</dc:creator>
 <dc:creator>Murphy, Kevin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Current image captioning methods are usually trained via (penalized) maximum
likelihood estimation. However, the log-likelihood score of a caption does not
correlate well with human assessments of quality. Standard syntactic evaluation
metrics, such as BLEU, METEOR and ROUGE, are also not well correlated. The
newer SPICE and CIDEr metrics are better correlated, but have traditionally
been hard to optimize for. In this paper, we show how to use a policy gradient
(PG) method to directly optimize a linear combination of SPICE and CIDEr (a
combination we call SPIDEr): the SPICE score ensures our captions are
semantically faithful to the image, while CIDEr score ensures our captions are
syntactically fluent. The PG method we propose improves on the prior MIXER
approach, by using Monte Carlo rollouts instead of mixing MLE training with PG.
We show empirically that our algorithm leads to easier optimization and
improved results compared to MIXER. Finally, we show that using our PG method
we can optimize any of the metrics, including the proposed SPIDEr metric which
results in image captions that are strongly preferred by human raters compared
to captions generated by the same model but trained to optimize MLE or the COCO
metrics.
</dc:description>
 <dc:description>Comment: Under review at ICCV 2017</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00374</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Decompositions for Large Scale SVMs</dc:title>
 <dc:creator>Thomann, Philipp</dc:creator>
 <dc:creator>Steinwart, Ingo</dc:creator>
 <dc:creator>Blaschzyk, Ingrid</dc:creator>
 <dc:creator>Meister, Mona</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Although support vector machines (SVMs) are theoretically well understood,
their underlying optimization problem becomes very expensive if, for example,
hundreds of thousands of samples and a non-linear kernel are considered.
Several approaches have been proposed in the past to address this serious
limitation. In this work we investigate a decomposition strategy that learns on
small, spatially defined data chunks. Our contributions are two fold: On the
theoretical side we establish an oracle inequality for the overall learning
method using the hinge loss, and show that the resulting rates match those
known for SVMs solving the complete optimization problem with Gaussian kernels.
On the practical side we compare our approach to learning SVMs on small,
randomly chosen chunks. Here it turns out that for comparable training times
our approach is significantly faster during testing and also reduces the test
error in most cases significantly. Furthermore, we show that our approach
easily scales up to 10 million training samples: including hyper-parameter
selection using cross validation, the entire training only takes a few hours on
a single machine. Finally, we report an experiment on 32 million training
samples.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00377</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Piecewise Latent Variables for Neural Variational Text Processing</dc:title>
 <dc:creator>Serban, Iulian V.</dc:creator>
 <dc:creator>Ororbia II, Alexander G.</dc:creator>
 <dc:creator>Pineau, Joelle</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Advances in neural variational inference have facilitated the learning of
powerful directed graphical models with continuous latent variables, such as
variational autoencoders. The hope is that such models will learn to represent
rich, multi-modal latent factors in real-world data, such as natural language
text. However, current models often assume simplistic priors on the latent
variables - such as the uni-modal Gaussian distribution - which are incapable
of representing complex latent factors efficiently. To overcome this
restriction, we propose the simple, but highly flexible, piecewise constant
distribution. This distribution has the capacity to represent an exponential
number of modes of a latent target distribution, while remaining mathematically
tractable. Our results demonstrate that incorporating this new latent
distribution into different models yields substantial improvements in natural
language processing tasks such as document modeling and natural language
generation for dialogue.
</dc:description>
 <dc:description>Comment: 19 pages, 2 figures, 8 tables; EMNLP 2017</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-09-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00380</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Playing Doom with SLAM-Augmented Deep Reinforcement Learning</dc:title>
 <dc:creator>Bhatti, Shehroze</dc:creator>
 <dc:creator>Desmaison, Alban</dc:creator>
 <dc:creator>Miksik, Ondrej</dc:creator>
 <dc:creator>Nardelli, Nantas</dc:creator>
 <dc:creator>Siddharth, N.</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A number of recent approaches to policy learning in 2D game domains have been
successful going directly from raw input images to actions. However when
employed in complex 3D environments, they typically suffer from challenges
related to partial observability, combinatorial exploration spaces, path
planning, and a scarcity of rewarding scenarios. Inspired from prior work in
human cognition that indicates how humans employ a variety of semantic concepts
and abstractions (object categories, localisation, etc.) to reason about the
world, we build an agent-model that incorporates such abstractions into its
policy-learning framework. We augment the raw image input to a Deep Q-Learning
Network (DQN), by adding details of objects and structural elements
encountered, along with the agent's localisation. The different components are
automatically extracted and composed into a topological representation using
on-the-fly object detection and 3D-scene reconstruction.We evaluate the
efficacy of our approach in Doom, a 3D first-person combat game that exhibits a
number of challenges discussed, and show that our augmented framework
consistently learns better, more effective policies.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00383</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tuning the Scheduling of Distributed Stochastic Gradient Descent with
  Bayesian Optimization</dc:title>
 <dc:creator>Dalibard, Valentin</dc:creator>
 <dc:creator>Schaarschmidt, Michael</dc:creator>
 <dc:creator>Yoneki, Eiko</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present an optimizer which uses Bayesian optimization to tune the system
parameters of distributed stochastic gradient descent (SGD). Given a specific
context, our goal is to quickly find efficient configurations which
appropriately balance the load between the available machines to minimize the
average SGD iteration time. Our experiments consider setups with over thirty
parameters. Traditional Bayesian optimization, which uses a Gaussian process as
its model, is not well suited to such high dimensional domains. To reduce
convergence time, we exploit the available structure. We design a probabilistic
model which simulates the behavior of distributed SGD and use it within
Bayesian optimization. Our model can exploit many runtime measurements for
inference per evaluation of the objective function. Our experiments show that
our resulting optimizer converges to efficient configurations within ten
iterations, the optimized configurations outperform those found by generic
optimizer in thirty iterations by up to 2X.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00385</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Attention-Gated Model for Robust Sequence Classification</dc:title>
 <dc:creator>Pei, Wenjie</dc:creator>
 <dc:creator>Baltru&#x161;aitis, Tadas</dc:creator>
 <dc:creator>Tax, David M. J.</dc:creator>
 <dc:creator>Morency, Louis-Philippe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Typical techniques for sequence classification are designed for
well-segmented sequences which have been edited to remove noisy or irrelevant
parts. Therefore, such methods cannot be easily applied on noisy sequences
expected in real-world applications. In this paper, we present the Temporal
Attention-Gated Model (TAGM) which integrates ideas from attention models and
gated recurrent networks to better deal with noisy or unsegmented sequences.
Specifically, we extend the concept of attention model to measure the relevance
of each observation (time step) of a sequence. We then use a novel gated
recurrent network to learn the hidden representation for the final prediction.
An important advantage of our approach is interpretability since the temporal
attention weights provide a meaningful value for the salience of each time step
in the sequence. We demonstrate the merits of our TAGM approach, both for
prediction accuracy and interpretability, on three different tasks: spoken
digit recognition, text-based sentiment analysis and visual event recognition.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2017</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00388</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diet2Vec: Multi-scale analysis of massive dietary data</dc:title>
 <dc:creator>Tansey, Wesley</dc:creator>
 <dc:creator>Lowe Jr., Edward W.</dc:creator>
 <dc:creator>Scott, James G.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Smart phone apps that enable users to easily track their diets have become
widespread in the last decade. This has created an opportunity to discover new
insights into obesity and weight loss by analyzing the eating habits of the
users of such apps. In this paper, we present diet2vec: an approach to modeling
latent structure in a massive database of electronic diet journals. Through an
iterative contract-and-expand process, our model learns real-valued embeddings
of users' diets, as well as embeddings for individual foods and meals. We
demonstrate the effectiveness of our approach on a real dataset of 55K users of
the popular diet-tracking app LoseIt\footnote{http://www.loseit.com/}. To the
best of our knowledge, this is the largest fine-grained diet tracking study in
the history of nutrition and obesity research. Our results suggest that
diet2vec finds interpretable results at all levels, discovering intuitive
representations of foods, meals, and diets.
</dc:description>
 <dc:description>Comment: Accepted to the NIPS 2016 Workshop on Machine Learning for Health</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00390</identifier>
 <datestamp>2016-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anomaly Detection in Video Using Predictive Convolutional Long
  Short-Term Memory Networks</dc:title>
 <dc:creator>Medel, Jefferson Ryan</dc:creator>
 <dc:creator>Savakis, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automating the detection of anomalous events within long video sequences is
challenging due to the ambiguity of how such events are defined. We approach
the problem by learning generative models that can identify anomalies in videos
using limited supervision. We propose end-to-end trainable composite
Convolutional Long Short-Term Memory (Conv-LSTM) networks that are able to
predict the evolution of a video sequence from a small number of input frames.
Regularity scores are derived from the reconstruction errors of a set of
predictions with abnormal video sequences yielding lower regularity scores as
they diverge further from the actual sequence over time. The models utilize a
composite structure and examine the effects of conditioning in learning more
meaningful representations. The best model is chosen based on the
reconstruction and prediction accuracy. The Conv-LSTM models are evaluated both
qualitatively and quantitatively, demonstrating competitive results on anomaly
detection datasets. Conv-LSTM units are shown to be an effective tool for
modeling and predicting video sequences.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2016-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00393</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hypervolume-based Multi-objective Bayesian Optimization with Student-t
  Processes</dc:title>
 <dc:creator>van der Herten, Joachim</dc:creator>
 <dc:creator>Couckuyt, Ivo</dc:creator>
 <dc:creator>Dhaene, Tom</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Student-$t$ processes have recently been proposed as an appealing alternative
non-parameteric function prior. They feature enhanced flexibility and
predictive variance. In this work the use of Student-$t$ processes are explored
for multi-objective Bayesian optimization. In particular, an analytical
expression for the hypervolume-based probability of improvement is developed
for independent Student-$t$ process priors of the objectives. Its effectiveness
is shown on a multi-objective optimization problem which is known to be
difficult with traditional Gaussian processes.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00394</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Definition Modeling: Learning to define word embeddings in natural
  language</dc:title>
 <dc:creator>Noraset, Thanapon</dc:creator>
 <dc:creator>Liang, Chen</dc:creator>
 <dc:creator>Birnbaum, Larry</dc:creator>
 <dc:creator>Downey, Doug</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Distributed representations of words have been shown to capture lexical
semantics, as demonstrated by their effectiveness in word similarity and
analogical relation tasks. But, these tasks only evaluate lexical semantics
indirectly. In this paper, we study whether it is possible to utilize
distributed representations to generate dictionary definitions of words, as a
more direct and transparent representation of the embeddings' semantics. We
introduce definition modeling, the task of generating a definition for a given
word and its embedding. We present several definition model architectures based
on recurrent neural networks, and experiment with the models over multiple data
sets. Our results show that a model that controls dependencies between the word
being defined and the definition words performs significantly better, and that
a character-level convolution layer designed to leverage morphology can
complement word-level embeddings. Finally, an error analysis suggests that the
errors made by a definition model may provide insight into the shortcomings of
word embeddings.
</dc:description>
 <dc:description>Comment: To appear in AAAI Conference 2017</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00397</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximal Sections of Sheaves of Data over an Abstract Simplicial Complex</dc:title>
 <dc:creator>Praggastis, Brenda</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:description>  We employ techniques from topological data analysis to model sensor networks.
Our approach to sensor integration uses the topological method of sheaves over
cell complexes. The internal consistency of data from individual sensors is
determined by a set of consistency functions assigned to elements of the
complex. Using these functions we determine, for any collection of data, the
unique set of maximal sections of consistent data received from the sensors. We
offer a proof for the existence and uniqueness of these sections and illustrate
the ideas with examples.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00402</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reduced Order Models for Pricing European and American Options under
  Stochastic Volatility and Jump-Diffusion Models</dc:title>
 <dc:creator>Balajewicz, Maciej</dc:creator>
 <dc:creator>Toivanen, Jari</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Finance - Computational Finance</dc:subject>
 <dc:description>  European options can be priced by solving parabolic partial(-integro)
differential equations under stochastic volatility and jump-diffusion models
like Heston, Merton, and Bates models. American option prices can be obtained
by solving linear complementary problems (LCPs) with the same operators. A
finite difference discretization leads to a so-called full order model (FOM).
Reduced order models (ROMs) are derived employing proper orthogonal
decomposition (POD). The early exercise constraint of American options is
enforced by a penalty on subset of grid points. The presented numerical
experiments demonstrate that pricing with ROMs can be orders of magnitude
faster within a given model parameter variation range.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00404</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Shape Abstractions by Assembling Volumetric Primitives</dc:title>
 <dc:creator>Tulsiani, Shubham</dc:creator>
 <dc:creator>Su, Hao</dc:creator>
 <dc:creator>Guibas, Leonidas J.</dc:creator>
 <dc:creator>Efros, Alexei A.</dc:creator>
 <dc:creator>Malik, Jitendra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a learning framework for abstracting complex shapes by learning to
assemble objects using 3D volumetric primitives. In addition to generating
simple and geometrically interpretable explanations of 3D objects, our
framework also allows us to automatically discover and exploit consistent
structure in the data. We demonstrate that using our method allows predicting
shape representations which can be leveraged for obtaining a consistent parsing
across the instances of a shape collection and constructing an interpretable
shape similarity measure. We also examine applications for image-based
prediction as well as shape manipulation.
</dc:description>
 <dc:description>Comment: Project url: https://shubhtuls.github.io/volumetricPrimitives/</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-06-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00407</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Governed Blockchains for Financial Process Authentications</dc:title>
 <dc:creator>Lundbaek, Leif-Nissen</dc:creator>
 <dc:creator>D'Iddio, Andrea Callia</dc:creator>
 <dc:creator>Huth, Michael</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We propose the formal study of governed blockchains that are owned and
controlled by organizations and that neither create cryptocurrencies nor
provide any incentives to solvers of cryptographic puzzles. We view such
approaches as frameworks in which system parts, such as the cryptographic
puzzle, may be instantiated with different technology. Owners of such a
blockchain procure puzzle solvers as resources they control, and use a
mathematical model to compute optimal parameters for the cryptographic puzzle
mechanism or other parts of the blockchain. We illustrate this approach with a
use case in which blockchains record hashes of financial process transactions
to increase their trustworthiness and that of their audits. For Proof of Work
as cryptographic puzzle, we develop a detailed mathematical model to derive
MINLP optimization problems for computing optimal Proof of Work configuration
parameters that trade off potentially conflicting aspects such as availability,
resiliency, security, and cost in this governed setting. We demonstrate the
utility of such a mining calculus by solving some instances of this problem.
This experimental validation is strengthened by statistical experiments that
confirm the validity of random variables used in formulating our mathematical
model. We hope that our work may facilitate the creation of domain-specific
blockchains for a wide range of applications such as trustworthy information in
Internet of Things systems and bespoke improvements of legacy financial
services.
</dc:description>
 <dc:description>Comment: 25 pages, 4 tables, minor corrections and edits throughout second
  version, updated relation work in second version, statistical evaluation of
  random variable for disputes added in second version</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00408</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computerized Multiparametric MR image Analysis for Prostate Cancer
  Aggressiveness-Assessment</dc:title>
 <dc:creator>Banerjee, Imon</dc:creator>
 <dc:creator>Hahn, Lewis</dc:creator>
 <dc:creator>Sonn, Geoffrey</dc:creator>
 <dc:creator>Fan, Richard</dc:creator>
 <dc:creator>Rubin, Daniel L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose an automated method for detecting aggressive prostate cancer(CaP)
(Gleason score &gt;=7) based on a comprehensive analysis of the lesion and the
surrounding normal prostate tissue which has been simultaneously captured in
T2-weighted MR images, diffusion-weighted images (DWI) and apparent diffusion
coefficient maps (ADC). The proposed methodology was tested on a dataset of 79
patients (40 aggressive, 39 non-aggressive). We evaluated the performance of a
wide range of popular quantitative imaging features on the characterization of
aggressive versus non-aggressive CaP. We found that a group of 44
discriminative predictors among 1464 quantitative imaging features can be used
to produce an area under the ROC curve of 0.73.
</dc:description>
 <dc:description>Comment: NIPS 2016 Workshop on Machine Learning for Health (NIPS ML4HC)</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00408</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00410</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Variational Information Bottleneck</dc:title>
 <dc:creator>Alemi, Alexander A.</dc:creator>
 <dc:creator>Fischer, Ian</dc:creator>
 <dc:creator>Dillon, Joshua V.</dc:creator>
 <dc:creator>Murphy, Kevin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present a variational approximation to the information bottleneck of
Tishby et al. (1999). This variational approach allows us to parameterize the
information bottleneck model using a neural network and leverage the
reparameterization trick for efficient training. We call this method &quot;Deep
Variational Information Bottleneck&quot;, or Deep VIB. We show that models trained
with the VIB objective outperform those that are trained with other forms of
regularization, in terms of generalization performance and robustness to
adversarial attack.
</dc:description>
 <dc:description>Comment: 19 pages, 8 figures, Accepted to ICLR17</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00414</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Nash Equilibrium Seeking via the Alternating Direction
  Method of Multipliers</dc:title>
 <dc:creator>Salehisadaghiani, Farzad</dc:creator>
 <dc:creator>Pavel, Lacra</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, the problem of finding a Nash equilibrium of a multi-player
game is considered. The players are only aware of their own cost functions as
well as the action space of all players. We develop a relatively fast algorithm
within the framework of inexact-ADMM. It requires a communication graph for the
information exchange between the players as well as a few mild assumptions on
cost functions. The convergence proof of the algorithm to a Nash equilibrium of
the game is then provided. Moreover, the convergence rate is investigated via
simulations.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00423</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TorontoCity: Seeing the World with a Million Eyes</dc:title>
 <dc:creator>Wang, Shenlong</dc:creator>
 <dc:creator>Bai, Min</dc:creator>
 <dc:creator>Mattyus, Gellert</dc:creator>
 <dc:creator>Chu, Hang</dc:creator>
 <dc:creator>Luo, Wenjie</dc:creator>
 <dc:creator>Yang, Bin</dc:creator>
 <dc:creator>Liang, Justin</dc:creator>
 <dc:creator>Cheverie, Joel</dc:creator>
 <dc:creator>Fidler, Sanja</dc:creator>
 <dc:creator>Urtasun, Raquel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we introduce the TorontoCity benchmark, which covers the full
greater Toronto area (GTA) with 712.5 $km^2$ of land, 8439 $km$ of road and
around 400,000 buildings. Our benchmark provides different perspectives of the
world captured from airplanes, drones and cars driving around the city.
Manually labeling such a large scale dataset is infeasible. Instead, we propose
to utilize different sources of high-precision maps to create our ground truth.
Towards this goal, we develop algorithms that allow us to align all data
sources with the maps while requiring minimal human supervision. We have
designed a wide variety of tasks including building height estimation
(reconstruction), road centerline and curb extraction, building instance
segmentation, building contour extraction (reorganization), semantic labeling
and scene type classification (recognition). Our pilot study shows that most of
these tasks are still difficult for modern convolutional neural networks.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00429</identifier>
 <datestamp>2017-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalizing Skills with Semi-Supervised Reinforcement Learning</dc:title>
 <dc:creator>Finn, Chelsea</dc:creator>
 <dc:creator>Yu, Tianhe</dc:creator>
 <dc:creator>Fu, Justin</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Deep reinforcement learning (RL) can acquire complex behaviors from low-level
inputs, such as images. However, real-world applications of such methods
require generalizing to the vast variability of the real world. Deep networks
are known to achieve remarkable generalization when provided with massive
amounts of labeled data, but can we provide this breadth of experience to an RL
agent, such as a robot? The robot might continuously learn as it explores the
world around it, even while deployed. However, this learning requires access to
a reward function, which is often hard to measure in real-world domains, where
the reward could depend on, for example, unknown positions of objects or the
emotional state of the user. Conversely, it is often quite practical to provide
the agent with reward functions in a limited set of situations, such as when a
human supervisor is present or in a controlled setting. Can we make use of this
limited supervision, and still benefit from the breadth of experience an agent
might collect on its own? In this paper, we formalize this problem as
semisupervised reinforcement learning, where the reward function can only be
evaluated in a set of &quot;labeled&quot; MDPs, and the agent must generalize its
behavior to the wide range of states it might encounter in a set of &quot;unlabeled&quot;
MDPs, by using experience from both settings. Our proposed method infers the
task objective in the unlabeled MDPs through an algorithm that resembles
inverse RL, using the agent's own prior experience in the labeled MDPs as a
kind of demonstration of optimal behavior. We evaluate our method on
challenging tasks that require control directly from images, and show that our
approach can improve the generalization of a learned deep neural network policy
by using experience for which no reward function is available. We also show
that our method outperforms direct supervised learning of the reward.
</dc:description>
 <dc:description>Comment: ICLR 2017</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00437</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Pose and Cell Segmentation using Column Generation</dc:title>
 <dc:creator>Wang, Shaofei</dc:creator>
 <dc:creator>Zhang, Chong</dc:creator>
 <dc:creator>Gonzalez-Ballester, Miguel A.</dc:creator>
 <dc:creator>Yarkony, Julian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the problems of multi-person pose segmentation in natural images and
instance segmentation in biological images with crowded cells. We formulate
these distinct tasks as integer programs where variables correspond to
poses/cells. To optimize, we propose a generic relaxation scheme for solving
these combinatorial problems using a column generation formulation where the
program for generating a column is solved via exact optimization of very small
scale integer programs. This results in efficient exploration of the spaces of
poses and cells.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00443</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection of Dangerous Magnetic Field Ranges from Tablets by Clustering
  Analysis</dc:title>
 <dc:creator>Brodi&#x107;, Darko</dc:creator>
 <dc:creator>Amelio, Alessia</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  The paper considers the problem of the extremely low frequency magnetic field
radiation generated by the tablet computers. Accordingly, the measurement of
the magnetic field radiation from a set of tablets is carried out. Furthermore,
the measurement results are analyzed and clustered according to the K-Medians
algorithm to obtain different magnetic field ranges. The obtained cluster
ranges are evaluated according to the reference level proposed by the TCO
standard in order to define dangerous areas in the neighborhood of tablet,
which are established during the typical work with tablet computers. Analysis
shows that dangerous areas correspond to specific inner components of tablet,
and gives suggestions to users for a safe usage of tablet and to companies
producing tablet components for limiting the risk of magnetic field exposure.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, International Scientific Conference UNITECH,
  November 18-19, Gabrovo, Bulgaria</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00445</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Memory Address Translation</dc:title>
 <dc:creator>Picorel, Javier</dc:creator>
 <dc:creator>Jevdjic, Djordje</dc:creator>
 <dc:creator>Falsafi, Babak</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  Memory and logic integration on the same chip is becoming increasingly cost
effective, creating the opportunity to offload data-intensive functionality to
processing units placed inside memory chips. The introduction of memory-side
processing units (MPUs) into conventional systems faces virtual memory as the
first big showstopper: without efficient hardware support for address
translation MPUs have highly limited applicability. Unfortunately, conventional
translation mechanisms fall short of providing fast translations as
contemporary memories exceed the reach of TLBs, making expensive page walks
common.
  In this paper, we are the first to show that the historically important
flexibility to map any virtual page to any page frame is unnecessary in today's
servers. We find that while limiting the associativity of the
virtual-to-physical mapping incurs no penalty, it can break the
translate-then-fetch serialization if combined with careful data placement in
the MPU's memory, allowing for translation and data fetch to proceed
independently and in parallel. We propose the Distributed Inverted Page Table
(DIPTA), a near-memory structure in which the smallest memory partition keeps
the translation information for its data share, ensuring that the translation
completes together with the data fetch. DIPTA completely eliminates the
performance overhead of translation, achieving speedups of up to 3.81x and
2.13x over conventional translation using 4KB and 1GB pages respectively.
</dc:description>
 <dc:description>Comment: 15 pages, 9 figures</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00456</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterising radio telescope software with the Workload
  Characterisation Framework</dc:title>
 <dc:creator>Grange, Y. G.</dc:creator>
 <dc:creator>Lakhoo, R.</dc:creator>
 <dc:creator>Petschow, M.</dc:creator>
 <dc:creator>Wu, C.</dc:creator>
 <dc:creator>Veenboer, B.</dc:creator>
 <dc:creator>Emsley, I.</dc:creator>
 <dc:creator>Dijkema, T. J.</dc:creator>
 <dc:creator>Mechev, A. P.</dc:creator>
 <dc:creator>Mariani, G.</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>D.4.8</dc:subject>
 <dc:subject>K.6.2</dc:subject>
 <dc:description>  We present a modular framework, the Workload Characterisation Framework
(WCF), that is developed to reproducibly obtain, store and compare key
characteristics of radio astronomy processing software. As a demonstration, we
discuss the experiences using the framework to characterise a LOFAR calibration
and imaging pipeline.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures; to be published in ADASS XXVI (held October
  16-20, 2016) proceedings. See
  http://www.adass2016.inaf.it/images/posters/grange.pdf for the poster</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00467</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Document Embeddings for Intensive Care Patient Mortality
  Prediction</dc:title>
 <dc:creator>Grnarova, Paulina</dc:creator>
 <dc:creator>Schmidt, Florian</dc:creator>
 <dc:creator>Hyland, Stephanie L.</dc:creator>
 <dc:creator>Eickhoff, Carsten</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present an automatic mortality prediction scheme based on the unstructured
textual content of clinical notes. Proposing a convolutional document embedding
approach, our empirical investigation using the MIMIC-III intensive care
database shows significant performance gains compared to previously employed
methods such as latent topic distributions or generic doc2vec embeddings. These
improvements are especially pronounced for the difficult problem of
post-discharge mortality prediction.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00472</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised learning of image motion by recomposing sequences</dc:title>
 <dc:creator>Jaegle, Andrew</dc:creator>
 <dc:creator>Phillips, Stephen</dc:creator>
 <dc:creator>Ippolito, Daphne</dc:creator>
 <dc:creator>Daniilidis, Kostas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose a new method for learning a representation of image motion in an
unsupervised fashion. We do so by learning an image sequence embedding that
respects associativity and invertibility properties of composed sequences with
known temporal order. This procedure makes minimal assumptions about scene
content, and the resulting networks learn to exploit rigid and non-rigid motion
cues. We show that a deep neural network trained to respect these constraints
implicitly identifies the characteristic motion patterns of many different
sequence types.
  Our network architecture consists of a CNN followed by an LSTM and is
structured to learn motion representations over sequences of arbitrary length.
We demonstrate that a network trained using our unsupervised procedure on
real-world sequences of human actions and vehicle motion can capture semantic
regions corresponding to the motion in the scene, and not merely image-level
differences, without requiring any motion labels. Furthermore, we present
results that suggest our method can be used to extract information useful for
independent motion tracking, localization, and nearest neighbor identification.
Our results suggest that this representation may be useful for motion-related
tasks where explicit labels are often very difficult to obtain.
</dc:description>
 <dc:description>Comment: 14 pages, including references and supplement</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00475</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transfer Learning Across Patient Variations with Hidden Parameter Markov
  Decision Processes</dc:title>
 <dc:creator>Killian, Taylor</dc:creator>
 <dc:creator>Konidaris, George</dc:creator>
 <dc:creator>Doshi-Velez, Finale</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Due to physiological variation, patients diagnosed with the same condition
may exhibit divergent, but related, responses to the same treatments. Hidden
Parameter Markov Decision Processes (HiP-MDPs) tackle this transfer-learning
problem by embedding these tasks into a low-dimensional space. However, the
original formulation of HiP-MDP had a critical flaw: the embedding uncertainty
was modeled independently of the agent's state uncertainty, requiring an
unnatural training procedure in which all tasks visited every part of the state
space---possible for robots that can be moved to a particular location,
impossible for human patients. We update the HiP-MDP framework and extend it to
more robustly develop personalized medicine strategies for HIV treatment.
</dc:description>
 <dc:description>Comment: Brief abstract for poster submission to Machine Learning for
  Healthcare workshop at NIPS 2016</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00476</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extensive Large-Scale Study of Error in Samping-Based Distinct Value
  Estimators for Databases</dc:title>
 <dc:creator>Deolalikar, Vinay</dc:creator>
 <dc:creator>Laffitte, Hernan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  The problem of distinct value estimation has many applications. Being a
critical component of query optimizers in databases, it also has high
commercial impact. Many distinct value estimators have been proposed, using
various statistical approaches. However, characterizing the errors incurred by
these estimators is an open problem: existing analytical approaches are not
powerful enough, and extensive empirical studies at large scale do not exist.
We conduct an extensive large-scale empirical study of 11 distinct value
estimators from four different approaches to the problem over families of
Zipfian distributions whose parameters model real-world applications. Our study
is the first that \emph{scales to the size of a billion-rows} that today's
large commercial databases have to operate in. This allows us to characterize
the error that is encountered in real-world applications of distinct value
estimation. By mining the generated data, we show that estimator error depends
on a key latent parameter --- the average uniform class size --- that has not
been studied previously. This parameter also allows us to unearth error
patterns that were previously unknown. Importantly, ours is the first approach
that provides a framework for \emph{visualizing the error patterns} in distinct
value estimation, facilitating discussion of this problem in enterprise
settings. Our characterization of errors can be used for several problems in
distinct value estimation, such as the design of hybrid estimators. This work
aims at the practitioner and the researcher alike, and addresses questions
frequently asked by both audiences.
</dc:description>
 <dc:description>Comment: This is the full-length version of a shorter published paper, and
  includes supplementary material for the published paper. Please cite as
  &quot;Vinay Deolalikar and Hernan Laffitte: Extensive Large-Scale Study of Error
  in Samping-Based Distinct Value Estimators for Databases, IEEE Big Data
  Conference, Washington DC, December 2016.&quot;</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00478</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In Teacher We Trust: Learning Compressed Models for Pedestrian Detection</dc:title>
 <dc:creator>Shen, Jonathan</dc:creator>
 <dc:creator>Vesdapunt, Noranart</dc:creator>
 <dc:creator>Boddeti, Vishnu N.</dc:creator>
 <dc:creator>Kitani, Kris M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep convolutional neural networks continue to advance the state-of-the-art
in many domains as they grow bigger and more complex. It has been observed that
many of the parameters of a large network are redundant, allowing for the
possibility of learning a smaller network that mimics the outputs of the large
network through a process called Knowledge Distillation. We show, however, that
standard Knowledge Distillation is not effective for learning small models for
the task of pedestrian detection. To improve this process, we introduce a
higher-dimensional hint layer to increase information flow. We also estimate
the variance in the outputs of the large network and propose a loss function to
incorporate this uncertainty. Finally, we attempt to boost the complexity of
the small network without increasing its size by using as input hand-designed
features that have been demonstrated to be effective for pedestrian detection.
We succeed in training a model that contains $400\times$ fewer parameters than
the large network while outperforming AlexNet on the Caltech Pedestrian
Dataset.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00480</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Scalable and Adaptable Multiple-Place Foraging Algorithm for
  Ant-Inspired Robot Swarms</dc:title>
 <dc:creator>Lu, Qi</dc:creator>
 <dc:creator>Moses, Melanie E.</dc:creator>
 <dc:creator>Hecker, Joshua P.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Individual robots are not effective at exploring large unmapped areas. An
alternate approach is to use a swarm of simple robots that work together,
rather than a single highly capable robot. The central-place foraging algorithm
(CPFA) is effective for coordinating robot swarm search and collection tasks.
Robots start at a centrally placed location (nest), explore potential targets
in the area without global localization or central control, and return the
targets to the nest. The scalability of the CPFA is limited because large
numbers of robots produce more inter-robot collisions and large search areas
result in substantial travel costs. We address these problems with the
multiple-place foraging algorithm (MPFA), which uses multiple nests distributed
throughout the search area. Robots start from a randomly assigned home nest but
return to the closest nest with found targets. We simulate the foraging
behavior of robot swarms in the robot simulator ARGoS and employ a genetic
algorithm to discover different optimized foraging strategies as swarm sizes
and the number of targets are scaled up. In our experiments, the MPFA always
produces higher foraging rates, fewer collisions, and lower travel and search
time compared to the CPFA for the partially clustered targets distribution. The
main contribution of this paper is that we systematically quantify the
advantages of the MPFA (reduced travel time and collisions), the potential
disadvantages (less communication among robots), and the ability of a genetic
algorithm to tune MPFA parameters to mitigate search inefficiency due to less
communication.
</dc:description>
 <dc:description>Comment: Robotics: Science and Systems, Swarm robotics, Scalable System, 7
  pages, 10 figures</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00484</identifier>
 <datestamp>2016-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Calculus of Cyber-Physical Systems</dc:title>
 <dc:creator>Lanotte, Ruggero</dc:creator>
 <dc:creator>Merro, Massimo</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We propose a hybrid process calculus for modelling and reasoning on
cyber-physical systems (CPS{s}). The dynamics of the calculus is expressed in
terms of a labelled transition system in the SOS style of Plotkin. This is used
to define a bisimulation-based behavioural semantics which support
compositional reasonings. Finally, we prove run-time properties and system
equalities for a non-trivial case study.
</dc:description>
 <dc:description>Comment: 11th International Conference on Language and Automata Theory and
  Applications. arXiv admin note: text overlap with arXiv:1611.01377</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2016-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00485</identifier>
 <datestamp>2017-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulating with AcCoRD: Actor-Based Communication via Reaction-Diffusion</dc:title>
 <dc:creator>Noel, Adam</dc:creator>
 <dc:creator>Cheung, Karen C.</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:creator>Makrakis, Dimitrios</dc:creator>
 <dc:creator>Hafid, Abdelhakim</dc:creator>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  This paper introduces AcCoRD (Actor-based Communication via
Reaction-Diffusion) version 1.0. AcCoRD is a sandbox reaction-diffusion solver
designed for the study of molecular communication systems. It uses a hybrid of
microscopic and mesoscopic simulation models that enables scalability via user
control of local accuracy. AcCoRD is developed in C as an open source command
line tool and includes utilities to process simulation output in MATLAB. The
latest code and links to user documentation can be found at
https://github.com/adamjgnoel/AcCoRD/. This paper provides an overview of
AcCoRD's design, including the motivation for developing a specialized
reaction-diffusion solver. The corresponding algorithms are presented in
detail, including the computational complexity of the microscopic and
mesoscopic models. Other novel derivations include the transition rates between
adjacent mesoscopic subvolumes of different sizes. Simulation results
demonstrate the use of AcCoRD as both an accurate reaction-diffusion solver and
one that is catered to the analysis of molecular communication systems. A link
is included to videos that demonstrate many of the simulated scenarios.
Additional insights from the simulation results include the selection of
suitable hybrid model parameters, the impact of reactive surfaces that are in
the proximity of a hybrid interface, and the size of a bounded environment that
is necessary to assume that it is unbounded. The development of AcCoRD is
ongoing, so its future direction is also discussed in order to highlight
improvements that will expand its potential areas of application. New features
that are being planned at the time of writing include a fluid flow model and
more complex actor behavior.
</dc:description>
 <dc:description>Comment: 42 pages, 21 figures, 2 tables. To appear in Nano Communication
  Networks</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00485</dc:identifier>
 <dc:identifier>doi:10.1016/j.nancom.2017.02.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00496</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Bounding Box Estimation Using Deep Learning and Geometry</dc:title>
 <dc:creator>Mousavian, Arsalan</dc:creator>
 <dc:creator>Anguelov, Dragomir</dc:creator>
 <dc:creator>Flynn, John</dc:creator>
 <dc:creator>Kosecka, Jana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a method for 3D object detection and pose estimation from a single
image. In contrast to current techniques that only regress the 3D orientation
of an object, our method first regresses relatively stable 3D object properties
using a deep convolutional neural network and then combines these estimates
with geometric constraints provided by a 2D object bounding box to produce a
complete 3D bounding box. The first network output estimates the 3D object
orientation using a novel hybrid discrete-continuous loss, which significantly
outperforms the L2 loss. The second output regresses the 3D object dimensions,
which have relatively little variance compared to alternatives and can often be
predicted for many object types. These estimates, combined with the geometric
constraints on translation imposed by the 2D bounding box, enable us to recover
a stable and accurate 3D object pose. We evaluate our method on the challenging
KITTI object detection benchmark both on the official metric of 3D orientation
estimation and also on the accuracy of the obtained 3D bounding boxes. Although
conceptually simple, our method outperforms more complex and computationally
expensive approaches that leverage semantic segmentation, instance level
segmentation and flat ground priors and sub-category detection. Our
discrete-continuous loss also produces state of the art results for 3D
viewpoint estimation on the Pascal 3D+ dataset.
</dc:description>
 <dc:description>Comment: To appear in IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR) 2017</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00500</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object-Centric Representation Learning from Unlabeled Videos</dc:title>
 <dc:creator>Gao, Ruohan</dc:creator>
 <dc:creator>Jayaraman, Dinesh</dc:creator>
 <dc:creator>Grauman, Kristen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Supervised (pre-)training currently yields state-of-the-art performance for
representation learning for visual recognition, yet it comes at the cost of (1)
intensive manual annotations and (2) an inherent restriction in the scope of
data relevant for learning. In this work, we explore unsupervised feature
learning from unlabeled video. We introduce a novel object-centric approach to
temporal coherence that encourages similar representations to be learned for
object-like regions segmented from nearby frames. Our framework relies on a
Siamese-triplet network to train a deep convolutional neural network (CNN)
representation. Compared to existing temporal coherence methods, our idea has
the advantage of lightweight preprocessing of the unlabeled video (no tracking
required) while still being able to extract object-level regions from which to
learn invariances. Furthermore, as we show in results on several standard
datasets, our method typically achieves substantial accuracy gains over
competing unsupervised methods for image classification and retrieval tasks.
</dc:description>
 <dc:description>Comment: In Proceedings of the Asian Conference on Computer Vision (ACCV),
  2016</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00516</identifier>
 <datestamp>2017-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Canonical Correlation Analysis for Analyzing Sequences of Medical
  Billing Codes</dc:title>
 <dc:creator>Jones, Corinne L.</dc:creator>
 <dc:creator>Kakade, Sham M.</dc:creator>
 <dc:creator>Thornblade, Lucas W.</dc:creator>
 <dc:creator>Flum, David R.</dc:creator>
 <dc:creator>Flaxman, Abraham D.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose using canonical correlation analysis (CCA) to generate features
from sequences of medical billing codes. Applying this novel use of CCA to a
database of medical billing codes for patients with diverticulitis, we first
demonstrate that the CCA embeddings capture meaningful relationships among the
codes. We then generate features from these embeddings and establish their
usefulness in predicting future elective surgery for diverticulitis, an
important marker in efforts for reducing costs in healthcare.
</dc:description>
 <dc:description>Comment: Accepted at NIPS 2016 Workshop on Machine Learning for Health</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00521</identifier>
 <datestamp>2016-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Modeling of Distributed Deep Neural Networks</dc:title>
 <dc:creator>Hashemi, Sayed Hadi</dc:creator>
 <dc:creator>Noghabi, Shadi A.</dc:creator>
 <dc:creator>Gropp, William</dc:creator>
 <dc:creator>Campbell, Roy H</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  During the past decade, machine learning has become extremely popular and can
be found in many aspects of our every day life. Nowayadays with explosion of
data while rapid growth of computation capacity, Distributed Deep Neural
Networks (DDNNs) which can improve their performance linearly with more
computation resources, have become hot and trending. However, there has not
been an in depth study of the performance of these systems, and how well they
scale.
  In this paper we analyze CNTK, one of the most commonly used DDNNs, by first
building a performance model and then evaluating the system two settings: a
small cluster with all nodes in a single rack connected to a top of rack
switch, and in large scale using Blue Waters with arbitary placement of nodes.
Our main focus was the scalability of the system with respect to adding more
nodes. Based on our results, this system has an excessive initialization
overhead because of poor I/O utilization which dominates the whole execution
time. Because of this, the system does not scale beyond a few nodes (4 in Blue
Waters). Additionally, due to a single server-multiple worker design the server
becomes a bottleneck after 16 nodes limiting the scalability of the CNTK.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2016-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00522</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Visual Representation for Editing Face Images</dc:title>
 <dc:creator>Lu, Jiajun</dc:creator>
 <dc:creator>Sunkavalli, Kalyan</dc:creator>
 <dc:creator>Carr, Nathan</dc:creator>
 <dc:creator>Hadap, Sunil</dc:creator>
 <dc:creator>Forsyth, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We propose a new approach for editing face images, which enables numerous
exciting applications including face relighting, makeup transfer and face
detail editing. Our face edits are based on a visual representation, which
includes geometry, face segmentation, albedo, illumination and detail map. To
recover our visual representation, we start by estimating geometry using a
morphable face model, then decompose the face image to recover the albedo, and
then shade the geometry with the albedo and illumination. The residual between
our shaded geometry and the input image produces our detail map, which carries
high frequency information that is either insufficiently or incorrectly
captured by our shading process. By manipulating the detail map, we can edit
face images with reality and identity preserved. Our representation allows
various applications. First, it allows a user to directly manipulate various
illumination. Second, it allows non-parametric makeup transfer with input
face's distinctive identity features preserved. Third, it allows non-parametric
modifications to the face appearance by transferring details. For face
relighting and detail editing, we evaluate via a user study and our method
outperforms other methods. For makeup transfer, we evaluate via an online
attractiveness evaluation system, and can reliably make people look younger and
more attractive. We also show extensive qualitative comparisons to existing
methods, and have significant improvements over previous techniques.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00523</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Photorealistic Facial Texture Inference Using Deep Neural Networks</dc:title>
 <dc:creator>Saito, Shunsuke</dc:creator>
 <dc:creator>Wei, Lingyu</dc:creator>
 <dc:creator>Hu, Liwen</dc:creator>
 <dc:creator>Nagano, Koki</dc:creator>
 <dc:creator>Li, Hao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present a data-driven inference method that can synthesize a
photorealistic texture map of a complete 3D face model given a partial 2D view
of a person in the wild. After an initial estimation of shape and low-frequency
albedo, we compute a high-frequency partial texture map, without the shading
component, of the visible face area. To extract the fine appearance details
from this incomplete input, we introduce a multi-scale detail analysis
technique based on mid-layer feature correlations extracted from a deep
convolutional neural network. We demonstrate that fitting a convex combination
of feature correlations from a high-resolution face database can yield a
semantically plausible facial detail description of the entire face. A complete
and photorealistic texture map can then be synthesized by iteratively
optimizing for the reconstructed feature correlations. Using these
high-resolution textures and a commercial rendering framework, we can produce
high-fidelity 3D renderings that are visually comparable to those obtained with
state-of-the-art multi-view face capture systems. We demonstrate successful
face reconstructions from a wide range of low resolution input images,
including those of historical figures. In addition to extensive evaluations, we
validate the realism of our results using a crowdsourced user study.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00525</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Noise-Filtering Approach for Cancer Drug Sensitivity Prediction</dc:title>
 <dc:creator>Turki, Turki</dc:creator>
 <dc:creator>Wei, Zhi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Accurately predicting drug responses to cancer is an important problem
hindering oncologists' efforts to find the most effective drugs to treat
cancer, which is a core goal in precision medicine. The scientific community
has focused on improving this prediction based on genomic, epigenomic, and
proteomic datasets measured in human cancer cell lines. Real-world cancer cell
lines contain noise, which degrades the performance of machine learning
algorithms. This problem is rarely addressed in the existing approaches. In
this paper, we present a noise-filtering approach that integrates techniques
from numerical linear algebra and information retrieval targeted at filtering
out noisy cancer cell lines. By filtering out noisy cancer cell lines, we can
train machine learning algorithms on better quality cancer cell lines. We
evaluate the performance of our approach and compare it with an existing
approach using the Area Under the ROC Curve (AUC) on clinical trial data. The
experimental results show that our proposed approach is stable and also yields
the highest AUC at a statistically significant level.
</dc:description>
 <dc:description>Comment: Accepted at NIPS 2016 Workshop on Machine Learning for Health</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00530</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementation and evaluation of data-compression algorithms for
  irregular-grid iterative methods on the PEZY-SC processor</dc:title>
 <dc:creator>Yoshifuji, Naoki</dc:creator>
 <dc:creator>Sakamoto, Ryo</dc:creator>
 <dc:creator>Nitadori, Keigo</dc:creator>
 <dc:creator>Makino, Jun</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Iterative methods on irregular grids have been used widely in all areas of
comptational science and engineering for solving partial differential equations
with complex geometry. They provide the flexibility to express complex shapes
with relatively low computational cost. However, the direction of the evolution
of high-performance processors in the last two decades have caused serious
degradation of the computational efficiency of iterative methods on irregular
grids, because of relatively low memory bandwidth. Data compression can in
principle reduce the necessary memory memory bandwidth of iterative methods and
thus improve the efficiency. We have implemented several data compression
algorithms on the PEZY-SC processor, using the matrix generated for the HPCG
benchmark as an example. For the SpMV (Sparse Matrix-Vector multiplication)
part of the HPCG benchmark, the best implementation without data compression
achieved 11.6Gflops/chip, close to the theoretical limit due to the memory
bandwidth. Our implementation with data compression has achieved 32.4Gflops.
This is of course rather extreme case, since the grid used in HPCG is
geometrically regular and thus its compression efficiency is very high.
However, in real applications, it is in many cases possible to make a large
part of the grid to have regular geometry, in particular when the resolution is
high. Note that we do not need to change the structure of the program, except
for the addition of the data compression/decompression subroutines. Thus, we
believe the data compression will be very useful way to improve the performance
of many applications which rely on the use of irregular grids.
</dc:description>
 <dc:description>Comment: Talk given at IA3 2016 Sixth Workshop on Irregular Applications:
  Architectures and Algorithms http://hpc.pnl.gov/IA3/IA3/Program.html</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00531</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revenue Maximization in Incentivized Social Advertising</dc:title>
 <dc:creator>Aslay, Cigdem</dc:creator>
 <dc:creator>Bonchi, Francesco</dc:creator>
 <dc:creator>Lakshmanan, Laks V. S.</dc:creator>
 <dc:creator>Lu, Wei</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  Incentivized social advertising, an emerging marketing model, provides
monetization opportunities not only to the owners of the social networking
platforms but also to their influential users by offering a &quot;cut&quot; on the
advertising revenue. We consider a social network (the host) that sells
ad-engagements to advertisers by inserting their ads, in the form of promoted
posts, into the feeds of carefully selected &quot;initial endorsers&quot; or seed users:
these users receive monetary incentives in exchange for their endorsements. The
endorsements help propagate the ads to the feeds of their followers. In this
context, the problem for the host is is to allocate ads to influential users,
taking into account the propensity of ads for viral propagation, and carefully
apportioning the monetary budget of each of the advertisers between incentives
to influential users and ad-engagement costs, with the rational goal of
maximizing its own revenue. We consider a monetary incentive for the
influential users, which is proportional to their influence potential. We show
that revenue maximization in incentivized social advertising corresponds to the
problem of monotone submodular function maximization, subject to a partition
matroid constraint on the ads-to-seeds allocation, and submodular knapsack
constraints on the advertisers' budgets. This problem is NP-hard and we devise
2 greedy algorithms with provable approximation guarantees, which differ in
their sensitivity to seed user incentive costs. Our approximation algorithms
require repeatedly estimating the expected marginal gain in revenue as well as
in advertiser payment. By exploiting a connection to the recent advances made
in scalable estimation of expected influence spread, we devise efficient and
scalable versions of the greedy algorithms.
</dc:description>
 <dc:description>Comment: 14 pages; Under peer-review as of April 16, 2017</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00534</identifier>
 <datestamp>2017-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object Detection via Aspect Ratio and Context Aware Region-based
  Convolutional Networks</dc:title>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Wu, Tianfu</dc:creator>
 <dc:creator>Shao, Shuai</dc:creator>
 <dc:creator>Zhang, Lun</dc:creator>
 <dc:creator>Chu, Rufeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Jointly integrating aspect ratio and context has been extensively studied and
shown performance improvement in traditional object detection systems such as
the DPMs. It, however, has been largely ignored in deep neural network based
detection systems. This paper presents a method of integrating a mixture of
object models and region-based convolutional networks for accurate object
detection. Each mixture component accounts for both object aspect ratio and
multi-scale contextual information explicitly: (i) it exploits a mixture of
tiling configurations in the RoI pooling to remedy the warping artifacts caused
by a single type RoI pooling (e.g., with equally-sized 7 x 7 cells), and to
respect the underlying object shapes more; (ii) it &quot;looks from both the inside
and the outside of a RoI&quot; by incorporating contextual information at two
scales: global context pooled from the whole image and local context pooled
from the surrounding of a RoI. To facilitate accurate detection, this paper
proposes a multi-stage detection scheme for integrating the mixture of object
models, which utilizes the detection results of the model at the previous stage
as the proposals for the current in both training and testing. The proposed
method is called the aspect ratio and context aware region-based convolutional
network (ARC-R-CNN). In experiments, ARC-R-CNN shows very competitive results
with Faster R-CNN [41] and R-FCN [10] on two datasets: the PASCAL VOC and the
Microsoft COCO. It obtains significantly better mAP performance using high IoU
thresholds on both datasets.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00542</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Breast Mass Classification from Mammograms using Deep Convolutional
  Neural Networks</dc:title>
 <dc:creator>L&#xe9;vy, Daniel</dc:creator>
 <dc:creator>Jain, Arzav</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Mammography is the most widely used method to screen breast cancer. Because
of its mostly manual nature, variability in mass appearance, and low
signal-to-noise ratio, a significant number of breast masses are missed or
misdiagnosed. In this work, we present how Convolutional Neural Networks can be
used to directly classify pre-segmented breast masses in mammograms as benign
or malignant, using a combination of transfer learning, careful pre-processing
and data augmentation to overcome limited training data. We achieve
state-of-the-art results on the DDSM dataset, surpassing human performance, and
show interpretability of our model.
</dc:description>
 <dc:description>Comment: NIPS 2016 ML4HC Workshop</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00547</identifier>
 <datestamp>2017-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradient Descent Efficiently Finds the Cubic-Regularized Non-Convex
  Newton Step</dc:title>
 <dc:creator>Carmon, Yair</dc:creator>
 <dc:creator>Duchi, John C.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the minimization of non-convex quadratic forms regularized by a
cubic term, which exhibit multiple saddle points and poor local minima.
Nonetheless, we prove that, under mild assumptions, gradient descent
approximates the $\textit{global minimum}$ to within $\varepsilon$ accuracy in
$O(\varepsilon^{-1}\log(1/\varepsilon))$ steps for large $\varepsilon$ and
$O(\log(1/\varepsilon))$ steps for small $\varepsilon$ (compared to a condition
number we define), with at most logarithmic dependence on the problem
dimension. When we use gradient descent to approximate the Nesterov-Polyak
cubic-regularized Newton step, our result implies a rate of convergence to
second-order stationary points of general smooth non-convex functions.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00552</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massive Non-Orthogonal Multiple Access for Cellular IoT: Potentials and
  Limitations</dc:title>
 <dc:creator>Shirvanimoghaddam, Mahyar</dc:creator>
 <dc:creator>Dohler, Mischa</dc:creator>
 <dc:creator>Johnson, Sarah</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The Internet of Things (IoT) promises ubiquitous connectivity of everything
everywhere, which represents the biggest technology trend in the years to come.
It is expected that by 2020 over 25 billion devices will be connected to
cellular networks; far beyond the number of devices in current wireless
networks. Machine-to-Machine (M2M) communications aims at providing the
communication infrastructure for enabling IoT by facilitating the billions of
multi-role devices to communicate with each other and with the underlying data
transport infrastructure without, or with little, human intervention. Providing
this infrastructure will require a dramatic shift from the current protocols
mostly designed for human-to-human (H2H) applications. This article reviews
recent 3GPP solutions for enabling massive cellular IoT and investigates the
random access strategies for M2M communications, which shows that cellular
networks must evolve to handle the new ways in which devices will connect and
communicate with the system. A massive non-orthogonal multiple access (NOMA)
technique is then presented as a promising solution to support a massive number
of IoT devices in cellular networks, where we also identify its practical
challenges and future research directions.
</dc:description>
 <dc:description>Comment: To appear in IEEE Communications Magazine</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00554</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Higher Order Mutual Information Approximation for Feature Selection</dc:title>
 <dc:creator>Wu, Jilin</dc:creator>
 <dc:creator>Gupta, Soumyajit</dc:creator>
 <dc:creator>Bajaj, Chandrajit</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Feature selection is a process of choosing a subset of relevant features so
that the quality of prediction models can be improved. An extensive body of
work exists on information-theoretic feature selection, based on maximizing
Mutual Information (MI) between subsets of features and class labels. The prior
methods use a lower order approximation, by treating the joint entropy as a
summation of several single variable entropies. This leads to locally optimal
selections and misses multi-way feature combinations. We present a higher order
MI based approximation technique called Higher Order Feature Selection (HOFS).
Instead of producing a single list of features, our method produces a ranked
collection of feature subsets that maximizes MI, giving better comprehension
(feature ranking) as to which features work best together when selected, due to
their underlying interdependent structure. Our experiments demonstrate that the
proposed method performs better than existing feature selection approaches
while keeping similar running times and computational complexity.
</dc:description>
 <dc:description>Comment: 14 page, 5 figures</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00554</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00558</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Human Action Detection by Action Matching</dc:title>
 <dc:creator>Fernando, Basura</dc:creator>
 <dc:creator>Shirazi, Sareh</dc:creator>
 <dc:creator>Gould, Stephen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a new task of unsupervised action detection by action matching.
Given two long videos, the objective is to temporally detect all pairs of
matching video segments. A pair of video segments are matched if they share the
same human action. The task is category independent---it does not matter what
action is being performed---and no supervision is used to discover such video
segments. Unsupervised action detection by action matching allows us to align
videos in a meaningful manner. As such, it can be used to discover new action
categories or as an action proposal technique within, say, an action detection
pipeline. Moreover, it is a useful pre-processing step for generating video
highlights, e.g., from sports videos.
  We present an effective and efficient method for unsupervised action
detection. We use an unsupervised temporal encoding method and exploit the
temporal consistency in human actions to obtain candidate action segments. We
evaluate our method on this challenging task using three activity recognition
benchmarks, namely, the MPII Cooking activities dataset, the THUMOS15 action
detection benchmark and a new dataset called the IKEA dataset. On the MPII
Cooking dataset we detect action segments with a precision of 21.6% and recall
of 11.7% over 946 long video pairs and over 5000 ground truth action segments.
Similarly, on THUMOS dataset we obtain 18.4% precision and 25.1% recall over
5094 ground truth action segment pairs.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Computer Vision and Pattern
  Recognition CVPR 2017 Workshops</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00560</identifier>
 <datestamp>2017-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-Shot Learning posed as a Missing Data Problem</dc:title>
 <dc:creator>Zhao, Bo</dc:creator>
 <dc:creator>Wu, Botong</dc:creator>
 <dc:creator>Wu, Tianfu</dc:creator>
 <dc:creator>Wang, Yizhou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a method of zero-shot learning (ZSL) which poses ZSL as
the missing data problem, rather than the missing label problem. Specifically,
most existing ZSL methods focus on learning mapping functions from the image
feature space to the label embedding space. Whereas, the proposed method
explores a simple yet effective transductive framework in the reverse way \---
our method estimates data distribution of unseen classes in the image feature
space by transferring knowledge from the label embedding space. In experiments,
our method outperforms the state-of-the-art on two popular datasets.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00563</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-critical Sequence Training for Image Captioning</dc:title>
 <dc:creator>Rennie, Steven J.</dc:creator>
 <dc:creator>Marcheret, Etienne</dc:creator>
 <dc:creator>Mroueh, Youssef</dc:creator>
 <dc:creator>Ross, Jarret</dc:creator>
 <dc:creator>Goel, Vaibhava</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently it has been shown that policy-gradient methods for reinforcement
learning can be utilized to train deep end-to-end systems directly on
non-differentiable metrics for the task at hand. In this paper we consider the
problem of optimizing image captioning systems using reinforcement learning,
and show that by carefully optimizing our systems using the test metrics of the
MSCOCO task, significant gains in performance can be realized. Our systems are
built using a new optimization approach that we call self-critical sequence
training (SCST). SCST is a form of the popular REINFORCE algorithm that, rather
than estimating a &quot;baseline&quot; to normalize the rewards and reduce variance,
utilizes the output of its own test-time inference algorithm to normalize the
rewards it experiences. Using this approach, estimating the reward signal (as
actor-critic methods must do) and estimating normalization (as REINFORCE
algorithms typically do) is avoided, while at the same time harmonizing the
model with respect to its test-time inference procedure. Empirically we find
that directly optimizing the CIDEr metric with SCST and greedy decoding at
test-time is highly effective. Our results on the MSCOCO evaluation sever
establish a new state-of-the-art on the task, improving the best result in
terms of CIDEr from 104.9 to 114.7.
</dc:description>
 <dc:description>Comment: CVPR 2017 + additional analysis + fixed baseline results, 16 pages</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00564</identifier>
 <datestamp>2016-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropy bounds on state estimation for stochastic non-linear systems
  under information constraints</dc:title>
 <dc:creator>Kawan, Christoph</dc:creator>
 <dc:creator>Y&#xfc;ksel, Serdar</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies state estimation over noisy channels for stochastic
non-linear systems. We consider three estimation objectives, a strong and a
weak form of almost sure stability of the estimation error as well as quadratic
stability in expectation. For all three objectives, we derive lower bounds on
the smallest channel capacity $C_0$ above which the objective can be achieved
with an arbitrarily small error. Lower bounds are obtained via a dynamical
systems (through a novel construction of a dynamical system), an
information-theoretic and a random dynamical systems approach. The first two
approaches show that for a large class of systems, such as additive noise
systems, $C_0 = \infty$, i.e., the estimation objectives cannot be achieved via
channels of finite capacity. The random dynamical systems approach is shown to
be operationally non-adequate for the problem, since it yields finite lower
bounds $C_0$ under mild assumptions. Finally, we prove that a memoryless noisy
channel in general constitutes no obstruction to asymptotic almost sure state
estimation with arbitrarily small errors, when there is no noise in the system.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2016-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00565</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Programming by Demonstration with User-Specified Perceptual Landmarks</dc:title>
 <dc:creator>Huang, Justin</dc:creator>
 <dc:creator>Cakmak, Maya</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:description>  Programming by demonstration (PbD) is an effective technique for developing
complex robot manipulation tasks, such as opening bottles or using human tools.
In order for such tasks to generalize to new scenes, the robot needs to be able
to perceive objects, object parts, or other task-relevant parts of the scene.
Previous work has relied on rigid, task-specific perception systems for this
purpose. This paper presents a flexible and open-ended perception system that
lets users specify perceptual &quot;landmarks&quot; during the demonstration, by
capturing parts of the point cloud from the demonstration scene. We present a
method for localizing landmarks in new scenes and experimentally evaluate this
method in a variety of settings. Then, we provide examples where user-specified
landmarks are used together with PbD on a PR2 robot to perform several complex
manipulation tasks. Finally, we present findings from a user evaluation of our
landmark specification interface demonstrating its feasibility as an end-user
tool.
</dc:description>
 <dc:description>Comment: Under review at the International Conference on Robotics and
  Automation (ICRA) 2017</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00567</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shift-Reduce Constituent Parsing with Neural Lookahead Features</dc:title>
 <dc:creator>Liu, Jiangming</dc:creator>
 <dc:creator>Zhang, Yue</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Transition-based models can be fast and accurate for constituent parsing.
Compared with chart-based models, they leverage richer features by extracting
history information from a parser stack, which spans over non-local
constituents. On the other hand, during incremental parsing, constituent
information on the right hand side of the current word is not utilized, which
is a relative weakness of shift-reduce parsing. To address this limitation, we
leverage a fast neural model to extract lookahead features. In particular, we
build a bidirectional LSTM model, which leverages the full sentence information
to predict the hierarchy of constituents that each word starts and ends. The
results are then passed to a strong transition-based constituent parser as
lookahead features. The resulting parser gives 1.3% absolute improvement in WSJ
and 2.3% in CTB compared to the baseline, given the highest reported accuracies
for fully-supervised parsing.
</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00570</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of Microgrids in Supporting Distribution Grid Flexibility</dc:title>
 <dc:creator>Majzoobi, Alireza</dc:creator>
 <dc:creator>Khodaei, Amin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Distributed renewable energy resources have attracted significant attention
in recent years due to the falling cost of the renewable energy technology,
extensive federal and state incentives, and the application in improving
load-point reliability. This growing proliferation, however, is changing the
traditional consumption load curves by adding considerable levels of
variability and further challenging the electricity supply-demand balance. In
this paper, the application of microgrids in effectively capturing the
distribution network net load variability, caused primarily by the prosumers,
is investigated. Microgrids provide a viable and localized solution to this
challenge while removing the need for costly investments by the electric
utility on reinforcing the existing electricity infrastructure. A
flexibility-oriented microgrid optimal scheduling model is proposed and
developed to coordinate the microgrid net load with the aggregated
consumers/prosumers net load in the distribution network with a focus on
ramping issues. The proposed coordination is performed to capture both
inter-hour and intra-hour net load variabilities. Numerical simulations on a
test distribution feeder with one microgrid and several consumers and prosumers
exhibit the effectiveness of the proposed model.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Power Systems</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00570</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00575</identifier>
 <datestamp>2016-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Not Call Me Cellular Any More: The Emergence of Scaling Law, Fractal
  Patterns and Small-World in Wireless Networks</dc:title>
 <dc:creator>Yuan, Chao</dc:creator>
 <dc:creator>Zhao, Zhifeng</dc:creator>
 <dc:creator>Li, Rongpeng</dc:creator>
 <dc:creator>Li, Meng</dc:creator>
 <dc:creator>Zhang, Honggang</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In conventional cellular networks, for base stations (BSs) that are deployed
far away from each other, it is general to assume them to be mutually
independent. Nevertheless, after long-term evolution of cellular networks in
various generations, this assumption no longer holds. Instead, the BSs, which
seem to be gradually deployed by operators in a service-oriented manner, have
embedded many fundamentally distinctive features in their locations, coverage
and traffic loading. These features can be leveraged to analyze the intrinsic
pattern in BSs and even human community. In this paper, according to
large-scale measurement datasets, we build up a correlation model of BSs by
utilizing one of the most important features, ie., spatial traffic. Coupling
with the theory of complex networks, we make further analysis on the structure
and characteristics of this traffic load correlation model. Numerical results
show that the degree distribution follows scale-free property. Also the
datasets unveil the characteristics of fractality and small-world. Furthermore,
we apply collective influence (CI) algorithm to localize the influential base
stations and demonstrate that some low-degree BSs may outrank BSs with larger
degree.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2016-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00576</identifier>
 <datestamp>2017-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guided Open Vocabulary Image Captioning with Constrained Beam Search</dc:title>
 <dc:creator>Anderson, Peter</dc:creator>
 <dc:creator>Fernando, Basura</dc:creator>
 <dc:creator>Johnson, Mark</dc:creator>
 <dc:creator>Gould, Stephen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Existing image captioning models do not generalize well to out-of-domain
images containing novel scenes or objects. This limitation severely hinders the
use of these models in real world applications dealing with images in the wild.
We address this problem using a flexible approach that enables existing deep
captioning architectures to take advantage of image taggers at test time,
without re-training. Our method uses constrained beam search to force the
inclusion of selected tag words in the output, and fixed, pretrained word
embeddings to facilitate vocabulary expansion to previously unseen tag words.
Using this approach we achieve state of the art results for out-of-domain
captioning on MSCOCO (and improved results for in-domain captioning). Perhaps
surprisingly, our results significantly outperform approaches that incorporate
the same tag predictions into the learning algorithm. We also show that we can
significantly improve the quality of generated ImageNet captions by leveraging
ground-truth labels.
</dc:description>
 <dc:description>Comment: EMNLP 2017</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00582</identifier>
 <datestamp>2017-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Changes in Affective States using Neural Networks</dc:title>
 <dc:creator>Carstensen, Stina Lyck</dc:creator>
 <dc:creator>Madsen, Jens</dc:creator>
 <dc:creator>Larsen, Jan</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Knowledge of patients affective state could prove to be crucial for
health-care professionals in both diagnosis and treatment, however, this
requires patients to report how they feel. In practice the sampling rate of
affective states needs to be kept low, in order to ensure that the patients can
rest. Furthermore using traditional methods of measuring affective states, is
not always possible, e.g. patients can be incapable of verbal communications.
In this study we explore the prediction of peoples self-reported affective
state by measuring multiple physiological signals. We use different Neural
networks (NN) setups and compare with different multiple linear regression
(MLR) setups for prediction of changes in affective states. The results showed
that NN and MLR predicted the change in affective states with accuracies of
91.88% and 89.10%, respectively.
</dc:description>
 <dc:description>Comment: NIPS 2016 Workshop on Machine Learning for Health</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00582</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00583</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Search for Sparse Signals with Region Sensing</dc:title>
 <dc:creator>Ma, Yifei</dc:creator>
 <dc:creator>Garnett, Roman</dc:creator>
 <dc:creator>Schneider, Jeff</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Autonomous systems can be used to search for sparse signals in a large space;
e.g., aerial robots can be deployed to localize threats, detect gas leaks, or
respond to distress calls. Intuitively, search algorithms may increase
efficiency by collecting aggregate measurements summarizing large contiguous
regions. However, most existing search methods either ignore the possibility of
such region observations (e.g., Bayesian optimization and multi-armed bandits)
or make strong assumptions about the sensing mechanism that allow each
measurement to arbitrarily encode all signals in the entire environment (e.g.,
compressive sensing). We propose an algorithm that actively collects data to
search for sparse signals using only noisy measurements of the average values
on rectangular regions (including single points), based on the greedy
maximization of information gain. We analyze our algorithm in 1d and show that
it requires $\tilde{O}(\frac{n}{\mu^2}+k^2)$ measurements to recover all of $k$
signal locations with small Bayes error, where $\mu$ and $n$ are the signal
strength and the size of the search space, respectively. We also show that
active designs can be fundamentally more efficient than passive designs with
region sensing, contrasting with the results of Arias-Castro, Candes, and
Davenport (2013). We demonstrate the empirical performance of our algorithm on
a search problem using satellite image data and in high dimensions.
</dc:description>
 <dc:description>Comment: aaai 2017 preprint; nips exhibition of rejections</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00584</identifier>
 <datestamp>2017-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alleviating Overfitting for Polysemous Words for Word Representation
  Estimation Using Lexicons</dc:title>
 <dc:creator>Ke, Yuanzhi</dc:creator>
 <dc:creator>Hagiwara, Masafumi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Though there are some works on improving distributed word representations
using lexicons, the improper overfitting of the words that have multiple
meanings is a remaining issue deteriorating the learning when lexicons are
used, which needs to be solved. An alternative method is to allocate a vector
per sense instead of a vector per word. However, the word representations
estimated in the former way are not as easy to use as the latter one. Our
previous work uses a probabilistic method to alleviate the overfitting, but it
is not robust with a small corpus. In this paper, we propose a new neural
network to estimate distributed word representations using a lexicon and a
corpus. We add a lexicon layer in the continuous bag-of-words model and a
threshold node after the output of the lexicon layer. The threshold rejects the
unreliable outputs of the lexicon layer that are less likely to be the same
with their inputs. In this way, it alleviates the overfitting of the polysemous
words. The proposed neural network can be trained using negative sampling,
which maximizing the log probabilities of target words given the context words,
by distinguishing the target words from random noises. We compare the proposed
neural network with the continuous bag-of-words model, the other works
improving it, and the previous works estimating distributed word
representations using both a lexicon and a corpus. The experimental results
show that the proposed neural network is more efficient and balanced for both
semantic tasks and syntactic tasks than the previous works, and robust to the
size of the corpus.
</dc:description>
 <dc:description>Comment: Accepted by IEEE IJCNN 2017. Copyright transferred to IEEE</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00584</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00585</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development of a hybrid learning system based on SVM, ANFIS and domain
  knowledge: DKFIS</dc:title>
 <dc:creator>Chaki, Soumi</dc:creator>
 <dc:creator>Routray, Aurobinda</dc:creator>
 <dc:creator>Mohanty, William K.</dc:creator>
 <dc:creator>Jenamani, Mamata</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents the development of a hybrid learning system based on
Support Vector Machines (SVM), Adaptive Neuro-Fuzzy Inference System (ANFIS)
and domain knowledge to solve prediction problem. The proposed two-stage Domain
Knowledge based Fuzzy Information System (DKFIS) improves the prediction
accuracy attained by ANFIS alone. The proposed framework has been implemented
on a noisy and incomplete dataset acquired from a hydrocarbon field located at
western part of India. Here, oil saturation has been predicted from four
different well logs i.e. gamma ray, resistivity, density, and clay volume. In
the first stage, depending on zero or near zero and non-zero oil saturation
levels the input vector is classified into two classes (Class 0 and Class 1)
using SVM. The classification results have been further fine-tuned applying
expert knowledge based on the relationship among predictor variables i.e. well
logs and target variable - oil saturation. Second, an ANFIS is designed to
predict non-zero (Class 1) oil saturation values from predictor logs. The
predicted output has been further refined based on expert knowledge. It is
apparent from the experimental results that the expert intervention with
qualitative judgment at each stage has rendered the prediction into the
feasible and realistic ranges. The performance analysis of the prediction in
terms of four performance metrics such as correlation coefficient (CC), root
mean square error (RMSE), and absolute error mean (AEM), scatter index (SI) has
established DKFIS as a useful tool for reservoir characterization.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, 3tables Presented at Indicon 2015</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00593</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PointNet: Deep Learning on Point Sets for 3D Classification and
  Segmentation</dc:title>
 <dc:creator>Qi, Charles R.</dc:creator>
 <dc:creator>Su, Hao</dc:creator>
 <dc:creator>Mo, Kaichun</dc:creator>
 <dc:creator>Guibas, Leonidas J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Point cloud is an important type of geometric data structure. Due to its
irregular format, most researchers transform such data to regular 3D voxel
grids or collections of images. This, however, renders data unnecessarily
voluminous and causes issues. In this paper, we design a novel type of neural
network that directly consumes point clouds and well respects the permutation
invariance of points in the input. Our network, named PointNet, provides a
unified architecture for applications ranging from object classification, part
segmentation, to scene semantic parsing. Though simple, PointNet is highly
efficient and effective. Empirically, it shows strong performance on par or
even better than state of the art. Theoretically, we provide analysis towards
understanding of what the network has learnt and why the network is robust with
respect to input perturbation and corruption.
</dc:description>
 <dc:description>Comment: CVPR 2017</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00596</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Search on Manifolds for 3D Pose Estimation of Articulated
  Objects</dc:title>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Xu, Chi</dc:creator>
 <dc:creator>Cheng, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper focuses on the challenging problem of 3D pose estimation of a
diverse spectrum of articulated objects from single depth images. A novel
structured prediction approach is considered, where 3D poses are represented as
skeletal models that naturally operate on manifolds. Given an input depth
image, the problem of predicting the most proper articulation of underlying
skeletal model is thus formulated as sequentially searching for the optimal
skeletal configuration. This is subsequently addressed by convolutional neural
nets trained end-to-end to render sequential prediction of the joint locations
as regressing a set of tangent vectors of the underlying manifolds. Our
approach is examined on various articulated objects including human hand,
mouse, and fish benchmark datasets. Empirically it is shown to deliver highly
competitive performance with respect to the state-of-the-arts, while operating
in real-time (over 30 FPS).
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00599</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication Lower Bounds for Distributed Convex Optimization:
  Partition Data on Features</dc:title>
 <dc:creator>Chen, Zihao</dc:creator>
 <dc:creator>Luo, Luo</dc:creator>
 <dc:creator>Zhang, Zhihua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recently, there has been an increasing interest in designing distributed
convex optimization algorithms under the setting where the data matrix is
partitioned on features. Algorithms under this setting sometimes have many
advantages over those under the setting where data is partitioned on samples,
especially when the number of features is huge. Therefore, it is important to
understand the inherent limitations of these optimization problems. In this
paper, with certain restrictions on the communication allowed in the
procedures, we develop tight lower bounds on communication rounds for a broad
class of non-incremental algorithms under this setting. We also provide a lower
bound on communication rounds for a class of (randomized) incremental
algorithms.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00603</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Point Set Generation Network for 3D Object Reconstruction from a
  Single Image</dc:title>
 <dc:creator>Fan, Haoqiang</dc:creator>
 <dc:creator>Su, Hao</dc:creator>
 <dc:creator>Guibas, Leonidas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Generation of 3D data by deep neural network has been attracting increasing
attention in the research community. The majority of extant works resort to
regular representations such as volumetric grids or collection of images;
however, these representations obscure the natural invariance of 3D shapes
under geometric transformations and also suffer from a number of other issues.
In this paper we address the problem of 3D reconstruction from a single image,
generating a straight-forward form of output -- point cloud coordinates. Along
with this problem arises a unique and interesting issue, that the groundtruth
shape for an input image may be ambiguous. Driven by this unorthodox output
form and the inherent ambiguity in groundtruth, we design architecture, loss
function and learning paradigm that are novel and effective. Our final solution
is a conditional shape sampler, capable of predicting multiple plausible 3D
point clouds from an input image. In experiments not only can our system
outperform state-of-the-art methods on single image based 3d reconstruction
benchmarks; but it also shows a strong performance for 3d shape completion and
promising ability in making multiple plausible predictions.
</dc:description>
 <dc:description>Comment: The first two authors contributed equally</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00604</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Globally Consistent Multi-People Tracking using Motion Patterns</dc:title>
 <dc:creator>Maksai, Andrii</dc:creator>
 <dc:creator>Wang, Xinchao</dc:creator>
 <dc:creator>Fleuret, Francois</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:description>  Many state-of-the-art approaches to people tracking rely on detecting them in
each frame independently, grouping detections into short but reliable
trajectory segments, and then further grouping them into full trajectories.
This grouping typically relies on imposing local smoothness constraints but
almost never on enforcing more global constraints on the trajectories. In this
paper, we propose an approach to imposing global consistency by first inferring
behavioral patterns from the ground truth and then using them to guide the
tracking algorithm. When used in conjunction with several state-of-the-art
algorithms, this further increases their already good performance. Furthermore,
we propose an unsupervised scheme that yields almost similar improvements
without the need for ground truth.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures. 11 pages supplementary</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00606</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation</dc:title>
 <dc:creator>Yi, Li</dc:creator>
 <dc:creator>Su, Hao</dc:creator>
 <dc:creator>Guo, Xingwen</dc:creator>
 <dc:creator>Guibas, Leonidas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we study the problem of semantic annotation on 3D models that
are represented as shape graphs. A functional view is taken to represent
localized information on graphs, so that annotations such as part segment or
keypoint are nothing but 0-1 indicator vertex functions. Compared with images
that are 2D grids, shape graphs are irregular and non-isomorphic data
structures. To enable the prediction of vertex functions on them by
convolutional neural networks, we resort to spectral CNN method that enables
weight sharing by parameterizing kernels in the spectral domain spanned by
graph laplacian eigenbases. Under this setting, our network, named SyncSpecCNN,
strive to overcome two key challenges: how to share coefficients and conduct
multi-scale analysis in different parts of the graph for a single shape, and
how to share information across related but different shapes that may be
represented by very different graphs. Towards these goals, we introduce a
spectral parameterization of dilated convolutional kernels and a spectral
transformer network. Experimentally we tested our SyncSpecCNN on various tasks,
including 3D shape part segmentation and 3D keypoint prediction.
State-of-the-art performance has been achieved on all benchmark datasets.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00611</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predictive Clinical Decision Support System with RNN Encoding and Tensor
  Decoding</dc:title>
 <dc:creator>Yang, Yinchong</dc:creator>
 <dc:creator>Fasching, Peter A.</dc:creator>
 <dc:creator>Wallwiener, Markus</dc:creator>
 <dc:creator>Fehm, Tanja N.</dc:creator>
 <dc:creator>Brucker, Sara Y.</dc:creator>
 <dc:creator>Tresp, Volker</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  With the introduction of the Electric Health Records, large amounts of
digital data become available for analysis and decision support. When
physicians are prescribing treatments to a patient, they need to consider a
large range of data variety and volume, making decisions increasingly complex.
Machine learning based Clinical Decision Support systems can be a solution to
the data challenges. In this work we focus on a class of decision support in
which the physicians' decision is directly predicted. Concretely, the model
would assign higher probabilities to decisions that it presumes the physician
are more likely to make. Thus the CDS system can provide physicians with
rational recommendations. We also address the problem of correlation in target
features: Often a physician is required to make multiple (sub-)decisions in a
block, and that these decisions are mutually dependent. We propose a solution
to the target correlation problem using a tensor factorization model. In order
to handle the patients' historical information as sequential data, we apply the
so-called Encoder-Decoder-Framework which is based on Recurrent Neural Networks
(RNN) as encoders and a tensor factorization model as a decoder, a combination
which is novel in machine learning. With experiments with real-world datasets
we show that the proposed model does achieve better prediction performances.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00615</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A temporal model for multiple sclerosis course evolution</dc:title>
 <dc:creator>Fiorini, Samuele</dc:creator>
 <dc:creator>Tacchino, Andrea</dc:creator>
 <dc:creator>Brichetto, Giampaolo</dc:creator>
 <dc:creator>Verri, Alessandro</dc:creator>
 <dc:creator>Barla, Annalisa</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Multiple Sclerosis is a degenerative condition of the central nervous system
that affects nearly 2.5 million of individuals in terms of their physical,
cognitive, psychological and social capabilities. Researchers are currently
investigating on the use of patient reported outcome measures for the
assessment of impact and evolution of the disease on the life of the patients.
To date, a clear understanding on the use of such measures to predict the
evolution of the disease is still lacking. In this work we resort to
regularized machine learning methods for binary classification and multiple
output regression. We propose a pipeline that can be used to predict the
disease progression from patient reported measures. The obtained model is
tested on a data set collected from an ongoing clinical research project.
</dc:description>
 <dc:description>Comment: NIPS Machine Learning for health Workshop 2016</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00615</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00623</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Density Based Algorithm With Automatic Parameters Generation</dc:title>
 <dc:creator>Vijendra, Singh</dc:creator>
 <dc:creator>Trikha, Priyanka</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The traditional algorithms do not meet the latest multiple requirements
simultaneously for objects. Density-based method is one of the methodologies,
which can detect arbitrary shaped clusters where clusters are defined as dense
regions separated by low density regions. In this paper, we present a new
clustering algorithm to enhance the density-based algorithm DBSCAN. This
enables an automatic parameter generation strategy to create clusters with
different densities and enables noises recognition, and generates arbitrary
shaped clusters. The kdtree is used for increasing the memory efficiency.
Experimental result shows that proposed algorithm is capable of handling
complex objects with good memory efficiency and accuracy.
</dc:description>
 <dc:description>Comment: 2011 IEEE 3rd International Conference on Machine Learning and
  Computing (ICMLC 2011), Singapore</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00625</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recognition of Text Image Using Multilayer Perceptron</dc:title>
 <dc:creator>Vijendra, Singh</dc:creator>
 <dc:creator>Vasudeva, Nisha</dc:creator>
 <dc:creator>Parashar, Hem Jyotsana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The biggest challenge in the field of image processing is to recognize
documents both in printed and handwritten format. Optical Character Recognition
OCR is a type of document image analysis where scanned digital image that
contains either machine printed or handwritten script input into an OCR
software engine and translating it into an editable machine readable digital
text format. A Neural network is designed to model the way in which the brain
performs a particular task or function of interest: The neural network is
simulated in software on a digital computer. Character Recognition refers to
the process of converting printed Text documents into translated Unicode Text.
The printed documents available in the form of books, papers, magazines, etc.
are scanned using standard scanners which produce an image of the scanned
document. Lines are identifying by an algorithm where we identify top and
bottom of line. Then in each line character boundaries are calculated by an
algorithm then using these calculation, characters is isolated from the image
and then we classify each character by basic back propagation. Each image
character is comprised of 30*20 pixels. We have used the Back propagation
Neural Network for efficient recognition where the errors were corrected
through back propagation and rectified neuron values were transmitted by
feed-forward method in the neural network of multiple layers.
</dc:description>
 <dc:description>Comment: 2011 IEEE 3rd International Conference on Machine Learning and
  Computing (ICMLC 2011, Singapore, PP 547-550</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00628</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overloaded Multiuser MISO Transmission with Imperfect CSIT</dc:title>
 <dc:creator>Piovano, Enrico</dc:creator>
 <dc:creator>Joudeh, Hamdi</dc:creator>
 <dc:creator>Clerckx, Bruno</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A required feature for the next generation of wireless communication networks
will be the capability to serve simultaneously a large number of devices with
heterogeneous CSIT qualities and demands. In this paper, we consider the
overloaded MISO BC with two groups of CSIT qualities. We propose a transmission
scheme where degraded symbols are superimposed on top of spatially-multiplexed
symbols. The developed strategy allows to serve all users in a non-orthogonal
manner and the analysis shows an enhanced perfomance compared to existing
schemes. Moreover, optimality in a DoF sense is shown.
</dc:description>
 <dc:description>Comment: Presented at the 50th Annual Asilomar Conference on Signals, Systems
  and Computers (ASILOMAR 2016). Funding acknowledgement statement added and
  minor typos corrected</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00631</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design Automation and Design Space Exploration for Quantum Computers</dc:title>
 <dc:creator>Soeken, Mathias</dc:creator>
 <dc:creator>Roetteler, Martin</dc:creator>
 <dc:creator>Wiebe, Nathan</dc:creator>
 <dc:creator>De Micheli, Giovanni</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  A major hurdle to the deployment of quantum linear systems algorithms and
recent quantum simulation algorithms lies in the difficulty to find inexpensive
reversible circuits for arithmetic using existing hand coded methods. Motivated
by recent advances in reversible logic synthesis, we synthesize arithmetic
circuits using classical design automation flows and tools. The combination of
classical and reversible logic synthesis enables the automatic design of large
components in reversible logic starting from well-known hardware description
languages such as Verilog. As a prototype example for our approach we
automatically generate high quality networks for the reciprocal $1/x$, which is
necessary for quantum linear systems algorithms.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, in 2017 Design, Automation &amp; Test in Europe
  Conference &amp; Exhibition, DATE 2017, Lausanne, Switzerland, March 27-31, 2017</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00637</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General Framework for Density Based Time Series Clustering Exploiting
  a Novel Admissible Pruning Strategy</dc:title>
 <dc:creator>Begum, Nurjahan</dc:creator>
 <dc:creator>Ulanova, Liudmila</dc:creator>
 <dc:creator>Dau, Hoang Anh</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:creator>Keogh, Eamonn</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Time Series Clustering is an important subroutine in many higher-level data
mining analyses, including data editing for classifiers, summarization, and
outlier detection. It is well known that for similarity search the superiority
of Dynamic Time Warping (DTW) over Euclidean distance gradually diminishes as
we consider ever larger datasets. However, as we shall show, the same is not
true for clustering. Clustering time series under DTW remains a computationally
expensive operation. In this work, we address this issue in two ways. We
propose a novel pruning strategy that exploits both the upper and lower bounds
to prune off a very large fraction of the expensive distance calculations. This
pruning strategy is admissible and gives us provably identical results to the
brute force algorithm, but is at least an order of magnitude faster. For
datasets where even this level of speedup is inadequate, we show that we can
use a simple heuristic to order the unavoidable calculations in a
most-useful-first ordering, thus casting the clustering into an anytime
framework. We demonstrate the utility of our ideas with both single and
multidimensional case studies in the domains of astronomy, speech physiology,
medicine and entomology. In addition, we show the generality of our clustering
framework to other domains by efficiently obtaining semantically significant
clusters in protein sequences using the Edit Distance, the discrete data
analogue of DTW.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00645</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Centrog Feature technique for vehicle type recognition at day and night
  times</dc:title>
 <dc:creator>Irhebhude, Martins E.</dc:creator>
 <dc:creator>Odion, Philip O.</dc:creator>
 <dc:creator>Chinyio, Darius T.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This work proposes a feature-based technique to recognize vehicle types
within day and night times. Support vector machine (SVM) classifier is applied
on image histogram and CENsus Transformed histogRam Oriented Gradient (CENTROG)
features in order to classify vehicle types during the day and night. Thermal
images were used for the night time experiments. Although thermal images suffer
from low image resolution, lack of colour and poor texture information, they
offer the advantage of being unaffected by high intensity light sources such as
vehicle headlights which tend to render normal images unsuitable for night time
image capturing and subsequent analysis. Since contour is useful in shape based
categorisation and the most distinctive feature within thermal images, CENTROG
is used to capture this feature information and is used within the experiments.
The experimental results so obtained were compared with those obtained by
employing the CENsus TRansformed hISTogram (CENTRIST). Experimental results
revealed that CENTROG offers better recognition accuracies for both day and
night times vehicle types recognition.
</dc:description>
 <dc:description>Comment: 14 pages, 8 figures, Journal article</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00645</dc:identifier>
 <dc:identifier>doi:10.5121/ijaia.2016.7604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00649</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Storage Management in Modern Electricity Power Grids</dc:title>
 <dc:creator>Nardelli, Pedro H. J.</dc:creator>
 <dc:creator>Alves, Hirley</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This letter introduces a method to manage energy storage in electricity
grids. Starting from the stochastic characterization of electricity generation
and demand, we propose an equation that relates the storage level for every
time-step as a function of its previous state and the realized surplus/deficit
of electricity. Therefrom, we can obtain the probability that, in the next
time-step: (i) there is a generation surplus that cannot be stored, or (ii)
there is a demand need that cannot be supplied by the available storage. We
expect this simple procedure can be used as the basis of electricity
self-management algorithms in micro-level (e.g. individual households) or in
meso-level (e.g. groups of houses).
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00649</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00651</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling Theorems for Shift-invariant Spaces, Gabor Frames, and Totally
  Positive Functions</dc:title>
 <dc:creator>Gr&#xf6;chenig, Karlheinz</dc:creator>
 <dc:creator>Romero, Jos&#xe9; Luis</dc:creator>
 <dc:creator>St&#xf6;ckler, Joachim</dc:creator>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>42C15, 42C40, 94A20</dc:subject>
 <dc:description>  We study nonuniform sampling in shift-invariant spaces and the construction
of Gabor frames with respect to the class of totally positive functions whose
Fourier transform factors as $ \hat g(\xi)= \prod_{j=1}^n (1+2\pi
i\delta_j\xi)^{-1} \, e^{-c \xi^2}$ for $\delta_1,\ldots,\delta_n\in
\mathbb{R}, c &gt;0$ (in which case $g$ is called totally positive of Gaussian
type).
  In analogy to Beurling's sampling theorem for the Paley-Wiener space of
entire functions, we prove that every separated set with lower Beurling density
$&gt;1$ is a sampling set for the shift-invariant space generated by such a $g$.
In view of the known necessary density conditions, this result is optimal and
validates the heuristic reasonings in the engineering literature.
  Using a subtle connection between sampling in shift-invariant spaces and the
theory of Gabor frames, we show that the set of phase-space shifts of $g$ with
respect to a rectangular lattice $\alpha \mathbb{Z} \times \beta \mathbb{Z}$
forms a frame, if and only if $\alpha \beta &lt;1$. This solves an open problem
going back to Daubechies in 1990 for the class of totally positive functions of
Gaussian type.
  The proof strategy involves the connection between sampling in
shift-invariant spaces and Gabor frames, a new characterization of sampling
sets &quot;without inequalities&quot; in the style of Beurling, new properties of totally
positive functions, and the interplay between zero sets of functions in a
shift-invariant space and functions in the Bargmann-Fock space.
</dc:description>
 <dc:description>Comment: 25 pages</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00653</identifier>
 <datestamp>2017-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring Cognitive Models from Data using Approximate Bayesian
  Computation</dc:title>
 <dc:creator>Kangasr&#xe4;&#xe4;si&#xf6;, Antti</dc:creator>
 <dc:creator>Athukorala, Kumaripaba</dc:creator>
 <dc:creator>Howes, Andrew</dc:creator>
 <dc:creator>Corander, Jukka</dc:creator>
 <dc:creator>Kaski, Samuel</dc:creator>
 <dc:creator>Oulasvirta, Antti</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  An important problem for HCI researchers is to estimate the parameter values
of a cognitive model from behavioral data. This is a difficult problem, because
of the substantial complexity and variety in human behavioral strategies. We
report an investigation into a new approach using approximate Bayesian
computation (ABC) to condition model parameters to data and prior knowledge. As
the case study we examine menu interaction, where we have click time data only
to infer a cognitive model that implements a search behaviour with parameters
such as fixation duration and recall probability. Our results demonstrate that
ABC (i) improves estimates of model parameter values, (ii) enables meaningful
comparisons between model variants, and (iii) supports fitting models to
individual users. ABC provides ample opportunities for theoretical HCI research
by allowing principled inference of model parameter values and their
uncertainty.
</dc:description>
 <dc:description>Comment: To appear in CHI'2017</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00653</dc:identifier>
 <dc:identifier>doi:10.1145/3025453.3025576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00662</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Patient State-of-Health using Sliding Window and Recurrent
  Classifiers</dc:title>
 <dc:creator>McCarthy, Adam</dc:creator>
 <dc:creator>Williams, Christopher K. I.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Bedside monitors in Intensive Care Units (ICUs) frequently sound incorrectly,
slowing response times and desensitising nurses to alarms (Chambrin, 2001),
causing true alarms to be missed (Hug et al., 2011). We compare sliding window
predictors with recurrent predictors to classify patient state-of-health from
ICU multivariate time series; we report slightly improved performance for the
RNN for three out of four targets.
</dc:description>
 <dc:description>Comment: NIPS 2016 Workshop on Machine Learning for Health</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00666</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Structural Operational Semantics</dc:title>
 <dc:creator>Johansen, Christian</dc:creator>
 <dc:creator>Owe, Olaf</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We introduce Dynamic SOS as a framework for describing semantics of
programming languages that include dynamic software upgrades. Dynamic SOS
(DSOS) is built on top of the Modular SOS of P. Mosses, with an underlying
category theory formalization. The idea of Dynamic SOS is to bring out the
essential differences between dynamic upgrade constructs and program execution
constructs. The important feature of Modular SOS (MSOS) that we exploit in DSOS
is the sharp separation of the program execution code from the additional
(data) structures needed at run-time. In DSOS we aim to achieve the same
modularity and decoupling for dynamic software upgrades. This is partly
motivated by the long term goal of having machine-checkable proofs for general
results like type safety. We exemplify Dynamic SOS on two languages supporting
dynamic software upgrades, namely the C-like PROTEUS, which supports updating
of variables, functions, records, or types at specific program points, and
CREOL, which supports dynamic class upgrades in the setting of concurrent
objects. Existing type analyses for software upgrades can be done on top of
DSOS too, as we illustrate for PROTEUS. A second contribution is the definition
of a general encapsulating construction on Modular SOS useful in situations
where a form of encapsulation of the execution is needed. We show how to apply
this in the setting of concurrent object-oriented programming with active
objects and asynchronous method calls.
</dc:description>
 <dc:description>Comment: 32 pages</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00667</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Voxelwise nonlinear regression toolbox for neuroimage analysis:
  Application to aging and neurodegenerative disease modeling</dc:title>
 <dc:creator>Puch, Santi</dc:creator>
 <dc:creator>Aduriz, Asier</dc:creator>
 <dc:creator>Casamitjana, Adri&#xe0;</dc:creator>
 <dc:creator>Vilaplana, Veronica</dc:creator>
 <dc:creator>Petrone, Paula</dc:creator>
 <dc:creator>Operto, Gr&#xe9;gory</dc:creator>
 <dc:creator>Cacciaglia, Raffaele</dc:creator>
 <dc:creator>Skouras, Stavros</dc:creator>
 <dc:creator>Falcon, Carles</dc:creator>
 <dc:creator>Molinuevo, Jos&#xe9; Luis</dc:creator>
 <dc:creator>Gispert, Juan Domingo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  This paper describes a new neuroimaging analysis toolbox that allows for the
modeling of nonlinear effects at the voxel level, overcoming limitations of
methods based on linear models like the GLM. We illustrate its features using a
relevant example in which distinct nonlinear trajectories of Alzheimer's
disease related brain atrophy patterns were found across the full biological
spectrum of the disease. The open-source toolbox presented in this paper is
available at https://github.com/imatge-upc/VNeAT.
</dc:description>
 <dc:description>Comment: 4 pages + 1 page for acknowledgements and references. NIPS 2016
  Workshop on Machine Learning for Health (NIPS ML4HC)</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00667</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00668</identifier>
 <datestamp>2016-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estonian Voting Verification Mechanism Revisited</dc:title>
 <dc:creator>Mus, Koksal</dc:creator>
 <dc:creator>Kiraz, Mehmet Sabir</dc:creator>
 <dc:creator>Cenk, Murat</dc:creator>
 <dc:creator>Sertkaya, Isa</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>94A60</dc:subject>
 <dc:description>  After the Estonian Parliamentary Elections held in 2011, an additional
verification mechanism was integrated into the i-voting system in order to
resist corrupted voting devices, including the so called Student's Attack where
a student practically showed that the voting system is indeed not verifiable by
developing several versions of malware capable of blocking or even changing the
vote. This mechanism gives voters the opportunity to verify whether the vote
they cast is stored in the central system correctly. However, the verification
phase ends by displaying the cast vote in plain form on the verification
device. In other words, the device on which the verification is done learns the
voter's choice. In this work, our aim is to investigate this verification phase
in detail and to point out that leaking the voter's choice to the verification
application may harm the voter privacy. Additionally, when applied in a wide
range, this would even compromise the fairness and the overall secrecy of the
elections. In this respect, we propose an alternative verification mechanism
for the Estonian i-voting system to overcome this vulnerability. Not only is
the proposed mechanism secure and resistant against corrupted verification
devices, so does it successfully verify whether the vote is correctly stored in
the system. We also highlight that our proposed mechanism brings only symmetric
encryptions and hash functions on the verification device, thereby mitigating
these weaknesses in an efficient way with a negligible cost. More concretely,
it brings only $m$ additional symmetric key decryptions to the verification
device, where $m$ denoting the number of candidates. Finally, we prove the
security of the proposed verification mechanism and compare the cost complexity
of the proposed method with that of the current mechanism.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2016-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00669</identifier>
 <datestamp>2017-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transaction-based Sandboxing for JavaScript</dc:title>
 <dc:creator>Keil, Matthias</dc:creator>
 <dc:creator>Thiemann, Peter</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Today's JavaScript applications are composed of scripts from different
origins that are loaded at run time. As not all of these origins are equally
trusted, the execution of these scripts should be isolated from one another.
However, some scripts must access the application state and some may be allowed
to change it, while preserving the confidentiality and integrity constraints of
the application.
  This paper presents design and implementation of DecentJS, a
language-embedded sandbox for full JavaScript. It enables scripts to run in a
configurable degree of isolation with fine-grained access control. It provides
a transactional scope in which effects are logged for review by the access
control policy. After inspection of the log, effects can be committed to the
application state or rolled back.
  The implementation relies on JavaScript proxies to guarantee full
interposition for the full language and for all code, including dynamically
loaded scripts and code injected via eval. Its only restriction is that scripts
must be compliant with JavaScript's strict mode.
</dc:description>
 <dc:description>Comment: Technical Report</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00670</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Are Programs Found? Speculating About Language Ergonomics With
  Curry-Howard</dc:title>
 <dc:creator>Emerich, Johannes</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3</dc:subject>
 <dc:subject>K.2</dc:subject>
 <dc:description>  Functional languages with strong static type systems have beneficial
properties to help ensure program correctness and reliability. Surprisingly,
their practical significance in applications is low relative to other languages
lacking in those dimensions. In this paper, the programs-as-proofs analogy is
taken seriously to gain speculative insights by analysis of creation habits in
the proof-centric discipline of mathematics. Viewed in light of this analogy, a
sampling of mathematicians' attitudes towards formal proof suggests that the
crucial role of intuition and experimentation in programming tasks may be under
appreciated, hinting at a possible explanation of the challenges rigorously
disciplined languages face in practical applications.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00670</dc:identifier>
 <dc:identifier>Proceedings of the 2016 ACM International Symposium on New Ideas,
  New Paradigms, and Reflections on Programming and Software (Onward! 2016).
  ACM, New York, NY, USA, 212-223</dc:identifier>
 <dc:identifier>doi:10.1145/2986012.2986030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00671</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reliable Evaluation of Neural Network for Multiclass Classification of
  Real-world Data</dc:title>
 <dc:creator>Dinesh, Siddharth</dc:creator>
 <dc:creator>Dash, Tirtharaj</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents a systematic evaluation of Neural Network (NN) for
classification of real-world data. In the field of machine learning, it is
often seen that a single parameter that is 'predictive accuracy' is being used
for evaluating the performance of a classifier model. However, this parameter
might not be considered reliable given a dataset with very high level of
skewness. To demonstrate such behavior, seven different types of datasets have
been used to evaluate a Multilayer Perceptron (MLP) using twelve(12) different
parameters which include micro- and macro-level estimation. In the present
study, the most common problem of prediction called 'multiclass' classification
has been considered. The results that are obtained for different parameters for
each of the dataset could demonstrate interesting findings to support the
usability of these set of performance evaluation parameters.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00671</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00675</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Weight in Enumeration</dc:title>
 <dc:creator>Schmidt, Johannes</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In our setting enumeration amounts to generate all solutions of a problem
instance without duplicates. We address the problem of enumerating the models
of B-formulae. A B-formula is a propositional formula whose connectives are
taken from a fixed set B of Boolean connectives. Without imposing any specific
order to output the solutions, this task is solved. We completely classify the
complexity of this enumeration task for all possible sets of connectives B
imposing the orders of (1) non-decreasing weight, (2) non-increasing weight;
the weight of a model being the number of variables assigned to 1. We consider
also the weighted variants where a non-negative integer weight is assigned to
each variable and show that this add-on leads to more sophisticated enumeration
algorithms and even renders previously tractable cases intractable, contrarily
to the constraint setting. As a by-product we obtain complete complexity
classifications for the optimization problems known as Min-Ones and Max-Ones
which are in the B-formula setting two different tasks.
</dc:description>
 <dc:description>Comment: 12 main pages + 5 appendix pages</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00686</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying and Categorizing Anomalies in Retinal Imaging Data</dc:title>
 <dc:creator>Seeb&#xf6;ck, Philipp</dc:creator>
 <dc:creator>Waldstein, Sebastian</dc:creator>
 <dc:creator>Klimscha, Sophie</dc:creator>
 <dc:creator>Gerendas, Bianca S.</dc:creator>
 <dc:creator>Donner, Ren&#xe9;</dc:creator>
 <dc:creator>Schlegl, Thomas</dc:creator>
 <dc:creator>Schmidt-Erfurth, Ursula</dc:creator>
 <dc:creator>Langs, Georg</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The identification and quantification of markers in medical images is
critical for diagnosis, prognosis and management of patients in clinical
practice. Supervised- or weakly supervised training enables the detection of
findings that are known a priori. It does not scale well, and a priori
definition limits the vocabulary of markers to known entities reducing the
accuracy of diagnosis and prognosis. Here, we propose the identification of
anomalies in large-scale medical imaging data using healthy examples as a
reference. We detect and categorize candidates for anomaly findings untypical
for the observed data. A deep convolutional autoencoder is trained on healthy
retinal images. The learned model generates a new feature representation, and
the distribution of healthy retinal patches is estimated by a one-class support
vector machine. Results demonstrate that we can identify pathologic regions in
images without using expert annotations. A subsequent clustering categorizes
findings into clinically meaningful classes. In addition the learned features
outperform standard embedding approaches in a classification task.
</dc:description>
 <dc:description>Comment: Extended Abstract, Accepted for NIPS 2016 Workshop &quot;Machine Learning
  for Health&quot;</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00688</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unified Hanani-Tutte theorem</dc:title>
 <dc:creator>Fulek, Radoslav</dc:creator>
 <dc:creator>Kyn&#x10d;l, Jan</dc:creator>
 <dc:creator>P&#xe1;lv&#xf6;lgyi, D&#xf6;m&#xf6;t&#xf6;r</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C10, 68R10</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We introduce a common generalization of the strong Hanani-Tutte theorem and
the weak Hanani-Tutte theorem: if a graph $G$ has a drawing $D$ in the plane
where every pair of independent edges crosses an even number of times, then $G$
has a planar drawing preserving the rotation of each vertex whose incident
edges cross each other evenly in $D$. The theorem is implicit in the proof of
the strong Hanani-Tutte theorem by Pelsmajer, Schaefer and \v{S}tefankovi\v{c}.
We give a new, somewhat simpler proof.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures; minor revision, mostly in the abstract and
  Section 4</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00688</dc:identifier>
 <dc:identifier>The Electronic Journal of Combinatorics 24 (2017), Issue 3, P3.18,
  8 pp</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00693</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From signatures to monads in UniMath</dc:title>
 <dc:creator>Ahrens, Benedikt</dc:creator>
 <dc:creator>Matthes, Ralph</dc:creator>
 <dc:creator>M&#xf6;rtberg, Anders</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  The term UniMath refers both to a formal system for mathematics, as well as a
computer-checked library of mathematics formalized in that system. The UniMath
system is a core dependent type theory, augmented by the univalence axiom. The
system is kept as small as possible in order to ease verification of it - in
particular, general inductive types are not part of the system.
  In this work, we partially remedy the lack of inductive types by constructing
some datatypes and their associated induction principles from other type
constructors. This involves a formalization of a category-theoretic result on
the construction of initial algebras, as well as a mechanism to conveniently
use the datatypes obtained. We also connect this construction to a previous
formalization of substitution for languages with variable binding. Altogether,
we construct a framework that allows us to concisely specify, via a simple
notion of binding signature, a language with variable binding. From such a
specification we obtain the datatype of terms of that language, equipped with a
certified monadic substitution operation and a suitable recursion scheme. Using
this we formalize the untyped lambda calculus and the raw syntax of
Martin-L\&quot;of type theory.
</dc:description>
 <dc:description>Comment: 30 pages</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00694</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA</dc:title>
 <dc:creator>Han, Song</dc:creator>
 <dc:creator>Kang, Junlong</dc:creator>
 <dc:creator>Mao, Huizi</dc:creator>
 <dc:creator>Hu, Yiming</dc:creator>
 <dc:creator>Li, Xin</dc:creator>
 <dc:creator>Li, Yubin</dc:creator>
 <dc:creator>Xie, Dongliang</dc:creator>
 <dc:creator>Luo, Hong</dc:creator>
 <dc:creator>Yao, Song</dc:creator>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:creator>Yang, Huazhong</dc:creator>
 <dc:creator>Dally, William J.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Long Short-Term Memory (LSTM) is widely used in speech recognition. In order
to achieve higher prediction accuracy, machine learning scientists have built
larger and larger models. Such large model is both computation intensive and
memory intensive. Deploying such bulky model results in high power consumption
and leads to high total cost of ownership (TCO) of a data center. In order to
speedup the prediction and make it energy efficient, we first propose a
load-balance-aware pruning method that can compress the LSTM model size by 20x
(10x from pruning and 2x from quantization) with negligible loss of the
prediction accuracy. The pruned model is friendly for parallel processing.
Next, we propose scheduler that encodes and partitions the compressed model to
each PE for parallelism, and schedule the complicated LSTM data flow. Finally,
we design the hardware architecture, named Efficient Speech Recognition Engine
(ESE) that works directly on the compressed model. Implemented on Xilinx
XCKU060 FPGA running at 200MHz, ESE has a performance of 282 GOPS working
directly on the compressed LSTM network, corresponding to 2.52 TOPS on the
uncompressed one, and processes a full LSTM for speech recognition with a power
dissipation of 41 Watts. Evaluated on the LSTM for speech recognition
benchmark, ESE is 43x and 3x faster than Core i7 5930k CPU and Pascal Titan X
GPU implementations. It achieves 40x and 11.5x higher energy efficiency
compared with the CPU and GPU respectively.
</dc:description>
 <dc:description>Comment: Accepted as full paper in FPGA'17, Monterey, CA; Also appeared at 1st
  International Workshop on Efficient Methods for Deep Neural Networks at NIPS
  2016, Barcelona, Spain</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00712</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Neural Programs</dc:title>
 <dc:creator>Murray, Kenton W.</dc:creator>
 <dc:creator>Krishnamurthy, Jayant</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present probabilistic neural programs, a framework for program induction
that permits flexible specification of both a computational model and inference
algorithm while simultaneously enabling the use of deep neural networks.
Probabilistic neural programs combine a computation graph for specifying a
neural network with an operator for weighted nondeterministic choice. Thus, a
program describes both a collection of decisions as well as the neural network
architecture used to make each one. We evaluate our approach on a challenging
diagram question answering task where probabilistic neural programs correctly
execute nearly twice as many programs as a baseline model.
</dc:description>
 <dc:description>Comment: Appears in NAMPI workshop at NIPS 2016</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00715</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Frequency Regulation in Islanded Microgrid Using Demand Response</dc:title>
 <dc:creator>Eshraghi, Alireza</dc:creator>
 <dc:creator>Motalleb, Mahdi</dc:creator>
 <dc:creator>Reihani, Ehsan</dc:creator>
 <dc:creator>Ghorbani, Reza</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Introducing more Distributed Generation (DG) into power grid infrastructure
drives more attention to understand how large scale DG affects grid operation.
Islanding is an important concern in this area. Islanding refers to the
condition that DGs within a microgrid continue energizing while the microgrid
has been disconnected from the main grid. Considering the adverse effects of
Islanding, it should be detected and managed in a proper way. After Islanding
has been detected, even though the first option is tripping all inverterbased
DG unit in the system, the system has this option to work as a stand-alone
microgrid. For achieving this goal, the frequency of microgrid should be
regulated. This paper proposes an islanding detection method based on current
detection in a parallel arm with the fuse arm of the microgrid. After islanding
detection, this paper presents an effective implementation Demand Response (DR)
to regulate the frequency in islanded microgrid as an Ancillary Service (AS)
considering the transient constraints of frequency in inverterbased
generations.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00716</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Game Theoretic Model of Demand Response Aggregator Competition for
  Selling Stored Energy in Regulated and Unregulated Power Markets</dc:title>
 <dc:creator>Motalleb, Mahdi</dc:creator>
 <dc:creator>Ghorbani, Reza</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This work is concerned with the application of game theoretic principles to
model competition between demand response aggregators for selling excess energy
stored in electrochemical storage devices directly to other aggregators in a
power market. This market framework is presented as an alternative to the
traditional vertically integrated market structure, which may be better suited
for developing demand response and smart grid technologies, in addition to
increasing penetration of independent renewable energy generation devices.
Demand for power generated by the utility through combustion of fuel could be
replaced, lowering emission of pollutants, when the energy used to charge the
batteries is produced sustainably and traded on smaller scales. The four
variants of game are considered: both non-cooperative (unregulated competition)
and Stackelberg (regulations on transaction price and size), each with and
without DR scheduling. The Nash equilibrium is derived for each game variant in
order to serve as a bid-price decision making criteria which determines the
optimal bidding strategy for an aggregator to sell in the market. The model is
applied to a case study involving completion for selling between two
aggregators. Bidding strategy is dependent on parameters inherent to an
aggregator's energy storage hardware, and the strategy selected by each
aggregator does not vary with the variations in the game conditions considered.
Demand response scheduling offers greater payoff for aggregators who implement
it, compared with those who do not. Addition of transaction price and volume
regulations to the market do not affect the participants optimal bidding
strategies (the Nash equilibrium), but lowers payoffs for all aggregators
participating in the market relative to unregulated competition.
</dc:description>
 <dc:description>Comment: 26 pages</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00729</identifier>
 <datestamp>2017-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated assessment of non-native learner essays: Investigating the
  role of linguistic features</dc:title>
 <dc:creator>Vajjala, Sowmya</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Automatic essay scoring (AES) refers to the process of scoring free text
responses to given prompts, considering human grader scores as the gold
standard. Writing such essays is an essential component of many language and
aptitude exams. Hence, AES became an active and established area of research,
and there are many proprietary systems used in real life applications today.
However, not much is known about which specific linguistic features are useful
for prediction and how much of this is consistent across datasets. This article
addresses that by exploring the role of various linguistic features in
automatic essay scoring using two publicly available datasets of non-native
English essays written in test taking scenarios. The linguistic properties are
modeled by encoding lexical, syntactic, discourse and error types of learner
language in the feature set. Predictive models are then developed using these
features on both datasets and the most predictive features are compared. While
the results show that the feature set used results in good predictive models
with both datasets, the question &quot;what are the most predictive features?&quot; has a
different answer for each dataset.
</dc:description>
 <dc:description>Comment: Article accepted for publication at: International Journal of
  Artificial Intelligence in Education (IJAIED). To appear in early 2017
  (journal url: http://www.springer.com/computer/ai/journal/40593)</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00729</dc:identifier>
 <dc:identifier>doi:10.1007/s40593-017-0142-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00730</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Pilot Case Study on Innovative Behaviour: Lessons Learned and
  Directions for Future Work</dc:title>
 <dc:creator>Monteiro, Cleviton</dc:creator>
 <dc:creator>da Silva, Fabio Queda Bueno</dc:creator>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Context: A case study is a powerful research strategy for investigating
complex social-technical and managerial phenomena in real life settings.
However, when the phenomenon has not been fully discovered or understood, pilot
case studies are important to refine the research problem, the research
variables, and the case study design before launching a full-scale
investigation. The role of pilot case studies has not been fully addressed in
empirical software engineering research literature. Objective: To explore the
use of pilot case studies in the design of full-scale case studies, and to
report the main lessons learned from an industrial pilot study. Method: We
designed and conducted an exploratory case study to identify new relevant
research variables that influence the innovative behaviour of software
engineers in the industrial setting and to refine the full-scale case study
design for the next phase of our research. Results: The use of a pilot case
study identified several important research variables that were missing in the
initial framework. The pilot study also supported a more sophisticated case
study design, which was used to guide a full-scale study. Conclusions: When a
research topic has not been fully discovered or understood, it is difficult to
create a case study design that covers the relevant research variables and
their potential relationships. Conducting a full-scale case study using an
untested case design can lead to waste of resources and time if the design has
to be reworked during the study. In these situations, the use of pilot case
studies can significantly improve the case study design.
</dc:description>
 <dc:description>Comment: 6 pages in 10th International Symposium on Empirical Software
  Engineering and Measurement (ESEM), Ciudad Real, Spain, September 2016</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00730</dc:identifier>
 <dc:identifier>doi:10.1145/2961111.2962618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00733</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trends in Students Media Usage</dc:title>
 <dc:creator>Gidion, Gerd</dc:creator>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:creator>Grosch, Michael</dc:creator>
 <dc:creator>Meadows, Ke</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Trends in media usage by students can affect the way they learn. Students
demand the use of technology, thus institutions and instructors should meet
students requests. This paper describes the results of a survey where drivers
in the use of media show continuously increasing or decreasing values from the
first to the fourth year of study experience at the Western University, Canada,
highlighting trends in the usage of new and traditional media in higher
education by students. The survey was used to gather data on students media
usage habits and user satisfaction from first to fourth year of study and found
that media usage increases over the years from first to fourth. The
presentation of data using bar charts reveals a slight increase over the years
in students owning notebooks or laptops off-campus and a significant increase
from first to fourth year of students accessing online academic periodicals and
journals. Another noteworthy finding relates to fourth year students being more
conscious of the quality of information that they read on the Internet in
comparison to students in first year, even though this is a slight year on year
increase.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1507.06857</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00733</dc:identifier>
 <dc:identifier>International Conference on Computational Science and Its
  Applications (ICCSA), Beijing, China, pp. 491-502, LNCS 9786, 2016</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-42085-1_38</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00734</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why a Testing Career Is Not the First Choice of Engineers</dc:title>
 <dc:creator>Waychal, Pradeep Kashinath</dc:creator>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  As software systems are becoming larger, more complex, and dependent on many
third-party software components, the chances of their failure are increasing
further. This calls for intense efforts to improve the quality of testing in
the software development process.
</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00734</dc:identifier>
 <dc:identifier>123rd Annual Conference of the American Society for Engineering
  Education, Paper ID #14994, 12 pages, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00735</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Environmental Factors Influencing Individual Decision-Making Behavior in
  Software Project: A Systematic Literature Review</dc:title>
 <dc:creator>Jia, Jingdong</dc:creator>
 <dc:creator>Zhang, Pengnan</dc:creator>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  As one of the crucial human aspects, individual decision-making behavior that
may affect the quality of a software project is adaptive to the environment in
which the individual is. However, no comprehensive reference framework of the
environmental factors influencing individual decision-making behavior in
software projects is presently available. This paper undertakes a systematic
literature review (SLR) to gain insight into existing studies on this topic.
After a careful SLR process, 40 studies were targeted to solve this question.
Based on these extracted studies, we first provided a taxonomy of environmental
factors comprising eight categories. Then a total of 237 factors are identified
and classified using these eight categories, and some major environmental
factors of each category are listed in the paper. The environmental factors
listing and the taxonomy can help researchers and practitioners to better
understand and predict the behavior of individuals during decision making and
to design more effective solutions to improve people management in software
projects.
</dc:description>
 <dc:description>Comment: in IEEE 9th International Workshop on Cooperative and Human Aspects
  of Software Engineering, 2016</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00735</dc:identifier>
 <dc:identifier>doi:10.1145/2897586.2897589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00738</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Action Recognition with Dynamic Image Networks</dc:title>
 <dc:creator>Bilen, Hakan</dc:creator>
 <dc:creator>Fernando, Basura</dc:creator>
 <dc:creator>Gavves, Efstratios</dc:creator>
 <dc:creator>Vedaldi, Andrea</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce the concept of &quot;dynamic image&quot;, a novel compact representation
of videos useful for video analysis, particularly in combination with
convolutional neural networks (CNNs). A dynamic image encodes temporal data
such as RGB or optical flow videos by using the concept of `rank pooling'. The
idea is to learn a ranking machine that captures the temporal evolution of the
data and to use the parameters of the latter as a representation. When a linear
ranking machine is used, the resulting representation is in the form of an
image, which we call dynamic because it summarizes the video dynamics in
addition of appearance. This is a powerful idea because it allows to convert
any video to an image so that existing CNN models pre-trained for the analysis
of still images can be immediately extended to videos. We also present an
efficient and effective approximate rank pooling operator, accelerating
standard rank pooling algorithms by orders of magnitude, and formulate that as
a CNN layer. This new layer allows generalizing dynamic images to dynamic
feature maps. We demonstrate the power of the new representations on standard
benchmarks in action recognition achieving state-of-the-art performance.
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures, 9 tables</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00742</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison of the COG Defuzzification Technique and Its Variations to
  the GPA Index</dc:title>
 <dc:creator>Voskoglou, Michael Gr.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>03E72</dc:subject>
 <dc:description>  The Center of Gravity (COG) method is one of the most popular defuzzification
techniques of fuzzy mathematics. In earlier works the COG technique was
properly adapted to be used as an assessment model (RFAM)and several variations
of it (GRFAM, TFAM and TpFAM)were also constructed for the same purpose. In
this paper the outcomes of all these models are compared to the corresponding
outcomes of a traditional assessment method of the bi-valued logic, the Grade
Point Average (GPA) Index. Examples are also presented illustrating our
results.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures, 2 tables</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00742</dc:identifier>
 <dc:identifier>American Journal of Computational and Applied Mathematics, 6(5),
  187-193, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00745</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cognitive Deep Machine Can Train Itself</dc:title>
 <dc:creator>L&#x151;rincz, Andr&#xe1;s</dc:creator>
 <dc:creator>Cs&#xe1;kv&#xe1;ri, M&#xe1;t&#xe9;</dc:creator>
 <dc:creator>F&#xf3;thi, &#xc1;ron</dc:creator>
 <dc:creator>Milacski, Zolt&#xe1;n &#xc1;d&#xe1;m</dc:creator>
 <dc:creator>S&#xe1;rk&#xe1;ny, Andr&#xe1;s</dc:creator>
 <dc:creator>T&#x151;s&#xe9;r, Zolt&#xe1;n</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Machine learning is making substantial progress in diverse applications. The
success is mostly due to advances in deep learning. However, deep learning can
make mistakes and its generalization abilities to new tasks are questionable.
We ask when and how one can combine network outputs, when (i) details of the
observations are evaluated by learned deep components and (ii) facts and
confirmation rules are available in knowledge based systems. We show that in
limited contexts the required number of training samples can be low and
self-improvement of pre-trained networks in more general context is possible.
We argue that the combination of sparse outlier detection with deep components
that can support each other diminish the fragility of deep methods, an
important requirement for engineering applications. We argue that supervised
learning of labels may be fully eliminated under certain conditions: a
component based architecture together with a knowledge based system can train
itself and provide high quality answers. We demonstrate these concepts on the
State Farm Distracted Driver Detection benchmark. We argue that the view of the
Study Panel (2016) may overestimate the requirements on `years of focused
research' and `careful, unique construction' for `AI systems'.
</dc:description>
 <dc:description>Comment: 14 pages, 8 figures</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00750</identifier>
 <datestamp>2017-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Negative Matrix Factorizations for Multiplex Network Analysis</dc:title>
 <dc:creator>Gligorijevic, Vladimir</dc:creator>
 <dc:creator>Panagakis, Yannis</dc:creator>
 <dc:creator>Zafeiriou, Stefanos</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Networks have been a general tool for representing, analyzing, and modeling
relational data arising in several domains. One of the most important aspect of
network analysis is community detection or network clustering. Until recently,
the major focus have been on discovering community structure in single (i.e.,
monoplex) networks. However, with the advent of relational data with multiple
modalities, multiplex networks, i.e., networks composed of multiple layers
representing different aspects of relations, have emerged. Consequently,
community detection in multiplex network, i.e., detecting clusters of nodes
shared by all layers, has become a new challenge. In this paper, we propose
Network Fusion for Composite Community Extraction (NF-CCE), a new class of
algorithms, based on four different non-negative matrix factorization models,
capable of extracting composite communities in multiplex networks. Each
algorithm works in two steps: first, it finds a non-negative, low-dimensional
feature representation of each network layer; then, it fuses the feature
representation of layers into a common non-negative, low-dimensional feature
representation via collective factorization. The composite clusters are
extracted from the common feature representation. We demonstrate the superior
performance of our algorithms over the state-of-the-art methods on various
types of multiplex networks, including biological, social, economic, citation,
phone communication, and brain multiplex networks.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures, 3 tables</dc:description>
 <dc:date>2016-11-30</dc:date>
 <dc:date>2017-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00750</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00766</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>I Spy with My Little Eye: Analysis and Detection of Spying Browser
  Extensions</dc:title>
 <dc:creator>Aggarwal, Anupama</dc:creator>
 <dc:creator>Viswanath, Bimal</dc:creator>
 <dc:creator>Kumar, Saravana</dc:creator>
 <dc:creator>Shah, Ayush</dc:creator>
 <dc:creator>Zhang, Liang</dc:creator>
 <dc:creator>Kumaraguru, Ponnurangam</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Several studies have been conducted on understanding third-party user
tracking on the web. However, web trackers can only track users on sites where
they are embedded by the publisher, thus obtaining a fragmented view of a
user's online footprint. In this work, we investigate a different form of user
tracking, where browser extensions are repurposed to capture the complete
online activities of a user and communicate the collected sensitive information
to a third-party domain. We conduct an empirical study of spying browser
extensions on the Chrome Web Store. First, we present an in-depth analysis of
the spying behavior of these extensions. We observe that these extensions steal
a variety of sensitive user information, such as the complete browsing history
(e.g., the sequence of web traversals), online social network (OSN) access
tokens, IP address, and user geolocation. Second, we investigate the potential
for automatically detecting spying extensions by applying machine learning
schemes. We show that using a Recurrent Neural Network (RNN), the sequences of
browser API calls can be a robust feature, outperforming hand-crafted features
(used in prior work on malicious extensions) to detect spying extensions. Our
RNN based detection scheme achieves a high precision (90.02%) and recall
(93.31%) in detecting spying extensions.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00767</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asynchronous Stochastic Gradient MCMC with Elastic Coupling</dc:title>
 <dc:creator>Springenberg, Jost Tobias</dc:creator>
 <dc:creator>Klein, Aaron</dc:creator>
 <dc:creator>Falkner, Stefan</dc:creator>
 <dc:creator>Hutter, Frank</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider parallel asynchronous Markov Chain Monte Carlo (MCMC) sampling
for problems where we can leverage (stochastic) gradients to define continuous
dynamics which explore the target distribution. We outline a solution strategy
for this setting based on stochastic gradient Hamiltonian Monte Carlo sampling
(SGHMC) which we alter to include an elastic coupling term that ties together
multiple MCMC instances. The proposed strategy turns inherently sequential HMC
algorithms into asynchronous parallel versions. First experiments empirically
show that the resulting parallel sampler significantly speeds up exploration of
the target distribution, when compared to standard SGHMC, and is less prone to
the harmful effects of stale gradients than a naive parallelization approach.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00775</identifier>
 <datestamp>2017-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A simple squared-error reformulation for ordinal classification</dc:title>
 <dc:creator>Beckham, Christopher</dc:creator>
 <dc:creator>Pal, Christopher</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we explore ordinal classification (in the context of deep
neural networks) through a simple modification of the squared error loss which
not only allows it to not only be sensitive to class ordering, but also allows
the possibility of having a discrete probability distribution over the classes.
Our formulation is based on the use of a softmax hidden layer, which has
received relatively little attention in the literature. We empirically evaluate
its performance on the Kaggle diabetic retinopathy dataset, an ordinal and
high-resolution dataset and show that it outperforms all of the baselines
employed.
</dc:description>
 <dc:description>Comment: v1: Camera-ready abstract for NIPS for Health Workshop (2016) v2:
  Clean-up of some sections, added appendix section where we briefly explore
  optimisation of quadratic weighted kappa (QWK)</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00796</identifier>
 <datestamp>2017-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overcoming catastrophic forgetting in neural networks</dc:title>
 <dc:creator>Kirkpatrick, James</dc:creator>
 <dc:creator>Pascanu, Razvan</dc:creator>
 <dc:creator>Rabinowitz, Neil</dc:creator>
 <dc:creator>Veness, Joel</dc:creator>
 <dc:creator>Desjardins, Guillaume</dc:creator>
 <dc:creator>Rusu, Andrei A.</dc:creator>
 <dc:creator>Milan, Kieran</dc:creator>
 <dc:creator>Quan, John</dc:creator>
 <dc:creator>Ramalho, Tiago</dc:creator>
 <dc:creator>Grabska-Barwinska, Agnieszka</dc:creator>
 <dc:creator>Hassabis, Demis</dc:creator>
 <dc:creator>Clopath, Claudia</dc:creator>
 <dc:creator>Kumaran, Dharshan</dc:creator>
 <dc:creator>Hadsell, Raia</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The ability to learn tasks in a sequential fashion is crucial to the
development of artificial intelligence. Neural networks are not, in general,
capable of this and it has been widely thought that catastrophic forgetting is
an inevitable feature of connectionist models. We show that it is possible to
overcome this limitation and train networks that can maintain expertise on
tasks which they have not experienced for a long time. Our approach remembers
old tasks by selectively slowing down learning on the weights important for
those tasks. We demonstrate our approach is scalable and effective by solving a
set of classification tasks based on the MNIST hand written digit dataset and
by learning several Atari 2600 games sequentially.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00799</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Benchmark for Endoluminal Scene Segmentation of Colonoscopy Images</dc:title>
 <dc:creator>V&#xe1;zquez, David</dc:creator>
 <dc:creator>Bernal, Jorge</dc:creator>
 <dc:creator>S&#xe1;nchez, F. Javier</dc:creator>
 <dc:creator>Fern&#xe1;ndez-Esparrach, Gloria</dc:creator>
 <dc:creator>L&#xf3;pez, Antonio M.</dc:creator>
 <dc:creator>Romero, Adriana</dc:creator>
 <dc:creator>Drozdzal, Michal</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Colorectal cancer (CRC) is the third cause of cancer death worldwide.
Currently, the standard approach to reduce CRC-related mortality is to perform
regular screening in search for polyps and colonoscopy is the screening tool of
choice. The main limitations of this screening procedure are polyp miss-rate
and inability to perform visual assessment of polyp malignancy. These drawbacks
can be reduced by designing Decision Support Systems (DSS) aiming to help
clinicians in the different stages of the procedure by providing endoluminal
scene segmentation. Thus, in this paper, we introduce an extended benchmark of
colonoscopy image, with the hope of establishing a new strong benchmark for
colonoscopy image analysis research. We provide new baselines on this dataset
by training standard fully convolutional networks (FCN) for semantic
segmentation and significantly outperforming, without any further
post-processing, prior results in endoluminal scene segmentation.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00800</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HealthAdvisor: Recommendation System for Wearable Technologies enabling
  Proactive Health Monitoring</dc:title>
 <dc:creator>Asthana, Shubhi</dc:creator>
 <dc:creator>Strong, Ray</dc:creator>
 <dc:creator>Megahed, Aly</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Proactive monitoring of one's health could avoid serious diseases as well as
better maintain the individual's well-being. In today's IoT world, there has
been numerous wearable technological devices to monitor/measure different
health attributes. However, with that increasing number of attributes and
wearables, it becomes unclear to the individual which ones they should be
using. The aim of this paper is to provide a recommendation engine for
personalized recommended wearables for any given individual. The way the engine
works is through first identifying the diseases that this person is at risk of,
given his/her attributes and medical history. We built a machine learning
classification model for this task. Second, these diseases are mapped to the
attributes that need to be measured in order to monitor such diseases. Third,
we map these measurements to the appropriate wearable technologies. This is
done via a textual analytics model that we developed that uses available
information of different wearables to map the aforementioned measurements to
these wearables. The output can be used to recommend the wearables to
individuals as well as provide a feedback to wearable developers for common
measurements that do not have corresponding wearables today.
</dc:description>
 <dc:description>Comment: NIPS Workshop on Machine Learning for Health 2016, Barcelona, Spain</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00804</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Restricted Strong Convexity Implies Weak Submodularity</dc:title>
 <dc:creator>Elenberg, Ethan R.</dc:creator>
 <dc:creator>Khanna, Rajiv</dc:creator>
 <dc:creator>Dimakis, Alexandros G.</dc:creator>
 <dc:creator>Negahban, Sahand</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We connect high-dimensional subset selection and submodular maximization. Our
results extend the work of Das and Kempe (2011) from the setting of linear
regression to arbitrary objective functions. For greedy feature selection, this
connection allows us to obtain strong multiplicative performance bounds on
several methods without statistical modeling assumptions. We also derive
recovery guarantees of this form under standard assumptions. Our work shows
that greedy algorithms perform within a constant factor from the best possible
subset-selection solution for a broad class of general objective functions. Our
methods allow a direct control over the number of obtained features as opposed
to regularization parameters that only implicitly control sparsity. Our proof
technique uses the concept of weak submodularity initially defined by Das and
Kempe. We draw a connection between convex analysis and submodular set function
theory which may be of independent interest for other statistical learning
applications that have combinatorial structure.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-10-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00807</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-efficient 8-point DCT Approximations: Theory and Hardware
  Architectures</dc:title>
 <dc:creator>Cintra, R. J.</dc:creator>
 <dc:creator>Bayer, F. M.</dc:creator>
 <dc:creator>Coutinho, V. A.</dc:creator>
 <dc:creator>Kulasekera, S.</dc:creator>
 <dc:creator>Madanayake, A.</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  Due to its remarkable energy compaction properties, the discrete cosine
transform (DCT) is employed in a multitude of compression standards, such as
JPEG and H.265/HEVC. Several low-complexity integer approximations for the DCT
have been proposed for both 1-D and 2-D signal analysis. The increasing demand
for low-complexity, energy efficient methods require algorithms with even lower
computational costs. In this paper, new 8-point DCT approximations with very
low arithmetic complexity are presented. The new transforms are proposed based
on pruning state-of-the-art DCT approximations. The proposed algorithms were
assessed in terms of arithmetic complexity, energy retention capability, and
image compression performance. In addition, a metric combining performance and
computational complexity measures was proposed. Results showed good performance
and extremely low computational complexity. Introduced algorithms were mapped
into systolic-array digital architectures and physically realized as digital
prototype circuits using FPGA technology and mapped to 45nm CMOS technology.
All hardware-related metrics showed low resource consumption of the proposed
pruned approximate transforms. The best proposed transform according to the
introduced metric presents a reduction in power consumption of 21--25%.
</dc:description>
 <dc:description>Comment: 21 pages, 7 figures, 5 tables</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00807</dc:identifier>
 <dc:identifier>Circuits, Systems, and Signal Processing, November 2016, Volume
  35, Issue 11, pp 4009-4029</dc:identifier>
 <dc:identifier>doi:10.1007/s00034-015-0233-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00814</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perspective Transformer Nets: Learning Single-View 3D Object
  Reconstruction without 3D Supervision</dc:title>
 <dc:creator>Yan, Xinchen</dc:creator>
 <dc:creator>Yang, Jimei</dc:creator>
 <dc:creator>Yumer, Ersin</dc:creator>
 <dc:creator>Guo, Yijie</dc:creator>
 <dc:creator>Lee, Honglak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Understanding the 3D world is a fundamental problem in computer vision.
However, learning a good representation of 3D objects is still an open problem
due to the high dimensionality of the data and many factors of variation
involved. In this work, we investigate the task of single-view 3D object
reconstruction from a learning agent's perspective. We formulate the learning
process as an interaction between 3D and 2D representations and propose an
encoder-decoder network with a novel projection loss defined by the perspective
transformation. More importantly, the projection loss enables the unsupervised
learning using 2D observation without explicit 3D supervision. We demonstrate
the ability of the model in generating 3D volume from a single 2D image with
three sets of experiments: (1) learning from single-class objects; (2) learning
from multi-class objects and (3) testing on novel object classes. Results show
superior performance and better generalization ability for 3D object
reconstruction when the projection loss is involved.
</dc:description>
 <dc:description>Comment: published at NIPS 2016</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00817</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Summary - TerpreT: A Probabilistic Programming Language for Program
  Induction</dc:title>
 <dc:creator>Gaunt, Alexander L.</dc:creator>
 <dc:creator>Brockschmidt, Marc</dc:creator>
 <dc:creator>Singh, Rishabh</dc:creator>
 <dc:creator>Kushman, Nate</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:creator>Taylor, Jonathan</dc:creator>
 <dc:creator>Tarlow, Daniel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We study machine learning formulations of inductive program synthesis; that
is, given input-output examples, synthesize source code that maps inputs to
corresponding outputs. Our key contribution is TerpreT, a domain-specific
language for expressing program synthesis problems. A TerpreT model is composed
of a specification of a program representation and an interpreter that
describes how programs map inputs to outputs. The inference task is to observe
a set of input-output examples and infer the underlying program. From a TerpreT
model we automatically perform inference using four different back-ends:
gradient descent (thus each TerpreT model can be seen as defining a
differentiable interpreter), linear program (LP) relaxations for graphical
models, discrete satisfiability solving, and the Sketch program synthesis
system. TerpreT has two main benefits. First, it enables rapid exploration of a
range of domains, program representations, and interpreter models. Second, it
separates the model specification from the inference algorithm, allowing proper
comparisons between different approaches to inference.
  We illustrate the value of TerpreT by developing several interpreter models
and performing an extensive empirical comparison between alternative inference
algorithms on a variety of program models. To our knowledge, this is the first
work to compare gradient-based search over program space to traditional
search-based alternatives. Our key empirical finding is that constraint solvers
dominate the gradient descent and LP-based formulations.
  This is a workshop summary of a longer report at arXiv:1608.04428
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures, 4 tables in 1st Workshop on Neural Abstract
  Machines &amp; Program Induction (NAMPI), @NIPS 2016</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00824</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning with Hierarchical Gaussian Kernels</dc:title>
 <dc:creator>Steinwart, Ingo</dc:creator>
 <dc:creator>Thomann, Philipp</dc:creator>
 <dc:creator>Schmid, Nico</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We investigate iterated compositions of weighted sums of Gaussian kernels and
provide an interpretation of the construction that shows some similarities with
the architectures of deep neural networks. On the theoretical side, we show
that these kernels are universal and that SVMs using these kernels are
universally consistent. We further describe a parameter optimization method for
the kernel parameters and empirically compare this method to SVMs, random
forests, a multiple kernel learning approach, and to some deep neural networks.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00827</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Operations on a Stack with Neural Turing Machines</dc:title>
 <dc:creator>Deleu, Tristan</dc:creator>
 <dc:creator>Dureau, Joseph</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Multiple extensions of Recurrent Neural Networks (RNNs) have been proposed
recently to address the difficulty of storing information over long time
periods. In this paper, we experiment with the capacity of Neural Turing
Machines (NTMs) to deal with these long-term dependencies on well-balanced
strings of parentheses. We show that not only does the NTM emulate a stack with
its heads and learn an algorithm to recognize such words, but it is also
capable of strongly generalizing to much longer sequences.
</dc:description>
 <dc:description>Comment: 1st Workshop on Neural Abstract Machines &amp; Program Induction (NAMPI),
  NIPS 2016, Barcelona, Spain</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00835</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scribbler: Controlling Deep Image Synthesis with Sketch and Color</dc:title>
 <dc:creator>Sangkloy, Patsorn</dc:creator>
 <dc:creator>Lu, Jingwan</dc:creator>
 <dc:creator>Fang, Chen</dc:creator>
 <dc:creator>Yu, Fisher</dc:creator>
 <dc:creator>Hays, James</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recently, there have been several promising methods to generate realistic
imagery from deep convolutional networks. These methods sidestep the
traditional computer graphics rendering pipeline and instead generate imagery
at the pixel level by learning from large collections of photos (e.g. faces or
bedrooms). However, these methods are of limited utility because it is
difficult for a user to control what the network produces. In this paper, we
propose a deep adversarial image synthesis architecture that is conditioned on
sketched boundaries and sparse color strokes to generate realistic cars,
bedrooms, or faces. We demonstrate a sketch based image synthesis system which
allows users to 'scribble' over the sketch to indicate preferred color for
objects. Our network can then generate convincing images that satisfy both the
color and the sketch constraints of user. The network is feed-forward which
allows users to see the effect of their edits in real time. We compare to
recent work on sketch to image synthesis and show that our approach can
generate more realistic, more diverse, and more controllable outputs. The
architecture is also effective at user-guided colorization of grayscale images.
</dc:description>
 <dc:description>Comment: 13 pages, 14 figures</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00837</identifier>
 <datestamp>2017-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making the V in VQA Matter: Elevating the Role of Image Understanding in
  Visual Question Answering</dc:title>
 <dc:creator>Goyal, Yash</dc:creator>
 <dc:creator>Khot, Tejas</dc:creator>
 <dc:creator>Summers-Stay, Douglas</dc:creator>
 <dc:creator>Batra, Dhruv</dc:creator>
 <dc:creator>Parikh, Devi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Problems at the intersection of vision and language are of significant
importance both as challenging research questions and for the rich set of
applications they enable. However, inherent structure in our world and bias in
our language tend to be a simpler signal for learning than visual modalities,
resulting in models that ignore visual information, leading to an inflated
sense of their capability.
  We propose to counter these language priors for the task of Visual Question
Answering (VQA) and make vision (the V in VQA) matter! Specifically, we balance
the popular VQA dataset by collecting complementary images such that every
question in our balanced dataset is associated with not just a single image,
but rather a pair of similar images that result in two different answers to the
question. Our dataset is by construction more balanced than the original VQA
dataset and has approximately twice the number of image-question pairs. Our
complete balanced dataset is publicly available at www.visualqa.org as part of
the 2nd iteration of the Visual Question Answering Dataset and Challenge (VQA
v2.0).
  We further benchmark a number of state-of-art VQA models on our balanced
dataset. All models perform significantly worse on our balanced dataset,
suggesting that these models have indeed learned to exploit language priors.
This finding provides the first concrete empirical evidence for what seems to
be a qualitative sense among practitioners.
  Finally, our data collection protocol for identifying complementary images
enables us to develop a novel interpretable model, which in addition to
providing an answer to the given (image, question) pair, also provides a
counter-example based explanation. Specifically, it identifies an image that is
similar to the original image, but it believes has a different answer to the
same question. This can help in building trust for machines among their users.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00840</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel multiclassSVM based framework to classify lithology from well
  logs: a real-world application</dc:title>
 <dc:creator>Chaki, Soumi</dc:creator>
 <dc:creator>Routray, Aurobinda</dc:creator>
 <dc:creator>Mohanty, William K.</dc:creator>
 <dc:creator>Jenamani, Mamata</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Support vector machines (SVMs) have been recognized as a potential tool for
supervised classification analyses in different domains of research. In
essence, SVM is a binary classifier. Therefore, in case of a multiclass
problem, the problem is divided into a series of binary problems which are
solved by binary classifiers, and finally the classification results are
combined following either the one-against-one or one-against-all strategies. In
this paper, an attempt has been made to classify lithology using a multiclass
SVM based framework using well logs as predictor variables. Here, the lithology
is classified into four classes such as sand, shaly sand, sandy shale and shale
based on the relative values of sand and shale fractions as suggested by an
expert geologist. The available dataset consisting well logs (gamma ray,
neutron porosity, density, and P-sonic) and class information from four closely
spaced wells from an onshore hydrocarbon field is divided into training and
testing sets. We have used one-against-all strategy to combine the results of
multiple binary classifiers. The reported results established the superiority
of multiclass SVM compared to other classifiers in terms of classification
accuracy. The selection of kernel function and associated parameters has also
been investigated here. It can be envisaged from the results achieved in this
study that the proposed framework based on multiclass SVM can further be used
to solve classification problems. In future research endeavor, seismic
attributes can be introduced in the framework to classify the lithology
throughout a study area from seismic inputs.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures, 4 tables Presented at INDICON 2015 at New Delhi,
  India</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00841</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Framework based on SVDD to Classify Water Saturation from
  Seismic Attributes</dc:title>
 <dc:creator>Chaki, Soumi</dc:creator>
 <dc:creator>Verma, Akhilesh Kumar</dc:creator>
 <dc:creator>Routray, Aurobinda</dc:creator>
 <dc:creator>Mohanty, William K.</dc:creator>
 <dc:creator>Jenamani, Mamata</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Water saturation is an important property in reservoir engineering domain.
Thus, satisfactory classification of water saturation from seismic attributes
is beneficial for reservoir characterization. However, diverse and non-linear
nature of subsurface attributes makes the classification task difficult. In
this context, this paper proposes a generalized Support Vector Data Description
(SVDD) based novel classification framework to classify water saturation into
two classes (Class high and Class low) from three seismic attributes seismic
impedance, amplitude envelop, and seismic sweetness. G-metric means and program
execution time are used to quantify the performance of the proposed framework
along with established supervised classifiers. The documented results imply
that the proposed framework is superior to existing classifiers. The present
study is envisioned to contribute in further reservoir modeling.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, 2table Presented at Fourth International
  Conference on Emerging Applications of Information Technology (EAIT 2014),
  ISI Kolkata, India</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00866</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Creating a Real-Time, Reproducible Event Dataset</dc:title>
 <dc:creator>Beieler, John</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The generation of political event data has remained much the same since the
mid-1990s, both in terms of data acquisition and the process of coding text
into data. Since the 1990s, however, there have been significant improvements
in open-source natural language processing software and in the availability of
digitized news content. This paper presents a new, next-generation event
dataset, named Phoenix, that builds from these and other advances. This dataset
includes improvements in the underlying news collection process and event
coding software, along with the creation of a general processing pipeline
necessary to produce daily-updated data. This paper provides a face validity
checks by briefly examining the data for the conflict in Syria, and a
comparison between Phoenix and the Integrated Crisis Early Warning System data.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00867</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of Dynamic Line Rating on Dispatch Decisions and Integration of
  Variable RES Energy</dc:title>
 <dc:creator>Xu, Bolun</dc:creator>
 <dc:creator>Ulbig, Andreas</dc:creator>
 <dc:creator>Andersson, Goran</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Dynamic line rating (DLR) models the transmission capacity of overhead lines
as a function of ambient conditions. It takes advantage of the physical thermal
property of overhead line conductors, thus making DLR less conservative
compared to the traditional worst-case oriented nominal line rating (NLR).
Employing DLR brings potential benefits for grid integration of variable
Renewable Energy Sources (RES), such as wind and solar energy. In this paper,
we reproduce weather conditions from renewable feed-ins and local temperature
records, and calculate DLR in accordance with the RES feed-in and load demand
data step. Simulations with high time resolution, using a predictive dispatch
optimization and the Power Node modeling framework, of a six-node benchmark
power system loosely based on the German power system are performed for the
current situation, using actual wind and PV feed-in data. The integration
capability of DLR under high RES production shares is inspected through
simulations with scaled-up RES profiles and reduced dispatchable generation
capacity. The simulation result demonstrates a comparison between DLR and NLR
in terms of reductions in RES generation curtailments and load shedding, while
discussions on the practicality of adopting DLR in the current power system is
given in the end.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00874</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-resolution Data Fusion for Super-Resolution Electron Microscopy</dc:title>
 <dc:creator>Sreehari, Suhas</dc:creator>
 <dc:creator>Venkatakrishnan, S. V.</dc:creator>
 <dc:creator>Bouman, Katherine L.</dc:creator>
 <dc:creator>Simmons, Jeffrey P.</dc:creator>
 <dc:creator>Drummy, Lawrence F.</dc:creator>
 <dc:creator>Bouman, Charles A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Perhaps surprisingly, the total electron microscopy (EM) data collected to
date is less than a cubic millimeter. Consequently, there is an enormous demand
in the materials and biological sciences to image at greater speed and lower
dosage, while maintaining resolution. Traditional EM imaging based on
homogeneous raster-order scanning severely limits the volume of high-resolution
data that can be collected, and presents a fundamental limitation to
understanding physical processes such as material deformation, crack
propagation, and pyrolysis.
  We introduce a novel multi-resolution data fusion (MDF) method for
super-resolution computational EM. Our method combines innovative data
acquisition with novel algorithmic techniques to dramatically improve the
resolution/volume/speed trade-off. The key to our approach is to collect the
entire sample at low resolution, while simultaneously collecting a small
fraction of data at high resolution. The high-resolution measurements are then
used to create a material-specific patch-library that is used within the
&quot;plug-and-play&quot; framework to dramatically improve super-resolution of the
low-resolution data. We present results using FEI electron microscope data that
demonstrate super-resolution factors of 4x, 8x, and 16x, while substantially
maintaining high image quality and reducing dosage.
</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00876</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FRIDA: FRI-Based DOA Estimation for Arbitrary Array Layouts</dc:title>
 <dc:creator>Pan, Hanjie</dc:creator>
 <dc:creator>Scheibler, Robin</dc:creator>
 <dc:creator>Bezzam, Eric</dc:creator>
 <dc:creator>Dokmanic, Ivan</dc:creator>
 <dc:creator>Vetterli, Martin</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  In this paper we present FRIDA---an algorithm for estimating directions of
arrival of multiple wideband sound sources. FRIDA combines multi-band
information coherently and achieves state-of-the-art resolution at extremely
low signal-to-noise ratios. It works for arbitrary array layouts, but unlike
the various steered response power and subspace methods, it does not require a
grid search. FRIDA leverages recent advances in sampling signals with a finite
rate of innovation. It is based on the insight that for any array layout, the
entries of the spatial covariance matrix can be linearly transformed into a
uniformly sampled sum of sinusoids.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP2017</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00876</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00878</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Approach for Modeling Complex Deep Futures</dc:title>
 <dc:creator>Upchurch, Edwin</dc:creator>
 <dc:creator>Meshket, Leila</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Many large-scale, complex systems consist of interactions between humans,
human-made systems and the environment. The approach developed in this paper is
to partition the problem space into two fundamental layers and identify,
parameterize and model the main dimensions of each layer and interactions
across and in between layers. One layer is the key actors or major organization
or human decision makers who influence the state of the world. The other layer
includes the domains or fields of knowledge relevant to the problem being
addressed. These domains include elements such as the physical earth and its
atmosphere, world demography, world economy, level of globalization, and
politics. Key parameters for each of the actor types and domains will be
extracted and assessed using existing data sources. Novel systems, uncertainty
modeling and analysis techniques are combined with advanced computational
technologies to determine a spectrum of likely future system states and conduct
ifthen scenario analyses.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00881</identifier>
 <datestamp>2017-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Procedural Generation of Videos to Train Deep Action Recognition
  Networks</dc:title>
 <dc:creator>de Souza, C&#xe9;sar Roberto</dc:creator>
 <dc:creator>Gaidon, Adrien</dc:creator>
 <dc:creator>Cabon, Yohann</dc:creator>
 <dc:creator>Pe&#xf1;a, Antonio Manuel L&#xf3;pez</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning for human action recognition in videos is making significant
progress, but is slowed down by its dependency on expensive manual labeling of
large video collections. In this work, we investigate the generation of
synthetic training data for action recognition, as it has recently shown
promising results for a variety of other computer vision tasks. We propose an
interpretable parametric generative model of human action videos that relies on
procedural generation and other computer graphics techniques of modern game
engines. We generate a diverse, realistic, and physically plausible dataset of
human action videos, called PHAV for &quot;Procedural Human Action Videos&quot;. It
contains a total of 39,982 videos, with more than 1,000 examples for each
action of 35 categories. Our approach is not limited to existing motion capture
sequences, and we procedurally define 14 synthetic actions. We introduce a deep
multi-task representation learning architecture to mix synthetic and real
videos, even if the action categories differ. Our experiments on the UCF101 and
HMDB51 benchmarks suggest that combining our large set of synthetic videos with
small real-world datasets can boost recognition performance, significantly
outperforming fine-tuning state-of-the-art unsupervised generative models of
videos.
</dc:description>
 <dc:description>Comment: Accepted for publication at CVPR 2017. http://adas.cvc.uab.es/phav/</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00882</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Success Probability of Exploration: a Concrete Analysis of Learning
  Efficiency</dc:title>
 <dc:creator>Zhang, Liangpeng</dc:creator>
 <dc:creator>Tang, Ke</dc:creator>
 <dc:creator>Yao, Xin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Exploration has been a crucial part of reinforcement learning, yet several
important questions concerning exploration efficiency are still not answered
satisfactorily by existing analytical frameworks. These questions include
exploration parameter setting, situation analysis, and hardness of MDPs, all of
which are unavoidable for practitioners. To bridge the gap between the theory
and practice, we propose a new analytical framework called the success
probability of exploration. We show that those important questions of
exploration above can all be answered under our framework, and the answers
provided by our framework meet the needs of practitioners better than the
existing ones. More importantly, we introduce a concrete and practical approach
to evaluating the success probabilities in certain MDPs without the need of
actually running the learning algorithm. We then provide empirical results to
verify our approach, and demonstrate how the success probability of exploration
can be used to analyse and predict the behaviours and possible outcomes of
exploration, which are the keys to the answer of the important questions of
exploration.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00888</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On The Fundamental Energy Tradeoffs of Geographical Load Balancing</dc:title>
 <dc:creator>Kiani, Abbas</dc:creator>
 <dc:creator>Ansari, Nirwan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Geographical load balancing can optimize the utilization of green energy and
the cost of electricity by taking the advantages of green and price diversities
at geographical dispersed data centers. However, higher green energy
utilization or lower electricity cost may actually increase the total energy
consumption, and is not necessarily the best option. The achievable energy
tradeoffs can be captured by taking into consideration of a defined service
efficiency parameter for geo-dispersed data centers.
</dc:description>
 <dc:description>Comment: to appear IEEE Communications Magazine</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00888</dc:identifier>
 <dc:identifier>IEEE Communications Magazine, Volume: 55, Issue: 5, May 2017</dc:identifier>
 <dc:identifier>doi:10.1109/MCOM.2017.1600787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00889</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Frameworks for Offline and Streaming Coreset Constructions</dc:title>
 <dc:creator>Braverman, Vladimir</dc:creator>
 <dc:creator>Feldman, Dan</dc:creator>
 <dc:creator>Lang, Harry</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Let $P$ be a set (called points), $Q$ be a set (called queries) and a
function $ f:P\times Q\to [0,\infty)$ (called cost). For an error parameter
$\epsilon&gt;0$, a set $S\subseteq P$ with a \emph{weight function} $w:P
\rightarrow [0,\infty)$ is an $\epsilon$-coreset if $\sum_{s\in S}w(s) f(s,q)$
approximates $\sum_{p\in P} f(p,q)$ up to a multiplicative factor of
$1\pm\epsilon$ for every given query $q\in Q$.
  We construct coresets for the $k$-means clustering of $n$ input points, both
in an arbitrary metric space and $d$-dimensional Euclidean space. For Euclidean
space, we present the first coreset whose size is simultaneously independent of
both $d$ and $n$. In particular, this is the first coreset of size $o(n)$ for a
stream of $n$ sparse points in a $d \ge n$ dimensional space (e.g. adjacency
matrices of graphs). We also provide the first generalizations of such coresets
for handling outliers. For arbitrary metric spaces, we improve the dependence
on $k$ to $k \log k$ and present a matching lower bound.
  For $M$-estimator clustering (special cases include the well-known $k$-median
and $k$-means clustering), we introduce a new technique for converting an
offline coreset construction to the streaming setting. Our method yields
streaming coreset algorithms requiring the storage of $O(S + k \log n)$ points,
where $S$ is the size of the offline coreset. In comparison, the previous
state-of-the-art was the merge-and-reduce technique that required $O(S
\log^{2a+1} n)$ points, where $a$ is the exponent in the offline construction's
dependence on $\epsilon^{-1}$. For example, combining our offline and streaming
results, we produce a streaming metric $k$-means coreset algorithm using
$O(\epsilon^{-2} k \log k \log n)$ points of storage. The previous
state-of-the-art required $O(\epsilon^{-4} k \log k \log^{6} n)$ points.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00891</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parameter Compression of Recurrent Neural Networks and Degradation of
  Short-term Memory</dc:title>
 <dc:creator>Cox, Jonathan A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The significant computational costs of deploying neural networks in
large-scale or resource constrained environments, such as data centers and
mobile devices, has spurred interest in model compression, which can achieve a
reduction in both arithmetic operations and storage memory. Several techniques
have been proposed for reducing or compressing the parameters for feed-forward
and convolutional neural networks, but less is understood about the effect of
parameter compression on recurrent neural networks (RNN). In particular, the
extent to which the recurrent parameters can be compressed and the impact on
short-term memory performance, is not well understood. In this paper, we study
the effect of complexity reduction, through singular value decomposition rank
reduction, on RNN and minimal gated recurrent unit (MGRU) networks for several
tasks. We show that considerable rank reduction is possible when compressing
recurrent weights, even without fine tuning. Furthermore, we propose a
perturbation model for the effect of general perturbations, such as a
compression, on the recurrent parameters of RNNs. The model is tested against a
noiseless memorization experiment that elucidates the short-term memory
performance. In this way, we demonstrate that the effect of compression of
recurrent parameters is dependent on the degree of temporal coherence present
in the data and task. This work can guide on-the-fly RNN compression for novel
environments or tasks, and provides insight for applying RNN compression in
low-power devices, such as hearing aids.
</dc:description>
 <dc:description>Comment: Accepted to IJCNN 2017. Final camera ready paper</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00895</identifier>
 <datestamp>2017-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Motif Clustering and Overlapping Clustering for Social Network Analysis</dc:title>
 <dc:creator>Li, Pan</dc:creator>
 <dc:creator>Dau, Hoang</dc:creator>
 <dc:creator>Puleo, Gregory</dc:creator>
 <dc:creator>Milenkovic, Olgica</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Motivated by applications in social network community analysis, we introduce
a new clustering paradigm termed motif clustering. Unlike classical clustering,
motif clustering aims to minimize the number of clustering errors associated
with both edges and certain higher order graph structures (motifs) that
represent &quot;atomic units&quot; of social organizations. Our contributions are
two-fold: We first introduce motif correlation clustering, in which the goal is
to agnostically partition the vertices of a weighted complete graph so that
certain predetermined &quot;important&quot; social subgraphs mostly lie within the same
cluster, while &quot;less relevant&quot; social subgraphs are allowed to lie across
clusters. We then proceed to introduce the notion of motif covers, in which the
goal is to cover the vertices of motifs via the smallest number of (near)
cliques in the graph. Motif cover algorithms provide a natural solution for
overlapping clustering and they also play an important role in latent feature
inference of networks. For both motif correlation clustering and its extension
introduced via the covering problem, we provide hardness results, algorithmic
solutions and community detection results for two well-studied social networks.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00901</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Commonly Uncommon: Semantic Sparsity in Situation Recognition</dc:title>
 <dc:creator>Yatskar, Mark</dc:creator>
 <dc:creator>Ordonez, Vicente</dc:creator>
 <dc:creator>Zettlemoyer, Luke</dc:creator>
 <dc:creator>Farhadi, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Semantic sparsity is a common challenge in structured visual classification
problems; when the output space is complex, the vast majority of the possible
predictions are rarely, if ever, seen in the training set. This paper studies
semantic sparsity in situation recognition, the task of producing structured
summaries of what is happening in images, including activities, objects and the
roles objects play within the activity. For this problem, we find empirically
that most object-role combinations are rare, and current state-of-the-art
models significantly underperform in this sparse data regime. We avoid many
such errors by (1) introducing a novel tensor composition function that learns
to share examples across role-noun combinations and (2) semantically augmenting
our training data with automatically gathered examples of rarely observed
outputs using web data. When integrated within a complete CRF-based structured
prediction model, the tensor-based approach outperforms existing state of the
art by a relative improvement of 2.11% and 4.40% on top-5 verb and noun-role
accuracy, respectively. Adding 5 million images with our semantic augmentation
techniques gives further relative improvements of 6.23% and 9.57% on top-5 verb
and noun-role accuracy.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00903</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expander Graph and Communication-Efficient Decentralized Optimization</dc:title>
 <dc:creator>Chow, Yat-Tin</dc:creator>
 <dc:creator>Shi, Wei</dc:creator>
 <dc:creator>Wu, Tianyu</dc:creator>
 <dc:creator>Yin, Wotao</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  In this paper, we discuss how to design the graph topology to reduce the
communication complexity of certain algorithms for decentralized optimization.
Our goal is to minimize the total communication needed to achieve a prescribed
accuracy. We discover that the so-called expander graphs are near-optimal
choices. We propose three approaches to construct expander graphs for different
numbers of nodes and node degrees. Our numerical results show that the
performance of decentralized optimization is significantly better on expander
graphs than other regular graphs.
</dc:description>
 <dc:description>Comment: 2016 IEEE Asilomar Conference on Signals, Systems, and Computers</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00904</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SNIPE for Memory-Limited PCA From Incomplete Data</dc:title>
 <dc:creator>Eftekhari, Armin</dc:creator>
 <dc:creator>Balzano, Laura</dc:creator>
 <dc:creator>Yang, Dehui</dc:creator>
 <dc:creator>Wakin, Michael B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The linear subspace model is pervasive in science and engineering and
particularly in large datasets which are often incomplete due to missing
measurements and privacy issues. Therefore, a critical problem in modeling is
to develop algorithms for estimating a low-dimensional subspace model from
incomplete data efficiently in terms of both computational complexity and
memory storage. In this paper we study an algorithm that processes blocks of
incomplete data to estimate the underlying subspace model. Our algorithm has a
simple interpretation as optimizing the subspace to fit the observed data block
but remain close to the previous estimate. We prove a linear rate of
convergence for the algorithm and our rate holds with high probability.
</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00908</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cutting lemma and Zarankiewicz's problem in distal structures</dc:title>
 <dc:creator>Chernikov, Artem</dc:creator>
 <dc:creator>Galvin, David</dc:creator>
 <dc:creator>Starchenko, Sergei</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>03C45, 03C64, 05C35, 05D40</dc:subject>
 <dc:description>  We establish a cutting lemma for definable families of sets in distal
structures, as well as the optimality of the distal cell decomposition for
definable families of sets on the plane in $o$-minimal expansions of fields.
Using it, we generalize the results in [J. Fox, J. Pach, A. Sheffer, A. Suk,
and J. Zahl. &quot;A semi-algebraic version of Zarankiewicz's problem&quot;, Preprint,
arXiv:1407.5705 (2014)] on the semialgebraic planar Zarankiewicz problem to
arbitrary $o$-minimal structures, in particular obtaining an $o$-minimal
generalization of the Szemer\'edi-Trotter theorem.
</dc:description>
 <dc:description>Comment: 28 pages, 3 figures</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00913</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Joint Learning of Natural Language Understanding and Dialogue
  Manager</dc:title>
 <dc:creator>Yang, Xuesong</dc:creator>
 <dc:creator>Chen, Yun-Nung</dc:creator>
 <dc:creator>Hakkani-Tur, Dilek</dc:creator>
 <dc:creator>Crook, Paul</dc:creator>
 <dc:creator>Li, Xiujun</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Natural language understanding and dialogue policy learning are both
essential in conversational systems that predict the next system actions in
response to a current user utterance. Conventional approaches aggregate
separate models of natural language understanding (NLU) and system action
prediction (SAP) as a pipeline that is sensitive to noisy outputs of
error-prone NLU. To address the issues, we propose an end-to-end deep recurrent
neural network with limited contextual dialogue memory by jointly training NLU
and SAP on DSTC4 multi-domain human-human dialogues. Experiments show that our
proposed model significantly outperforms the state-of-the-art pipeline models
for both NLU and SAP, which indicates that our joint model is capable of
mitigating the affects of noisy NLU outputs, and NLU model can be refined by
error flows backpropagating from the extra supervised signals of system
actions.
</dc:description>
 <dc:description>Comment: Accepted in The 42nd IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP2017)</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00914</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some ternary cubic two-weight codes</dc:title>
 <dc:creator>Shi, Minjia</dc:creator>
 <dc:creator>Huang, Daitao</dc:creator>
 <dc:creator>Sole, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B25</dc:subject>
 <dc:description>  We study trace codes with defining set $L,$ a subgroup of the multiplicative
group of an extension of degree $m$ of the alphabet ring
$\mathbb{F}_3+u\mathbb{F}_3+u^{2}\mathbb{F}_{3},$ with $u^{3}=1.$ These codes
are abelian, and their ternary images are quasi-cyclic of co-index three
(a.k.a. cubic codes). Their Lee weight distributions are computed by using
Gauss sums. These codes have three nonzero weights when $m$ is singly-even and
$|L|=\frac{3^{3m}-3^{2m}}{2}.$ When $m$ is odd, and
$|L|=\frac{3^{3m}-3^{2m}}{2}$, or $|L|={3^{3m}-3^{2m}}$ and $m$ is a positive
integer, we obtain two new infinite families of two-weight codes which are
optimal. Applications of the image codes to secret sharing schemes are also
given.
</dc:description>
 <dc:description>Comment: 11 pages, submitted on 2 December. arXiv admin note: text overlap
  with arXiv:1612.00118</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00915</identifier>
 <datestamp>2017-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Classes of $p$-ary Few Weights Codes</dc:title>
 <dc:creator>Shi, Minjia</dc:creator>
 <dc:creator>Wu, Rongsheng</dc:creator>
 <dc:creator>Qian, Liqin</dc:creator>
 <dc:creator>Sok, Lin</dc:creator>
 <dc:creator>Sole, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B25</dc:subject>
 <dc:description>  In this paper, several classes of three-weight codes and two-weight codes for
the homogeneous metric over the chain ring $R=\mathbb{F}_p+u\mathbb{F}_p+\cdots
+u^{k-1}\mathbb{F}_{p},$ with $u^k=0,$ are constructed, which generalises
\cite{SL}, the special case of $p=k=2.$ These codes are defined as trace codes.
In some cases of their defining sets, they are abelian. Their homogeneous
weight distributions are computed by using exponential sums. In particular, in
the two-weight case, we give some conditions of optimality of their Gray images
by using the Griesmer bound. Their dual homogeneous distance is also given. The
codewords of these codes are shown to be minimal for inclusion of supports, a
fact favorable to an application to secret sharing schemes.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00916</identifier>
 <datestamp>2017-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Matrix Splitting Perspective on Planning with Options</dc:title>
 <dc:creator>Bacon, Pierre-Luc</dc:creator>
 <dc:creator>Precup, Doina</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We show that the Bellman operator underlying the options framework leads to a
matrix splitting, an approach traditionally used to speed up convergence of
iterative solvers for large linear systems of equations. Based on standard
comparison theorems for matrix splittings, we then show how the asymptotic rate
of convergence varies as a function of the inherent timescales of the options.
This new perspective highlights a trade-off between asymptotic performance and
the cost of computation associated with building a good set of options.
</dc:description>
 <dc:description>Comment: The results presented in the previous version of this paper were
  found be applicable only to &quot;gating execution&quot; and not &quot;call-and-return&quot;. We
  made this distinction clear in the text and added an extension to the
  call-and-return model</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00928</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Peer Prediction with Heterogeneous Tasks</dc:title>
 <dc:creator>Mandal, Debmalya</dc:creator>
 <dc:creator>Leifer, Matthew</dc:creator>
 <dc:creator>Parkes, David C.</dc:creator>
 <dc:creator>Pickard, Galen</dc:creator>
 <dc:creator>Shnayder, Victor</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Peer prediction is a method to promote contributions of information by users
in settings in which there is no way to verify the quality of responses. In
multi-task peer prediction, the reports from users across multiple tasks are
used to score contributions. This paper extends the correlated agreement (CA)
multi-task peer prediction mechanism to allow the reports from users to be on
heterogeneous tasks, each associated with different distributions on responses.
The motivation comes from wanting to elicit user-generated content about places
in a city, where tasks vary because places, and questions about places, vary.
We prove that the generalized CA mechanism is informed truthful under weak
conditions, meaning that it is strictly beneficial for a user to invest effort
and acquire information, and that truthful reporting is the best strategy when
investing effort, as well as an equilibrium. We demonstrate that the mechanism
has good incentive properties when tested in simulation on distributions
derived from user reports on Google Local Guides.
</dc:description>
 <dc:description>Comment: 11 pages, 15 figures</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:date>2017-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00933</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis and Design of a Passive Switched-Capacitor Matrix Multiplier
  for Approximate Computing</dc:title>
 <dc:creator>Lee, Edward H.</dc:creator>
 <dc:creator>Wong, S. Simon</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  A switched-capacitor matrix multiplier is presented for approximate computing
and machine learning applications. The multiply-and-accumulate operations
perform discrete-time charge-domain signal processing using passive switches
and 300 aF unit capacitors. The computation is digitized with a 6 b
asynchronous successive approximation register analog-to-digital converter. The
analyses of incomplete charge accumulation and thermal noise are discussed. The
design was fabricated in 40 nm CMOS, and experimental measurements of
multiplication are illustrated using matched filtering and image convolutions
to analyze noise and offset. Two applications are highlighted: 1)
energy-efficient feature extraction layer performing both compression and
classification in a neural network for an analog front end and 2) analog
acceleration for solving optimization problems that are traditionally performed
in the digital domain. The chip obtains measured efficiencies of 8.7 TOPS/W at
1 GHz for the first application and 7.7 TOPS/W at 2.5 GHz for the second
application.
</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00940</identifier>
 <datestamp>2017-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end learning of brain tissue segmentation from imperfect labeling</dc:title>
 <dc:creator>Fedorov, Alex</dc:creator>
 <dc:creator>Johnson, Jeremy</dc:creator>
 <dc:creator>Damaraju, Eswar</dc:creator>
 <dc:creator>Ozerin, Alexei</dc:creator>
 <dc:creator>Calhoun, Vince</dc:creator>
 <dc:creator>Plis, Sergey</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Segmenting a structural magnetic resonance imaging (MRI) scan is an important
pre-processing step for analytic procedures and subsequent inferences about
longitudinal tissue changes. Manual segmentation defines the current gold
standard in quality but is prohibitively expensive. Automatic approaches are
computationally intensive, incredibly slow at scale, and error prone due to
usually involving many potentially faulty intermediate steps. In order to
streamline the segmentation, we introduce a deep learning model that is based
on volumetric dilated convolutions, subsequently reducing both processing time
and errors. Compared to its competitors, the model has a reduced set of
parameters and thus is easier to train and much faster to execute. The contrast
in performance between the dilated network and its competitors becomes obvious
when both are tested on a large dataset of unprocessed human brain volumes. The
dilated network consistently outperforms not only another state-of-the-art deep
learning approach, the up convolutional network, but also the ground truth on
which it was trained. Not only can the incredible speed of our model make large
scale analyses much easier but we also believe it has great potential in a
clinical setting where, with little to no substantial delay, a patient and
provider can go over test results.
</dc:description>
 <dc:description>Comment: Published as a conference paper at IJCNN 2017 Preprint version</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:date>2017-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00944</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Discourse Signals for Robust Instructor Intervention Prediction</dc:title>
 <dc:creator>Chandrasekaran, Muthu Kumar</dc:creator>
 <dc:creator>Epp, Carrie Demmans</dc:creator>
 <dc:creator>Kan, Min-Yen</dc:creator>
 <dc:creator>Litman, Diane</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>K.3.1</dc:subject>
 <dc:description>  We tackle the prediction of instructor intervention in student posts from
discussion forums in Massive Open Online Courses (MOOCs). Our key finding is
that using automatically obtained discourse relations improves the prediction
of when instructors intervene in student discussions, when compared with a
state-of-the-art, feature-rich baseline. Our supervised classifier makes use of
an automatic discourse parser which outputs Penn Discourse Treebank (PDTB) tags
that represent in-post discourse features. We show PDTB relation-based features
increase the robustness of the classifier and complement baseline features in
recalling more diverse instructor intervention patterns. In comprehensive
experiments over 14 MOOC offerings from several disciplines, the PDTB discourse
features improve performance on average. The resultant models are less
dependent on domain-specific vocabulary, allowing them to better generalize to
new courses.
</dc:description>
 <dc:description>Comment: To appear in proceedings of the 31st AAAI Conference on Artificial
  Intelligence, San Francisco, USA</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00947</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disruptive innovations in RoboCup 2D Soccer Simulation League: from
  Cyberoos'98 to Gliders2016</dc:title>
 <dc:creator>Prokopenko, Mikhail</dc:creator>
 <dc:creator>Wang, Peter</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  We review disruptive innovations introduced in the RoboCup 2D Soccer
Simulation League over the twenty years since its inception, and trace the
progress of our champion team (Gliders). We conjecture that the League has been
developing as an ecosystem shaped by diverse approaches taken by participating
teams, increasing in its overall complexity. A common feature is that different
champion teams succeeded in finding a way to decompose the enormous
search-space of possible single- and multi-agent behaviours, by automating the
exploration of the problem space with various techniques which accelerated the
software development efforts. These methods included interactive debugging,
machine learning, automated planning, and opponent modelling. The winning
approach developed by Gliders is centred on human-based evolutionary
computation which optimised several components such as an action-dependent
evaluation function, dynamic tactics with Voronoi diagrams, information
dynamics, and bio-inspired collective behaviour.
</dc:description>
 <dc:description>Comment: 12 pages, RoboCup-2016, Leipzig, Germany, July 2016</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00958</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconfiguring Ordered Bases of a Matroid</dc:title>
 <dc:creator>Lubiw, Anna</dc:creator>
 <dc:creator>Pathak, Vinayak</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05B35</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  For a matroid with an ordered (or &quot;labelled&quot;) basis, a basis exchange step
removes one element with label $l$ and replaces it by a new element that
results in a new basis, and with the new element assigned label $l$. We prove
that one labelled basis can be reconfigured to another if and only if for every
label, the initial and final elements with that label lie in the same connected
component of the matroid. Furthermore, we prove that when the reconfiguration
is possible, the number of basis exchange steps required is $O(r^{1.5})$ for a
rank $r$ matroid. For a graphic matroid we improve the bound to $O(r \log r)$.
</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00959</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RecSys Challenge 2016: job recommendations based on preselection of
  offers and gradient boosting</dc:title>
 <dc:creator>Pacuk, Andrzej</dc:creator>
 <dc:creator>Sankowski, Piotr</dc:creator>
 <dc:creator>W&#x119;grzycki, Karol</dc:creator>
 <dc:creator>Witkowski, Adam</dc:creator>
 <dc:creator>Wygocki, Piotr</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>D.2.8</dc:subject>
 <dc:description>  We present the Mim-Solution's approach to the RecSys Challenge 2016, which
ranked 2nd. The goal of the competition was to prepare job recommendations for
the users of the website Xing.com.
  Our two phase algorithm consists of candidate selection followed by the
candidate ranking. We ranked the candidates by the predicted probability that
the user will positively interact with the job offer. We have used Gradient
Boosting Decision Trees as the regression tool.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, 2 tables, Description of 2nd place winning
  solution of RecSys 2016 Challange. To be published in RecSys'16 Challange
  Proceedings</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00959</dc:identifier>
 <dc:identifier>Proceedings of the Recommender Systems Challenge, RecSys Challenge
  '16, Boston, Massachusetts - September 15 - 15, 2016, pages 10:1--10:4</dc:identifier>
 <dc:identifier>doi:10.1145/2987538.2987544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00960</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-monotone DR-Submodular Function Maximization</dc:title>
 <dc:creator>Soma, Tasuku</dc:creator>
 <dc:creator>Yoshida, Yuichi</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider non-monotone DR-submodular function maximization, where
DR-submodularity (diminishing return submodularity) is an extension of
submodularity for functions over the integer lattice based on the concept of
the diminishing return property. Maximizing non-monotone DR-submodular
functions has many applications in machine learning that cannot be captured by
submodular set functions. In this paper, we present a
$\frac{1}{2+\epsilon}$-approximation algorithm with a running time of roughly
$O(\frac{n}{\epsilon}\log^2 B)$, where $n$ is the size of the ground set, $B$
is the maximum value of a coordinate, and $\epsilon &gt; 0$ is a parameter. The
approximation ratio is almost tight and the dependency of running time on $B$
is exponentially smaller than the naive greedy algorithm. Experiments on
synthetic and real-world datasets demonstrate that our algorithm outputs almost
the best solution compared to other baseline algorithms, whereas its running
time is several orders of magnitude faster.
</dc:description>
 <dc:description>Comment: This paper is to appear in AAAI 2017</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00962</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Positive blood culture detection in time series data using a BiLSTM
  network</dc:title>
 <dc:creator>De Baets, Leen</dc:creator>
 <dc:creator>Ruyssinck, Joeri</dc:creator>
 <dc:creator>Peiffer, Thomas</dc:creator>
 <dc:creator>Decruyenaere, Johan</dc:creator>
 <dc:creator>De Turck, Filip</dc:creator>
 <dc:creator>Ongenae, Femke</dc:creator>
 <dc:creator>Dhaene, Tom</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The presence of bacteria or fungi in the bloodstream of patients is abnormal
and can lead to life-threatening conditions. A computational model based on a
bidirectional long short-term memory artificial neural network, is explored to
assist doctors in the intensive care unit to predict whether examination of
blood cultures of patients will return positive. As input it uses nine
monitored clinical parameters, presented as time series data, collected from
2177 ICU admissions at the Ghent University Hospital. Our main goal is to
determine if general machine learning methods and more specific, temporal
models, can be used to create an early detection system. This preliminary
research obtains an area of 71.95% under the precision recall curve, proving
the potential of temporal neural networks in this context.
</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00962</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00966</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Classes of $p$-ary Few Weights Codes</dc:title>
 <dc:creator>Shi, Minjia</dc:creator>
 <dc:creator>Wu, Rongsheng</dc:creator>
 <dc:creator>Qian, Liqin</dc:creator>
 <dc:creator>Sok, Lin</dc:creator>
 <dc:creator>Sol&#xe9;, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B25</dc:subject>
 <dc:description>  In this paper, several classes of three-weight codes and two-weight codes for
the homogeneous metric over the chain ring $R=\mathbb{F}_p+u\mathbb{F}_p+\cdots
+u^{k-1}\mathbb{F}_{p},$ with $u^k=0,$ are constructed, which generalises
\cite{SL}, the special case of $p=k=2.$ These codes are defined as trace codes.
In some cases of their defining sets, they are abelian. Their homogeneous
weight distributions are computed by using exponential sums. In particular, in
the two-weight case, we give some conditions of optimality of their Gray images
by using the Griesmer bound. Their dual homogeneous distance is also given. The
codewords of these codes are shown to be minimal for inclusion of supports, a
fact favorable to an application to secret sharing schemes.
</dc:description>
 <dc:description>Comment: This manuscript in contained in arXiv:1612.00915, thus the authors
  expect to withdraw it</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:date>2017-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00967</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two new families of two-weight codes</dc:title>
 <dc:creator>Shi, Minjia</dc:creator>
 <dc:creator>Guan, Yue</dc:creator>
 <dc:creator>Sole, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B25</dc:subject>
 <dc:description>  We construct two new infinite families of trace codes of dimension $2m$, over
the ring $\mathbb{F}_p+u\mathbb{F}_p,$ when $p$ is an odd prime. They have the
algebraic structure of abelian codes. Their Lee weight distribution is computed
by using Gauss sums. By Gray mapping, we obtain two infinite families of linear
$p$-ary codes of respective lengths $(p^m-1)^2$ and $2(p^m-1)^2.$ When $m$ is
singly-even, the first family gives five-weight codes. When $m$ is odd, and
$p\equiv 3 \pmod{4},$ the first family yields $p$-ary two-weight codes, which
are shown to be optimal by application of the Griesmer bound. The second family
consists of two-weight codes that are shown to be optimal, by the Griesmer
bound, whenever $p=3$ and $m \ge 3,$ or $p\ge 5$ and $m\ge 4.$ Applications to
secret sharing schemes are given.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:date>2017-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00967</dc:identifier>
 <dc:identifier>IEEE Transactions on Information Theory, Volume: 63, Issue: 10,
  pp. 6240-6246, Oct. 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2017.2742499</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00969</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unit Dependency Graph and its Application to Arithmetic Word Problem
  Solving</dc:title>
 <dc:creator>Roy, Subhro</dc:creator>
 <dc:creator>Roth, Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Math word problems provide a natural abstraction to a range of natural
language understanding problems that involve reasoning about quantities, such
as interpreting election results, news about casualties, and the financial
section of a newspaper. Units associated with the quantities often provide
information that is essential to support this reasoning. This paper proposes a
principled way to capture and reason about units and shows how it can benefit
an arithmetic word problem solver. This paper presents the concept of Unit
Dependency Graphs (UDGs), which provides a compact representation of the
dependencies between units of numbers mentioned in a given problem. Inducing
the UDG alleviates the brittleness of the unit extraction system and allows for
a natural way to leverage domain knowledge about unit compatibility, for word
problem solving. We introduce a decomposed model for inducing UDGs with minimal
additional annotations, and use it to augment the expressions used in the
arithmetic word problem solver of (Roy and Roth 2015) via a constrained
inference framework. We show that introduction of UDGs reduces the error of the
solver by over 10 %, surpassing all existing systems for solving arithmetic
word problems. In addition, it also makes the system more robust to adaptation
to new vocabulary and equation forms .
</dc:description>
 <dc:description>Comment: AAAI 2017</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00979</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised learning of deep metrics for stereo reconstruction</dc:title>
 <dc:creator>Tulyakov, Stepan</dc:creator>
 <dc:creator>Ivanov, Anton</dc:creator>
 <dc:creator>Fleuret, Francois</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep-learning metrics have recently demonstrated extremely good performance
to match image patches for stereo reconstruction. However, training such
metrics requires large amount of labeled stereo images, which can be difficult
or costly to collect for certain applications. The main contribution of our
work is a new semi-supervised method for learning deep metrics from unlabeled
stereo images, given coarse information about the scenes and the optical
system. Our method alternatively optimizes the metric with a standard
stochastic gradient descent, and applies stereo constraints to regularize its
prediction. Experiments on reference data-sets show that, for a given network
architecture, training with this new method without ground-truth produces a
metric with performance as good as state-of-the-art baselines trained with the
said ground-truth. This work has three practical implications. Firstly, it
helps to overcome limitations of training sets, in particular noisy ground
truth. Secondly it allows to use much more training data during learning.
Thirdly, it allows to tune deep metric for a particular stereo system, even if
ground truth is not available.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00983</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Food Image Recognition by Using Convolutional Neural Networks (CNNs)</dc:title>
 <dc:creator>Lu, Yuzhen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Food image recognition is one of the promising applications of visual object
recognition in computer vision. In this study, a small-scale dataset consisting
of 5822 images of ten categories and a five-layer CNN was constructed to
recognize these images. The bag-of-features (BoF) model coupled with support
vector machine was first tested as comparison, resulting in an overall accuracy
of 56%, while the CNN performed much better with an overall accuracy of 74%.
Data expansion techniques were applied to increase the size of training images,
which achieved a significantly improved accuracy of more than 90% and prevent
the overfitting issue that occurred to the CNN without using data expansion.
Further improvement is within reach by collecting more images and optimizing
the network architecture and relevant hyper-parameters.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, 3 tables</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00984</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating latent feature-feature interactions in large feature-rich
  graphs</dc:title>
 <dc:creator>Monti, Corrado</dc:creator>
 <dc:creator>Boldi, Paolo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Real-world complex networks describe connections between objects; in reality,
those objects are often endowed with some kind of features. How does the
presence or absence of such features interplay with the network link structure?
Although the situation here described is truly ubiquitous, there is a limited
body of research dealing with large graphs of this kind. Many previous works
considered homophily as the only possible transmission mechanism translating
node features into links. Other authors, instead, developed more sophisticated
models, that are able to handle complex feature interactions, but are unfit to
scale to very large networks. We expand on the MGJ model, where interactions
between pairs of features can foster or discourage link formation. In this
work, we will investigate how to estimate the latent feature-feature
interactions in this model. We shall propose two solutions: the first one
assumes feature independence and it is essentially based on Naive Bayes; the
second one, which relaxes the independence assumption assumption, is based on
perceptrons. In fact, we show it is possible to cast the model equation in
order to see it as the prediction rule of a perceptron. We analyze how
classical results for the perceptrons can be interpreted in this context; then,
we define a fast and simple perceptron-like algorithm for this task, which can
process $10^8$ links in minutes. We then compare these two techniques, first
with synthetic datasets that follows our model, gaining evidence that the Naive
independence assumptions are detrimental in practice. Secondly, we consider a
real, large-scale citation network where each node (i.e., paper) can be
described by different types of characteristics; there, our algorithm can
assess how well each set of features can explain the links, and thus finding
meaningful latent feature-feature interactions.
</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:date>2017-10-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00984</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00985</identifier>
 <datestamp>2016-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wikiwhere: An interactive tool for studying the geographical provenance
  of Wikipedia references</dc:title>
 <dc:creator>K&#xf6;rner, Martin</dc:creator>
 <dc:creator>Sennikova, Tatiana</dc:creator>
 <dc:creator>Windh&#xe4;user, Florian</dc:creator>
 <dc:creator>Wagner, Claudia</dc:creator>
 <dc:creator>Fl&#xf6;ck, Fabian</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Wikipedia articles about the same topic in different language editions are
built around different sources of information. For example, one can find very
different news articles linked as references in the English Wikipedia article
titled &quot;Annexation of Crimea by the Russian Federation&quot; than in its German
counterpart (determined via Wikipedia's language links). Some of this
difference can of course be attributed to the different language proficiencies
of readers and editors in separate language editions, yet, although including
English-language news sources seems to be no issue in the German edition,
English references that are listed do not overlap highly with the ones in the
article's English version. Such patterns could be an indicator of bias towards
certain national contexts when referencing facts and statements in Wikipedia.
However, determining for each reference which national context it can be traced
back to, and comparing the link distributions to each other is infeasible for
casual readers or scientists with non-technical backgrounds. Wikiwhere answers
the question where Web references stem from by analyzing and visualizing the
geographic location of external reference links that are included in a given
Wikipedia article. Instead of relying solely on the IP location of a given URL
our machine learning models consider several features.
</dc:description>
 <dc:description>Comment: 4 pages, 2 tables, 1 figure</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:date>2016-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00986</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning with Energy-efficient Binary Gradient Cameras</dc:title>
 <dc:creator>Jayasuriya, Suren</dc:creator>
 <dc:creator>Gallo, Orazio</dc:creator>
 <dc:creator>Gu, Jinwei</dc:creator>
 <dc:creator>Kautz, Jan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Power consumption is a critical factor for the deployment of embedded
computer vision systems. We explore the use of computational cameras that
directly output binary gradient images to reduce the portion of the power
consumption allocated to image sensing. We survey the accuracy of binary
gradient cameras on a number of computer vision tasks using deep learning.
These include object recognition, head pose regression, face detection, and
gesture recognition. We show that, for certain applications, accuracy can be on
par or even better than what can be achieved on traditional images. We are also
the first to recover intensity information from binary spatial gradient
images--useful for applications with a human observer in the loop, such as
surveillance. Our results, which we validate with a prototype binary gradient
camera, point to the potential of gradient-based computer vision systems.
</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00989</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Page Migration on Ring Networks in Uniform Model</dc:title>
 <dc:creator>Khorramian, Amanj</dc:creator>
 <dc:creator>Matsubayashi, Akira</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>68W27</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2</dc:subject>
 <dc:description>  This paper explores the problem of page migration in ring networks. A ring
network is a connected graph, in which each node is connected with exactly two
other nodes. In this problem, one of the nodes in a given network holds a page
of size D. This node is called the server and the page is a non-duplicable data
in the network. Requests are issued by nodes to access the page one after
another. Every time a new request is issued, the server must serve the request
and may migrate to another node before the next request arrives. A service
costs the distance between the server and the requesting node, and the
migration costs the distance of the migration multiplied by D. The problem is
to minimize the total costs of services and migrations. We study this problem
in uniform model, for which the page has a unit size, i.e. D=1. A
3.326-competitive algorithm improving the current best upper bound is designed.
We show that this ratio is tight for our algorithm.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00991</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensembles of Generative Adversarial Networks</dc:title>
 <dc:creator>Wang, Yaxing</dc:creator>
 <dc:creator>Zhang, Lichao</dc:creator>
 <dc:creator>van de Weijer, Joost</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Ensembles are a popular way to improve results of discriminative CNNs. The
combination of several networks trained starting from different initializations
improves results significantly. In this paper we investigate the usage of
ensembles of GANs. The specific nature of GANs opens up several new ways to
construct ensembles. The first one is based on the fact that in the minimax
game which is played to optimize the GAN objective the generator network keeps
on changing even after the network can be considered optimal. As such ensembles
of GANs can be constructed based on the same network initialization but just
taking models which have different amount of iterations. These so-called self
ensembles are much faster to train than traditional ensembles. The second
method, called cascade GANs, redirects part of the training data which is badly
modeled by the first GAN to another GAN. In experiments on the CIFAR10 dataset
we show that ensembles of GANs obtain model probability distributions which
better model the data distribution. In addition, we show that these improved
results can be obtained at little additional computational cost.
</dc:description>
 <dc:description>Comment: accepted NIPS 2016 Workshop on Adversarial Training</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00992</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining Spatio-temporal Data on Industrialization from Historical
  Registries</dc:title>
 <dc:creator>Berenbaum, David</dc:creator>
 <dc:creator>Deighan, Dwyer</dc:creator>
 <dc:creator>Marlow, Thomas</dc:creator>
 <dc:creator>Lee, Ashley</dc:creator>
 <dc:creator>Frickel, Scott</dc:creator>
 <dc:creator>Howison, Mark</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Despite the growing availability of big data in many fields, historical data
on socioevironmental phenomena are often not available due to a lack of
automated and scalable approaches for collecting, digitizing, and assembling
them. We have developed a data-mining method for extracting tabulated, geocoded
data from printed directories. While scanning and optical character recognition
(OCR) can digitize printed text, these methods alone do not capture the
structure of the underlying data. Our pipeline integrates both page layout
analysis and OCR to extract tabular, geocoded data from structured text. We
demonstrate the utility of this method by applying it to scanned manufacturing
registries from Rhode Island that record 41 years of industrial land use. The
resulting spatio-temporal data can be used for socioenvironmental analyses of
industrialization at a resolution that was not previously possible. In
particular, we find strong evidence for the dispersion of manufacturing from
the urban core of Providence, the state's capital, along the Interstate 95
corridor to the north and south.
</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00993</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Protocol for a Secure Remote Keyless Entry System Applicable in
  Vehicles using Symmetric-Key Cryptography</dc:title>
 <dc:creator>Glocker, Tobias</dc:creator>
 <dc:creator>Mantere, Timo</dc:creator>
 <dc:creator>Elmusrati, Mohammed</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In our modern society comfort became a standard. This comfort, especially in
cars can only be achieved by equipping the car with more electronic devices.
Some of the electronic devices must cooperate with each other and thus they
require a communication channel, which can be wired or wireless. In these days,
it would be hard to sell a new car operating with traditional keys. Almost all
modern cars can be locked or unlocked with a Remote Keyless System. A Remote
Keyless System consists of a key fob that communicates wirelessly with the car
transceiver that is responsible for locking and unlocking the car. However
there are several threats for wireless communication channels.
  This paper describes the possible attacks against a Remote Keyless System and
introduces a secure protocol as well as a lightweight Symmetric Encryption
Algorithm for a Remote Keyless Entry System applicable in vehicles.
</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.00997</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving congestion control for Concurrent Multipath Transfer through
  bandwidth estimation based resource pooling</dc:title>
 <dc:creator>Shailendra, Samar</dc:creator>
 <dc:creator>Bhattacharjee, R.</dc:creator>
 <dc:creator>Bose, Sanjay K.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Stream Control Transmission Protocol (SCTP) was introduced in 2001 as a
multipath variant to traditional transport protocols, i.e. Transmission Control
Protocol (TCP) and User Datagram Protocol (UDP). Concurrent Multipath Transfer
(CMT) has been proposed as an extension for SCTP to support concurrent usage of
available multiple paths. In this paper, we propose a new congestion control
algorithm for CMT-SCTP based on the principle of resource pooling. We use the
connection bandwidth estimates to obtain the collection of the network
resources being used by different flows on multiple paths. Based on these
bandwidth estimates, we have used the bandwidth estimation based resource
pooling approach to adjust the congestion window of the respective paths. We
compare our proposed scheme with CMT-SCTP through ns-2 based simulations.
</dc:description>
 <dc:description>Comment: 8th International Conference on Information, Communications and
  Signal Processing, ICICS 2012</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.00997</dc:identifier>
 <dc:identifier>doi:10.1109/ICICS.2011.6174285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01005</identifier>
 <datestamp>2017-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixed powerdomains for probability and nondeterminism</dc:title>
 <dc:creator>Keimel, Klaus</dc:creator>
 <dc:creator>Plotkin, Gordon D.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We consider mixed powerdomains combining ordinary nondeterminism and
probabilistic nondeterminism. We characterise them as free algebras for
suitable (in)equation-al theories; we establish functional representation
theorems; and we show equivalencies between state transformers and
appropriately healthy predicate transformers. The extended nonnegative reals
serve as `truth-values'. As usual with powerdomains, everything comes in three
flavours: lower, upper, and order-convex. The powerdomains are suitable convex
sets of subprobability valuations, corresponding to resolving nondeterministic
choice before probabilistic choice. Algebraically this corresponds to the
probabilistic choice operator distributing over the nondeterministic choice
operator. (An alternative approach to combining the two forms of nondeterminism
would be to resolve probabilistic choice first, arriving at a domain-theoretic
version of random sets. However, as we also show, the algebraic approach then
runs into difficulties.)
  Rather than working directly with valuations, we take a domain-theoretic
functional-analytic approach, employing domain-theoretic abstract convex sets
called Kegelspitzen; these are equivalent to the abstract probabilistic
algebras of Graham and Jones, but are more convenient to work with. So we
define power Kegelspitzen, and consider free algebras, functional
representations, and predicate transformers. To do so we make use of previous
work on domain-theoretic cones (d-cones), with the bridge between the two of
them being provided by a free d-cone construction on Kegelspitzen.
</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:date>2017-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01005</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 1 (January
  24, 2017) lmcs:2665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01006</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Non-Local Means Approach for Gaussian Noise Removal from Images using
  a Modified Weighting Kernel</dc:title>
 <dc:creator>Kazemi, Mojtaba</dc:creator>
 <dc:creator>P, Ehsan Mohammadi.</dc:creator>
 <dc:creator>sadeghi, Parichehr shahidi</dc:creator>
 <dc:creator>Menhaj, Mohamad B.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Gaussian noise removal is an interesting area in digital image processing not
only to improve the visual quality, but for its impact on other post-processing
algorithms like image registration or segmentation. Many presented
state-of-the-art denoising methods are based on the self-similarity or
patch-based image processing. Specifically, Non-Local Means (NLM) as a
patch-based filter has gained increasing attention in recent years.
Essentially, this filter tends to obtain the noise-less signal value by
computing the Gaussian-weighted Euclidean distance between the patch
under-processing and other patches inside the image. However, the NLM filter is
sensitive to the outliers (pixels that their intensity values are far away from
other pixels) inside the patch, meaning that the pixels with the symmetric
locations in the patch are assigned the same weight. This can lead to
sub-optimal denoising performance when the destructive nature of noise
generates some outliers inside patches. In this paper, we propose a new
weighting approach to modify the Gaussian kernel of the NLM filter. Our
approach employs the geometric distance between image intensities to come up
with new weights for each pixel of a patch, lowering the impact of outliers on
the denoising performance. Experiments on a set of standard images and
different noise levels show that our proposed method outperforms the other
compared denoising filters.
</dc:description>
 <dc:description>Comment: 2017 25th Iranian Conference on Electrical Engineering (ICEE)</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01010</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepBach: a Steerable Model for Bach Chorales Generation</dc:title>
 <dc:creator>Hadjeres, Ga&#xeb;tan</dc:creator>
 <dc:creator>Pachet, Fran&#xe7;ois</dc:creator>
 <dc:creator>Nielsen, Frank</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This paper introduces DeepBach, a graphical model aimed at modeling
polyphonic music and specifically hymn-like pieces. We claim that, after being
trained on the chorale harmonizations by Johann Sebastian Bach, our model is
capable of generating highly convincing chorales in the style of Bach.
DeepBach's strength comes from the use of pseudo-Gibbs sampling coupled with an
adapted representation of musical data. This is in contrast with many automatic
music composition approaches which tend to compose music sequentially. Our
model is also steerable in the sense that a user can constrain the generation
by imposing positional constraints such as notes, rhythms or cadences in the
generated score. We also provide a plugin on top of the MuseScore music editor
making the interaction with DeepBach easy to use.
</dc:description>
 <dc:description>Comment: 10 pages, ICML2017 version</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:date>2017-06-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01010</dc:identifier>
 <dc:identifier>Proceedings of the 34th International Conference on Machine
  Learning, PMLR 70:1362-1371, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01020</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hypothesis Transfer Learning via Transformation Functions</dc:title>
 <dc:creator>Du, Simon Shaolei</dc:creator>
 <dc:creator>Koushik, Jayanth</dc:creator>
 <dc:creator>Singh, Aarti</dc:creator>
 <dc:creator>Poczos, Barnabas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the Hypothesis Transfer Learning (HTL) problem where one
incorporates a hypothesis trained on the source domain into the learning
procedure of the target domain. Existing theoretical analysis either only
studies specific algorithms or only presents upper bounds on the generalization
error but not on the excess risk. In this paper, we propose a unified
algorithm-dependent framework for HTL through a novel notion of transformation
function, which characterizes the relation between the source and the target
domains. We conduct a general risk analysis of this framework and in
particular, we show for the first time, if two domains are related, HTL enjoys
faster convergence rates of excess risks for Kernel Smoothing and Kernel Ridge
Regression than those of the classical non-transfer learning settings.
Experiments on real world data demonstrate the effectiveness of our framework.
</dc:description>
 <dc:description>Comment: Accepted by NIPS 2017</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01022</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Short-term traffic flow forecasting with spatial-temporal correlation in
  a hybrid deep learning framework</dc:title>
 <dc:creator>Wu, Yuankai</dc:creator>
 <dc:creator>Tan, Huachun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning approaches have reached a celebrity status in artificial
intelligence field, its success have mostly relied on Convolutional Networks
(CNN) and Recurrent Networks. By exploiting fundamental spatial properties of
images and videos, the CNN always achieves dominant performance on visual
tasks. And the Recurrent Networks (RNN) especially long short-term memory
methods (LSTM) can successfully characterize the temporal correlation, thus
exhibits superior capability for time series tasks. Traffic flow data have
plentiful characteristics on both time and space domain. However, applications
of CNN and LSTM approaches on traffic flow are limited. In this paper, we
propose a novel deep architecture combined CNN and LSTM to forecast future
traffic flow (CLTFP). An 1-dimension CNN is exploited to capture spatial
features of traffic flow, and two LSTMs are utilized to mine the short-term
variability and periodicities of traffic flow. Given those meaningful features,
the feature-level fusion is performed to achieve short-term forecasting. The
proposed CLTFP is compared with other popular forecasting methods on an open
datasets. Experimental results indicate that the CLTFP has considerable
advantages in traffic flow forecasting. in additional, the proposed CLTFP is
analyzed from the view of Granger Causality, and several interesting properties
of CLTFP are discovered and discussed .
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01030</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large scale modeling of antimicrobial resistance with interpretable
  classifiers</dc:title>
 <dc:creator>Drouin, Alexandre</dc:creator>
 <dc:creator>Raymond, Fr&#xe9;d&#xe9;ric</dc:creator>
 <dc:creator>St-Pierre, Ga&#xeb;l Letarte</dc:creator>
 <dc:creator>Marchand, Mario</dc:creator>
 <dc:creator>Corbeil, Jacques</dc:creator>
 <dc:creator>Laviolette, Fran&#xe7;ois</dc:creator>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Antimicrobial resistance is an important public health concern that has
implications in the practice of medicine worldwide. Accurately predicting
resistance phenotypes from genome sequences shows great promise in promoting
better use of antimicrobial agents, by determining which antibiotics are likely
to be effective in specific clinical cases. In healthcare, this would allow for
the design of treatment plans tailored for specific individuals, likely
resulting in better clinical outcomes for patients with bacterial infections.
In this work, we present the recent work of Drouin et al. (2016) on using Set
Covering Machines to learn highly interpretable models of antibiotic resistance
and complement it by providing a large scale application of their method to the
entire PATRIC database. We report prediction results for 36 new datasets and
present the Kover AMR platform, a new web-based tool allowing the visualization
and interpretation of the generated models.
</dc:description>
 <dc:description>Comment: Peer-reviewed and accepted for presentation at the Machine Learning
  for Health Workshop, NIPS 2016, Barcelona, Spain</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01033</identifier>
 <datestamp>2017-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Areas of Attention for Image Captioning</dc:title>
 <dc:creator>Pedersoli, Marco</dc:creator>
 <dc:creator>Lucas, Thomas</dc:creator>
 <dc:creator>Schmid, Cordelia</dc:creator>
 <dc:creator>Verbeek, Jakob</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose &quot;Areas of Attention&quot;, a novel attention-based model for automatic
image captioning. Our approach models the dependencies between image regions,
caption words, and the state of an RNN language model, using three pairwise
interactions. In contrast to previous attention-based approaches that associate
image regions only to the RNN state, our method allows a direct association
between caption words and image regions. During training these associations are
inferred from image-level captions, akin to weakly-supervised object detector
training. These associations help to improve captioning by localizing the
corresponding regions during testing. We also propose and compare different
ways of generating attention areas: CNN activation grids, object proposals, and
spatial transformers nets applied in a convolutional fashion. Spatial
transformers give the best results. They allow for image specific attention
areas, and can be trained jointly with the rest of the network. Our attention
mechanism and spatial transformer attention areas together yield
state-of-the-art results on the MSCOCO dataset.o meaningful latent semantic
structure in the generated captions.
</dc:description>
 <dc:description>Comment: Accepted in ICCV 2017</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:date>2017-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01034</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localization of networked robot systems subject to random delay and
  packet loss</dc:title>
 <dc:creator>Phung, Manh Duong</dc:creator>
 <dc:creator>Van Nguyen, Thi Thanh</dc:creator>
 <dc:creator>Tran, Thuan Hoang</dc:creator>
 <dc:creator>Tran, Quang Vinh</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper deals with the localization problem of mobile robot subject to
communication delay and packet loss. The delay and loss may appear in a random
fashion in both control inputs and observation measurements. A unified
state-space representation is constructed to describe these mixed
uncertainties. Based on it, the optimal linear estimator is developed. The main
idea is the derivation of a relevance factor to incorporate delayed
measurements to the being estimate. The estimator is then extended for
nonlinear systems. The performance of this method is tested within the
simulations in MATLAB and the experiments in a real robot system. The good
localization results prove the efficiency of the method for the purpose of
localization of networked mobile robot.
</dc:description>
 <dc:description>Comment: In 2013 IEEE/ASME International Conference on Advanced Intelligent
  Mechatronics (AIM</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01034</dc:identifier>
 <dc:identifier>doi:10.1109/AIM.2013.6584297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01035</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-Automated Annotation of Discrete States in Large Video Datasets</dc:title>
 <dc:creator>Fridman, Lex</dc:creator>
 <dc:creator>Reimer, Bryan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a framework for semi-automated annotation of video frames where
the video is of an object that at any point in time can be labeled as being in
one of a finite number of discrete states. A Hidden Markov Model (HMM) is used
to model (1) the behavior of the underlying object and (2) the noisy
observation of its state through an image processing algorithm. The key insight
of this approach is that the annotation of frame-by-frame video can be reduced
from a problem of labeling every single image to a problem of detecting a
transition between states of the underlying objected being recording on video.
The performance of the framework is evaluated on a driver gaze classification
dataset composed of 16,000,000 images that were fully annotated over 6,000
hours of direct manual annotation labor. On this dataset, we achieve a 13x
reduction in manual annotation for an average accuracy of 99.1% and a 84x
reduction for an average accuracy of 91.2%.
</dc:description>
 <dc:description>Comment: To be presented at AAAI 2017. arXiv admin note: text overlap with
  arXiv:1508.04028</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01038</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation Algorithms for the Maximum Profit Pick-up Problem with
  Time Windows and Capacity Constraint</dc:title>
 <dc:creator>Armaselu, Bogdan</dc:creator>
 <dc:creator>Daescu, Ovidiu</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we study the Maximum Profit Pick-up Problem with Time Windows
and Capacity Constraint (MP-PPTWC). Our main results are 3 polynomial time
algorithms, all having constant approximation factors. The first algorithm has
an approximation ratio of $~46 (1 + (71/60 + \frac{\alpha}{\sqrt{10+p}})
\epsilon) \log T$, where: (i) $\epsilon &gt; 0$ and $T$ are constants; (ii) The
maximum quantity supplied is $q_{max} = O(n^p) q_{min}$, for some $p &gt; 0$,
where $q_{min}$ is the minimum quantity supplied; (iii) $\alpha &gt; 0$ is a
constant such that the optimal number of vehicles is always at least $\sqrt{10
+ p} / \alpha$. The second algorithm has an approximation ratio of $\simeq 46
(1 + \epsilon + \frac{(2 + \alpha) \epsilon}{\sqrt{10 + p}}) \log T$. Finally,
the third algorithm has an approximation ratio of $\simeq 11 (1 + 2 \epsilon)
\log T$. While our algorithms may seem to have quite high approximation ratios,
in practice they work well and, in the majority of cases, the profit obtained
is at least 1/2 of the optimum.
</dc:description>
 <dc:description>Comment: 15 pages, 5 figures</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01039</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CER: Complementary Entity Recognition via Knowledge Expansion on Large
  Unlabeled Product Reviews</dc:title>
 <dc:creator>Xu, Hu</dc:creator>
 <dc:creator>Xie, Sihong</dc:creator>
 <dc:creator>Shu, Lei</dc:creator>
 <dc:creator>Yu, Philip S.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Product reviews contain a lot of useful information about product features
and customer opinions. One important product feature is the complementary
entity (products) that may potentially work together with the reviewed product.
Knowing complementary entities of the reviewed product is very important
because customers want to buy compatible products and avoid incompatible ones.
In this paper, we address the problem of Complementary Entity Recognition
(CER). Since no existing method can solve this problem, we first propose a
novel unsupervised method to utilize syntactic dependency paths to recognize
complementary entities. Then we expand category-level domain knowledge about
complementary entities using only a few general seed verbs on a large amount of
unlabeled reviews. The domain knowledge helps the unsupervised method to adapt
to different products and greatly improves the precision of the CER task. The
advantage of the proposed method is that it does not require any labeled data
for training. We conducted experiments on 7 popular products with about 1200
reviews in total to demonstrate that the proposed approach is effective.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures, IEEE BigData 2016</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01040</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controlling False Discoveries During Interactive Data Exploration</dc:title>
 <dc:creator>Zhao, Zheguang</dc:creator>
 <dc:creator>De Stefani, Lorenzo</dc:creator>
 <dc:creator>Zgraggen, Emanuel</dc:creator>
 <dc:creator>Binnig, Carsten</dc:creator>
 <dc:creator>Upfal, Eli</dc:creator>
 <dc:creator>Kraska, Tim</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Recent tools for interactive data exploration significantly increase the
chance that users make false discoveries. The crux is that these tools
implicitly allow the user to test a large body of different hypotheses with
just a few clicks thus incurring in the issue commonly known in statistics as
the multiple hypothesis testing error. In this paper, we propose solutions to
integrate multiple hypothesis testing control into interactive data exploration
tools. A key insight is that existing methods for controlling the false
discovery rate (such as FDR) are not directly applicable for interactive data
exploration. We therefore discuss a set of new control procedures that are
better suited and integrated them in our system called Aware. By means of
extensive experiments using both real-world and synthetic data sets we
demonstrate how Aware can help experts and novice users alike to efficiently
control false discoveries.
</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01041</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Optimality of Correlated Sampling</dc:title>
 <dc:creator>Bavarian, Mohammad</dc:creator>
 <dc:creator>Ghazi, Badih</dc:creator>
 <dc:creator>Haramaty, Elad</dc:creator>
 <dc:creator>Kamath, Pritish</dc:creator>
 <dc:creator>Rivest, Ronald L.</dc:creator>
 <dc:creator>Sudan, Madhu</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the &quot;correlated sampling&quot; problem, two players, say Alice and Bob, are
given two distributions, say $P$ and $Q$ respectively, over the same universe
and access to shared randomness. The two players are required to output two
elements, without any interaction, sampled according to their respective
distributions, while trying to minimize the probability that their outputs
disagree. A well-known protocol due to Holenstein, with close variants (for
similar problems) due to Broder, and to Kleinberg and Tardos, solves this task
with disagreement probability at most $2 \delta/(1+\delta)$, where $\delta$ is
the total variation distance between $P$ and $Q$. This protocol has been used
in several different contexts including sketching algorithms, approximation
algorithms based on rounding linear programming relaxations, the study of
parallel repetition and cryptography.
  In this note, we give a surprisingly simple proof that this protocol is in
fact tight. Specifically, for every $\delta \in (0,1)$, we show that any
correlated sampling scheme should have disagreement probability at least
$2\delta/(1+\delta)$. This partially answers a recent question of Rivest.
  Our proof is based on studying a new problem we call &quot;constrained agreement&quot;.
Here, Alice is given a subset $A \subseteq [n]$ and is required to output an
element $i \in A$, Bob is given a subset $B \subseteq [n]$ and is required to
output an element $j \in B$, and the goal is to minimize the probability that
$i \neq j$. We prove tight bounds on this question, which turn out to imply
tight bounds for correlated sampling. Though we settle basic questions about
the two problems, our formulation also leads to several questions that remain
open.
</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01044</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Magnetometer Calibration and Alignment to Inertial Sensors by
  Kalman Filtering</dc:title>
 <dc:creator>Wu, Yuanxin</dc:creator>
 <dc:creator>Zou, Danping</dc:creator>
 <dc:creator>Liu, Peilin</dc:creator>
 <dc:creator>Yu, Wenxian</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Magnetometer and inertial sensors are widely used for orientation estimation.
Magnetometer usage is often troublesome, as it is prone to be interfered by
onboard or ambient magnetic disturbance. The onboard soft-iron material
distorts not only the magnetic field, but the magnetometer sensor frame
coordinate and the cross-sensor misalignment relative to inertial sensors. It
is desirable to conveniently put magnetic and inertial sensors information in a
common frame. Existing methods either split the problem into successive
intrinsic and cross-sensor calibrations, or rely on stationary accelerometer
measurements which is infeasible in dynamic conditions. This paper formulates
the magnetometer calibration and alignment to inertial sensors as a state
estimation problem, and collectively solves the magnetometer intrinsic and
cross-sensor calibrations, as well as the gyroscope bias estimation. Sufficient
conditions are derived for the problem to be globally observable, even when no
accelerometer information is used at all. An extended Kalman filter is designed
to implement the state estimation and comprehensive test data results show the
superior performance of the proposed approach. It is immune to acceleration
disturbance and applicable potentially in any dynamic conditions.
</dc:description>
 <dc:description>Comment: IEEE Trans. on Control System Technology, 2016</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01047</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Placement Optimization of UAV-Mounted Mobile Base Stations</dc:title>
 <dc:creator>Lyu, Jiangbin</dc:creator>
 <dc:creator>Zeng, Yong</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:creator>Lim, Teng Joon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In terrestrial communication networks without fixed infrastructure, unmanned
aerial vehicle (UAV)-mounted mobile base stations (MBSs) provide an efficient
solution to achieve wireless connectivity. This letter aims to minimize the
number of MBSs needed to provide wireless coverage for a group of distributed
ground terminals (GTs), ensuring that each GT is within the communication range
of at least one MBS. We propose a polynomial-time algorithm with successive MBS
placement, where the MBSs are placed sequentially starting on the area
perimeter of the uncovered GTs along a spiral path towards the center, until
all GTs are covered. Each MBS is placed to cover as many uncovered GTs as
possible, with higher priority given to the GTs on the boundary to reduce the
occurrence of outlier GTs that each may require one dedicated MBS for its
coverage. Numerical results show that the proposed algorithm performs favorably
compared to other schemes in terms of the total number of required MBSs and/or
time complexity.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures, 1 table, accepted for publications in IEEE
  Communications Letters</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01047</dc:identifier>
 <dc:identifier>doi:10.1109/LCOMM.2016.2633248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01051</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SqueezeDet: Unified, Small, Low Power Fully Convolutional Neural
  Networks for Real-Time Object Detection for Autonomous Driving</dc:title>
 <dc:creator>Wu, Bichen</dc:creator>
 <dc:creator>Wan, Alvin</dc:creator>
 <dc:creator>Iandola, Forrest</dc:creator>
 <dc:creator>Jin, Peter H.</dc:creator>
 <dc:creator>Keutzer, Kurt</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object detection is a crucial task for autonomous driving. In addition to
requiring high accuracy to ensure safety, object detection for autonomous
driving also requires real-time inference speed to guarantee prompt vehicle
control, as well as small model size and energy efficiency to enable embedded
system deployment. In this work, we propose SqueezeDet, a fully convolutional
neural network for object detection that aims to simultaneously satisfy all of
the above constraints. In our network we use convolutional layers not only to
extract feature maps, but also as the output layer to compute bounding boxes
and class probabilities. The detection pipeline of our model only contains a
single forward pass of a neural network, thus it is extremely fast. Our model
is fully-convolutional, which leads to small model size and better energy
efficiency. Finally, our experiments show that our model is very accurate,
achieving state-of-the-art accuracy on the KITTI benchmark.
</dc:description>
 <dc:description>Comment: The supplementary material of this paper, which discusses the energy
  efficiency of SqueezeDet, is attached after the main paper. The source code
  of this work is open-source released at
  https://github.com/BichenWuUCB/squeezeDet</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01053</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings Second Graphs as Models Workshop</dc:title>
 <dc:creator>Heu&#xdf;ner, Alexander</dc:creator>
 <dc:creator>Kissinger, Aleks</dc:creator>
 <dc:creator>Wijs, Anton</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Graphs are used as models in all areas of computer science: examples are
state space graphs, control flow graphs, syntax graphs, UML-type models of all
kinds, network layouts, social networks, dependency graphs, and so forth. Once
such graphical models are constructed, they can be analysed and transformed to
verify their correctness within a domain, discover new properties, or produce
new equivalent and/or optimised versions.
  Graphs as Models' main focus is the exchange and collaboration of researchers
from different backgrounds. The workshop serves as platform to boost inter- and
transdisciplinary research and wants to serve as leeway for new ideas. Thus,
besides classical research presentations, the workshop is highly geared toward
numerous interactive sessions.
  The second edition of the Graphs as Models workshop was held on 2-3 June 2016
in Eindhoven, The Netherlands, colocated with the 19th European Joint
Conferences on Theory and Practice of Software (ETAPS 2016).
</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01053</dc:identifier>
 <dc:identifier>EPTCS 231, 2016</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01055</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling trajectories of mental health: challenges and opportunities</dc:title>
 <dc:creator>Erdman, Lauren</dc:creator>
 <dc:creator>Sharma, Ekansh</dc:creator>
 <dc:creator>Unternahrer, Eva</dc:creator>
 <dc:creator>Dass, Shantala Hari</dc:creator>
 <dc:creator>ODonnell, Kieran</dc:creator>
 <dc:creator>Mostafavi, Sara</dc:creator>
 <dc:creator>Edgar, Rachel</dc:creator>
 <dc:creator>Kobor, Michael</dc:creator>
 <dc:creator>Gaudreau, Helene</dc:creator>
 <dc:creator>Meaney, Michael</dc:creator>
 <dc:creator>Goldenberg, Anna</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  More than two thirds of mental health problems have their onset during
childhood or adolescence. Identifying children at risk for mental illness later
in life and predicting the type of illness is not easy. We set out to develop a
platform to define subtypes of childhood social-emotional development using
longitudinal, multifactorial trait-based measures. Subtypes discovered through
this study could ultimately advance psychiatric knowledge of the early
behavioural signs of mental illness. To this extent we have examined two types
of models: latent class mixture models and GP-based models. Our findings
indicate that while GP models come close in accuracy of predicting future
trajectories, LCMMs predict the trajectories as well in a fraction of the time.
Unfortunately, neither of the models are currently accurate enough to lead to
immediate clinical impact. The available data related to the development of
childhood mental health is often sparse with only a few time points measured
and require novel methods with improved efficiency and accuracy.
</dc:description>
 <dc:description>Comment: extended abstract for ML4HC at NIPS 2016, 4 pages</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01057</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Segment Object Proposals via Recursive Neural Networks</dc:title>
 <dc:creator>Chen, Tianshui</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:creator>Wu, Xian</dc:creator>
 <dc:creator>Luo, Xiaonan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  To avoid the exhaustive search over locations and scales, current
state-of-the-art object detection systems usually involve a crucial component
generating a batch of candidate object proposals from images. In this paper, we
present a simple yet effective approach for segmenting object proposals via a
deep architecture of recursive neural networks (RNNs), which hierarchically
groups regions for detecting object candidates over scales. Unlike traditional
methods that mainly adopt fixed similarity measures for merging regions or
finding object proposals, our approach adaptively learns the region merging
similarity and the objectness measure during the process of hierarchical region
grouping. Specifically, guided by a structured loss, the RNN model jointly
optimizes the cross-region similarity metric with the region merging process as
well as the objectness prediction. During inference of the object proposal
generation, we introduce randomness into the greedy search to cope with the
ambiguity of grouping regions. Extensive experiments on standard benchmarks,
e.g., PASCAL VOC and ImageNet, suggest that our approach is capable of
producing object proposals with high recall while well preserving the object
boundaries and outperforms other existing methods in both accuracy and
efficiency.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01058</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithmic Songwriting with ALYSIA</dc:title>
 <dc:creator>Ackerman, Margareta</dc:creator>
 <dc:creator>Loker, David</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This paper introduces ALYSIA: Automated LYrical SongwrIting Application.
ALYSIA is based on a machine learning model using Random Forests, and we
discuss its success at pitch and rhythm prediction. Next, we show how ALYSIA
was used to create original pop songs that were subsequently recorded and
produced. Finally, we discuss our vision for the future of Automated
Songwriting for both co-creative and autonomous systems.
</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01061</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On spreading rumor in heterogeneous systems</dc:title>
 <dc:creator>Cicho&#x144;, Jacek</dc:creator>
 <dc:creator>Go&#x142;\eobbiewski, Zbigniew</dc:creator>
 <dc:creator>Kardas, Marcin</dc:creator>
 <dc:creator>Klonowski, Marek</dc:creator>
 <dc:creator>Zag&#xf3;rski, Filip</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper we consider a model of spreading information in heterogeneous
systems wherein we have two kinds of objects. Some of them are active and
others are passive. Active objects can, if they possess information, share it
with an encountered passive object. We focus on a particular case such that
active objects communicate independently with randomly chosen passive objects.
Such model is motivated by two real-life scenarios. The first one is a very
dynamic system of mobile devices distributing information among stationary
devices. The second is an architecture wherein clients communicate with several
servers and can leave some information learnt from other servers. The main
question we investigate is how many rounds is needed to deliver the information
to all objects under the assumption that at the beginning exactly one object
has the information?
  In this paper we provide mathematical models of such process and show rigid
and very precise mathematical analysis for some special cases important from
practical point of view. Some mathematical results are quite surprising -- we
find relation of investigated process to both coupon collector's problem as
well as the birthday paradox. Additionally, we present simulations for showing
behaviour for general parameters
</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01064</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trained Ternary Quantization</dc:title>
 <dc:creator>Zhu, Chenzhuo</dc:creator>
 <dc:creator>Han, Song</dc:creator>
 <dc:creator>Mao, Huizi</dc:creator>
 <dc:creator>Dally, William J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks are widely used in machine learning applications.
However, the deployment of large neural networks models can be difficult to
deploy on mobile devices with limited power budgets. To solve this problem, we
propose Trained Ternary Quantization (TTQ), a method that can reduce the
precision of weights in neural networks to ternary values. This method has very
little accuracy degradation and can even improve the accuracy of some models
(32, 44, 56-layer ResNet) on CIFAR-10 and AlexNet on ImageNet. And our AlexNet
model is trained from scratch, which means it's as easy as to train normal full
precision model. We highlight our trained quantization method that can learn
both ternary values and ternary assignment. During inference, only ternary
values (2-bit weights) and scaling factors are needed, therefore our models are
nearly 16x smaller than full-precision models. Our ternary models can also be
viewed as sparse binary weight networks, which can potentially be accelerated
with custom circuit. Experiments on CIFAR-10 show that the ternary models
obtained by trained quantization method outperform full-precision models of
ResNet-32,44,56 by 0.04%, 0.16%, 0.36%, respectively. On ImageNet, our model
outperforms full-precision AlexNet model by 0.3% of Top-1 accuracy and
outperforms previous ternary models by 3%.
</dc:description>
 <dc:description>Comment: Accepted for Poster Presentation on ICLR 2017</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01067</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Four-Dimensional Usability Investigation of Image CAPTCHA</dc:title>
 <dc:creator>Yu, Junnan</dc:creator>
 <dc:creator>Ma, Xuna</dc:creator>
 <dc:creator>Han, Ting</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Image CAPTCHA, aiming at effectively distinguishing human users from
malicious script attacks, has been an important mechanism to protect online
systems from spams and abuses. Despite the increasing interests in developing
and deploying image CAPTCHAs, the usability aspect of those CAPTCHAs has hardly
been explored systematically. In this paper, the universal design factors of
image CAPTCHAs, such as image layouts, quantities, sizes, tilting angles and
colors were experimentally evaluated through the following four dimensions:
eye-tracking, efficiency, effectiveness and satisfaction. The cognitive
processes revealed by eye-tracking indicate that the distribution of eye gaze
is equally assigned to each candidate image and irrelevant to the variation of
image contents. In addition, the gazing plot suggests that more than 70% of the
participants inspected CAPTCHA images row-by-row, which is more efficient than
scanning randomly. Those four-dimensional evaluations essentially suggest that
square and horizontal rectangle are the preferred layout; image quantities may
not exceed 16 while the image color is insignificant. Meanwhile, the image size
and tilting angle are suggested to be larger than 55 pixels x 55 pixels and
within -45~45 degrees, respectively. Basing on those usability experiment
results, we proposed a design guideline that is expected to be useful for
developing more usable image CAPTCHAs.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01069</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Mathematical Proof of the Superiority of NOMA Compared to Conventional
  OMA</dc:title>
 <dc:creator>Chen, Zhiyong</dc:creator>
 <dc:creator>Ding, Zhiguo</dc:creator>
 <dc:creator>Dai, Xuchu</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  While existing works about non-orthogonal multiple access (NOMA) have
indicated that NOMA can yield a significant performance gain over orthogonal
multiple access (OMA) with fixed resource allocation, it is not clear whether
such a performance gain will diminish when optimal resource
(Time/Frequency/Power) allocation is carried out. In this paper, the
performance comparison between NOMA and conventional OMA systems is
investigated, from an optimization point of view. Firstly, by using the idea of
power splitting, a closed-form expression for the optimum sum rate of NOMA
systems is derived. Then, with rigorous mathematical proofs, we reveal the fact
that NOMA can always outperform conventional OMA systems, even if both are
equipped with the optimal resource allocation policies. Finally, computer
simulations are conducted to validate the accuracy of the analytical results.
</dc:description>
 <dc:description>Comment: 28 pages, 8 figures, submitted to IEEE Transactions on Signal
  Processing</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01069</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2725223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01070</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Usability Investigation on the Localization of Text CAPTCHAs: Take
  Chinese Characters as a Case Study</dc:title>
 <dc:creator>Yu, Junnan</dc:creator>
 <dc:creator>Ma, Xuna</dc:creator>
 <dc:creator>Han, Ting</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Text CAPTCHA has been an effective means to protect online systems from spams
and abuses caused by automatic scripts which pretend to be human beings.
However, nearly all the Text CAPTCHA designs in nowadays are based on English
characters, which may not be the most user-friendly option for non-English
speakers. Therefore, under the background of globalization, there is an
increasing interest in designing local-language CAPTCHA, which is expected to
be more usable for native speakers. However, systematic studies on the
usability of localized CAPTCHAs are rare, and a general procedure for the
design of usable localized CAPTCHA is still unavailable. Here, we
comprehensively explored the design of CAPTCHAs based on Chinese characters
from a usability perspective: cognitive processes of solving alphanumeric and
Chinese CAPTCHAs are analyzed, followed by a usability comparison of those two
types of CAPTCHAs and the evaluation of intrinsic design factors of Chinese
CAPTCHAs. It was found that Chinese CAPTCHAs could be equally usable comparing
with alphanumeric ones. Meanwhile, guidelines for the design of usable Chinese
CAPTCHAs were also presented. Moreover, those design practices were also
summarized as a general procedure which is expected to be applicable for the
design of CAPTCHAs based on other languages.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01072</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Word Recognition with Deep Conditional Random Fields</dc:title>
 <dc:creator>Chen, Gang</dc:creator>
 <dc:creator>Li, Yawei</dc:creator>
 <dc:creator>Srihari, Sargur N.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recognition of handwritten words continues to be an important problem in
document analysis and recognition. Existing approaches extract hand-engineered
features from word images--which can perform poorly with new data sets.
Recently, deep learning has attracted great attention because of the ability to
learn features from raw data. Moreover they have yielded state-of-the-art
results in classification tasks including character recognition and scene
recognition. On the other hand, word recognition is a sequential problem where
we need to model the correlation between characters. In this paper, we propose
using deep Conditional Random Fields (deep CRFs) for word recognition.
Basically, we combine CRFs with deep learning, in which deep features are
learned and sequences are labeled in a unified framework. We pre-train the deep
structure with stacked restricted Boltzmann machines (RBMs) for feature
learning and optimize the entire network with an online learning algorithm. The
proposed model was evaluated on two datasets, and seen to perform significantly
better than competitive baseline models. The source code is available at
https://github.com/ganggit/deepCRFs.
</dc:description>
 <dc:description>Comment: 5 pages, published in ICIP 2016. arXiv admin note: substantial text
  overlap with arXiv:1412.3397</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01074</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skin Cancer Detection and Tracking using Data Synthesis and Deep
  Learning</dc:title>
 <dc:creator>Li, Yunzhu</dc:creator>
 <dc:creator>Esteva, Andre</dc:creator>
 <dc:creator>Kuprel, Brett</dc:creator>
 <dc:creator>Novoa, Rob</dc:creator>
 <dc:creator>Ko, Justin</dc:creator>
 <dc:creator>Thrun, Sebastian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Dense object detection and temporal tracking are needed across applications
domains ranging from people-tracking to analysis of satellite imagery over
time. The detection and tracking of malignant skin cancers and benign moles
poses a particularly challenging problem due to the general uniformity of large
skin patches, the fact that skin lesions vary little in their appearance, and
the relatively small amount of data available. Here we introduce a novel data
synthesis technique that merges images of individual skin lesions with
full-body images and heavily augments them to generate significant amounts of
data. We build a convolutional neural network (CNN) based system, trained on
this synthetic data, and demonstrate superior performance to traditional
detection and tracking techniques. Additionally, we compare our system to
humans trained with simple criteria. Our system is intended for potential
clinical use to augment the capabilities of healthcare providers. While
domain-specific, we believe the methods invoked in this work will be useful in
applying CNNs across domains that suffer from limited data availability.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures, Yunzhu Li and Andre Esteva contributed equally to
  this work</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01075</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Visual Denoising and Classification using Deep Learning</dc:title>
 <dc:creator>Chen, Gang</dc:creator>
 <dc:creator>Li, Yawei</dc:creator>
 <dc:creator>Srihari, Sargur N.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual restoration and recognition are traditionally addressed in pipeline
fashion, i.e. denoising followed by classification. Instead, observing
correlations between the two tasks, for example clearer image will lead to
better categorization and vice visa, we propose a joint framework for visual
restoration and recognition for handwritten images, inspired by advances in
deep autoencoder and multi-modality learning. Our model is a 3-pathway deep
architecture with a hidden-layer representation which is shared by multi-inputs
and outputs, and each branch can be composed of a multi-layer deep model. Thus,
visual restoration and classification can be unified using shared
representation via non-linear mapping, and model parameters can be learnt via
backpropagation. Using MNIST and USPS data corrupted with structured noise, the
proposed framework performs at least 20\% better in classification than
separate pipelines, as well as clearer recovered images. The noise model and
the reproducible source code is available at
{\url{https://github.com/ganggit/jointmodel}}.
</dc:description>
 <dc:description>Comment: 5 pages, 7 figures, ICIP 2016</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01078</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing Use Case Points Estimation Method Using Soft Computing
  Techniques</dc:title>
 <dc:creator>Nassif, Ali Bou</dc:creator>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:creator>Ho, Danny</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Software estimation is a crucial task in software engineering. Software
estimation encompasses cost, effort, schedule, and size. The importance of
software estimation becomes critical in the early stages of the software life
cycle when the details of software have not been revealed yet. Several
commercial and non-commercial tools exist to estimate software in the early
stages. Most software effort estimation methods require software size as one of
the important metric inputs and consequently, software size estimation in the
early stages becomes essential. One of the approaches that has been used for
about two decades in the early size and effort estimation is called use case
points. Use case points method relies on the use case diagram to estimate the
size and effort of software projects. Although the use case points method has
been widely used, it has some limitations that might adversely affect the
accuracy of estimation. This paper presents some techniques using fuzzy logic
and neural networks to improve the accuracy of the use case points method.
Results showed that an improvement up to 22% can be obtained using the proposed
approach.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01079</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end Learning of Driving Models from Large-scale Video Datasets</dc:title>
 <dc:creator>Xu, Huazhe</dc:creator>
 <dc:creator>Gao, Yang</dc:creator>
 <dc:creator>Yu, Fisher</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Robust perception-action models should be learned from training data with
diverse visual appearances and realistic behaviors, yet current approaches to
deep visuomotor policy learning have been generally limited to in-situ models
learned from a single vehicle or a simulation environment. We advocate learning
a generic vehicle motion model from large scale crowd-sourced video data, and
develop an end-to-end trainable architecture for learning to predict a
distribution over future vehicle egomotion from instantaneous monocular camera
observations and previous vehicle state. Our model incorporates a novel
FCN-LSTM architecture, which can be learned from large-scale crowd-sourced
vehicle action data, and leverages available scene segmentation side tasks to
improve performance under a privileged learning paradigm.
</dc:description>
 <dc:description>Comment: camera ready for CVPR2017</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01082</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Label Image Classification with Regional Latent Semantic
  Dependencies</dc:title>
 <dc:creator>Zhang, Junjie</dc:creator>
 <dc:creator>Wu, Qi</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Zhang, Jian</dc:creator>
 <dc:creator>Lu, Jianfeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep convolution neural networks (CNN) have demonstrated advanced performance
on single-label image classification, and various progress also have been made
to apply CNN methods on multi-label image classification, which requires to
annotate objects, attributes, scene categories etc. in a single shot. Recent
state-of-the-art approaches to multi-label image classification exploit the
label dependencies in an image, at global level, largely improving the labeling
capacity. However, predicting small objects and visual concepts is still
challenging due to the limited discrimination of the global visual features. In
this paper, we propose a Regional Latent Semantic Dependencies model (RLSD) to
address this problem. The utilized model includes a fully convolutional
localization architecture to localize the regions that may contain multiple
highly-dependent labels. The localized regions are further sent to the
recurrent neural networks (RNN) to characterize the latent semantic
dependencies at the regional level. Experimental results on several benchmark
datasets show that our proposed model achieves the best performance compared to
the state-of-the-art models, especially for predicting small objects occurred
in the images. In addition, we set up an upper bound model (RLSD+ft-RPN) using
bounding box coordinates during training, the experimental results also show
that our RLSD can approach the upper bound without using the bounding-box
annotations, which is more realistic in the real world.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01082</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01086</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning of Robotic Tasks without a Simulator using Strong and Weak
  Human Supervision</dc:title>
 <dc:creator>Hilleli, Bar</dc:creator>
 <dc:creator>El-Yaniv, Ran</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We propose a scheme for training a computerized agent to perform complex
human tasks such as highway steering. The scheme is designed to follow a
natural learning process whereby a human instructor teaches a computerized
trainee. The learning process consists of five elements: (i) unsupervised
feature learning; (ii) supervised imitation learning; (iii) supervised reward
induction; (iv) supervised safety module construction; and (v) reinforcement
learning. We implemented the last four elements of the scheme using deep
convolutional networks and applied it to successfully create a computerized
agent capable of autonomous highway steering over the well-known racing game
Assetto Corsa. We demonstrate that the use of the last four elements is
essential to effectively carry out the steering task using vision alone,
without access to a driving simulator internals, and operating in wall-clock
time. This is made possible also through the introduction of a safety network,
a novel way for preventing the agent from performing catastrophic mistakes
during the reinforcement learning stage.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01090</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Studying Academic Indicators within Virtual Learning Environment Using
  Educational Data Mining</dc:title>
 <dc:creator>Aldikanji, Eid</dc:creator>
 <dc:creator>Ajami, Khalil</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  Our main goal is to discover the main factors influencing students' academic
trajectory and students' academic evolution within such environment. Our
results indicate strong correlation in this virtual learning environment
between student average and some factors like: student's English level (despite
the fact that Arabic language is the teaching language), student's age,
student's gender, student's over-stay and student's place of residence (inside
or outside Syria). Our results indicate also a need to modify the academic
trajectory of students by changing the prerequisites of few courses delivered
as a part of BIT diploma like Advanced DBA II, Data Security. In this research,
the results also highlight the effect of the Syrian Crisis on students.
Finally, we've suggested some future recommendations based on our observations
and results to develop the current information system in SVU in order to help
us to deduce some indicators more easily.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01090</dc:identifier>
 <dc:identifier>doi:10.5121/ijdkp.2016.6603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01091</identifier>
 <datestamp>2017-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A new rule for almost-certain termination of probabilistic- and demonic
  programs</dc:title>
 <dc:creator>McIver, Annabelle</dc:creator>
 <dc:creator>Morgan, Carroll</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Extending our own and others' earlier approaches to reasoning about
termination of probabilistic programs, we propose and prove a new rule for
termination with probability one, also known as &quot;almost-certain termination&quot;.
The rule uses both (non-strict) super martingales and guarantees of progress,
together, and it seems to cover significant cases that earlier methods do not.
In particular, it suffices for termination of the unbounded symmetric random
walk in both one- and two dimensions: for the first, we give a proof; for the
second, we use a theorem of Foster to argue that a proof exists.
Non-determinism (i.e. demonic choice) is supported; but we do currently
restrict to discrete distributions.
</dc:description>
 <dc:description>Comment: Revises earlier version by correcting typographical errors and adding
  an extra Section 9 on historical background. The results are unchanged</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01093</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Globular: an online proof assistant for higher-dimensional rewriting</dc:title>
 <dc:creator>Bar, Krzysztof</dc:creator>
 <dc:creator>Kissinger, Aleks</dc:creator>
 <dc:creator>Vicary, Jamie</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:description>  This article introduces Globular, an online proof assistant for the
formalization and verification of proofs in higher-dimensional category theory.
The tool produces graphical visualizations of higher-dimensional proofs,
assists in their construction with a point-and- click interface, and performs
type checking to prevent incorrect rewrites. Hosted on the web, it has a low
barrier to use, and allows hyperlinking of formalized proofs directly from
research papers. It allows the formalization of proofs from logic, topology and
algebra which are not formalizable by other methods, and we give several
examples.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01093</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-14(1:8)2018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01094</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to superoptimize programs - Workshop Version</dc:title>
 <dc:creator>Bunel, Rudy</dc:creator>
 <dc:creator>Desmaison, Alban</dc:creator>
 <dc:creator>Kumar, M. Pawan</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Superoptimization requires the estimation of the best program for a given
computational task. In order to deal with large programs, superoptimization
techniques perform a stochastic search. This involves proposing a modification
of the current program, which is accepted or rejected based on the improvement
achieved. The state of the art method uses uniform proposal distributions,
which fails to exploit the problem structure to the fullest. To alleviate this
deficiency, we learn a proposal distribution over possible modifications using
Reinforcement Learning. We provide convincing results on the superoptimization
of &quot;Hacker's Delight&quot; programs.
</dc:description>
 <dc:description>Comment: Workshop version for the NIPS NAMPI Workshop. Extended version at
  arXiv:1611.01787</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01094</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01095</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representing Independence Models with Elementary Triplets</dc:title>
 <dc:creator>Pe&#xf1;a, Jose M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In an independence model, the triplets that represent conditional
independences between singletons are called elementary. It is known that the
elementary triplets represent the independence model unambiguously under some
conditions. In this paper, we show how this representation helps performing
some operations with independence models, such as finding the dominant triplets
or a minimal independence map of an independence model, or computing the union
or intersection of a pair of independence models, or performing causal
reasoning. For the latter, we rephrase in terms of conditional independences
some of Pearl's results for computing causal effects.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01096</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Codes over $\mathbb{F}_{q}[x]/(x^2)$ and $GR(p^2,m)$ Reaching the
  Griesmer Bound</dc:title>
 <dc:creator>Li, Jin</dc:creator>
 <dc:creator>Zhang, Aixian</dc:creator>
 <dc:creator>Feng, Keqin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We construct two series of linear codes over finite ring
$\mathbb{F}_{q}[x]/(x^2)$ and Galois ring $GR(p^2,m)$ respectively reaching the
Griesmer bound. They derive two series of codes over finite field
$\mathbb{F}_{q}$ by Gray map. The first series of codes over $\mathbb{F}_{q}$
derived from $\mathbb{F}_{q}[x]/(x^2)$ are linear and also reach the Griesmer
bound in some cases. Many of linear codes over finite field we constructed have
two Hamming (non-zero) weights.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01103</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust nonparametric nearest neighbor random process clustering</dc:title>
 <dc:creator>Tschannen, Michael</dc:creator>
 <dc:creator>B&#xf6;lcskei, Helmut</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of clustering noisy finite-length observations of
stationary ergodic random processes according to their generative models
without prior knowledge of the model statistics and the number of generative
models. Two algorithms, both using the $L^1$-distance between estimated power
spectral densities (PSDs) as a measure of dissimilarity, are analyzed. The
first one, termed nearest neighbor process clustering (NNPC), relies on
partitioning the nearest neighbor graph of the observations via spectral
clustering. The second algorithm, simply referred to as $k$-means (KM),
consists of a single $k$-means iteration with farthest point initialization and
was considered before in the literature, albeit with a different dissimilarity
measure. We prove that both algorithms succeed with high probability in the
presence of noise and missing entries, and even when the generative process
PSDs overlap significantly, all provided that the observation length is
sufficiently large. Our results quantify the tradeoff between the overlap of
the generative process PSDs, the observation length, the fraction of missing
entries, and the noise variance. Finally, we provide extensive numerical
results for synthetic and real data and find that NNPC outperforms
state-of-the-art algorithms in human motion sequence clustering.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01103</dc:identifier>
 <dc:identifier>IEEE Transactions on Signal Processing, Vol. 65, No. 22, pp.
  6009-6023, Nov. 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2736513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01105</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pyramid Scene Parsing Network</dc:title>
 <dc:creator>Zhao, Hengshuang</dc:creator>
 <dc:creator>Shi, Jianping</dc:creator>
 <dc:creator>Qi, Xiaojuan</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:creator>Jia, Jiaya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Scene parsing is challenging for unrestricted open vocabulary and diverse
scenes. In this paper, we exploit the capability of global context information
by different-region-based context aggregation through our pyramid pooling
module together with the proposed pyramid scene parsing network (PSPNet). Our
global prior representation is effective to produce good quality results on the
scene parsing task, while PSPNet provides a superior framework for pixel-level
prediction tasks. The proposed approach achieves state-of-the-art performance
on various datasets. It came first in ImageNet scene parsing challenge 2016,
PASCAL VOC 2012 benchmark and Cityscapes benchmark. A single PSPNet yields new
record of mIoU accuracy 85.4% on PASCAL VOC 2012 and accuracy 80.2% on
Cityscapes.
</dc:description>
 <dc:description>Comment: CVPR 2017</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01113</identifier>
 <datestamp>2017-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel Adaptive weighted Kronecker Compressive Sensing</dc:title>
 <dc:creator>Safavi, Seyed Hamid</dc:creator>
 <dc:creator>Torkamani-Azar, Farah</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Recently, multidimensional signal reconstruction using a low number of
measurements is of great interest. Therefore, an effective sampling scheme
which should acquire the most information of signal using a low number of
measurements is required. In this paper, we study a novel cube-based method for
sampling and reconstruction of multidimensional signals. First, inspired by the
block-based compressive sensing (BCS), we divide a group of pictures (GoP) in a
video sequence into cubes. By this way, we can easily store the measurement
matrix and also easily can generate the sparsifying basis. The reconstruction
process also can be done in parallel. Second, along with the Kronecker
structure of the sampling matrix, we design a weight matrix based on the human
visuality system, i.e. perceptually. We will also benefit from different
weighted $\ell_1$-minimization methods for reconstruction. Furthermore,
conventional methods for BCS consider an equal number of samples for all
blocks. However, the sparsity order of blocks in natural images could be
different and, therefore, a various number of samples could be required for
their reconstruction. Motivated by this point, we will adaptively allocate the
samples for each cube in a video sequence. Our aim is to show that our simple
linear sampling approach can be competitive with the other state-of-the-art
methods.
</dc:description>
 <dc:description>Comment: The 42nd IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP 2017), Ph.D. Forum</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01114</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Performance of Visible Light Communications Systems with
  Non-Orthogonal Multiple Access</dc:title>
 <dc:creator>Marshoud, Hanaa</dc:creator>
 <dc:creator>Sofotasios, Paschalis C.</dc:creator>
 <dc:creator>Muhaidat, Sami</dc:creator>
 <dc:creator>Karagiannidis, George K.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Visible light communications (VLC) have been recently proposed as a promising
and efficient solution to indoor ubiquitous broadband connectivity. In this
paper, non-orthogonal multiple access, which has been recently proposed as an
effective scheme for fifth generation (5G) wireless networks, is considered in
the context of VLC systems, under different channel uncertainty models. To this
end, we first derive a novel closed-form expression for the bit-error-rate
(BER) under perfect channel state information (CSI). Capitalizing on this, we
quantify the effect of noisy and outdated CSI by deriving a simple approximated
expression for the former and a tight upper bound for the latter. The offered
results are corroborated by respective results from extensive Monte Carlo
simulations and are used to provide useful insights on the effect of imperfect
CSI knowledge on the system performance. It was shown that, while noisy CSI
leads to slight degradation in the BER performance, outdated CSI can cause
detrimental performance degradation if the order of the users' channel gains
change as a result of mobility
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01119</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security Analysis of Encrypted Virtual Machines</dc:title>
 <dc:creator>Hetzelt, Felicitas</dc:creator>
 <dc:creator>Buhren, Robert</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Cloud computing has become indispensable in today's computer landscape. The
flexibility it offers for customers as well as for providers has become a
crucial factor for large parts of the computer industry. Virtualization is the
key technology that allows for sharing of hardware resources among different
customers. The controlling software component, called hypervisor, provides a
virtualized view of the computer resources and ensures separation of different
guest virtual machines. However, this important cornerstone of cloud computing
is not necessarily trustworthy. To mitigate this threat AMD introduced Secure
Encrypted Virtualization, short SEV. SEV is a processor extension that encrypts
guest memory in order to prevent a potentially malicious hypervisor from
accessing guest data. In this paper we analyse whether the proposed features
can resist a malicious hypervisor and discuss the trade-offs imposed by
additional protection mechanisms. To do so, we developed a model of SEV's
security capabilities based on the available documentation as actual silicon
implementations are not yet on the market. We found that the currently proposed
version of SEV is not up to the task owing to three design shortcomings. First,
as with standard AMD-V, under SEV, the virtual machine control block is not
encrypted and handled directly by the hypervisor, allowing him to bypass VM
memory encryption by executing conveniently chosen gadgets. Secondly, the
general purpose registers are not encrypted upon vmexit, leaking potentially
sensitive data. Finally, the control of the nested pagetables allows a
malicious hypervisor to closely control the execution of a VM and attack it
with memory replay attacks.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01120</identifier>
 <datestamp>2017-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity of Bayesian Networks Specified by Propositional and
  Relational Languages</dc:title>
 <dc:creator>Cozman, Fabio Gagliardi</dc:creator>
 <dc:creator>Mau&#xe1;, Denis Deratani</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We examine the complexity of inference in Bayesian networks specified by
logical languages. We consider representations that range from fragments of
propositional logic to function-free first-order logic with equality; in doing
so we cover a variety of plate models and of probabilistic relational models.
We study the complexity of inferences when network, query and domain are the
input (the inferential and the combined complexity), when the network is fixed
and query and domain are the input (the query/data complexity), and when the
network and query are fixed and the domain is the input (the domain
complexity). We draw connections with probabilistic databases and liftability
results, and obtain complexity classes that range from polynomial to
exponential levels.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01131</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A method for the segmentation of images based on thresholding and
  applied to vesicular textures</dc:title>
 <dc:creator>Sparavigna, Amelia Carolina</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In image processing, a segmentation is a process of partitioning an image
into multiple sets of pixels, that are defined as super-pixels. Each
super-pixel is characterized by a label or parameter. Here, we are proposing a
method for determining the super-pixels based on the thresholding of the image.
This approach is quite useful for studying the images showing vesicular
textures.
</dc:description>
 <dc:description>Comment: Keywords: Segmentation, Edge Detection, Image Analysis, 2D Textures,
  Texture Functions</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01133</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Novel Delivery Schemes for Decentralized Coded Caching in the Finite
  File Size Regime</dc:title>
 <dc:creator>Wan, Kai</dc:creator>
 <dc:creator>Tuninetti, Daniela</dc:creator>
 <dc:creator>Piantanida, Pablo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper analyzes the achievable tradeoff between cache~size and
download~rate in decentralized caching systems with the uncoded cache placement
originally proposed by Maddah-Ali and Niesen. It proposes two novel delivery
schemes that take advantage of the multicasting opportunities that arise when a
file is demanded by multiple users. These delivery schemes are extensions of
known ones to the regime where the file size is finite. Numerical evaluations
for the case of file uniform popularity show that the proposed schemes
outperform previous ones for all value of the cache size.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, ICC 2017-WT10</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01147</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The limits of SDP relaxations for general-valued CSPs</dc:title>
 <dc:creator>Thapper, Johan</dc:creator>
 <dc:creator>Zivny, Stanislav</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.2.0</dc:subject>
 <dc:description>  It has been shown that for a general-valued constraint language $\Gamma$ the
following statements are equivalent: (1) any instance of
$\operatorname{VCSP}(\Gamma)$ can be solved to optimality using a constant
level of the Sherali-Adams LP hierarchy; (2) any instance of
$\operatorname{VCSP}(\Gamma)$ can be solved to optimality using the third level
of the Sherali-Adams LP hierarchy; (3) the support of $\Gamma$ satisfies the
&quot;bounded width condition&quot;, i.e., it contains weak near-unanimity operations of
all arities.
  We show that if the support of $\Gamma$ violates the bounded with condition
then not only is $\operatorname{VCSP}(\Gamma)$ not solved by a constant level
of the Sherali-Adams LP hierarchy but it is also not solved by $\Omega(n)$
levels of the Lasserre SDP hierarchy (also known as the sum-of-squares SDP
hierarchy). For $\Gamma$ corresponding to linear equations in an Abelian group,
this result follows from existing work on inapproximability of Max-CSPs. By a
breakthrough result of Lee, Raghavendra, and Steurer [STOC'15], our result
implies that for any $\Gamma$ whose support violates the bounded width
condition no SDP relaxation of polynomial-size solves
$\operatorname{VCSP}(\Gamma)$.
  We establish our result by proving that various reductions preserve exact
solvability by the Lasserre SDP hierarchy (up to a constant factor in the level
of the hierarchy). Our results hold for general-valued constraint languages,
i.e., sets of functions on a fixed finite domain that take on rational or
infinite values, and thus also hold in notable special cases of
$\{0,\infty\}$-valued languages (CSPs), $\{0,1\}$-valued languages
(Min-CSPs/Max-CSPs), and $\mathbb{Q}$-valued languages (finite-valued CSPs).
</dc:description>
 <dc:description>Comment: Full version of a LICS'17 paper. Builds on and extends
  arXiv:1606.02577</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01158</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Properties and Bayesian fitting of restricted Boltzmann machines</dc:title>
 <dc:creator>Kaplan, Andee</dc:creator>
 <dc:creator>Nordman, Daniel</dc:creator>
 <dc:creator>Vardeman, Stephen</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A restricted Boltzmann machine (RBM) is an undirected graphical model
constructed for discrete or continuous random variables, with two layers, one
hidden and one visible, and no conditional dependency within a layer. In recent
years, RBMs have risen to prominence due to their connection to deep learning.
By treating a hidden layer of one RBM as the visible layer in a second RBM, a
deep architecture can be created. RBMs are thought to thereby have the ability
to encode very complex and rich structures in data, making them attractive for
supervised learning. However, the generative behavior of RBMs is largely
unexplored. In this paper, we discuss the relationship between RBM parameter
specification in the binary case and model properties such as degeneracy,
instability and uninterpretability. We also describe the difficulties that
arise in likelihood-based and Bayes fitting of such (highly flexible) models,
especially as Gibbs sampling (quasi-Bayes) methods are often advocated for the
RBM model structure.
</dc:description>
 <dc:description>Comment: 42 pages, 13 figures</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01160</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>General models for rational cameras and the case of two-slit projections</dc:title>
 <dc:creator>Trager, Matthew</dc:creator>
 <dc:creator>Sturmfels, Bernd</dc:creator>
 <dc:creator>Canny, John</dc:creator>
 <dc:creator>Hebert, Martial</dc:creator>
 <dc:creator>Ponce, Jean</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The rational camera model recently introduced in [19] provides a general
methodology for studying abstract nonlinear imaging systems and their
multi-view geometry. This paper builds on this framework to study &quot;physical
realizations&quot; of rational cameras. More precisely, we give an explicit account
of the mapping between between physical visual rays and image points (missing
in the original description), which allows us to give simple analytical
expressions for direct and inverse projections. We also consider &quot;primitive&quot;
camera models, that are orbits under the action of various projective
transformations, and lead to a general notion of intrinsic parameters. The
methodology is general, but it is illustrated concretely by an in-depth study
of two-slit cameras, that we model using pairs of linear projections. This
simple analytical form allows us to describe models for the corresponding
primitive cameras, to introduce intrinsic parameters with a clear geometric
meaning, and to define an epipolar tensor characterizing two-view
correspondences. In turn, this leads to new algorithms for structure from
motion and self-calibration.
</dc:description>
 <dc:description>Comment: 9 pages + supplementary material</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01163</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QoS-based Computing Resources Partitioning between Virtual Machines in
  the Cloud Architecture</dc:title>
 <dc:creator>Nikulchev, Evgeny</dc:creator>
 <dc:creator>Pluzhnik, Evgeniy</dc:creator>
 <dc:creator>Lukyanchikov, Oleg</dc:creator>
 <dc:creator>Biryukov, Dmitry</dc:creator>
 <dc:creator>Andrianova, Elena</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Cloud services have been used very widely, but configuration of the
parameters, including the efficient allocation of resources, is an important
objective for the system architect. The article is devoted to solving the
problem of choosing the architecture of computers based on simulation and
developed program for monitoring computing resources. Techniques were developed
aimed at providing the required quality of service and efficient use of
resources. The article describes the monitoring program of computing resources
and time efficiency of the target application functions. On the basis of this
application the technique is shown and described in the experiment, designed to
ensure the requirements for quality of service, by isolating one process from
the others on different virtual machines inside the hypervisor.
</dc:description>
 <dc:description>Comment: 6 pages, International Journal of Advanced Computer Science and
  Applications (2016) 7</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01163</dc:identifier>
 <dc:identifier>doi:10.14569/IJACSA.2016.071121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01171</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The limited blessing of low dimensionality: when $1-1/d$ is the best
  possible exponent for $d$-dimensional geometric problems</dc:title>
 <dc:creator>Marx, D&#xe1;niel</dc:creator>
 <dc:creator>Sidiropoulos, Anastasios</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We are studying $d$-dimensional geometric problems that have algorithms with
$1-1/d$ appearing in the exponent of the running time, for example, in the form
of $2^{n^{1-1/d}}$ or $n^{k^{1-1/d}}$. This means that these algorithms perform
somewhat better in low dimensions, but the running time is almost the same r
all large values $d$ of the dimension. Our main result is showing that for some
of these problems the dependence on $1-1/d$ is best possible under a standard
complexity assumption. We show that, assuming the Exponential Time Hypothesis,
  --- $d$-dimensional Euclidean TSP on $n$ points cannot be solved in time
$2^{O(n^{1-1/d-\epsilon})}$ for any $\epsilon&gt;0$, and
  --- the problem of finding a set of $k$ pairwise nonintersecting
$d$-dimensional unit balls/axis parallel unit cubes cannot be solved in time
$f(k)n^{o(k^{1-1/d})}$ for any computable function $f$.
  These lower bounds essentially match the known algorithms for these problems.
To obtain these results, we first prove lower bounds on the complexity of
Constraint Satisfaction Problems (CSPs) whose constraint graphs are
$d$-dimensional grids. We state the complexity results on CSPs in a way to make
them convenient starting points for problem-specific reductions to particular
$d$-dimensional geometric problems and to be reusable in the future for further
results of similar flavor.
</dc:description>
 <dc:description>Comment: Full version of SoCG 2014 paper</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01175</identifier>
 <datestamp>2017-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Who is Mistaken?</dc:title>
 <dc:creator>Eysenbach, Benjamin</dc:creator>
 <dc:creator>Vondrick, Carl</dc:creator>
 <dc:creator>Torralba, Antonio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recognizing when people have false beliefs is crucial for understanding their
actions. We introduce the novel problem of identifying when people in abstract
scenes have incorrect beliefs. We present a dataset of scenes, each visually
depicting an 8-frame story in which a character has a mistaken belief. We then
create a representation of characters' beliefs for two tasks in human action
understanding: predicting who is mistaken, and when they are mistaken.
Experiments suggest that our method for identifying mistaken characters
performs better on these tasks than simple baselines. Diagnostics on our model
suggest it learns important cues for recognizing mistaken beliefs, such as
gaze. We believe models of people's beliefs will have many applications in
action understanding, robotics, and healthcare.
</dc:description>
 <dc:description>Comment: See project website at: http://people.csail.mit.edu/bce/mistaken/ .
  (Edit: fixed typos and references)</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01178</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Work-Efficient Connected Components on the GPU</dc:title>
 <dc:creator>Sutton, Michael</dc:creator>
 <dc:creator>Ben-Nun, Tal</dc:creator>
 <dc:creator>Barak, Amnon</dc:creator>
 <dc:creator>Pai, Sreepathi</dc:creator>
 <dc:creator>Pingali, Keshav</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This report presents an adaptive work-efficient approach for implementing the
Connected Components algorithm on GPUs. The results show a considerable
increase in performance (up to 6.8$\times$) over current state-of-the-art
solutions.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01183</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AMP-Inspired Deep Networks for Sparse Linear Inverse Problems</dc:title>
 <dc:creator>Borgerding, Mark</dc:creator>
 <dc:creator>Schniter, Philip</dc:creator>
 <dc:creator>Rangan, Sundeep</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Deep learning has gained great popularity due to its widespread success on
many inference problems. We consider the application of deep learning to the
sparse linear inverse problem, where one seeks to recover a sparse signal from
a few noisy linear measurements. In this paper, we propose two novel
neural-network architectures that decouple prediction errors across layers in
the same way that the approximate message passing (AMP) algorithms decouple
them across iterations: through Onsager correction. First, we propose a
&quot;learned AMP&quot; network that significantly improves upon Gregor and LeCun's
&quot;learned ISTA.&quot; Second, inspired by the recently proposed &quot;vector AMP&quot; (VAMP)
algorithm, we propose a &quot;learned VAMP&quot; network that offers increased robustness
to deviations in the measurement matrix from i.i.d. Gaussian. In both cases, we
jointly learn the linear transforms and scalar nonlinearities of the network.
Interestingly, with i.i.d. signals, the linear transforms and scalar
nonlinearities prescribed by the VAMP algorithm coincide with the values
learned through back-propagation, leading to an intuitive interpretation of
learned VAMP. Finally, we apply our methods to two problems from 5G wireless
communications: compressive random access and massive-MIMO channel estimation.
</dc:description>
 <dc:description>Comment: to appear in IEEE Transactions in Signal Processing</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01183</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2708040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01186</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vector Approximate Message Passing for the Generalized Linear Model</dc:title>
 <dc:creator>Schniter, Philip</dc:creator>
 <dc:creator>Rangan, Sundeep</dc:creator>
 <dc:creator>Fletcher, Alyson K.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The generalized linear model (GLM), where a random vector $\boldsymbol{x}$ is
observed through a noisy, possibly nonlinear, function of a linear transform
output $\boldsymbol{z}=\boldsymbol{Ax}$, arises in a range of applications such
as robust regression, binary classification, quantized compressed sensing,
phase retrieval, photon-limited imaging, and inference from neural spike
trains. When $\boldsymbol{A}$ is large and i.i.d. Gaussian, the generalized
approximate message passing (GAMP) algorithm is an efficient means of MAP or
marginal inference, and its performance can be rigorously characterized by a
scalar state evolution. For general $\boldsymbol{A}$, though, GAMP can
misbehave. Damping and sequential-updating help to robustify GAMP, but their
effects are limited. Recently, a &quot;vector AMP&quot; (VAMP) algorithm was proposed for
additive white Gaussian noise channels. VAMP extends AMP's guarantees from
i.i.d. Gaussian $\boldsymbol{A}$ to the larger class of rotationally invariant
$\boldsymbol{A}$. In this paper, we show how VAMP can be extended to the GLM.
Numerical experiments show that the proposed GLM-VAMP is much more robust to
ill-conditioning in $\boldsymbol{A}$ than damped GAMP.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01188</identifier>
 <datestamp>2016-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy on the Blockchain: Unique Ring Signatures</dc:title>
 <dc:creator>Mercer, Rebekah</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Ring signatures are cryptographic protocols designed to allow any member of a
group to produce a signature on behalf of the group, without revealing the
individual signer's identity. This offers group members a level of anonymity
not attainable through generic digital signature schemes. We call this property
'plausible deniability', or anonymity with respect to an anonymity set. We
concentrate in particular on implementing privacy on the blockchain,
introducing a unique ring signature scheme that works with existing blockchain
systems. We implement a unique ring signature (URS) scheme using secp256k1,
creating the first implementation compatible with blockchain libraries in this
way, so as for easy implementation as an Ethereum smart contract. We review the
privacy and security properties offered by the scheme we have constructed, and
compare its efficiency with other commonly suggested approaches to privacy on
the blockchain.
</dc:description>
 <dc:description>Comment: 42 pages, 8 figures</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2016-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01189</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cache-Enabled Physical-Layer Security for Video Streaming in Wireless
  Networks with Limited Backhaul</dc:title>
 <dc:creator>Xiang, Lin</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:creator>Wong, Vincent W. S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate for the first time the benefits of wireless
caching for the physical layer security (PLS) of wireless networks. In
particular, a caching scheme enabling power-efficient PLS is proposed for
cellular video streaming with constrained backhaul capacity. By sharing video
data across a subset of base stations (BSs) through both caching and backhaul
loading, secure cooperative transmission of several BSs is dynamically enabled
in accordance with the cache status, the channel conditions, and the backhaul
capacity. Thereby, caching reduces the data sharing overhead over the
capacity-constrained backhaul links. More importantly, caching introduces
additional secure degrees of freedom and enables a power-efficient design. We
investigate the optimal caching and transmission policies for minimizing the
total transmit power while providing quality of service (QoS) and guaranteeing
secrecy during video delivery. A two-stage non-convex mixed-integer
optimization problem is formulated, which optimizes the caching policy in an
offline video caching stage and the cooperative transmission policy in an
online video delivery stage. As the problem is NP-hard, suboptimal
polynomial-time algorithms are proposed for low-complexity cache training and
delivery control, respectively. Sufficient optimality conditions, under which
the proposed schemes attain global optimal solutions, are also provided.
Simulation results show that the proposed schemes achieve low secrecy outage
probability and high power efficiency simultaneously.
</dc:description>
 <dc:description>Comment: Accepted for presentation at IEEE Globecom 2016, Washington, DC, Dec.
  2016</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01193</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal transport over nonlinear systems via infinitesimal generators on
  graphs</dc:title>
 <dc:creator>Elamvazhuthi, Karthik</dc:creator>
 <dc:creator>Grover, Piyush</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>37M99, 47D03, 93C10, 93C20</dc:subject>
 <dc:description>  We present a set-oriented graph-based computational framework for
continuous-time optimal transport over nonlinear dynamical systems. We recover
provably optimal control laws for steering a given initial distribution in
phase space to a final distribution in prescribed finite time for the case of
non-autonomous nonlinear control-affine systems, while minimizing a quadratic
transport cost. The resulting control law can be used to obtain approximate
feedback laws for individual agents in a swarm control application. Using
infinitesimal generators, the optimal control problem is reduced to a modified
Monge-Kantorovich optimal transport problem, resulting in a convex
Benamou-Brenier type fluid dynamics formulation on a graph. The well-posedness
of this problem is shown to be a consequence of the graph being
strongly-connected, which in turn is shown to result from controllability of
the underlying dynamical system. Using our computational framework, we study
optimal transport in dynamical systems arising in chaotic fluid dynamics and
non-holonomic vehicle dynamics. The solutions to the optimal transport problem
elucidate the role played by invariant manifolds, lobe-dynamics and
almost-invariant sets in efficient transport of distributions in finite time.
Our work connects set-oriented operator-theoretic methods in dynamical systems
with optimal mass transportation theory, and opens up new directions in design
of efficient feedback control strategies for nonlinear multi-agent and swarm
systems operating in nonlinear ambient flow fields.
</dc:description>
 <dc:description>Comment: 36 pages, 11 figures. Added controllability proof, and fixed issues
  with earlier draft</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01194</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Localization and Prediction of Actions and Interactions</dc:title>
 <dc:creator>Soomro, Khurram</dc:creator>
 <dc:creator>Idrees, Haroon</dc:creator>
 <dc:creator>Shah, Mubarak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a person-centric and online approach to the challenging
problem of localization and prediction of actions and interactions in videos.
Typically, localization or recognition is performed in an offline manner where
all the frames in the video are processed together. This prevents timely
localization and prediction of actions and interactions - an important
consideration for many tasks including surveillance and human-machine
interaction.
  In our approach, we estimate human poses at each frame and train
discriminative appearance models using the superpixels inside the pose bounding
boxes. Since the pose estimation per frame is inherently noisy, the conditional
probability of pose hypotheses at current time-step (frame) is computed using
pose estimations in the current frame and their consistency with poses in the
previous frames. Next, both the superpixel and pose-based foreground
likelihoods are used to infer the location of actors at each time through a
Conditional Random. The issue of visual drift is handled by updating the
appearance models, and refining poses using motion smoothness on joint
locations, in an online manner. For online prediction of action (interaction)
confidences, we propose an approach based on Structural SVM that operates on
short video segments, and is trained with the objective that confidence of an
action or interaction increases as time progresses. Lastly, we quantify the
performance of both detection and prediction together, and analyze how the
prediction accuracy varies as a time function of observed action (interaction)
at different levels of detection performance. Our experiments on several
datasets suggest that despite using only a few frames to localize actions
(interactions) at each time instant, we are able to obtain competitive results
to state-of-the-art offline methods.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01197</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Symbolic Machines: Learning Semantic Parsers on Freebase with
  Weak Supervision (Short Version)</dc:title>
 <dc:creator>Liang, Chen</dc:creator>
 <dc:creator>Berant, Jonathan</dc:creator>
 <dc:creator>Le, Quoc</dc:creator>
 <dc:creator>Forbus, Kenneth D.</dc:creator>
 <dc:creator>Lao, Ni</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Extending the success of deep neural networks to natural language
understanding and symbolic reasoning requires complex operations and external
memory. Recent neural program induction approaches have attempted to address
this problem, but are typically limited to differentiable memory, and
consequently cannot scale beyond small synthetic tasks. In this work, we
propose the Manager-Programmer-Computer framework, which integrates neural
networks with non-differentiable memory to support abstract, scalable and
precise operations through a friendly neural computer interface. Specifically,
we introduce a Neural Symbolic Machine, which contains a sequence-to-sequence
neural &quot;programmer&quot;, and a non-differentiable &quot;computer&quot; that is a Lisp
interpreter with code assist. To successfully apply REINFORCE for training, we
augment it with approximate gold programs found by an iterative maximum
likelihood training process. NSM is able to learn a semantic parser from weak
supervision over a large knowledge base. It achieves new state-of-the-art
performance on WebQuestionsSP, a challenging semantic parsing dataset, with
weak supervision. Compared to previous approaches, NSM is end-to-end, therefore
does not rely on feature engineering or domain specific knowledge.
</dc:description>
 <dc:description>Comment: Published in NAMPI workshop at NIPS 2016. Short version of
  arXiv:1611.00020</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01198</identifier>
 <datestamp>2017-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementing and Evaluating Candidate-Based Invariant Generation</dc:title>
 <dc:creator>Betts, Adam</dc:creator>
 <dc:creator>Chong, Nathan</dc:creator>
 <dc:creator>Deligiannis, Pantazis</dc:creator>
 <dc:creator>Donaldson, Alastair F.</dc:creator>
 <dc:creator>Ketema, Jeroen</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The discovery of inductive invariants lies at the heart of static program
verification. Presently, many automatic solutions to inductive invariant
generation are inflexible, only applicable to certain classes of programs, or
unpredictable. An automatic technique that circumvents these deficiencies to
some extent is candidate-based invariant generation. This paper describes our
efforts to apply candidate-based invariant generation in GPUVerify, a static
checker for programs that run on GPUs. We study a set of GPU programs that
contain loops, drawn from a number of open source suites and vendor SDKs.
  We describe the methodology we used to incrementally improve the invariant
generation capabilities of GPUVerify to handle these benchmarks, through
candidate-based invariant generation, using cheap static analysis to speculate
potential program invariants. We also describe a set of experiments that we
used to examine the effectiveness of our rules for candidate generation,
assessing rules based on their generality (the extent to which they generate
candidate invariants), hit rate (the extent to which the generated candidates
hold), worth (the extent to which provable candidates actually help in allowing
verification to succeed), and influence (the extent to which the success of one
generation rule depends on candidates generated by another rule).
  The candidates produced by GPUVerify help to verify 231 of the 253 programs.
This increase in precision, however, makes GPUVerify sluggish: the more
candidates that are generated, the more time is spent determining which are
inductive invariants. To speed up this process, we have investigated four
under-approximating program analyses that aim to reject false candidates
quickly and a framework whereby these analyses can run in sequence or in
parallel.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01200</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intra-day Activity Better Predicts Chronic Conditions</dc:title>
 <dc:creator>Quisel, Tom</dc:creator>
 <dc:creator>Kale, David C.</dc:creator>
 <dc:creator>Foschini, Luca</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work we investigate intra-day patterns of activity on a population of
7,261 users of mobile health wearable devices and apps. We show that: (1) using
intra-day step and sleep data recorded from passive trackers significantly
improves classification performance on self-reported chronic conditions related
to mental health and nervous system disorders, (2) Convolutional Neural
Networks achieve top classification performance vs. baseline models when
trained directly on multivariate time series of activity data, and (3) jointly
predicting all condition classes via multi-task learning can be leveraged to
extract features that generalize across data sets and achieve the highest
classification performance.
</dc:description>
 <dc:description>Comment: Presented at the NIPS 2016 Workshop on Machine Learning for Health</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01202</identifier>
 <datestamp>2017-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DenseReg: Fully Convolutional Dense Shape Regression In-the-Wild</dc:title>
 <dc:creator>G&#xfc;ler, R&#x131;za Alp</dc:creator>
 <dc:creator>Trigeorgis, George</dc:creator>
 <dc:creator>Antonakos, Epameinondas</dc:creator>
 <dc:creator>Snape, Patrick</dc:creator>
 <dc:creator>Zafeiriou, Stefanos</dc:creator>
 <dc:creator>Kokkinos, Iasonas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we propose to learn a mapping from image pixels into a dense
template grid through a fully convolutional network. We formulate this task as
a regression problem and train our network by leveraging upon manually
annotated facial landmarks &quot;in-the-wild&quot;. We use such landmarks to establish a
dense correspondence field between a three-dimensional object template and the
input image, which then serves as the ground-truth for training our regression
system. We show that we can combine ideas from semantic segmentation with
regression networks, yielding a highly-accurate &quot;quantized regression&quot;
architecture.
  Our system, called DenseReg, allows us to estimate dense image-to-template
correspondences in a fully convolutional manner. As such our network can
provide useful correspondence information as a stand-alone system, while when
used as an initialization for Statistical Deformable Models we obtain landmark
localization results that largely outperform the current state-of-the-art on
the challenging 300W benchmark. We thoroughly evaluate our method on a host of
facial analysis tasks and also provide qualitative results for dense human body
correspondence. We make our code available at http://alpguler.com/DenseReg.html
along with supplementary materials.
</dc:description>
 <dc:description>Comment: CVPR 2017</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01205</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal and Adaptive Off-policy Evaluation in Contextual Bandits</dc:title>
 <dc:creator>Wang, Yu-Xiang</dc:creator>
 <dc:creator>Agarwal, Alekh</dc:creator>
 <dc:creator>Dudik, Miroslav</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the off-policy evaluation problem---estimating the value of a target
policy using data collected by another policy---under the contextual bandit
model. We consider the general (agnostic) setting without access to a
consistent model of rewards and establish a minimax lower bound on the mean
squared error (MSE). The bound is matched up to constants by the inverse
propensity scoring (IPS) and doubly robust (DR) estimators. This highlights the
difficulty of the agnostic contextual setting, in contrast with multi-armed
bandits and contextual bandits with access to a consistent reward model, where
IPS is suboptimal. We then propose the SWITCH estimator, which can use an
existing reward model (not necessarily consistent) to achieve a better
bias-variance tradeoff than IPS and DR. We prove an upper bound on its MSE and
demonstrate its benefits empirically on a diverse collection of data sets,
often outperforming prior work by orders of magnitude.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01205</dc:identifier>
 <dc:identifier>International Conference on Machine Learning (pp. 3589-3597)
  (2017)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01209</identifier>
 <datestamp>2017-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput of Infrastructure-based Cooperative Vehicular Networks</dc:title>
 <dc:creator>Chen, Jieqiong</dc:creator>
 <dc:creator>Mao, Guoqiang</dc:creator>
 <dc:creator>Li, Changle</dc:creator>
 <dc:creator>Zafar, Ammar</dc:creator>
 <dc:creator>Zomaya, Albert Y.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we provide detailed analysis of the achievable throughput of
infrastructure-based vehicular network with a finite traffic density under a
cooperative communication strategy, which explores combined use of
vehicle-to-infrastructure (V2I) communications, vehicle-to-vehicle (V2V)
communications, mobility of vehicles and cooperations among vehicles and
infrastructure to facilitate the data transmission. A closed form expression of
the achievable throughput is obtained, which reveals the relationship between
the achievable throughput and its major performance-impacting parameters such
as distance between adjacent infrastructure points, radio ranges of
infrastructure and vehicles, transmission rates of V2I and V2V communications
and vehicular density. Numerical and simulation results show that the proposed
cooperative communication strategy significantly increases the throughput of
vehicular networks, compared with its non-cooperative counterpart, even when
the traffic density is low. Our results shed insight on the optimum deployment
of vehicular network infrastructure and optimum design of cooperative
communication strategies in vehicular networks to maximize the throughput.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01209</dc:identifier>
 <dc:identifier>IEEE Transactions on Intelligent Transportation Systems, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TITS.2017.2663434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01211</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Process Model Predictive Control of Unknown Nonlinear Systems</dc:title>
 <dc:creator>Cao, Gang</dc:creator>
 <dc:creator>Lai, Edmund M-K</dc:creator>
 <dc:creator>Alam, Fakhrul</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Model Predictive Control (MPC) of an unknown system that is modelled by
Gaussian Process (GP) techniques is studied in this paper. Using GP, the
variances computed during the modelling and inference processes allow us to
take model uncertainty into account. The main issue in using MPC to control
systems modelled by GP is the propagation of such uncertainties within the
control horizon. In this paper, two approaches to solve this problem, called
GPMPC1 and GPMPC2, are proposed. With GPMPC1, the original Stochastic Model
Predictive Control (SMPC) problem is relaxed to a deterministic nonlinear MPC
based on a basic linearized GP local model. The resulting optimization problem,
though non-convex, can be solved by the Sequential Quadratic Programming (SQP).
By incorporating the model variance into the state vector, an extended local
model is derived. This model allows us to relax the non-convex MPC problem to a
convex one which can be solved by an active-set method efficiently. The
performance of both approaches is demonstrated by applying them to two
trajectory tracking problems. Results show that both GPMPC1 and GPMPC2 produce
effective controls but GPMPC2 is much more efficient computationally.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01213</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Metric Learning via Facility Location</dc:title>
 <dc:creator>Song, Hyun Oh</dc:creator>
 <dc:creator>Jegelka, Stefanie</dc:creator>
 <dc:creator>Rathod, Vivek</dc:creator>
 <dc:creator>Murphy, Kevin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning the representation and the similarity metric in an end-to-end
fashion with deep networks have demonstrated outstanding results for clustering
and retrieval. However, these recent approaches still suffer from the
performance degradation stemming from the local metric training procedure which
is unaware of the global structure of the embedding space.
  We propose a global metric learning scheme for optimizing the deep metric
embedding with the learnable clustering function and the clustering metric
(NMI) in a novel structured prediction framework.
  Our experiments on CUB200-2011, Cars196, and Stanford online products
datasets show state of the art performance both on the clustering and retrieval
tasks measured in the NMI and Recall@K evaluation metrics.
</dc:description>
 <dc:description>Comment: Submission accepted at CVPR 2017</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01215</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Do What I Want, Not What I Did: Imitation of Skills by Planning
  Sequences of Actions</dc:title>
 <dc:creator>Paxton, Chris</dc:creator>
 <dc:creator>Jonathan, Felix</dc:creator>
 <dc:creator>Kobilarov, Marin</dc:creator>
 <dc:creator>Hager, Gregory D</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We propose a learning-from-demonstration approach for grounding actions from
expert data and an algorithm for using these actions to perform a task in new
environments. Our approach is based on an application of sampling-based motion
planning to search through the tree of discrete, high-level actions constructed
from a symbolic representation of a task. Recursive sampling-based planning is
used to explore the space of possible continuous-space instantiations of these
actions. We demonstrate the utility of our approach with a magnetic structure
assembly task, showing that the robot can intelligently select a sequence of
actions in different parts of the workspace and in the presence of obstacles.
This approach can better adapt to new environments by selecting the correct
high-level actions for the particular environment while taking human
preferences into account.
</dc:description>
 <dc:description>Comment: 8 pages, published at IROS 2016</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01216</identifier>
 <datestamp>2017-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decentralized Frank-Wolfe Algorithm for Convex and Non-convex Problems</dc:title>
 <dc:creator>Wai, Hoi-To</dc:creator>
 <dc:creator>Lafond, Jean</dc:creator>
 <dc:creator>Scaglione, Anna</dc:creator>
 <dc:creator>Moulines, Eric</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Decentralized optimization algorithms have received much attention due to the
recent advances in network information processing. However, conventional
decentralized algorithms based on projected gradient descent are incapable of
handling high dimensional constrained problems, as the projection step becomes
computationally prohibitive to compute. To address this problem, this paper
adopts a projection-free optimization approach, a.k.a.~the Frank-Wolfe (FW) or
conditional gradient algorithm. We first develop a decentralized FW (DeFW)
algorithm from the classical FW algorithm. The convergence of the proposed
algorithm is studied by viewing the decentralized algorithm as an inexact FW
algorithm. Using a diminishing step size rule and letting $t$ be the iteration
number, we show that the DeFW algorithm's convergence rate is ${\cal O}(1/t)$
for convex objectives; is ${\cal O}(1/t^2)$ for strongly convex objectives with
the optimal solution in the interior of the constraint set; and is ${\cal
O}(1/\sqrt{t})$ towards a stationary point for smooth but non-convex
objectives. We then show that a consensus-based DeFW algorithm meets the above
guarantees with two communication rounds per iteration. Furthermore, we
demonstrate the advantages of the proposed DeFW algorithm on low-complexity
robust matrix completion and communication efficient sparse learning. Numerical
results on synthetic and real data are presented to support our findings.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Transactions on Automatic Control. 32 pages, 7
  figures</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:date>2017-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01216</dc:identifier>
 <dc:identifier>doi:10.1109/TAC.2017.2685559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01225</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Multi-Modal Image Correspondence Learning</dc:title>
 <dc:creator>Liu, Chen</dc:creator>
 <dc:creator>Wu, Jiajun</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:creator>Furukawa, Yasutaka</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Inference of correspondences between images from different modalities is an
extremely important perceptual ability that enables humans to understand and
recognize cross-modal concepts. In this paper, we consider an instance of this
problem that involves matching photographs of building interiors with their
corresponding floorplan. This is a particularly challenging problem because a
floorplan, as a stylized architectural drawing, is very different in appearance
from a color photograph. Furthermore, individual photographs by themselves
depict only a part of a floorplan (e.g., kitchen, bathroom, and living room).
We propose the use of a number of different neural network architectures for
this task, which are trained and evaluated on a novel large-scale dataset of 5
million floorplan images and 80 million associated photographs. Experimental
evaluation reveals that our neural network architectures are able to identify
visual cues that result in reliable matches across these two quite different
modalities. In fact, the trained networks are able to even outperform human
subjects in several challenging image matching problems. Our result implies
that neural networks are effective at perceptual tasks that require long
periods of reasoning even for humans to solve.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01227</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Blur Mapping: Exploiting High-Level Semantics by Deep Neural
  Networks</dc:title>
 <dc:creator>Ma, Kede</dc:creator>
 <dc:creator>Fu, Huan</dc:creator>
 <dc:creator>Liu, Tongliang</dc:creator>
 <dc:creator>Wang, Zhou</dc:creator>
 <dc:creator>Tao, Dacheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The human visual system excels at detecting local blur of visual images, but
the underlying mechanism is mysterious. Traditional views of blur such as
reduction in local or global high-frequency energy and loss of local phase
coherence have fundamental limitations. For example, they cannot well
discriminate flat regions from blurred ones. Here we argue that high-level
semantic information is critical in successfully detecting local blur.
Therefore, we resort to deep neural networks that are proficient in learning
high-level features and propose the first end-to-end local blur mapping
algorithm based on a fully convolutional network (FCN). We empirically show
that high-level features of deeper layers indeed play a more important role
than low-level features of shallower layers in resolving challenging
ambiguities for this task. We test the proposed method on a standard blur
detection benchmark and demonstrate that it significantly advances the
state-of-the-art (ODS F-score of 0.853). In addition, we explore the use of the
generated blur map in three applications, including blur region segmentation,
blur degree estimation, and blur magnification.
</dc:description>
 <dc:description>Comment: Tech report</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01230</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Pyramidal Residual Networks with Separated Stochastic Depth</dc:title>
 <dc:creator>Yamada, Yoshihiro</dc:creator>
 <dc:creator>Iwamura, Masakazu</dc:creator>
 <dc:creator>Kise, Koichi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  On general object recognition, Deep Convolutional Neural Networks (DCNNs)
achieve high accuracy. In particular, ResNet and its improvements have broken
the lowest error rate records. In this paper, we propose a method to
successfully combine two ResNet improvements, ResDrop and PyramidNet. We
confirmed that the proposed network outperformed the conventional methods; on
CIFAR-100, the proposed network achieved an error rate of 16.18% in contrast to
PiramidNet achieving that of 18.29% and ResNeXt 17.31%.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01234</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-way Particle Swarm Fusion</dc:title>
 <dc:creator>Liu, Chen</dc:creator>
 <dc:creator>Yan, Hang</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:creator>Furukawa, Yasutaka</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a novel MAP inference framework for Markov Random Field
(MRF) in parallel computing environments. The inference framework, dubbed Swarm
Fusion, is a natural generalization of the Fusion Move method. Every thread (in
a case of multi-threading environments) maintains and updates a solution. At
each iteration, a thread can generate arbitrary number of solution proposals
and take arbitrary number of concurrent solutions from the other threads to
perform multi-way fusion in updating its solution. The framework is general,
making popular existing inference techniques such as alpha-expansion, fusion
move, parallel alpha-expansion, and hierarchical fusion, its special cases. We
have evaluated the effectiveness of our approach against competing methods on
three problems of varying difficulties, in particular, the stereo, the optical
flow, and the layered depthmap estimation problems.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01235</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Turning an Urban Scene Video into a Cinemagraph</dc:title>
 <dc:creator>Yan, Hang</dc:creator>
 <dc:creator>Liu, Yebin</dc:creator>
 <dc:creator>Furukawa, Yasutaka</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes an algorithm that turns a regular video capturing urban
scenes into a high-quality endless animation, known as a Cinemagraph. The
creation of a Cinemagraph usually requires a static camera in a carefully
configured scene. The task becomes challenging for a regular video with a
moving camera and objects. Our approach first warps an input video into the
viewpoint of a reference camera. Based on the warped video, we propose
effective temporal analysis algorithms to detect regions with static geometry
and dynamic appearance, where geometric modeling is reliable and visually
attractive animations can be created. Lastly, the algorithm applies a sequence
of video processing techniques to produce a Cinemagraph movie. We have tested
the proposed approach on numerous challenging real scenes. To our knowledge,
this work is the first to automatically generate Cinemagraph animations from
regular movies in the wild.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01237</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cancerous Nuclei Detection and Scoring in Breast Cancer
  Histopathological Images</dc:title>
 <dc:creator>Faridi, Pegah</dc:creator>
 <dc:creator>Danyali, Habibollah</dc:creator>
 <dc:creator>Helfroush, Mohammad Sadegh</dc:creator>
 <dc:creator>Jahromi, Mojgan Akbarzadeh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Early detection and prognosis of breast cancer are feasible by utilizing
histopathological grading of biopsy specimens. This research is focused on
detection and grading of nuclear pleomorphism in histopathological images of
breast cancer. The proposed method consists of three internal steps. First,
unmixing colors of H&amp;E is used in the preprocessing step. Second, nuclei
boundaries are extracted incorporating the center of cancerous nuclei which are
detected by applying morphological operations and Difference of Gaussian filter
on the preprocessed image. Finally, segmented nuclei are scored to accomplish
one parameter of the Nottingham grading system for breast cancer. In this
approach, the nuclei area, chromatin density, contour regularity, and nucleoli
presence, are features for nuclear pleomorphism scoring. Experimental results
showed that the proposed algorithm, with an accuracy of 86.6%, made significant
advancement in detecting cancerous nuclei compared to existing methods in the
related literature.
</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01243</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vehicle Powertrain Connected Route Optimization for Conventional, Hybrid
  and Plug-in Electric Vehicles</dc:title>
 <dc:creator>Qiao, Zhiqian</dc:creator>
 <dc:creator>Karabasoglu, Orkun</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Most navigation systems use data from satellites to provide drivers with the
shortest-distance, shortest-time or highway-preferred paths. However, when the
routing decisions are made for advanced vehicles, there are other factors
affecting cost, such as vehicle powertrain type, battery state of charge (SOC)
and the change of component efficiencies under traffic conditions, which are
not considered by traditional routing systems. The impact of the trade-off
between distance and traffic on the cost of the trip might change with the type
of vehicle technology and component dynamics. As a result, the least-cost paths
might be different from the shortest-distance or shortest-time paths. In this
work, a novel routing strategy has been proposed where the decision-making
process benefits from the aforementioned information to result in a least-cost
path for drivers. We integrate vehicle powertrain dynamics into route
optimization and call this strategy as Vehicle Powertrain Connected Route
Optimization (VPCRO). We find that the optimal paths might change significantly
for all types of vehicle powertrains when VPCRO is used instead of
shortest-distance strategy. About 81% and 58% of trips were replaced by
different optimal paths with VPCRO when the vehicle type was Conventional
Vehicle (CV) and Electrified Vehicle (EV), respectively. Changed routes had
reduced travel costs on an average of 15% up to a maximum of 60% for CVs and on
an average of 6% up to a maximum of 30% for EVs. Moreover, it was observed that
3% and 10% of trips had different optimal paths for a plug-in hybrid electric
vehicle, when initial battery SOC changed from 90% to 60% and 40%,
respectively. Paper shows that using sensory information from vehicle
powertrain for route optimization plays an important role to minimize travel
costs.
</dc:description>
 <dc:description>Comment: Submitted to Transportation Research Part D: Transport and
  Environment</dc:description>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01251</identifier>
 <datestamp>2016-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Known Unknowns: Uncertainty Quality in Bayesian Neural Networks</dc:title>
 <dc:creator>Oliveira, Ramon</dc:creator>
 <dc:creator>Tabacof, Pedro</dc:creator>
 <dc:creator>Valle, Eduardo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We evaluate the uncertainty quality in neural networks using anomaly
detection. We extract uncertainty measures (e.g. entropy) from the predictions
of candidate models, use those measures as features for an anomaly detector,
and gauge how well the detector differentiates known from unknown classes. We
assign higher uncertainty quality to candidate models that lead to better
detectors. We also propose a novel method for sampling a variational
approximation of a Bayesian neural network, called One-Sample Bayesian
Approximation (OSBA). We experiment on two datasets, MNIST and CIFAR10. We
compare the following candidate neural network models: Maximum Likelihood,
Bayesian Dropout, OSBA, and --- for MNIST --- the standard variational
approximation. We show that Bayesian Dropout and OSBA provide better
uncertainty information than Maximum Likelihood, and are essentially equivalent
to the standard variational approximation, but much faster.
</dc:description>
 <dc:description>Comment: Workshop on Bayesian Deep Learning, NIPS 2016, Barcelona, Spain;
  EDIT: Changed analysis from Logit-AUC space to AUC (with changes to Figs. 2
  and 3)</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2016-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01253</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Image Category Discovery using a Transferred Similarity Function</dc:title>
 <dc:creator>Hsu, Yen-Chang</dc:creator>
 <dc:creator>Lv, Zhaoyang</dc:creator>
 <dc:creator>Kira, Zsolt</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Automatically discovering image categories in unlabeled natural images is one
of the important goals of unsupervised learning. However, the task is
challenging and even human beings define visual categories based on a large
amount of prior knowledge. In this paper, we similarly utilize prior knowledge
to facilitate the discovery of image categories. We present a novel end-to-end
network to map unlabeled images to categories as a clustering network. We
propose that this network can be learned with contrastive loss which is only
based on weak binary pair-wise constraints. Such binary constraints can be
learned from datasets in other domains as transferred similarity functions,
which mimic a simple knowledge transfer. We first evaluate our experiments on
the MNIST dataset as a proof of concept, based on predicted similarities
trained on Omniglot, showing a 99\% accuracy which significantly outperforms
clustering based approaches. Then we evaluate the discovery performance on
Cifar-10, STL-10, and ImageNet, which achieves both state-of-the-art accuracy
and shows it can be scalable to various large natural images.
</dc:description>
 <dc:description>Comment: 13 pages, 9 figures</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01254</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Symbolic Representation Learning for Heterogeneous Time-series
  Classification</dc:title>
 <dc:creator>Zhang, Shengdong</dc:creator>
 <dc:creator>Bahrampour, Soheil</dc:creator>
 <dc:creator>Ramakrishnan, Naveen</dc:creator>
 <dc:creator>Shah, Mohak</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we consider the problem of event classification with
multi-variate time series data consisting of heterogeneous (continuous and
categorical) variables. The complex temporal dependencies between the variables
combined with sparsity of the data makes the event classification problem
particularly challenging. Most state-of-art approaches address this either by
designing hand-engineered features or breaking up the problem over homogeneous
variates. In this work, we propose and compare three representation learning
algorithms over symbolized sequences which enables classification of
heterogeneous time-series data using a deep architecture. The proposed
representations are trained jointly along with the rest of the network
architecture in an end-to-end fashion that makes the learned features
discriminative for the given task. Experiments on three real-world datasets
demonstrate the effectiveness of the proposed approaches.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01256</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Panoramic Structure from Motion via Geometric Relationship Detection</dc:title>
 <dc:creator>Ikehata, Satoshi</dc:creator>
 <dc:creator>Boyadzhiev, Ivaylo</dc:creator>
 <dc:creator>Shan, Qi</dc:creator>
 <dc:creator>Furukawa, Yasutaka</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the problem of Structure from Motion (SfM) for indoor
panoramic image streams, extremely challenging even for the state-of-the-art
due to the lack of textures and minimal parallax. The key idea is the fusion of
single-view and multi-view reconstruction techniques via geometric relationship
detection (e.g., detecting 2D lines as coplanar in 3D). Rough geometry suffices
to perform such detection, and our approach utilizes rough surface normal
estimates from an image-to-normal deep network to discover geometric
relationships among lines. The detected relationships provide exact geometric
constraints in our line-based linear SfM formulation. A constrained linear
least squares is used to reconstruct a 3D model and camera motions, followed by
the bundle adjustment. We have validated our algorithm on challenging datasets,
outperforming various state-of-the-art reconstruction techniques.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01260</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time Collision Handling in Railway Network:An Agent-based Approach</dc:title>
 <dc:creator>Dalapati, Poulami</dc:creator>
 <dc:creator>Padhy, Abhijeet</dc:creator>
 <dc:creator>Mishra, Bhawana</dc:creator>
 <dc:creator>Dutta, Animesh</dc:creator>
 <dc:creator>Bhattacharya, Swapan</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Advancement in intelligent transportation systems with complex operations
requires autonomous planning and management to avoid collisions in day-to-day
traffic. As failure and/or inadequacy in traffic safety system are
life-critical, such collisions must be detected and resolved in an efficient
way to manage continuously rising traffic. In this paper, we address different
types of collision scenarios along with their early detection and resolution
techniques in a complex railway system. In order to handle collisions
dynamically in distributed manner, a novel agent based solution approach is
proposed using the idea of max-sum algorithm, where each agent (train agent,
station agent, and junction agent) communicates and cooperates with others to
generate a good feasible solution that keeps the system in a safe state, i.e.,
collision free. We implement the proposed mechanism in Java Agent DEvelopment
Framework (JADE). The results are evaluated with exhaustive experiments and
compared with different existing collision handling methods to show the
efficiency of our proposed approach.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01263</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Complexity of the Quantified Bit-Vector Arithmetic with Binary
  Encoding</dc:title>
 <dc:creator>Jon&#xe1;&#x161;, Martin</dc:creator>
 <dc:creator>Strej&#x10d;ek, Jan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We study the precise computational complexity of deciding satisfiability of
first-order quantified formulas over the theory of fixed-size bit-vectors with
binary-encoded bit-widths and constants. This problem is known to be in
EXPSPACE and to be NEXPTIME-hard. We show that this problem is complete for the
complexity class AEXP(poly) -- the class of problems decidable by an
alternating Turing machine using exponential time, but only a polynomial number
of alternations between existential and universal states.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01264</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Generation Value Networks for Content Delivery</dc:title>
 <dc:creator>Iellamo, Stefano</dc:creator>
 <dc:creator>Klas, Guenter</dc:creator>
 <dc:creator>Smith, Kevin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper we paint a broad picture of the Internet content delivery
market, by taking into consideration both economical and technical challenges
that might drive the interactions among the stakeholders in the future. We
focus on a few disrupting factors, namely ubiquitous encryption, traffic boost,
network scalability, latency needs and network control; and try to figure out
whether the current model (CDN) is robust against their variation, which
optimization can be envisioned and how the most accredited option (ICN) can be
of help.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01276</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Tractable Delay Analysis in Large Wireless Networks</dc:title>
 <dc:creator>Zhong, Yi</dc:creator>
 <dc:creator>Haenggi, Martin</dc:creator>
 <dc:creator>Zheng, Fu-Chun</dc:creator>
 <dc:creator>Zhang, Wenyi</dc:creator>
 <dc:creator>Quek, Tony Q. S.</dc:creator>
 <dc:creator>Nie, Weili</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Meeting the diverse delay requirements of next-generation wireless
communication networks is one of the most critical goals of wireless system
design. Though the delay of point-to-point communications has been well
investigated using classical queueing theory, the delay of multi-point to
multi-point communications has not been explored in depth. The main technical
difficulty lies in the interacting queues problem, in which the service rate is
coupled with the statuses of other queues. In this article, we elaborate on the
main challenges of delay analysis in large wireless networks. Several promising
approaches to bypass these difficulties are proposed and summarized to provide
useful guidance.
</dc:description>
 <dc:description>Comment: 17 pages, 4 figures, 1 table, submitted to IEEE Communications
  Magazine</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01277</identifier>
 <datestamp>2017-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cryptocurrency Portfolio Management with Deep Reinforcement Learning</dc:title>
 <dc:creator>Jiang, Zhengyao</dc:creator>
 <dc:creator>Liang, Jinjun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Portfolio management is the decision-making process of allocating an amount
of fund into different financial investment products. Cryptocurrencies are
electronic and decentralized alternatives to government-issued money, with
Bitcoin as the best-known example of a cryptocurrency. This paper presents a
model-less convolutional neural network with historic prices of a set of
financial assets as its input, outputting portfolio weights of the set. The
network is trained with 0.7 years' price data from a cryptocurrency exchange.
The training is done in a reinforcement manner, maximizing the accumulative
return, which is regarded as the reward function of the network. Backtest
trading experiments with trading period of 30 minutes is conducted in the same
market, achieving 10-fold returns in 1.8 months' periods. Some recently
published portfolio selection strategies are also used to perform the same
back-tests, whose results are compared with the neural network. The network is
not limited to cryptocurrency, but can be applied to any other financial
markets.
</dc:description>
 <dc:description>Comment: accepted by Intelligent Systems Conference (IntelliSys) 2017</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01282</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In-network Compression for Multiterminal Cascade MIMO Systems</dc:title>
 <dc:creator>Aguerri, Inaki Estella</dc:creator>
 <dc:creator>Zaidi, Abdellatif</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the problem of receive beamforming in uplink cascade multiple-input
multiple-output (MIMO) systems as an instance of that of cascade multiterminal
source coding for lossy function computation. Using this connection, we develop
two coding schemes for the second and show that their application leads to
beamforming schemes for the first. In the first coding scheme, each terminal in
the cascade sends a description of the source that it observes; the decoder
reconstructs all sources, lossily, and then computes an estimate of the desired
function. This scheme improves upon standard routing in that every terminal
only compresses the innovation of its source w.r.t. the descriptions that are
sent by the previous terminals in the cascade. In the second scheme, the
desired function is computed gradually in the cascade network, and each
terminal sends a finer description of it. In the context of uplink cascade MIMO
systems, the application of these two schemes leads to centralized
receive-beamforming and distributed receive-beamforming, respectively.
Numerical results illustrate the performance of the proposed methods and show
that they outperform standard routing.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Communications</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01284</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Structure and Resilience of the Dark Network</dc:title>
 <dc:creator>De Domenico, M.</dc:creator>
 <dc:creator>Arenas, A.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  While the statistical and resilience properties of the Internet are no more
changing significantly across time, the Darknet, a network devoted to keep
anonymous its traffic, still experiences rapid changes to improve the security
of its users. Here, we study the structure of the Darknet and we find that its
topology is rather peculiar, being characterized by non-homogenous distribution
of connections -- typical of scale-free networks --, very short path lengths
and high clustering -- typical of small-world networks -- and lack of a core of
highly connected nodes.
  We propose a model to reproduce such features, demonstrating that the
mechanisms used to improve cyber-security are responsible for the observed
topology. Unexpectedly, we reveal that its peculiar structure makes the Darknet
much more resilient than the Internet -- used as a benchmark for comparison at
a descriptive level -- to random failures, targeted attacks and cascade
failures, as a result of adaptive changes in response to the attempts of
dismantling the network across time.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01284</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.95.022313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01288</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Point Pair Feature based Object Detection for Random Bin Picking</dc:title>
 <dc:creator>Abbeloos, Wim</dc:creator>
 <dc:creator>Goedem&#xe9;, Toon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Point pair features are a popular representation for free form 3D object
detection and pose estimation. In this paper, their performance in an
industrial random bin picking context is investigated. A new method to generate
representative synthetic datasets is proposed. This allows to investigate the
influence of a high degree of clutter and the presence of self similar
features, which are typical to our application. We provide an overview of
solutions proposed in literature and discuss their strengths and weaknesses. A
simple heuristic method to drastically reduce the computational complexity is
introduced, which results in improved robustness, speed and accuracy compared
to the naive approach.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01288</dc:identifier>
 <dc:identifier>doi:10.1109/CRV.2016.59</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01294</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Message Passing Multi-Agent GANs</dc:title>
 <dc:creator>Ghosh, Arnab</dc:creator>
 <dc:creator>Kulharia, Viveka</dc:creator>
 <dc:creator>Namboodiri, Vinay</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Communicating and sharing intelligence among agents is an important facet of
achieving Artificial General Intelligence. As a first step towards this
challenge, we introduce a novel framework for image generation: Message Passing
Multi-Agent Generative Adversarial Networks (MPM GANs). While GANs have
recently been shown to be very effective for image generation and other tasks,
these networks have been limited to mostly single generator-discriminator
networks. We show that we can obtain multi-agent GANs that communicate through
message passing to achieve better image generation. The objectives of the
individual agents in this framework are two fold: a co-operation objective and
a competing objective. The co-operation objective ensures that the message
sharing mechanism guides the other generator to generate better than itself
while the competing objective encourages each generator to generate better than
its counterpart. We analyze and visualize the messages that these GANs share
among themselves in various scenarios. We quantitatively show that the message
sharing formulation serves as a regularizer for the adversarial training.
Qualitatively, we show that the different generators capture different traits
of the underlying data distribution.
</dc:description>
 <dc:description>Comment: The first 2 authors contributed equally for this work</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01313</identifier>
 <datestamp>2017-01-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Capacity of Discrete-Time Laguerre Channel</dc:title>
 <dc:creator>Esmaeili, Hossein</dc:creator>
 <dc:creator>Salehi, Jawad</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, new upper and lower bounds are proposed for the capacity of
discrete-time Laguerre channel. Laguerre behavior is used to model various
types of optical systems and networks such as optical amplifiers, short
distance visible light communication systems with direct detection and coherent
code division multiple access (CDMA) networks. Bounds are derived for short
distance visible light communication systems and coherent CDMA networks. These
bounds are separated in three main cases: when both average and peak power
constraints are imposed, when peak power constraint is inactive and when only
peak power constraint is active.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2016-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01316</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ranking Biomarkers Through Mutual Information</dc:title>
 <dc:creator>Sechidis, Konstantinos</dc:creator>
 <dc:creator>Turner, Emily</dc:creator>
 <dc:creator>Metcalfe, Paul D.</dc:creator>
 <dc:creator>Weatherall, James</dc:creator>
 <dc:creator>Brown, Gavin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  We study information theoretic methods for ranking biomarkers. In clinical
trials there are two, closely related, types of biomarkers: predictive and
prognostic, and disentangling them is a key challenge. Our first step is to
phrase biomarker ranking in terms of optimizing an information theoretic
quantity. This formalization of the problem will enable us to derive rankings
of predictive/prognostic biomarkers, by estimating different, high dimensional,
conditional mutual information terms. To estimate these terms, we suggest
efficient low dimensional approximations, and we derive an empirical Bayes
estimator, which is suitable for small or sparse datasets. Finally, we
introduce a new visualisation tool that captures the prognostic and the
predictive strength of a set of biomarkers. We believe this representation will
prove to be a powerful tool in biomarker discovery.
</dc:description>
 <dc:description>Comment: Accepted at NIPS 2016 Workshop on Machine Learning for Health</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01323</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stereo image de-fencing using smartphones</dc:title>
 <dc:creator>Jonna, Sankaraganesh</dc:creator>
 <dc:creator>Satapathy, Sukla</dc:creator>
 <dc:creator>Sahay, Rajiv R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Conventional approaches to image de-fencing have limited themselves to using
only image data in adjacent frames of the captured video of an approximately
static scene. In this work, we present a method to harness disparity using a
stereo pair of fenced images in order to detect fence pixels. Tourists and
amateur photographers commonly carry smartphones/phablets which can be used to
capture a short video sequence of the fenced scene. We model the formation of
the occluded frames in the captured video. Furthermore, we propose an
optimization framework to estimate the de-fenced image using the total
variation prior to regularize the ill-posed problem.
</dc:description>
 <dc:description>Comment: Under review as a conference paper</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01325</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Code with Dynamic Staging</dc:title>
 <dc:creator>Danilewski, Piotr</dc:creator>
 <dc:creator>Slusallek, Philipp</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  When creating a new domain-specific language (DSL) it is common to embed it
as a part of a flexible host language, rather than creating it entirely from
scratch. The semantics of an embedded DSL (EDSL) is either given directly as a
set of functions (shallow embedding), or an AST is constructed that is later
processed (deep embedding). Typically, the deep embedding is used when the EDSL
specifies domain-specific optimizations (DSO) in a form of AST transformations.
  In this paper we show that deep embedding is not necessary to specify most
optimizations. We define language semantics as action functions that are
executed during parsing. These actions build incrementally a new, arbitrary
complex program function.
  The EDSL designer is able to specify many aspects of the semantics as a
runnable code, such as variable scoping rules, custom type checking, arbitrary
control flow structures, or DSO. A sufficiently powerful staging mechanism
helps assembling the code from different actions, as well as evaluate the
semantics in arbitrarily many stages. In the end, we obtain code that is as
efficient as one written by hand.
  We never create any object representation of the code. No external traversing
algorithm is used to process the code. All program fragments are functions with
their entire semantics embedded within the function bodies. This approach
allows reusing the code between EDSL and the host language, as well as
combining actions of many different EDSLs.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures, 14 listings</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01335</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized Incremental Construction for the Hausdorff Voronoi Diagram of
  point clusters</dc:title>
 <dc:creator>Khramtcova, Elena</dc:creator>
 <dc:creator>Papadopoulou, Evanthia</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  This paper applies the randomized incremental construction (RIC) framework to
computing the Hausdorff Voronoi diagram of a family of k clusters of points in
the plane. The total number of points is n. The diagram is a generalization of
Voronoi diagrams based on the Hausdorff distance function. The combinatorial
complexity of the Hausdorff Voronoi diagram is O(n+m), where m is the total
number of crossings between pairs of clusters. For non-crossing clusters (m=0),
our algorithm works in expected O(n log n + k log n log k) time and
deterministic
  O(n) space. For arbitrary clusters (m=O(n^2)), the algorithm runs in expected
O((m+n log k) log n) time and O(m +n log k) space. When clusters cross,
bisectors are disconnected curves resulting in disconnected Voronoi regions
that challenge the incremental construction. This paper applies the RIC
paradigm to a Voronoi diagram with disconnected regions and disconnected
bisectors, for the first time.
</dc:description>
 <dc:description>Comment: 18 pages, 4 figures</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01337</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification With an Edge: Improving Semantic Image Segmentation with
  Boundary Detection</dc:title>
 <dc:creator>Marmanis, Dimitrios</dc:creator>
 <dc:creator>Schindler, Konrad</dc:creator>
 <dc:creator>Wegner, Jan Dirk</dc:creator>
 <dc:creator>Galliani, Silvano</dc:creator>
 <dc:creator>Datcu, Mihai</dc:creator>
 <dc:creator>Stilla, Uwe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an end-to-end trainable deep convolutional neural network (DCNN)
for semantic segmentation with built-in awareness of semantically meaningful
boundaries. Semantic segmentation is a fundamental remote sensing task, and
most state-of-the-art methods rely on DCNNs as their workhorse. A major reason
for their success is that deep networks learn to accumulate contextual
information over very large windows (receptive fields). However, this success
comes at a cost, since the associated loss of effecive spatial resolution
washes out high-frequency details and leads to blurry object boundaries. Here,
we propose to counter this effect by combining semantic segmentation with
semantically informed edge detection, thus making class-boundaries explicit in
the model, First, we construct a comparatively simple, memory-efficient model
by adding boundary detection to the Segnet encoder-decoder architecture.
Second, we also include boundary detection in FCN-type models and set up a
high-end classifier ensemble. We show that boundary detection significantly
improves semantic segmentation with CNNs. Our high-end ensemble achieves &gt; 90%
overall accuracy on the ISPRS Vaihingen benchmark.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01337</dc:identifier>
 <dc:identifier>ISPRS Journal of Photogrammetry and Remote Sensing, Volume 135,
  January 2018, Pages 158-172, ISSN 0924-2716,
  https://doi.org/10.1016/j.isprsjprs.2017.11.009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01339</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirical Research Plan: Effects of Sketching on Program Comprehension</dc:title>
 <dc:creator>Baltes, Sebastian</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Sketching is an important means of communication in software engineering
practice. Yet, there is little research investigating the use of sketches. We
want to contribute a better understanding of sketching, in particular its use
during program comprehension. We propose a controlled experiment to investigate
the effectiveness and efficiency of program comprehension with the support of
sketches as well as what sketches are used in what way.
</dc:description>
 <dc:description>Comment: 5 pages, 0 figures, Proc. International Conference on Agile Software
  Development (XP'16). Volume 251 of the book series Lecture Notes in Business
  Information Processing (LNBIP). Springer, 2016</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01339</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-33515-5_26</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01340</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>We used Neural Networks to Detect Clickbaits: You won't believe what
  happened Next!</dc:title>
 <dc:creator>Anand, Ankesh</dc:creator>
 <dc:creator>Chakraborty, Tanmoy</dc:creator>
 <dc:creator>Park, Noseong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Online content publishers often use catchy headlines for their articles in
order to attract users to their websites. These headlines, popularly known as
clickbaits, exploit a user's curiosity gap and lure them to click on links that
often disappoint them. Existing methods for automatically detecting clickbaits
rely on heavy feature engineering and domain knowledge. Here, we introduce a
neural network architecture based on Recurrent Neural Networks for detecting
clickbaits. Our model relies on distributed word representations learned from a
large unannotated corpora, and character embeddings learned via Convolutional
Neural Networks. Experimental results on a dataset of news headlines show that
our model outperforms existing techniques for clickbait detection with an
accuracy of 0.98 with F1-score of 0.98 and ROC-AUC of 0.99.
</dc:description>
 <dc:description>Comment: Accepted to the European Conference on Information Retrieval (ECIR),
  2017</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01341</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Highly Efficient Regression for Scalable Person Re-Identification</dc:title>
 <dc:creator>Wang, Hanxiao</dc:creator>
 <dc:creator>Gong, Shaogang</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Existing person re-identification models are poor for scaling up to large
data required in real-world applications due to: (1) Complexity: They employ
complex models for optimal performance resulting in high computational cost for
training at a large scale; (2) Inadaptability: Once trained, they are
unsuitable for incremental update to incorporate any new data available. This
work proposes a truly scalable solution to re-id by addressing both problems.
Specifically, a Highly Efficient Regression (HER) model is formulated by
embedding the Fisher's criterion to a ridge regression model for very fast
re-id model learning with scalable memory/storage usage. Importantly, this new
HER model supports faster than real-time incremental model updates therefore
making real-time active learning feasible in re-id with human-in-the-loop.
Extensive experiments show that such a simple and fast model not only
outperforms notably the state-of-the-art re-id methods, but also is more
scalable to large data with additional benefits to active learning for reducing
human labelling effort in re-id deployment.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01345</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human-In-The-Loop Person Re-Identification</dc:title>
 <dc:creator>Wang, Hanxiao</dc:creator>
 <dc:creator>Gong, Shaogang</dc:creator>
 <dc:creator>Zhu, Xiatian</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current person re-identification (re-id) methods assume that (1) pre-labelled
training data are available for every camera pair, (2) the gallery size for
re-identification is moderate. Both assumptions scale poorly to real-world
applications when camera network size increases and gallery size becomes large.
Human verification of automatic model ranked re-id results becomes inevitable.
In this work, a novel human-in-the-loop re-id model based on Human Verification
Incremental Learning (HVIL) is formulated which does not require any
pre-labelled training data to learn a model, therefore readily scalable to new
camera pairs. This HVIL model learns cumulatively from human feedback to
provide instant improvement to re-id ranking of each probe on-the-fly enabling
the model scalable to large gallery sizes. We further formulate a Regularised
Metric Ensemble Learning (RMEL) model to combine a series of incrementally
learned HVIL models into a single ensemble model to be used when human feedback
becomes unavailable.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01349</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A One class Classifier based Framework using SVDD : Application to an
  Imbalanced Geological Dataset</dc:title>
 <dc:creator>Chaki, Soumi</dc:creator>
 <dc:creator>Verma, Akhilesh Kumar</dc:creator>
 <dc:creator>Routray, Aurobinda</dc:creator>
 <dc:creator>Mohanty, William K.</dc:creator>
 <dc:creator>Jenamani, Mamata</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Evaluation of hydrocarbon reservoir requires classification of petrophysical
properties from available dataset. However, characterization of reservoir
attributes is difficult due to the nonlinear and heterogeneous nature of the
subsurface physical properties. In this context, present study proposes a
generalized one class classification framework based on Support Vector Data
Description (SVDD) to classify a reservoir characteristic water saturation into
two classes (Class high and Class low) from four logs namely gamma ray, neutron
porosity, bulk density, and P sonic using an imbalanced dataset. A comparison
is carried out among proposed framework and different supervised classification
algorithms in terms of g metric means and execution time. Experimental results
show that proposed framework has outperformed other classifiers in terms of
these performance evaluators. It is envisaged that the classification analysis
performed in this study will be useful in further reservoir modeling.
</dc:description>
 <dc:description>Comment: presented at IEEE Students Technology Symposium (TechSym), 28
  February to 2 March 2014, IIT Kharagpur, India. 6 pages, 7 figures, 2tables</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01352</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate-Compatible Punctured Polar Codes: Optimal Construction Based on
  Polar Spectra</dc:title>
 <dc:creator>Niu, Kai</dc:creator>
 <dc:creator>Dai, Jincheng</dc:creator>
 <dc:creator>Chen, Kai</dc:creator>
 <dc:creator>Lin, Jiaru</dc:creator>
 <dc:creator>Zhang, Q. T.</dc:creator>
 <dc:creator>Vasilakos, Athanasios V.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Polar codes are the first class of constructive channel codes achieving the
symmetric capacity of the binary-input discrete memoryless channels. But the
corresponding code length is limited to the power of two. In this paper, we
establish a systematic framework to design the rate-compatible punctured polar
(RCPP) codes with arbitrary code length. A new theoretic tool, called polar
spectra, is proposed to count the number of paths on the code tree with the
same number of zeros or ones respectively. Furthermore, a spectrum distance SD0
(SD1) and a joint spectrum distance (JSD) are presented as performance criteria
to optimize the puncturing tables. For the capacity-zero puncturing mode
(punctured bits are unknown to the decoder), we propose a quasi-uniform
puncturing algorithm, analyze the number of equivalent puncturings and prove
that this scheme can maximize SD1 and JSD. Similarly, for the capacity-one mode
(punctured bits are known to the decoder), we also devise a reversal
quasi-uniform puncturing scheme and prove that it has the maximum SD0 and JSD.
Both schemes have a universal puncturing table without any exhausted search.
These optimal RCPP codes outperform the performance of turbo codes in LTE
wireless communication systems.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01356</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diagnostic Prediction Using Discomfort Drawings</dc:title>
 <dc:creator>Zhang, Cheng</dc:creator>
 <dc:creator>Kjellstrom, Hedvig</dc:creator>
 <dc:creator>Bertilson, Bo C.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we explore the possibility to apply machine learning to make
diagnostic predictions using discomfort drawings. A discomfort drawing is an
intuitive way for patients to express discomfort and pain related symptoms.
These drawings have proven to be an effective method to collect patient data
and make diagnostic decisions in real-life practice. A dataset from real-world
patient cases is collected for which medical experts provide diagnostic labels.
Next, we extend a factorized multimodal topic model, Inter-Battery Topic Model
(IBTM), to train a system that can make diagnostic predictions given an unseen
discomfort drawing. Experimental results show reasonable predictions of
diagnostic labels given an unseen discomfort drawing. The positive result
indicates a significant potential of machine learning to be used for parts of
the pain diagnostic process and to be a decision support system for physicians
and other health care personnel.
</dc:description>
 <dc:description>Comment: NIPS 2016 Workshop on Machine Learning for Health</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01357</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geodesic equations and their numerical solutions in geodetic and
  Cartesian coordinates on an oblate spheroid</dc:title>
 <dc:creator>Panou, G.</dc:creator>
 <dc:creator>Korakitis, R.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  The direct geodesic problem on an oblate spheroid is described as an initial
value problem and is solved numerically in geodetic and Cartesian coordinates.
The geodesic equations are formulated by means of the theory of differential
geometry. The initial value problem under consideration is reduced to a system
of first-order ordinary differential equations, which is solved using a
numerical method. The solution provides the coordinates and the azimuths at any
point along the geodesic. The Clairaut constant is not assumed known but it is
computed, allowing to check the precision of the method. An extended data set
of geodesics is used, in order to evaluate the performance of the method in
each coordinate system. The results for the direct geodesic problem are
validated by comparison to Karney's method. We conclude that a complete,
stable, precise, accurate and fast solution of the problem in Cartesian
coordinates is accomplished.
</dc:description>
 <dc:description>Comment: Submitted to an academic Journal</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01361</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Repairing Reed-Solomon Codes With Multiple Erasures</dc:title>
 <dc:creator>Dau, Hoang</dc:creator>
 <dc:creator>Duursma, Iwan</dc:creator>
 <dc:creator>Kiah, Han Mao</dc:creator>
 <dc:creator>Milenkovic, Olgica</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Despite their exceptional error-correcting properties, Reed-Solomon (RS)
codes have been overlooked in distributed storage applications due to the
common belief that they have poor repair bandwidth: A naive repair approach
would require the whole file to be reconstructed in order to recover a single
erased codeword symbol. In a recent work, Guruswami and Wootters (STOC'16)
proposed a single-erasure repair method for RS codes that achieves the optimal
repair bandwidth amongst all linear encoding schemes. Their key idea is to
recover the erased symbol by collecting a sufficiently large number of its
traces, each of which can be constructed from a number of traces of other
symbols. As all traces belong to a subfield of the defining field of the RS
code and many of them are linearly dependent, the total repair bandwidth is
significantly reduced compared to that of the naive repair scheme. We extend
the trace collection technique to cope with multiple erasures.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01367</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Asymptotically Optimal Contextual Bandit Algorithm Using Hierarchical
  Structures</dc:title>
 <dc:creator>Neyshabouri, Mohammadreza Mohaghegh</dc:creator>
 <dc:creator>Gokcesu, Kaan</dc:creator>
 <dc:creator>Ozkan, Huseyin</dc:creator>
 <dc:creator>Kozat, Suleyman S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose online algorithms for sequential learning in the contextual
multi-armed bandit setting. Our approach is to partition the context space and
then optimally combine all of the possible mappings between the partition
regions and the set of bandit arms in a data driven manner. We show that in our
approach, the best mapping is able to approximate the best arm selection policy
to any desired degree under mild Lipschitz conditions. Therefore, we design our
algorithms based on the optimal adaptive combination and asymptotically achieve
the performance of the best mapping as well as the best arm selection policy.
This optimality is also guaranteed to hold even in adversarial environments
since we do not rely on any statistical assumptions regarding the contexts or
the loss of the bandit arms. Moreover, we design efficient implementations for
our algorithms in various hierarchical partitioning structures such as
lexicographical or arbitrary position splitting and binary trees (and several
other partitioning examples). For instance, in the case of binary tree
partitioning, the computational complexity is only log-linear in the number of
regions in the finest partition. In conclusion, we provide significant
performance improvements by introducing upper bounds (w.r.t. the best arm
selection policy) that are mathematically proven to vanish in the average loss
per round sense at a faster rate compared to the state-of-the-art. Our
experimental work extensively covers various scenarios ranging from bandit
settings to multi-class classification with real and synthetic data. In these
experiments, we show that our algorithms are highly superior over the
state-of-the-art techniques while maintaining the introduced mathematical
guarantees and a computationally decent scalability.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01370</identifier>
 <datestamp>2017-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimizing the Continuous Diameter when Augmenting a Geometric Tree with
  a Shortcut</dc:title>
 <dc:creator>De Carufel, Jean-Lou</dc:creator>
 <dc:creator>Grimm, Carsten</dc:creator>
 <dc:creator>Maheshwari, Anil</dc:creator>
 <dc:creator>Schirra, Stefan</dc:creator>
 <dc:creator>Smid, Michiel</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>68U05, 05C85</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  We augment a tree $T$ with a shortcut $pq$ to minimize the largest distance
between any two points along the resulting augmented tree $T+pq$. We study this
problem in a continuous and geometric setting where $T$ is a geometric tree in
the Euclidean plane, where a shortcut is a line segment connecting any two
points along the edges of $T$, and we consider all points on $T+pq$ (i.e.,
vertices and points along edges) when determining the largest distance along
$T+pq$. We refer to the largest distance between any two points along edges as
the continuous diameter to distinguish it from the discrete diameter, i.e., the
largest distance between any two vertices.
  We establish that a single shortcut is sufficient to reduce the continuous
diameter of a geometric tree $T$ if and only if the intersection of all
diametral paths of $T$ is neither a line segment nor a single point. We
determine an optimal shortcut for a geometric tree with $n$ straight-line edges
in $O(n \log n)$ time. Apart from the running time, our results extend to
geometric trees whose edges are rectifiable curves. The algorithm for trees
generalizes our algorithm for paths.
</dc:description>
 <dc:description>Comment: A preliminary version of this work was presented at the 15th
  International Symposium on Algorithms and Data Structures (WADS~2017), July
  31 to August 2, 2017, St. John's, NL, Canada</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-10-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01375</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consensus analysis of large-scale nonlinear homogeneous multi-agent
  formations with polynomial dynamics</dc:title>
 <dc:creator>Massioni, Paolo</dc:creator>
 <dc:creator>Scorletti, G&#xe9;rard</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Drawing inspiration from the theory of linear &quot;decomposable systems&quot;, we
provide a method, based on linear matrix inequalities (LMIs), which makes it
possible to prove the convergence (or consensus) of a set of interacting agents
with polynomial dynamic. We also show that the use of a generalised version of
the famous Kalman-Yakubovic-Popov lemma allows the development of an LMI test
whose size does not depend on the number of agents. The method is validated
experimentally on two academic examples.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01380</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On-Demand Learning for Deep Image Restoration</dc:title>
 <dc:creator>Gao, Ruohan</dc:creator>
 <dc:creator>Grauman, Kristen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While machine learning approaches to image restoration offer great promise,
current methods risk training models fixated on performing well only for image
corruption of a particular level of difficulty---such as a certain level of
noise or blur. First, we examine the weakness of conventional &quot;fixated&quot; models
and demonstrate that training general models to handle arbitrary levels of
corruption is indeed non-trivial. Then, we propose an on-demand learning
algorithm for training image restoration models with deep convolutional neural
networks. The main idea is to exploit a feedback mechanism to self-generate
training instances where they are needed most, thereby learning models that can
generalize across difficulty levels. On four restoration tasks---image
inpainting, pixel interpolation, image deblurring, and image denoising---and
three diverse datasets, our approach consistently outperforms both the status
quo training procedure and curriculum learning alternatives.
</dc:description>
 <dc:description>Comment: International Conference on Computer Vision (ICCV), Venice, Italy,
  Oct. 2017</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01385</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In Quest for Proper Mediums for Technology Transfer in Software
  Engineering</dc:title>
 <dc:creator>Grigoleit, F.</dc:creator>
 <dc:creator>Vetr&#xf2;, A.</dc:creator>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:creator>B&#xf6;hm, W.</dc:creator>
 <dc:creator>Diebold, P.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Successful transfer of the results of research projects into practice is of
great interest to all project participants. It can be assumed that different
transfer mediums fulfill technology transfer (TT) with different levels of
success and that they are impaired by different kinds of barriers. The goal of
this study is to gain a better understanding about the different mediums used
for TT in software engineering, and to identify barriers weakening the success
of the application of such mediums. We conducted an exploratory study
implemented by a survey in the context of a German research project with a
broad range of used mediums. The main reported barriers were low expectations
of usefulness, no awareness of existence, lack of resources, or inadequateness
in terms of outdated material or being in an immature state. We interpreted our
results as symptoms of a lack of a dissemination plan in the project. Further
work will be needed to explore the implications for the transfer of research
results (knowledge and techniques) to practice.
</dc:description>
 <dc:description>Comment: Proceedings of the International Conference on Empirical Software
  Engineering and Measurement, 2015</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01385</dc:identifier>
 <dc:identifier>doi:10.1109/ESEM.2015.7321203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01386</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universality of the SIS prevalence in networks</dc:title>
 <dc:creator>Van Mieghem, Piet</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  Epidemic models are increasingly used in real-world networks to understand
diffusion phenomena (such as the spread of diseases, emotions, innovations,
failures) or the transport of information (such as news, memes in social
on-line networks). A new analysis of the prevalence, the expected number of
infected nodes in a network, is presented and physically interpreted. The
analysis method is based on spectral decomposition and leads to a universal,
analytic curve, that can bound the time-varying prevalence in any finite time
interval. Moreover, that universal curve also applies to various types of
Susceptible-Infected-Susceptible (SIS) (and Susceptible-Infected-Removed (SIR))
infection processes, with both homogenous and heterogeneous infection
characteristics (curing and infection rates), in temporal and even disconnected
graphs and in SIS processes with and without self-infections. The accuracy of
the universal curve is comparable to that of well-established mean-field
approximations.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01392</identifier>
 <datestamp>2017-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Extended Treatment of Uncertainty Constrained robotic Exploration: An
  Integrated Exploration Planner</dc:title>
 <dc:creator>Ivanov, Alexander</dc:creator>
 <dc:creator>Campbell, Mark</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Efficient robotic exploration of unknown, sensor limited,
global-information-deficient environments poses unique challenges to path
planning algorithms. In these difficult environments, no deterministic
guarantees on path completion and mission success can be made in general.
Integrated Exploration (IE), which strives to combine localization and
exploration, must be solved in order to create an autonomous robotic system
capable of long term operation in new and challenging environments. This paper
formulates a probabilistic framework which allows the creation of exploration
algorithms providing probabilistic guarantees of success. A novel connection is
made between the Hamiltonian Path Problem and exploration. The Guaranteed
Probabilistic Information Explorer (G-PIE) is developed for the IE problem,
providing a probabilistic guarantee on path completion, and asymptotic
optimality of exploration. A receding horizon formulation, dubbed RH-PIE, is
presented which addresses the exponential complexity present in G-PIE. Finally,
RH-PIE planner is verified via autonomous, hardware-in-the-loop experiments.
</dc:description>
 <dc:description>Comment: 18 Pages, 13 figures</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01395</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The communication-hiding pipelined BiCGStab method for the parallel
  solution of large unsymmetric linear systems</dc:title>
 <dc:creator>Cools, Siegfried</dc:creator>
 <dc:creator>Vanroose, Wim</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>65F10</dc:subject>
 <dc:description>  A High Performance Computing alternative to traditional Krylov subspace
methods, pipelined Krylov subspace solvers offer better scalability in the
strong scaling limit compared to standard Krylov subspace methods for large and
sparse linear systems. The typical synchronization bottleneck is mitigated by
overlapping time-consuming global communication phases with local computations
in the algorithm. This paper describes a general framework for deriving the
pipelined variant of any Krylov subspace algorithm. The proposed framework was
implicitly used to derive the pipelined Conjugate Gradient (p-CG) method in
&quot;Hiding global synchronization latency in the preconditioned Conjugate Gradient
algorithm&quot; by P. Ghysels and W. Vanroose, Parallel Computing, 40(7):224--238,
2014. The pipelining framework is subsequently illustrated by formulating a
pipelined version of the BiCGStab method for the solution of large unsymmetric
linear systems on parallel hardware. A residual replacement strategy is
proposed to account for the possible loss of attainable accuracy and robustness
by the pipelined BiCGStab method. It is shown that the pipelined algorithm
improves scalability on distributed memory machines, leading to significant
speedups compared to standard preconditioned BiCGStab.
</dc:description>
 <dc:description>Comment: 24 pages, 5 figures, 4 tables, 45 references</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01395</dc:identifier>
 <dc:identifier>Parallel Computing 65, pp. 1-20, July 2017</dc:identifier>
 <dc:identifier>doi:10.1016/j.parco.2017.04.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01397</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implicit Modeling -- A Generalization of Discriminative and Generative
  Approaches</dc:title>
 <dc:creator>Schlesinger, Dmitrij</dc:creator>
 <dc:creator>Rother, Carsten</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a new modeling approach that is a generalization of generative and
discriminative models. The core idea is to use an implicit parameterization of
a joint probability distribution by specifying only the conditional
distributions. The proposed scheme combines the advantages of both worlds -- it
can use powerful complex discriminative models as its parts, having at the same
time better generalization capabilities. We thoroughly evaluate the proposed
method for a simple classification task with artificial data and illustrate its
advantages for real-word scenarios on a semantic image segmentation problem.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01399</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Type-II Fuzzy Logic Based Controller for Non-linear Dynamical
  Systems with Application to a 3-PSP Parallel Robot</dc:title>
 <dc:creator>Hassanzadeh, Hamid Reza</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The concept of uncertainty is posed in almost any complex system including
parallel robots as an outstanding instance of dynamical robotics systems. As
suggested by the name, uncertainty, is some missing information that is beyond
the knowledge of human thus we may tend to handle it properly to minimize the
side-effects through the control process.
  Type-II fuzzy logic has shown its superiority over traditional fuzzy logic
when dealing with uncertainty. Type-II fuzzy logic controllers are however
newer and more promising approaches that have been recently applied to various
fields due to their significant contribution especially when noise (as an
important instance of uncertainty) emerges. During the design of Type-I fuzzy
logic systems, we presume that we are almost certain about the fuzzy membership
functions which is not true in many cases. Thus T2FLS as a more realistic
approach dealing with practical applications might have a lot to offer. Type-II
fuzzy logic takes into account a higher level of uncertainty, in other words,
the membership grade for a type-II fuzzy variable is no longer a crisp number
but rather is itself a type-I linguistic term. In this thesis the effects of
uncertainty in dynamic control of a parallel robot is considered. More
specifically, it is intended to incorporate the Type-II Fuzzy Logic paradigm
into a model based controller, the so-called computed torque control method,
and apply the result to a 3 degrees of freedom parallel manipulator.
  ...
</dc:description>
 <dc:description>Comment: Master's thesis</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01400</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distance Function for Comparing Straight-Edge Geometric Figures</dc:title>
 <dc:creator>Roopa, Apoorva Honnegowda</dc:creator>
 <dc:creator>Rao, Shrisha</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>65D10 (primary), 51K05 (secondary)</dc:subject>
 <dc:description>  This paper defines a distance function that measures the dissimilarity
between planar geometric figures formed with straight lines. This function can
in turn be used in partial matching of different geometric figures. For a given
pair of geometric figures that are graphically isomorphic, one function
measures the angular dissimilarity and another function measures the edge
length disproportionality. The distance function is then defined as the convex
sum of these two functions. The novelty of the presented function is that it
satisfies all properties of a distance function and the computation of the same
is done by projecting appropriate features to a cartesian plane. To compute the
deviation from the angular similarity property, the Euclidean distance between
the given angular pairs and the corresponding points on the $y=x$ line is
measured. Further while computing the deviation from the edge length
proportionality property, the best fit line, for the set of edge lengths, which
passes through the origin is found, and the Euclidean distance between the
given edge length pairs and the corresponding point on a $y=mx$ line is
calculated. Iterative Proportional Fitting Procedure (IPFP) is used to find
this best fit line. We demonstrate the behavior of the defined function for
some sample pairs of figures.
</dc:description>
 <dc:description>Comment: 29 pages, 12 figures including appendices</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01401</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Adversary-Resistant Deep Neural Networks</dc:title>
 <dc:creator>Wang, Qinglong</dc:creator>
 <dc:creator>Guo, Wenbo</dc:creator>
 <dc:creator>Zhang, Kaixuan</dc:creator>
 <dc:creator>Ororbia II, Alexander G.</dc:creator>
 <dc:creator>Xing, Xinyu</dc:creator>
 <dc:creator>Liu, Xue</dc:creator>
 <dc:creator>Giles, C. Lee</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks (DNNs) have proven to be quite effective in a vast array
of machine learning tasks, with recent examples in cyber security and
autonomous vehicles. Despite the superior performance of DNNs in these
applications, it has been recently shown that these models are susceptible to a
particular type of attack that exploits a fundamental flaw in their design.
This attack consists of generating particular synthetic examples referred to as
adversarial samples. These samples are constructed by slightly manipulating
real data-points in order to &quot;fool&quot; the original DNN model, forcing it to
mis-classify previously correctly classified samples with high confidence.
Addressing this flaw in the model is essential if DNNs are to be used in
critical applications such as those in cyber security.
  Previous work has provided various learning algorithms to enhance the
robustness of DNN models, and they all fall into the tactic of &quot;security
through obscurity&quot;. This means security can be guaranteed only if one can
obscure the learning algorithms from adversaries. Once the learning technique
is disclosed, DNNs protected by these defense mechanisms are still susceptible
to adversarial samples. In this work, we investigate this issue shared across
previous research work and propose a generic approach to escalate a DNN's
resistance to adversarial samples. More specifically, our approach integrates a
data transformation module with a DNN, making it robust even if we reveal the
underlying learning algorithm. To demonstrate the generality of our proposed
approach and its potential for handling cyber security applications, we
evaluate our method and several other existing solutions on datasets publicly
available. Our results indicate that our approach typically provides superior
classification performance and resistance in comparison with state-of-art
solutions.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01402</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the existence of weak subgame perfect equilibria</dc:title>
 <dc:creator>Bruy&#xe8;re, V&#xe9;ronique</dc:creator>
 <dc:creator>Roux, St&#xe9;phane Le</dc:creator>
 <dc:creator>Pauly, Arno</dc:creator>
 <dc:creator>Raskin, Jean-Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>91A18</dc:subject>
 <dc:description>  We study multi-player turn-based games played on (potentially infinite)
directed graphs. An outcome is assigned to every play of the game. Each player
has a preference relation on the set of outcomes which allows him to compare
plays. We focus on the recently introduced notion of weak subgame perfect
equilibrium (weak SPE). This is a variant of the classical notion of SPE, where
players who deviate can only use strategies deviating from their initial
strategy in a finite number of histories. Having an SPE in a game implies
having a weak SPE but the contrary is generally false.
  We propose general conditions on the structure of the game graph and on the
preference relations of the players that guarantee the existence of a weak SPE,
that additionally is finite-memory. From this general result, we derive two
large classes of games for which there always exists a weak SPE: (i) the games
with a finite-range outcome function, and (ii) the games with a finite
underlying graph and a prefix-independent outcome function. For the second
class, we identify conditions on the preference relations that guarantee
memoryless strategies for the weak SPE.
</dc:description>
 <dc:description>Comment: 28 pages</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01404</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mapping the Dialog Act Annotations of the LEGO Corpus into the
  Communicative Functions of ISO 24617-2</dc:title>
 <dc:creator>Ribeiro, Eug&#xe9;nio</dc:creator>
 <dc:creator>Ribeiro, Ricardo</dc:creator>
 <dc:creator>de Matos, David Martins</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:description>  In this paper we present strategies for mapping the dialog act annotations of
the LEGO corpus into the communicative functions of the ISO 24617-2 standard.
Using these strategies, we obtained an additional 347 dialogs annotated
according to the standard. This is particularly important given the reduced
amount of existing data in those conditions due to the recency of the standard.
Furthermore, these are dialogs from a widely explored corpus for dialog related
tasks. However, its dialog annotations have been neglected due to their high
domain-dependency, which renders them unuseful outside the context of the
corpus. Thus, through our mapping process, we both obtain more data annotated
according to a recent standard and provide useful dialog act annotations for a
widely explored corpus in the context of dialog research.
</dc:description>
 <dc:description>Comment: 20 pages, 2 figures</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01406</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From output regulation theory to flatness based tracking: a bridge for
  linear systems</dc:title>
 <dc:creator>Khodaverdian, Saman</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The trajectory tracking problem for multivariable linear systems is
considered. Two different techniques are examined: the output regulation theory
(ORT) and the flatness based tracking (FBT). ORT and FBT are two different
approaches to solve the tracking problem, and both methods have different
restrictions. The tracking controller of the ORT furthermore depends on the
solution of the so-called regulator equations. In this paper, a special
analytic solution of the regulator equations is presented. Additionally, based
on this analytic solution, a link from the ORT to the FBT approach is provided,
and the connection of both tracking controllers is highlighted. It is shown how
the ORT controller can be converted to the FBT controller and that both methods
lead to identical control laws for a certain class of systems.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01414</identifier>
 <datestamp>2017-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-Supervised Learning via Sparse Label Propagation</dc:title>
 <dc:creator>Jung, Alexander</dc:creator>
 <dc:creator>Hero III, Alfred O.</dc:creator>
 <dc:creator>Mara, Alexandru</dc:creator>
 <dc:creator>Jahromi, Saeed</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This work proposes a novel method for semi-supervised learning from partially
labeled massive network-structured datasets, i.e., big data over networks. We
model the underlying hypothesis, which relates data points to labels, as a
graph signal, defined over some graph (network) structure intrinsic to the
dataset. Following the key principle of supervised learning, i.e., similar
inputs yield similar outputs, we require the graph signals induced by labels to
have small total variation. Accordingly, we formulate the problem of learning
the labels of data points as a non-smooth convex optimization problem which
amounts to balancing between the empirical loss, i.e., the discrepancy with
some partially available label information, and the smoothness quantified by
the total variation of the learned graph signal. We solve this optimization
problem by appealing to a recently proposed preconditioned variant of the
popular primal-dual method by Pock and Chambolle, which results in a sparse
label propagation algorithm. This learning algorithm allows for a highly
scalable implementation as message passing over the underlying data graph. By
applying concepts of compressed sensing to the learning problem, we are also
able to provide a transparent sufficient condition on the underlying network
structure such that accurate learning of the labels is possible. We also
present an implementation of the message passing formulation allows for a
highly scalable implementation in big data frameworks.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01416</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Green Networking in Cellular HetNets: A Unified Radio Resource
  Management Framework with Base Station ON/OFF Switching</dc:title>
 <dc:creator>Ghazzai, Hakim</dc:creator>
 <dc:creator>Farooq, Muhammad Junaid</dc:creator>
 <dc:creator>Alsharoa, Ahmad</dc:creator>
 <dc:creator>Yaacoub, Elias</dc:creator>
 <dc:creator>Kadri, Abdullah</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, the problem of energy efficiency in cellular heterogeneous
networks (HetNets) is investigated using radio resource and power management
combined with the base station (BS) ON/OFF switching. The objective is to
minimize the total power consumption of the network while satisfying the
quality of service (QoS) requirements of each connected user. We consider the
case of co-existing macrocell BS, small cell BSs, and private femtocell access
points (FAPs). Three different network scenarios are investigated, depending on
the status of the FAPs, i.e., HetNets without FAPs, HetNets with closed FAPs,
and HetNets with semi-closed FAPs. A unified framework is proposed to
simultaneously allocate spectrum resources to users in an energy efficient
manner and switch off redundant small cell BSs. The high complexity dual
decomposition technique is employed to achieve optimal solutions for the
problem. A low complexity iterative algorithm is also proposed and its
performances are compared to those of the optimal technique. The particularly
interesting case of semi-closed FAPs, in which the FAPs accept to serve
external users, achieves the highest energy efficiency due to increased degrees
of freedom. In this paper, a cooperation scheme between FAPs and mobile
operator is also investigated. The incentives for FAPs, e.g., renewable energy
sharing and roaming prices, enabling cooperation are discussed to be considered
as a useful guideline for inter-operator agreements.
</dc:description>
 <dc:description>Comment: 15 pages, 9 Figures, IEEE Transactions on Vehicular Technology 2017</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01425</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zeroth-order Asynchronous Doubly Stochastic Algorithm with Variance
  Reduction</dc:title>
 <dc:creator>Gu, Bin</dc:creator>
 <dc:creator>Huo, Zhouyuan</dc:creator>
 <dc:creator>Huang, Heng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Zeroth-order (derivative-free) optimization attracts a lot of attention in
machine learning, because explicit gradient calculations may be computationally
expensive or infeasible. To handle large scale problems both in volume and
dimension, recently asynchronous doubly stochastic zeroth-order algorithms were
proposed. The convergence rate of existing asynchronous doubly stochastic
zeroth order algorithms is $O(\frac{1}{\sqrt{T}})$ (also for the sequential
stochastic zeroth-order optimization algorithms). In this paper, we focus on
the finite sums of smooth but not necessarily convex functions, and propose an
asynchronous doubly stochastic zeroth-order optimization algorithm using the
accelerated technology of variance reduction (AsyDSZOVR). Rigorous theoretical
analysis show that the convergence rate can be improved from
$O(\frac{1}{\sqrt{T}})$ the best result of existing algorithms to
$O(\frac{1}{T})$. Also our theoretical results is an improvement to the ones of
the sequential stochastic zeroth-order optimization algorithms.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01428</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extracting Implicit Social Relation for Social Recommendation Techniques
  in User Rating Prediction</dc:title>
 <dc:creator>Taheri, Seyed Mohammad</dc:creator>
 <dc:creator>Mahyar, Hamidreza</dc:creator>
 <dc:creator>Firouzi, Mohammad</dc:creator>
 <dc:creator>K., Elahe Ghalebi</dc:creator>
 <dc:creator>Grosu, Radu</dc:creator>
 <dc:creator>Movaghar, Ali</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recommendation plays an increasingly important role in our daily lives.
Recommender systems automatically suggest items to users that might be
interesting for them. Recent studies illustrate that incorporating social trust
in Matrix Factorization methods demonstrably improves accuracy of rating
prediction. Such approaches mainly use the trust scores explicitly expressed by
users. However, it is often challenging to have users provide explicit trust
scores of each other. There exist quite a few works, which propose Trust
Metrics to compute and predict trust scores between users based on their
interactions. In this paper, first we present how social relation can be
extracted from users' ratings to items by describing Hellinger distance between
users in recommender systems. Then, we propose to incorporate the predicted
trust scores into social matrix factorization models. By analyzing social
relation extraction from three well-known real-world datasets, which both:
trust and recommendation data available, we conclude that using the implicit
social relation in social recommendation techniques has almost the same
performance compared to the actual trust scores explicitly expressed by users.
Hence, we build our method, called Hell-TrustSVD, on top of the
state-of-the-art social recommendation technique to incorporate both the
extracted implicit social relations and ratings given by users on the
prediction of items for an active user. To the best of our knowledge, this is
the first work to extend TrustSVD with extracted social trust information. The
experimental results support the idea of employing implicit trust into matrix
factorization whenever explicit trust is not available, can perform much better
than the state-of-the-art approaches in user rating prediction.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01428</dc:identifier>
 <dc:identifier>doi:10.1145/3041021.3051153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01431</identifier>
 <datestamp>2016-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Three practical field normalised alternative indicator formulae for
  research evaluation</dc:title>
 <dc:creator>Thelwall, Mike</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Although altmetrics and other web-based alternative indicators are now
commonplace in publishers' websites, they can be difficult for research
evaluators to use because of the time or expense of the data, the need to
benchmark in order to assess their values, the high proportion of zeros in some
alternative indicators, and the time taken to calculate multiple complex
indicators. These problems are addressed here by (a) a field normalisation
formula, the Mean Normalised Log-transformed Citation Score (MNLCS) that allows
simple confidence limits to be calculated and is similar to a proposal of
Lundberg, (b) field normalisation formulae for the proportion of cited articles
in a set, the Equalised Mean-based Normalised Proportion Cited (EMNPC) and the
Mean-based Normalised Proportion Cited (MNPC), to deal with mostly uncited data
sets, (c) a sampling strategy to minimise data collection costs, and (d) free
unified software to gather the raw data, implement the sampling strategy, and
calculate the indicator formulae and confidence limits. The approach is
demonstrated (but not fully tested) by comparing the Scopus citations, Mendeley
readers and Wikipedia mentions of research funded by Wellcome, NIH, and MRC in
three large fields for 2013-2016. Within the results, statistically significant
differences in both citation counts and Mendeley reader counts were found even
for sets of articles that were less than six months old. Mendeley reader counts
were more precise than Scopus citations for the most recent articles and all
three funders could be demonstrated to have an impact in Wikipedia that was
significantly above the world average.
</dc:description>
 <dc:description>Comment: Thelwall, M. (in press). Three practical field normalised alternative
  indicator formulae for research evaluation. Journal of Informetrics.
  doi:10.1016/j.joi.2016.12.002 Changes from the previous version are
  highlighted in yellow</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2016-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01431</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2016.12.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01434</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proportional Rankings</dc:title>
 <dc:creator>Skowron, Piotr</dc:creator>
 <dc:creator>Lackner, Martin</dc:creator>
 <dc:creator>Brill, Markus</dc:creator>
 <dc:creator>Peters, Dominik</dc:creator>
 <dc:creator>Elkind, Edith</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  In this paper we extend the principle of proportional representation to
rankings. We consider the setting where alternatives need to be ranked based on
approval preferences. In this setting, proportional representation requires
that cohesive groups of voters are represented proportionally in each initial
segment of the ranking. Proportional rankings are desirable in situations where
initial segments of different lengths may be relevant, e.g., hiring decisions
(if it is unclear how many positions are to be filled), the presentation of
competing proposals on a liquid democracy platform (if it is unclear how many
proposals participants are taking into consideration), or recommender systems
(if a ranking has to accommodate different user types). We study the
proportional representation provided by several ranking methods and prove
theoretical guarantees. Furthermore, we experimentally evaluate these methods
and present preliminary evidence as to which methods are most suitable for
producing proportional rankings.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01436</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative Multi-bitrate Video Caching and Processing in Mobile-Edge
  Computing Networks</dc:title>
 <dc:creator>Tran, Tuyen X.</dc:creator>
 <dc:creator>Pandey, Parul</dc:creator>
 <dc:creator>Hajisami, Abolfazl</dc:creator>
 <dc:creator>Pompili, Dario</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Recently, Mobile-Edge Computing (MEC) has arisen as an emerging paradigm that
extends cloud-computing capabilities to the edge of the Radio Access Network
(RAN) by deploying MEC servers right at the Base Stations (BSs). In this paper,
we envision a collaborative joint caching and processing strategy for on-demand
video streaming in MEC networks. Our design aims at enhancing the widely used
Adaptive BitRate (ABR) streaming technology, where multiple bitrate versions of
a video can be delivered so as to adapt to the heterogeneity of user
capabilities and the varying of network connection bandwidth. The proposed
strategy faces two main challenges: (i) not only the videos but their
appropriate bitrate versions have to be effectively selected to store in the
caches, and (ii) the transcoding relationships among different versions need to
be taken into account to effectively utilize the processing capacity at the MEC
servers. To this end, we formulate the collaborative joint caching and
processing problem as an Integer Linear Program (ILP) that minimizes the
backhaul network cost, subject to the cache storage and processing capacity
constraints. Due to the NP-completeness of the problem and the impractical
overheads of the existing offline approaches, we propose a novel online
algorithm that makes cache placement and video scheduling decisions upon the
arrival of each new request. Extensive simulations results demonstrate the
significant performance improvement of the proposed strategy over traditional
approaches in terms of cache hit ratio increase, backhaul traffic and initial
access delay reduction.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, to appear in Proc. IEEE/IFIP Conference on
  Wireless On-demand Network Systems and Services (WONS), 2017</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01437</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding and Optimizing the Performance of Distributed Machine
  Learning Applications on Apache Spark</dc:title>
 <dc:creator>D&#xfc;nner, Celestine</dc:creator>
 <dc:creator>Parnell, Thomas</dc:creator>
 <dc:creator>Atasu, Kubilay</dc:creator>
 <dc:creator>Sifalakis, Manolis</dc:creator>
 <dc:creator>Pozidis, Haralampos</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper we explore the performance limits of Apache Spark for machine
learning applications. We begin by analyzing the characteristics of a
state-of-the-art distributed machine learning algorithm implemented in Spark
and compare it to an equivalent reference implementation using the high
performance computing framework MPI. We identify critical bottlenecks of the
Spark framework and carefully study their implications on the performance of
the algorithm. In order to improve Spark performance we then propose a number
of practical techniques to alleviate some of its overheads. However, optimizing
computational efficiency and framework related overheads is not the only key to
performance -- we demonstrate that in order to get the best performance out of
any implementation it is necessary to carefully tune the algorithm to the
respective trade-off between computation time and communication latency. The
optimal trade-off depends on both the properties of the distributed algorithm
as well as infrastructure and framework-related characteristics. Finally, we
apply these technical and algorithmic optimizations to three different
distributed linear machine learning algorithms that have been implemented in
Spark. We present results using five large datasets and demonstrate that by
using the proposed optimizations, we can achieve a reduction in the performance
difference between Spark and MPI from 20x to 2x.
</dc:description>
 <dc:description>Comment: To appear in the 2017 IEEE International Conference on Big Data (Big
  Data 2017), December 11-14, 2017, Boston, MA, USA</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01445</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>N-gram Opcode Analysis for Android Malware Detection</dc:title>
 <dc:creator>Kang, BooJoong</dc:creator>
 <dc:creator>Yerima, Suleiman Y.</dc:creator>
 <dc:creator>Sezer, Sakir</dc:creator>
 <dc:creator>McLaughlin, Kieran</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Android malware has been on the rise in recent years due to the increasing
popularity of Android and the proliferation of third party application markets.
Emerging Android malware families are increasingly adopting sophisticated
detection avoidance techniques and this calls for more effective approaches for
Android malware detection. Hence, in this paper we present and evaluate an
n-gram opcode features based approach that utilizes machine learning to
identify and categorize Android malware. This approach enables automated
feature discovery without relying on prior expert or domain knowledge for
pre-determined features. Furthermore, by using a data segmentation technique
for feature selection, our analysis is able to scale up to 10-gram opcodes. Our
experiments on a dataset of 2520 samples showed an f-measure of 98% using the
n-gram opcode based approach. We also provide empirical findings that
illustrate factors that have probable impact on the overall n-gram opcodes
performance trends.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01445</dc:identifier>
 <dc:identifier>International Journal on Cyber Situational Awareness, Vol. 1, No.
  1, pp231-255 (2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01450</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inspiration or Preparation? Explaining Creativity in Scientific
  Enterprise</dc:title>
 <dc:creator>Zhang, Xinyang</dc:creator>
 <dc:creator>Wang, Dashun</dc:creator>
 <dc:creator>Wang, Ting</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Human creativity is the ultimate driving force behind scientific progress.
While the building blocks of innovations are often embodied in existing
knowledge, it is creativity that blends seemingly disparate ideas. Existing
studies have made striding advances in quantifying creativity of scientific
publications by investigating their citation relationships. Yet, little is
known hitherto about the underlying mechanisms governing scientific creative
processes, largely due to that a paper's references, at best, only partially
reflect its authors' actual information consumption. This work represents an
initial step towards fine-grained understanding of creative processes in
scientific enterprise. In specific, using two web-scale longitudinal datasets
(120.1 million papers and 53.5 billion web requests spanning 4 years), we
directly contrast authors' information consumption behaviors against their
knowledge products. We find that, of 59.0\% papers across all scientific
fields, 25.7\% of their creativity can be readily explained by information
consumed by their authors. Further, by leveraging these findings, we develop a
predictive framework that accurately identifies the most critical knowledge to
fostering target scientific innovations. We believe that our framework is of
fundamental importance to the study of scientific creativity. It promotes
strategies to stimulate and potentially automate creative processes, and
provides insights towards more effective designs of information recommendation
platforms.
</dc:description>
 <dc:description>Comment: Published in CIKM'16</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01452</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ImageNet pre-trained models with batch normalization</dc:title>
 <dc:creator>Simon, Marcel</dc:creator>
 <dc:creator>Rodner, Erik</dc:creator>
 <dc:creator>Denzler, Joachim</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks (CNN) pre-trained on ImageNet are the backbone
of most state-of-the-art approaches. In this paper, we present a new set of
pre-trained models with popular state-of-the-art architectures for the Caffe
framework. The first release includes Residual Networks (ResNets) with
generation script as well as the batch-normalization-variants of AlexNet and
VGG19. All models outperform previous models with the same architecture. The
models and training code are available at
http://www.inf-cv.uni-jena.de/Research/CNN+Models.html and
https://github.com/cvjena/cnn-models
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01458</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Support vector regression model for BigData systems</dc:title>
 <dc:creator>Rizzi, Alessandro Maria</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Nowadays Big Data are becoming more and more important. Many sectors of our
economy are now guided by data-driven decision processes. Big Data and business
intelligence applications are facilitated by the MapReduce programming model
while, at infrastructural layer, cloud computing provides flexible and cost
effective solutions for allocating on demand large clusters. In such systems,
capacity allocation, which is the ability to optimally size minimal resources
for achieve a certain level of performance, is a key challenge to enhance
performance for MapReduce jobs and minimize cloud resource costs. In order to
do so, one of the biggest challenge is to build an accurate performance model
to estimate job execution time of MapReduce systems. Previous works applied
simulation based models for modeling such systems. Although this approach can
accurately describe the behavior of Big Data clusters, it is too
computationally expensive and does not scale to large system. We try to
overcome these issues by applying machine learning techniques. More precisely
we focus on Support Vector Regression (SVR) which is intrinsically more robust
w.r.t other techniques, like, e.g., neural networks, and less sensitive to
outliers in the training set. To better investigate these benefits, we compare
SVR to linear regression.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01459</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Support Recovery of Atomic Line Spectral Estimation: A Tale
  of Resolution and Precision</dc:title>
 <dc:creator>Li, Qiuwei</dc:creator>
 <dc:creator>Tang, Gongguo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This work investigates the parameter estimation performance of
super-resolution line spectral estimation using atomic norm minimization. The
focus is on analyzing the algorithm's accuracy of inferring the frequencies and
complex magnitudes from noisy observations. When the Signal-to-Noise Ratio is
reasonably high and the true frequencies are separated by $O(\frac{1}{n})$, the
atomic norm estimator is shown to localize the correct number of frequencies,
each within a neighborhood of size $O(\sqrt{\frac{\log n}{n^3}} \sigma)$ of one
of the true frequencies. Here $n$ is half the number of temporal samples and
$\sigma^2$ is the Gaussian noise variance. The analysis is based on a
primal-dual witness construction procedure. The obtained error bound matches
the Cram\'er-Rao lower bound up to a logarithmic factor. The relationship
between resolution (separation of frequencies) and precision or accuracy of the
estimator is highlighted. Our analysis also reveals that the atomic norm
minimization can be viewed as a convex way to solve a $\ell_1$-norm
regularized, nonlinear and nonconvex least-squares problem to global
optimality.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01464</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite blocklength and moderate deviation analysis of hypothesis testing
  of correlated quantum states and application to classical-quantum channels
  with memory</dc:title>
 <dc:creator>Rouze, Cambyse</dc:creator>
 <dc:creator>Datta, Nilanjana</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Martingale concentration inequalities constitute a powerful mathematical tool
in the analysis of problems in a wide variety of fields ranging from
probability and statistics to information theory and machine learning. Here we
apply techniques borrowed from this field to quantum hypothesis testing, which
is the problem of discriminating quantum states belonging to two different
sequences $\{\rho_n\}_{n}$ and $\{\sigma_n\}_n$. We obtain upper bounds on the
finite blocklength type II Stein- and Hoeffding errors, which, for i.i.d.
states, are in general tighter than the corresponding bounds obtained by
Audenaert, Mosonyi and Verstraete [Journal of Mathematical Physics, 53(12),
2012]. We also derive finite blocklength bounds and moderate deviation results
for pairs of sequences of correlated states satisfying a (non-homogeneous)
factorization property. Examples of such sequences include Gibbs states of spin
chains with translation-invariant finite range interaction, as well as finitely
correlated quantum states. We apply our results to find bounds on the capacity
of a certain class of classical-quantum channels with memory, which satisfy a
so-called channel factorization property- both in the finite blocklength and
moderate deviation regimes.
</dc:description>
 <dc:description>Comment: 47 pages, 1 figure. This paper supersedes our previous paper
  (arXiv:1612.01464), in which hypothesis testing of sequences of correlated
  states, and analysis of classical-quantum channels with memory, were not done</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01465</identifier>
 <datestamp>2017-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ArtTrack: Articulated Multi-person Tracking in the Wild</dc:title>
 <dc:creator>Insafutdinov, Eldar</dc:creator>
 <dc:creator>Andriluka, Mykhaylo</dc:creator>
 <dc:creator>Pishchulin, Leonid</dc:creator>
 <dc:creator>Tang, Siyu</dc:creator>
 <dc:creator>Levinkov, Evgeny</dc:creator>
 <dc:creator>Andres, Bjoern</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we propose an approach for articulated tracking of multiple
people in unconstrained videos. Our starting point is a model that resembles
existing architectures for single-frame pose estimation but is substantially
faster. We achieve this in two ways: (1) by simplifying and sparsifying the
body-part relationship graph and leveraging recent methods for faster
inference, and (2) by offloading a substantial share of computation onto a
feed-forward convolutional architecture that is able to detect and associate
body joints of the same person even in clutter. We use this model to generate
proposals for body joint locations and formulate articulated tracking as
spatio-temporal grouping of such proposals. This allows to jointly solve the
association problem for all people in the scene by propagating evidence from
strong detections through time and enforcing constraints that each proposal can
be assigned to one person only. We report results on a public MPII Human Pose
benchmark and on a new MPII Video Pose dataset of image sequences with multiple
people. We demonstrate that our model achieves state-of-the-art results while
using only a fraction of time and is able to leverage temporal information to
improve state-of-the-art for crowded scenes.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01465</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01474</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple and Scalable Predictive Uncertainty Estimation using Deep
  Ensembles</dc:title>
 <dc:creator>Lakshminarayanan, Balaji</dc:creator>
 <dc:creator>Pritzel, Alexander</dc:creator>
 <dc:creator>Blundell, Charles</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks (NNs) are powerful black box predictors that have
recently achieved impressive performance on a wide spectrum of tasks.
Quantifying predictive uncertainty in NNs is a challenging and yet unsolved
problem. Bayesian NNs, which learn a distribution over weights, are currently
the state-of-the-art for estimating predictive uncertainty; however these
require significant modifications to the training procedure and are
computationally expensive compared to standard (non-Bayesian) NNs. We propose
an alternative to Bayesian NNs that is simple to implement, readily
parallelizable, requires very little hyperparameter tuning, and yields high
quality predictive uncertainty estimates. Through a series of experiments on
classification and regression benchmarks, we demonstrate that our method
produces well-calibrated uncertainty estimates which are as good or better than
approximate Bayesian NNs. To assess robustness to dataset shift, we evaluate
the predictive uncertainty on test examples from known and unknown
distributions, and show that our method is able to express higher uncertainty
on out-of-distribution examples. We demonstrate the scalability of our method
by evaluating predictive uncertainty estimates on ImageNet.
</dc:description>
 <dc:description>Comment: NIPS 2017</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01476</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling and Control of an Autonomous Three Wheeled Mobile Robot with
  Front Steer</dc:title>
 <dc:creator>Pandey, Ayush</dc:creator>
 <dc:creator>Jha, Siddharth</dc:creator>
 <dc:creator>Chakravarty, Debashish</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Modeling and control strategies for a design of an autonomous three wheeled
mobile robot with front wheel steer is presented. Although, the three-wheel
vehicle design with front wheel steer is common in automotive vehicles used
often in public transport, but its advantages in navigation and localization of
autonomous vehicles is seldom utilized. We present the system model for such a
robotic vehicle. A PID controller for speed control is designed for the model
obtained and has been implemented in a digital control framework. The
trajectory control framework, which is a challenging task for such a
three-wheeled robot has also been presented in the paper. The derived system
model has been verified using experimental results obtained for the robot
vehicle design. Controller performance and robustness issues have also been
discussed briefly.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Robotic Computing 2017. (under
  review)</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01479</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Authoring image decompositions with generative models</dc:title>
 <dc:creator>Rock, Jason</dc:creator>
 <dc:creator>Issaranon, Theerasit</dc:creator>
 <dc:creator>Deshpande, Aditya</dc:creator>
 <dc:creator>Forsyth, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We show how to extend traditional intrinsic image decompositions to
incorporate further layers above albedo and shading. It is hard to obtain data
to learn a multi-layer decomposition. Instead, we can learn to decompose an
image into layers that are &quot;like this&quot; by authoring generative models for each
layer using proxy examples that capture the Platonic ideal (Mondrian images for
albedo; rendered 3D primitives for shading; material swatches for shading
detail). Our method then generates image layers, one from each model, that
explain the image. Our approach rests on innovation in generative models for
images. We introduce a Convolutional Variational Auto Encoder (conv-VAE), a
novel VAE architecture that can reconstruct high fidelity images. The approach
is general, and does not require that layers admit a physical interpretation.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01479</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01480</identifier>
 <datestamp>2017-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized RBF kernel for incomplete data</dc:title>
 <dc:creator>Struski, &#x141;ukasz</dc:creator>
 <dc:creator>&#x15a;mieja, Marek</dc:creator>
 <dc:creator>Tabor, Jacek</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We construct $\bf genRBF$ kernel, which generalizes the classical Gaussian
RBF kernel to the case of incomplete data. We model the uncertainty contained
in missing attributes making use of data distribution and associate every point
with a conditional probability density function. This allows to embed
incomplete data into the function space and to define a kernel between two
missing data points based on scalar product in $L_2$. Experiments show that
introduced kernel applied to SVM classifier gives better results than other
state-of-the-art methods, especially in the case when large number of features
is missing. Moreover, it is easy to implement and can be used together with any
kernel approaches with no additional modifications.
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01481</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Nonparametric Latent Factor Model For Location-Aware Video
  Recommendations</dc:title>
 <dc:creator>Elahi, Ehtsham</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We are interested in learning customers' video preferences from their
historic viewing patterns and geographical location. We consider a Bayesian
latent factor modeling approach for this task. In order to tune the complexity
of the model to best represent the data, we make use of Bayesian nonparameteric
techniques. We describe an inference technique that can scale to large
real-world data sets. Finally we show results obtained by applying the model to
a large internal Netflix data set, that illustrates that the model was able to
capture interesting relationships between viewing patterns and geographical
location.
</dc:description>
 <dc:description>Comment: NIPS 2016 Workshop on Practical Bayesian Nonparametrics</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01487</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity Regions of Two-Receiver Broadcast Erasure Channels with
  Feedback and Memory</dc:title>
 <dc:creator>Heindlmaier, Michael</dc:creator>
 <dc:creator>Bidokhti, Shirin Saeedi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The two-receiver broadcast packet erasure channel with feedback and memory is
studied. Memory is modeled using a finite-state Markov chain representing a
channel state. Two scenarios are considered: (i) when the transmitter has
causal knowledge of the channel state (i.e., the state is visible), and (ii)
when the channel state is unknown at the transmitter, but observations of it
are available at the transmitter through feedback (i.e., the state is hidden).
In both scenarios, matching outer and inner bounds on the rates of
communication are derived and the capacity region is determined. It is shown
that similar results carry over to channels with memory and delayed feedback
and memoryless compound channels with feedback. When the state is visible, the
capacity region has a single-letter characterization and is in terms of a
linear program. Two optimal coding schemes are devised that use feedback to
keep track of the sent/received packets via a network of queues: a
probabilistic scheme and a deterministic backpressure-like algorithm. The
former bases its decisions solely on the past channel state information and the
latter follows a max-weight queue-based policy. The performance of the
algorithms are analyzed using the frameworks of rate stability in networks of
queues, max-flow min-cut duality in networks, and finite-horizon Lyapunov drift
analysis. When the state is hidden, the capacity region does not have a
single-letter characterization and is, in this sense, uncomputable.
Approximations of the capacity region are provided and two optimal coding
algorithms are outlined. The first algorithm is a probabilistic coding scheme
that bases its decisions on the past L acknowledgments and its achievable rate
region approaches the capacity region exponentially fast in L. The second
algorithm is a backpressure-like algorithm that performs optimally in the long
run.
</dc:description>
 <dc:description>Comment: revised and shortened version</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01489</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MCMC Louvain for Online Community Detection</dc:title>
 <dc:creator>Darmaillac, Yves</dc:creator>
 <dc:creator>Loustau, S&#xe9;bastien</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce a novel algorithm of community detection that maintains
dynamically a community structure of a large network that evolves with time.
The algorithm maximizes the modularity index thanks to the construction of a
randomized hierarchical clustering based on a Monte Carlo Markov Chain (MCMC)
method. Interestingly, it could be seen as a dynamization of Louvain algorithm
(see Blondel et Al, 2008) where the aggregation step is replaced by the
hierarchical instrumental probability.
</dc:description>
 <dc:description>Comment: 12 pages, in progress, experiments are coming</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01491</identifier>
 <datestamp>2016-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Bio-Plausible Multi-level STDP using CMOS Neurons with
  Dendrites and Bistable RRAMs</dc:title>
 <dc:creator>Wu, Xinyu</dc:creator>
 <dc:creator>Saxena, Vishal</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Large-scale integration of emerging nanoscale non-volatile memory devices,
e.g. resistive random-access memory (RRAM), can enable a new generation of
neuromorphic computers that can solve a wide range of machine learning
problems. Such hybrid CMOS-RRAM neuromorphic architectures will result in
several orders of magnitude reduction in energy consumption at a very small
form factor, and herald autonomous learning machines capable of self-adapting
to their environment. However, the progress in this area has been impeded from
the realization that the actual memory devices fall well short of their
expected behavior. In this work, we discuss the challenges associated with
these memory devices and their use in neuromorphic computing circuits, and
propose pathways to overcome these limitations by introducing 'dendritic
learning'.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2016-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01492</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Plane Gossip: Approximating rumor spread in planar graphs</dc:title>
 <dc:creator>Iglesias, Jennifer</dc:creator>
 <dc:creator>Rajaraman, Rajmohan</dc:creator>
 <dc:creator>Ravi, R</dc:creator>
 <dc:creator>Sundaram, Ravi</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We study the design of schedules for multi-commodity multicast; we are given
an undirected graph $G$ and a collection of source destination pairs, and the
goal is to schedule a minimum-length sequence of matchings that connects every
source with its respective destination. Multi-commodity multicast models a
classic information dissemination problem in networks where the primary
communication constraint is the number of connections that a node can make, not
link bandwidth.
  Multi-commodity multicast is closely related to the problem of finding a
subgraph, $H$, of optimal poise, where the poise is defined as the sum of the
maximum degree of $H$ and the maximum distance between any source-destination
pair in $H$. We first show that the minimum poise subgraph for single-commodity
multicast can be approximated to within a factor of $O(\log k)$ with respect to
the value of a natural LP relaxation in an instance with $k$ terminals. This is
the first upper bound on the integrality gap of the natural LP. Using this
poise result and shortest-path separators in planar graphs, we obtain a
$O(\log^3 k\log n/(\log\log n))$-approximation for multi-commodity multicast
for planar graphs.
  We also study the minimum-time radio gossip problem in planar graphs where a
message from each node must be transmitted to all other nodes under a model
where nodes can broadcast to all neighbors in a single step but only nodes with
a single broadcasting neighbor get a message. We give an $O(\log^2
n)$-approximation for radio gossip in planar graphs breaking previous barriers.
This is the first bound for radio gossip that does not rely on the maximum
degree of the graph.
  Finally, we show that our techniques for planar graphs extend to graphs with
excluded minors. We establish polylogarithmic-approximation algorithms for both
multi-commodity multicast and radio gossip problems in minor-free graphs.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01495</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ROAM: a Rich Object Appearance Model with Application to Rotoscoping</dc:title>
 <dc:creator>Miksik, Ondrej</dc:creator>
 <dc:creator>P&#xe9;rez-R&#xfa;a, Juan-Manuel</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:creator>P&#xe9;rez, Patrick</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Rotoscoping, the detailed delineation of scene elements through a video shot,
is a painstaking task of tremendous importance in professional post-production
pipelines. While pixel-wise segmentation techniques can help for this task,
professional rotoscoping tools rely on parametric curves that offer the artists
a much better interactive control on the definition, editing and manipulation
of the segments of interest. Sticking to this prevalent rotoscoping paradigm,
we propose a novel framework to capture and track the visual aspect of an
arbitrary object in a scene, given a first closed outline of this object. This
model combines a collection of local foreground/background appearance models
spread along the outline, a global appearance model of the enclosed object and
a set of distinctive foreground landmarks. The structure of this rich
appearance model allows simple initialization, efficient iterative optimization
with exact minimization at each step, and on-line adaptation in videos. We
demonstrate qualitatively and quantitatively the merit of this framework
through comparisons with tools based on either dynamic segmentation with a
closed curve or pixel-wise binary labelling.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01497</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>StreamNF: Performance and Correctness for Stateful Chained NFs</dc:title>
 <dc:creator>Khalid, Junaid</dc:creator>
 <dc:creator>Akella, Aditya</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Network functions virtualization (NFV) -- deploying network functions in
software on commodity machines -- allows operators to employ rich chains of NFs
to realize custom performance, security, and compliance policies, and ensure
high performance by dynamically adding instances and/or failing over. Because
NFs are stateful, it is important to carefully manage their state, especially
during such dynamic actions. Crucially, state management must: (1) offer good
performance to match the needs of modern networks; (2) ensure NF chain-wide
properties; and (3) not require the operator to manage low-level state
management details. We present StreamNF, an NFV framework that satisfies the
above requirements. To do so, StreamNF leverages an external state store with
novel caching strategies and offloading of state operations, and chain-level
logical packet clocks and packet logging/replay. Extensive evaluation of a
StreamNF prototype built atop Apache Storm shows that the significant benefits
of StreamNF in terms of state management performance and chain-wide properties
come at a modest per-packet latency cost.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01501</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BrainFrame: A node-level heterogeneous accelerator platform for neuron
  simulations</dc:title>
 <dc:creator>Smaragdos, Georgios</dc:creator>
 <dc:creator>Chatzikonstantis, Georgios</dc:creator>
 <dc:creator>Kukreja, Rahul</dc:creator>
 <dc:creator>Sidiropoulos, Harry</dc:creator>
 <dc:creator>Rodopoulos, Dimitrios</dc:creator>
 <dc:creator>Sourdis, Ioannis</dc:creator>
 <dc:creator>Al-Ars, Zaid</dc:creator>
 <dc:creator>Kachris, Christoforos</dc:creator>
 <dc:creator>Soudris, Dimitrios</dc:creator>
 <dc:creator>De Zeeuw, Chris I.</dc:creator>
 <dc:creator>Strydis, Christos</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Objective: The advent of High-Performance Computing (HPC) in recent years has
led to its increasing use in brain study through computational models. The
scale and complexity of such models are constantly increasing, leading to
challenging computational requirements. Even though modern HPC platforms can
often deal with such challenges, the vast diversity of the modeling field does
not permit for a single acceleration (or homogeneous) platform to effectively
address the complete array of modeling requirements. Approach: In this paper we
propose and build BrainFrame, a heterogeneous acceleration platform,
incorporating three distinct acceleration technologies, a Dataflow Engine, a
Xeon Phi and a GP-GPU. The PyNN framework is also integrated into the platform.
As a challenging proof of concept, we analyze the performance of BrainFrame on
different instances of a state-of-the-art neuron model, modeling the Inferior-
Olivary Nucleus using a biophysically-meaningful, extended Hodgkin-Huxley
representation. The model instances take into account not only the neuronal-
network dimensions but also different network-connectivity circumstances that
can drastically change application workload characteristics. Main results: The
synthetic approach of three HPC technologies demonstrated that BrainFrame is
better able to cope with the modeling diversity encountered. Our performance
analysis shows clearly that the model directly affect performance and all three
technologies are required to cope with all the model use cases.
</dc:description>
 <dc:description>Comment: 16 pages, 18 figures, 5 tables</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01506</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Technology Beats Algorithms (in Exact String Matching)</dc:title>
 <dc:creator>Tarhio, Jorma</dc:creator>
 <dc:creator>Holub, Jan</dc:creator>
 <dc:creator>Giaquinta, Emanuele</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  More than 120 algorithms have been developed for exact string matching within
the last 40 years. We show by experiments that the \naive{} algorithm
exploiting SIMD instructions of modern CPUs (with symbols compared in a special
order) is the fastest one for patterns of length up to about 50 symbols and
extremely good for longer patterns and small alphabets. The algorithm compares
16 or 32 characters in parallel by applying SSE2 or AVX2 instructions,
respectively. Moreover, it uses loop peeling to further speed up the searching
phase. We tried several orders for comparisons of pattern symbols and the
increasing order of their probabilities in the text was the best.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01506</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01507</identifier>
 <datestamp>2016-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eldan's Stochastic Localization and the KLS Hyperplane Conjecture: An
  Improved Lower Bound for Expansion</dc:title>
 <dc:creator>Lee, Yin Tat</dc:creator>
 <dc:creator>Vempala, Santosh S.</dc:creator>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We show that the KLS constant for $n$-dimensional isotropic logconcave
measures is $O(n^{1/4})$, improving on the current best bound of
$O(n^{1/3}\sqrt{\log n})$$.$ As corollaries we obtain the same improved bound
on the thin-shell estimate, Poincare constant and exponential concentration
constant and an alternative proof of this bound for the isotropic constant; it
also follows that the ball walk for sampling from an isotropic logconcave
density in ${\bf R}^{n}$ converges in $O^{*}(n^{2.5})$ steps from a warm start.
</dc:description>
 <dc:description>Comment: 30 pages. Corrects the first version. KLS bound is n^1/4</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2016-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01510</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Effects of Data Quality on the Analysis of Corporate Board Interlock
  Networks</dc:title>
 <dc:creator>Garcia-Bernardo, Javier</dc:creator>
 <dc:creator>Takes, Frank W.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Nowadays, social networks of ever increasing size are studied by researchers
from a range of disciplines. The data underlying these networks is often
automatically gathered from API's, websites or existing databases. As a result,
the quality of this data is typically not manually validated, and the resulting
networks may be based on false, biased or incomplete data. In this paper, we
investigate the effect of data quality issues on the analysis of large
networks. We focus on the global board interlock network, in which nodes
represent firms across the globe, and edges model social ties between firms --
shared board members holding a position at both firms. First, we demonstrate
how we can automatically assess the completeness of a large dataset of 160
million firms, in which data is missing not at random. Second, we present a
novel method to increase the accuracy of the entries in our data. By comparing
the expected and empirical characteristics of the resulting network topology,
we develop a technique that automatically prunes and merges duplicate nodes and
edges. Third, we use a case study of the board interlock network of Sweden to
show how poor quality data results in incorrect network topologies, biased
centrality values and abnormal influence spread under a well-known diffusion
model. Finally, we demonstrate how our data quality assessment methods help
restore the correct network structure, ultimately allowing us to derive
meaningful and correct results from analyzing the network.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2016-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01510</dc:identifier>
 <dc:identifier>doi:10.1016/j.is.2017.10.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01511</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HellRank: A Hellinger-based Centrality Measure for Bipartite Social
  Networks</dc:title>
 <dc:creator>Taheri, Seyed Mohammad</dc:creator>
 <dc:creator>Mahyar, Hamidreza</dc:creator>
 <dc:creator>Firouzi, Mohammad</dc:creator>
 <dc:creator>K., Elahe Ghalebi</dc:creator>
 <dc:creator>Grosu, Radu</dc:creator>
 <dc:creator>Movaghar, Ali</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Measuring centrality in a social network, especially in bipartite mode, poses
several challenges such as requirement of full knowledge of the network
topology and lack of properly detection of top-k behavioral representative
users. In this paper, to overcome the aforementioned challenging issues, we
propose an accurate centrality measure, called HellRank, to identify central
nodes in bipartite social networks. HellRank is based on the Hellinger distance
between two nodes on the same side of a bipartite network. We theoretically
analyze the impact of the Hellinger distance on a bipartite network and find an
upper and lower bounds for this distance. The computation of HellRank
centrality measure can be distributed by letting each node uses only local
information on its immediate neighbors and therefore do not need a central
entity to have full knowledge of the network topological structure. We
experimentally evaluate performance of the HellRank measure in correlation with
other centrality measures on real-world networks. The results show partial
ranking similarity between the HellRank and the other conventional metrics
according to the Kendall and Spearman rank correlation coefficient.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01511</dc:identifier>
 <dc:identifier>Soc. Netw. Anal. Min. (2017) 7: 22</dc:identifier>
 <dc:identifier>doi:10.1007/s13278-017-0440-7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01513</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Essential obstacles to Helly circular-arc graphs</dc:title>
 <dc:creator>Safe, Mart&#xed;n D.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C62, 05C75, 05C85</dc:subject>
 <dc:description>  A Helly circular-arc graph is the intersection graph of a set of arcs on a
circle having the Helly property. We introduce essential obstacles, which are a
refinement of the notion of obstacles, and prove that essential obstacles are
precisely the minimal forbidden induced circular-arc subgraphs for the class of
Helly circular-arc graphs. We show that it is possible to find in linear time,
in any given obstacle, some minimal forbidden induced subgraph for the class of
Helly circular-arc graphs contained as an induced subgraph. Moreover, relying
on an existing linear-time algorithm for finding induced obstacles in
circular-arc graphs, we conclude that it is possible to find in linear time an
induced essential obstacle in any circular-arc graph that is not a Helly
circular-arc graph. The problem of finding a forbidden induced subgraph
characterization, not restricted only to circular-arc graphs, for the class of
Helly circular-arc graphs remains unresolved. As a partial answer to this
problem, we find the minimal forbidden induced subgraph characterization for
the class of Helly circular-arc graphs restricted to graphs containing no
induced claw and no induced 5-wheel. Furthermore, we show that there is a
linear-time algorithm for finding, in any given graph that is not a Helly
circular-arc graph, an induced subgraph isomorphic to claw, 5-wheel, or some
minimal forbidden induced subgraph for the class of Helly circular-arc graphs.
</dc:description>
 <dc:description>Comment: 18 pages, 3 figures</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01514</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Randomized Concurrent Algorithm for Disjoint Set Union</dc:title>
 <dc:creator>Jayanti, Siddhartha V.</dc:creator>
 <dc:creator>Tarjan, Robert E.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The disjoint set union problem is a basic problem in data structures with a
wide variety of applications. We extend a known efficient sequential algorithm
for this problem to obtain a simple and efficient concurrent wait-free
algorithm running on an asynchronous parallel random access machine (APRAM).
Crucial to our result is the use of randomization. Under a certain independence
assumption, for a problem instance in which there are n elements, m operations,
and p processes, our algorithm does Theta(m (alpha(n, m/(np)) + log(np/m + 1)))
expected work, where the expectation is over the random choices made by the
algorithm and alpha is a functional inverse of Ackermann's function. In
addition, each operation takes O(log n) steps with high probability. Our
algorithm is significantly simpler and more efficient than previous algorithms
proposed by Anderson and Woll. Under our independence assumption, our algorithm
achieves almost-linear speed-up for applications in which all or most of the
processes can be kept busy.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01527</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matrix multiplication algorithms from group orbits</dc:title>
 <dc:creator>Grochow, Joshua A.</dc:creator>
 <dc:creator>Moore, Cristopher</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Mathematics - Representation Theory</dc:subject>
 <dc:subject>68Q17, 68Q25, 14L30, 15A69</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:description>  We show how to construct highly symmetric algorithms for matrix
multiplication. In particular, we consider algorithms which decompose the
matrix multiplication tensor into a sum of rank-1 tensors, where the
decomposition itself consists of orbits under some finite group action. We show
how to use the representation theory of the corresponding group to derive
simple constraints on the decomposition, which we solve by hand for n=2,3,4,5,
recovering Strassen's algorithm (in a particularly symmetric form) and new
algorithms for larger n. While these new algorithms do not improve the known
upper bounds on tensor rank or the matrix multiplication exponent, they are
beautiful in their own right, and we point out modifications of this idea that
could plausibly lead to further improvements. Our constructions also suggest
further patterns that could be mined for new algorithms, including a
tantalizing connection with lattices. In particular, using lattices we give the
most transparent proof to date of Strassen's algorithm; the same proof works
for all n, to yield a decomposition with $n^3 - n + 1$ terms.
</dc:description>
 <dc:description>Comment: Added transparent proof of Strassen's algorithm and its
  generalization using lattices</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2016-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01527</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01543</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards the Limit of Network Quantization</dc:title>
 <dc:creator>Choi, Yoojin</dc:creator>
 <dc:creator>El-Khamy, Mostafa</dc:creator>
 <dc:creator>Lee, Jungwon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Network quantization is one of network compression techniques to reduce the
redundancy of deep neural networks. It reduces the number of distinct network
parameter values by quantization in order to save the storage for them. In this
paper, we design network quantization schemes that minimize the performance
loss due to quantization given a compression ratio constraint. We analyze the
quantitative relation of quantization errors to the neural network loss
function and identify that the Hessian-weighted distortion measure is locally
the right objective function for the optimization of network quantization. As a
result, Hessian-weighted k-means clustering is proposed for clustering network
parameters to quantize. When optimal variable-length binary codes, e.g.,
Huffman codes, are employed for further compression, we derive that the network
quantization problem can be related to the entropy-constrained scalar
quantization (ECSQ) problem in information theory and consequently propose two
solutions of ECSQ for network quantization, i.e., uniform quantization and an
iterative solution similar to Lloyd's algorithm. Finally, using the simple
uniform quantization followed by Huffman coding, we show from our experiments
that the compression ratios of 51.25, 22.17 and 40.65 are achievable for LeNet,
32-layer ResNet and AlexNet, respectively.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01553</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy Patterns</dc:title>
 <dc:creator>Thomborson, Clark</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Inspired by the design patterns of object-oriented software architecture, we
offer an initial set of &quot;privacy patterns&quot;. Our intent is to describe the most
important ways in which software systems can offer privacy to their
stakeholders. We express our privacy patterns as class diagrams in the UML
(Universal Modelling Language), because this is a commonly-used language for
expressing the high-level architecture of an object-oriented system. In this
initial set of privacy patterns, we sketch how each of Westin's four states of
privacy can be implemented in a software system. In addition to Westin's states
of Solitude, Intimacy, Anonymity, and Reserve, we develop a privacy pattern for
an institutionalised form of Intimacy which we call Confidence.
</dc:description>
 <dc:description>Comment: 8 pages, 12 August 2016. To be presented orally at PST 2016
  (http://pst2016.unitec.ac.nz/) on 13 December 2016. A revised version was
  submitted to IEEE Trans IFS on 5 December 2016</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01554</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robustness of Control Barrier Functions for Safety Critical Control</dc:title>
 <dc:creator>Xu, Xiangru</dc:creator>
 <dc:creator>Tabuada, Paulo</dc:creator>
 <dc:creator>Grizzle, Jessy W.</dc:creator>
 <dc:creator>Ames, Aaron D.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Barrier functions (also called certificates) have been an important tool for
the verification of hybrid systems, and have also played important roles in
optimization and multi-objective control. The extension of a barrier function
to a controlled system results in a control barrier function. This can be
thought of as being analogous to how Sontag extended Lyapunov functions to
control Lyapunov functions in order to enable controller synthesis for
stabilization tasks. A control barrier function enables controller synthesis
for safety requirements specified by forward invariance of a set using a
Lyapunov-like condition. This paper develops several important extensions to
the notion of a control barrier function. The first involves robustness under
perturbations to the vector field defining the system. Input-to-State stability
conditions are given that provide for forward invariance, when disturbances are
present, of a &quot;relaxation&quot; of set rendered invariant without disturbances. A
control barrier function can be combined with a control Lyapunov function in a
quadratic program to achieve a control objective subject to safety guarantees.
The second result of the paper gives conditions for the control law obtained by
solving the quadratic program to be Lipschitz continuous and therefore to gives
rise to well-defined solutions of the resulting closed-loop system.
</dc:description>
 <dc:description>Comment: Correction to Theorem 3 and some typos of the paper appeared in IFAC
  Conference on Analysis and Design of Hybrid Systems, Atlanta, GA, USA, page
  54-61, 2015. arXiv admin note: text overlap with arXiv:1609.06408</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01554</dc:identifier>
 <dc:identifier>IFAC Conference on Analysis and Design of Hybrid Systems, Atlanta,
  GA, USA, page 54-61, 2015</dc:identifier>
 <dc:identifier>doi:10.1016/j.ifacol.2015.11.152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01556</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Evolution of Sentiment Analysis - A Review of Research Topics,
  Venues, and Top Cited Papers</dc:title>
 <dc:creator>M&#xe4;ntyl&#xe4;, Mika Viking</dc:creator>
 <dc:creator>Graziotin, Daniel</dc:creator>
 <dc:creator>Kuutila, Miikka</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Sentiment analysis is one of the fastest growing research areas in computer
science, making it challenging to keep track of all the activities in the area.
We present a computer-assisted literature review, where we utilize both text
mining and qualitative coding, and analyze 6,996 papers from Scopus. We find
that the roots of sentiment analysis are in the studies on public opinion
analysis at the beginning of 20th century and in the text subjectivity analysis
performed by the computational linguistics community in 1990's. However, the
outbreak of computer-based sentiment analysis only occurred with the
availability of subjective texts on the Web. Consequently, 99% of the papers
have been published after 2004. Sentiment analysis papers are scattered to
multiple publication venues, and the combined number of papers in the top-15
venues only represent ca. 30% of the papers in total. We present the top-20
cited papers from Google Scholar and Scopus and a taxonomy of research topics.
In recent years, sentiment analysis has shifted from analyzing online product
reviews to social media texts from Twitter and Facebook. Many topics beyond
product reviews like stock markets, elections, disasters, medicine, software
engineering and cyberbullying extend the utilization of sentiment analysis
</dc:description>
 <dc:description>Comment: 29 pages, 14 figures</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01556</dc:identifier>
 <dc:identifier>Computer Science Review, Volume 27, February 2018, Pages 16-32</dc:identifier>
 <dc:identifier>doi:10.1016/j.cosrev.2017.10.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01564</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MIMO Secret Communications Against an Active Eavesdropper</dc:title>
 <dc:creator>Li, Lingxiang</dc:creator>
 <dc:creator>Petropulu, Athina P.</dc:creator>
 <dc:creator>Chen, Zhi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers a scenario in which an Alice-Bob pair wishes to
communicate in secret in the presence of an active Eve, who is capable of
jamming as well as eavesdropping in Full-Duplex (FD) mode. As countermeasure,
Bob also operates in FD mode, using a subset of its antennas to act as
receiver, and the remaining antennas to act as jammer and transmit noise. With
a goal to maximize the achievable secrecy degrees of freedom (S.D.o.F.) of the
system, we provide the optimal transmit/receive antennas allocation at Bob,
based on which we determine in closed form the maximum achievable S.D.o.F.. We
further investigate the adverse scenario in which Eve knows Bob's transmission
strategy and optimizes its transmit/receive antennas allocation in order to
minimize the achievable S.D.o.F.. For that case we find the worst-case
achievable S.D.o.F.. We also provide a method for constructing the precoding
matrices of Alice and Bob, based on which the maximum S.D.o.F. can be achieved.
Numerical results validate the theoretical findings and demonstrate the
performance of the proposed method in realistic settings.
</dc:description>
 <dc:description>Comment: 13 pages, 9 figures</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01574</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Bandwidth and Large Coupling Tolerance Graded-Index Multimode
  Polymer Waveguides for On-board High-Speed Optical Interconnects</dc:title>
 <dc:creator>Chen, Jian</dc:creator>
 <dc:creator>Bamiedakis, Nikolaos</dc:creator>
 <dc:creator>Vasil'ev, Peter P.</dc:creator>
 <dc:creator>Edwards, Tom J.</dc:creator>
 <dc:creator>Brown, Christian T. A.</dc:creator>
 <dc:creator>Penty, Richard V.</dc:creator>
 <dc:creator>White, Ian H.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Optical interconnects have attracted significant research interest for use in
short-reach board-level optical communication links in supercomputers and data
centres. Multimode polymer waveguides in particular constitute an attractive
technology for on-board optical interconnects as they provide high bandwidth,
offer relaxed alignment tolerances, and can be cost-effectively integrated onto
standard printed circuit boards (PCBs). However, the continuing improvements in
bandwidth performance of optical sources make it important to investigate
approaches to develop high bandwidth polymer waveguides. In this paper, we
present dispersion studies on a graded-index (GI) waveguide in siloxane
materials designed to deliver high bandwidth over a range of launch conditions.
Bandwidth-length products of &gt;70 GHzxm and ~65 GHzxm are observed using a
50/125 um multimode fibre (MMF) launch for input offsets of +/- 10 um without
and with the use of a mode mixer respectively; and enhanced values of &gt;100
GHzxm are found under a 10x microscope objective launch for input offsets of
~18 x 20 um^2. The large range of offsets is within the -1 dB alignment
tolerances. A theoretical model is developed using the measured refractive
index profile of the waveguide, and general agreement is found with
experimental bandwidth measurements. The reported results clearly demonstrate
the potential of this technology for use in high-speed board-level optical
links, and indicate that data transmission of 100 Gb/s over a multimode polymer
waveguide is feasible with appropriate refractive index engineering.
</dc:description>
 <dc:description>Comment: 8 pages, 10 figures</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01574</dc:identifier>
 <dc:identifier>Journal of Lightwave Technology, Vol. 34, Issue. 12 (2015)</dc:identifier>
 <dc:identifier>doi:10.1109/JLT.2015.2500611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01576</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Mixing and Systematic Scan Markov chains</dc:title>
 <dc:creator>Blanca, Antonio</dc:creator>
 <dc:creator>Caputo, Pietro</dc:creator>
 <dc:creator>Sinclair, Alistair</dc:creator>
 <dc:creator>Vigoda, Eric</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We consider spin systems on the integer lattice graph $\mathbb{Z}^d$ with
nearest-neighbor interactions. We develop a combinatorial framework for
establishing that exponential decay with distance of spin correlations,
specifically the strong spatial mixing condition (SSM), implies rapid mixing of
a large class of Markov chains. As a first application of our method we prove
that SSM implies $O(\log n)$ mixing of systematic scan dynamics (under mild
conditions) on an $n$-vertex $d$-dimensional cube of the integer lattice graph
$\mathbb{Z}^d$. Systematic scan dynamics are widely employed in practice but
have proved hard to analyze. A second application of our technology concerns
the Swendsen-Wang dynamics for the ferromagnetic Ising and Potts models. We
show that SSM implies an $O(1)$ bound for the relaxation time (i.e., the
inverse spectral gap). As a by-product of this implication we observe that the
relaxation time of the Swendsen-Wang dynamics in square boxes of $\mathbb{Z}^2$
is $O(1)$ throughout the subcritical regime of the $q$-state Potts model, for
all $q \ge 2$. We also use our combinatorial framework to give a simple
coupling proof of the classical result that SSM entails optimal mixing time of
the Glauber dynamics. Although our results in the paper focus on
$d$-dimensional cubes in $\mathbb{Z}^d$, they generalize straightforwardly to
arbitrary regions of $\mathbb{Z}^d$ and to graphs with subexponential growth.
</dc:description>
 <dc:description>Comment: See arXiv:1708.01513 for a corrected version. The new version
  includes a new proof of the result for the Swendsen-Wang dynamics, as well as
  new results for block dynamics and for the alternating scan dynamics. Our
  results for the systematic scan dynamics now require monotonicity of the spin
  system</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01577</identifier>
 <datestamp>2017-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity of Cooperative Vehicular Networks with Infrastructure Support:
  Multi-user Case</dc:title>
 <dc:creator>Chen, Jieqiong</dc:creator>
 <dc:creator>Mao, Guoqiang</dc:creator>
 <dc:creator>Li, Changle</dc:creator>
 <dc:creator>Liang, Weifa</dc:creator>
 <dc:creator>Zhang, Degan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Capacity of vehicular networks with infrastructure support is both an
interesting and challenging problem as the capacity is determined by the
inter-play of multiple factors including vehicle-to-infrastructure (V2I)
communications, vehicle-to-vehicle (V2V) communications, density and mobility
of vehicles, and cooperation among vehicles and infrastructure. In this paper,
we consider a typical delay-tolerant application scenario with a subset of
vehicles, termed Vehicles of Interest (VoIs), having download requests. Each
VoI downloads a distinct large-size file from the Internet and other vehicles
without download requests assist the delivery of the files to the VoIs. A
cooperative communication strategy is proposed that explores the combined use
of V2I communications, V2V communications, mobility of vehicles and cooperation
among vehicles and infrastructure to improve the capacity of vehicular
networks. An analytical framework is developed to model the data dissemination
process using this strategy, and a closed form expression of the achievable
capacity is obtained, which reveals the relationship between the capacity and
its major performance-impacting parameters such as inter-infrastructure
distance, radio ranges of infrastructure and vehicles, sensing range of
vehicles, transmission rates of V2I and V2V communications, vehicular density
and proportion of VoIs. Numerical result shows that the proposed cooperative
communication strategy significantly boosts the capacity of vehicular networks,
especially when the proportion of VoIs is low. Our results provide guidance on
the optimum deployment of vehicular network infrastructure and the design of
cooperative communication strategy to maximize the capacity.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01586</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A One-Field Monolithic Fictitious Domain Method for Fluid-Structure
  Interactions</dc:title>
 <dc:creator>Wang, Yongxing</dc:creator>
 <dc:creator>Jimack, Peter</dc:creator>
 <dc:creator>Walkley, Mark</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  In this article, we present a one-field monolithic fictitious domain (FD)
method for simulation of general fluid-structure interactions (FSI). One-field
means only one velocity field is solved in the whole domain, based upon the use
of an appropriate L2 projection. Monolithic means the fluid and solid equations
are solved synchronously (rather than sequentially). We argue that the proposed
method has the same generality and robustness as FD methods with distributed
Lagrange multiplier (DLM) but is significantly more computationally efficient
(because of one-field) whilst being very straightforward to implement. The
method is described in detail, followed by the presentation of multiple
computational examples in order to validate it across a wide range of fluid and
solid parameters and interactions.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1608.04998</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01586</dc:identifier>
 <dc:identifier>doi:10.1016/j.cma.2017.01.023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01587</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A System Architecture for the Detection of Insider Attacks in Big Data
  Systems</dc:title>
 <dc:creator>Aditham, Santosh</dc:creator>
 <dc:creator>Ranganathan, Nagarajan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In big data systems, the infrastructure is such that large amounts of data
are hosted away from the users. In such a system information security is
considered as a major challenge. From a customer perspective, one of the big
risks in adopting big data systems is in trusting the provider who designs and
owns the infrastructure from accessing user data. Yet there does not exist much
in the literature on detection of insider attacks. In this work, we propose a
new system architecture in which insider attacks can be detected by utilizing
the replication of data on various nodes in the system. The proposed system
uses a two-step attack detection algorithm and a secure communication protocol
to analyze processes executing in the system. The first step involves the
construction of control instruction sequences for each process in the system.
The second step involves the matching of these instruction sequences among the
replica nodes. Initial experiments on real-world hadoop and spark tests show
that the proposed system needs to consider only 20% of the code to analyze a
program and incurs 3.28% time overhead. The proposed security system can be
implemented and built for any big data system due to its extrinsic workflow.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01589</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving the Performance of Neural Networks in Regression Tasks Using
  Drawering</dc:title>
 <dc:creator>Zolna, Konrad</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The method presented extends a given regression neural network to make its
performance improve. The modification affects the learning procedure only,
hence the extension may be easily omitted during evaluation without any change
in prediction. It means that the modified model may be evaluated as quickly as
the original one but tends to perform better.
  This improvement is possible because the modification gives better expressive
power, provides better behaved gradients and works as a regularization. The
knowledge gained by the temporarily extended neural network is contained in the
parameters shared with the original neural network.
  The only cost is an increase in learning time.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01593</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competitive Caching of Contents in 5G Edge Cloud Networks</dc:title>
 <dc:creator>De Pellegrini, Francesco</dc:creator>
 <dc:creator>Massaro, Antonio</dc:creator>
 <dc:creator>Goratti, Leonardo</dc:creator>
 <dc:creator>El-Azouzi, Rachid</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The surge of mobile data traffic forces network operators to cope with
capacity shortage. The deployment of small cells in 5G networks is meant to
reduce latency, backhaul traffic and increase radio access capacity. In this
context, mobile edge computing technology will be used to manage dedicated
cache space in the radio access network. Thus, mobile network operators will be
able to provision OTT content providers with new caching services to enhance
the quality of experience of their customers on the move. In turn, the cache
memory in the mobile edge network will become a shared resource. Hence, we
study a competitive caching scheme where contents are stored at given price set
by the mobile network operator. We first formulate a resource allocation
problem for a tagged content provider seeking to minimize the expected missed
cache rate. The optimal caching policy is derived accounting for popularity and
availability of contents, the spatial distribution of small cells, and the
caching strategies of competing content providers. It is showed to induce a
specific order on contents to be cached based on their popularity and
availability. Next, we study a game among content providers in the form of a
generalized Kelly mechanism with bounded strategy sets and heterogeneous
players. Existence and uniqueness of the Nash equilibrium are proved. Finally,
extensive numerical results validate and characterize the performance of the
model.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01594</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object Classification with Joint Projection and Low-rank Dictionary
  Learning</dc:title>
 <dc:creator>Foroughi, Homa</dc:creator>
 <dc:creator>Ray, Nilanjan</dc:creator>
 <dc:creator>Zhang, Hong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  For an object classification system, the most critical obstacles towards
real-world applications are often caused by large intra-class variability,
arising from different lightings, occlusion and corruption, in limited sample
sets. Most methods in the literature would fail when the training samples are
heavily occluded, corrupted or have significant illumination or viewpoint
variations. Besides, most of the existing methods and especially deep
learning-based methods, need large training sets to achieve a satisfactory
recognition performance. Although using the pre-trained network on a generic
large-scale dataset and fine-tune it to the small-sized target dataset is a
widely used technique, this would not help when the content of base and target
datasets are very different. To address these issues, we propose a joint
projection and low-rank dictionary learning method using dual graph constraints
(JP-LRDL). The proposed joint learning method would enable us to learn the
features on top of which dictionaries can be better learned, from the data with
large intra-class variability. Specifically, a structured class-specific
dictionary is learned and the discrimination is further improved by imposing a
graph constraint on the coding coefficients, that maximizes the intra-class
compactness and inter-class separability. We also enforce low-rank and
structural incoherence constraints on sub-dictionaries to make them more
compact and robust to variations and outliers and reduce the redundancy among
them, respectively. To preserve the intrinsic structure of data and penalize
unfavourable relationship among training samples simultaneously, we introduce a
projection graph into the framework, which significantly enhances the
discriminative ability of the projection matrix and makes the method robust to
small-sized and high-dimensional datasets.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1603.07697; text overlap
  with arXiv:1404.3606 by other authors</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01594</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01597</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic and Probabilistic Conditions for Finite Completability of
  Low Rank Tensor</dc:title>
 <dc:creator>Ashraphijuo, Morteza</dc:creator>
 <dc:creator>Aggarwal, Vaneet</dc:creator>
 <dc:creator>Wang, Xiaodong</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We investigate the fundamental conditions on the sampling pattern, i.e.,
locations of the sampled entries, for finite completability of a low-rank
tensor given some components of its Tucker rank. In order to find the
deterministic necessary and sufficient conditions, we propose an algebraic
geometric analysis on the Tucker manifold, which allows us to incorporate
multiple rank components in the proposed analysis in contrast with the
conventional geometric approaches on the Grassmannian manifold. This analysis
characterizes the algebraic independence of a set of polynomials defined based
on the sampling pattern, which is closely related to finite completion.
Probabilistic conditions are then studied and a lower bound on the sampling
probability is given, which guarantees that the proposed deterministic
conditions on the sampling patterns for finite completability hold with high
probability. Furthermore, using the proposed geometric approach for finite
completability, we propose a sufficient condition on the sampling pattern that
ensures there exists exactly one completion for the sampled tensor.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01600</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Gaussian Learning over Time-varying Directed Graphs</dc:title>
 <dc:creator>Nedi&#x107;, Angelia</dc:creator>
 <dc:creator>Olshevsky, Alex</dc:creator>
 <dc:creator>Uribe, C&#xe9;sar A.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a distributed (non-Bayesian) learning algorithm for the problem of
parameter estimation with Gaussian noise. The algorithm is expressed as
explicit updates on the parameters of the Gaussian beliefs (i.e. means and
precision). We show a convergence rate of $O(1/k)$ with the constant term
depending on the number of agents and the topology of the network. Moreover, we
show almost sure convergence to the optimal solution of the estimation problem
for the general case of time-varying directed graphs.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01601</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Superpixels: An Evaluation of the State-of-the-Art</dc:title>
 <dc:creator>Stutz, David</dc:creator>
 <dc:creator>Hermans, Alexander</dc:creator>
 <dc:creator>Leibe, Bastian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Superpixels group perceptually similar pixels to create visually meaningful
entities while heavily reducing the number of primitives for subsequent
processing steps. As of these properties, superpixel algorithms have received
much attention since their naming in 2003. By today, publicly available
superpixel algorithms have turned into standard tools in low-level vision. As
such, and due to their quick adoption in a wide range of applications,
appropriate benchmarks are crucial for algorithm selection and comparison.
Until now, the rapidly growing number of algorithms as well as varying
experimental setups hindered the development of a unifying benchmark. We
present a comprehensive evaluation of 28 state-of-the-art superpixel algorithms
utilizing a benchmark focussing on fair comparison and designed to provide new
insights relevant for applications. To this end, we explicitly discuss
parameter optimization and the importance of strictly enforcing connectivity.
Furthermore, by extending well-known metrics, we are able to summarize
algorithm performance independent of the number of generated superpixels,
thereby overcoming a major limitation of available benchmarks. Furthermore, we
discuss runtime, robustness against noise, blur and affine transformations,
implementation details as well as aspects of visual quality. Finally, we
present an overall ranking of superpixel algorithms which redefines the
state-of-the-art and enables researchers to easily select appropriate
algorithms and the corresponding implementations which themselves are made
publicly available as part of our benchmark at
davidstutz.de/projects/superpixel-benchmark/.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01601</dc:identifier>
 <dc:identifier>doi:10.1016/j.cviu.2017.03.007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01603</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study of shoplifting prevention using image analysis and ERP check</dc:title>
 <dc:creator>Yamato, Yoji</dc:creator>
 <dc:creator>Fukumoto, Yoshifumi</dc:creator>
 <dc:creator>Kumazaki, Hiroki</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper, we propose a SaaS service which prevents shoplifting using
image analysis and ERP. In Japan, total damage of shoplifting reaches 450
billion yen and more than 1000 small shops gave up their businesses because of
shoplifting. Based on recent cloud technology and data analysis technology, we
propose a shoplifting prevention service with image analysis of security camera
and ERP data check for small shops. We evaluated stream analysis of security
camera movie using online machine learining framework Jubatus.
</dc:description>
 <dc:description>Comment: 4 pages, in Japanese, 2 figures, IEICE Technical Report, SC2016-14,
  Aug. 2016</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01603</dc:identifier>
 <dc:identifier>IEICE Technical Report, SC2016-14, Aug. 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01607</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Review of &quot;Continuous Finite-Time Stabilization of Translational and
  Rotational Double Integrators&quot;</dc:title>
 <dc:creator>Ogunmolu, Olalekan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We review Bhat et al's paper where a class of bounded, continuous
time-invariant finite time stabilizing feedback laws are derived for the double
integrator and Lyapunov theory is employed in establishing finite-time
convergence.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01608</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AI Researchers, Video Games Are Your Friends!</dc:title>
 <dc:creator>Togelius, Julian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  If you are an artificial intelligence researcher, you should look to video
games as ideal testbeds for the work you do. If you are a video game developer,
you should look to AI for the technology that makes completely new types of
games possible. This chapter lays out the case for both of these propositions.
It asks the question &quot;what can video games do for AI&quot;, and discusses how in
particular general video game playing is the ideal testbed for artificial
general intelligence research. It then asks the question &quot;what can AI do for
video games&quot;, and lays out a vision for what video games might look like if we
had significantly more advanced AI at our disposal. The chapter is based on my
keynote at IJCCI 2015, and is written in an attempt to be accessible to a broad
audience.
</dc:description>
 <dc:description>Comment: in Studies in Computational Intelligence Studies in Computational
  Intelligence, Volume 669 2017. Springer</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01608</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-48506-5_1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01610</identifier>
 <datestamp>2017-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tighter inapproximability for set cover</dc:title>
 <dc:creator>Harris, David G.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Set Cover is a classic NP-hard problem; as shown by Slav\'{i}k (1997) the
greedy algorithm gives an approximation ratio of $\ln n - \ln \ln n +
\Theta(1)$. A series of works by Lund \&amp; Yannakakis (1994), Feige (1998),
Moshkovitz (2015) have shown that, under the assumption $P \neq NP$, it is
impossible to obtain a polynomial-time approximation ratio with approximation
ratio $(1 - \alpha) \ln n$, for any constant $\alpha &gt; 0$.
  In this note, we show that under the Exponential Time Hypothesis (a stronger
complexity-theoretic assumptions than $P \neq NP$), there are no
polynomial-time algorithms achieving approximation ratio $\ln n - C \ln \ln n$,
where $C$ is some universal constant. Thus, the greedy algorithm achieves an
essentially optimal approximation ratio (up to the coefficient of $\ln \ln n$).
</dc:description>
 <dc:description>Comment: We discovered that these results have already appeared in Dinur &amp;
  Steurer, &quot;Analytical approach to parallel repetition.&quot;</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01611</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Event Detection for Signal-based Surveillance</dc:title>
 <dc:creator>Xu, Jingxin</dc:creator>
 <dc:creator>Fookes, Clinton</dc:creator>
 <dc:creator>Sridharan, Sridha</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Signal-based Surveillance systems such as Closed Circuits Televisions (CCTV)
have been widely installed in public places. Those systems are normally used to
find the events with security interest, and play a significant role in public
safety. Though such systems are still heavily reliant on human labour to
monitor the captured information, there have been a number of automatic
techniques proposed to analysing the data. This article provides an overview of
automatic surveillance event detection techniques . Despite it's popularity in
research, it is still too challenging a problem to be realised in a real world
deployment. The challenges come from not only the detection techniques such as
signal processing and machine learning, but also the experimental design with
factors such as data collection, evaluation protocols, and ground-truth
annotation. Finally, this article propose that multi-disciplinary research is
the path towards a solution to this problem.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01626</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Inference of Software Library Usage Patterns</dc:title>
 <dc:creator>Saied, Mohamed Aymen</dc:creator>
 <dc:creator>Ouni, Ali</dc:creator>
 <dc:creator>Sahraoui, Houari</dc:creator>
 <dc:creator>Kula, Raula Gaikovina</dc:creator>
 <dc:creator>Inoue, Katsuro</dc:creator>
 <dc:creator>Lo, David</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Modern software systems are increasingly dependent on third-party libraries.
It is widely recognized that using mature and well-tested third-party libraries
can improve developers' productivity, reduce time-to-market, and produce more
reliable software. Today's open-source repositories provide a wide range of
libraries that can be freely downloaded and used. However, as software
libraries are documented separately but intended to be used together,
developers are unlikely to fully take advantage of these reuse opportunities.
In this paper, we present a novel approach to automatically identify
third-party library usage patterns, i.e., collections of libraries that are
commonly used together by developers. Our approach employs hierarchical
clustering technique to group together software libraries based on external
client usage. To evaluate our approach, we mined a large set of over 6,000
popular libraries from Maven Central Repository and investigated their usage by
over 38,000 client systems from the Github repository. Our experiments show
that our technique is able to detect the majority (77%) of highly consistent
and cohesive library usage patterns across a considerable number of client
systems.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01627</identifier>
 <datestamp>2017-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequential Matching Network: A New Architecture for Multi-turn Response
  Selection in Retrieval-based Chatbots</dc:title>
 <dc:creator>Wu, Yu</dc:creator>
 <dc:creator>Wu, Wei</dc:creator>
 <dc:creator>Xing, Chen</dc:creator>
 <dc:creator>Zhou, Ming</dc:creator>
 <dc:creator>Li, Zhoujun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We study response selection for multi-turn conversation in retrieval-based
chatbots. Existing work either concatenates utterances in context or matches a
response with a highly abstract context vector finally, which may lose
relationships among utterances or important contextual information. We propose
a sequential matching network (SMN) to address both problems. SMN first matches
a response with each utterance in the context on multiple levels of
granularity, and distills important matching information from each pair as a
vector with convolution and pooling operations. The vectors are then
accumulated in a chronological order through a recurrent neural network (RNN)
which models relationships among utterances. The final matching score is
calculated with the hidden states of the RNN. An empirical study on two public
data sets shows that SMN can significantly outperform state-of-the-art methods
for response selection in multi-turn conversation.
</dc:description>
 <dc:description>Comment: ACL 2017</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-05-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01630</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parametric equations for temporal style assertions</dc:title>
 <dc:creator>Yodaiken, Victor</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Temporal logic provided an appealing approach to specifying properties of
operating systems and other &quot;reactive&quot; software by making referencing the state
graph implicitly. This paper shows how to get the same effect, with a finer
control over specification and a compositional notion of state, using ordinary
working mathematics, without the weight of formal logic, by using parametric
state variables.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01635</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Detect Multiple Photographic Defects</dc:title>
 <dc:creator>Yu, Ning</dc:creator>
 <dc:creator>Shen, Xiaohui</dc:creator>
 <dc:creator>Lin, Zhe</dc:creator>
 <dc:creator>Mech, Radomir</dc:creator>
 <dc:creator>Barnes, Connelly</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we introduce the problem of simultaneously detecting multiple
photographic defects. We aim at detecting the existence, severity, and
potential locations of common photographic defects related to color, noise,
blur and composition. The automatic detection of such defects could be used to
provide users with suggestions for how to improve photos without the need to
laboriously try various correction methods. Defect detection could also help
users select photos of higher quality while filtering out those with severe
defects in photo curation and summarization.
  To investigate this problem, we collected a large-scale dataset of user
annotations on seven common photographic defects, which allows us to evaluate
algorithms by measuring their consistency with human judgments. Our new dataset
enables us to formulate the problem as a multi-task learning problem and train
a multi-column deep convolutional neural network (CNN) to simultaneously
predict the severity of all the defects. Unlike some existing single-defect
estimation methods that rely on low-level statistics and may fail in many cases
on natural photographs, our model is able to understand image contents and
quality at a higher level. As a result, in our experiments, we show that our
model has predictions with much higher consistency with human judgments than
low-level methods as well as several baseline CNN models. Our model also
performs better than an average human from our user study.
</dc:description>
 <dc:description>Comment: Accepted to WACV'18</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01635</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01636</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Stochastic Geometry-based Demand Response Management Framework for
  Cellular Networks Powered by Smart Grid</dc:title>
 <dc:creator>Farooq, Muhammad Junaid</dc:creator>
 <dc:creator>Ghazzai, Hakim</dc:creator>
 <dc:creator>Kadri, Abdullah</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, the production decisions across multiple energy suppliers in
smart grid, powering cellular networks are investigated. The suppliers are
characterized by different offered prices and pollutant emissions levels. The
challenge is to decide the amount of energy provided by each supplier to each
of the operators such that their profitability is maximized while respecting
the maximum tolerated level of CO2 emissions. The cellular operators are
characterized by their offered quality of service (QoS) to the subscribers and
the number of users that determines their energy requirements. Stochastic
geometry is used to determine the average power needed to achieve the target
probability of coverage for each operator. The total average power requirements
of all networks are fed to an optimization framework to find the optimal amount
of energy to be provided from each supplier to the operators. The generalized
$\alpha$-fair utility function is used to avoid production bias among the
suppliers based on profitability of generation. Results illustrate the
production behavior of the energy suppliers versus QoS level, cost of energy,
capacity of generation, and level of fairness.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01636</dc:identifier>
 <dc:identifier>doi:10.1109/WCNC.2016.7564929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01637</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Type Annotation for Adaptive Systems</dc:title>
 <dc:creator>Bottoni, Paolo</dc:creator>
 <dc:creator>Fish, Andrew</dc:creator>
 <dc:creator>Presicce, Francesco Parisi</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:subject>D.2.10</dc:subject>
 <dc:description>  We introduce type annotations as a flexible typing mechanism for graph
systems and discuss their advantages with respect to classical typing based on
graph morphisms. In this approach the type system is incorporated with the
graph and elements can adapt to changes in context by changing their type
annotations. We discuss some case studies in which this mechanism is relevant.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2016, arXiv:1612.01053</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01637</dc:identifier>
 <dc:identifier>EPTCS 231, 2016, pp. 1-15</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.231.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01638</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An EMOF-Compliant Abstract Syntax for Bigraphs</dc:title>
 <dc:creator>Kehrer, Timo</dc:creator>
 <dc:creator>Tsigkanos, Christos</dc:creator>
 <dc:creator>Ghezzi, Carlo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:subject>D.2.10</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>I.6.5</dc:subject>
 <dc:description>  Bigraphs are an emerging modeling formalism for structures in ubiquitous
computing. Besides an algebraic notation, which can be adopted to provide an
algebraic syntax for bigraphs, the bigraphical theory introduces a visual
concrete syntax which is intuitive and unambiguous at the same time; the
standard visual notation can be customized and thus tailored to domain-specific
requirements. However, in contrast to modeling standards based on the
Meta-Object Facility (MOF) and domain-specific languages typically used in
model-driven engineering (MDE), the bigraphical theory lacks a precise
definition of an abstract syntax for bigraphical modeling languages. As a
consequence, available modeling and analysis tools use proprietary formats for
representing bigraphs internally and persistently, which hampers the exchange
of models across tool boundaries. Moreover, tools can be hardly integrated with
standard MDE technologies in order to build sophisticated tool chains and
modeling environments, as required for systematic engineering of large systems
or fostering experimental work to evaluate the bigraphical theory in real-world
applications. To overcome this situation, we propose an abstract syntax for
bigraphs which is compliant to the Essential MOF (EMOF) standard defined by the
Object Management Group (OMG). We use typed graphs as a formal underpinning of
EMOF-based models and present a canonical mapping which maps bigraphs to typed
graphs in a natural way. We also discuss application-specific variation points
in the graph-based representation of bigraphs. Following standard techniques
from software product line engineering, we present a framework to customize the
graph-based representation to support a variety of application scenarios.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2016, arXiv:1612.01053</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01638</dc:identifier>
 <dc:identifier>EPTCS 231, 2016, pp. 16-30</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.231.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01639</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Graph Grammar for Modelling RNA Folding</dc:title>
 <dc:creator>Mamuye, Adane Letta</dc:creator>
 <dc:creator>Merelli, Emanuela</dc:creator>
 <dc:creator>Tesei, Luca</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:description>  We propose a new approach for modelling the process of RNA folding as a graph
transformation guided by the global value of free energy. Since the folding
process evolves towards a configuration in which the free energy is minimal,
the global behaviour resembles the one of a self-adaptive system. Each RNA
configuration is a graph and the evolution of configurations is constrained by
precise rules that can be described by a graph grammar.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2016, arXiv:1612.01053</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01639</dc:identifier>
 <dc:identifier>EPTCS 231, 2016, pp. 31-41</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.231.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01640</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Step Semantics for Story-Driven Modelling</dc:title>
 <dc:creator>Kulcs&#xe1;r, G&#xe9;za</dc:creator>
 <dc:creator>Anjorin, Anthony</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Graph Transformation (GraTra) provides a formal, declarative means of
specifying model transformation. In practice, GraTra rule applications are
often programmed via an additional language with which the order of rule
applications can be suitably controlled.
  Story-Driven Modelling (SDM) is a dialect of programmed GraTra, originally
developed as part of the Fujaba CASE tool suite. Using an intuitive,
UML-inspired visual syntax, SDM provides usual imperative control flow
constructs such as sequences, conditionals and loops that are fairly simple,
but whose interaction with individual GraTra rules is nonetheless non-trivial.
In this paper, we present the first results of our ongoing work towards
providing a formal step semantics for SDM, which focuses on the execution of an
SDM specification.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2016, arXiv:1612.01053</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01640</dc:identifier>
 <dc:identifier>EPTCS 231, 2016, pp. 42-56</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.231.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01641</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental View Maintenance for Deductive Graph Databases Using
  Generalized Discrimination Networks</dc:title>
 <dc:creator>Beyhl, Thomas</dc:creator>
 <dc:creator>Giese, Holger</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Nowadays, graph databases are employed when relationships between entities
are in the scope of database queries to avoid performance-critical join
operations of relational databases. Graph queries are used to query and modify
graphs stored in graph databases. Graph queries employ graph pattern matching
that is NP-complete for subgraph isomorphism. Graph database views can be
employed that keep ready answers in terms of precalculated graph pattern
matches for often stated and complex graph queries to increase query
performance. However, such graph database views must be kept consistent with
the graphs stored in the graph database.
  In this paper, we describe how to use incremental graph pattern matching as
technique for maintaining graph database views. We present an incremental
maintenance algorithm for graph database views, which works for imperatively
and declaratively specified graph queries. The evaluation shows that our
maintenance algorithm scales when the number of nodes and edges stored in the
graph database increases. Furthermore, our evaluation shows that our approach
can outperform existing approaches for the incremental maintenance of graph
query results.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2016, arXiv:1612.01053</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01641</dc:identifier>
 <dc:identifier>EPTCS 231, 2016, pp. 57-71</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.231.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01642</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On High-Order Capacity Statistics of Spectrum Aggregation Systems over
  $\kappa$-$\mu$ and $\kappa$-$\mu$ shadowed Fading Channels</dc:title>
 <dc:creator>Zhang, Jiayi</dc:creator>
 <dc:creator>Chen, Xiaoyu</dc:creator>
 <dc:creator>Peppas, Kostas P.</dc:creator>
 <dc:creator>Li, Xu</dc:creator>
 <dc:creator>Liu, Ying</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The frequency scarcity imposed by fast growing demand for mobile data service
requires promising spectrum aggregation systems. The so-called higher-order
statistics (HOS) of the channel capacity is a suitable metric on the system
performance. While prior relevant works have improved our knowledge on the HOS
characterization of spectrum aggregation systems, an analytical framework
encompassing generalized fading models of interest is not yet available. In
this paper, we pursue a detailed HOS analysis of $\kappa$-$\mu$ and
$\kappa$-$\mu$ shadowed fading channels by deriving novel and exact
expressions. Furthermore, the simplified HOS expressions for the asymptotically
low and high signal-to-noise regimes are derived. Several important statistical
measures, such as amount of fading, amount of dispersion, reliability,
skewness, and kurtosis, are obtained by using the HOS results. More
importantly, the useful implications of system and fading parameters on
spectrum aggregation systems are investigated for channel selection. Finally,
all derived expressions are validated via Monte-Carlo simulations.
</dc:description>
 <dc:description>Comment: to appear in IEEE Transactions on Communications</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01650</identifier>
 <datestamp>2017-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Closed-Chain Manipulation of Large Objects by Multi-Arm Robotic Systems</dc:title>
 <dc:creator>Zhou, Xian</dc:creator>
 <dc:creator>Lertkultanon, Puttichai</dc:creator>
 <dc:creator>Pham, Quang-Cuong</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Closed kinematic chains are created whenever multiple robot arms concurrently
manipulate a single object. The closed-chain constraint, when coupled with
robot joint limits, dramatically changes the connectivity of the configuration
space. We propose a regrasping move, termed &quot;IK-switch&quot;, which allows
efficiently bridging components of the configuration space that are otherwise
mutually disconnected. This move, combined with several other developments,
such as a method to stabilize the manipulated object using the environment, a
new tree structure, and a compliant control scheme, enables us to address
complex closed-chain manipulation tasks, such as flipping a chair frame, which
is otherwise impossible to realize using existing multi-arm planning methods.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, 1 table</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01650</dc:identifier>
 <dc:identifier>doi:10.1109/LRA.2017.2708134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01652</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experimental Study of Forrelation in Nuclear Spins</dc:title>
 <dc:creator>Li, Hang</dc:creator>
 <dc:creator>Gao, Xun</dc:creator>
 <dc:creator>Xin, Tao</dc:creator>
 <dc:creator>Yung, Man-Hong</dc:creator>
 <dc:creator>Long, Guilu</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Correlation functions are often employed to quantify the relationships among
interdependent variables or sets of data. Recently, a new class of correlation
functions, called Forrelation, has been introduced by Aaronson and Ambainis for
studying the query complexity of quantum devices. It was found that there
exists a quantum query algorithm solving 2-fold Forrelation problems with an
exponential quantum speedup over all possible classical means, which represents
essentially the largest possible separation between quantum and classical query
complexities. Here we report an experimental study probing the 2-fold and
3-fold Forrelations encoded in nuclear spins. The major experimental challenge
is to control the spin fluctuation to within a threshold value, which is
achieved by developing a set of optimized GRAPE pulse sequences. Overall, our
small-scale implementation indicates that the quantum query algorithm is
capable of determine the values of Forrelations within an acceptable accuracy
required for demonstrating quantum supremacy, given the current technology and
in the presence of experimental noise.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01655</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-grained Recurrent Neural Networks for Automatic Prostate
  Segmentation in Ultrasound Images</dc:title>
 <dc:creator>Yang, Xin</dc:creator>
 <dc:creator>Yu, Lequan</dc:creator>
 <dc:creator>Wu, Lingyun</dc:creator>
 <dc:creator>Wang, Yi</dc:creator>
 <dc:creator>Ni, Dong</dc:creator>
 <dc:creator>Qin, Jing</dc:creator>
 <dc:creator>Heng, Pheng-Ann</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Boundary incompleteness raises great challenges to automatic prostate
segmentation in ultrasound images. Shape prior can provide strong guidance in
estimating the missing boundary, but traditional shape models often suffer from
hand-crafted descriptors and local information loss in the fitting procedure.
In this paper, we attempt to address those issues with a novel framework. The
proposed framework can seamlessly integrate feature extraction and shape prior
exploring, and estimate the complete boundary with a sequential manner. Our
framework is composed of three key modules. Firstly, we serialize the static 2D
prostate ultrasound images into dynamic sequences and then predict prostate
shapes by sequentially exploring shape priors. Intuitively, we propose to learn
the shape prior with the biologically plausible Recurrent Neural Networks
(RNNs). This module is corroborated to be effective in dealing with the
boundary incompleteness. Secondly, to alleviate the bias caused by different
serialization manners, we propose a multi-view fusion strategy to merge shape
predictions obtained from different perspectives. Thirdly, we further implant
the RNN core into a multiscale Auto-Context scheme to successively refine the
details of the shape prediction map. With extensive validation on challenging
prostate ultrasound images, our framework bridges severe boundary
incompleteness and achieves the best performance in prostate boundary
delineation when compared with several advanced methods. Additionally, our
approach is general and can be extended to other medical image segmentation
tasks, where boundary incompleteness is one of the main challenges.
</dc:description>
 <dc:description>Comment: To appear in AAAI Conference 2017</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01657</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Subspace Coding for Query-by-Image Video Retrieval</dc:title>
 <dc:creator>Xu, Ruicong</dc:creator>
 <dc:creator>Yang, Yang</dc:creator>
 <dc:creator>Luo, Yadan</dc:creator>
 <dc:creator>Shen, Fumin</dc:creator>
 <dc:creator>Huang, Zi</dc:creator>
 <dc:creator>Shen, Heng Tao</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The query-by-image video retrieval (QBIVR) task has been attracting
considerable research attention recently. However, most existing methods
represent a video by either aggregating or projecting all its frames into a
single datum point, which may easily cause severe information loss. In this
paper, we propose an efficient QBIVR framework to enable an effective and
efficient video search with image query. We first define a
similarity-preserving distance metric between an image and its orthogonal
projection in the subspace of the video, which can be equivalently transformed
to a Maximum Inner Product Search (MIPS) problem.
  Besides, to boost the efficiency of solving the MIPS problem, we propose two
asymmetric hashing schemes, which bridge the domain gap of images and videos.
The first approach, termed Inner-product Binary Coding (IBC), preserves the
inner relationships of images and videos in a common Hamming space. To further
improve the retrieval efficiency, we devise a Bilinear Binary Coding (BBC)
approach, which employs compact bilinear projections instead of a single large
projection matrix. Extensive experiments have been conducted on four real-world
video datasets to verify the effectiveness of our proposed approaches as
compared to the state-of-the-arts.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01659</identifier>
 <datestamp>2017-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fractal Intersections and Products via Algorithmic Dimension</dc:title>
 <dc:creator>Lutz, Neil</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  Algorithmic dimensions quantify the algorithmic information density of
individual points and may be defined in terms of Kolmogorov complexity. This
work uses these dimensions to bound the classical Hausdorff and packing
dimensions of intersections and Cartesian products of fractals in Euclidean
spaces. This approach shows that a known intersection formula for Borel sets
holds for arbitrary sets, and it significantly simplifies the proof of a known
product formula. Both of these formulas are prominent, fundamental results in
fractal geometry that are taught in typical undergraduate courses on the
subject.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01663</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Non-oblivious Randomized Reduction for Risk Minimization with
  Improved Excess Risk Guarantee</dc:title>
 <dc:creator>Xu, Yi</dc:creator>
 <dc:creator>Yang, Haiqin</dc:creator>
 <dc:creator>Zhang, Lijun</dc:creator>
 <dc:creator>Yang, Tianbao</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we address learning problems for high dimensional data.
Previously, oblivious random projection based approaches that project high
dimensional features onto a random subspace have been used in practice for
tackling high-dimensionality challenge in machine learning. Recently, various
non-oblivious randomized reduction methods have been developed and deployed for
solving many numerical problems such as matrix product approximation, low-rank
matrix approximation, etc. However, they are less explored for the machine
learning tasks, e.g., classification. More seriously, the theoretical analysis
of excess risk bounds for risk minimization, an important measure of
generalization performance, has not been established for non-oblivious
randomized reduction methods. It therefore remains an open problem what is the
benefit of using them over previous oblivious random projection based
approaches. To tackle these challenges, we propose an algorithmic framework for
employing non-oblivious randomized reduction method for general empirical risk
minimizing in machine learning tasks, where the original high-dimensional
features are projected onto a random subspace that is derived from the data
with a small matrix approximation error. We then derive the first excess risk
bound for the proposed non-oblivious randomized reduction approach without
requiring strong assumptions on the training data. The established excess risk
bound exhibits that the proposed approach provides much better generalization
performance and it also sheds more insights about different randomized
reduction approaches. Finally, we conduct extensive experiments on both
synthetic and real-world benchmark datasets, whose dimension scales to
$O(10^7)$, to demonstrate the efficacy of our proposed approach.
</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01669</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MarioQA: Answering Questions by Watching Gameplay Videos</dc:title>
 <dc:creator>Mun, Jonghwan</dc:creator>
 <dc:creator>Seo, Paul Hongsuck</dc:creator>
 <dc:creator>Jung, Ilchae</dc:creator>
 <dc:creator>Han, Bohyung</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a framework to analyze various aspects of models for video
question answering (VideoQA) using customizable synthetic datasets, which are
constructed automatically from gameplay videos. Our work is motivated by the
fact that existing models are often tested only on datasets that require
excessively high-level reasoning or mostly contain instances accessible through
single frame inferences. Hence, it is difficult to measure capacity and
flexibility of trained models, and existing techniques often rely on ad-hoc
implementations of deep neural networks without clear insight into datasets and
models. We are particularly interested in understanding temporal relationships
between video events to solve VideoQA problems; this is because reasoning
temporal dependency is one of the most distinct components in videos from
images. To address this objective, we automatically generate a customized
synthetic VideoQA dataset using {\em Super Mario Bros.} gameplay videos so that
it contains events with different levels of reasoning complexity. Using the
dataset, we show that properly constructed datasets with events in various
complexity levels are critical to learn effective models and improve overall
performance.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01675</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Managing Usability and Reliability Aspects in Cloud Computing</dc:title>
 <dc:creator>Spichkova, Maria</dc:creator>
 <dc:creator>Schmidt, Heinz W.</dc:creator>
 <dc:creator>Thomas, Ian E.</dc:creator>
 <dc:creator>Yusuf, Iman I.</dc:creator>
 <dc:creator>Androulakis, Steve</dc:creator>
 <dc:creator>Meyer, Grischa R.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Cloud computing provides a great opportunity for scientists, as it enables
large-scale experiments that cannot are too long to run on local desktop
machines. Cloud-based computations can be highly parallel, long running and
data-intensive, which is desirable for many kinds of scientific experiments.
However, to unlock this power, we need a user-friendly interface and an
easy-to-use methodology for conducting these experiments. For this reason, we
introduce here a formal model of a cloud-based platform and the corresponding
open-source implementation. The proposed solution allows to conduct experiments
without having a deep technical understanding of cloud-computing, HPC, fault
tolerance, or data management in order to leverage the benefits of cloud
computing. In the current version, we have focused on biophysics and structural
chemistry experiments, based on the analysis of big data from synchrotrons and
atomic force microscopy. The domain experts noted the time savings for
computing and data management, as well as user-friendly interface.
</dc:description>
 <dc:description>Comment: Preprint. Accepted to the 11th International Conference on Evaluation
  of Novel Approaches to Software Engineering (ENASE 2016). Final version
  published by SCITEPRESS, http://www.scitepress.org</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01680</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-based generation of natural language specifications</dc:title>
 <dc:creator>Nhat, Phan Vo Thu</dc:creator>
 <dc:creator>Spichkova, Maria</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Application of formal models provides many benefits for the software and
system development, however, the learning curve of formal languages could be a
critical factor for an industrial project. Thus, a natural language
specification that reflects all the aspects of the formal model might help to
understand the model and be especially useful for the stakeholders who do not
know the corresponding formal language. Moreover, an automated generation of
the documentation from the model would replace manual updates of the
documentation for the cases the model is modified. This paper presents an
ongoing work on generating natural language specifications from formal models.
Our goal is to generate documentation in English from the basic modelling
artefacts, such as data types, state machines, and architectural components. To
allow further formal analysis of the generated specification, we restrict
English to its subset, Attempto Controlled English.
</dc:description>
 <dc:description>Comment: Preprint. Accepted to the Software Technologies: Applications and
  Foundations (STAF 2016). Final version published by Springer International
  Publishing AG</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01682</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Boring formal methods&quot; or &quot;Sherlock Holmes deduction methods&quot;?</dc:title>
 <dc:creator>Spichkova, Maria</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This paper provides an overview of common challenges in teaching of logic and
formal methods to Computer Science and IT students. We discuss our experiences
from the course IN3050: Applied Logic in Engineering, introduced as a &quot;logic
for everybody&quot; elective course at at TU Munich, Germany, to engage pupils
studying Computer Science, IT and engineering subjects on Bachelor and Master
levels. Our goal was to overcome the bias that logic and formal methods are not
only very complicated but also very boring to study and to apply. In this
paper, we present the core structure of the course, provide examples of
exercises and evaluate the course based on the students' surveys.
</dc:description>
 <dc:description>Comment: Preprint. Accepted to the Software Technologies: Applications and
  Foundations (STAF 2016). Final version published by Springer International
  Publishing AG. arXiv admin note: substantial text overlap with
  arXiv:1602.05170</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01684</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput-Optimal Load Balancing for Intra Datacenter Networks</dc:title>
 <dc:creator>Supittayapornpong, Sucha</dc:creator>
 <dc:creator>Neely, Michael J.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Traffic load-balancing in datacenters alleviates hot spots and improves
network utilization. In this paper, a stable in-network load-balancing
algorithm is developed in the setting of software-defined networking. A control
plane configures a data plane over successive intervals of time. While the
MaxWeight algorithm can be applied in this setting and offers certain
throughput optimality properties, its bang-bang control structure rewards
single flows on each interval and prohibits link-capacity sharing. This paper
develops a new algorithm that is throughput-optimal and allows link-capacity
sharing, leading to low queue occupancy. The algorithm deliberately imitates
weighted fair queueing, which provides fairness and graceful interaction with
TCP traffic. Inspired by insights from the analysis, a heuristic improvement is
also developed to operate with practical switches and TCP flows. Simulations
from a network simulator shows that the algorithm outperforms the widely-used
equal-cost multipath (ECMP) technique.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01686</identifier>
 <datestamp>2016-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-temporal Models for Formal Analysis and Property-based Testing</dc:title>
 <dc:creator>Alzahrani, Nasser</dc:creator>
 <dc:creator>Spichkova, Maria</dc:creator>
 <dc:creator>Blech, Jan Olaf</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This paper presents our ongoing work on spatio-temporal models for formal
analysis and property-based testing. Our proposed framework aims at reducing
the impedance mismatch between formal methods and practitioners. We introduce a
set of formal methods and explain their interplay and benefits in terms of
usability.
</dc:description>
 <dc:description>Comment: Preprint. Accepted to the Software Technologies: Applications and
  Foundations (STAF 2016). Final version published by Springer International
  Publishing AG</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2016-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01689</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cluster-Wise Ratio Tests for Fast Camera Localization</dc:title>
 <dc:creator>D&#xed;az, Ra&#xfa;l</dc:creator>
 <dc:creator>Fowlkes, Charless C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Feature point matching for camera localization suffers from scalability
problems. Even when feature descriptors associated with 3D scene points are
locally unique, as coverage grows, similar or repeated features become
increasingly common. As a result, the standard distance ratio-test used to
identify reliable image feature points is overly restrictive and rejects many
good candidate matches. We propose a simple coarse-to-fine strategy that uses
conservative approximations to robust local ratio-tests that can be computed
efficiently using global approximate k-nearest neighbor search. We treat these
forward matches as votes in camera pose space and use them to prioritize
back-matching within candidate camera pose clusters, exploiting feature
co-visibility captured by clustering the 3D model camera pose graph. This
approach achieves state-of-the-art camera localization results on a variety of
popular benchmarks, outperforming several methods that use more complicated
data structures and that make more restrictive assumptions on camera pose. We
also carry out diagnostic analyses on a difficult test dataset containing
globally repetitive structure that suggest our approach successfully adapts to
the challenges of large-scale image localization.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01691</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fleet Size and Mix Split-Delivery Vehicle Routing</dc:title>
 <dc:creator>Mah&#xe9;o, Arthur</dc:creator>
 <dc:creator>Urli, Tommaso</dc:creator>
 <dc:creator>Kilby, Philip</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>90B06, 90C11</dc:subject>
 <dc:description>  In the classic Vehicle Routing Problem (VRP) a fleet of of vehicles has to
visit a set of customers while minimising the operations' costs. We study a
rich variant of the VRP featuring split deliveries, an heterogeneous fleet, and
vehicle-commodity incompatibility constraints. Our goal is twofold: define the
cheapest routing and the most adequate fleet.
  To do so, we split the problem into two interdependent components: a fleet
design component and a routing component. First, we define two Mixed Integer
Programming (MIP) formulations for each component. Then we discuss several
improvements in the form of valid cuts and symmetry breaking constraints.
  The main contribution of this paper is a comparison of the four resulting
models for this Rich VRP. We highlight their strengths and weaknesses with
extensive experiments.
  Finally, we explore a lightweight integration with Constraint Programming
(CP). We use a fast CP model which gives good solutions and use the solution to
warm-start our models.
</dc:description>
 <dc:description>Comment: Rich Vehicle Routing, Split Delivery, Fleet Size and Mix, Mixed
  Integer Programming, Constraint Programming</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01693</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Evaluation of Alternate Enumeration Techniques for Subset Sum
  Problem</dc:title>
 <dc:creator>Verma, Avni</dc:creator>
 <dc:creator>Karlapalem, Kamalakar</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The subset sum problem, also referred as SSP, is a NP-Hard computational
problem. SSP has its applications in broad domains like cryptography, number
theory, operation research and complexity theory. The most famous algorithm for
solving SSP is Backtracking Algorithm which has exponential time complexity.
Therefore, our goal is to design and develop better alternate enumeration
techniques for faster generation of SSP solutions. Given the set of first n
natural numbers which is denoted by Xn and a target sum S, we propose various
alternate enumeration techniques which find all the subsets of Xn that add up
to sum S.
  In this paper, we present the mathematics behind this exponential problem. We
analyze the distribution of power set of Xn and present formulas which show
definite patterns and relations among these subsets. We introduce three major
distributions for power set of Xn: Sum Distribution, Length-Sum Distribution
and Element Distribution. These distributions are prepossessing procedures for
various alternate enumeration techniques for solving SSP. We propose novel
algorithms: Subset Generation using Sum Distribution, Subset Generation using
Length-Sum Distribution, Basic Bucket Algorithm, Maximum and Minimum Frequency
Driven Bucket Algorithms and Local Search using Maximal and Minimal Subsets for
enumerating SSP.
  We compare the performance of these approaches against the traditional
backtracking algorithm. The efficiency and effectiveness of these algorithms
are presented with the help of these experimental results. Furthermore, we
studied the over solution set of subsets generated by various algorithms to get
the complete solution for subset sum problem. Finally, we present a conjecture
about upper bound on the number of subsets that has to be enumerated to get all
solutions for Subset Sum Problem.
</dc:description>
 <dc:description>Comment: 39 pages, 4 figures, 19 tables</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2016-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01696</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Approximate Polytope Membership</dc:title>
 <dc:creator>Arya, Sunil</dc:creator>
 <dc:creator>da Fonseca, Guilherme D.</dc:creator>
 <dc:creator>Mount, David M.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  In the polytope membership problem, a convex polytope $K$ in $R^d$ is given,
and the objective is to preprocess $K$ into a data structure so that, given a
query point $q \in R^d$, it is possible to determine efficiently whether $q \in
K$. We consider this problem in an approximate setting and assume that $d$ is a
constant. Given an approximation parameter $\varepsilon &gt; 0$, the query can be
answered either way if the distance from $q$ to $K$'s boundary is at most
$\varepsilon$ times $K$'s diameter. Previous solutions to the problem were on
the form of a space-time trade-off, where logarithmic query time demands
$O(1/\varepsilon^{d-1})$ storage, whereas storage $O(1/\varepsilon^{(d-1)/2})$
admits roughly $O(1/\varepsilon^{(d-1)/8})$ query time. In this paper, we
present a data structure that achieves logarithmic query time with storage of
only $O(1/\varepsilon^{(d-1)/2})$, which matches the worst-case lower bound on
the complexity of any $\varepsilon$-approximating polytope. Our data structure
is based on a new technique, a hierarchy of ellipsoids defined as
approximations to Macbeath regions.
  As an application, we obtain major improvements to approximate Euclidean
nearest neighbor searching. Notably, the storage needed to answer
$\varepsilon$-approximate nearest neighbor queries for a set of $n$ points in
$O(\log \frac{n}{\varepsilon})$ time is reduced to $O(n/\varepsilon^{d/2})$.
This halves the exponent in the $\varepsilon$-dependency of the existing space
bound of roughly $O(n/\varepsilon^d)$, which has stood for 15 years (Har-Peled,
2001).
</dc:description>
 <dc:description>Comment: SODA 2017</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01696</dc:identifier>
 <dc:identifier>doi:10.1137/1.9781611974782.18</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01697</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Neural Networks for No-Reference and Full-Reference Image Quality
  Assessment</dc:title>
 <dc:creator>Bosse, Sebastian</dc:creator>
 <dc:creator>Maniry, Dominique</dc:creator>
 <dc:creator>M&#xfc;ller, Klaus-Robert</dc:creator>
 <dc:creator>Wiegand, Thomas</dc:creator>
 <dc:creator>Samek, Wojciech</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a deep neural network-based approach to image quality assessment
(IQA). The network is trained end-to-end and comprises ten convolutional layers
and five pooling layers for feature extraction, and two fully connected layers
for regression, which makes it significantly deeper than related IQA models.
Unique features of the proposed architecture are that: 1) with slight
adaptations it can be used in a no-reference (NR) as well as in a
full-reference (FR) IQA setting and 2) it allows for joint learning of local
quality and local weights, i.e., relative importance of local quality to the
global quality estimate, in an unified framework. Our approach is purely
data-driven and does not rely on hand-crafted features or other types of prior
domain knowledge about the human visual system or image statistics. We evaluate
the proposed approach on the LIVE, CISQ, and TID2013 databases as well as the
LIVE In the wild image quality challenge database and show superior performance
to state-of-the-art NR and FR IQA methods. Finally, cross-database evaluation
shows a high ability to generalize between different databases, indicating a
high robustness of the learned features.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01697</dc:identifier>
 <dc:identifier>IEEE Transactions on Image Processing, 27(1):206-219, 2018</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2017.2760518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01704</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Method of Detecting Core-Periphery Structure and Community
  Structure in Networks</dc:title>
 <dc:creator>Xiang, Bing-Bing</dc:creator>
 <dc:creator>Bao, Zhong-Kui</dc:creator>
 <dc:creator>Ma, Chuang</dc:creator>
 <dc:creator>Zhang, Xingyi</dc:creator>
 <dc:creator>Chen, Han-Shuang</dc:creator>
 <dc:creator>Zhang, Hai-Feng</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Core-periphery structure and community structure are two typical meso-scale
structures in complex networks. Though the community detection has been
extensively investigated from different perspectives, the definition and the
detection of core-periphery structure have not received much attention.
Furthermore, the detection problems of the core-periphery and community
structure were separately investigated. In this paper, we develop a unified
framework to simultaneously detect core-periphery structure and community
structure in complex networks. Moreover, there are several extra advantages of
our algorithm: our method can detect not only single but also multiple pairs of
core-periphery structures; the overlapping nodes belonging to different
communities can be identified; different scales of core-periphery structures
can be detected by adjusting the size of core. The good performance of the
method has been validated on synthetic and real complex networks. So we provide
a basic framework to detect the two typical meso-scale structures:
core-periphery structure and community structure.
</dc:description>
 <dc:description>Comment: 10 figures. Accepted by Chaos</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01704</dc:identifier>
 <dc:identifier>Chaos, 28,013122, (2018)</dc:identifier>
 <dc:identifier>doi:10.1063/1.4990734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01707</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Byzantine Attacks for Gaussian Two-Way Relay System</dc:title>
 <dc:creator>Cao, Ruohan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper focuses on Byzantine attack detection for Gaussian two-way relay
network. In this network, two source nodes communicate with each other with the
help of an amplify-and-forward relay which may perform Byzantine attacks by
forwarding altered symbols to the sources. For simple investigating the
detectability of attacks conducted in Gaussian channels, we focus on the MA
channel of the network, while assuming the BC channel is noiseless. Upon such
model, we propose a attack detection scheme implemented in the sources.
Specifically, we consider a open wireless propagation environment that allows
the symbols, forwarded by the relay, to go through a continuous channel and
arrive to the sources. With the observations of the source, we develop a
detection scheme for the source by comparing the joint empirical distribution
of its received and transmitted signals with the known channel statistics. The
main contribution of this paper is to prove that if and only if the Gaussian
relay network satisfies a non-manipulable channel condition, the proposed
detection scheme can detect arbitrary attacks that allows the stochastic
distributions of altered symbols to vary arbitrarily and depend on each other.
No pre-shared secret or secret transmission is needed for the detection.
Furthermore, we also prove that for the considered Gaussian two-way relay
networks, the non-manipulable channel condition is always satisfied. This
result indicates that arbitrary attacks conducted in MA Gaussian channels are
detectable by only using observations, while providing a base for attack
detection in more general Gaussian networks.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01707</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01711</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memristor Threshold Logic: An Overview to Challenges and Applications</dc:title>
 <dc:creator>James, Alex Pappachen</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Once referred to as the missing circuit component, memristor has come long
way across to be recognized and taken as important to future circuit designs.
The memristor due to its ability to memorize the state, switch between
different resistance level, smaller size and low leakage currents makes it
useful for a wide range of intelligent memory and computing applications. This
overview paper highlights broadly provides the uses of memristor in the
implementation of cognitive cells for different imaging and pattern matching
applications.
</dc:description>
 <dc:description>Comment: Invited paper, International Conference on Contemporary Computing and
  Informatics, Dec, 2016</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01717</identifier>
 <datestamp>2017-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical mechanics of unsupervised feature learning in a restricted
  Boltzmann machine with binary synapses</dc:title>
 <dc:creator>Huang, Haiping</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Revealing hidden features in unlabeled data is called unsupervised feature
learning, which plays an important role in pretraining a deep neural network.
Here we provide a statistical mechanics analysis of the unsupervised learning
in a restricted Boltzmann machine with binary synapses. A message passing
equation to infer the hidden feature is derived, and furthermore, variants of
this equation are analyzed. A statistical analysis by replica theory describes
the thermodynamic properties of the model. Our analysis confirms an entropy
crisis preceding the non-convergence of the message passing equation,
suggesting a discontinuous phase transition as a key characteristic of the
restricted Boltzmann machine. Continuous phase transition is also confirmed
depending on the embedded feature strength in the data. The mean-field result
under the replica symmetric assumption agrees with that obtained by running
message passing algorithms on single instances of finite sizes. Interestingly,
in an approximate Hopfield model, the entropy crisis is absent, and a
continuous phase transition is observed instead. We also develop an iterative
equation to infer the hyper-parameter (temperature) hidden in the data, which
in physics corresponds to iteratively imposing Nishimori condition. Our study
provides insights towards understanding the thermodynamic properties of the
restricted Boltzmann machine learning, and moreover important theoretical basis
to build simplified deep networks.
</dc:description>
 <dc:description>Comment: 24 pages, 9 figures, results added</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01717</dc:identifier>
 <dc:identifier>J. Stat. Mech. (2017) 053302</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/aa6ddc</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01720</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weighted Matrix Completion and Recovery with Prior Subspace Information</dc:title>
 <dc:creator>Eftekhari, Armin</dc:creator>
 <dc:creator>Yang, Dehui</dc:creator>
 <dc:creator>Wakin, Michael B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  An incoherent low-rank matrix can be efficiently reconstructed after
observing a few of its entries at random, and then solving a convex program
that minimizes the nuclear norm. In many applications, in addition to these
entries, potentially valuable prior knowledge about the column and row spaces
of the matrix is also available to the practitioner. In this paper, we
incorporate this prior knowledge in matrix completion---by minimizing a
weighted nuclear norm---and precisely quantify any improvements. In particular,
we find in theory that reliable prior knowledge reduces the sample complexity
of matrix completion by a logarithmic factor, and the observed improvement in
numerical simulations is considerably more magnified. We also present similar
results for the closely related problem of matrix recovery from generic linear
measurements.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01721</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the power domination number of de Bruijn and Kautz digraphs</dc:title>
 <dc:creator>Grigorious, Cyriac</dc:creator>
 <dc:creator>Kalinowski, Thomas</dc:creator>
 <dc:creator>Ryan, Joe</dc:creator>
 <dc:creator>Stephen, Sudeep</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Let $G=(V,A)$ be a directed graph without parallel arcs, and let $S\subseteq
V$ be a set of vertices. Let the sequence $S=S_0\subseteq S_1\subseteq
S_2\subseteq\cdots$ be defined as follows: $S_1$ is obtained from $S_0$ by
adding all out-neighbors of vertices in $S_0$. For $k\geqslant 2$, $S_k$ is
obtained from $S_{k-1}$ by adding all vertices $w$ such that for some vertex
$v\in S_{k-1}$, $w$ is the unique out-neighbor of $v$ in $V\setminus S_{k-1}$.
We set $M(S)=S_0\cup S_1\cup\cdots$, and call $S$ a \emph{power dominating set}
for $G$ if $M(S)=V(G)$. The minimum cardinality of such a set is called the
\emph{power domination number} of $G$. In this paper, we determine the power
domination numbers of de Bruijn and Kautz digraphs.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01725</identifier>
 <datestamp>2017-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Stereo Matching with Dense CRF Priors</dc:title>
 <dc:creator>Slossberg, Ron</dc:creator>
 <dc:creator>Wetzler, Aaron</dc:creator>
 <dc:creator>Kimmel, Ron</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Stereo reconstruction from rectified images has recently been revisited
within the context of deep learning. Using a deep Convolutional Neural Network
to obtain patch-wise matching cost volumes has resulted in state of the art
stereo reconstruction on classic datasets like Middlebury and Kitti. By
introducing this cost into a classical stereo pipeline, the final results are
improved dramatically over non-learning based cost models. However these
pipelines typically include hand engineered post processing steps to
effectively regularize and clean the result. Here, we show that it is possible
to take a more holistic approach by training a fully end-to-end network which
directly includes regularization in the form of a densely connected Conditional
Random Field (CRF) that acts as a prior on inter-pixel interactions. We
demonstrate that our approach on both synthetic and real world datasets
outperforms an alternative end-to-end network and compares favorably to more
hand engineered approaches.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01728</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Focusing in Orthologic</dc:title>
 <dc:creator>Laurent, Olivier</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We propose new sequent calculus systems for orthologic (also known as minimal
quantum logic) which satisfy the cut elimination property. The first one is a
simple system relying on the involutive status of negation. The second one
incorporates the notion of focusing (coming from linear logic) to add
constraints on proofs and to optimise proof search. We demonstrate how to take
benefits from the new systems in automatic proof search for orthologic.
</dc:description>
 <dc:description>Comment: Small rewritings. Updated benchmark section. Updated coq and ocaml
  files</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01728</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 3 (July 21,
  2017) lmcs:3808</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-13(3:6)2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01734</identifier>
 <datestamp>2017-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Do we really need to catch them all? A new User-guided Social Media
  Crawling method</dc:title>
 <dc:creator>Erlandsson, Fredrik</dc:creator>
 <dc:creator>Br&#xf3;dka, Piotr</dc:creator>
 <dc:creator>Boldt, Martin</dc:creator>
 <dc:creator>Johnson, Henric</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  With the growing use of popular social media services like Facebook and
Twitter it is challenging to collect all content from the networks without
access to the core infrastructure or paying for it. Thus, if all content cannot
be collected one must consider which data are of most importance. In this work
we present a novel User-guided Social Media Crawling method (USMC) that is able
to collect data from social media, utilizing the wisdom of the crowd to decide
the order in which user generated content should be collected to cover as many
user interactions as possible. USMC is validated by crawling 160 public
Facebook pages, containing content from 368 million users including 1.3 billion
interactions, and it is compared with two other crawling methods. The results
show that it is possible to cover approximately 75% of the interactions on a
Facebook page by sampling just 20% of its posts, and at the same time reduce
the crawling time by 53%. In addition, the social network constructed from the
20% sample contains more than 75% of the users and edges compared to the social
network created from all posts, and it has similar degree distribution.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01734</dc:identifier>
 <dc:identifier>Erlandsson, F.; Br\'odka, P.; Boldt, M.; Johnson, H. Do We Really
  Need to Catch Them All? A New User-Guided Social Media Crawling Method.
  Entropy 2017, 19, 686</dc:identifier>
 <dc:identifier>doi:10.3390/e19120686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01744</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Listen and Translate: A Proof of Concept for End-to-End Speech-to-Text
  Translation</dc:title>
 <dc:creator>Berard, Alexandre</dc:creator>
 <dc:creator>Pietquin, Olivier</dc:creator>
 <dc:creator>Servan, Christophe</dc:creator>
 <dc:creator>Besacier, Laurent</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper proposes a first attempt to build an end-to-end speech-to-text
translation system, which does not use source language transcription during
learning or decoding. We propose a model for direct speech-to-text translation,
which gives promising results on a small French-English synthetic corpus.
Relaxing the need for source language transcription would drastically change
the data collection methodology in speech translation, especially in
under-resourced scenarios. For instance, in the former project DARPA TRANSTAC
(speech translation from spoken Arabic dialects), a large effort was devoted to
the collection of speech transcripts (and a prerequisite to obtain transcripts
was often a detailed transcription guide for languages with little standardized
spelling). Now, if end-to-end approaches for speech-to-text translation are
successful, one might consider collecting data by asking bilingual speakers to
directly utter speech in the source language from target language text
utterances. Such an approach has the advantage to be applicable to any
unwritten (source) language.
</dc:description>
 <dc:description>Comment: accepted to NIPS workshop on End-to-end Learning for Speech and Audio
  Processing</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01744</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01746</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Factored Contextual Policy Search with Bayesian Optimization</dc:title>
 <dc:creator>Karkus, Peter</dc:creator>
 <dc:creator>Kupcsik, Andras</dc:creator>
 <dc:creator>Hsu, David</dc:creator>
 <dc:creator>Lee, Wee Sun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Scarce data is a major challenge to scaling robot learning to truly complex
tasks, as we need to generalize locally learned policies over different
&quot;contexts&quot;. Bayesian optimization approaches to contextual policy search (CPS)
offer data-efficient policy learning that generalize over a context space. We
propose to improve data- efficiency by factoring typically considered contexts
into two components: target- type contexts that correspond to a desired outcome
of the learned behavior, e.g. target position for throwing a ball; and
environment type contexts that correspond to some state of the environment,
e.g. initial ball position or wind speed. Our key observation is that
experience can be directly generalized over target-type contexts. Based on that
we introduce Factored Contextual Policy Search with Bayesian Optimization for
both passive and active learning settings. Preliminary results show faster
policy generalization on a simulated toy problem.
</dc:description>
 <dc:description>Comment: BayesOpt 2016, NIPS Workshop on Bayesian Optimization. 5 pages, 2
  figures</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01746</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01748</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic Indexing for Packed Strings</dc:title>
 <dc:creator>Bille, Philip</dc:creator>
 <dc:creator>G&#xf8;rtz, Inge Li</dc:creator>
 <dc:creator>Skjoldjensen, Frederik Rye</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:description>  Given a string $S$ of length $n$, the classic string indexing problem is to
preprocess $S$ into a compact data structure that supports efficient subsequent
pattern queries. In the \emph{deterministic} variant the goal is to solve the
string indexing problem without any randomization (at preprocessing time or
query time). In the \emph{packed} variant the strings are stored with several
character in a single word, giving us the opportunity to read multiple
characters simultaneously. Our main result is a new string index in the
deterministic \emph{and} packed setting. Given a packed string $S$ of length
$n$ over an alphabet $\sigma$, we show how to preprocess $S$ in $O(n)$
(deterministic) time and space $O(n)$ such that given a packed pattern string
of length $m$ we can support queries in (deterministic) time $O\left(m/\alpha +
\log m + \log \log \sigma\right), $ where $\alpha = w / \log \sigma$ is the
number of characters packed in a word of size $w = \Theta(\log n)$. Our query
time is always at least as good as the previous best known bounds and whenever
several characters are packed in a word, i.e., $\log \sigma \ll w$, the query
times are faster.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01748</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01749</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FoCUS: Fourier-based Coded Ultrasound</dc:title>
 <dc:creator>Lahav, Almog</dc:creator>
 <dc:creator>Chernyakova, Tanya</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Modern imaging systems typically use single-carrier short pulses for
transducer excitation. Coded signals together with pulse compression are
successfully used in radar and communication to increase the amount of
transmitted energy. Previous research verified significant improvement in SNR
and imaging depth for ultrasound imaging with coded signals. Since pulse
compression needs to be applied at each transducer element, the implementation
of coded excitation (CE) in array imaging is computationally complex. Applying
pulse compression on the beamformer output reduces the computational load but
also degrades both the axial and lateral point spread function (PSF)
compromising image quality. In this work we present an approach for efficient
implementation of pulse compression by integrating it into frequency domain
beamforming. This method leads to significant reduction in the amount of
computations without affecting axial resolution. The lateral resolution is
dictated by the factor of savings in computational load. We verify the
performance of our method on a Verasonics imaging system and compare the
resulting images to time-domain processing. We show that up to 77 fold
reduction in computational complexity can be achieved in a typical imaging
setups. The efficient implementation makes CE a feasible approach in array
imaging paving the way to enhanced SNR as well as improved imaging depth and
frame-rate.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01752</identifier>
 <datestamp>2017-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complexity of Single-Swap Heuristics for Metric Facility Location and
  Related Problem</dc:title>
 <dc:creator>Brauer, Sascha</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Metric facility location and $K$-means are well-known problems of
combinatorial optimization. Both admit a fairly simple heuristic called
single-swap, which adds, drops or swaps open facilities until it reaches a
local optimum. For both problems, it is known that this algorithm produces a
solution that is at most a constant factor worse than the respective global
optimum. In this paper, we show that single-swap applied to the weighted metric
uncapacitated facility location and weighted discrete $K$-means problem is
tightly PLS-complete and hence has exponential worst-case running time.
</dc:description>
 <dc:description>Comment: This is a full version of the paper with the same name that will be
  presented at CIAC 2017</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01753</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytical approach to the multiband filter synthesis and comparison to
  other approaches</dc:title>
 <dc:creator>Bogatyrev, Andrei B.</dc:creator>
 <dc:creator>Goreinov, Sergei A.</dc:creator>
 <dc:creator>Lyamaev, Sergei Yu.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>41A20, 93B50, 30E10, 14Hxx, 41A25</dc:subject>
 <dc:description>  A novel analytical approach to the synthesis of electrical (e.g. analogue,
digital or microwave) filters is proposed. This approach allows to obtain
lowest possible degree filters with given involved specification including e.g.
many pass and stop bands, narrow transition bands, high attenuation at the stop
bands and low magnitude oscillations at the pass bands. Comparison to other
existing approaches is given.
</dc:description>
 <dc:description>Comment: 16 pages, in Russian. 17 figures, 2 tables</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01753</dc:identifier>
 <dc:identifier>Problems Inform. Transmission, 53:3 (2017), 260--273</dc:identifier>
 <dc:identifier>doi:10.1134/S0032946017030073</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01756</identifier>
 <datestamp>2017-01-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Ladder Networks</dc:title>
 <dc:creator>Cricri, Francesco</dc:creator>
 <dc:creator>Ni, Xingyang</dc:creator>
 <dc:creator>Honkala, Mikko</dc:creator>
 <dc:creator>Aksu, Emre</dc:creator>
 <dc:creator>Gabbouj, Moncef</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present the Video Ladder Network (VLN) for efficiently generating future
video frames. VLN is a neural encoder-decoder model augmented at all layers by
both recurrent and feedforward lateral connections. At each layer, these
connections form a lateral recurrent residual block, where the feedforward
connection represents a skip connection and the recurrent connection represents
the residual. Thanks to the recurrent connections, the decoder can exploit
temporal summaries generated from all layers of the encoder. This way, the top
layer is relieved from the pressure of modeling lower-level spatial and
temporal details. Furthermore, we extend the basic version of VLN to
incorporate ResNet-style residual blocks in the encoder and decoder, which help
improving the prediction results. VLN is trained in self-supervised regime on
the Moving MNIST dataset, achieving competitive results while having very
simple structure and providing fast inference.
</dc:description>
 <dc:description>Comment: This version extends the paper accepted at the NIPS 2016 workshop on
  ML for Spatiotemporal Forecasting, with more details and more experimental
  results</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2016-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01770</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring field-normalized impact of papers on specific societal groups:
  An altmetrics study based on Mendeley data</dc:title>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:creator>Haunschild, Robin</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Bibliometrics is successful in measuring impact, because the target is
clearly defined: the publishing scientist who is still active and working.
Thus, citations are a target-oriented metric which measures impact on science.
In contrast, societal impact measurements based on altmetrics are as a rule
intended to measure impact in a broad sense on all areas of society (e.g.
science, culture, politics, and economics). This tendency is especially
reflected in the efforts to design composite indicators (e.g. the Altmetric
attention score). We deem appropriate that not only the impact measurement
using citations is target-oriented (citations measure the impact of papers on
scientists), but also the measurement of impact using altmetrics. Impact
measurements only make sense, if the target group - the recipient of academic
papers - is clearly defined. Thus, we extend in this study the field-normalized
reader impact indicator proposed by us in an earlier study, which is based on
Mendeley data (the mean normalized reader score, MNRS), to a target-oriented
field-normalized impact indicator (e.g., MNRS_ED measures reader impact on the
sector of educational donation, i.e., teaching). This indicator can show - as
demonstrated in empirical examples - the ability of journals, countries, and
academic institutions to publish papers which are below or above the average
impact of papers on a specific sector in society (e.g., the educational or
teaching sector). For example, the method allows to measure the impact of
scientific papers on students - controlling for the field in which the papers
have been published and their publication year.
</dc:description>
 <dc:description>Comment: In press at Research Evaluation</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01770</dc:identifier>
 <dc:identifier>doi:10.1093/reseval/rvx005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01785</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Local Commuting Patterns From Geolocated Twitter Data</dc:title>
 <dc:creator>McNeill, Graham</dc:creator>
 <dc:creator>Bright, Jonathan</dc:creator>
 <dc:creator>Hale, Scott A.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The emergence of large stores of transactional data generated by increasing
use of digital devices presents a huge opportunity for policymakers to improve
their knowledge of the local environment and thus make more informed and better
decisions. A research frontier is hence emerging which involves exploring the
type of measures that can be drawn from data stores such as mobile phone logs,
Internet searches and contributions to social media platforms, and the extent
to which these measures are accurate reflections of the wider population. This
paper contributes to this research frontier, by exploring the extent to which
local commuting patterns can be estimated from data drawn from Twitter. It
makes three contributions in particular. First, it shows that simple heuristics
drawn from geolocated Twitter data offer a good proxy for local commuting
patterns; one which outperforms the major existing method for estimating these
patterns (the radiation model). Second, it investigates sources of error in the
proxy measure, showing that the model performs better on short trips with
higher volumes of commuters; it also looks at demographic biases but finds
that, surprisingly, measurements are not significantly affected by the fact
that the demographic makeup of Twitter users differs significantly from the
population as a whole. Finally, it looks at potential ways of going beyond
simple heuristics by incorporating temporal information into models.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01785</dc:identifier>
 <dc:identifier>Graham McNeill, Jonathan Bright and Scott A Hale (2017) Estimating
  local commuting patterns from geolocated Twitter data, EPJ Data Science
  20176:24</dc:identifier>
 <dc:identifier>doi:10.1140/epjds/s13688-017-0120-x</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01787</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PRIMA: Privacy-Preserving Identity and Access Management at
  Internet-Scale</dc:title>
 <dc:creator>Asghar, Muhammad Rizwan</dc:creator>
 <dc:creator>Backes, Michael</dc:creator>
 <dc:creator>Simeonovski, Milivoj</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The management of identities on the Internet has evolved from the traditional
approach (where each service provider stores and manages identities) to a
federated identity management system (where the identity management is
delegated to a set of identity providers). On the one hand, federated identity
ensures usability and provides economic benefits to service providers. On the
other hand, it poses serious privacy threats to users as well as service
providers. The current technology, which is prevalently deployed on the
Internet, allows identity providers to track the user's behavior across a broad
range of services.
  In this work, we propose PRIMA, a universal credential-based authentication
system for supporting federated identity management in a privacy-preserving
manner. Basically, PRIMA does not require any interaction between service
providers and identity providers during the authentication process, thus
preventing identity providers to profile users' behavior. Moreover, throughout
the authentication process, PRIMA provides a mechanism for controlled
disclosure of the users' private information. We have conducted comprehensive
evaluations of the system to show the feasibility of our approach. Our
performance analysis shows that an identity provider can process 1,426 to 3,332
requests per second when the key size is varied from 1024 to 2048-bit,
respectively.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01810</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FLIC: Fast Linear Iterative Clustering with Active Search</dc:title>
 <dc:creator>Zhao, Jia-Xin</dc:creator>
 <dc:creator>Bo, Ren</dc:creator>
 <dc:creator>Hou, Qibin</dc:creator>
 <dc:creator>Cheng, Ming-Ming</dc:creator>
 <dc:creator>Rosin, Paul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Benefiting from its high efficiency and simplicity, Simple Linear Iterative
Clustering (SLIC) remains one of the most popular over-segmentation tools.
However, due to explicit enforcement of spatial similarity for region
continuity, the boundary adaptation of SLIC is sub-optimal. It also has
drawbacks on convergence rate as a result of both the fixed search region and
separately doing the assignment step and the update step. In this paper, we
propose an alternative approach to fix the inherent limitations of SLIC. In our
approach, each pixel actively searches its corresponding segment under the help
of its neighboring pixels, which naturally enables region coherence without
being harmful to boundary adaptation. We also jointly perform the assignment
and update steps, allowing high convergence rate. Extensive evaluations on
Berkeley segmentation benchmark verify that our method outperforms competitive
methods under various evaluation metrics. It also has the lowest time cost
among existing methods (approximately 30fps for a 481x321 image on a single CPU
core).
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01810</dc:identifier>
 <dc:identifier>AAAI 2018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01812</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control Matching via Discharge Code Sequences</dc:title>
 <dc:creator>Nguyen, Dang</dc:creator>
 <dc:creator>Luo, Wei</dc:creator>
 <dc:creator>Phung, Dinh</dc:creator>
 <dc:creator>Venkatesh, Svetha</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we consider the patient similarity matching problem over a
cancer cohort of more than 220,000 patients. Our approach first leverages on
Word2Vec framework to embed ICD codes into vector-valued representation. We
then propose a sequential algorithm for case-control matching on this
representation space of diagnosis codes. The novel practice of applying the
sequential matching on the vector representation lifted the matching accuracy
measured through multiple clinical outcomes. We reported the results on a
large-scale dataset to demonstrate the effectiveness of our method. For such a
large dataset where most clinical information has been codified, the new method
is particularly relevant.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01814</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symmetries in the wheeled inverted pendulum mechanism</dc:title>
 <dc:creator>Gajbhiye, Sneha</dc:creator>
 <dc:creator>Banavar, Ravi N.</dc:creator>
 <dc:creator>Delgado, Sergio</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The purpose of this article is to illustrate the role of connections and
symmetries in the Wheeled Inverted Pendulum (WIP) mechanism - an underactuated
system with rolling constraints - popularized commercially as the Segway, and
thereby arrive at a set of simpler dynamical equations that could serve as the
starting point for more complex feedback control designs. The first part of the
article views the nonholonomic constraints enforced by the rolling assumption
as defining an Ehresmann connection on a fiber bundle. The resulting equations
are the reduced Euler-Lagrange equations, which are identical to the Lagrange
d'Alembert equations of motion. In the second part we explore conserved
quantities, in particular, nonholonomic momenta. To do so, we first introduce
the notion of a symmetry group, whose action leaves both the Lagrangian and
distribution invariant. We examine two symmetry groups - $SE (2)$ and $SE(2)
\times \mathbb{S}^{1}$. The first group leads to the purely kinematic case
while the second gives rise to nonholonomic momentum equations.
</dc:description>
 <dc:description>Comment: 20 pages, 2 figures, Submitted to Nonlinear Dynamics: An
  International Journal of Nonlinear Dynamics and Chaos in Engineering Systems</dc:description>
 <dc:date>2016-12-03</dc:date>
 <dc:date>2016-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01817</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pseudodeterministic Constructions in Subexponential Time</dc:title>
 <dc:creator>Oliveira, Igor C.</dc:creator>
 <dc:creator>Santhanam, Rahul</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  We study pseudodeterministic constructions, i.e., randomized algorithms which
output the same solution on most computation paths. We establish
unconditionally that there is an infinite sequence $\{p_n\}_{n \in \mathbb{N}}$
of increasing primes and a randomized algorithm $A$ running in expected
sub-exponential time such that for each $n$, on input $1^{|p_n|}$, $A$ outputs
$p_n$ with probability $1$. In other words, our result provides a
pseudodeterministic construction of primes in sub-exponential time which works
infinitely often.
  This result follows from a much more general theorem about
pseudodeterministic constructions. A property $Q \subseteq \{0,1\}^{*}$ is
$\gamma$-dense if for large enough $n$, $|Q \cap \{0,1\}^n| \geq \gamma 2^n$.
We show that for each $c &gt; 0$ at least one of the following holds: (1) There is
a pseudodeterministic polynomial time construction of a family $\{H_n\}$ of
sets, $H_n \subseteq \{0,1\}^n$, such that for each $(1/n^c)$-dense property $Q
\in \mathsf{DTIME}(n^c)$ and every large enough $n$, $H_n \cap Q \neq
\emptyset$; or (2) There is a deterministic sub-exponential time construction
of a family $\{H'_n\}$ of sets, $H'_n \subseteq \{0,1\}^n$, such that for each
$(1/n^c)$-dense property $Q \in \mathsf{DTIME}(n^c)$ and for infinitely many
values of $n$, $H'_n \cap Q \neq \emptyset$.
  We provide further algorithmic applications that might be of independent
interest. Perhaps intriguingly, while our main results are unconditional, they
have a non-constructive element, arising from a sequence of applications of the
hardness versus randomness paradigm.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01820</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explaining Radiological Emphysema Subtypes with Unsupervised Texture
  Prototypes: MESA COPD Study</dc:title>
 <dc:creator>Yang, Jie</dc:creator>
 <dc:creator>Angelini, Elsa D.</dc:creator>
 <dc:creator>Smith, Benjamin M.</dc:creator>
 <dc:creator>Austin, John H. M.</dc:creator>
 <dc:creator>Hoffman, Eric A.</dc:creator>
 <dc:creator>Bluemke, David A.</dc:creator>
 <dc:creator>Barr, R. Graham</dc:creator>
 <dc:creator>Laine, Andrew F.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pulmonary emphysema is traditionally subcategorized into three subtypes,
which have distinct radiological appearances on computed tomography (CT) and
can help with the diagnosis of chronic obstructive pulmonary disease (COPD).
Automated texture-based quantification of emphysema subtypes has been
successfully implemented via supervised learning of these three emphysema
subtypes. In this work, we demonstrate that unsupervised learning on a large
heterogeneous database of CT scans can generate texture prototypes that are
visually homogeneous and distinct, reproducible across subjects, and capable of
predicting accurately the three standard radiological subtypes. These texture
prototypes enable automated labeling of lung volumes, and open the way to new
interpretations of lung CT scans with finer subtyping of emphysema.
</dc:description>
 <dc:description>Comment: MICCAI workshop on Medical Computer Vision: Algorithms for Big Data
  (2016)</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01822</identifier>
 <datestamp>2017-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How many scientific papers are mentioned in policy-related documents? An
  empirical investigation using Web of Science and Altmetric data</dc:title>
 <dc:creator>Haunschild, Robin</dc:creator>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  In this short communication, we provide an overview of a relatively newly
provided source of altmetrics data which could possibly be used for societal
impact measurements in scientometrics. Recently, Altmetric - a start-up
providing publication level metrics - started to make data for publications
available which have been mentioned in policy-related documents. Using data
from Altmetric, we study how many papers indexed in the Web of Science (WoS)
are mentioned in policy-related documents. We find that less than 0.5% of the
papers published in different subject categories are mentioned at least once in
policy-related documents. Based on our results, we recommend that the analysis
of (WoS) publications with at least one policy-related mention is repeated
regularly (annually). Mentions in policy-related documents should not be used
for impact measurement until new policy-related sites are tracked.
</dc:description>
 <dc:description>Comment: 14 pages, 3 tables</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01822</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-016-2237-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01829</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symmetry exploitation for Online Machine Covering with Bounded Migration</dc:title>
 <dc:creator>G&#xe1;lvez, Waldo</dc:creator>
 <dc:creator>Soto, Jos&#xe9; A.</dc:creator>
 <dc:creator>Verschae, Jos&#xe9;</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Online models that allow recourse are highly effective in situations where
classical models are too pessimistic. One such problem is the online machine
covering problem on identical machines. In this setting jobs arrive one by one
and must be assigned to machines with the objective of maximizing the minimum
machine load. When a job arrives, we are allowed to reassign some jobs as long
as their total size is (at most) proportional to the processing time of the
arriving job. The proportionality constant is called the migration factor of
the algorithm.
  Using a new rounding procedure specially tailored for online problems, we
design a $(4/3+\varepsilon)$-competitive algorithm using migration factor
$\tilde{O}(1/\varepsilon^3)$. At every arrival we run an adaptation of the
Largest Processing Time first (LPT) algorithm. Since the new job can cause a
complete change of the assignment of smaller jobs, a low migration factor is
achieved by carefully exploiting the highly symmetric structure obtained by our
rounding.
  We also study local search algorithms for the machine covering problem, and
show that jump and swap optimality have an approximation ratio which lies in
the interval $[1.691, 1.75]$ and can be adapted to the online context with a
small constant as migration factor. Our lower bound is obtained by a nice
construction based on Sylvester's sequence.
</dc:description>
 <dc:description>Comment: 25 pages, 4 figures</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01834</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting Winner Take All (WTA) Hashing for Sparse Datasets</dc:title>
 <dc:creator>Chen, Beidi</dc:creator>
 <dc:creator>Shrivastava, Anshumali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  WTA (Winner Take All) hashing has been successfully applied in many large
scale vision applications. This hashing scheme was tailored to take advantage
of the comparative reasoning (or order based information), which showed
significant accuracy improvements. In this paper, we identify a subtle issue
with WTA, which grows with the sparsity of the datasets. This issue limits the
discriminative power of WTA. We then propose a solution for this problem based
on the idea of Densification which provably fixes the issue. Our experiments
show that Densified WTA Hashing outperforms Vanilla WTA both in image
classification and retrieval tasks consistently and significantly.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01835</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sub-Linear Privacy-Preserving Near-Neighbor Search with Untrusted Server
  on Large-Scale Datasets</dc:title>
 <dc:creator>Riazi, M. Sadegh</dc:creator>
 <dc:creator>Chen, Beidi</dc:creator>
 <dc:creator>Shrivastava, Anshumali</dc:creator>
 <dc:creator>Wallach, Dan</dc:creator>
 <dc:creator>Koushanfar, Farinaz</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In Near-Neighbor Search (NNS), a new client queries a database (held by a
server) for the most similar data (near-neighbors) given a certain similarity
metric. The Privacy-Preserving variant (PP-NNS) requires that neither server
nor the client shall learn information about the other party's data except what
can be inferred from the outcome of NNS. The overwhelming growth in the size of
current datasets and the lack of a truly secure server in the online world
render the existing solutions impractical; either due to their high
computational requirements or non-realistic assumptions which potentially
compromise privacy. PP-NNS having query time {\it sub-linear} in the size of
the database has been suggested as an open research direction by Li et al.
(CCSW'15). In this paper, we provide the first such algorithm, called Secure
Locality Sensitive Indexing (SLSI) which has a sub-linear query time and the
ability to handle honest-but-curious parties. At the heart of our proposal lies
a secure binary embedding scheme generated from a novel probabilistic
transformation over locality sensitive hashing family. We provide information
theoretic bound for the privacy guarantees and support our theoretical claims
using substantial empirical evidence on real-world datasets.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01837</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and ARM-embedded implementation of a chaotic map-based multicast
  scheme for multiuser speech wireless communication</dc:title>
 <dc:creator>Gan, Qiuye</dc:creator>
 <dc:creator>Yu, Simin</dc:creator>
 <dc:creator>Li, Chengqing</dc:creator>
 <dc:creator>L&#xfc;, Jinhu</dc:creator>
 <dc:creator>Lin, Zhuosheng</dc:creator>
 <dc:creator>Chen, Ping</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>94A05</dc:subject>
 <dc:description>  This paper proposes a chaotic map-based multicast scheme for multiuser speech
wireless communication and implements it in an ARM platform. The scheme
compresses the digital audio signal decoded by a sound card and then encrypts
it with a three-level chaotic encryption scheme. First, the position of every
bit of the compressed data is permuted randomly with a pseudo-random number
sequence (PRNS) generated by a 6-D chaotic map. Then, the obtained data are
further permuted in the level of byte with a PRNS generated by a 7-D chaotic
map. Finally, it is operated with a multiround chaotic stream cipher. The whole
system owns the following merits: the redundancy in the original audio file is
reduced effectively and the corresponding unicity distance is increased; the
balancing point between a high security level of the system and real-time
conduction speed is achieved well. In the ARM implementation, the framework of
communication of multicast-multiuser in a subnet and the Internet Group Manage
Protocol is adopted to obtain the function of communication between one client
and other ones. Comprehensive test results were provided to show the
feasibility and security performance of the whole system.
</dc:description>
 <dc:description>Comment: 22 pages, 14 figures in International Journal of Circuit Theory and
  Applications, 2017</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01837</dc:identifier>
 <dc:identifier>doi:10.1002/cta.2300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01840</identifier>
 <datestamp>2017-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FMA: A Dataset For Music Analysis</dc:title>
 <dc:creator>Defferrard, Micha&#xeb;l</dc:creator>
 <dc:creator>Benzi, Kirell</dc:creator>
 <dc:creator>Vandergheynst, Pierre</dc:creator>
 <dc:creator>Bresson, Xavier</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We introduce the Free Music Archive (FMA), an open and easily accessible
dataset suitable for evaluating several tasks in MIR, a field concerned with
browsing, searching, and organizing large music collections. The community's
growing interest in feature and end-to-end learning is however restrained by
the limited availability of large audio datasets. The FMA aims to overcome this
hurdle by providing 917 GiB and 343 days of Creative Commons-licensed audio
from 106,574 tracks from 16,341 artists and 14,854 albums, arranged in a
hierarchical taxonomy of 161 genres. It provides full-length and high-quality
audio, pre-computed features, together with track- and user-level metadata,
tags, and free-form text such as biographies. We here describe the dataset and
how it was created, propose a train/validation/test split and three subsets,
discuss some suitable MIR tasks, and evaluate some baselines for genre
recognition. Code, data, and usage examples are available at
https://github.com/mdeff/fma
</dc:description>
 <dc:description>Comment: ISMIR 2017 camera-ready</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01842</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Improved One-to-All Broadcasting in Higher Dimensional
  Eisenstein-Jacobi Networks</dc:title>
 <dc:creator>Hussain, Zaid</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Recently, a higher dimensional Eisenstein-Jacobi networks, has been proposed
in [22], which is shown that they have better average distance with more number
of nodes than a single dimensional EJ networks. Some communication algorithms
such as one-to-all and all-to-all communications are well known and used in
interconnection networks. In one-to-all communication, a source node sends a
message to every other node in the network. Whereas, in all-to-all
communication, every node is considered as a source node and sends its message
to every other node in the network. In this paper, an improved one-to-all
communication algorithm in higher dimensional EJ networks is presented. The
paper shows that the proposed algorithm achieves a lower average number of
steps to receiving the broadcasted message. In addition, since the links are
assumed to be half-duplex, the all-to-all broadcasting algorithm is divided
into three phases. The simulation results are discussed and showed that the
improved one-to-all algorithm achieves better traffic performance than the
well-known one-to-all algorithm and has 2.7% less total number of senders
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01845</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transient Provisioning and Performance Evaluation for Cloud Computing
  Platforms: A Capacity Value Approach</dc:title>
 <dc:creator>Patch, Brendan</dc:creator>
 <dc:creator>Taimre, Thomas</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  User demand on the computational resources of cloud computing platforms
varies over time. These variations in demand can be predictable or
unpredictable, resulting in `bursty' fluctuations in demand. Furthermore,
demand can arrive in batches, and users whose demands are not met can be
impatient. We demonstrate how to compute the expected revenue loss over a
finite time horizon in the presence of all these model characteristics through
the use of matrix analytic methods. We then illustrate how to use this
knowledge to make frequent short term provisioning decisions --- transient
provisioning. It is seen that taking each of the characteristics of fluctuating
user demand (predictable, unpredictable, batchy) into account can result in a
substantial reduction of losses. Moreover, our transient provisioning framework
allows for a wide variety of system behaviors to be modeled and gives simple
expressions for expected revenue loss which are straightforward to evaluate
numerically.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-10-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01848</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Condensed Memory Networks for Clinical Diagnostic Inferencing</dc:title>
 <dc:creator>Prakash, Aaditya</dc:creator>
 <dc:creator>Zhao, Siyuan</dc:creator>
 <dc:creator>Hasan, Sadid A.</dc:creator>
 <dc:creator>Datla, Vivek</dc:creator>
 <dc:creator>Lee, Kathy</dc:creator>
 <dc:creator>Qadir, Ashequl</dc:creator>
 <dc:creator>Liu, Joey</dc:creator>
 <dc:creator>Farri, Oladimeji</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Diagnosis of a clinical condition is a challenging task, which often requires
significant medical investigation. Previous work related to diagnostic
inferencing problems mostly consider multivariate observational data (e.g.
physiological signals, lab tests etc.). In contrast, we explore the problem
using free-text medical notes recorded in an electronic health record (EHR).
Complex tasks like these can benefit from structured knowledge bases, but those
are not scalable. We instead exploit raw text from Wikipedia as a knowledge
source. Memory networks have been demonstrated to be effective in tasks which
require comprehension of free-form text. They use the final iteration of the
learned representation to predict probable classes. We introduce condensed
memory neural networks (C-MemNNs), a novel model with iterative condensation of
memory representations that preserves the hierarchy of features in the memory.
Experiments on the MIMIC-III dataset show that the proposed model outperforms
other variants of memory networks to predict the most probable diagnoses given
a complex clinical scenario.
</dc:description>
 <dc:description>Comment: Accepted to AAAI 2017</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01855</identifier>
 <datestamp>2017-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication-Avoiding Parallel Algorithms for Solving Triangular
  Systems of Linear Equations</dc:title>
 <dc:creator>Wicky, Tobias</dc:creator>
 <dc:creator>Solomonik, Edgar</dc:creator>
 <dc:creator>Hoefler, Torsten</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  We present a new parallel algorithm for solving triangular systems with
multiple right hand sides (TRSM). TRSM is used extensively in numerical linear
algebra computations, both to solve triangular linear systems of equations as
well as to compute factorizations with triangular matrices, such as Cholesky,
LU, and QR. Our algorithm achieves better theoretical scalability than known
alternatives, while maintaining numerical stability, via selective use of
triangular matrix inversion. We leverage the fact that triangular inversion and
matrix multiplication are more parallelizable than the standard TRSM algorithm.
By only inverting triangular blocks along the diagonal of the initial matrix,
we generalize the usual way of TRSM computation and the full matrix inversion
approach. This flexibility leads to an efficient algorithm for any ratio of the
number of right hand sides to the triangular matrix dimension. We provide a
detailed communication cost analysis for our algorithm as well as for the
recursive triangular matrix inversion. This cost analysis makes it possible to
determine optimal block sizes and processor grids a priori. Relative to the
best known algorithms for TRSM, our approach can require asymptotically fewer
messages, while performing optimal amounts of computation and communication in
terms of words sent.
</dc:description>
 <dc:description>Comment: 10 pages, 1 figure, accepted at IPDPS 2017</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01857</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a Well-behaved Relational Generalisation of Rough Set Approximations</dc:title>
 <dc:creator>Gopaulsingh, Alexa</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We examine non-dual relational extensions of rough set approximations and
find an extension which satisfies surprisingly many of the usual rough set
properties. We then use this definition to give an explanation for an
observation made by Samanta and Chakraborty in their recent paper [P. Samanta
and M.K. Chakraborty. Interface of rough set systems and modal logics: A
survey. Transactions on Rough Sets XIX, pages 114-137, 2015].
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01857</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01859</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorial semi-bandit with known covariance</dc:title>
 <dc:creator>Degenne, R&#xe9;my</dc:creator>
 <dc:creator>Perchet, Vianney</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The combinatorial stochastic semi-bandit problem is an extension of the
classical multi-armed bandit problem in which an algorithm pulls more than one
arm at each stage and the rewards of all pulled arms are revealed. One
difference with the single arm variant is that the dependency structure of the
arms is crucial. Previous works on this setting either used a worst-case
approach or imposed independence of the arms. We introduce a way to quantify
the dependency structure of the problem and design an algorithm that adapts to
it. The algorithm is based on linear regression and the analysis develops
techniques from the linear bandit literature. By comparing its performance to a
new lower bound, we prove that it is optimal, up to a poly-logarithmic factor
in the number of pulled arms.
</dc:description>
 <dc:description>Comment: in NIPS 2016 (Conference on Neural Information Processing Systems),
  Dec 2016, Barcelona, Spain</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01859</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01860</identifier>
 <datestamp>2017-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An algorithm to assign musical prime commas to every prime number and
  construct a universal and compact free Just Intonation musical notation</dc:title>
 <dc:creator>Ryan, David</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Musical frequencies in Just Intonation are comprised of rational numbers. The
structure of rational numbers is determined by prime factorisations. Just
Intonation frequencies can be split into two components. The larger component
uses only integer powers of the first two primes, 2 and 3. The smaller
component decomposes into a series of microtonal adjustments, one for each
prime number 5 and above present in the original frequency. The larger 3-limit
component can be notated using scientific pitch notation modified to use
Pythagorean tuning. The microtonal adjustments can be notated using rational
commas which are built up from prime commas. This gives a notation system for
the whole of free-JI, called Rational Comma Notation. RCN is compact since all
microtonal adjustments can be represented by a single notational unit based on
a rational number. RCN has different versions depending on the choice of
algorithm to assign a prime comma to each prime number. Two existing algorithms
SAG and KG2 are found in the literature. A novel algorithm DR is developed
based on discussion of mathematical and musical criteria for algorithm design.
Results for DR are presented for primes below 1400. Some observations are made
about these results and their applications, including shorthand notation and
pitch class lattices. Results for DR are compared with those for SAG and KG2.
Translation is possible between any two free-JI notations and any two versions
of RCN since they all represent the same underlying set of rational numbers.
</dc:description>
 <dc:description>Comment: This pre-print is a fifth draft, 28th March 2017. It incorporates an
  updated algorithm KG2 from its author, an updated 3-way comparison between
  DR, SAG, KG2 algorithms, some extra information about higher Pythagorean
  integers, functions 3EPO and CSPO, and normalisation of comma pumps. Any
  feedback is welcome, the author's contact details are listed at the end of
  the paper</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01868</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Broadcast Strategies and Performance Evaluation of IEEE 802.15.4 in
  Wireless Body Area Networks WBAN</dc:title>
 <dc:creator>Badreddine, Wafa</dc:creator>
 <dc:creator>Chaudet, Claude</dc:creator>
 <dc:creator>Petruzzi, Federico</dc:creator>
 <dc:creator>Potop-Butucaru, Maria</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The rapid advances in sensors and ultra-low power wireless communication has
enabled a new generation of wireless sensor networks: Wireless Body Area
Networks (WBAN). To the best of our knowledge the current paper is the first to
address broadcast in WBAN. We first analyze several broadcast strategies
inspired from the area of Delay Tolerant Networks (DTN). The proposed
strategies are evaluated via the OMNET++ simulator that we enriched with
realistic human body mobility models and channel models issued from the recent
research on biomedical and health informatics. Contrary to the common
expectation, our results show that existing research in DTN cannot be
transposed without significant modifications in WBANs area. That is, existing
broadcast strategies for DTNs do not perform well with human body mobility.
However, our extensive simulations give valuable insights and directions for
designing efficient broadcast in WBAN. Furthermore, we propose a novel
broadcast strategy that outperforms the existing ones in terms of end-to-end
delay, network coverage and energy consumption. Additionally, we performed
investigations of independent interest related to the ability of all the
studied strategies to ensure the total order delivery property when stressed
with various packet rates. These investigations open new and challenging
research directions.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01870</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the computational power of affine automata</dc:title>
 <dc:creator>Hirvensalo, Mika</dc:creator>
 <dc:creator>Moutot, Etienne</dc:creator>
 <dc:creator>Yakary&#x131;lmaz, Abuzer</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We investigate the computational power of affine automata (AfAs) introduced
in [4]. In particular, we present a simpler proof for how to change the
cutpoint for any affine language and a method how to reduce error in bounded
error case. Moreover, we address to the question of [4] by showing that any
affine language can be recognized by an AfA with certain limitation on the
entries of affine states and transition matrices. Lastly, we present the first
languages shown to be not recognized by AfAs with bounded-error.
</dc:description>
 <dc:description>Comment: 12 pages. Accepted to LATA2017</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01887</identifier>
 <datestamp>2017-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image
  Captioning</dc:title>
 <dc:creator>Lu, Jiasen</dc:creator>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Parikh, Devi</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Attention-based neural encoder-decoder frameworks have been widely adopted
for image captioning. Most methods force visual attention to be active for
every generated word. However, the decoder likely requires little to no visual
information from the image to predict non-visual words such as &quot;the&quot; and &quot;of&quot;.
Other words that may seem visual can often be predicted reliably just from the
language model e.g., &quot;sign&quot; after &quot;behind a red stop&quot; or &quot;phone&quot; following
&quot;talking on a cell&quot;. In this paper, we propose a novel adaptive attention model
with a visual sentinel. At each time step, our model decides whether to attend
to the image (and if so, to which regions) or to the visual sentinel. The model
decides whether to attend to the image and where, in order to extract
meaningful information for sequential word generation. We test our method on
the COCO image captioning 2015 challenge dataset and Flickr30K. Our approach
sets the new state-of-the-art by a significant margin.
</dc:description>
 <dc:description>Comment: 12 pages, 11 figures, CVPR2017 camera ready</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-06-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01888</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relative generalized matrix weights of matrix codes for universal
  security on wire-tap networks</dc:title>
 <dc:creator>Mart&#xed;nez-Pe&#xf1;as, Umberto</dc:creator>
 <dc:creator>Matsumoto, Ryutaroh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>15A03, 15B33, 94B05, 94C99</dc:subject>
 <dc:description>  Universal security over a network with linear network coding has been
intensively studied. However, previous linear codes and code pairs used for
this purpose were linear over a larger field than that used on the network,
which restricts the possible packet lengths of optimal universal secure codes,
does not allow to apply known list-decodable rank-metric codes and requires
performing operations over a large field. In this work, we introduce new
parameters (relative generalized matrix weights and relative dimension/rank
support profile) for code pairs that are linear over the field used in the
network, and show that they measure the universal security performance of these
code pairs. For one code and non-square matrices, generalized matrix weights
coincide with the existing Delsarte generalized weights, hence we prove the
connection between these latter weights and secure network coding, which was
left open. As main applications, the proposed new parameters enable us to: 1)
Obtain optimal universal secure linear codes on noiseless networks for all
possible packet lengths, in particular for packet lengths not considered
before, 2) Obtain the first universal secure list-decodable rank-metric code
pairs with polynomial-sized lists, based on a recent construction by Guruswami
et al, and 3) Obtain new characterizations of security equivalences of linear
codes. Finally, we show that our parameters extend relative generalized Hamming
weights and relative dimension/length profile, respectively, and relative
generalized rank weights and relative dimension/intersection profile,
respectively.
</dc:description>
 <dc:description>Comment: 21 pages, LaTeX; Parts of this manuscript have been presented at the
  54th Annual Allerton Conference on Communication, Control, and Computing,
  Monticello, IL, USA, 2016. Conference version available at arXiv:1607.01263</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01888</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2017.2766292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01892</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-Lingual Predicate Mapping Between Linked Data Ontologies</dc:title>
 <dc:creator>Singh, Gautam</dc:creator>
 <dc:creator>Jang, Saemi</dc:creator>
 <dc:creator>Yi, Mun Y.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Ontologies in different natural languages often differ in quality in terms of
richness of schema or richness of internal links. This difference is markedly
visible when comparing a rich English language ontology with a non-English
language counterpart. Discovering alignment between them is a useful endeavor
as it serves as a starting point in bridging the disparity. In particular, our
work is motivated by the absence of inter-language links for predicates in the
localised versions of DBpedia. In this paper, we propose and demonstrate an
ad-hoc system to find possible owl:equivalentProperty links between predicates
in ontologies of different natural languages. We seek to achieve this mapping
by using pre-existing inter-language links of the resources connected by the
given predicate. Thus, our methodology stresses on semantic similarity rather
than lexical. Moreover, through an evaluation, we show that our system is
capable of outperforming a baseline system that is similar to the one used in
recent OAEI campaigns.
</dc:description>
 <dc:description>Comment: 11 pages, 1 figure, 1 table</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01894</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis and Evaluation of Real-time and Safety Characteristics of IEEE
  802.11p protocol in VANET</dc:title>
 <dc:creator>Ahmadvand, Hossein</dc:creator>
 <dc:creator>Jahangir, Amir Hossein</dc:creator>
 <dc:creator>Baarzi, Ataollah Fatahi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The need for safety in transportation systems has increased the popularity
and applicability of Vehicular Ad-Hoc Networks (VANETs) in recent years.
On-time reception and processing of alarms caused by possible accidents as well
as the preventive actions have important roles in reducing human and financial
losses in road accidents. In such cases, the performance of safety applications
should be evaluated and guaranteed to show whether or not they can ensure the
safety of humans and cars. In this paper, we analyze the behavior of Vehicular
Ad-Hoc Networks by checking the real-time properties of the IEEE 802.11p
protocol using a Colored Petri Net model. To analyze the performance of related
standards, simulations are conducted using CPNTools. Standards from European
Telecommunications Standards Institute (ETSI), and Vehicle Safety
Communications (VSC) are evaluated in this research. We will show that such
standards may not completely fulfill the safety requirements in particular
situations.
</dc:description>
 <dc:description>Comment: 21 pages, 10 figures</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01895</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal Transfer: A Hierarchical Deep Convolutional Neural Network
  for Fast Artistic Style Transfer</dc:title>
 <dc:creator>Wang, Xin</dc:creator>
 <dc:creator>Oxholm, Geoffrey</dc:creator>
 <dc:creator>Zhang, Da</dc:creator>
 <dc:creator>Wang, Yuan-Fang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Transferring artistic styles onto everyday photographs has become an
extremely popular task in both academia and industry. Recently, offline
training has replaced on-line iterative optimization, enabling nearly real-time
stylization. When those stylization networks are applied directly to
high-resolution images, however, the style of localized regions often appears
less similar to the desired artistic style. This is because the transfer
process fails to capture small, intricate textures and maintain correct texture
scales of the artworks. Here we propose a multimodal convolutional neural
network that takes into consideration faithful representations of both color
and luminance channels, and performs stylization hierarchically with multiple
losses of increasing scales. Compared to state-of-the-art networks, our network
can also perform style transfer in nearly real-time by conducting much more
sophisticated training offline. By properly handling style and texture cues at
multiple scales using several modalities, we can transfer not just large-scale,
obvious style cues but also subtle, exquisite ones. That is, our scheme can
generate results that are visually pleasing and more similar to multiple
desired artistic styles with color and texture cues at multiple scales.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2017</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01901</identifier>
 <datestamp>2017-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolving network structure of academic institutions</dc:title>
 <dc:creator>Wang, Shufan</dc:creator>
 <dc:creator>Avagyan, Mariam</dc:creator>
 <dc:creator>Skardal, Per Sebastian</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  Today's colleges and universities consist of highly complex structures that
dictate interactions between the administration, faculty, and student body.
These structures can play a role in dictating the efficiency of policy enacted
by the administration and determine the effect that curriculum changes in one
department have on other departments. Despite the fact that the features of
these complex structures have a strong impact on the institutions, they remain
by-and-large unknown in many cases. In this paper we study the academic
structure of our home institution of Trinity College in Hartford, CT using the
major and minor patterns between graduating students to build a temporal
multiplex network describing the interactions between different departments.
Using recent network science techniques developed for such temporal networks we
identify the evolving community structures that organize departments'
interactions, as well as quantify the interdisciplinary centrality of each
department. We implement this framework for Trinity College, finding practical
insights and applications, but also present it as a general framework for
colleges and universities to better understand their own structural makeup in
order to better inform academic and administrative policy.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01901</dc:identifier>
 <dc:identifier>doi:10.1007/s41109-016-0020-1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01904</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Detection in Ad Hoc Networks Through Quantized Consensus</dc:title>
 <dc:creator>Zhu, Shengyu</dc:creator>
 <dc:creator>Chen, Biao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study asymptotic performance of distributed detection in large scale
connected sensor networks. Contrasting to canonical parallel networks where a
single node has access to local decisions from all other nodes, each node can
only exchange information with its direct neighbors in the present setting. We
establish that, with each node employing an identical one-bit quantizer for
local information exchange, a novel consensus reaching approach can achieve the
optimal asymptotic performance of centralized detection as the network size
scales. The statement is true under three different detection frameworks: the
Bayesian criterion where the maximum a posteriori detector is optimal, the
Neyman-Pearson criterion with a constant type-I error probability constraint,
and the Neyman-Pearson criterion with an exponential type-I error probability
constraint. Leveraging recent development in distributed consensus reaching
using bounded quantizers with possibly unbounded data (which are log-likelihood
ratios of local observations in the context of distributed detection), we
design a one-bit deterministic quantizer with controllable threshold that leads
to desirable consensus error bounds. The obtained bounds are key to
establishing the optimal asymptotic detection performance. In addition, we
examine non-asymptotic performance of the proposed approach and show that the
type-I and type-II error probabilities at each node can be made arbitrarily
close to the centralized ones simultaneously when a continuity condition is
satisfied.
</dc:description>
 <dc:description>Comment: Revised manuscript submitted to IEEE Trans. Information Theory.
  Adding discussions on multi-hypothesis testing and practical considerations</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01905</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Classical Limit of Entropic Quantum Dynamics</dc:title>
 <dc:creator>Demme, Anthony</dc:creator>
 <dc:creator>Caticha, Ariel</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The framework of entropic dynamics (ED) allows one to derive quantum
mechanics as an application of entropic inference. In this work we derive the
classical limit of quantum mechanics in the context of ED. Our goal is to find
conditions so that the center of mass (CM) of a system of N particles behaves
as a classical particle. What is of interest is that Planck's constant remains
finite at all steps in the calculation and that the classical motion is
obtained as the result of a central limit theorem. More explicitly we show that
if the system is sufficiently large, and if the CM is initially uncorrelated
with other degrees of freedom, then the CM follows a smooth trajectory and
obeys the classical Hamilton-Jacobi with a vanishing quantum potential.
</dc:description>
 <dc:description>Comment: Presented at MaxEnt 2016, the 36th International Workshop on Bayesian
  Inference and Maximum Entropy Methods in Science and Engineering (July 10-15,
  2016, Ghent, Belgium). In version 2 some typos and an algebra mistake are
  corrected. The corrections do not affect the conclusions</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01905</dc:identifier>
 <dc:identifier>doi:10.1063/1.4985370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01922</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tag Prediction at Flickr: a View from the Darkroom</dc:title>
 <dc:creator>Boakye, Kofi</dc:creator>
 <dc:creator>Farfade, Sachin</dc:creator>
 <dc:creator>Izadinia, Hamid</dc:creator>
 <dc:creator>Kalantidis, Yannis</dc:creator>
 <dc:creator>Garrigues, Pierre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automated photo tagging has established itself as one of the most compelling
applications of deep learning. While deep convolutional neural networks have
repeatedly demonstrated top performance on standard datasets for
classification, there are a number of often overlooked but important
considerations when deploying this technology in a real-world scenario. In this
paper, we present our efforts in developing a large-scale photo tagging system
for Flickr photo search. We discuss topics including how to 1) select the tags
that matter most to our users; 2) develop lightweight, high-performance models
for tag prediction; and 3) leverage the power of large amounts of noisy data
for training. Our results demonstrate that, for real-world datasets, training
exclusively with this noisy data yields performance on par with the standard
paradigm of first pre-training on clean data and then fine-tuning. In addition,
we observe that the models trained with user-generated data can yield better
fine-tuning results when a small amount of clean data is available. As such, we
advocate for the approach of harnessing user-generated data in large-scale
systems.
</dc:description>
 <dc:description>Comment: Presented at the ACM Multimedia Thematic Workshops, 2017</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01925</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks</dc:title>
 <dc:creator>Ilg, Eddy</dc:creator>
 <dc:creator>Mayer, Nikolaus</dc:creator>
 <dc:creator>Saikia, Tonmoy</dc:creator>
 <dc:creator>Keuper, Margret</dc:creator>
 <dc:creator>Dosovitskiy, Alexey</dc:creator>
 <dc:creator>Brox, Thomas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The FlowNet demonstrated that optical flow estimation can be cast as a
learning problem. However, the state of the art with regard to the quality of
the flow has still been defined by traditional methods. Particularly on small
displacements and real-world data, FlowNet cannot compete with variational
methods. In this paper, we advance the concept of end-to-end learning of
optical flow and make it work really well. The large improvements in quality
and speed are caused by three major contributions: first, we focus on the
training data and show that the schedule of presenting data during training is
very important. Second, we develop a stacked architecture that includes warping
of the second image with intermediate optical flow. Third, we elaborate on
small displacements by introducing a sub-network specializing on small motions.
FlowNet 2.0 is only marginally slower than the original FlowNet but decreases
the estimation error by more than 50%. It performs on par with state-of-the-art
methods, while running at interactive frame rates. Moreover, we present faster
variants that allow optical flow computation at up to 140fps with accuracy
matching the original FlowNet.
</dc:description>
 <dc:description>Comment: Including supplementary material. For the video see:
  http://lmb.informatik.uni-freiburg.de/Publications/2016/IMKDB16/</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01925</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01928</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Invariant Representations for Noisy Speech Recognition</dc:title>
 <dc:creator>Serdyuk, Dmitriy</dc:creator>
 <dc:creator>Audhkhasi, Kartik</dc:creator>
 <dc:creator>Brakel, Phil&#xe9;mon</dc:creator>
 <dc:creator>Ramabhadran, Bhuvana</dc:creator>
 <dc:creator>Thomas, Samuel</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Modern automatic speech recognition (ASR) systems need to be robust under
acoustic variability arising from environmental, speaker, channel, and
recording conditions. Ensuring such robustness to variability is a challenge in
modern day neural network-based ASR systems, especially when all types of
variability are not seen during training. We attempt to address this problem by
encouraging the neural network acoustic model to learn invariant feature
representations. We use ideas from recent research on image generation using
Generative Adversarial Networks and domain adaptation ideas extending
adversarial gradient-based training. A recent work from Ganin et al. proposes
to use adversarial training for image domain adaptation by using an
intermediate representation from the main target classification network to
deteriorate the domain classifier performance through a separate neural
network. Our work focuses on investigating neural architectures which produce
representations invariant to noise conditions for ASR. We evaluate the proposed
architecture on the Aurora-4 task, a popular benchmark for noise robust ASR. We
show that our method generalizes better than the standard multi-condition
training especially when only a few noise categories are seen during training.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, 1 table, NIPS workshop on end-to-end speech
  recognition</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01936</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Probabilistic Framework for Deep Learning</dc:title>
 <dc:creator>Patel, Ankit B.</dc:creator>
 <dc:creator>Nguyen, Tan</dc:creator>
 <dc:creator>Baraniuk, Richard G.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We develop a probabilistic framework for deep learning based on the Deep
Rendering Mixture Model (DRMM), a new generative probabilistic model that
explicitly capture variations in data due to latent task nuisance variables. We
demonstrate that max-sum inference in the DRMM yields an algorithm that exactly
reproduces the operations in deep convolutional neural networks (DCNs),
providing a first principles derivation. Our framework provides new insights
into the successes and shortcomings of DCNs as well as a principled route to
their improvement. DRMM training via the Expectation-Maximization (EM)
algorithm is a powerful alternative to DCN back-propagation, and initial
training results are promising. Classification based on the DRMM and other
variants outperforms DCNs in supervised digit classification, training 2-3x
faster while achieving similar accuracy. Moreover, the DRMM is applicable to
semi-supervised and unsupervised learning tasks, achieving results that are
state-of-the-art in several categories on the MNIST benchmark and comparable to
state of the art on the CIFAR10 benchmark.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1504.00641</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01939</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correlation Alignment for Unsupervised Domain Adaptation</dc:title>
 <dc:creator>Sun, Baochen</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Saenko, Kate</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this chapter, we present CORrelation ALignment (CORAL), a simple yet
effective method for unsupervised domain adaptation. CORAL minimizes domain
shift by aligning the second-order statistics of source and target
distributions, without requiring any target labels. In contrast to subspace
manifold methods, it aligns the original feature distributions of the source
and target domains, rather than the bases of lower-dimensional subspaces. It is
also much simpler than other distribution matching methods. CORAL performs
remarkably well in extensive evaluations on standard benchmark datasets. We
first describe a solution that applies a linear transformation to source
features to align them with target features before classifier training. For
linear classifiers, we propose to equivalently apply CORAL to the classifier
weights, leading to added efficiency when the number of classifiers is small
but the number and dimensionality of target examples are very high. The
resulting CORAL Linear Discriminant Analysis (CORAL-LDA) outperforms LDA by a
large margin on standard domain adaptation benchmarks. Finally, we extend CORAL
to learn a nonlinear transformation that aligns correlations of layer
activations in deep neural networks (DNNs). The resulting Deep CORAL approach
works seamlessly with DNNs and achieves state-of-the-art performance on
standard benchmark datasets. Our code is available
at:~\url{https://github.com/VisionLearningGroup/CORAL}
</dc:description>
 <dc:description>Comment: Introduction to CORAL, CORAL-LDA, and Deep CORAL. arXiv admin note:
  text overlap with arXiv:1511.05547</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01941</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coactive Critiquing: Elicitation of Preferences and Features</dc:title>
 <dc:creator>Teso, Stefano</dc:creator>
 <dc:creator>Dragone, Paolo</dc:creator>
 <dc:creator>Passerini, Andrea</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  When faced with complex choices, users refine their own preference criteria
as they explore the catalogue of options. In this paper we propose an approach
to preference elicitation suited for this scenario. We extend Coactive
Learning, which iteratively collects manipulative feedback, to optionally query
example critiques. User critiques are integrated into the learning model by
dynamically extending the feature space. Our formulation natively supports
constructive learning tasks, where the option catalogue is generated
on-the-fly. We present an upper bound on the average regret suffered by the
learner. Our empirical analysis highlights the promise of our approach.
</dc:description>
 <dc:description>Comment: AAAI'17</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01942</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-Supervised Learning with the Deep Rendering Mixture Model</dc:title>
 <dc:creator>Nguyen, Tan</dc:creator>
 <dc:creator>Liu, Wanjia</dc:creator>
 <dc:creator>Perez, Ethan</dc:creator>
 <dc:creator>Baraniuk, Richard G.</dc:creator>
 <dc:creator>Patel, Ankit B.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Semi-supervised learning algorithms reduce the high cost of acquiring labeled
training data by using both labeled and unlabeled data during learning. Deep
Convolutional Networks (DCNs) have achieved great success in supervised tasks
and as such have been widely employed in the semi-supervised learning. In this
paper we leverage the recently developed Deep Rendering Mixture Model (DRMM), a
probabilistic generative model that models latent nuisance variation, and whose
inference algorithm yields DCNs. We develop an EM algorithm for the DRMM to
learn from both labeled and unlabeled data. Guided by the theory of the DRMM,
we introduce a novel non-negativity constraint and a variational inference
term. We report state-of-the-art performance on MNIST and SVHN and competitive
results on CIFAR10. We also probe deeper into how a DRMM trained in a
semi-supervised setting represents latent nuisance variation using
synthetically rendered images. Taken together, our work provides a unified
framework for supervised, unsupervised, and semi-supervised learning.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01943</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Segmental Convolutional Neural Networks for Detection of Cardiac
  Abnormality With Noisy Heart Sound Recordings</dc:title>
 <dc:creator>Zhang, Yuhao</dc:creator>
 <dc:creator>Ayyar, Sandeep</dc:creator>
 <dc:creator>Chen, Long-Huei</dc:creator>
 <dc:creator>Li, Ethan J.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Heart diseases constitute a global health burden, and the problem is
exacerbated by the error-prone nature of listening to and interpreting heart
sounds. This motivates the development of automated classification to screen
for abnormal heart sounds. Existing machine learning-based systems achieve
accurate classification of heart sound recordings but rely on expert features
that have not been thoroughly evaluated on noisy recordings. Here we propose a
segmental convolutional neural network architecture that achieves automatic
feature learning from noisy heart sound recordings. Our experiments show that
our best model, trained on noisy recording segments acquired with an existing
hidden semi-markov model-based approach, attains a classification accuracy of
87.5% on the 2016 PhysioNet/CinC Challenge dataset, compared to the 84.6%
accuracy of the state-of-the-art statistical classifier trained and evaluated
on the same dataset. Our results indicate the potential of using neural
network-based methods to increase the accuracy of automated classification of
heart sound recordings for improved screening of heart diseases.
</dc:description>
 <dc:description>Comment: This work was finished in May 2016, and remains unpublished until
  December 2016 due to a request from the data provider</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01944</identifier>
 <datestamp>2017-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Porous Structure Design in Tissue Engineering Using Anisotropic Radial
  Basis Function</dc:title>
 <dc:creator>Liu, Ke</dc:creator>
 <dc:creator>Guo, Ye</dc:creator>
 <dc:creator>Yu, Zeyun</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Development of additive manufacturing in last decade greatly improves tissue
engineering. During the manufacturing of porous scaffold, simplified but
functionally equivalent models are getting focused for practically reasons.
Scaffolds can be classified into regular porous scaffolds and irregular porous
scaffolds. Several methodologies are developed to design these scaffolds. A
novel method is proposed in this paper using anisotropic radial basis function
(ARBF) interpolation. This is method uses geometric models such as volumetric
meshes as input and proves to be flexible because geometric models are able to
capture the characteristics of complex tissues easily. Moreover, this method is
straightforward and easy to implement.
</dc:description>
 <dc:description>Comment: Department of Computer Science, University of Wisconsin Milwaukee</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01958</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Diverse Image Colorization</dc:title>
 <dc:creator>Deshpande, Aditya</dc:creator>
 <dc:creator>Lu, Jiajun</dc:creator>
 <dc:creator>Yeh, Mao-Chuang</dc:creator>
 <dc:creator>Chong, Min Jin</dc:creator>
 <dc:creator>Forsyth, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Colorization is an ambiguous problem, with multiple viable colorizations for
a single grey-level image. However, previous methods only produce the single
most probable colorization. Our goal is to model the diversity intrinsic to the
problem of colorization and produce multiple colorizations that display
long-scale spatial co-ordination. We learn a low dimensional embedding of color
fields using a variational autoencoder (VAE). We construct loss terms for the
VAE decoder that avoid blurry outputs and take into account the uneven
distribution of pixel colors. Finally, we build a conditional model for the
multi-modal distribution between grey-level image and the color field
embeddings. Samples from this conditional model result in diverse colorization.
We demonstrate that our method obtains better diverse colorizations than a
standard conditional variational autoencoder (CVAE) model, as well as a
recently proposed conditional generative adversarial network (cGAN).
</dc:description>
 <dc:description>Comment: This revision to appear in CVPR17</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01963</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Dynamic Network Reconstruction from Heterogeneous Datasets</dc:title>
 <dc:creator>Yue, Zuogong</dc:creator>
 <dc:creator>Thunberg, Johan</dc:creator>
 <dc:creator>Pan, Wei</dc:creator>
 <dc:creator>Ljung, Lennart</dc:creator>
 <dc:creator>Goncalves, Jorge</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper addresses reconstruction of linear dynamic networks from
heterogeneous datasets. Those datasets consist of measurements from linear
dynamical systems in multiple experiment subjected to different experimental
conditions, e.g., changes/perturbations in parameters, disturbance or noise. A
main assumption is that the Boolean structures of the underlying networks are
the same in all experiments. The ARMAX model is adopted to parameterize the
general linear dynamic network representation &quot;Dynamical Structure Function&quot;
(DSF), which provides the Granger Causality graph as a special case. The
network identification is performed by integrating all available datasets,
which resorts to group sparsity to assure both network sparsity and the
consistency of Boolean structures over datasets. In terms of solving the
problem, a treatment by the iterative reweighted $l_1$ method is used, together
with its implementations via proximal methods and ADMM for large-dimensional
networks.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01966</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Minimum Chordal Completion Polytope</dc:title>
 <dc:creator>Bergman, David</dc:creator>
 <dc:creator>Cardonha, Carlos H.</dc:creator>
 <dc:creator>Cire, Andre A.</dc:creator>
 <dc:creator>Raghunathan, Arvind U.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A graph is chordal if every cycle of length at least four contains a chord,
that is, an edge connecting two nonconsecutive vertices of the cycle. Several
classical applications in sparse linear systems, database management, computer
vision, and semidefinite programming can be reduced to finding the minimum
number of edges to add to a graph so that it becomes chordal, known as the
minimum chordal completion problem (MCCP). In this article we propose a new
formulation for the MCCP which does not rely on finding perfect elimination
orderings of the graph, as has been considered in previous work. We introduce
several families of facet-defining inequalities for cycle subgraphs and
investigate the underlying separation problems, showing that some key
inequalities are NP-Hard to separate. We also show general properties of the
proposed polyhedra, indicating certain conditions and methods through which
facets and inequalities associated with the polytope of a certain graph can be
adapted in order to become valid and eventually facet-defining for some of its
subgraphs or supergraphs. Numerical studies combining heuristic separation
methods based on a threshold rounding and lazy-constraint generation indicate
that our approach substantially outperforms existing methods for the MCCP,
solving many benchmark graphs to optimality for the first time.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01980</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Mechanics of MAP Estimation: General Replica Ansatz</dc:title>
 <dc:creator>Bereyhi, Ali</dc:creator>
 <dc:creator>M&#xfc;ller, Ralf R.</dc:creator>
 <dc:creator>Schulz-Baldes, Hermann</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The large-system performance of MAP estimation is studied considering a
general distortion function when the observation vector is received through a
linear system with additive white Gaussian noise. The analysis considers the
system matrix to be chosen from the large class of rotationally invariant
random matrices. We take a statistical mechanical approach by introducing a
spin glass corresponding to the estimator, and employing the replica method for
the large-system analysis. In contrast to earlier replica based studies, our
analysis evaluates the general replica ansatz of the corresponding spin glass
and determines the asymptotic distortion of the estimator for any structure of
the replica correlation matrix. Consequently, the replica symmetric as well as
the Replica Symmetry (RS) breaking ansatz with $b$ steps of breaking is deduced
from the given general replica ansatz. The generality of our distortion
function lets us derive a more general form of the MAP decoupling principle.
Based on the general replica ansatz, we show that for any structure of the
replica correlation matrix, the vector-valued system decouples into a bank of
equivalent decoupled linear systems followed by MAP estimators. The structure
of the decoupled linear system is further studied under both the RS and the
Replica Symmetry Breaking (RSB) assumptions. For $b$ steps of RSB, the
decoupled system is found to be an additive system with a noise term given as
the sum of an independent Gaussian random variable with $b$ correlated
impairment terms. As an application of our study, we investigate large
compressive sensing systems by considering the $\ell_p$ minimization recovery
schemes. Our numerical investigations show that the replica symmetric ansatz
for $\ell_0$ norm recovery fails to give an accurate approximation of the mean
square error as the compression rate grows, and therefore, the RSB ans\&quot;atze
are needed.
</dc:description>
 <dc:description>Comment: 80 pages, 14 Figures, Submitted to IEEE Transactions on Information
  Theory</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-10-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01981</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Core Sampling Framework for Pixel Classification</dc:title>
 <dc:creator>Karki, Manohar</dc:creator>
 <dc:creator>DiBiano, Robert</dc:creator>
 <dc:creator>Basu, Saikat</dc:creator>
 <dc:creator>Mukhopadhyay, Supratik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The intermediate map responses of a Convolutional Neural Network (CNN)
contain information about an image that can be used to extract contextual
knowledge about it. In this paper, we present a core sampling framework that is
able to use these activation maps from several layers as features to another
neural network using transfer learning to provide an understanding of an input
image. Our framework creates a representation that combines features from the
test data and the contextual knowledge gained from the responses of a
pretrained network, processes it and feeds it to a separate Deep Belief
Network. We use this representation to extract more information from an image
at the pixel level, hence gaining understanding of the whole image. We
experimentally demonstrate the usefulness of our framework using a pretrained
VGG-16 model to perform segmentation on the BAERI dataset of Synthetic Aperture
Radar(SAR) imagery and the CAMVID dataset.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01988</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Group Invariant Representations via Orbit Embeddings</dc:title>
 <dc:creator>Raj, Anant</dc:creator>
 <dc:creator>Kumar, Abhishek</dc:creator>
 <dc:creator>Mroueh, Youssef</dc:creator>
 <dc:creator>Fletcher, P. Thomas</dc:creator>
 <dc:creator>Sch&#xf6;lkopf, Bernhard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Invariance to nuisance transformations is one of the desirable properties of
effective representations. We consider transformations that form a \emph{group}
and propose an approach based on kernel methods to derive local group invariant
representations. Locality is achieved by defining a suitable probability
distribution over the group which in turn induces distributions in the input
feature space. We learn a decision function over these distributions by
appealing to the powerful framework of kernel methods and generate local
invariant random feature maps via kernel approximations. We show uniform
convergence bounds for kernel approximation and provide excess risk bounds for
learning with these features. We evaluate our method on three real datasets,
including Rotated MNIST and CIFAR-10, and observe that it outperforms competing
kernel based approaches. The proposed method also outperforms deep CNN on
Rotated-MNIST and performs comparably to the recently proposed
group-equivariant CNN.
</dc:description>
 <dc:description>Comment: AISTATS 2017 accepted version including appendix, 18 pages, 1 figure</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01991</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diverse Sampling for Self-Supervised Learning of Semantic Segmentation</dc:title>
 <dc:creator>Mostajabi, Mohammadreza</dc:creator>
 <dc:creator>Kolkin, Nicholas</dc:creator>
 <dc:creator>Shakhnarovich, Gregory</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose an approach for learning category-level semantic segmentation
purely from image-level classification tags indicating presence of categories.
It exploits localization cues that emerge from training classification-tasked
convolutional networks, to drive a &quot;self-supervision&quot; process that
automatically labels a sparse, diverse training set of points likely to belong
to classes of interest. Our approach has almost no hyperparameters, is modular,
and allows for very fast training of segmentation in less than 3 minutes. It
obtains competitive results on the VOC 2012 segmentation benchmark. More,
significantly the modularity and fast training of our framework allows new
classes to efficiently added for inference.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.01991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02034</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Modularity Revisited</dc:title>
 <dc:creator>Feige, Uriel</dc:creator>
 <dc:creator>Feldman, Michal</dc:creator>
 <dc:creator>Talgam-Cohen, Inbal</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Set functions with convenient properties (such as submodularity) appear in
application areas of current interest, such as algorithmic game theory, and
allow for improved optimization algorithms. It is natural to ask (e.g., in the
context of data driven optimization) how robust such properties are, and
whether small deviations from them can be tolerated. We consider two such
questions in the important special case of linear set functions.
  One question that we address is whether any set function that approximately
satisfies the modularity equation (linear functions satisfy the modularity
equation exactly) is close to a linear function. The answer to this is positive
(in a precise formal sense) as shown by Kalton and Roberts [1983] (and further
improved by Bondarenko, Prymak, and Radchenko [2013]). We revisit their proof
idea that is based on expander graphs, and provide significantly stronger upper
bounds by combining it with new techniques. Furthermore, we provide improved
lower bounds for this problem.
  Another question that we address is that of how to learn a linear function
$h$ that is close to an approximately linear function $f$, while querying the
value of $f$ on only a small number of sets. We present a deterministic
algorithm that makes only linearly many (in the number of items) nonadaptive
queries, by this improving over a previous algorithm of Chierichetti, Das,
Dasgupta and Kumar [2015] that is randomized and makes more than a quadratic
number of queries. Our learning algorithm is based on a Hadamard transform.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02044</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Voltage Uncertainties in the Presence of Photovoltaic Systems</dc:title>
 <dc:creator>Hughes, Katherine</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  With the rising demand for solar energy installation, there is a pressing
need for utilities to regulate the voltages at the distribution level. In grids
with high penetration of photovoltaic (PV) systems, voltage fluctuations can
occur at the distribution systems, resulting in inverter tripping and
insufficient power to meet the load. We present a linear model for voltage rise
versus PV output power. This model can be used to study the effect of
increasing PV system capacities on distribution system voltages. It is observed
that voltage fluctuations have greater correlation with the location of the PV
systems on the grid than with the PV system capacities, i.e., more randomness
and disorder in the behavior of voltage occurs with PV systems with larger line
impedance.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02045</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of Grid Impedance Variations on Harmonic Emission of
  Grid-Connected Inverters</dc:title>
 <dc:creator>Hoseinzadeh, Bakhtyar</dc:creator>
 <dc:creator>Bak, Claus Leth</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper addresses harmonic magnification due to resonance circuits
resulting from interaction between uncertain grid impedance and converter. The
source of harmonic may be either the grid or inverter. It is demonstrated that
unknown and unpredictable grid impedance may result in variable resonance
frequency, which challenges robust design of LCL filter of inverter.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:date>2017-04-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02055</identifier>
 <datestamp>2017-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Logic and Topology for Knowledge, Knowability, and Belief</dc:title>
 <dc:creator>Bjorndahl, Adam</dc:creator>
 <dc:creator>&#xd6;zg&#xfc;n, Ayb&#xfc;ke</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In recent work, Stalnaker proposes a logical framework in which belief is
realized as a weakened form of knowledge. Building on Stalnaker's core
insights, and using frameworks developed in previous work by Bjorndahl and
Baltag et al., we employ topological tools to refine and, we argue, improve on
this analysis. The structure of topological subset spaces allows for a natural
distinction between what is known and (roughly speaking) what is knowable; we
argue that the foundational axioms of Stalnaker's system rely intuitively on
both of these notions. More precisely, we argue that the plausibility of the
principles Stalnaker proposes relating knowledge and belief relies on a subtle
equivocation between an &quot;evidence-in-hand&quot; conception of knowledge and a weaker
&quot;evidence-out-there&quot; notion of what could come to be known. Our analysis leads
to a trimodal logic of knowledge, knowability, and belief interpreted in
topological subset spaces in which belief is definable in terms of knowledge
and knowability. We provide a sound and complete axiomatization for this logic
as well as its uni-modal belief fragment. We then consider weaker logics that
preserve suitable translations of Stalnaker's postulates, yet do not allow for
any reduction of belief. We propose novel topological semantics for these
irreducible notions of belief, generalizing our previous semantics, and provide
sound and complete axiomatizations for the corresponding logics.
</dc:description>
 <dc:description>Comment: 26 pages</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02062</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistency in the face of change: an adaptive approach to physical
  layer cooperation</dc:title>
 <dc:creator>Sengupta, Ayan</dc:creator>
 <dc:creator>Ezzeldin, Yahya H.</dc:creator>
 <dc:creator>Brahma, Siddhartha</dc:creator>
 <dc:creator>Fragouli, Christina</dc:creator>
 <dc:creator>Diggavi, Suhas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Most existing works on physical-layer (PHY) cooperation (beyond routing)
focus on how to best use a given, static relay network--while wireless networks
are anything but static. In this paper, we pose a different set of questions:
given that we have multiple devices within range, which relay(s) do we use for
PHY cooperation, to maintain a consistent target performance? How can we
efficiently adapt, as network conditions change? And how important is it, in
terms of performance, to adapt? Although adapting to the best path when routing
is a well understood problem, how to do so over PHY cooperation networks is an
open question. Our contributions are: (1) We demonstrate via theoretical
evaluation, a diminishing returns trend as the number of deployed relays
increases. (2) Using a simple algorithm based on network metrics, we
efficiently select the sub-network to use at any given time to maintain a
target reliability. (3) When streaming video from Netflix, we experimentally
show (using measurements from a WARP radio testbed employing DIQIF relaying)
that our adaptive PHY cooperation scheme provides a throughput gain of 2x over
nonadaptive PHY schemes, and a gain of 6x over genie-aided IP-level adaptive
routing.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02065</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative Visual Area Coverage using Unmanned Aerial Vehicles</dc:title>
 <dc:creator>Papatheodorou, Sotiris</dc:creator>
 <dc:creator>Tzes, Anthony</dc:creator>
 <dc:creator>Stergiopoulos, Yiannis</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  This article addresses the visual area coverage problem using a team of
Unmanned Aerial Vehicles (UAVs). The UAVs are assumed to be equipped with a
downward facing camera covering all points of interest within a circle on the
ground. The diameter of this circular conic-section increases as the UAV flies
at a larger height, yet the quality of the observed area is inverse
proportional to the UAV's height. The objective is to provide a distributed
control algorithm that maximizes a combined coverage-quality criterion by
adjusting the UAV's altitude. Simulation studies are offered to highlight the
effectiveness of the suggested scheme.
</dc:description>
 <dc:description>Comment: 8 pages, 14 figures, submitted to ICRA 2017 for review. arXiv admin
  note: substantial text overlap with arXiv:1612.02067</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02067</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative Visual Area Coverage</dc:title>
 <dc:creator>Papatheodorou, Sotiris</dc:creator>
 <dc:creator>Tzes, Anthony</dc:creator>
 <dc:creator>Stergiopoulos, Yiannis</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  This article examines the problem of visual area coverage by a network of
Mobile Aerial Agents (MAAs). Each MAA is assumed to be equipped with a
downwards facing camera with a conical field of view which covers all points
within a circle on the ground. The diameter of that circle is proportional to
the altitude of the MAA, whereas the quality of the covered area decreases with
the altitude. A distributed control law that maximizes a joint coverage-quality
criterion by adjusting the MAAs' spatial coordinates is developed. The
effectiveness of the proposed control scheme is evaluated through simulation
studies.
</dc:description>
 <dc:description>Comment: 26 pages, 14 figures, submitted to Robotics and Autonomous Systems on
  October 31 2016. arXiv admin note: substantial text overlap with
  arXiv:1612.02065</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02067</dc:identifier>
 <dc:identifier>doi:10.1016/j.robot.2017.03.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02088</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effect of Reward Function Choices in MDPs with Value-at-Risk</dc:title>
 <dc:creator>Ma, Shuai</dc:creator>
 <dc:creator>Yu, Jia Yuan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper studies Value-at-Risk (VaR) problems in short- and long-horizon
Markov decision processes (MDPs) with finite state space and two different
reward functions. Firstly we examine the effects of two reward functions under
two criteria in a short-horizon MDP. We show that under the VaR criterion, when
the original reward function is on both current and next states, the reward
simplification will change the VaR. Secondly, for long-horizon MDPs, we
estimate the Pareto front of the total reward distribution set with the aid of
spectral theory and the central limit theorem. Since the estimation is for a
Markov process with the simplified reward function only, we present a
transformation algorithm for the Markov process with the original reward
function, in order to estimate the Pareto front with an intact total reward
distribution.
</dc:description>
 <dc:description>Comment: 23 pages, 5 figures</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02095</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ExtremeWeather: A large-scale climate dataset for semi-supervised
  detection, localization, and understanding of extreme weather events</dc:title>
 <dc:creator>Racah, Evan</dc:creator>
 <dc:creator>Beckham, Christopher</dc:creator>
 <dc:creator>Maharaj, Tegan</dc:creator>
 <dc:creator>Kahou, Samira Ebrahimi</dc:creator>
 <dc:creator>Prabhat</dc:creator>
 <dc:creator>Pal, Christopher</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Then detection and identification of extreme weather events in large-scale
climate simulations is an important problem for risk management, informing
governmental policy decisions and advancing our basic understanding of the
climate system. Recent work has shown that fully supervised convolutional
neural networks (CNNs) can yield acceptable accuracy for classifying well-known
types of extreme weather events when large amounts of labeled data are
available. However, many different types of spatially localized climate
patterns are of interest including hurricanes, extra-tropical cyclones, weather
fronts, and blocking events among others. Existing labeled data for these
patterns can be incomplete in various ways, such as covering only certain years
or geographic areas and having false negatives. This type of climate data
therefore poses a number of interesting machine learning challenges. We present
a multichannel spatiotemporal CNN architecture for semi-supervised bounding box
prediction and exploratory data analysis. We demonstrate that our approach is
able to leverage temporal information and unlabeled data to improve the
localization of extreme weather events. Further, we explore the representations
learned by our model in order to better understand this important data. We
present a dataset, ExtremeWeather, to encourage machine learning research in
this area and to help facilitate further work in understanding and mitigating
the effects of climate change. The dataset is available at
extremeweatherdataset.github.io and the code is available at
https://github.com/eracah/hur-detect.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02099</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical and Computational Guarantees of Lloyd's Algorithm and its
  Variants</dc:title>
 <dc:creator>Lu, Yu</dc:creator>
 <dc:creator>Zhou, Harrison H.</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Clustering is a fundamental problem in statistics and machine learning.
Lloyd's algorithm, proposed in 1957, is still possibly the most widely used
clustering algorithm in practice due to its simplicity and empirical
performance. However, there has been little theoretical investigation on the
statistical and computational guarantees of Lloyd's algorithm. This paper is an
attempt to bridge this gap between practice and theory. We investigate the
performance of Lloyd's algorithm on clustering sub-Gaussian mixtures. Under an
appropriate initialization for labels or centers, we show that Lloyd's
algorithm converges to an exponentially small clustering error after an order
of $\log n$ iterations, where $n$ is the sample size. The error rate is shown
to be minimax optimal. For the two-mixture case, we only require the
initializer to be slightly better than random guess.
  In addition, we extend the Lloyd's algorithm and its analysis to community
detection and crowdsourcing, two problems that have received a lot of attention
recently in statistics and machine learning. Two variants of Lloyd's algorithm
are proposed respectively for community detection and crowdsourcing. On the
theoretical side, we provide statistical and computational guarantees of the
two algorithms, and the results improve upon some previous signal-to-noise
ratio conditions in literature for both problems. Experimental results on
simulated and real data sets demonstrate competitive performance of our
algorithms to the state-of-the-art methods.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02101</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bottom-Up Top-Down Cues for Weakly-Supervised Semantic Segmentation</dc:title>
 <dc:creator>Hou, Qinbin</dc:creator>
 <dc:creator>Dokania, Puneet Kumar</dc:creator>
 <dc:creator>Massiceti, Daniela</dc:creator>
 <dc:creator>Wei, Yunchao</dc:creator>
 <dc:creator>Cheng, Ming-Ming</dc:creator>
 <dc:creator>Torr, Philip</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We consider the task of learning a classifier for semantic segmentation using
weak supervision in the form of image labels which specify the object classes
present in the image. Our method uses deep convolutional neural networks (CNNs)
and adopts an Expectation-Maximization (EM) based approach. We focus on the
following three aspects of EM: (i) initialization; (ii) latent posterior
estimation (E-step) and (iii) the parameter update (M-step). We show that
saliency and attention maps, our bottom-up and top-down cues respectively, of
simple images provide very good cues to learn an initialization for the
EM-based algorithm. Intuitively, we show that before trying to learn to segment
complex images, it is much easier and highly effective to first learn to
segment a set of simple images and then move towards the complex ones. Next, in
order to update the parameters, we propose minimizing the combination of the
standard softmax loss and the KL divergence between the true latent posterior
and the likelihood given by the CNN. We argue that this combination is more
robust to wrong predictions made by the expectation step of the EM method. We
support this argument with empirical and visual results. Extensive experiments
and discussions show that: (i) our method is very simple and intuitive; (ii)
requires only image-level labels; and (iii) consistently outperforms other
weakly-supervised state-of-the-art methods with a very high margin on the
PASCAL VOC 2012 dataset.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02103</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Richer Convolutional Features for Edge Detection</dc:title>
 <dc:creator>Liu, Yun</dc:creator>
 <dc:creator>Cheng, Ming-Ming</dc:creator>
 <dc:creator>Hu, Xiaowei</dc:creator>
 <dc:creator>Wang, Kai</dc:creator>
 <dc:creator>Bai, Xiang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose an accurate edge detector using richer
convolutional features (RCF). Since objects in nature images have various
scales and aspect ratios, the automatically learned rich hierarchical
representations by CNNs are very critical and effective to detect edges and
object boundaries. And the convolutional features gradually become coarser with
receptive fields increasing. Based on these observations, our proposed network
architecture makes full use of multiscale and multi-level information to
perform the image-to-image edge prediction by combining all of the useful
convolutional features into a holistic framework. It is the first attempt to
adopt such rich convolutional features in computer vision tasks. Using VGG16
network, we achieve \sArt results on several available datasets. When
evaluating on the well-known BSDS500 benchmark, we achieve ODS F-measure of
\textbf{.811} while retaining a fast speed (\textbf{8} FPS). Besides, our fast
version of RCF achieves ODS F-measure of \textbf{.806} with \textbf{30} FPS.
</dc:description>
 <dc:description>Comment: IEEE CVPR 2017</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02106</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Free {\omega}-Continuous and Regular Ordered Algebras</dc:title>
 <dc:creator>Esik, Zoltan</dc:creator>
 <dc:creator>Kozen, Dexter</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Let E be a set of inequalities between finite {\Sigma}-terms. Let V_{\omega}
and V_r denote the varieties of all {\omega}-continuous ordered
{\Sigma}-algebras and regular ordered {\Sigma}-algebras satisfying E,
respectively. We prove that the free V_r-algebra R(X) on generators X is the
subalgebra of the corresponding free V_{\omega}-algebra F_{\omega}(X)
determined by those elements of F_{\omega}(X) denoted by the regular
{\Sigma}-coterms. We actually establish this fact as a special case of a more
general construction for families of algebras specified by syntactically
restricted completeness and continuity properties. Thus our result is also
applicable to ordered regular algebras of higher order.
</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02109</identifier>
 <datestamp>2017-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generalized Mixed-Integer Convex Program for Multilegged Footstep
  Planning on Uneven Terrain</dc:title>
 <dc:creator>Aceituno-Cabezas, Bernardo</dc:creator>
 <dc:creator>Cappelletto, Jose</dc:creator>
 <dc:creator>Grieco, Juan C.</dc:creator>
 <dc:creator>Fernandez-Lopez, Gerardo</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robot footstep planning strategies can be divided in two main approaches:
discrete searches and continuous optimizations. While discrete searches have
been broadly applied, continuous optimizations approaches have been restricted
for humanoid platforms. This article introduces a generalized
continuous-optimization approach for multilegged footstep planning which can be
adapted to different platforms, regardless the number and geometry of legs.
This approach leverages Mixed-Integer Convex Programming to account for the
non-convex constraints that represent footstep rotation and obstacle avoidance.
The planning problem is formulated as an optimization problem which considers
robot geometry and reachability with linear constraints, and can be efficiently
solved using optimization software. To demonstrate the functionality and
adaptability of the planner, a set of tests are performed on a BH3R hexapod and
a LittleDog quadruped on scenarios which can't be easily handled with discrete
searches, such tests are solved efficiently in fractions of a second. This work
represents, to the knowledge of the authors, the first successful
implementation of a continuous optimization-based multilegged footstep planner.
</dc:description>
 <dc:description>Comment: Submitted to a Journal</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02111</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Space Framework: An API for representation, persistence and
  visualization of knowledge spaces</dc:title>
 <dc:creator>Nasar, Syed</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This paper will discuss the challenges in tooling around the management and
utilization of knowledge space structures, via standardized APIs for external
Adaptive Learning Systems (ALS) to consume. It then describes how these
challenges are addressed in a graph based knowledge management framework
application designed for external ALSs.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02113</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fountain Code-Inspired Channel Estimation for Multi-user Millimeter Wave
  MIMO Systems</dc:title>
 <dc:creator>Kokshoorn, Matthew</dc:creator>
 <dc:creator>Chen, He</dc:creator>
 <dc:creator>Li, Yonghui</dc:creator>
 <dc:creator>Vucetic, Branka</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper develops a novel channel estimation approach for multi-user
millimeter wave (mmWave) wireless systems with large antenna arrays. By
exploiting the inherent mmWave channel sparsity, we propose a novel
simultaneous-estimation with iterative fountain training (SWIFT) framework, in
which the average number of channel measurements is adapted to various channel
conditions. To this end, the base station (BS) and each user continue to
measure the channel with a random subset of transmit/receive beamforming
directions until the channel estimate converges. We formulate the channel
estimation process as a compressed sensing problem and apply a sparse
estimation approach to recover the virtual channel information. As SWIFT does
not adapt the BS's transmitting beams to any single user, we are able to
estimate all user channels simultaneously. Simulation results show that SWIFT
can significantly outperform existing random-beamforming based approaches that
use a fixed number of measurements, over a range of signal-to-noise ratios and
channel coherence times.
</dc:description>
 <dc:description>Comment: To be presented at ICC, 2017</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02114</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experimental measurement-device-independent quantum random number
  generation</dc:title>
 <dc:creator>Nie, You-Qi</dc:creator>
 <dc:creator>Guan, Jian-Yu</dc:creator>
 <dc:creator>Zhou, Hongyi</dc:creator>
 <dc:creator>Zhang, Qiang</dc:creator>
 <dc:creator>Ma, Xiongfeng</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Pan, Jian-Wei</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The randomness from a quantum random number generator (QRNG) relies on the
accurate characterization of its devices. However, device imperfections and
inaccurate characterizations can result in wrong entropy estimation and bias in
practice, which highly affects the genuine randomness generation and may even
induce the disappearance of quantum randomness in an extreme case. Here we
experimentally demonstrate a measurement-device-independent (MDI) QRNG based on
time-bin encoding to achieve certified quantum randomness even when the
measurement devices are uncharacterized and untrusted. The MDI-QRNG is randomly
switched between the regular randomness generation mode and a test mode, in
which four quantum states are randomly prepared to perform measurement
tomography in real-time. With a clock rate of 25 MHz, the MDI-QRNG generates a
final random bit rate of 5.7 Kbps. Such implementation with an all-fiber setup
provides an approach to construct a fully-integrated MDI-QRNG with trusted but
error-prone devices in practice.
</dc:description>
 <dc:description>Comment: 15 pages, 5 figures, accepted for publication as a Rapid
  Communication in Physical Review A</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02114</dc:identifier>
 <dc:identifier>Phys. Rev. A 94, 060301(R) (2016)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevA.94.060301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02120</identifier>
 <datestamp>2016-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-Pass Approach to Large-Scale Connectomics</dc:title>
 <dc:creator>Meirovitch, Yaron</dc:creator>
 <dc:creator>Matveev, Alexander</dc:creator>
 <dc:creator>Saribekyan, Hayk</dc:creator>
 <dc:creator>Budden, David</dc:creator>
 <dc:creator>Rolnick, David</dc:creator>
 <dc:creator>Odor, Gergely</dc:creator>
 <dc:creator>Knowles-Barley, Seymour</dc:creator>
 <dc:creator>Jones, Thouis Raymond</dc:creator>
 <dc:creator>Pfister, Hanspeter</dc:creator>
 <dc:creator>Lichtman, Jeff William</dc:creator>
 <dc:creator>Shavit, Nir</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  The field of connectomics faces unprecedented &quot;big data&quot; challenges. To
reconstruct neuronal connectivity, automated pixel-level segmentation is
required for petabytes of streaming electron microscopy data. Existing
algorithms provide relatively good accuracy but are unacceptably slow, and
would require years to extract connectivity graphs from even a single cubic
millimeter of neural tissue. Here we present a viable real-time solution, a
multi-pass pipeline optimized for shared-memory multicore systems, capable of
processing data at near the terabyte-per-hour pace of multi-beam electron
microscopes. The pipeline makes an initial fast-pass over the data, and then
makes a second slow-pass to iteratively correct errors in the output of the
fast-pass. We demonstrate the accuracy of a sparse slow-pass reconstruction
algorithm and suggest new methods for detecting morphological errors. Our
fast-pass approach provided many algorithmic challenges, including the design
and implementation of novel shallow convolutional neural nets and the
parallelization of watershed and object-merging techniques. We use it to
reconstruct, from image stack to skeletons, the full dataset of Kasthuri et al.
(463 GB capturing 120,000 cubic microns) in a matter of hours on a single
multicore machine rather than the weeks it has taken in the past on much larger
distributed systems.
</dc:description>
 <dc:description>Comment: 18 pages, 10 figures</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02126</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate-cost tradeoffs in control</dc:title>
 <dc:creator>Kostina, Victoria</dc:creator>
 <dc:creator>Hassibi, Babak</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Consider a control problem with a communication channel connecting the
observer of a linear stochastic system to the controller. The goal of the
controller is to minimize a quadratic cost function in the state variables and
control signal, known as the linear quadratic regulator (LQR). We study the
fundamental tradeoff between the communication rate $r$ bits/sec and the
expected cost $b$. We obtain a lower bound on a certain rate-cost function,
which quantifies the minimum directed mutual information between the channel
input and output that is compatible with a target LQR cost. The rate-cost
function has operational significance in multiple scenarios of interest: among
others, it allows us to lower-bound the minimum communication rate for fixed
and variable length quantization, and for control over noisy channels. We
derive an explicit lower bound to the rate-cost function, which applies to the
vector, non-Gaussian, and partially observed systems, thereby extending and
generalizing an earlier explicit expression for the scalar Gaussian system, due
to Tatikonda el al. The bound applies as long as the system noise has a
probability density function. It can be closely approached by a simple lattice
quantization scheme that only quantizes the innovation, that is, the difference
between the controller's belief about the current state and the true state. Via
a separation principle between control and communication, similar results hold
for causal lossy compression of additive noise Markov sources. Apart from
standard dynamic programming arguments, our technical approach leverages the
Shannon lower bound, develops new estimates for data compression with coding
memory, and uses some recent results on high resolution variable-length vector
quantization to prove that the new converse bounds are tight.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02126</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02128</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate-cost tradeoffs in control. Part II: achievable scheme</dc:title>
 <dc:creator>Kostina, Victoria</dc:creator>
 <dc:creator>Hassibi, Babak</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Consider a distributed control problem with a communication channel
connecting the observer of a linear stochastic system to the controller. The
goal of the controller is to minimize a quadratic cost function in the state
variables and control signal, known as the linear quadratic regulator (LQR). We
study the fundamental tradeoff between the communication rate r bits/sec and
the limsup of the expected cost b. In the companion paper, which can be read
independently of the current one, we show a lower bound on a certain cost
function, which quantifies the minimum mutual information between the channel
input and output, given the past, that is compatible with a target LQR cost.
The bound applies as long as the system noise has a probability density
function, and it holds for a general class of codes that can take full
advantage of the memory of the data observed so far and that are not
constrained to have any particular structure. In this paper, we prove that the
bound can be approached by a simple variable-length lattice quantization
scheme, as long as the system noise satisfies a smoothness condition. The
quantization scheme only quantizes the innovation, that is, the difference
between the controller's belief about the current state and the encoder's state
estimate. Our proof technique leverages some recent results on nonasymptotic
high resolution vector quantization.
</dc:description>
 <dc:description>Comment: merged with Part I (1612.02126)</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02130</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predictive Business Process Monitoring with LSTM Neural Networks</dc:title>
 <dc:creator>Tax, Niek</dc:creator>
 <dc:creator>Verenich, Ilya</dc:creator>
 <dc:creator>La Rosa, Marcello</dc:creator>
 <dc:creator>Dumas, Marlon</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Predictive business process monitoring methods exploit logs of completed
cases of a process in order to make predictions about running cases thereof.
Existing methods in this space are tailor-made for specific prediction tasks.
Moreover, their relative accuracy is highly sensitive to the dataset at hand,
thus requiring users to engage in trial-and-error and tuning when applying them
in a specific setting. This paper investigates Long Short-Term Memory (LSTM)
neural networks as an approach to build consistently accurate models for a wide
range of predictive process monitoring tasks. First, we show that LSTMs
outperform existing techniques to predict the next event of a running case and
its timestamp. Next, we show how to use models for predicting the next task in
order to predict the full continuation of a running case. Finally, we apply the
same approach to predict the remaining time, and show that this approach
outperforms existing tailor-made methods.
</dc:description>
 <dc:description>Comment: Accepted at the International Conference on Advanced Information
  Systems Engineering (CAiSE) 2017</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02130</dc:identifier>
 <dc:identifier>Lecture Notes in Computer Science, 10253 (2017) 477-492</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-59536-8_30</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02135</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrete and Continuous ambush games: optimal policies and approximate
  solutions</dc:title>
 <dc:creator>Boidot, Emmanuel</dc:creator>
 <dc:creator>Marzuoli, Aude</dc:creator>
 <dc:creator>Feron, Eric</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We consider an autonomous navigation problem, whereby a traveler aims at
traversing an environment in which an adversary tries to set an ambush. A two
players zero sum game is introduced. Players' strategies are computed as random
path distributions, a realization of which is the path chosen by the traveler.
A parallel is drawn between the discrete problem, where the traveler moves on a
network, and the continuous problem, where the traveler moves in the plane.
Analytical optimal policies are derived. Using assumptions from the Minimal Cut
- Maximal Flow literature, the optimal value of the game is shown to be related
to the maximum flow on the environment in both the discrete and the continuous
cases, when the reward function for the ambusher is uniform. A linear program
is introduced that allows for the computation of optimal policies, compatible
with non-uniform reward functions. In order to relax the assumptions for the
computation of the players' optimal strategies of the continuous game, a
network is created, inspired by recently introduced sampling based motion
planning techniques, and the linear program is adapted for continuous
constraints.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02136</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mode Regularized Generative Adversarial Networks</dc:title>
 <dc:creator>Che, Tong</dc:creator>
 <dc:creator>Li, Yanran</dc:creator>
 <dc:creator>Jacob, Athul Paul</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:creator>Li, Wenjie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Although Generative Adversarial Networks achieve state-of-the-art results on
a variety of generative tasks, they are regarded as highly unstable and prone
to miss modes. We argue that these bad behaviors of GANs are due to the very
particular functional shape of the trained discriminators in high dimensional
spaces, which can easily make training stuck or push probability mass in the
wrong direction, towards that of higher concentration than that of the data
generating distribution. We introduce several ways of regularizing the
objective, which can dramatically stabilize the training of GAN models. We also
show that our regularizers can help the fair distribution of probability mass
across the modes of the data generating distribution, during the early phases
of training and thus providing a unified solution to the missing modes problem.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02141</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Localized Geometric Features Using 3D-CNN: An Application to
  Manufacturability Analysis of Drilled Holes</dc:title>
 <dc:creator>Balu, Aditya</dc:creator>
 <dc:creator>Ghadai, Sambit</dc:creator>
 <dc:creator>Lore, Kin Gwn</dc:creator>
 <dc:creator>Young, Gavin</dc:creator>
 <dc:creator>Krishnamurthy, Adarsh</dc:creator>
 <dc:creator>Sarkar, Soumik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  3D convolutional neural networks (3D-CNN) have been used for object
recognition based on the voxelized shape of an object. In this paper, we
present a 3D-CNN based method to learn distinct local geometric features of
interest within an object. In this context, the voxelized representation may
not be sufficient to capture the distinguishing information about such local
features. To enable efficient learning, we augment the voxel data with surface
normals of the object boundary. We then train a 3D-CNN with this augmented data
and identify the local features critical for decision-making using 3D
gradient-weighted class activation maps. An application of this feature
identification framework is to recognize difficult-to-manufacture drilled hole
features in a complex CAD geometry. The framework can be extended to identify
difficult-to-manufacture features at multiple spatial scales leading to a
real-time decision support system for design for manufacturability.
</dc:description>
 <dc:description>Comment: 9 Pages</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02145</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Linear Precoding Design for Multi-user MIMO Systems</dc:title>
 <dc:creator>Sarker, Md. Abdul Latif</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We address the problem of the bit error rate (BER) performance gap between
the sub-optimal and optimal linear precoder (LP) for a multiuser (MU) multiple
input and multiple output (MIMO) broadcast systems in this paper. Particularly,
mobile users suffer noise enhancement effect due to a sub-optimal LP that can
be suppressed by an optimal LP matrix. A sub-optimal LP matrix such as a linear
zero-forcing (LZF) precoder performs in high signal to noise ratio (SNR) regime
only, in contrast, an optimal precoder for instance a linear minimum
mean-square-error (LMMSE) precoder outperforms in both low and high SNR
scenarios. These kinds of precoder illustrates the BER gap distance at least
0.1 when it is used in itself in a MU MIMO systems. Thus, we propose and design
a unified linear precoding (ULP) matrix using a precoding selection technique
that combines the sub-optimal and optimal LP matrix for a multi-user MIMO
systems to ensure zero BER performance gap in this paper. The numerical results
show that our proposed ULP technique offers significant performance in both low
and high SNR scenarios.
</dc:description>
 <dc:description>Comment: 4</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02149</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Covering many points with a small-area box</dc:title>
 <dc:creator>de Berg, Mark</dc:creator>
 <dc:creator>Cabello, Sergio</dc:creator>
 <dc:creator>Cheong, Otfried</dc:creator>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:creator>Knauer, Christian</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Let $P$ be a set of $n$ points in the plane. We show how to find, for a given
integer $k&gt;0$, the smallest-area axis-parallel rectangle that covers $k$ points
of $P$ in $O(nk^2 \log n+ n\log^2 n)$ time. We also consider the problem of,
given a value $\alpha&gt;0$, covering as many points of $P$ as possible with an
axis-parallel rectangle of area at most $\alpha$. For this problem we give a
randomized $(1-\varepsilon)$-approximation that works in near-linear time: in
$O((n/\varepsilon^4)\log^3 n \log (1/\varepsilon))$ time we find an
axis-parallel rectangle of area at most $\alpha$ that covers at least
$(1-\varepsilon)\kappa^*$ points, where $\kappa^*$ is the maximum possible
number of points that could be covered.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02153</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting Hammel et al. (1987): Does the shadowing property hold for
  modern computers?</dc:title>
 <dc:creator>Silva, B. C.</dc:creator>
 <dc:creator>Milani, F. L.</dc:creator>
 <dc:creator>Nepomuceno, E. G.</dc:creator>
 <dc:creator>Martins, S. A. M.</dc:creator>
 <dc:creator>Amaral, G. F. V.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Computational techniques are extensively applied in nonlinear science.
However, while the use of computers for research has been expressive, the
evaluation of numerical results does not grow in the same pace. Hammel et al.
(Journal of Complexity, 1987, 3(2), 136--145) were pioneers in the numerical
reliability field and have proved a theorem that a pseudo-orbit of a logistic
map is shadowed by a true orbit within a distance of $10^{-8}$ for $10^{7}$
iterates. But the simulation of the logistic map with less than 100 iterates
presents an error greater than $10^{-8}$ in a modern computer, performing a
test based on the concept of multiple pseudo-orbits and symbolic computing.
</dc:description>
 <dc:description>Comment: 6th NSC - International Conference on Nonlinear Science and
  Complexity, NSC, S\~ao Jos\'e dos Campos, Brazil, p.1-4</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02155</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Re-identification of Humans in Crowds using Personal, Social and
  Environmental Constraints</dc:title>
 <dc:creator>Assari, Shayan Modiri</dc:creator>
 <dc:creator>Idrees, Haroon</dc:creator>
 <dc:creator>Shah, Mubarak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the problem of human re-identification across
non-overlapping cameras in crowds.Re-identification in crowded scenes is a
challenging problem due to large number of people and frequent occlusions,
coupled with changes in their appearance due to different properties and
exposure of cameras. To solve this problem, we model multiple Personal, Social
and Environmental (PSE) constraints on human motion across cameras. The
personal constraints include appearance and preferred speed of each individual
assumed to be similar across the non-overlapping cameras. The social influences
(constraints) are quadratic in nature, i.e. occur between pairs of individuals,
and modeled through grouping and collision avoidance. Finally, the
environmental constraints capture the transition probabilities between gates
(entrances / exits) in different cameras, defined as multi-modal distributions
of transition time and destination between all pairs of gates. We incorporate
these constraints into an energy minimization framework for solving human
re-identification. Assigning $1-1$ correspondence while modeling PSE
constraints is NP-hard. We present a stochastic local search algorithm to
restrict the search space of hypotheses, and obtain $1-1$ solution in the
presence of linear and quadratic PSE constraints. Moreover, we present an
alternate optimization using Frank-Wolfe algorithm that solves the convex
approximation of the objective function with linear relaxation on binary
variables, and yields an order of magnitude speed up over stochastic local
search with minor drop in performance. We evaluate our approach using
Cumulative Matching Curves as well $1-1$ assignment on several thousand frames
of Grand Central, PRID and DukeMTMC datasets, and obtain significantly better
results compared to existing re-identification methods.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02158</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proper Coloring of Geometric Hypergraphs</dc:title>
 <dc:creator>Keszegh, Bal&#xe1;zs</dc:creator>
 <dc:creator>P&#xe1;lv&#xf6;lgyi, D&#xf6;m&#xf6;t&#xf6;r</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We study whether for a given planar family F there is an m such that any
finite set of points can be 3-colored such that any member of F that contains
at least m points contains two points with different colors. We conjecture that
if F is a family of pseudo-disks, then m=3 is sufficient. We prove that when F
is the family of all homothetic copies of a given convex polygon, then such an
m exists. We also study the problem in higher dimensions.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02161</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring the non-asymptotic convergence of sequential Monte Carlo
  samplers using probabilistic programming</dc:title>
 <dc:creator>Cusumano-Towner, Marco F.</dc:creator>
 <dc:creator>Mansinghka, Vikash K.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A key limitation of sampling algorithms for approximate inference is that it
is difficult to quantify their approximation error. Widely used sampling
schemes, such as sequential importance sampling with resampling and
Metropolis-Hastings, produce output samples drawn from a distribution that may
be far from the target posterior distribution. This paper shows how to
upper-bound the symmetric KL divergence between the output distribution of a
broad class of sequential Monte Carlo (SMC) samplers and their target posterior
distributions, subject to assumptions about the accuracy of a separate
gold-standard sampler. The proposed method applies to samplers that combine
multiple particles, multinomial resampling, and rejuvenation kernels. The
experiments show the technique being used to estimate bounds on the divergence
of SMC samplers for posterior inference in a Bayesian linear regression model
and a Dirichlet process mixture model.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-05-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02166</identifier>
 <datestamp>2016-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consensus Based Medical Image Segmentation Using Semi-Supervised
  Learning And Graph Cuts</dc:title>
 <dc:creator>Mahapatra, Dwarikanath</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Medical image segmentation requires consensus ground truth segmentations to
be derived from multiple expert annotations. A novel approach is proposed that
obtains consensus segmentations from experts using graph cuts (GC) and semi
supervised learning (SSL). Popular approaches use iterative Expectation
Maximization (EM) to estimate the final annotation and quantify annotator's
performance. Such techniques pose the risk of getting trapped in local minima.
We propose a self consistency (SC) score to quantify annotator consistency
using low level image features. SSL is used to predict missing annotations by
considering global features and local image consistency. The SC score also
serves as the penalty cost in a second order Markov random field (MRF) cost
function optimized using graph cuts to derive the final consensus label. Graph
cut obtains a global maximum without an iterative procedure. Experimental
results on synthetic images, real data of Crohn's disease patients and retinal
images show our final segmentation to be accurate and more consistent than
competing methods.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2016-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02166</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02168</identifier>
 <datestamp>2017-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asynchronous approach in the plane: A deterministic polynomial algorithm</dc:title>
 <dc:creator>Bouchard, S&#xe9;bastien</dc:creator>
 <dc:creator>Bournat, Marjorie</dc:creator>
 <dc:creator>Dieudonn&#xe9;, Yoann</dc:creator>
 <dc:creator>Dubois, Swan</dc:creator>
 <dc:creator>Petit, Franck</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper we study the task of approach of two mobile agents having the
same limited range of vision and moving asynchronously in the plane. This task
consists in getting them in finite time within each other's range of vision.
The agents execute the same deterministic algorithm and are assumed to have a
compass showing the cardinal directions as well as a unit measure. On the other
hand, they do not share any global coordinates system (like GPS), cannot
communicate and have distinct labels. Each agent knows its label but does not
know the label of the other agent or the initial position of the other agent
relative to its own. The route of an agent is a sequence of segments that are
subsequently traversed in order to achieve approach. For each agent, the
computation of its route depends only on its algorithm and its label. An
adversary chooses the initial positions of both agents in the plane and
controls the way each of them moves along every segment of the routes, in
particular by arbitrarily varying the speeds of the agents. A deterministic
approach algorithm is a deterministic algorithm that always allows two agents
with any distinct labels to solve the task of approach regardless of the
choices and the behavior of the adversary. The cost of a complete execution of
an approach algorithm is the length of both parts of route travelled by the
agents until approach is completed. Let $\Delta$ and $l$ be the initial
distance separating the agents and the length of the shortest label,
respectively. Assuming that $\Delta$ and $l$ are unknown to both agents, does
there exist a deterministic approach algorithm always working at a cost that is
polynomial in $\Delta$ and $l$? In this paper, we provide a positive answer to
the above question by designing such an algorithm.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02170</identifier>
 <datestamp>2017-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-volatile spin wave majority gate at the nanoscale</dc:title>
 <dc:creator>Zografos, Odysseas</dc:creator>
 <dc:creator>Dutta, Sourav</dc:creator>
 <dc:creator>Manfrini, Mauricio</dc:creator>
 <dc:creator>Vaysset, Adrien</dc:creator>
 <dc:creator>Sor&#xe9;e, Bart</dc:creator>
 <dc:creator>Naeemi, Azad</dc:creator>
 <dc:creator>Raghavan, Praveen</dc:creator>
 <dc:creator>Lauwereins, Rudy</dc:creator>
 <dc:creator>Radu, Iuliana P.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:description>  A spin wave majority fork-like structure with feature size of 40\,nm, is
presented and investigated, through micromagnetic simulations. The structure
consists of three merging out-of-plane magnetization spin wave buses and four
magneto-electric cells serving as three inputs and an output. The information
of the logic signals is encoded in the phase of the transmitted spin waves and
subsequently stored as direction of magnetization of the magneto-electric cells
upon detection. The minimum dimensions of the structure that produce an
operational majority gate are identified. For all input combinations, the
detection scheme employed manages to capture the majority phase result of the
spin wave interference and ignore all reflection effects induced by the
geometry of the structure.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02170</dc:identifier>
 <dc:identifier>AIP Advances, Volume 7, Issue 5, 2017</dc:identifier>
 <dc:identifier>doi:10.1063/1.4975693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02172</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Play With Me? Understanding and Measuring the Social Aspect of Casual
  Gaming</dc:title>
 <dc:creator>Als&#xe9;n, Adam</dc:creator>
 <dc:creator>Runge, Julian</dc:creator>
 <dc:creator>Drachen, Anders</dc:creator>
 <dc:creator>Klapper, Daniel</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>00Bxx</dc:subject>
 <dc:description>  Social gaming is today a pervasive phenomenon. Driven by the advent of social
networks and the digitization of game distribution. In this paper the impact of
digitization and so-cial networks such as Facebook on digital games is
de-scribed and evaluated. This impact follows several vectors, including the
introduction of new game formats and extend-ing the traditional audiences for
games, which in turn has increased industrial revenue. The industry is in turn
shaped by new business model such as Free-to-Play, digital distri-bution and
the use of viral social features. These changes do not only appear
irreversible, but more importantly, play a part in shaping the future of
digital game design, notably for mobile devices. The paper presents new
knowledge from controlled live experiments from a casual social game across
Facebook and mobile platforms, finding positive re-turns by adding social
gameplay features. This suggests that not only social network games, but also
casual mobile games can benefit from deeper social gameplay mechanics. Given
the impact of social features on gameplay, Game An-alytics will need to evolve
to be able to handle requirements that arise from the introduction of social
features, e.g. how to measure engagement against social features and shaping
organic and viral spreading of a game.
</dc:description>
 <dc:description>Comment: Preprint version for PA workshop 2016. 7 pages. 7 figures</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02174</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EMC Regulations and Spectral Constraints for Multicarrier Modulation in
  PLC</dc:title>
 <dc:creator>Girotto, Mauro</dc:creator>
 <dc:creator>Tonello, Andrea M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers Electromagnetic Compatibility (EMC) aspects in the
context of Power Line Communication (PLC) systems. It offers a complete
overview of both narrow band PLC and broad band PLC EMC norms. How to interpret
and translate such norms and measurement procedures into typical constraints
used by designers of communication systems, is discussed. In particular, the
constraints to the modulated signal spectrum are considered and the ability of
pulse shaped OFDM (PS-OFDM), used in most of the PLC standards as IEEE P1901
and P1901.2, to fulfill them is analyzed. In addition, aiming to improve the
spectrum management ability, a novel scheme named Pulse Shaped Cyclic Block
Filtered Multitone modulation (PS-CB-FMT) is introduced and compared to
PS-OFDM. It is shown that, PS-CB-FMT offers better ability to fulfill the norms
which translates in higher system capacity.
</dc:description>
 <dc:description>Comment: A version of this manuscript has been submitted to the IEEE Access
  for possible publication</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02175</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient use of paired spectrum bands through TDD small cell
  deployments</dc:title>
 <dc:creator>Agustin, A.</dc:creator>
 <dc:creator>Lagen, S.</dc:creator>
 <dc:creator>Vidal, J.</dc:creator>
 <dc:creator>Mu&#xf1;oz, O.</dc:creator>
 <dc:creator>Pascual-Iserte, A.</dc:creator>
 <dc:creator>Zhiheng, G.</dc:creator>
 <dc:creator>Ronghui, W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Traditionally, wireless cellular systems have been designed to operate in
Frequency Division Duplexing (FDD) paired bands that allocates the same amount
of spectrum for both downlink (DL) and uplink (UL) communication. Such design
is very convenient under symmetric DL/UL traffic conditions, as it used to be
the case when the voice transmission was the predominant service. However, with
the overwhelming advent of data services, bringing along large asymmetries
between DL and UL, the conventional FDD solution becomes inefficient. In this
regard, flexible duplexing concepts aim to derive procedures for improving the
spectrum utilization, by adjusting resources to the actual traffic demand. In
this work we review these concepts and propose the use of unpaired Time
Division Duplexing (TDD) spectrum on the unused resources for small eNBs
(SeNB), so that user equipment (UEs) associated to those SeNB could be served
either in DL or UL. This proposal alleviates the saturated DL in FDD-based
system through user offloading towards the TDD-based system. The flexible
duplexing concept is analyzed from three points of view: a) regulation, b) Long
Term Evolution (LTE)standardization, and c) technical solutions.
</dc:description>
 <dc:description>Comment: submitted to IEEE Communications Magazine</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02177</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Multi-scale Convolutional Neural Network for Dynamic Scene
  Deblurring</dc:title>
 <dc:creator>Nah, Seungjun</dc:creator>
 <dc:creator>Kim, Tae Hyun</dc:creator>
 <dc:creator>Lee, Kyoung Mu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Non-uniform blind deblurring for general dynamic scenes is a challenging
computer vision problem since blurs are caused by camera shake, scene depth as
well as multiple object motions. To remove these complicated motion blurs,
conventional energy optimization based methods rely on simple assumptions such
that blur kernel is partially uniform or locally linear. Moreover, recent
machine learning based methods also depend on synthetic blur datasets generated
under these assumptions. This makes conventional deblurring methods fail to
remove blurs where blur kernel is difficult to approximate or parameterize
(e.g. object motion boundaries). In this work, we propose a multi-scale
convolutional neural network that restores blurred images caused by various
sources in an end-to-end manner. Furthermore, we present multi-scale loss
function that mimics conventional coarse-to-fine approaches. Moreover, we
propose a new large scale dataset that provides pairs of realistic blurry image
and the corresponding ground truth sharp image that are obtained by a
high-speed camera. With the proposed model trained on this dataset, we
demonstrate empirically that our method achieves the state-of-the-art
performance in dynamic scene deblurring not only qualitatively, but also
quantitatively.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02179</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-based Adversarial Imitation Learning</dc:title>
 <dc:creator>Baram, Nir</dc:creator>
 <dc:creator>Anschel, Oron</dc:creator>
 <dc:creator>Mannor, Shie</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative adversarial learning is a popular new approach to training
generative models which has been proven successful for other related problems
as well. The general idea is to maintain an oracle $D$ that discriminates
between the expert's data distribution and that of the generative model $G$.
The generative model is trained to capture the expert's distribution by
maximizing the probability of $D$ misclassifying the data it generates.
Overall, the system is \emph{differentiable} end-to-end and is trained using
basic backpropagation. This type of learning was successfully applied to the
problem of policy imitation in a model-free setup. However, a model-free
approach does not allow the system to be differentiable, which requires the use
of high-variance gradient estimations. In this paper we introduce the Model
based Adversarial Imitation Learning (MAIL) algorithm. A model-based approach
for the problem of adversarial imitation learning. We show how to use a forward
model to make the system fully differentiable, which enables us to train
policies using the (stochastic) gradient of $D$. Moreover, our approach
requires relatively few environment interactions, and fewer hyper-parameters to
tune. We test our method on the MuJoCo physics simulator and report initial
results that surpass the current state-of-the-art.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02183</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fusion of Range and Thermal Images for Person Detection</dc:title>
 <dc:creator>Abbeloos, Wim</dc:creator>
 <dc:creator>Goedem&#xe9;, Toon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Detecting people in images is a challenging problem. Differences in pose,
clothing and lighting, along with other factors, cause a lot of variation in
their appearance. To overcome these issues, we propose a system based on fused
range and thermal infrared images. These measurements show considerably less
variation and provide more meaningful information. We provide a brief
introduction to the sensor technology used and propose a calibration method.
Several data fusion algorithms are compared and their performance is assessed
on a simulated data set. The results of initial experiments on real data are
analyzed and the measurement errors and the challenges they present are
discussed. The resulting fused data are used to efficiently detect people in a
fixed camera set-up. The system is extended to include person tracking.
</dc:description>
 <dc:description>Comment: VII International Conference on Electrical Engineering FIE 2014,
  Santiago de Cuba</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02183</dc:identifier>
 <dc:identifier>Proceedings Conferencia Internacional de Ingenier\'ia El\'ectrica
  7 (2014) 1-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02184</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Saliency Driven Image Manipulation</dc:title>
 <dc:creator>Mechrez, Roey</dc:creator>
 <dc:creator>Shechtman, Eli</dc:creator>
 <dc:creator>Zelnik-Manor, Lihi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Have you ever taken a picture only to find out that an unimportant background
object ended up being overly salient? Or one of those team sports photos where
your favorite player blends with the rest? Wouldn't it be nice if you could
tweak these pictures just a little bit so that the distractor would be
attenuated and your favorite player will stand-out among her peers?
Manipulating images in order to control the saliency of objects is the goal of
this paper. We propose an approach that considers the internal color and
saliency properties of the image. It changes the saliency map via an
optimization framework that relies on patch-based manipulation using only
patches from within the same image to achieve realistic looking results.
Applications include object enhancement, distractors attenuation and background
decluttering. Comparing our method to previous ones shows significant
improvement, both in the achieved saliency manipulation and in the realistic
appearance of the resulting images.
</dc:description>
 <dc:description>Comment: to appear in WACV'18</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02184</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02190</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Template Matching with Deformable Diversity Similarity</dc:title>
 <dc:creator>Talmi, Itamar</dc:creator>
 <dc:creator>Mechrez, Roey</dc:creator>
 <dc:creator>Zelnik-Manor, Lihi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel measure for template matching named Deformable Diversity
Similarity -- based on the diversity of feature matches between a target image
window and the template. We rely on both local appearance and geometric
information that jointly lead to a powerful approach for matching. Our key
contribution is a similarity measure, that is robust to complex deformations,
significant background clutter, and occlusions. Empirical evaluation on the
most up-to-date benchmark shows that our method outperforms the current
state-of-the-art in its detection accuracy while improving computational
complexity.
</dc:description>
 <dc:description>Comment: accepted to CVPR2017 (spotlight)</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02192</identifier>
 <datestamp>2017-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Adaptation in Generative Models with Generative Matching Networks</dc:title>
 <dc:creator>Bartunov, Sergey</dc:creator>
 <dc:creator>Vetrov, Dmitry P.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:description>  Despite recent advances, the remaining bottlenecks in deep generative models
are necessity of extensive training and difficulties with generalization from
small number of training examples. We develop a new generative model called
Generative Matching Network which is inspired by the recently proposed matching
networks for one-shot learning in discriminative tasks. By conditioning on the
additional input dataset, our model can instantly learn new concepts that were
not available in the training data but conform to a similar generative process.
The proposed framework does not explicitly restrict diversity of the
conditioning data and also does not require an extensive inference procedure
for training or adaptation. Our experiments on the Omniglot dataset demonstrate
that Generative Matching Networks significantly improve predictive performance
on the fly as more additional data is available and outperform existing state
of the art conditional generative models.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02198</identifier>
 <datestamp>2016-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards computer-assisted understanding of dynamics in symphonic music</dc:title>
 <dc:creator>Grachten, Maarten</dc:creator>
 <dc:creator>Cancino-Chac&#xf3;n, Carlos Eduardo</dc:creator>
 <dc:creator>Gadermaier, Thassilo</dc:creator>
 <dc:creator>Widmer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Many people enjoy classical symphonic music. Its diverse instrumentation
makes for a rich listening experience. This diversity adds to the conductor's
expressive freedom to shape the sound according to their imagination. As a
result, the same piece may sound quite differently from one conductor to
another. Differences in interpretation may be noticeable subjectively to
listeners, but they are sometimes hard to pinpoint, presumably because of the
acoustic complexity of the sound. We describe a computational model that
interprets dynamics---expressive loudness variations in performances---in terms
of the musical score, highlighting differences between performances of the same
piece. We demonstrate experimentally that the model has predictive power, and
give examples of conductor ideosyncrasies found by using the model as an
explanatory tool. Although the present model is still in active development, it
may pave the road for a consumer-oriented companion to interactive classical
music understanding.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2016-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02202</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full diversity sets of unitary matrices from orthogonal sets of
  idempotents</dc:title>
 <dc:creator>Hurley, Ted</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>16S99, 94A05</dc:subject>
 <dc:description>  Orthogonal sets of idempotents are used to design sets of unitary matrices,
known as constellations, such that the modulus of the determinant of the
difference of any two distinct elements is greater than $0$. It is shown that
unitary matrices in general are derived from orthogonal sets of idempotents
reducing the design problem to a construction problem of unitary matrices from
such sets. The quality of the constellations constructed in this way and the
actual differences between the unitary matrices can be determined algebraically
from the idempotents used.
  This has applications to the design of unitary space time constellations.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1205.0703</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02203</identifier>
 <datestamp>2017-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Functional Regression approach to Facial Landmark Tracking</dc:title>
 <dc:creator>S&#xe1;nchez-Lozano, Enrique</dc:creator>
 <dc:creator>Tzimiropoulos, Georgios</dc:creator>
 <dc:creator>Martinez, Brais</dc:creator>
 <dc:creator>De la Torre, Fernando</dc:creator>
 <dc:creator>Valstar, Michel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Linear regression is a fundamental building block in many face detection and
tracking algorithms, typically used to predict shape displacements from image
features through a linear mapping. This paper presents a Functional Regression
solution to the least squares problem, which we coin Continuous Regression,
resulting in the first real-time incremental face tracker. Contrary to prior
work in Functional Regression, in which B-splines or Fourier series were used,
we propose to approximate the input space by its first-order Taylor expansion,
yielding a closed-form solution for the continuous domain of displacements. We
then extend the continuous least squares problem to correlated variables, and
demonstrate the generalisation of our approach. We incorporate Continuous
Regression into the cascaded regression framework, and show its computational
benefits for both training and testing. We then present a fast approach for
incremental learning within Cascaded Continuous Regression, coined iCCR, and
show that its complexity allows real-time face tracking, being 20 times faster
than the state of the art. To the best of our knowledge, this is the first
incremental face tracker that is shown to operate in real-time. We show that
iCCR achieves state-of-the-art performance on the 300-VW dataset, the most
recent, large-scale benchmark for face tracking.
</dc:description>
 <dc:description>Comment: Accepted at IEEE TPAMI. This is authors' version. 0162-8828
  \copyright 2017 IEEE. Personal use is permitted, but
  republication/redistribution requires IEEE permission. See
  http://www.ieee.org/publications_standards/publications/rights/index.html for
  more information</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02203</dc:identifier>
 <dc:identifier>IEEE Transactions on Pattern Analysis and Machine Intelligence,
  2017</dc:identifier>
 <dc:identifier>doi:10.1109/TPAMI.2017.2745568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02213</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Counting Subring-Subcodes of Free Linear Codes Over Finite Principal
  Ideal Rings</dc:title>
 <dc:creator>Bandi, Ramakrishna</dc:creator>
 <dc:creator>Tabue, Alexandre Fotue</dc:creator>
 <dc:creator>Mart&#xed;nez-Moro, Edgar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Let $R$ be a finite principal ideal ring and $S$ the Galois extension of $R$
of degree $m$. For $k$ and $k_0$, positive integers we determine the number of
free $S$-linear codes $B$ of length $l$ with the property $k = rank_S(B)$ and
$k_0 = rank_R (B\cap R^l)$. This corrects a wrong result which was given in the
case of finite fields.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02218</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedded Line Scan Image Sensors: The Low Cost Alternative for High
  Speed Imaging</dc:title>
 <dc:creator>Van Wolputte, Stef</dc:creator>
 <dc:creator>Abbeloos, Wim</dc:creator>
 <dc:creator>Helsen, Stijn</dc:creator>
 <dc:creator>Bey-Temsamani, Abdellatif</dc:creator>
 <dc:creator>Goedem&#xe9;, Toon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we propose a low-cost high-speed imaging line scan system. We
replace an expensive industrial line scan camera and illumination with a
custom-built set-up of cheap off-the-shelf components, yielding a measurement
system with comparative quality while costing about 20 times less. We use a
low-cost linear (1D) image sensor, cheap optics including a LED-based or
LASER-based lighting and an embedded platform to process the images. A
step-by-step method to design such a custom high speed imaging system and
select proper components is proposed. Simulations allowing to predict the final
image quality to be obtained by the set-up has been developed. Finally, we
applied our method in a lab, closely representing the real-life cases. Our
results shows that our simulations are very accurate and that our low-cost line
scan set-up acquired image quality compared to the high-end commercial vision
system, for a fraction of the price.
</dc:description>
 <dc:description>Comment: 2015 International Conference on Image Processing Theory, Tools and
  Applications (IPTA)</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02218</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on Image Processing
  Theory, Tools and Applications (2015) 543-549</dc:identifier>
 <dc:identifier>doi:10.1109/IPTA.2015.7367207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02219</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Process Monitoring of Extrusion Based 3D Printing via Laser Scanning</dc:title>
 <dc:creator>Faes, Matthias</dc:creator>
 <dc:creator>Abbeloos, Wim</dc:creator>
 <dc:creator>Vogeler, Frederik</dc:creator>
 <dc:creator>Valkenaers, Hans</dc:creator>
 <dc:creator>Coppens, Kurt</dc:creator>
 <dc:creator>Goedem&#xe9;, Toon</dc:creator>
 <dc:creator>Ferraris, Eleonora</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Extrusion based 3D Printing (E3DP) is an Additive Manufacturing (AM)
technique that extrudes thermoplastic polymer in order to build up components
using a layerwise approach. Hereby, AM typically requires long production times
in comparison to mass production processes such as Injection Molding. Failures
during the AM process are often only noticed after build completion and
frequently lead to part rejection because of dimensional inaccuracy or lack of
mechanical performance, resulting in an important loss of time and material. A
solution to improve the accuracy and robustness of a manufacturing technology
is the integration of sensors to monitor and control process state-variables
online. In this way, errors can be rapidly detected and possibly compensated at
an early stage. To achieve this, we integrated a modular 2D laser triangulation
scanner into an E3DP machine and analyzed feedback signals. A 2D laser
triangulation scanner was selected here owing to the very compact size,
achievable accuracy and the possibility of capturing geometrical 3D data. Thus,
our implemented system is able to provide both quantitative and qualitative
information. Also, in this work, first steps towards the development of a
quality control loop for E3DP processes are presented and opportunities are
discussed.
</dc:description>
 <dc:description>Comment: International Conference on Polymers and Moulds Innovations(PMI) 2014</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02219</dc:identifier>
 <dc:identifier>Conference Proceedings PMI 6 (2014) 363-367</dc:identifier>
 <dc:identifier>doi:10.13140/2.1.5175.0081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02222</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Communication-Efficient Parallel Method for Group-Lasso</dc:title>
 <dc:creator>Chen, Binghong</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Group-Lasso (gLasso) identifies important explanatory factors in predicting
the response variable by considering the grouping structure over input
variables. However, most existing algorithms for gLasso are not scalable to
deal with large-scale datasets, which are becoming a norm in many applications.
In this paper, we present a divide-and-conquer based parallel algorithm
(DC-gLasso) to scale up gLasso in the tasks of regression with grouping
structures. DC-gLasso only needs two iterations to collect and aggregate the
local estimates on subsets of the data, and is provably correct to recover the
true model under certain conditions. We further extend it to deal with
overlappings between groups. Empirical results on a wide range of synthetic and
real-world datasets show that DC-gLasso can significantly improve the time
efficiency without sacrificing regression accuracy.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02223</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring the potential of combining time of flight and thermal infrared
  cameras for person detection</dc:title>
 <dc:creator>Abbeloos, Wim</dc:creator>
 <dc:creator>Goedem&#xe9;, Toon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Combining new, low-cost thermal infrared and time-of-flight range sensors
provides new opportunities. In this position paper we explore the possibilities
of combining these sensors and using their fused data for person detection. The
proposed calibration approach for this sensor combination differs from the
traditional stereo camera calibration in two fundamental ways. A first
distinction is that the spectral sensitivity of the two sensors differs
significantly. In fact, there is no sensitivity range overlap at all. A second
distinction is that their resolution is typically very low, which requires
special attention. We assume a situation in which the sensors' relative
position is known, but their orientation is unknown. In addition, some of the
typical measurement errors are discussed, and methods to compensate for them
are proposed. We discuss how the fused data could allow increased accuracy and
robustness without the need for complex algorithms requiring large amounts of
computational power and training data.
</dc:description>
 <dc:description>Comment: Proceedings of the 10th International Conference on Informatics in
  Control, Automation and Robotics</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02223</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on Informatics in
  Control, Automation and Robotics (2013) 464-470</dc:identifier>
 <dc:identifier>doi:10.5220/0004595704640470</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02233</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A simple and efficient SNN and its performance &amp; robustness evaluation
  method to enable hardware implementation</dc:title>
 <dc:creator>Biswas, Anmol</dc:creator>
 <dc:creator>Prasad, Sidharth</dc:creator>
 <dc:creator>Lashkare, Sandip</dc:creator>
 <dc:creator>Ganguly, Udayan</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Spiking Neural Networks (SNN) are more closely related to brain-like
computation and inspire hardware implementation. This is enabled by small
networks that give high performance on standard classification problems. In
literature, typical SNNs are deep and complex in terms of network structure,
weight update rules and learning algorithms. This makes it difficult to
translate them into hardware. In this paper, we first develop a simple
2-layered network in software which compares with the state of the art on four
different standard data-sets within SNNs and has improved efficiency. For
example, it uses lower number of neurons (3 x), synapses (3.5 x) and epochs for
training (30 x) for the Fisher Iris classification problem. The efficient
network is based on effective population coding and synapse-neuron co-design.
Second, we develop a computationally efficient (15000 x) and accurate
(correlation of 0.98) method to evaluate the performance of the network without
standard recognition tests. Third, we show that the method produces a
robustness metric that can be used to evaluate noise tolerance.
</dc:description>
 <dc:description>Comment: 9 page conference paper submitted at IJCNN 2017</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02251</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When is multitask learning effective? Semantic sequence prediction under
  varying data conditions</dc:title>
 <dc:creator>Alonso, H&#xe9;ctor Mart&#xed;nez</dc:creator>
 <dc:creator>Plank, Barbara</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Multitask learning has been applied successfully to a range of tasks, mostly
morphosyntactic. However, little is known on when MTL works and whether there
are data characteristics that help to determine its success. In this paper we
evaluate a range of semantic sequence labeling tasks in a MTL setup. We examine
different auxiliary tasks, amongst which a novel setup, and correlate their
impact to data-dependent conditions. Our results show that MTL is not always
effective, significant improvements are obtained only for 1 out of 5 tasks.
When successful, auxiliary tasks with compact and more uniform label
distributions are preferable.
</dc:description>
 <dc:description>Comment: In EACL 2017</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02255</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Representation in Graphs using Convolutional Neural Networks</dc:title>
 <dc:creator>Vieira, Armando</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Knowledge Graphs (KG) constitute a flexible representation of complex
relationships between entities particularly useful for biomedical data. These
KG, however, are very sparse with many missing edges (facts) and the
visualisation of the mesh of interactions nontrivial. Here we apply a
compositional model to embed nodes and relationships into a vectorised semantic
space to perform graph completion. A visualisation tool based on Convolutional
Neural Networks and Self-Organised Maps (SOM) is proposed to extract high-level
insights from the KG. We apply this technique to a subset of CTD, containing
interactions of compounds with human genes / proteins and show that the
performance is comparable to the one obtained by structural models.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02261</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Geometric Representation Through Local Shape Probing</dc:title>
 <dc:creator>Digne, Julie</dc:creator>
 <dc:creator>Valette, S&#xe9;bastien</dc:creator>
 <dc:creator>Chaine, Rapha&#xeb;lle</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>68U05, 97R60</dc:subject>
 <dc:description>  We propose a new shape analysis approach based on the non-local analysis of
local shape variations. Our method relies on a novel description of shape
variations, called Local Probing Field (LPF), which describes how a local
probing operator transforms a pattern onto the shape. By carefully optimizing
the position and orientation of each descriptor, we are able to capture shape
similarities and gather them into a geometrically relevant dictionary over
which the shape decomposes sparsely. This new representation permits to handle
shapes with mixed intrinsic dimensionality (e.g. shapes containing both
surfaces and curves) and to encode various shape features such as boundaries.
Our shape representation has several potential applications; here we
demonstrate its efficiency for shape resampling and point set denoising for
both synthetic and real data.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02261</dc:identifier>
 <dc:identifier>IEEE Transactions on Visualization and Computer Graphics, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TVCG.2017.2719024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02275</identifier>
 <datestamp>2017-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer Algebra and Material Design</dc:title>
 <dc:creator>Kikuchi, Akihito</dc:creator>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:description>  This article is intended to an introductory lecture in material physics, in
which the modern computational group theory and the electronic structure
calculation are in collaboration. The effort of mathematicians in field of the
group theory, have ripened as a new trend, called &quot;computer algebra&quot;, outcomes
of which now can be available as handy computational packages, and would also
be useful to physicists with practical purposes. This article, in the former
part, explains how to use the computer algebra for the applications in the
solid-state simulation, by means of one of the computer algebra package, the
GAP system. The computer algebra enables us to obtain various group theoretical
properties with ease, such as the representations, the character tables, the
subgroups, etc. Furthermore it would grant us a new perspective of material
design, which could be executed in mathematically rigorous and systematic way.
Some technical details and some computations which require the knowledge of a
little higher mathematics (but computable easily by the computer algebra) are
also given. The selected topics will provide the reader with some insights
toward the dominating role of the symmetry in crystal, or, the &quot;mathematical
first principles&quot; in it. In the latter part of the article, we analyze the
relation between the structural symmetry and the electronic structure in
C$_{60}$ (as an example to the sysmem without periodicity). The principal
object of the study is to illustrate the hierarchical change of the
quantum-physical properties of the molecule, in accordance with the reduction
of the symmetry (as it descends down in the ladder of subgroups). In order to
serve the common interest of the researchers, the details of the computations
(the required initial data and the small programs developed for the purpose)
are explained as minutely as possible.
</dc:description>
 <dc:description>Comment: Third version: supplemental materials (some small programs and some
  data used in the articles,written in the GAP language) are added. The typos
  errors in the first and the second version (in the generators of the
  icosahedral group) are fixed. (In fact these generators of this group can be
  generated by the small programs in the supplemental materials.)</dc:description>
 <dc:date>2016-12-06</dc:date>
 <dc:date>2017-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02284</identifier>
 <datestamp>2017-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LogLog-Beta and More: A New Algorithm for Cardinality Estimation Based
  on LogLog Counting</dc:title>
 <dc:creator>Qin, Jason</dc:creator>
 <dc:creator>Kim, Denys</dc:creator>
 <dc:creator>Tung, Yumei</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W10, 68W15, 68W25, 62-07</dc:subject>
 <dc:subject>B.2.4</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  The information presented in this paper defines LogLog-Beta. LogLog-Beta is a
new algorithm for estimating cardinalities based on LogLog counting. The new
algorithm uses only one formula and needs no additional bias corrections for
the entire range of cardinalities, therefore, it is more efficient and simpler
to implement. Our simulations show that the accuracy provided by the new
algorithm is as good as or better than the accuracy provided by either of
HyperLogLog or HyperLogLog++. In addition to LogLog-Beta we also provide
another one-formula estimator for cardinalities based on order statistics, a
modification of an algorithm developed by Lumbroso.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2016-12-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02287</identifier>
 <datestamp>2017-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Hypothesis Generation for 6D Object Pose Estimation</dc:title>
 <dc:creator>Michel, Frank</dc:creator>
 <dc:creator>Kirillov, Alexander</dc:creator>
 <dc:creator>Brachmann, Eric</dc:creator>
 <dc:creator>Krull, Alexander</dc:creator>
 <dc:creator>Gumhold, Stefan</dc:creator>
 <dc:creator>Savchynskyy, Bogdan</dc:creator>
 <dc:creator>Rother, Carsten</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the task of estimating the 6D pose of a known 3D object
from a single RGB-D image. Most modern approaches solve this task in three
steps: i) Compute local features; ii) Generate a pool of pose-hypotheses; iii)
Select and refine a pose from the pool. This work focuses on the second step.
While all existing approaches generate the hypotheses pool via local reasoning,
e.g. RANSAC or Hough-voting, we are the first to show that global reasoning is
beneficial at this stage. In particular, we formulate a novel fully-connected
Conditional Random Field (CRF) that outputs a very small number of
pose-hypotheses. Despite the potential functions of the CRF being non-Gaussian,
we give a new and efficient two-step optimization procedure, with some
guarantees for optimality. We utilize our global hypotheses generation
procedure to produce results that exceed state-of-the-art for the challenging
&quot;Occluded Object Dataset&quot;.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02295</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Margin Softmax Loss for Convolutional Neural Networks</dc:title>
 <dc:creator>Liu, Weiyang</dc:creator>
 <dc:creator>Wen, Yandong</dc:creator>
 <dc:creator>Yu, Zhiding</dc:creator>
 <dc:creator>Yang, Meng</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Cross-entropy loss together with softmax is arguably one of the most common
used supervision components in convolutional neural networks (CNNs). Despite
its simplicity, popularity and excellent performance, the component does not
explicitly encourage discriminative learning of features. In this paper, we
propose a generalized large-margin softmax (L-Softmax) loss which explicitly
encourages intra-class compactness and inter-class separability between learned
features. Moreover, L-Softmax not only can adjust the desired margin but also
can avoid overfitting. We also show that the L-Softmax loss can be optimized by
typical stochastic gradient descent. Extensive experiments on four benchmark
datasets demonstrate that the deeply-learned features with L-softmax loss
become more discriminative, hence significantly boosting the performance on a
variety of visual classification and verification tasks.
</dc:description>
 <dc:description>Comment: Published in ICML 2016 (with typo fixed)</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02297</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatially Adaptive Computation Time for Residual Networks</dc:title>
 <dc:creator>Figurnov, Michael</dc:creator>
 <dc:creator>Collins, Maxwell D.</dc:creator>
 <dc:creator>Zhu, Yukun</dc:creator>
 <dc:creator>Zhang, Li</dc:creator>
 <dc:creator>Huang, Jonathan</dc:creator>
 <dc:creator>Vetrov, Dmitry</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper proposes a deep learning architecture based on Residual Network
that dynamically adjusts the number of executed layers for the regions of the
image. This architecture is end-to-end trainable, deterministic and
problem-agnostic. It is therefore applicable without any modifications to a
wide range of computer vision problems such as image classification, object
detection and image segmentation. We present experimental results showing that
this model improves the computational efficiency of Residual Networks on the
challenging ImageNet classification and COCO object detection datasets.
Additionally, we evaluate the computation time maps on the visual saliency
dataset cat2000 and find that they correlate surprisingly well with human eye
fixation positions.
</dc:description>
 <dc:description>Comment: CVPR 2017</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02298</identifier>
 <datestamp>2017-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Individual Differential Privacy: A Utility-Preserving Formulation of
  Differential Privacy Guarantees</dc:title>
 <dc:creator>Soria-Comas, Jordi</dc:creator>
 <dc:creator>Domingo-Ferrer, Josep</dc:creator>
 <dc:creator>S&#xe1;nchez, David</dc:creator>
 <dc:creator>Meg&#xed;as, David</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Differential privacy is a popular privacy model within the research community
because of the strong privacy guarantee it offers, namely that the presence or
absence of any individual in a data set does not significantly influence the
results of analyses on the data set. However, enforcing this strict guarantee
in practice significantly distorts data and/or limits data uses, thus
diminishing the analytical utility of the differentially private results. In an
attempt to address this shortcoming, several relaxations of differential
privacy have been proposed that trade off privacy guarantees for improved data
utility. In this work, we argue that the standard formalization of differential
privacy is stricter than required by the intuitive privacy guarantee it seeks.
In particular, the standard formalization requires indistinguishability of
results between any pair of neighbor data sets, while indistinguishability
between the actual data set and its neighbor data sets should be enough. This
limits the data controller's ability to adjust the level of protection to the
actual data, hence resulting in significant accuracy loss. In this respect, we
propose individual differential privacy, an alternative differential privacy
notion that offers em the same privacy guarantees as standard differential
privacy to individuals (even though not to groups of individuals). This new
notion allows the data controller to adjust the distortion to the actual data
set, which results in less distortion and more analytical accuracy. We propose
several mechanisms to attain individual differential privacy and we compare the
new notion against standard differential privacy in terms of the accuracy of
the analytical results.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02298</dc:identifier>
 <dc:identifier>doi:10.1109/TIFS.2017.2663337</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02307</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Over-the-air Function Computation in Sensor Networks</dc:title>
 <dc:creator>Abari, Omid</dc:creator>
 <dc:creator>Rahul, Hariharan</dc:creator>
 <dc:creator>Katabi, Dina</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Many sensor applications are interested in computing a function over
measurements (e.g., sum, average, max) as opposed to collecting all sensor
data. Today, such data aggregation is done in a cluster-head. Sensor nodes
transmit their values sequentially to a cluster-head node, which calculates the
aggregation function and forwards it to the base station. In contrast, this
paper explores the possibility of computing a desired function over the air. We
devise a solution that enables sensors to transmit coherently over the wireless
medium so that the cluster-head directly receives the value of the desired
function. We present analysis and preliminary results that demonstrate that
such a design yield a large improvement in network throughput.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02310</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extend natural neighbor: a novel classification method with
  self-adaptive neighborhood parameters in different stages</dc:title>
 <dc:creator>Feng, Ji</dc:creator>
 <dc:creator>Zhu, Qingsheng</dc:creator>
 <dc:creator>Huang, Jinlong</dc:creator>
 <dc:creator>Yang, Lijun</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Various kinds of k-nearest neighbor (KNN) based classification methods are
the bases of many well-established and high-performance pattern-recognition
techniques, but both of them are vulnerable to their parameter choice.
Essentially, the challenge is to detect the neighborhood of various data sets,
while utterly ignorant of the data characteristic. This article introduces a
new supervised classification method: the extend natural neighbor (ENaN)
method, and shows that it provides a better classification result without
choosing the neighborhood parameter artificially. Unlike the original KNN based
method which needs a prior k, the ENaNE method predicts different k in
different stages. Therefore, the ENaNE method is able to learn more from
flexible neighbor information both in training stage and testing stage, and
provide a better classification result.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures, 2 tables</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02314</identifier>
 <datestamp>2017-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Productive, Anxious, Lonely - 24 Hours Without Push Notifications</dc:title>
 <dc:creator>Pielot, Martin</dc:creator>
 <dc:creator>Rello, Luz</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.m</dc:subject>
 <dc:description>  We report from the Do Not Disturb Challenge where 30 volunteers disabled
notification alerts for 24 hours across all devices. The effect of the absence
of notifications on the participants was isolated through an experimental study
design: we compared self-reported feedback from the day without notifications
against a baseline day. The evidence indicates that notifications have locked
us in a dilemma: without notifications, participants felt less distracted and
more productive. But, they also felt no longer able to be as responsive as
expected, which made some participants anxious. And, they felt less connected
with one's social group. In contrast to previous reports, about two third of
the participants expressed the intention to change how they manage
notifications. Two years later, half of the participants are still following
through with their plans.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02314</dc:identifier>
 <dc:identifier>doi:10.1145/3098279.3098526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02320</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Energy Efficiency Perspective on Massive MIMO Quantization</dc:title>
 <dc:creator>Sarajli&#x107;, Muris</dc:creator>
 <dc:creator>Liu, Liang</dc:creator>
 <dc:creator>Edfors, Ove</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  One of the basic aspects of Massive MIMO (MaMi) that is in the focus of
current investigations is its potential of using low-cost and energy-efficient
hardware. It is often claimed that MaMi will allow for using analog-to-digital
converters (ADCs) with very low resolutions and that this will result in
overall improvement of energy efficiency. In this contribution, we perform a
parametric energy efficiency analysis of MaMi uplink for the entire base
station receiver system with varying ADC resolutions. The analysis shows that,
for a wide variety of system parameters, ADCs with intermediate bit resolutions
(4 - 10 bits) are optimal in energy efficiency sense, and that using very low
bit resolutions results in degradation of energy efficiency.
</dc:description>
 <dc:description>Comment: To be published in Proceedings of 50th Asilomar Conference on
  Signals, Systems and Computers</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02327</identifier>
 <datestamp>2017-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Coverage Maximization via Sketching</dc:title>
 <dc:creator>Bateni, MohammadHossein</dc:creator>
 <dc:creator>Esfandiari, Hossein</dc:creator>
 <dc:creator>Mirrokni, Vahab</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Coverage problems are central in optimization and have a wide range of
applications in data mining and machine learning. While several distributed
algorithms have been developed for coverage problems, the existing methods
suffer from several limitations, e.g., they all achieve either suboptimal
approximation guarantees or suboptimal space and memory complexities. In
addition, previous algorithms developed for submodular maximization assume
oracle access, and ignore the computational complexity of communicating large
subsets or computing the size of the union of the subsets in this subfamily. In
this paper, we develop an improved distributed algorithm for the $k$-cover and
the set cover with $\lambda$ outliers problems, with almost optimal
approximation guarantees, almost optimal memory complexity, and linear
communication complexity running in only four rounds of computation. Finally,
we perform an extensive empirical study of our algorithms on a number of
publicly available real data sets, and show that using sketches of size $30$ to
$600$ times smaller than the input, one can solve the coverage maximization
problem with quality very close to that of the state-of-the-art single-machine
algorithm.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02334</identifier>
 <datestamp>2016-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Low-Complexity Randomized Methods for Locating Outliers in Large
  Matrices</dc:title>
 <dc:creator>Li, Xingguo</dc:creator>
 <dc:creator>Haupt, Jarvis</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper examines the problem of locating outlier columns in a large,
otherwise low-rank matrix, in settings where {}{the data} are noisy, or where
the overall matrix has missing elements. We propose a randomized two-step
inference framework, and establish sufficient conditions on the required sample
complexities under which these methods succeed (with high probability) in
accurately locating the outliers for each task. Comprehensive numerical
experimental results are provided to verify the theoretical bounds and
demonstrate the computational efficiency of the proposed algorithm.
</dc:description>
 <dc:description>Comment: 16 pages, 4 figures</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02335</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pano2Vid: Automatic Cinematography for Watching 360$^{\circ}$ Videos</dc:title>
 <dc:creator>Su, Yu-Chuan</dc:creator>
 <dc:creator>Jayaraman, Dinesh</dc:creator>
 <dc:creator>Grauman, Kristen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce the novel task of Pano2Vid $-$ automatic cinematography in
panoramic 360$^{\circ}$ videos. Given a 360$^{\circ}$ video, the goal is to
direct an imaginary camera to virtually capture natural-looking normal
field-of-view (NFOV) video. By selecting &quot;where to look&quot; within the panorama at
each time step, Pano2Vid aims to free both the videographer and the end viewer
from the task of determining what to watch. Towards this goal, we first compile
a dataset of 360$^{\circ}$ videos downloaded from the web, together with
human-edited NFOV camera trajectories to facilitate evaluation. Next, we
propose AutoCam, a data-driven approach to solve the Pano2Vid task. AutoCam
leverages NFOV web video to discriminatively identify space-time &quot;glimpses&quot; of
interest at each time instant, and then uses dynamic programming to select
optimal human-like camera trajectories. Through experimental evaluation on
multiple newly defined Pano2Vid performance measures against several baselines,
we show that our method successfully produces informative videos that could
conceivably have been captured by human videographers.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02336</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Turing Machines: Convergence of Copy Tasks</dc:title>
 <dc:creator>Ale&#x161;, Janez</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The architecture of neural Turing machines is differentiable end to end and
is trainable with gradient descent methods. Due to their large unfolded depth
Neural Turing Machines are hard to train and because of their linear access of
complete memory they do not scale. Other architectures have been studied to
overcome these difficulties. In this report we focus on improving the quality
of prediction of the original linear memory architecture on copy and repeat
copy tasks. Copy task predictions on sequences of length six times larger than
those the neural Turing machine was trained on prove to be highly accurate and
so do predictions of repeat copy tasks for sequences with twice the repetition
number and twice the sequence length neural Turing machine was trained on.
</dc:description>
 <dc:description>Comment: Predictor weights can be provided upon request</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02344</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formation of coalition structures as a non-cooperative game 1: theory</dc:title>
 <dc:creator>Levando, Dmitry V.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The paper defines a non-cooperative simultaneous finite game to study
coalition structure formation with intra and inter-coalition externalities. The
novelty of the game is that the game definition embeds a \textit{coalition
structure formation mechanism}. This mechanism portions a set of strategies of
the game into partition-specific strategy domains, what makes every partition
to be a non-cooperative game with partition-specific payoffs for every player.
The mechanism includes a maximum coalition size, a set of eligible partitions
with coalitions sizes no greater than this number (which also serves as a
restriction for a maximum number of deviators) and a coalition structure
formation rule. The paper defines a family of nested non-cooperative games
parametrized by a size of a maximum coalition size. Every game in the family
has an equilibrium in mixed strategies. The equilibrium can generate more than
one coalition and encompasses intra and inter group externalities, what makes
it different from the Shapley value. Presence of individual payoff allocation
makes it different from a strong Nash, coalition-proof equilibrium, and some
other equilibrium concepts. The accompanying papers demonstrate applications of
the proposed toolkit.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02346</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quotient inductive-inductive types</dc:title>
 <dc:creator>Altenkirch, Thorsten</dc:creator>
 <dc:creator>Capriotti, Paolo</dc:creator>
 <dc:creator>Dijkstra, Gabe</dc:creator>
 <dc:creator>Kraus, Nicolai</dc:creator>
 <dc:creator>Forsberg, Fredrik Nordvall</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03B15 (Primary) 18C10 (Secondary)</dc:subject>
 <dc:description>  Higher inductive types (HITs) in Homotopy Type Theory (HoTT) allow the
definition of datatypes which have constructors for equalities over the defined
type. HITs generalise quotient types and allow to define types which are not
sets in the sense of HoTT (i.e. do not satisfy uniqueness of equality proofs)
such as spheres, suspensions and the torus. However, there are also interesting
uses of HITs to define sets, such as the Cauchy reals, the partiality monad,
and the internal, total syntax of type theory. In each of these examples we
define several types that depend on each other mutually, i.e. they are
inductive-inductive definitions. We call those HITs quotient
inductive-inductive types (QIITs).
  Although there has been recent progress on the general theory of HITs, there
isn't yet a theoretical foundation of the combination of equality constructors
and induction-induction, despite having many interesting applications. In the
present paper we present a first step towards a semantic definition of QIITs.
In particular, we give an initial-algebra semantics and show that this is
equivalent to the section induction principle, which justifies the intuitively
expected elimination rules.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02350</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Information-theoretic Approach to Machine-oriented Music
  Summarization</dc:title>
 <dc:creator>Raposo, Francisco</dc:creator>
 <dc:creator>de Matos, David Martins</dc:creator>
 <dc:creator>Ribeiro, Ricardo</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:description>  Applying generic media-agnostic summarization to music allows for higher
efficiency in automatic processing, storage, and sharing of datasets, while
also alleviating copyright issues. This process has already been proven useful
in the context of music genre classification. In this paper, we generalize
conclusions from previous work by evaluating the impact of generic
summarization of music from a probabilistic perspective and agnostic relative
to certain tasks. We estimate Gaussian distributions for original and
summarized songs and compute their relative entropy, in order to measure how
much information is lost in the summarization process. Our results suggest that
relative entropy is a good predictor of summarization performance and
therefore, a good measure of information loss, in the context of tasks relying
on a bag-of-features model. Motivated by this observation, we further propose a
simple yet expressive summarization method, based on building summaries that
minimize relative entropy with respect to the original song, that objectively
outperforms previous methods and is better suited to avoid copyright issues.
</dc:description>
 <dc:description>Comment: 10 pages, 1 algorithm, 3 figures, 8 tables, submitted to IEEE TASLP</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-09-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02353</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Certified RAT Verification</dc:title>
 <dc:creator>Cruz-Filipe, Lu&#xed;s</dc:creator>
 <dc:creator>Heule, Marijn</dc:creator>
 <dc:creator>Hunt, Warren</dc:creator>
 <dc:creator>Kaufmann, Matt</dc:creator>
 <dc:creator>Schneider-Kamp, Peter</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Clausal proofs have become a popular approach to validate the results of SAT
solvers. However, validating clausal proofs in the most widely supported format
(DRAT) is expensive even in highly optimized implementations. We present a new
format, called LRAT, which extends the DRAT format with hints that facilitate a
simple and fast validation algorithm. Checking validity of LRAT proofs can be
implemented using trusted systems such as the languages supported by theorem
provers. We demonstrate this by implementing two certified LRAT checkers, one
in Coq and one in ACL2.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02353</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-63046-5_14</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02372</identifier>
 <datestamp>2017-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differential Angular Imaging for Material Recognition</dc:title>
 <dc:creator>Xue, Jia</dc:creator>
 <dc:creator>Zhang, Hang</dc:creator>
 <dc:creator>Dana, Kristin</dc:creator>
 <dc:creator>Nishino, Ko</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Material recognition for real-world outdoor surfaces has become increasingly
important for computer vision to support its operation &quot;in the wild.&quot;
Computational surface modeling that underlies material recognition has
transitioned from reflectance modeling using in-lab controlled radiometric
measurements to image-based representations based on internet-mined images of
materials captured in the scene. We propose to take a middle-ground approach
for material recognition that takes advantage of both rich radiometric cues and
flexible image capture. We realize this by developing a framework for
differential angular imaging, where small angular variations in image capture
provide an enhanced appearance representation and significant recognition
improvement. We build a large-scale material database, Ground Terrain in
Outdoor Scenes (GTOS) database, geared towards real use for autonomous agents.
The database consists of over 30,000 images covering 40 classes of outdoor
ground terrain under varying weather and lighting conditions. We develop a
novel approach for material recognition called a Differential Angular Imaging
Network (DAIN) to fully leverage this large dataset. With this novel network
architecture, we extract characteristics of materials encoded in the angular
and spatial gradients of their appearance. Our results show that DAIN achieves
recognition performance that surpasses single view or coarsely quantized
multiview images. These results demonstrate the effectiveness of differential
angular imaging as a means for flexible, in-place material recognition.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02374</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Detection of ADHD and ASD from Expressive Behaviour in RGBD
  Data</dc:title>
 <dc:creator>Jaiswal, Shashank</dc:creator>
 <dc:creator>Valstar, Michel</dc:creator>
 <dc:creator>Gillott, Alinda</dc:creator>
 <dc:creator>Daley, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Attention Deficit Hyperactivity Disorder (ADHD) and Autism Spectrum Disorder
(ASD) are neurodevelopmental conditions which impact on a significant number of
children and adults. Currently, the diagnosis of such disorders is done by
experts who employ standard questionnaires and look for certain behavioural
markers through manual observation. Such methods for their diagnosis are not
only subjective, difficult to repeat, and costly but also extremely time
consuming. In this work, we present a novel methodology to aid diagnostic
predictions about the presence/absence of ADHD and ASD by automatic visual
analysis of a person's behaviour. To do so, we conduct the questionnaires in a
computer-mediated way while recording participants with modern RGBD
(Colour+Depth) sensors. In contrast to previous automatic approaches which have
focussed only detecting certain behavioural markers, our approach provides a
fully automatic end-to-end system for directly predicting ADHD and ASD in
adults. Using state of the art facial expression analysis based on Dynamic Deep
Learning and 3D analysis of behaviour, we attain classification rates of 96%
for Controls vs Condition (ADHD/ASD) group and 94% for Comorbid (ADHD+ASD) vs
ASD only group. We show that our system is a potentially useful time saving
contribution to the diagnostic field of ADHD and ASD.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02375</identifier>
 <datestamp>2017-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distribution of Cell Size in Bounded Poisson Voronoi Tesselations with
  Application to Secure Local Connectivity</dc:title>
 <dc:creator>Koufos, Konstantinos</dc:creator>
 <dc:creator>Dettmann, Carl P.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider the Voronoi tessellation induced by a homogeneous and stationary
Poisson point process of unit intensity in a quadrant, where the two half-axes
represent boundaries. We show that the mean cell size is less than unity when
the seed is located exactly at the boundary, and it can be larger than unity
when the seed lies close to the boundary. In addition, we calculate the second
moment of the cell size at two locations: (i) at the corner of a quadrant, and
(ii) at the boundary of the half-plane. In both cases, we illustrate that the
two-parameter Gamma distribution, with location-dependent parameters, provides
a good fit. As a potential application, we use the Gamma approximations to
study the degree distribution for secure in-connectivity in wireless sensor
networks deployed over a bounded domain.
</dc:description>
 <dc:description>Comment: 20 pages, 10 figures</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02377</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Method for Group Extraction and Analysis in Multilayer Social Networks</dc:title>
 <dc:creator>Br&#xf3;dka, Piotr</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The main subject studied in this dissertation is a multi-layered social
network (MSN) and its analysis. One of the crucial problems in multi-layered
social network analysis is community extraction. To cope with this problem the
CLECC measure (Cross Layered Edge Clustering Coefficient) was proposed in the
thesis. It is an edge measure which expresses how much the neighbors of two
given users are similar each other. Based on this measure the CLECC algorithm
for community extraction in the multi-layered social networks was designed. The
algorithm was tested on the real single-layered social networks (SSN) and
multi-layered social networks (MSN), as well as on benchmark networks from GN
Benchmark (SSN), LFR Benchmark (SSN) and mLFR Benchmark (MSN) a special
extension of LFR Benchmark, designed as a part of this thesis, which is able to
produce multi-layered benchmark networks. The second research problem
considered in the thesis was group evolution discovery. Studies on this problem
have led to the development of the inclusion measure and the Group Evolution
Discovery (GED) method, which is designed to identify events between two groups
in successive time frames in the social network. The method was tested on a
real social network and compared with two well-known algorithms regarding
accuracy, execution time, flexibility and ease of implementation. Finally, a
new approach to prediction of group evolution in the social network was
developed. The new approach involves usage of the outputs of the GED method. It
is shown, that using even a simple sequence, which consists of several
preceding groups sizes and events, as an input for the classifier, the learned
model can produce very good results also for simple classifiers.
</dc:description>
 <dc:description>Comment: My PhD Thesis defended in October 2012. Please cite as Br\'odka P. A
  Method for Group Extraction and Analysis in Multilayer Social Networks, PhD
  dissertation 2012</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02384</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subquadratic Algorithms for Algebraic Generalizations of 3SUM</dc:title>
 <dc:creator>Barba, Luis</dc:creator>
 <dc:creator>Cardinal, Jean</dc:creator>
 <dc:creator>Iacono, John</dc:creator>
 <dc:creator>Langerman, Stefan</dc:creator>
 <dc:creator>Ooms, Aur&#xe9;lien</dc:creator>
 <dc:creator>Solomon, Noam</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  The 3SUM problem asks if an input $n$-set of real numbers contains a triple
whose sum is zero. We consider the 3POL problem, a natural generalization of
3SUM where we replace the sum function by a constant-degree polynomial in three
variables. The motivations are threefold. Raz, Sharir, and de Zeeuw gave a
$O(n^{11/6})$ upper bound on the number of solutions of trivariate polynomial
equations when the solutions are taken from the cartesian product of three
$n$-sets of real numbers. We give algorithms for the corresponding problem of
counting such solutions. Gr\o nlund and Pettie recently designed subquadratic
algorithms for 3SUM. We generalize their results to 3POL. Finally, we shed
light on the General Position Testing (GPT) problem: &quot;Given $n$ points in the
plane, do three of them lie on a line?&quot;, a key problem in computational
geometry.
  We prove that there exist bounded-degree algebraic decision trees of depth
$O(n^{\frac{12}{7}+\varepsilon})$ that solve 3POL, and that 3POL can be solved
in $O(n^2 {(\log \log n)}^\frac{3}{2} / {(\log n)}^\frac{1}{2})$ time in the
real-RAM model. Among the possible applications of those results, we show how
to solve GPT in subquadratic time when the input points lie on $o({(\log
n)}^\frac{1}{6}/{(\log \log n)}^\frac{1}{2})$ constant-degree polynomial
curves. This constitutes a first step towards closing the major open question
of whether GPT can be solved in subquadratic time.
  To obtain these results, we generalize important tools --- such as batch
range searching and dominance reporting --- to a polynomial setting. We expect
these new tools to be useful in other applications.
</dc:description>
 <dc:description>Comment: Submitted to SoCG'17</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02401</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeMoN: Depth and Motion Network for Learning Monocular Stereo</dc:title>
 <dc:creator>Ummenhofer, Benjamin</dc:creator>
 <dc:creator>Zhou, Huizhong</dc:creator>
 <dc:creator>Uhrig, Jonas</dc:creator>
 <dc:creator>Mayer, Nikolaus</dc:creator>
 <dc:creator>Ilg, Eddy</dc:creator>
 <dc:creator>Dosovitskiy, Alexey</dc:creator>
 <dc:creator>Brox, Thomas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we formulate structure from motion as a learning problem. We
train a convolutional network end-to-end to compute depth and camera motion
from successive, unconstrained image pairs. The architecture is composed of
multiple stacked encoder-decoder networks, the core part being an iterative
network that is able to improve its own predictions. The network estimates not
only depth and motion, but additionally surface normals, optical flow between
the images and confidence of the matching. A crucial component of the approach
is a training loss based on spatial relative differences. Compared to
traditional two-frame structure from motion methods, results are more accurate
and more robust. In contrast to the popular depth-from-single-image networks,
DeMoN learns the concept of matching and, thus, better generalizes to
structures not seen during training.
</dc:description>
 <dc:description>Comment: Camera ready version for CVPR 2017. Supplementary material included.
  Project page:
  http://lmb.informatik.uni-freiburg.de/people/ummenhof/depthmotionnet/</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02401</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2017.596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02412</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shortcuts for the Circle</dc:title>
 <dc:creator>Bae, Sang Won</dc:creator>
 <dc:creator>de Berg, Mark</dc:creator>
 <dc:creator>Cheong, Otfried</dc:creator>
 <dc:creator>Gudmundsson, Joachim</dc:creator>
 <dc:creator>Levcopoulos, Christos</dc:creator>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Let $C$ be the unit circle in $\mathbb{R}^2$. We can view $C$ as a plane
graph whose vertices are all the points on $C$, and the distance between any
two points on $C$ is the length of the smaller arc between them. We consider a
graph augmentation problem on $C$, where we want to place $k\geq 1$
\emph{shortcuts} on $C$ such that the diameter of the resulting graph is
minimized.
  We analyze for each $k$ with $1\leq k\leq 7$ what the optimal set of
shortcuts is. Interestingly, the minimum diameter one can obtain is not a
strictly decreasing function of~$k$. For example, with seven shortcuts one
cannot obtain a smaller diameter than with six shortcuts. Finally, we prove
that the optimal diameter is $2 + \Theta(1/k^{\frac{2}{3}})$ for any~$k$.
</dc:description>
 <dc:description>Comment: An extended abstract appeared in ISAAC 2017</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02462</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Normalisation by Evaluation for Type Theory, in Type Theory</dc:title>
 <dc:creator>Altenkirch, Thorsten</dc:creator>
 <dc:creator>Kaposi, Ambrus</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We develop normalisation by evaluation (NBE) for dependent types based on
presheaf categories. Our construction is formulated in the metalanguage of type
theory using quotient inductive types. We use a typed presentation hence there
are no preterms or realizers in our construction, and every construction
respects the conversion relation. NBE for simple types uses a logical relation
between the syntax and the presheaf interpretation. In our construction, we
merge the presheaf interpretation and the logical relation into a
proof-relevant logical predicate. We prove normalisation, completeness,
stability and decidability of definitional equality. Most of the constructions
were formalized in Agda.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-10-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02462</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 4 (October
  23, 2017) lmcs:4005</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-13(4:1)2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02463</identifier>
 <datestamp>2016-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Community detection by label propagation with compression of flow</dc:title>
 <dc:creator>Han, Jihui</dc:creator>
 <dc:creator>Li, Wei</dc:creator>
 <dc:creator>Su, Zhu</dc:creator>
 <dc:creator>Zhao, Longfeng</dc:creator>
 <dc:creator>Deng, Weibing</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  The label propagation algorithm (LPA) has been proved to be a fast and
effective method for detecting communities in large complex networks. However,
its performance is subject to the non-stable and trivial solutions of the
problem. In this paper, we propose a modified label propagation algorithm LPAf
to efficiently detect community structures in networks. Instead of the majority
voting rule of the basic LPA, LPAf updates the label of a node by considering
the compression of a description of random walks on a network. A multi-step
greedy agglomerative strategy is employed to enable LPAf to escape the local
optimum. Furthermore, an incomplete update condition is also adopted to speed
up the convergence. Experimental results on both synthetic and real-world
networks confirm the effectiveness of our algorithm.
</dc:description>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02463</dc:identifier>
 <dc:identifier>The European Physical Journal B, 89(12), 1-11 (2016)</dc:identifier>
 <dc:identifier>doi:10.1140/epjb/e2016-70264-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02466</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure and reliable connectivity in heterogeneous wireless sensor
  networks</dc:title>
 <dc:creator>Eletreby, Rashad</dc:creator>
 <dc:creator>Ya&#x11f;an, Osman</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We consider wireless sensor networks secured by the heterogeneous random key
predistribution scheme under an on/off channel model. The heterogeneous random
key predistribution scheme considers the case when the network includes sensor
nodes with varying levels of resources, features, or connectivity requirements;
e.g., regular nodes vs. cluster heads, but does not incorporate the fact that
wireless channel are unreliable. To capture the unreliability of the wireless
medium, we use an on/off channel model; wherein, each wireless channel is
either on (with probability $\alpha$) or off (with probability $1-\alpha$)
independently. We present conditions (in the form of zero-one laws) on how to
scale the parameters of the network model so that with high probability the
network is $k$-connected, i.e., the network remains connected even if any $k-1$
nodes fail or leave the network. We also present numerical results to support
these conditions in the finite-node regime.
</dc:description>
 <dc:description>Comment: Submitted to IEEE International Conference on Communications 2017
  (ICC 2017). substantial text overlap with arXiv:1611.02733, arXiv:1611.02675,
  arXiv:1610.07576</dc:description>
 <dc:date>2016-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02466</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02467</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiscale Computing in the Exascale Era</dc:title>
 <dc:creator>Alowayyed, Saad</dc:creator>
 <dc:creator>Groen, Derek</dc:creator>
 <dc:creator>Coveney, Peter V.</dc:creator>
 <dc:creator>Hoekstra, Alfons G.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We expect that multiscale simulations will be one of the main high
performance computing workloads in the exascale era. We propose multiscale
computing patterns as a generic vehicle to realise load balanced, fault
tolerant and energy aware high performance multiscale computing. Multiscale
computing patterns should lead to a separation of concerns, whereby application
developers can compose multiscale models and execute multiscale simulations,
while pattern software realises optimized, fault tolerant and energy aware
multiscale computing. We introduce three multiscale computing patterns, present
an example of the extreme scaling pattern, and discuss our vision of how this
may shape multiscale computing in the exascale era.
</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02468</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spontaneous Proximity Clouds: Making Mobile Devices to Collaborate for
  Resource and Data Sharing</dc:title>
 <dc:creator>Golchay, Roya</dc:creator>
 <dc:creator>Mou&#xeb;l, Fr&#xe9;d&#xe9;ric Le</dc:creator>
 <dc:creator>Ponge, Julien</dc:creator>
 <dc:creator>Stouls, Nicolas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The base motivation of Mobile Cloud Computing was empowering mobile devices
by application offloading onto powerful cloud resources. However, this goal
can't entirely be reached because of the high offloading cost imposed by the
long physical distance between the mobile device and the cloud. To address this
issue, we propose an application offloading onto a nearby mobile cloud composed
of the mobile devices in the vicinity-a Spontaneous Proximity Cloud. We
introduce our proposed dynamic, ant-inspired, bi-objective offloading
middleware-ACOMMA, and explain its extension to perform a close mobile
application offloading. With the learning-based offloading decision-making
process of ACOMMA, combined to the collaborative resource sharing, the mobile
devices can cooperate for decision cache sharing. We evaluate the performance
of ACOMMA in collaborative mode with real benchmarks Face Recognition and
Monte-Carlo algorithms-and achieve 50% execution time gain.
</dc:description>
 <dc:description>Comment: in Proceedings of the 12th EAI International Conference on
  Collaborative Computing: Networking, Applications and Worksharing
  (CollaborateCom'2016), Nov 2016, Beijing, China</dc:description>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02482</identifier>
 <datestamp>2017-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving the Performance of Neural Machine Translation Involving
  Morphologically Rich Languages</dc:title>
 <dc:creator>Hans, Krupakar</dc:creator>
 <dc:creator>Milton, R S</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The advent of the attention mechanism in neural machine translation models
has improved the performance of machine translation systems by enabling
selective lookup into the source sentence. In this paper, the efficiencies of
translation using bidirectional encoder attention decoder models were studied
with respect to translation involving morphologically rich languages. The
English - Tamil language pair was selected for this analysis. First, the use of
Word2Vec embedding for both the English and Tamil words improved the
translation results by 0.73 BLEU points over the baseline RNNSearch model with
4.84 BLEU score. The use of morphological segmentation before word
vectorization to split the morphologically rich Tamil words into their
respective morphemes before the translation, caused a reduction in the target
vocabulary size by a factor of 8. Also, this model (RNNMorph) improved the
performance of neural machine translation by 7.05 BLEU points over the
RNNSearch model used over the same corpus. Since the BLEU evaluation of the
RNNMorph model might be unreliable due to an increase in the number of matching
tokens per sentence, the performances of the translations were also compared by
means of human evaluation metrics of adequacy, fluency and relative ranking.
Further, the use of morphological segmentation also improved the efficacy of
the attention mechanism.
</dc:description>
 <dc:description>Comment: 21 pages, 11 figures, 2 tables, Corrected typos</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02483</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High Dimensional Consistent Digital Segments</dc:title>
 <dc:creator>Chiu, Man-Kwun</dc:creator>
 <dc:creator>Korman, Matias</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:subject>I.4.1</dc:subject>
 <dc:description>  We consider the problem of digitalizing Euclidean line segments from
$\mathbb{R}^d$ to $\mathbb{Z}^d$. Christ {\em et al.} (DCG, 2012) showed how to
construct a set of {\em consistent digital segment} (CDS) for $d=2$: a
collection of segments connecting any two points in $\mathbb{Z}^2$ that
satisfies the natural extension of the Euclidean axioms to $\mathbb{Z}^d$. In
this paper we study the construction of CDSs in higher dimensions.
  We show that any total order can be used to create a set of {\em consistent
digital rays} CDR in $\mathbb{Z}^d$ (a set of rays emanating from a fixed point
$p$ that satisfies the extension of the Euclidean axioms). We fully
characterize for which total orders the construction holds and study their
Hausdorff distance, which in particular positively answers the question posed
by Christ {\em et al.}.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02485</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparative Evaluation of Big-Data Systems on Scientific Image Analytics
  Workloads</dc:title>
 <dc:creator>Mehta, Parmita</dc:creator>
 <dc:creator>Dorkenwald, Sven</dc:creator>
 <dc:creator>Zhao, Dongfang</dc:creator>
 <dc:creator>Kaftan, Tomer</dc:creator>
 <dc:creator>Cheung, Alvin</dc:creator>
 <dc:creator>Balazinska, Magdalena</dc:creator>
 <dc:creator>Rokem, Ariel</dc:creator>
 <dc:creator>Connolly, Andrew</dc:creator>
 <dc:creator>Vanderplas, Jacob</dc:creator>
 <dc:creator>AlSayyad, Yusra</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Scientific discoveries are increasingly driven by analyzing large volumes of
image data. Many new libraries and specialized database management systems
(DBMSs) have emerged to support such tasks. It is unclear, however, how well
these systems support real-world image analysis use cases, and how performant
are the image analytics tasks implemented on top of such systems. In this
paper, we present the first comprehensive evaluation of large-scale image
analysis systems using two real-world scientific image data processing use
cases. We evaluate five representative systems (SciDB, Myria, Spark, Dask, and
TensorFlow) and find that each of them has shortcomings that complicate
implementation or hurt performance. Such shortcomings lead to new research
opportunities in making large-scale image analysis both efficient and easy to
use.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02486</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Universal Multi-Hierarchy Figure-of-Merit for On-Chip Computing and
  Communications</dc:title>
 <dc:creator>Sun, Shuai</dc:creator>
 <dc:creator>Narayana, Vikram K.</dc:creator>
 <dc:creator>Mehrabian, Armin</dc:creator>
 <dc:creator>El-Ghazawi, Tarek</dc:creator>
 <dc:creator>Sorger, Volker J.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Continuing demands for increased compute efficiency and communication
bandwidth have led to the development of novel interconnect technologies with
the potential to outperform conventional electrical interconnects. With a
plurality of interconnect technologies to include electronics, photonics,
plasmonics, and hybrids thereof, the simple approach of counting on-chip
devices to capture performance is insufficient. While some efforts have been
made to capture the performance evolution more accurately, they eventually
deviate from the observed development pace. Thus, a holistic figure of merit
(FOM) is needed to adequately compare these recent technology paradigms. Here
we introduce the Capability-to-Latency-Energy-Amount-Resistance (CLEAR) FOM
derived from device and link performance criteria of both active optoelectronic
devices and passive components alike. As such CLEAR incorporates communication
delay, energy efficiency, on-chip scaling and economic cost. We show that CLEAR
accurately describes compute development including most recent machines. Since
this FOM is derived bottom-up, we demonstrate remarkable adaptability to
applications ranging from device-level to network and system-level. Applying
CLEAR to benchmark device, link, and network performance against fundamental
physical compute and communication limits shows that photonics is competitive
even for fractions of the die-size, thus making a case for on-chip optical
interconnects.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02487</identifier>
 <datestamp>2017-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interactive Elicitation of Knowledge on Feature Relevance Improves
  Predictions in Small Data Sets</dc:title>
 <dc:creator>Micallef, Luana</dc:creator>
 <dc:creator>Sundin, Iiris</dc:creator>
 <dc:creator>Marttinen, Pekka</dc:creator>
 <dc:creator>Ammad-ud-din, Muhammad</dc:creator>
 <dc:creator>Peltola, Tomi</dc:creator>
 <dc:creator>Soare, Marta</dc:creator>
 <dc:creator>Jacucci, Giulio</dc:creator>
 <dc:creator>Kaski, Samuel</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Providing accurate predictions is challenging for machine learning algorithms
when the number of features is larger than the number of samples in the data.
Prior knowledge can improve machine learning models by indicating relevant
variables and parameter values. Yet, this prior knowledge is often tacit and
only available from domain experts. We present a novel approach that uses
interactive visualization to elicit the tacit prior knowledge and uses it to
improve the accuracy of prediction models. The main component of our approach
is a user model that models the domain expert's knowledge of the relevance of
different features for a prediction task. In particular, based on the expert's
earlier input, the user model guides the selection of the features on which to
elicit user's knowledge next. The results of a controlled user study show that
the user model significantly improves prior knowledge elicitation and
prediction accuracy, when predicting the relative citation counts of scientific
documents in a specific domain.
</dc:description>
 <dc:description>Comment: in Proceedings of the 22nd International Conference on Intelligent
  User Interfaces (IUI 2017)</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02490</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bridging Medical Data Inference to Achilles Tendon Rupture
  Rehabilitation</dc:title>
 <dc:creator>Qu, An</dc:creator>
 <dc:creator>Zhang, Cheng</dc:creator>
 <dc:creator>Ackermann, Paul</dc:creator>
 <dc:creator>Kjellstr&#xf6;m, Hedvig</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Imputing incomplete medical tests and predicting patient outcomes are crucial
for guiding the decision making for therapy, such as after an Achilles Tendon
Rupture (ATR). We formulate the problem of data imputation and prediction for
ATR relevant medical measurements into a recommender system framework. By
applying MatchBox, which is a collaborative filtering approach, on a real
dataset collected from 374 ATR patients, we aim at offering personalized
medical data imputation and prediction. In this work, we show the feasibility
of this approach and discuss potential research directions by conducting
initial qualitative evaluations.
</dc:description>
 <dc:description>Comment: Workshop on Machine Learning for Healthcare, NIPS 2016, Barcelona,
  Spain</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02493</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Research on the Multiple Feature Fusion Image Retrieval Algorithm based
  on Texture Feature and Rough Set Theory</dc:title>
 <dc:creator>Shi, Xiaojie</dc:creator>
 <dc:creator>Shao, Yijun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, we have witnessed the explosive growth of images with complex
information and content. In order to effectively and precisely retrieve desired
images from a large-scale image database with low time-consuming, we propose
the multiple feature fusion image retrieval algorithm based on the texture
feature and rough set theory in this paper. In contrast to the conventional
approaches that only use the single feature or standard, we fuse the different
features with operation of normalization. The rough set theory will assist us
to enhance the robustness of retrieval system when facing with incomplete data
warehouse. To enhance the texture extraction paradigm, we use the wavelet Gabor
function that holds better robustness. In addition, from the perspectives of
the internal and external normalization, we re-organize extracted feature with
the better combination. The numerical experiment has verified general
feasibility of our methodology. We enhance the overall accuracy compared with
the other state-of-the-art algorithms.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02493</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02495</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An initial investigation of the performance of GPU-based swept
  time-space decomposition</dc:title>
 <dc:creator>Magee, Daniel</dc:creator>
 <dc:creator>Niemeyer, Kyle E</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>65M55 (Primary), 35Q35 (Secondary)</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  Simulations of physical phenomena are essential to the expedient design of
precision components in aerospace and other high-tech industries. These
phenomena are often described by mathematical models involving partial
differential equations (PDEs) without exact solutions. Modern design problems
require simulations with a level of resolution that is difficult to achieve in
a reasonable amount of time even in effectively parallelized solvers. Though
the scale of the problem relative to available computing power is the greatest
impediment to accelerating these applications, significant performance gains
can be achieved through careful attention to the details of memory accesses.
Parallelized PDE solvers are subject to a trade-off in memory management: store
the solution for each timestep in abundant, global memory with high access
costs or in a limited, private memory with low access costs that must be passed
between nodes. The GPU implementation of swept time-space decomposition
presented here mitigates this dilemma by using private (shared) memory,
avoiding internode communication, and overwriting unnecessary values. It shows
significant improvement in the execution time of the PDE solvers in one
dimension achieving speedups of 6-2x for large and small problem sizes
respectively compared to naive GPU versions and 7-300x compared to parallel CPU
versions.
</dc:description>
 <dc:description>Comment: 14 pages; submitted to 2017 AIAA SciTech Forum</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02498</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrete Schroedinger Transform For Texture Recognition</dc:title>
 <dc:creator>Florindo, Jo&#xe3;o B.</dc:creator>
 <dc:creator>Bruno, Odemir M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  This work presents a new procedure to extract features of grey-level texture
images based on the discrete Schroedinger transform. This is a non-linear
transform where the image is mapped as the initial probability distribution of
a wave function and such distribution evolves in time following the
Schroedinger equation from Quantum Mechanics. The features are provided by
statistical moments of the distribution measured at different times. The
proposed method is applied to the classification of three databases of textures
used for benchmark and compared to other well-known texture descriptors in the
literature, such as textons, local binary patterns, multifractals, among
others. All of them are outperformed by the proposed method in terms of
percentage of images correctly classified. The proposal is also applied to the
identification of plant species using scanned images of leaves and again it
outperforms other texture methods. A test with images affected by Gaussian and
&quot;salt \&amp; pepper&quot; noise is also carried out, also with the best performance
achieved by the Schroedinger descriptors.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02503</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What do Shannon-type Inequalities, Submodular Width, and Disjunctive
  Datalog have to do with one another?</dc:title>
 <dc:creator>Khamis, Mahmoud Abo</dc:creator>
 <dc:creator>Ngo, Hung Q.</dc:creator>
 <dc:creator>Suciu, Dan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Recent works on bounding the output size of a conjunctive query with
functional dependencies and degree constraints have shown a deep connection
between fundamental questions in information theory and database theory. We
prove analogous output bounds for disjunctive datalog rules, and answer several
open questions regarding the tightness and looseness of these bounds along the
way. Our bounds are intimately related to Shannon-type information
inequalities. We devise the notion of a &quot;proof sequence&quot; of a specific class of
Shannon-type information inequalities called &quot;Shannon flow inequalities&quot;. We
then show how such a proof sequence can be interpreted as symbolic instructions
guiding an algorithm called &quot;PANDA&quot;, which answers disjunctive datalog rules
within the time that the size bound predicted. We show that PANDA can be used
as a black-box to devise algorithms matching precisely the fractional hypertree
width and the submodular width runtimes for aggregate and conjunctive queries
with functional dependencies and degree constraints.
  Our results improve upon known results in three ways. First, our bounds and
algorithms are for the much more general class of disjunctive datalog rules, of
which conjunctive queries are a special case. Second, the runtime of PANDA
matches precisely the submodular width bound, while the previous algorithm by
Marx has a runtime that is polynomial in this bound. Third, our bounds and
algorithms work for queries with input cardinality bounds, functional
dependencies, and degree constraints.
  Overall, our results show a deep connection between three seemingly unrelated
lines of research; and, our results on proof sequences for Shannon flow
inequalities might be of independent interest.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02509</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geodesics using Waves: Computing Distances using Wave Propagation</dc:title>
 <dc:creator>Sinha, Ayushi</dc:creator>
 <dc:creator>Kazhdan, Michael</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  In this paper, we present a new method for computing approximate geodesic
distances. We introduce the wave method for approximating geodesic distances
from a point on a manifold mesh. Our method involves the solution of two linear
systems of equations. One system of equations is solved repeatedly to propagate
the wave on the entire mesh, and one system is solved once after wave
propagation is complete in order to compute the approximate geodesic distances
up to an additive constant. However, these systems need to be pre-factored only
once, and can be solved efficiently at each iteration. All of our tests
required approximately between 300 and 400 iterations, which were completed in
a few seconds. Therefore, this method can approximate geodesic distances
quickly, and the approximation is highly accurate.
</dc:description>
 <dc:description>Comment: 10 pages, 14 figures</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02513</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complex Matrix Factorization for Face Recognition</dc:title>
 <dc:creator>Duong, Viet-Hang</dc:creator>
 <dc:creator>Lee, Yuan-Shan</dc:creator>
 <dc:creator>Pham, Bach-Tung</dc:creator>
 <dc:creator>Mathulaprangsan, Seksan</dc:creator>
 <dc:creator>Bao, Pham The</dc:creator>
 <dc:creator>Wang, Jia-Ching</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This work developed novel complex matrix factorization methods for face
recognition; the methods were complex matrix factorization (CMF), sparse
complex matrix factorization (SpaCMF), and graph complex matrix factorization
(GraCMF). After real-valued data are transformed into a complex field, the
complex-valued matrix will be decomposed into two matrices of bases and
coefficients, which are derived from solutions to an optimization problem in a
complex domain. The generated objective function is the real-valued function of
the reconstruction error, which produces a parametric description. Factorizing
the matrix of complex entries directly transformed the constrained optimization
problem into an unconstrained optimization problem. Additionally, a complex
vector space with N dimensions can be regarded as a 2N-dimensional real vector
space. Accordingly, all real analytic properties can be exploited in the
complex field. The ability to exploit these important characteristics motivated
the development herein of a simpler framework that can provide better
recognition results. The effectiveness of this framework will be clearly
elucidated in later sections in this paper.
</dc:description>
 <dc:description>Comment: 4 pages,3 figures,4 tables</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02516</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Primal-Dual Methods and Sample Complexity of Reinforcement
  Learning</dc:title>
 <dc:creator>Chen, Yichen</dc:creator>
 <dc:creator>Wang, Mengdi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We study the online estimation of the optimal policy of a Markov decision
process (MDP). We propose a class of Stochastic Primal-Dual (SPD) methods which
exploit the inherent minimax duality of Bellman equations. The SPD methods
update a few coordinates of the value and policy estimates as a new state
transition is observed. These methods use small storage and has low
computational complexity per iteration. The SPD methods find an
absolute-$\epsilon$-optimal policy, with high probability, using
$\mathcal{O}\left(\frac{|\mathcal{S}|^4 |\mathcal{A}|^2\sigma^2
}{(1-\gamma)^6\epsilon^2} \right)$ iterations/samples for the infinite-horizon
discounted-reward MDP and $\mathcal{O}\left(\frac{|\mathcal{S}|^4
|\mathcal{A}|^2H^6\sigma^2 }{\epsilon^2} \right)$ for the finite-horizon MDP.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02521</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Algorithm for the Piecewise-Smooth Model with Approximately
  Explicit Solutions</dc:title>
 <dc:creator>Song, Huihui</dc:creator>
 <dc:creator>Zheng, Yuhui</dc:creator>
 <dc:creator>Zhang, Kaihua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents an efficient approach to image segmentation that
approximates the piecewise-smooth (PS) functional in [12] with explicit
solutions. By rendering some rational constraints on the initial conditions and
the final solutions of the PS functional, we propose two novel formulations
which can be approximated to be the explicit solutions of the evolution partial
differential equations (PDEs) of the PS model, in which only one PDE needs to
be solved efficiently. Furthermore, an energy term that regularizes the level
set function to be a signed distance function is incorporated into our
evolution formulation, and the time-consuming re-initialization is avoided.
Experiments on synthetic and real images show that our method is more efficient
than both the PS model and the local binary fitting (LBF) model [4], while
having similar segmentation accuracy as the LBF model.
</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02522</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric Decomposition of Feed Forward Neural Networks</dc:title>
 <dc:creator>Cattell, Sven</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>92B20</dc:subject>
 <dc:description>  There have been several attempts to mathematically understand neural networks
and many more from biological and computational perspectives. The field has
exploded in the last decade, yet neural networks are still treated much like a
black box. In this work we describe a structure that is inherent to a feed
forward neural network. This will provide a framework for future work on neural
networks to improve training algorithms, compute the homology of the network,
and other applications. Our approach takes a more geometric point of view and
is unlike other attempts to mathematically understand neural networks that rely
on a functional perspective.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02526</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction with a Short Memory</dc:title>
 <dc:creator>Kakade, Sham</dc:creator>
 <dc:creator>Liang, Percy</dc:creator>
 <dc:creator>Sharan, Vatsal</dc:creator>
 <dc:creator>Valiant, Gregory</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of predicting the next observation given a sequence
of past observations, and consider the extent to which accurate prediction
requires complex algorithms that explicitly leverage long-range dependencies.
Perhaps surprisingly, our positive results show that for a broad class of
sequences, there is an algorithm that predicts well on average, and bases its
predictions only on the most recent few observation together with a set of
simple summary statistics of the past observations. Specifically, we show that
for any distribution over observations, if the mutual information between past
observations and future observations is upper bounded by $I$, then a simple
Markov model over the most recent $I/\epsilon$ observations obtains expected KL
error $\epsilon$---and hence $\ell_1$ error $\sqrt{\epsilon}$---with respect to
the optimal predictor that has access to the entire past and knows the data
generating distribution. For a Hidden Markov Model with $n$ hidden states, $I$
is bounded by $\log n$, a quantity that does not depend on the mixing time, and
we show that the trivial prediction algorithm based on the empirical
frequencies of length $O(\log n/\epsilon)$ windows of observations achieves
this error, provided the length of the sequence is $d^{\Omega(\log
n/\epsilon)}$, where $d$ is the size of the observation alphabet.
  We also establish that this result cannot be improved upon, even for the
class of HMMs, in the following two senses: First, for HMMs with $n$ hidden
states, a window length of $\log n/\epsilon$ is information-theoretically
necessary to achieve expected $\ell_1$ error $\sqrt{\epsilon}$. Second, the
$d^{\Theta(\log n/\epsilon)}$ samples required to estimate the Markov model for
an observation alphabet of size $d$ is necessary for any computationally
tractable learning algorithm, assuming the hardness of strongly refuting a
certain class of CSPs.
</dc:description>
 <dc:description>Comment: 37 pages, 3 figures</dc:description>
 <dc:date>2016-12-07</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02531</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on Logarithmic Space Stream Algorithms for Matchings in Low
  Arboricity Graphs</dc:title>
 <dc:creator>McGregor, Andrew</dc:creator>
 <dc:creator>Vorotnikova, Sofya</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a data stream algorithm for estimating the size of the maximum
matching of a low arboricity graph. Recall that a graph has arboricity $\alpha$
if its edges can be partitioned into at most $\alpha$ forests and that a planar
graph has arboricity $\alpha=3$. Estimating the size of the maximum matching in
such graphs has been a focus of recent data stream research.
  A surprising result on this problem was recently proved by Cormode et al.
They designed an ingenious algorithm that returned a
$(22.5\alpha+6)(1+\epsilon)$ approximation using a single pass over the edges
of the graph (ordered arbitrarily) and $O(\epsilon^{-2}\alpha \cdot \log n
\cdot \log_{1+\epsilon} n)$ space. In this note, we improve the approximation
factor to $(\alpha+2)(1+\epsilon)$ via a tighter analysis and show that, with a
modification of their algorithm, the space required can be reduced to
$O(\epsilon^{-2} \log n)$.
</dc:description>
 <dc:description>Comment: An update to the proof of Theorem 3. See paper for details</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02534</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextual Visual Similarity</dc:title>
 <dc:creator>Wang, Xiaofang</dc:creator>
 <dc:creator>Kitani, Kris M.</dc:creator>
 <dc:creator>Hebert, Martial</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Measuring visual similarity is critical for image understanding. But what
makes two images similar? Most existing work on visual similarity assumes that
images are similar because they contain the same object instance or category.
However, the reason why images are similar is much more complex. For example,
from the perspective of category, a black dog image is similar to a white dog
image. However, in terms of color, a black dog image is more similar to a black
horse image than the white dog image. This example serves to illustrate that
visual similarity is ambiguous but can be made precise when given an explicit
contextual perspective. Based on this observation, we propose the concept of
contextual visual similarity. To be concrete, we examine the concept of
contextual visual similarity in the application domain of image search. Instead
of providing only a single image for image similarity search (\eg, Google image
search), we require three images. Given a query image, a second positive image
and a third negative image, dissimilar to the first two images, we define a
contextualized similarity search criteria. In particular, we learn feature
weights over all the feature dimensions of each image such that the distance
between the query image and the positive image is small and their distances to
the negative image are large after reweighting their features. The learned
feature weights encode the contextualized visual similarity specified by the
user and can be used for attribute specific image search. We also show the
usefulness of our contextualized similarity weighting scheme for different
tasks, such as answering visual analogy questions and unsupervised attribute
discovery.
</dc:description>
 <dc:description>Comment: Submitted to CVPR 2017</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02540</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>City traffic forecasting using taxi GPS data: A coarse-grained cellular
  automata model</dc:title>
 <dc:creator>Hu, Yucheng</dc:creator>
 <dc:creator>Li, Minwei</dc:creator>
 <dc:creator>Liu, Hao</dc:creator>
 <dc:creator>Guo, Xiaolu</dc:creator>
 <dc:creator>Wang, Xiaowei</dc:creator>
 <dc:creator>Li, Tiejun</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  City traffic is a dynamic system of enormous complexity. Modeling and
predicting city traffic flow remains to be a challenge task and the main
difficulties are how to specify the supply and demands and how to parameterize
the model. In this paper we attempt to solve these problems with the help of
large amount of floating car data. We propose a coarse-grained cellular
automata model that simulates vehicles moving on uniform grids whose size are
much larger compared with the microscopic cellular automata model. The car-car
interaction in the microscopic model is replaced by the coupling between
vehicles and coarse-grained state variables in our model. To parameterize the
model, flux-occupancy relations are fitted from the historical data at every
grids, which serve as the coarse-grained fundamental diagrams coupling the
occupancy and speed. To evaluate the model, we feed it with the historical
travel demands and trajectories obtained from the floating car data and use the
model to predict road speed one hour into the future. Numerical results show
that our model can capture the traffic flow pattern of the entire city and make
reasonable predictions. The current work can be considered a prototype for a
model-based forecasting system for city traffic.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02541</identifier>
 <datestamp>2017-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query-adaptive Image Retrieval by Deep Weighted Hashing</dc:title>
 <dc:creator>Zhang, Jian</dc:creator>
 <dc:creator>Peng, Yuxin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>H.3.1, H.3.3</dc:subject>
 <dc:description>  Hashing methods have attracted much attention for large scale image
retrieval. Some deep hashing methods have achieved promising results by taking
advantage of the strong representation power of deep networks recently.
However, existing deep hashing methods treat all hash bits equally. On one
hand, a large number of images share the same distance to a query image due to
the discrete Hamming distance, which raises a critical issue of image retrieval
where fine-grained rankings are very important. On the other hand, different
hash bits actually contribute to the image retrieval differently, and treating
them equally greatly affects the retrieval accuracy of image. To address the
above two problems, we propose the query-adaptive deep weighted hashing (QaDWH)
approach, which can perform fine-grained ranking for different queries by
weighted Hamming distance. First, a novel deep hashing network is proposed to
learn the hash codes and corresponding class-wise weights jointly, so that the
learned weights can reflect the importance of different hash bits for different
image classes. Second, a query-adaptive image retrieval method is proposed,
which rapidly generates hash bit weights for different query images by fusing
its semantic probability and the learned class-wise weights. Fine-grained image
retrieval is then performed by the weighted Hamming distance, which can provide
more accurate ranking than the traditional Hamming distance. Experiments on
four widely used datasets show that the proposed approach outperforms eight
state-of-the-art hashing methods.
</dc:description>
 <dc:description>Comment: 13 pages, submitted to IEEE Transactions On Multimedia</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02542</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum Rates of Approximate Sufficient Statistics</dc:title>
 <dc:creator>Hayashi, Masahito</dc:creator>
 <dc:creator>Tan, Vincent Y. F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Given a sufficient statistic for a parametric family of distributions, one
can estimate the parameter without access to the data. However, the memory or
code size for storing the sufficient statistic may nonetheless still be
prohibitive. Indeed, for $n$ independent samples drawn from a $k$-nomial
distribution with $d=k-1$ degrees of freedom, the length of the code scales as
$d\log n+O(1)$. In many applications, we may not have a useful notion of
sufficient statistics (e.g., when the parametric family is not an exponential
family) and we also may not need to reconstruct the generating distribution
exactly. By adopting a Shannon-theoretic approach in which we allow a small
error in estimating the generating distribution, we construct various {\em
approximate sufficient statistics} and show that the code length can be reduced
to $\frac{d}{2}\log n+O(1)$. We consider errors measured according to the
relative entropy and variational distance criteria. For the code constructions,
we leverage Rissanen's minimum description length principle, which yields a
non-vanishing error measured according to the relative entropy. For the
converse parts, we use Clarke and Barron's formula for the relative entropy of
a parametrized distribution and the corresponding mixture distribution.
However, this method only yields a weak converse for the variational distance.
We develop new techniques to achieve vanishing errors and we also prove strong
converses. The latter means that even if the code is allowed to have a
non-vanishing error, its length must still be at least $\frac{d}{2}\log n$.
</dc:description>
 <dc:description>Comment: To appear in the IEEE Transactions on Information Theory</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02545</identifier>
 <datestamp>2017-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Constituent Codes Oriented Code Construction Scheme for Polar Code-Aim
  to Reduce the Decoding Latency</dc:title>
 <dc:creator>Che, Tiben</dc:creator>
 <dc:creator>Choi, Gwan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper proposes a polar code construction scheme that reduces
constituent-code supplemented decoding latency. Constituent codes are the
sub-codewords with specific patterns. They are used to accelerate the
successive cancellation decoding process of polar code without any performance
degradation. We modify the traditional construction approach to yield increased
number of desirable constituent codes that speeds the decoding process. For
(n,k) polar code, instead of directly setting the k best and (n-k) worst bits
to the information bits and frozen bits, respectively, we swap the locations of
some information and frozen bits carefully according to the qualities of their
equivalent channels. We conducted the simulation of 1024 and 2048 bits length
polar codes with multiple rates and analyzed the decoding latency for various
length codes. The numerical results show that the proposed construction scheme
generally is able to achieve at least around 20% latency deduction with an
negligible loss in gain with carefully selected optimization threshold.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02547</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-composable Programming</dc:title>
 <dc:creator>Kim, Hiun</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Many variability management techniques rely on sophisticated language
extension or tools to support it. While this can provide dedicated syntax and
operational mechanism but it struggling practical adaptation for the cost of
adapting new technology as part of development process. We present
Self-composable Programming, a language-driven, composition-based variability
implementation which takes an object-oriented approach to modeling and
composing behaviors in software. Self-composable Programming introduces
hierarchical relationship of behavior by providing concepts of abstract
function, which modularise commonalities, and specific function which inherits
from abstract function and be apply refinement to contain variabilities to
fulfill desired functionality. Various object-oriented techniques can
applicable in the refinement process including explicit method-based, and
implicit traits-based refinement. In order to evaluate the potential
independence of behavior from the object by applying object-orientation to
function, we compare it to Aspect-oriented Programming both conceptually and
empirically.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02549</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constructibility and Rosserizability of the Proofs of Boolos and Chaitin
  for Godel's Incompleteness Theorem</dc:title>
 <dc:creator>Salehi, Saeed</dc:creator>
 <dc:creator>Seraji, Payam</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03F40, 03F30, 03D32</dc:subject>
 <dc:description>  The proofs of Chaitin and Boolos for Godel's Incompleteness Theorem are
studied from the perspectives of constructibility and Rosserizability. By
Rosserization of a proof we mean that the independence of the true but
unprovable sentence can be shown by assuming only the (simple) consistency of
the theory. It is known that Godel's own proof for his incompleteness theorem
is not Rosserizable, and we show that neither are Kleene's or Boolos' proofs.
However, we prove a Rosserized version of Chaitin's (incompleteness) theorem.
The proofs of Godel, Rosser and Kleene are constructive in the sense that they
explicitly construct, by algorithmic ways, the independent sentence(s) from the
theory. We show that the proofs of Chaitin and Boolos are not constructive, and
they prove only the mere existence of the independent sentences.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02557</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sorting Data on Ultra-Large Scale with RADULS. New Incarnation of Radix
  Sort</dc:title>
 <dc:creator>Kokot, Marek</dc:creator>
 <dc:creator>Deorowicz, Sebastian</dc:creator>
 <dc:creator>Debudaj-Grabysz, Agnieszka</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  The paper introduces RADULS, a new parallel sorter based on radix sort
algorithm, intended to organize ultra-large data sets efficiently. For example
4G 16-byte records can be sorted with 16 threads in less than 15 seconds on
Intel Xeon-based workstation. The implementation of RADULS is not only highly
optimized to gain such an excellent performance, but also parallelized in a
cache friendly manner to make the most of modern multicore architectures.
Besides, our parallel scheduler launches a few different procedures at runtime,
according to the current parameters of the execution, for proper workload
management. All experiments show RADULS to be superior to competing algorithms.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02559</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AGA: Attribute Guided Augmentation</dc:title>
 <dc:creator>Dixit, Mandar</dc:creator>
 <dc:creator>Kwitt, Roland</dc:creator>
 <dc:creator>Niethammer, Marc</dc:creator>
 <dc:creator>Vasconcelos, Nuno</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We consider the problem of data augmentation, i.e., generating artificial
samples to extend a given corpus of training data. Specifically, we propose
attributed-guided augmentation (AGA) which learns a mapping that allows to
synthesize data such that an attribute of a synthesized sample is at a desired
value or strength. This is particularly interesting in situations where little
data with no attribute annotation is available for learning, but we have access
to a large external corpus of heavily annotated samples. While prior works
primarily augment in the space of images, we propose to perform augmentation in
feature space instead. We implement our approach as a deep encoder-decoder
architecture that learns the synthesis function in an end-to-end manner. We
demonstrate the utility of our approach on the problems of (1) one-shot object
recognition in a transfer-learning setting where we have no prior knowledge of
the new classes, as well as (2) object-based one-shot scene recognition. As
external data, we leverage 3D depth and pose information from the SUN RGB-D
dataset. Our experiments show that attribute-guided augmentation of high-level
CNN features considerably improves one-shot recognition performance on both
problems.
</dc:description>
 <dc:description>Comment: CVPR 2017</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02561</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Higher Order Isoparametric Fictitious Domain Method for Level Set
  Domains</dc:title>
 <dc:creator>Lehrenfeld, Christoph</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65N85, 65N30</dc:subject>
 <dc:description>  We consider a new fictitious domain approach of higher order accuracy. To
implement Dirichlet conditions we apply the classical Nitsche method combined
with a facet-based stabilization (ghost penalty). Both techniques are combined
with a higher order isoparametric finite element space which is based on a
special mesh transformation. The mesh transformation is build upon a higher
order accurate level set representation and allows to reduce the problem of
numerical integration to problems on domains which are described by piecewise
linear level set functions. The combination of this strategy for the numerical
integration and the stabilized Nitsche formulation results in an accurate and
robust method. We introduce and analyze it and give numerical examples.
</dc:description>
 <dc:description>Comment: 27 pages, 8 figures. (v2 of this paper is an accidental copy of
  arXiv:1602.02970v2)</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02562</identifier>
 <datestamp>2017-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification of Neurological Gait Disorders Using Multi-task Feature
  Learning</dc:title>
 <dc:creator>Papavasileiou, Ioannis</dc:creator>
 <dc:creator>Zhang, Wenlong</dc:creator>
 <dc:creator>Wang, Xin</dc:creator>
 <dc:creator>Bi, Jinbo</dc:creator>
 <dc:creator>Zhang, Li</dc:creator>
 <dc:creator>Han, Song</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68T10</dc:subject>
 <dc:description>  As our population ages, neurological impairments and degeneration of the
musculoskeletal system yield gait abnormalities, which can significantly reduce
quality of life. Gait rehabilitative therapy has been widely adopted to help
patients maximize community participation and living independence. To further
improve the precision and efficiency of rehabilitative therapy, more objective
methods need to be developed based on sensory data. In this paper, an
algorithmic framework is proposed to provide classification of gait disorders
caused by two common neurological diseases, stroke and Parkinson's Disease
(PD), from ground contact force (GCF) data. An advanced machine learning
method, multi-task feature learning (MTFL), is used to jointly train
classification models of a subject's gait in three classes, post-stroke, PD and
healthy gait. Gait parameters related to mobility, balance, strength and rhythm
are used as features for the classification. Out of all the features used, the
MTFL models capture the more important ones per disease, which will help
provide better objective assessment and therapy progress tracking. To evaluate
the proposed methodology we use data from a human participant study, which
includes five PD patients, three post-stroke patients, and three healthy
subjects. Despite the diversity of abnormalities, the evaluation shows that the
proposed approach can successfully distinguish post-stroke and PD gait from
healthy gait, as well as post-stroke from PD gait, with Area Under the Curve
(AUC) score of at least 0.96. Moreover, the methodology helps select important
gait features to better understand the key characteristics that distinguish
abnormal gaits and design personalized treatment.
</dc:description>
 <dc:description>Comment: shorter version of this paper is submitted to CHASE '17 conference</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02564</identifier>
 <datestamp>2017-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Publish/Subscribe Query Processing on the Spatio-Textual
  Data Stream</dc:title>
 <dc:creator>Chen, Zhida</dc:creator>
 <dc:creator>Cong, Gao</dc:creator>
 <dc:creator>Zhang, Zhenjie</dc:creator>
 <dc:creator>Fu, Tom Z. J.</dc:creator>
 <dc:creator>Chen, Lisi</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>C.1.2</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  Huge amount of data with both space and text information, e.g., geo-tagged
tweets, is flooding on the Internet. Such spatio-textual data stream contains
valuable information for millions of users with various interests on different
keywords and locations. Publish/subscribe systems enable efficient and
effective information distribution by allowing users to register continuous
queries with both spatial and textual constraints. However, the explosive
growth of data scale and user base has posed challenges to the existing
centralized publish/subscribe systems for spatio-textual data streams.
  In this paper, we propose our distributed publish/subscribe system, called
PS2Stream, which digests a massive spatio-textual data stream and directs the
stream to target users with registered interests. Compared with existing
systems, PS2Stream achieves a better workload distribution in terms of both
minimizing the total amount of workload and balancing the load of workers. To
achieve this, we propose a new workload distribution algorithm considering both
space and text properties of the data. Additionally, PS2Stream supports dynamic
load adjustments to adapt to the change of the workload, which makes PS2Stream
adaptive. Extensive empirical evaluation, on commercial cloud computing
platform with real data, validates the superiority of our system design and
advantages of our techniques on system performance improvement.
</dc:description>
 <dc:description>Comment: 13 pages, 16 figures, this paper has been accepted by ICDE2017</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02569</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monitorability Bounds via Expander, Sparsifier and Random Walks. The
  Interplay Between On-Demand Monitoring and Anonymity</dc:title>
 <dc:creator>Dolev, Shlomi</dc:creator>
 <dc:creator>Khankin, Daniel</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The network virtualization allows new on-demand management capabilities, in
this work we demonstrate such a service, namely, on-demand efficient monitoring
or anonymity. The proposed service is based on network virtualization of
expanders or sparsifiers over the physical network. The defined virtual (or
overlay) communication graphs coupled with a multi-hop extension of Valiant
randomization based routing lets us monitor the entire traffic in the network,
with a very few monitoring nodes.
  In particular, we show that using overlay network with expansion properties
and Valiant randomized load balancing it is enough to place $O(m)$ monitor
nodes when the length of the overlay path (number of intermediate nodes chosen
by Valiant's routing procedure) is $O(n/m)$.
  We propose two randomized routing methods to implement policies for sending
messages, and we show that they facilitate efficient monitoring of the entire
traffic, such that the traffic is distributed uniformly in the network, and
each monitor has equiprobable view of the network flow. In terms of complex
networks, our result can be interpreted as a way to enforce the same
betweenness centrality to all nodes in the network.
  Additionally, we show that our results are useful in employing anonymity
services. Thus, we propose monitoring or anonymity services, which can be
deployed and shut down on-demand. Our work is the first, as far as we know, to
bring such on-demand infrastructure structuring using the cloud network
virtualization capability to existing monitoring or anonymity networks. We
propose methods to theoretically improve services provided by existing
anonymity networks, and optimize the degree of anonymity, in addition providing
robustness and reliability to system usage and security.
  We believe that, our constructions of overlay expanders and sparsifiers
weighted network are of independent interest.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02572</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting brain age with deep learning from raw imaging data results in
  a reliable and heritable biomarker</dc:title>
 <dc:creator>Cole, James H</dc:creator>
 <dc:creator>Poudel, Rudra PK</dc:creator>
 <dc:creator>Tsagkrasoulis, Dimosthenis</dc:creator>
 <dc:creator>Caan, Matthan WA</dc:creator>
 <dc:creator>Steves, Claire</dc:creator>
 <dc:creator>Spector, Tim D</dc:creator>
 <dc:creator>Montana, Giovanni</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Machine learning analysis of neuroimaging data can accurately predict
chronological age in healthy people and deviations from healthy brain ageing
have been associated with cognitive impairment and disease. Here we sought to
further establish the credentials of &quot;brain-predicted age&quot; as a biomarker of
individual differences in the brain ageing process, using a predictive
modelling approach based on deep learning, and specifically convolutional
neural networks (CNN), and applied to both pre-processed and raw T1-weighted
MRI data. Firstly, we aimed to demonstrate the accuracy of CNN brain-predicted
age using a large dataset of healthy adults (N = 2001). Next, we sought to
establish the heritability of brain-predicted age using a sample of monozygotic
and dizygotic female twins (N = 62). Thirdly, we examined the test-retest and
multi-centre reliability of brain-predicted age using two samples
(within-scanner N = 20; between-scanner N = 11). CNN brain-predicted ages were
generated and compared to a Gaussian Process Regression (GPR) approach, on all
datasets. Input data were grey matter (GM) or white matter (WM) volumetric maps
generated by Statistical Parametric Mapping (SPM) or raw data. Brain-predicted
age represents an accurate, highly reliable and genetically-valid phenotype,
that has potential to be used as a biomarker of brain ageing. Moreover, age
predictions can be accurately generated on raw T1-MRI data, substantially
reducing computation time for novel data, bringing the process closer to giving
real-time information on brain health in clinical settings.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02574</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Pilot and Payload Power Control in Single-Cell Massive MIMO
  Systems</dc:title>
 <dc:creator>Cheng, Hei Victor</dc:creator>
 <dc:creator>Bj&#xf6;rnson, Emil</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper considers the jointly optimal pilot and data power allocation in
single-cell uplink massive multiple-input-multiple-output (MIMO) systems. Using
the spectral efficiency (SE) as performance metric and setting a total energy
budget per coherence interval, the power control is formulated as optimization
problems for two different objective functions: the weighted minimum SE among
the users and the weighted sum SE. A closed form solution for the optimal
length of the pilot sequence is derived. The optimal power control policy for
the former problem is found by solving a simple equation with a single
variable. Utilizing the special structure arising from imperfect channel
estimation, a convex reformulation is found to solve the latter problem to
global optimality in polynomial time. The gain of the optimal joint power
control is theoretically justified, and is proved to be large in the low SNR
regime. Simulation results also show the advantage of optimizing the power
control over both pilot and data power, as compared to the cases of using full
power and of only optimizing the data powers as done in previous work.
</dc:description>
 <dc:description>Comment: 16 pages, 6 figures, to appear in IEEE Transactions on Signal
  Processing</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02574</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2641381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02575</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Filter sharing: Efficient learning of parameters for volumetric
  convolutions</dc:title>
 <dc:creator>Venkataramani, Rahul</dc:creator>
 <dc:creator>Thiruvenkadam, Sheshadri</dc:creator>
 <dc:creator>Sudhakar, Prasad</dc:creator>
 <dc:creator>Ravishankar, Hariharan</dc:creator>
 <dc:creator>Vaidya, Vivek</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Typical convolutional neural networks (CNNs) have several millions of
parameters and require a large amount of annotated data to train them. In
medical applications where training data is hard to come by, these
sophisticated machine learning models are difficult to train. In this paper, we
propose a method to reduce the inherent complexity of CNNs during training by
exploiting the significant redundancy that is noticed in the learnt CNN
filters. Our method relies on finding a small set of filters and mixing
coefficients to derive every filter in each convolutional layer at the time of
training itself, thereby reducing the number of parameters to be trained. We
consider the problem of 3D lung nodule segmentation in CT images and
demonstrate the effectiveness of our method in achieving good results with only
few training examples.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures. Published in NIPS 2016 workshop on Machine
  Learning for Health, December 2016, Barcelona</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02583</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Motion Blur to Motion Flow: a Deep Learning Solution for Removing
  Heterogeneous Motion Blur</dc:title>
 <dc:creator>Gong, Dong</dc:creator>
 <dc:creator>Yang, Jie</dc:creator>
 <dc:creator>Liu, Lingqiao</dc:creator>
 <dc:creator>Zhang, Yanning</dc:creator>
 <dc:creator>Reid, Ian</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Hengel, Anton van den</dc:creator>
 <dc:creator>Shi, Qinfeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Removing pixel-wise heterogeneous motion blur is challenging due to the
ill-posed nature of the problem. The predominant solution is to estimate the
blur kernel by adding a prior, but the extensive literature on the subject
indicates the difficulty in identifying a prior which is suitably informative,
and general. Rather than imposing a prior based on theory, we propose instead
to learn one from the data. Learning a prior over the latent image would
require modeling all possible image content. The critical observation
underpinning our approach is thus that learning the motion flow instead allows
the model to focus on the cause of the blur, irrespective of the image content.
This is a much easier learning task, but it also avoids the iterative process
through which latent image priors are typically applied. Our approach directly
estimates the motion flow from the blurred image through a fully-convolutional
deep neural network (FCN) and recovers the unblurred image from the estimated
motion flow. Our FCN is the first universal end-to-end mapping from the blurred
image to the dense motion flow. To train the FCN, we simulate motion flows to
generate synthetic blurred-image-motion-flow pairs thus avoiding the need for
human labeling. Extensive experiments on challenging realistic blurred images
demonstrate that the proposed method outperforms the state-of-the-art.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02587</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inverses, Conditionals and Compositional Operators in Separative
  Valuation Algebra</dc:title>
 <dc:creator>Kohlas, Juerg</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Compositional models were introduce by Jirousek and Shenoy in the general
framework of valuation-based systems. They based their theory on an axiomatic
system of valuations involving not only the operations of combination and
marginalisation, but also of removal. They claimed that this systems covers
besides the classical case of discrete probability distributions, also the
cases of Gaussian densities and belief functions, and many other systems.
  Whereas their results on the compositional operator are correct, the
axiomatic basis is not sufficient to cover the examples claimed above. We
propose here a different axiomatic system of valuation algebras, which permits
a rigorous mathematical theory of compositional operators in valuation-based
systems and covers all the examples mentioned above. It extends the classical
theory of inverses in semigroup theory and places thereby the present theory
into its proper mathematical frame. Also this theory sheds light on the
different structures of valuation-based systems, like regular algebras
(represented by probability potentials), canncellative algebras (Gaussian
potentials) and general separative algebras (density functions).
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02589</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-source Transfer Learning with Convolutional Neural Networks for
  Lung Pattern Analysis</dc:title>
 <dc:creator>Christodoulidis, Stergios</dc:creator>
 <dc:creator>Anthimopoulos, Marios</dc:creator>
 <dc:creator>Ebner, Lukas</dc:creator>
 <dc:creator>Christe, Andreas</dc:creator>
 <dc:creator>Mougiakakou, Stavroula</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Early diagnosis of interstitial lung diseases is crucial for their treatment,
but even experienced physicians find it difficult, as their clinical
manifestations are similar. In order to assist with the diagnosis,
computer-aided diagnosis (CAD) systems have been developed. These commonly rely
on a fixed scale classifier that scans CT images, recognizes textural lung
patterns and generates a map of pathologies. In a previous study, we proposed a
method for classifying lung tissue patterns using a deep convolutional neural
network (CNN), with an architecture designed for the specific problem. In this
study, we present an improved method for training the proposed network by
transferring knowledge from the similar domain of general texture
classification. Six publicly available texture databases are used to pretrain
networks with the proposed architecture, which are then fine-tuned on the lung
tissue data. The resulting CNNs are combined in an ensemble and their fused
knowledge is compressed back to a network with the original architecture. The
proposed approach resulted in an absolute increase of about 2% in the
performance of the proposed CNN. The results demonstrate the potential of
transfer learning in the field of medical image analysis, indicate the textural
nature of the problem and show that the method used for training a network can
be as important as designing its architecture.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02589</dc:identifier>
 <dc:identifier>doi:10.1109/JBHI.2016.2636929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02590</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scene Flow Estimation: A Survey</dc:title>
 <dc:creator>Yan, Zike</dc:creator>
 <dc:creator>Xiang, Xuezhi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper is the first to review the scene flow estimation field, which
analyzes and compares methods, technical challenges, evaluation methodologies
and performance of scene flow estimation. Existing algorithms are categorized
in terms of scene representation, data source, and calculation scheme, and the
pros and cons in each category are compared briefly. The datasets and
evaluation protocols are enumerated, and the performance of the most
representative methods is presented. A future vision is illustrated with few
questions arisen for discussion. This survey presents a general introduction
and analysis of scene flow estimation.
</dc:description>
 <dc:description>Comment: 51 pages, 12 figures, 10 tables, 108 references</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02603</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compact CAR: Low-Overhead Cache Replacement Policy for an ICN Router</dc:title>
 <dc:creator>Ooka, Atsushi</dc:creator>
 <dc:creator>Eum, Suyong</dc:creator>
 <dc:creator>Ata, Shingo</dc:creator>
 <dc:creator>Murata, Masayuki</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Information-centric networking (ICN) has gained attention from network
research communities due to its capability of efficient content dissemination.
In-network caching function in ICN plays an important role to achieve the
design motivation. However, many researchers on in-network caching have focused
on where to cache rather than how to cache: the former is known as contents
deployment in the network and the latter is known as cache replacement in an
ICN element. Although, the cache replacement has been intensively researched in
the context of web-caching and content delivery network previously, the
conventional approaches cannot be directly applied to ICN due to the fine
granularity of cacheable items in ICN, which eventually changes the access
patterns.
  In this paper, we argue that ICN requires a novel cache replacement algorithm
to fulfill the requirements in the design of high performance ICN element.
Then, we propose a novel cache replacement algorithm to satisfy the
requirements named Compact CLOCK with Adaptive Replacement (Compact CAR), which
can reduce the consumption of cache memory to one-tenth compared to
conventional approaches.
</dc:description>
 <dc:description>Comment: 15 pages, 29 figures, submitted to Computer Communications</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02605</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Information-Seeking Agents</dc:title>
 <dc:creator>Bachman, Philip</dc:creator>
 <dc:creator>Sordoni, Alessandro</dc:creator>
 <dc:creator>Trischler, Adam</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We develop a general problem setting for training and testing the ability of
agents to gather information efficiently. Specifically, we present a collection
of tasks in which success requires searching through a partially-observed
environment, for fragments of information which can be pieced together to
accomplish various goals. We combine deep architectures with techniques from
reinforcement learning to develop agents that solve our tasks. We shape the
behavior of these agents by combining extrinsic and intrinsic rewards. We
empirically demonstrate that these agents learn to search actively and
intelligently for new information to reduce their uncertainty, and to exploit
information they have already acquired.
</dc:description>
 <dc:description>Comment: Under review for ICLR 2017</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02606</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aerial Picking and Delivery of Magnetic Objects with MAVs</dc:title>
 <dc:creator>Gawel, Abel</dc:creator>
 <dc:creator>Kamel, Mina</dc:creator>
 <dc:creator>Novkovic, Tonci</dc:creator>
 <dc:creator>Widauer, Jakob</dc:creator>
 <dc:creator>Schindler, Dominik</dc:creator>
 <dc:creator>von Altishofen, Benjamin Pfyffer</dc:creator>
 <dc:creator>Siegwart, Roland</dc:creator>
 <dc:creator>Nieto, Juan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Autonomous delivery of goods using a MAV is a difficult problem, as it poses
high demand on the MAV's control, perception and manipulation capabilities.
This problem is especially challenging if the exact shape, location and
configuration of the objects are unknown. In this paper, we report our findings
during the development and evaluation of a fully integrated system that is
energy efficient and enables MAVs to pick up and deliver objects with partly
ferrous surface of varying shapes and weights. This is achieved by using a
novel combination of an electro-permanent magnetic gripper with a passively
compliant structure and integration with detection, control and servo
positioning algorithms. The system's ability to grasp stationary and moving
objects was tested, as well as its ability to cope with different shapes of the
object and external disturbances. We show that such a system can be
successfully deployed in scenarios where an object with partly ferrous parts
needs to be gripped and placed in a predetermined location.
</dc:description>
 <dc:description>Comment: under review for the IEEE International Conference on Robotics and
  Automation (ICRA) 2017</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02631</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Progressive Tree-like Curvilinear Structure Reconstruction with
  Structured Ranking Learning and Graph Algorithm</dc:title>
 <dc:creator>Jeong, Seong-Gyun</dc:creator>
 <dc:creator>Tarabalka, Yuliya</dc:creator>
 <dc:creator>Nisse, Nicolas</dc:creator>
 <dc:creator>Zerubia, Josiane</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel tree-like curvilinear structure reconstruction algorithm
based on supervised learning and graph theory. In this work we analyze image
patches to obtain the local major orientations and the rankings that correspond
to the curvilinear structure. To extract local curvilinear features, we compute
oriented gradient information using steerable filters. We then employ
Structured Support Vector Machine for ordinal regression of the input image
patches, where the ordering is determined by shape similarity to latent
curvilinear structure. Finally, we progressively reconstruct the curvilinear
structure by looking for geodesic paths connecting remote vertices in the graph
built on the structured output rankings. Experimental results show that the
proposed algorithm faithfully provides topological features of the curvilinear
structures using minimal pixels for various datasets.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02636</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Distinct Heavy Hitters for DNS DDoS Attack Detection</dc:title>
 <dc:creator>Afek, Yehuda</dc:creator>
 <dc:creator>Bremler-Barr, Anat</dc:creator>
 <dc:creator>Cohen, Edith</dc:creator>
 <dc:creator>Feibish, Shir Landau</dc:creator>
 <dc:creator>Shagam, Michal</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Motivated by a recent new type of randomized Distributed Denial of Service
(DDoS) attacks on the Domain Name Service (DNS), we develop novel and efficient
distinct heavy hitters algorithms and build an attack identification system
that uses our algorithms. Heavy hitter detection in streams is a fundamental
problem with many applications, including detecting certain DDoS attacks and
anomalies. A (classic) heavy hitter (HH) in a stream of elements is a key
(e.g., the domain of a query) which appears in many elements (e.g., requests).
When stream elements consist of a &lt;key; subkey&gt; pairs, (&lt;domain; subdomain&gt;) a
distinct heavy hitter (dhh) is a key that is paired with a large number of
different subkeys. Our dHH algorithms are considerably more practical than
previous algorithms. Specifically the new fixed-size algorithms are simple to
code and with asymptotically optimal space accuracy tradeoffs. In addition we
introduce a new measure, a combined heavy hitter (cHH), which is a key with a
large combination of distinct and classic weights. Efficient algorithms are
also presented for cHH detection. Finally, we perform extensive experimental
evaluation on real DNS attack traces, demonstrating the effectiveness of both
our algorithms and our DNS malicious queries identification system.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02640</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Realtime Predictive Maintenance with Lambda Architecture</dc:title>
 <dc:creator>Yamato, Yoji</dc:creator>
 <dc:creator>Kumazaki, Hiroki</dc:creator>
 <dc:creator>Fukumoto, Yoshifumi</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Recently, IoT technologies have been progressed and applications of
maintenance area are expected. However, IoT maintenance applications are not
spread in Japan yet because of insufficient analysis of real time situation,
high cost to collect sensing data and to configure failure detection rules. In
this paper, using lambda architecture concept, we propose a maintenance
platform in which edge nodes analyze sensing data, detect anomaly, extract a
new detection rule in real time and a cloud orders maintenance automatically,
also analyzes whole data collected by batch process in detail, updates learning
model of edge nodes to improve analysis accuracy.
</dc:description>
 <dc:description>Comment: 4 pages, in Japanese, 3 figures, IEICE Technical Report, SC2016-28,
  Nov. 2016</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02640</dc:identifier>
 <dc:identifier>IEICE Technical Report, SC2016-28, Nov. 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02646</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Video Object Segmentation from Static Images</dc:title>
 <dc:creator>Khoreva, Anna</dc:creator>
 <dc:creator>Perazzi, Federico</dc:creator>
 <dc:creator>Benenson, Rodrigo</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:creator>Sorkine-Hornung, Alexander</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Inspired by recent advances of deep learning in instance segmentation and
object tracking, we introduce video object segmentation problem as a concept of
guided instance segmentation. Our model proceeds on a per-frame basis, guided
by the output of the previous frame towards the object of interest in the next
frame. We demonstrate that highly accurate object segmentation in videos can be
enabled by using a convnet trained with static images only. The key ingredient
of our approach is a combination of offline and online learning strategies,
where the former serves to produce a refined mask from the previous frame
estimate and the latter allows to capture the appearance of the specific object
instance. Our method can handle different types of input annotations: bounding
boxes and segments, as well as incorporate multiple annotated frames, making
the system suitable for diverse applications. We obtain competitive results on
three different datasets, independently from the type of input annotation.
</dc:description>
 <dc:description>Comment: Submitted to CVPR 2017</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02647</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison of max-plus automata and joint spectral radius of tropical
  matrices</dc:title>
 <dc:creator>Daviaud, Laure</dc:creator>
 <dc:creator>Guillon, Pierre</dc:creator>
 <dc:creator>Merlet, Glenn</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Weighted automata over the max-plus semiring S are closely related to
finitely generated semigroups of matrices over S. In this paper, we use results
in automata theory to study two quantities associated with sets of matrices:
the joint spectral radius and the ultimate rank. We prove that these two
quantities are not computable over the tropical semiring, i.e. there is no
algorithm that takes as input a finite set of matrices M and provides as output
the joint spectral radius (resp. the ultimate rank) of M. On the other hand, we
prove that the joint spectral radius is nevertheless approximable and we
exhibit restricted cases in which the joint spectral radius and the ultimate
rank are computable. To reach this aim, we study the problem of comparing
functions computed by weighted automata over the tropical semiring. This
problem is known to be undecidable and we prove that it remains undecidable in
some specific subclasses of automata.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02649</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FCNs in the Wild: Pixel-level Adversarial and Constraint-based
  Adaptation</dc:title>
 <dc:creator>Hoffman, Judy</dc:creator>
 <dc:creator>Wang, Dequan</dc:creator>
 <dc:creator>Yu, Fisher</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Fully convolutional models for dense prediction have proven successful for a
wide range of visual tasks. Such models perform well in a supervised setting,
but performance can be surprisingly poor under domain shifts that appear mild
to a human observer. For example, training on one city and testing on another
in a different geographic region and/or weather condition may result in
significantly degraded performance due to pixel-level distribution shift. In
this paper, we introduce the first domain adaptive semantic segmentation
method, proposing an unsupervised adversarial approach to pixel prediction
problems. Our method consists of both global and category specific adaptation
techniques. Global domain alignment is performed using a novel semantic
segmentation network with fully convolutional domain adversarial learning. This
initially adapted space then enables category specific adaptation through a
generalization of constrained weak learning, with explicit transfer of the
spatial layout from the source to the target domains. Our approach outperforms
baselines across different settings on multiple large-scale datasets, including
adapting across various real city environments, different synthetic
sub-domains, from simulated to real environments, and on a novel large-scale
dash-cam dataset.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02649</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02652</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Operations in the era of large distributed telescopes</dc:title>
 <dc:creator>Grange, Yan Guillaume</dc:creator>
 <dc:creator>Vinsen, Kevin</dc:creator>
 <dc:creator>Guzman, Juan Carlos</dc:creator>
 <dc:creator>Parra, Jos&#xe9; Alfredo</dc:creator>
 <dc:creator>Mol, Jan David</dc:creator>
 <dc:creator>Renil, Rosly</dc:creator>
 <dc:creator>Schollar, Christoper</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>K.6.2</dc:subject>
 <dc:subject>K.6.3</dc:subject>
 <dc:subject>K.6.4</dc:subject>
 <dc:description>  The previous generation of astronomical instruments tended to consist of
single receivers in the focal point of one or more physical reflectors. Because
of this, most astronomical data sets were small enough that the raw data could
easily be downloaded and processed on a single machine.
  In the last decade, several large, complex Radio Astronomy instruments have
been built and the SKA is currently being designed. Many of these instruments
have been designed by international teams, and, in the case of LOFAR span an
area larger than a single country. Such systems are ICT telescopes and consist
mainly of complex software. This causes the main operational issues to be
related to the ICT systems and not the telescope hardware. However, it is
important that the operations of the ICT systems are coordinated with the
traditional operational work. Managing the operations of such telescopes
therefore requires an approach that significantly differs from classical
telescope operations.
  The goal of this session is to bring together members of operational teams
responsible for such large-scale ICT telescopes. This gathering will be used to
exchange experiences and knowledge between those teams. Also, we consider such
a meeting as very valuable input for future instrumentation, especially the SKA
and its regional centres.
</dc:description>
 <dc:description>Comment: 4 pages; to be published in ADASS XXVI (held October 16-20, 2016)
  proceedings. Recording can be found here</dc:description>
 <dc:date>2016-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02660</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decision Theory in an Algebraic Setting</dc:title>
 <dc:creator>Negri, Maurizio</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>91B06, 90B50</dc:subject>
 <dc:description>  In decision theory an act is a function from a set of conditions to the set
of real numbers. The set of conditions is a partition in some algebra of
events. The expected value of an act can be calculated when a probability
measure is given. We adopt an algebraic point of view by substituting the
algebra of events with a finite distributive lattice and the probability
measure with a lattice valuation. We introduce a partial order on acts that
generalizes the dominance relation and show that the set of acts is a lattice
with respect to this order. Finally we analyze some different kinds of
comparison between acts, without supposing a common set of conditions for the
acts to be compared.
</dc:description>
 <dc:description>Comment: 22 pages, 1 figure</dc:description>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02663</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A constructive algorithm for the LLL on permutations</dc:title>
 <dc:creator>Harris, David G.</dc:creator>
 <dc:creator>Srinivasan, Aravind</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  While there has been significant progress on algorithmic aspects of the
Lov\'{a}sz Local Lemma (LLL) in recent years, a noteworthy exception is when
the LLL is used in the context of random permutations. The breakthrough
algorithm of Moser &amp; Tardos only works in the setting of independent variables,
and does not apply in this context. We resolve this by developing a randomized
polynomial-time algorithm for such applications. A noteworthy application is
for Latin transversals: the best-known general result here (Bissacot et al.,
improving on Erd\H{o}s and Spencer), states that any $n \times n$ matrix in
which each entry appears at most $(27/256)n$ times, has a Latin transversal. We
present the first polynomial-time algorithm to construct such a transversal. We
also develop RNC algorithms for Latin transversals, rainbow Hamiltonian cycles,
strong chromatic number, and hypergraph packing.
  In addition to efficiently finding a configuration which avoids bad-events,
the algorithm of Moser &amp; Tardos has many powerful extensions and properties.
These include a well-characterized distribution on the output distribution,
parallel algorithms, and a partial resampling variant. We show that our
algorithm has nearly all of the same useful properties as the Moser-Tardos
algorithm, and present a comparison of this aspect with recent works on the LLL
in general probability spaces.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02666</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating the Performance of ANN Prediction System at Shanghai Stock
  Market in the Period 21-Sep-2016 to 11-Oct-2016</dc:title>
 <dc:creator>Wanjawa, Barack Wamkaya</dc:creator>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This research evaluates the performance of an Artificial Neural Network based
prediction system that was employed on the Shanghai Stock Exchange for the
period 21-Sep-2016 to 11-Oct-2016. It is a follow-up to a previous paper in
which the prices were predicted and published before September 21. Stock market
price prediction remains an important quest for investors and researchers. This
research used an Artificial Intelligence system, being an Artificial Neural
Network that is feedforward multi-layer perceptron with error backpropagation
for prediction, unlike other methods such as technical, fundamental or time
series analysis. While these alternative methods tend to guide on trends and
not the exact likely prices, neural networks on the other hand have the ability
to predict the real value prices, as was done on this research. Nonetheless,
determination of suitable network parameters remains a challenge in neural
network design, with this research settling on a configuration of 5:21:21:1
with 80% training data or 4-year of training data as a good enough model for
stock prediction, as already determined in a previous research by the author.
The comparative results indicate that neural network can predict typical stock
market prices with mean absolute percentage errors that are as low as 1.95%
over the ten prediction instances that was studied in this research.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures, 8 tables</dc:description>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02675</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domain knowledge assisted cyst segmentation in OCT retinal images</dc:title>
 <dc:creator>Gopinath, Karthik</dc:creator>
 <dc:creator>Sivaswamy, Jayanthi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  3D imaging modalities are becoming increasingly popular and relevant in
retinal imaging owing to their effectiveness in highlighting structures in
sub-retinal layers. OCT is one such modality which has great importance in the
context of analysis of cystoid structures in subretinal layers. Signal to noise
ratio(SNR) of the images obtained from OCT is less and hence automated and
accurate determination of cystoid structures from OCT is a challenging task. We
propose an automated method for detecting/segmenting cysts in 3D OCT volumes.
The proposed method is biologically inspired and fast aided by the domain
knowledge about the cystoid structures. An ensemble learning methodRandom
forests is learnt for classification of detected region into cyst region. The
method achieves detection and segmentation in a unified setting. We believe the
proposed approach with further improvements can be a promising starting point
for more robust approach. This method is validated against the training set
achieves a mean dice coefficient of 0.3893 with a standard deviation of 0.2987
</dc:description>
 <dc:description>Comment: The paper was accepted as an oral presentation in MICCAI-2015 OPTIMA
  Cyst Segmentation Challenge</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02684</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fixpoint Approximation of Strategic Abilities under Imperfect
  Information</dc:title>
 <dc:creator>Jamroga, Wojciech</dc:creator>
 <dc:creator>Knapik, Micha&#x142;</dc:creator>
 <dc:creator>Kurpiewski, Damian</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Model checking of strategic ability under imperfect information is known to
be hard. The complexity results range from NP-completeness to undecidability,
depending on the precise setup of the problem. No less importantly, fixpoint
equivalences do not generally hold for imperfect information strategies, which
seriously hampers incremental synthesis of winning strategies. In this paper,
we propose translations of ATLir formulae that provide lower and upper bounds
for their truth values, and are cheaper to verify than the original
specifications. That is, if the expression is verified as true then the
corresponding formula of ATLir should also hold in the given model. We begin by
showing where the straightforward approach does not work. Then, we propose how
it can be modified to obtain guaranteed lower bounds. To this end, we alter the
next-step operator in such a way that traversing one's indistinguishability
relation is seen as atomic activity. Most interestingly, the lower
approximation is provided by a fixpoint expression that uses a nonstandard
variant of the next-step ability operator. We show the correctness of the
translations, establish their computational complexity, and validate the
approach by experiments with a scalable scenario of Bridge play.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02685</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonlinear 1-Bit Precoding for Massive MU-MIMO with Higher-Order
  Modulation</dc:title>
 <dc:creator>Jacobsson, Sven</dc:creator>
 <dc:creator>Durisi, Giuseppe</dc:creator>
 <dc:creator>Coldrey, Mikael</dc:creator>
 <dc:creator>Goldstein, Tom</dc:creator>
 <dc:creator>Studer, Christoph</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Massive multi-user (MU) multiple-input multiple- output (MIMO) is widely
believed to be a core technology for the upcoming fifth-generation (5G)
wireless communication standards. The use of low-precision digital-to-analog
converters (DACs) in MU-MIMO base stations is of interest because it reduces
the power consumption, system costs, and raw baseband data rates. In this
paper, we develop novel algorithms for downlink precoding in massive MU-MIMO
systems with 1-bit DACs that support higher-order modulation schemes such as
8-PSK or 16-QAM. Specifically, we present low-complexity nonlinear precoding
algorithms that achieve low error rates when combined with blind or
training-based channel-estimation algorithms at the user equipment. These
results are in stark contrast to linear-quantized precoding algorithms, which
suffer from a high error floor if used with high-order modulation schemes and
1-bit DACs.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02685</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02686</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effects of online group exercises for older adults on physical,
  psychological and social wellbeing: a pilot trial</dc:title>
 <dc:creator>Baez, Marcos</dc:creator>
 <dc:creator>Far, Iman Khaghani</dc:creator>
 <dc:creator>Ibarra, Francisco</dc:creator>
 <dc:creator>Ferron, Michela</dc:creator>
 <dc:creator>Didino, Daniele</dc:creator>
 <dc:creator>Casati, Fabio</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Background. There are many factors that can make of group exercises a
challenging setting for older adults. A major one in the elderly population is
the difference in the level of skills. In this paper we report on the physical,
psychological and social wellbeing outcomes of a novel virtual gym that enables
online group-exercises in older adults with different levels of skills.
  Methods. A total of 37 older adults (65-87 years old) followed a personalized
exercise program based on the OTAGO program for fall prevention, for a period
of eight weeks. Participants could join online group exercises using a
tablet-based application. Participants were assigned either to a Control group
(individual training) or Social group (online group-exercising). Pre- and post-
measurements were taken to analyze the physical, psychological and social
wellbeing outcomes. The study received ethical approval from the CREATE-NET
Ethics Committee on ICT Research Involving Human Beings (Application N.
2014-001).
  Results. There were improvements in both the Social and Control groups in
terms of physical outcomes. Interestingly though, while in the Control group
fitter individuals tended to adhere more to the training, this was not the case
for the Social group, where the initial level had no effect on adherence. For
psychological and social wellbeing outcomes there were improvements on both
groups, regardless of the application used.
  Conclusion. Group exercising in a virtual gym can be effective in motivating
and enabling individuals who are less fit to train as much as fitter
individuals. This not only indicates the feasibility of training together
despite differences in physical skills but also suggests that online exercise
can reduce the effect of skills on adherence in a social context. Longer term
interventions with more participants are instead recommended to assess impacts
on wellbeing.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02690</identifier>
 <datestamp>2016-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint remote state preparation (JRSP) of two-qubit equatorial state in
  quantum noisy channels</dc:title>
 <dc:creator>Adepoju, Adenike Grace</dc:creator>
 <dc:creator>Falaye, Babatunde James</dc:creator>
 <dc:creator>Sun, Guo-Hua</dc:creator>
 <dc:creator>Camacho-Nieto, Oscar</dc:creator>
 <dc:creator>Dong, Shi-Hai</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter reports the influence of noisy channels on JRSP of two-qubit
equatorial state. We present a scheme for JRSP of two-qubit equatorial state.
We employ two tripartite Greenberger-Horne-Zeilinger (GHZ) entangled states as
the quantum channel linking the parties. We find the success probability to be
$1/4$. However, this probability can be ameliorated to $3/4$ if the state
preparers assist by transmitting individual partial information through
classical channel to the receiver non-contemporaneously. Afterward, we
investigate the effects of five quantum noises: the bit-flip noise, bit-phase
flip noise, amplitude-damping noise, phase-damping noise and depolarizing noise
on the JRSP process. We obtain the analytical derivation of the fidelities
corresponding to each quantum noisy channel, which is a measure of information
loss as the qubits are being distributed in these quantum channels. We find
that the system loses some of its properties as a consequence of unwanted
interactions with environment. For instance, within the domain
$0&lt;\lambda&lt;0.65$, the information lost via transmission of qubits in amplitude
channel is most minimal, while for $0.65&lt;\lambda\leq1$, the information lost in
phase flip channel becomes the most minimal. Also, for any given $\lambda$, the
information transmitted through depolarizing channel has the least chance of
success.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1609.01538</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02690</dc:identifier>
 <dc:identifier>doi:10.1016/j.physleta.2016.12.021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02695</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards better decoding and language model integration in sequence to
  sequence models</dc:title>
 <dc:creator>Chorowski, Jan</dc:creator>
 <dc:creator>Jaitly, Navdeep</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The recently proposed Sequence-to-Sequence (seq2seq) framework advocates
replacing complex data processing pipelines, such as an entire automatic speech
recognition system, with a single neural network trained in an end-to-end
fashion. In this contribution, we analyse an attention-based seq2seq speech
recognition system that directly transcribes recordings into characters. We
observe two shortcomings: overconfidence in its predictions and a tendency to
produce incomplete transcriptions when language models are used. We propose
practical solutions to both problems achieving competitive speaker independent
word error rates on the Wall Street Journal dataset: without separate language
models we reach 10.6% WER, while together with a trigram language model, we
reach 6.7% WER.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02696</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on the triangle inequality for the Jaccard distance</dc:title>
 <dc:creator>Kosub, Sven</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Two simple proofs of the triangle inequality for the Jaccard distance in
terms of nonnegative, monotone, submodular functions are given and discussed.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02699</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Supervision with Shape Concepts for Occlusion-Aware 3D Object
  Parsing</dc:title>
 <dc:creator>Li, Chi</dc:creator>
 <dc:creator>Zia, M. Zeeshan</dc:creator>
 <dc:creator>Tran, Quoc-Huy</dc:creator>
 <dc:creator>Yu, Xiang</dc:creator>
 <dc:creator>Hager, Gregory D.</dc:creator>
 <dc:creator>Chandraker, Manmohan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Monocular 3D object parsing is highly desirable in various scenarios
including occlusion reasoning and holistic scene interpretation. We present a
deep convolutional neural network (CNN) architecture to localize semantic parts
in 2D image and 3D space while inferring their visibility states, given a
single RGB image. Our key insight is to exploit domain knowledge to regularize
the network by deeply supervising its hidden layers, in order to sequentially
infer intermediate concepts associated with the final task. To acquire training
data in desired quantities with ground truth 3D shape and relevant concepts, we
render 3D object CAD models to generate large-scale synthetic data and simulate
challenging occlusion configurations between objects. We train the network only
on synthetic data and demonstrate state-of-the-art performances on real image
benchmarks including an extended version of KITTI, PASCAL VOC, PASCAL3D+ and
IKEA for 2D and 3D keypoint localization and instance segmentation. The
empirical results substantiate the utility of our deep supervision scheme by
demonstrating effective transfer of knowledge from synthetic data to real
images, resulting in less overfitting compared to standard end-to-end training.
</dc:description>
 <dc:description>Comment: Accepted in CVPR 2017</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02699</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02701</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stream Clustering using Probabilistic Data Structures</dc:title>
 <dc:creator>Sabau, Andrei Sorin</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Most density based stream clustering algorithms separate the clustering
process into an online and offline component. Exact summarized statistics are
being employed for defining micro-clusters or grid cells during the online
stage followed by macro-clustering during the offline stage. This paper
proposes a novel alternative to the traditional two phase stream clustering
scheme, introducing sketch-based data structures for assessing both stream
density and cluster membership with probabilistic accuracy guarantees. A
count-min sketch using a damped window model estimates stream density. Bloom
filters employing a variation of active-active buffering estimate cluster
membership. Instances of both types of sketches share the same set of hash
functions. The resulting stream clustering algorithm is capable of detecting
arbitrarily shaped clusters while correctly handling outliers and making no
assumption on the total number of clusters. Experimental results over a number
of real and synthetic datasets illustrate the proposed algorithm quality and
efficiency.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02703</identifier>
 <datestamp>2017-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedding Words and Senses Together via Joint Knowledge-Enhanced
  Training</dc:title>
 <dc:creator>Mancini, Massimiliano</dc:creator>
 <dc:creator>Camacho-Collados, Jose</dc:creator>
 <dc:creator>Iacobacci, Ignacio</dc:creator>
 <dc:creator>Navigli, Roberto</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Word embeddings are widely used in Natural Language Processing, mainly due to
their success in capturing semantic information from massive corpora. However,
their creation process does not allow the different meanings of a word to be
automatically separated, as it conflates them into a single vector. We address
this issue by proposing a new model which learns word and sense embeddings
jointly. Our model exploits large corpora and knowledge from semantic networks
in order to produce a unified vector space of word and sense embeddings. We
evaluate the main features of our approach both qualitatively and
quantitatively in a variety of tasks, highlighting the advantages of the
proposed method in comparison to state-of-the-art word- and sense-based models.
</dc:description>
 <dc:description>Comment: Accepted in CoNLL 2017. 12 pages</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02706</identifier>
 <datestamp>2017-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entity Identification as Multitasking</dc:title>
 <dc:creator>Stratos, Karl</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Standard approaches in entity identification hard-code boundary detection and
type prediction into labels (e.g., John/B-PER Smith/I-PER) and then perform
Viterbi. This has two disadvantages: 1. the runtime complexity grows
quadratically in the number of types, and 2. there is no natural segment-level
representation. In this paper, we propose a novel neural architecture that
addresses these disadvantages. We frame the problem as multitasking, separating
boundary detection and type prediction but optimizing them jointly. Despite its
simplicity, this architecture performs competitively with fully structured
models such as BiLSTM-CRFs while scaling linearly in the number of types.
Furthermore, by construction, the model induces type-disambiguating embeddings
of predicted mentions.
</dc:description>
 <dc:description>Comment: EMNLP 2017, Workshop on Structured Prediction for NLP</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02707</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CrowdMI: Multiple Imputation via Crowdsourcing</dc:title>
 <dc:creator>Gondara, Lovedeep</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Can humans impute missing data with similar proficiency as machines? This is
the question we aim to answer in this paper. We present a novel idea of
converting observations with missing data to a survey questionnaire, which is
presented to crowdworkers for completion. We replicate a multiple imputation
framework by having multiple unique crowdworkers complete our questionnaire.
Experimental results demonstrate that using our method, it is possible to
generate valid imputations for qualitative and quantitative missing data, with
results comparable to imputations generated by complex statistical models.
</dc:description>
 <dc:description>Comment: updated</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02707</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02709</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Ground-Level Scene Layout from Aerial Imagery</dc:title>
 <dc:creator>Zhai, Menghua</dc:creator>
 <dc:creator>Bessinger, Zachary</dc:creator>
 <dc:creator>Workman, Scott</dc:creator>
 <dc:creator>Jacobs, Nathan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a novel strategy for learning to extract semantically meaningful
features from aerial imagery. Instead of manually labeling the aerial imagery,
we propose to predict (noisy) semantic features automatically extracted from
co-located ground imagery. Our network architecture takes an aerial image as
input, extracts features using a convolutional neural network, and then applies
an adaptive transformation to map these features into the ground-level
perspective. We use an end-to-end learning approach to minimize the difference
between the semantic segmentation extracted directly from the ground image and
the semantic segmentation predicted solely based on the aerial image. We show
that a model learned using this strategy, with no additional training, is
already capable of rough semantic labeling of aerial imagery. Furthermore, we
demonstrate that by finetuning this model we can achieve more accurate semantic
segmentation than two baseline initialization strategies. We use our network to
address the task of estimating the geolocation and geoorientation of a ground
image. Finally, we show how features extracted from an aerial image can be used
to hallucinate a plausible ground-level panorama.
</dc:description>
 <dc:description>Comment: 13 pages including appendix</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02712</identifier>
 <datestamp>2017-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Influence Maximization for Multiple Products in Continuous-Time
  Diffusion Networks</dc:title>
 <dc:creator>Du, Nan</dc:creator>
 <dc:creator>Liang, Yingyu</dc:creator>
 <dc:creator>Balcan, Maria-Florina</dc:creator>
 <dc:creator>Gomez-Rodriguez, Manuel</dc:creator>
 <dc:creator>Zha, Hongyuan</dc:creator>
 <dc:creator>Song, Le</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A typical viral marketing model identifies influential users in a social
network to maximize a single product adoption assuming unlimited user
attention, campaign budgets, and time. In reality, multiple products need
campaigns, users have limited attention, convincing users incurs costs, and
advertisers have limited budgets and expect the adoptions to be maximized soon.
Facing these user, monetary, and timing constraints, we formulate the problem
as a submodular maximization task in a continuous-time diffusion model under
the intersection of a matroid and multiple knapsack constraints. We propose a
randomized algorithm estimating the user influence in a network
($|\mathcal{V}|$ nodes, $|\mathcal{E}|$ edges) to an accuracy of $\epsilon$
with $n=\mathcal{O}(1/\epsilon^2)$ randomizations and
$\tilde{\mathcal{O}}(n|\mathcal{E}|+n|\mathcal{V}|)$ computations. By
exploiting the influence estimation algorithm as a subroutine, we develop an
adaptive threshold greedy algorithm achieving an approximation factor $k_a/(2+2
k)$ of the optimal when $k_a$ out of the $k$ knapsack constraints are active.
Extensive experiments on networks of millions of nodes demonstrate that the
proposed algorithms achieve the state-of-the-art in terms of effectiveness and
scalability.
</dc:description>
 <dc:description>Comment: 45 pages, to appear in Journal of Machine Learning Research. arXiv
  admin note: substantial text overlap with arXiv:1312.2164, arXiv:1311.3669</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02731</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementing Operational calculus on programming spaces for
  Differentiable computing</dc:title>
 <dc:creator>Sajovic, &#x17d;iga</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  We provide an illustrative implementation of an analytic,
infinitely-differentiable virtual machine, implementing
infinitely-differentiable programming spaces and operators acting upon them, as
constructed in the paper Operational calculus on programming spaces.
Implementation closely follows theorems and derivations of the paper, intended
as an educational guide for those transitioning from automatic differentiation
to this general theory.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02732</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TCP-aware Cross Layer Scheduling with Adaptive Modulation in IEEE 802.16
  (WiMAX) Networks</dc:title>
 <dc:creator>Rath, Hemant Kumar</dc:creator>
 <dc:creator>Karandikar, Abhay</dc:creator>
 <dc:creator>Sharma, Vishal</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we propose Transmission Control Protocol (TCP)-aware cross
layer scheduling algorithms in a multipoint-to-point network such as the uplink
of an IEEE 802.16 (WiMAX) network. Inadequate bandwidth allocation to a TCP
flow may lead to timeout and since TCP source drops its congestion window
($cwnd$) immediately after a timeout, it may affect the average throughput
adversely. On the other hand, since the TCP source increases its $cwnd$ only
linearly upon the availability of bandwidth, any excess assignment of bandwidth
may remain underutilized. The proposed scheduling algorithms address this by
allocating the resources based on $cwnd$ and TCP timeout. Moreover, since we
focus on uplink scheduling, we consider that only {\em flow} level resource
requirement is communicated to the Base Station ($BS$) instead of per {\em
packet} information. The schedulers also take into account the wireless channel
characteristics and are thus cross layer in nature. Through exhaustive
simulations, we demonstrate that the proposed schedulers exhibit enhanced
throughput and fairness properties when compared to that of Round Robin (RR)
scheduler under different shadowing. We demonstrate a gain between 3.5 \% to 15
\% in throughput and 15 \% to 25 \% in channel utilization over RR scheduler
under different shadowing.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02734</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning in the Machine: Random Backpropagation and the Deep Learning
  Channel</dc:title>
 <dc:creator>Baldi, Pierre</dc:creator>
 <dc:creator>Sadowski, Peter</dc:creator>
 <dc:creator>Lu, Zhiqin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Random backpropagation (RBP) is a variant of the backpropagation algorithm
for training neural networks, where the transpose of the forward matrices are
replaced by fixed random matrices in the calculation of the weight updates. It
is remarkable both because of its effectiveness, in spite of using random
matrices to communicate error information, and because it completely removes
the taxing requirement of maintaining symmetric weights in a physical neural
system. To better understand random backpropagation, we first connect it to the
notions of local learning and learning channels. Through this connection, we
derive several alternatives to RBP, including skipped RBP (SRPB), adaptive RBP
(ARBP), sparse RBP, and their combinations (e.g. ASRBP) and analyze their
computational complexity. We then study their behavior through simulations
using the MNIST and CIFAR-10 bechnmark datasets. These simulations show that
most of these variants work robustly, almost as well as backpropagation, and
that multiplication by the derivatives of the activation functions is
important. As a follow-up, we study also the low-end of the number of bits
required to communicate error information over the learning channel. We then
provide partial intuitive explanations for some of the remarkable properties of
RBP and its variations. Finally, we prove several mathematical results,
including the convergence to fixed points of linear chains of arbitrary length,
the convergence to fixed points of linear autoencoders with decorrelated data,
the long-term existence of solutions for linear systems with a single hidden
layer and convergence in special cases, and the convergence to fixed points of
non-linear chains, when the derivative of the activation functions is included.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02739</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controlling Robot Morphology from Incomplete Measurements</dc:title>
 <dc:creator>Pecka, Martin</dc:creator>
 <dc:creator>Zimmermann, Karel</dc:creator>
 <dc:creator>Rein&#x161;tein, Michal</dc:creator>
 <dc:creator>Svoboda, Tom&#xe1;&#x161;</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:description>  Mobile robots with complex morphology are essential for traversing rough
terrains in Urban Search &amp; Rescue missions (USAR). Since teleoperation of the
complex morphology causes high cognitive load of the operator, the morphology
is controlled autonomously. The autonomous control measures the robot state and
surrounding terrain which is usually only partially observable, and thus the
data are often incomplete. We marginalize the control over the missing
measurements and evaluate an explicit safety condition. If the safety condition
is violated, tactile terrain exploration by the body-mounted robotic arm
gathers the missing data.
</dc:description>
 <dc:description>Comment: Accepted into IEEE Transactions to Industrial Electronics, Special
  Section on Motion Control for Novel Emerging Robotic Devices and Systems</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02739</dc:identifier>
 <dc:identifier>doi:10.1109/TIE.2016.2580125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02741</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coupling Distributed and Symbolic Execution for Natural Language Queries</dc:title>
 <dc:creator>Mou, Lili</dc:creator>
 <dc:creator>Lu, Zhengdong</dc:creator>
 <dc:creator>Li, Hang</dc:creator>
 <dc:creator>Jin, Zhi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Building neural networks to query a knowledge base (a table) with natural
language is an emerging research topic in deep learning. An executor for table
querying typically requires multiple steps of execution because queries may
have complicated structures. In previous studies, researchers have developed
either fully distributed executors or symbolic executors for table querying. A
distributed executor can be trained in an end-to-end fashion, but is weak in
terms of execution efficiency and explicit interpretability. A symbolic
executor is efficient in execution, but is very difficult to train especially
at initial stages. In this paper, we propose to couple distributed and symbolic
execution for natural language queries, where the symbolic executor is
pretrained with the distributed executor's intermediate execution results in a
step-by-step fashion. Experiments show that our approach significantly
outperforms both distributed and symbolic executors, exhibiting high accuracy,
high learning efficiency, high execution efficiency, and high interpretability.
</dc:description>
 <dc:description>Comment: Accepted by ICML-17; also presented at ICLR-17 Workshop</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:date>2017-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02742</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Hand Detection and Rotation Estimation by Using CNN</dc:title>
 <dc:creator>Deng, Xiaoming</dc:creator>
 <dc:creator>Yuan, Ye</dc:creator>
 <dc:creator>Zhang, Yinda</dc:creator>
 <dc:creator>Tan, Ping</dc:creator>
 <dc:creator>Chang, Liang</dc:creator>
 <dc:creator>Yang, Shuo</dc:creator>
 <dc:creator>Wang, Hongan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Hand detection is essential for many hand related tasks, e.g. parsing hand
pose, understanding gesture, which are extremely useful for robotics and
human-computer interaction. However, hand detection in uncontrolled
environments is challenging due to the flexibility of wrist joint and cluttered
background. We propose a deep learning based approach which detects hands and
calibrates in-plane rotation under supervision at the same time. To guarantee
the recall, we propose a context aware proposal generation algorithm which
significantly outperforms the selective search. We then design a convolutional
neural network(CNN) which handles object rotation explicitly to jointly solve
the object detection and rotation estimation tasks. Experiments show that our
method achieves better results than state-of-the-art detection models on
widely-used benchmarks such as Oxford and Egohands database. We further show
that rotation estimation and classification can mutually benefit each other.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02751</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Protein-Ligand Scoring with Convolutional Neural Networks</dc:title>
 <dc:creator>Ragoza, Matthew</dc:creator>
 <dc:creator>Hochuli, Joshua</dc:creator>
 <dc:creator>Idrobo, Elisa</dc:creator>
 <dc:creator>Sunseri, Jocelyn</dc:creator>
 <dc:creator>Koes, David Ryan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:description>  Computational approaches to drug discovery can reduce the time and cost
associated with experimental assays and enable the screening of novel
chemotypes. Structure-based drug design methods rely on scoring functions to
rank and predict binding affinities and poses. The ever-expanding amount of
protein-ligand binding and structural data enables the use of deep machine
learning techniques for protein-ligand scoring.
  We describe convolutional neural network (CNN) scoring functions that take as
input a comprehensive 3D representation of a protein-ligand interaction. A CNN
scoring function automatically learns the key features of protein-ligand
interactions that correlate with binding. We train and optimize our CNN scoring
functions to discriminate between correct and incorrect binding poses and known
binders and non-binders. We find that our CNN scoring function outperforms the
AutoDock Vina scoring function when ranking poses both for pose prediction and
virtual screening.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02751</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02757</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchy through Composition with Linearly Solvable Markov Decision
  Processes</dc:title>
 <dc:creator>Saxe, Andrew M.</dc:creator>
 <dc:creator>Earle, Adam</dc:creator>
 <dc:creator>Rosman, Benjamin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Hierarchical architectures are critical to the scalability of reinforcement
learning methods. Current hierarchical frameworks execute actions serially,
with macro-actions comprising sequences of primitive actions. We propose a
novel alternative to these control hierarchies based on concurrent execution of
many actions in parallel. Our scheme uses the concurrent compositionality
provided by the linearly solvable Markov decision process (LMDP) framework,
which naturally enables a learning agent to draw on several macro-actions
simultaneously to solve new tasks. We introduce the Multitask LMDP module,
which maintains a parallel distributed representation of tasks and may be
stacked to form deep hierarchies abstracted in space and time.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02761</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Maximum A Posteriori Estimation Framework for Robust High Dynamic
  Range Video Synthesis</dc:title>
 <dc:creator>Li, Yuelong</dc:creator>
 <dc:creator>Lee, Chul</dc:creator>
 <dc:creator>Monga, Vishal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  High dynamic range (HDR) image synthesis from multiple low dynamic range
(LDR) exposures continues to be actively researched. The extension to HDR video
synthesis is a topic of significant current interest due to potential cost
benefits. For HDR video, a stiff practical challenge presents itself in the
form of accurate correspondence estimation of objects between video frames. In
particular, loss of data resulting from poor exposures and varying intensity
make conventional optical flow methods highly inaccurate. We avoid exact
correspondence estimation by proposing a statistical approach via maximum a
posterior (MAP) estimation, and under appropriate statistical assumptions and
choice of priors and models, we reduce it to an optimization problem of solving
for the foreground and background of the target frame. We obtain the background
through rank minimization and estimate the foreground via a novel multiscale
adaptive kernel regression technique, which implicitly captures local structure
and temporal motion by solving an unconstrained optimization problem. Extensive
experimental results on both real and synthetic datasets demonstrate that our
algorithm is more capable of delivering high-quality HDR videos than current
state-of-the-art methods, under both subjective and objective assessments.
Furthermore, a thorough complexity analysis reveals that our algorithm achieves
better complexity-performance trade-off than conventional methods.
</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02761</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2642790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02766</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feedback Neural Network for Weakly Supervised Geo-Semantic Segmentation</dc:title>
 <dc:creator>Liu, Xianming</dc:creator>
 <dc:creator>Zhang, Amy</dc:creator>
 <dc:creator>Tiecke, Tobias</dc:creator>
 <dc:creator>Gros, Andreas</dc:creator>
 <dc:creator>Huang, Thomas S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning from weakly-supervised data is one of the main challenges in machine
learning and computer vision, especially for tasks such as image semantic
segmentation where labeling is extremely expensive and subjective. In this
paper, we propose a novel neural network architecture to perform
weakly-supervised learning by suppressing irrelevant neuron activations. It
localizes objects of interest by learning from image-level categorical labels
in an end-to-end manner. We apply this algorithm to a practical challenge of
transforming satellite images into a map of settlements and individual
buildings. Experimental results show that the proposed algorithm achieves
superior performance and efficiency when compared with various baseline models.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.02780</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved generator objectives for GANs</dc:title>
 <dc:creator>Poole, Ben</dc:creator>
 <dc:creator>Alemi, Alexander A.</dc:creator>
 <dc:creator>Sohl-Dickstein, Jascha</dc:creator>
 <dc:creator>Angelova, Anelia</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a framework to understand GAN training as alternating density
ratio estimation and approximate divergence minimization. This provides an
interpretation for the mismatched GAN generator and discriminator objectives
often used in practice, and explains the problem of poor sample diversity. We
also derive a family of generator objectives that target arbitrary
$f$-divergences without minimizing a lower bound, and use them to train
generative image models that target either improved sample quality or greater
sample diversity.
</dc:description>
 <dc:description>Comment: NIPS 2016 Workshop on Adversarial Training</dc:description>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.02780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="111000" completeListSize="155308">2369777|112001</resumptionToken>
</ListRecords>
</OAI-PMH>
