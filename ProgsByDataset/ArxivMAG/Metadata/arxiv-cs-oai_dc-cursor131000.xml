<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:35:26Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|131001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01639</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Treatment of Reactive Routing Protocols Using Second Chance Based On
  Malicious Behavior of Nodes in MANETS</dc:title>
 <dc:creator>Belgaum, Mohammad Riyaz</dc:creator>
 <dc:creator>Soomro, Safeeullah</dc:creator>
 <dc:creator>Alansari, Zainab</dc:creator>
 <dc:creator>Alam, Muhammad</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Mobile nodes of various routing protocols in Mobile Ad hoc Networks follow
different strategies in transmission and receiving of data. Security, packet
delivery and routing overhead are important concerns for any protocol during
designing them. The presence and absence of malicious nodes in the network
affect a lot on the performance of the protocol. This research is mainly
focused on the study of the threats, attacks and reasons for malicious behavior
of nodes in the network for reactive routing protocols in MANETS. DSR and AODV
are the two reactive routing protocols that were considered for the study to
propose a second chance strategy to be given to the nodes considering the
reason for malicious behavior to improve the packet delivery ratio and reduce
the routing overhead in the network. A simulative study has been conducted
using Ad hoc Simulator (ASIM) considering the DSR and AODV routing protocols in
the presence of malicious nodes and in the absence of malicious nodes which
showed that the packet delivery ratio is low and routing overhead is high in
the absence of malicious nodes. The second chance strategy proposed considers
the reasons for malicious behavior and helps the node to get reintegrated in
the network to improve the packet delivery ratio and reduce the routing
overhead.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01640</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Speech-driven Animation with Meaningful Behaviors</dc:title>
 <dc:creator>Sadoughi, Najmeh</dc:creator>
 <dc:creator>Busso, Carlos</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Conversational agents (CAs) play an important role in human computer
interaction. Creating believable movements for CAs is challenging, since the
movements have to be meaningful and natural, reflecting the coupling between
gestures and speech. Studies in the past have mainly relied on rule-based or
data-driven approaches. Rule-based methods focus on creating meaningful
behaviors conveying the underlying message, but the gestures cannot be easily
synchronized with speech. Data-driven approaches, especially speech-driven
models, can capture the relationship between speech and gestures. However, they
create behaviors disregarding the meaning of the message. This study proposes
to bridge the gap between these two approaches overcoming their limitations.
The approach builds a dynamic Bayesian network (DBN), where a discrete variable
is added to constrain the behaviors on the underlying constraint. The study
implements and evaluates the approach with two constraints: discourse functions
and prototypical behaviors. By constraining on the discourse functions (e.g.,
questions), the model learns the characteristic behaviors associated with a
given discourse class learning the rules from the data. By constraining on
prototypical behaviors (e.g., head nods), the approach can be embedded in a
rule-based system as a behavior realizer creating trajectories that are timely
synchronized with speech. The study proposes a DBN structure and a training
approach that (1) models the cause-effect relationship between the constraint
and the gestures, (2) initializes the state configuration models increasing the
range of the generated behaviors, and (3) captures the differences in the
behaviors across constraints by enforcing sparse transitions between shared and
exclusive states per constraint. Objective and subjective evaluations
demonstrate the benefits of the proposed approach over an unconstrained model.
</dc:description>
 <dc:description>Comment: 13 pages, 12 figures, 5 tables</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01641</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localizing Moments in Video with Natural Language</dc:title>
 <dc:creator>Hendricks, Lisa Anne</dc:creator>
 <dc:creator>Wang, Oliver</dc:creator>
 <dc:creator>Shechtman, Eli</dc:creator>
 <dc:creator>Sivic, Josef</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:creator>Russell, Bryan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We consider retrieving a specific temporal segment, or moment, from a video
given a natural language text description. Methods designed to retrieve whole
video clips with natural language determine what occurs in a video but not
when. To address this issue, we propose the Moment Context Network (MCN) which
effectively localizes natural language queries in videos by integrating local
and global video features over time. A key obstacle to training our MCN model
is that current video datasets do not include pairs of localized video segments
and referring expressions, or text descriptions which uniquely identify a
corresponding moment. Therefore, we collect the Distinct Describable Moments
(DiDeMo) dataset which consists of over 10,000 unedited, personal videos in
diverse visual settings with pairs of localized video segments and referring
expressions. We demonstrate that MCN outperforms several baseline methods and
believe that our initial results together with the release of DiDeMo will
inspire further research on localizing video moments with natural language.
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01642</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cut, Paste and Learn: Surprisingly Easy Synthesis for Instance Detection</dc:title>
 <dc:creator>Dwibedi, Debidatta</dc:creator>
 <dc:creator>Misra, Ishan</dc:creator>
 <dc:creator>Hebert, Martial</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A major impediment in rapidly deploying object detection models for instance
detection is the lack of large annotated datasets. For example, finding a large
labeled dataset containing instances in a particular kitchen is unlikely. Each
new environment with new instances requires expensive data collection and
annotation. In this paper, we propose a simple approach to generate large
annotated instance datasets with minimal effort. Our key insight is that
ensuring only patch-level realism provides enough training signal for current
object detector models. We automatically `cut' object instances and `paste'
them on random backgrounds. A naive way to do this results in pixel artifacts
which result in poor performance for trained models. We show how to make
detectors ignore these artifacts during training and generate data that gives
competitive performance on real data. Our method outperforms existing synthesis
approaches and when combined with real images improves relative performance by
more than 21% on benchmark datasets. In a cross-domain setting, our synthetic
data combined with just 10% real data outperforms models trained on all real
data.
</dc:description>
 <dc:description>Comment: To appear in ICCV 2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01643</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensuring patients privacy in a cryptographic-based-electronic health
  records using bio-cryptography</dc:title>
 <dc:creator>Omotosho, Adebayo</dc:creator>
 <dc:creator>Emuoyibofarhe, Justice</dc:creator>
 <dc:creator>Meinel, Christoph</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Several recent works have proposed and implemented cryptography as a means to
preserve privacy and security of patients health data. Nevertheless, the
weakest point of electronic health record (EHR) systems that relied on these
cryptographic schemes is key management. Thus, this paper presents the
development of privacy and security system for cryptography-based-EHR by taking
advantage of the uniqueness of fingerprint and iris characteristic features to
secure cryptographic keys in a bio-cryptography framework. The results of the
system evaluation showed significant improvements in terms of time efficiency
of this approach to cryptographic-based-EHR. Both the fuzzy vault and fuzzy
commitment demonstrated false acceptance rate (FAR) of 0%, which reduces the
likelihood of imposters gaining successful access to the keys protecting
patients protected health information. This result also justifies the
feasibility of implementing fuzzy key binding scheme in real applications,
especially fuzzy vault which demonstrated a better performance during key
reconstruction.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01643</dc:identifier>
 <dc:identifier>International Journal of Electronic Healthcare (IJEH), Vol. 9, No.
  4, pp.227 - 254 (2017)</dc:identifier>
 <dc:identifier>doi:10.1504/IJEH.2017.10003030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01646</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matrix rigidity and the Croot-Lev-Pach lemma</dc:title>
 <dc:creator>Dvir, Zeev</dc:creator>
 <dc:creator>Edelman, Benjamin</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Matrix rigidity is a notion put forth by Valiant as a means for proving
arithmetic circuit lower bounds. A matrix is rigid if it is far, in Hamming
distance, from any low rank matrix. Despite decades of efforts, no explicit
matrix rigid enough to carry out Valiant's plan has been found. Recently, Alman
and Williams showed, contrary to common belief, that the $2^n \times 2^n$
Hadamard matrix could not be used for Valiant's program as it is not
sufficiently rigid. In this note we observe a similar `non rigidity' phenomena
for any $q^n \times q^n$ matrix $M$ of the form $M(x,y) = f(x+y)$, where
$f:F_q^n \to F_q$ is any function and $F_q$ is a fixed finite field of $q$
elements ($n$ goes to infinity). The theorem follows almost immediately from a
recent lemma of Croot, Lev and Pach which is also the main ingredient in the
recent solution of the cap-set problem.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01647</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamics on networks. Case of Heterogeneous Opinion Status Model</dc:title>
 <dc:creator>Tupikina, Liubov</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Here we developed a new conceptual, stochastic Heterogeneous Opinion-Status
model (HOpS model), which is adaptive network model. The HOpS model admits to
identify the main attributes of dynamics on networks and to study analytically
the relation between topological network properties and processes taking place
on a network. Another key point of the HOpS model is the possibility to study
network dynamics via the novel parameter of heterogeneity. We show that not
only clear topological network properties, such as node degree, but also, the
nodes' status distribution (the factor of network heterogeneity) play an
important role in so-called opinion spreading and information diffusion on a
network. This model can be potentially used for studying the co-evolution of
globally aggregated or averaged key observables of the earth system. These
include natural variables such as atmospheric, oceanic and land carbon stocks,
as well as socio-economic quantities such as global human population, economic
production or wellbeing.
</dc:description>
 <dc:description>Comment: This model has been develope in PIK (Potsdam Climate Institute),
  Germany, as part of my Phd in the group of Prof.Kurths and together with
  Jobst Heitzig. It has not been published elsewhere except as part of my
  thesis in HU, Berlin University</dc:description>
 <dc:date>2017-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01648</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks</dc:title>
 <dc:creator>Zou, Chuhang</dc:creator>
 <dc:creator>Yumer, Ersin</dc:creator>
 <dc:creator>Yang, Jimei</dc:creator>
 <dc:creator>Ceylan, Duygu</dc:creator>
 <dc:creator>Hoiem, Derek</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The success of various applications including robotics, digital content
creation, and visualization demand a structured and abstract representation of
the 3D world from limited sensor data. Inspired by the nature of human
perception of 3D shapes as a collection of simple parts, we explore such an
abstract shape representation based on primitives. Given a single depth image
of an object, we present 3D-PRNN, a generative recurrent neural network that
synthesizes multiple plausible shapes composed of a set of primitives. Our
generative model encodes symmetry characteristics of common man-made objects,
preserves long-range structural coherence, and describes objects of varying
complexity with a compact representation. We also propose a method based on
Gaussian Fields to generate a large scale dataset of primitive-based shape
representations to train our network. We evaluate our approach on a wide range
of examples and show that it outperforms nearest-neighbor based shape retrieval
methods and is on-par with voxel-based generative models while using a
significantly reduced parameter space.
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01650</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BDCI: Behavioral Driven Conflict Identification</dc:title>
 <dc:creator>Pastore, Fabrizio</dc:creator>
 <dc:creator>Mariani, Leonardo</dc:creator>
 <dc:creator>Micucci, Daniela</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Source Code Management (SCM) systems support software evolution by providing
features, such as version control, branching, and conflict detection. Despite
the presence of these features, support to parallel software development is
often limited. SCM systems can only address a subset of the conflicts that
might be introduced by developers when concurrently working on multiple
parallel branches. In fact, SCM systems can detect textual conflicts, which are
generated by the concurrent modification of the same program locations, but
they are unable to detect higher-order conflicts, which are generated by the
concurrent modification of different program locations that generate program
misbehaviors once merged. Higher-order conflicts are painful to detect and
expensive to fix because they might be originated by the interference of
apparently unrelated changes. In this paper we present Behavioral Driven
Conflict Identification (BDCI), a novel approach to conflict detection. BDCI
moves the analysis of conflicts from the source code level to the level of
program behavior by generating and comparing behavioral models. The analysis
based on behavioral models can reveal interfering changes as soon as they are
introduced in the SCM system, even if they do not introduce any textual
conflict. To evaluate the effectiveness and the cost of the proposed approach,
we developed BDCIf , a specific instance of BDCI dedicated to the detection of
higher-order conflicts related to the functional behavior of a program. The
evidence collected by analyzing multiple versions of Git and Redis suggests
that BDCIf can effectively detect higher-order conflicts and report how changes
might interfere.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01650</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01654</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Better Together: Joint Reasoning for Non-rigid 3D Reconstruction with
  Specularities and Shading</dc:title>
 <dc:creator>Liu-Yin, Qi</dc:creator>
 <dc:creator>Yu, Rui</dc:creator>
 <dc:creator>Agapito, Lourdes</dc:creator>
 <dc:creator>Fitzgibbon, Andrew</dc:creator>
 <dc:creator>Russell, Chris</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We demonstrate the use of shape-from-shading (SfS) to improve both the
quality and the robustness of 3D reconstruction of dynamic objects captured by
a single camera. Unlike previous approaches that made use of SfS as a
post-processing step, we offer a principled integrated approach that solves
dynamic object tracking and reconstruction and SfS as a single unified cost
function. Moving beyond Lambertian S f S , we propose a general approach that
models both specularities and shading while simultaneously tracking and
reconstructing general dynamic objects. Solving these problems jointly prevents
the kinds of tracking failures which can not be recovered from by pipeline
approaches. We show state-of-the-art results both qualitatively and
quantitatively.
</dc:description>
 <dc:description>Comment: Submitted to IJCV</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01657</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple PTAS for the Dual Bin Packing Problem and Advice Complexity of
  Its Online Version</dc:title>
 <dc:creator>Borodin, Allan</dc:creator>
 <dc:creator>Pankratov, Denis</dc:creator>
 <dc:creator>Salehi-Abari, Amirali</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Recently, Renault (2016) studied the dual bin packing problem in the
per-request advice model of online algorithms. He showed that given
$O(1/\epsilon)$ advice bits for each input item allows approximating the dual
bin packing problem online to within a factor of $1+\epsilon$. Renault asked
about the advice complexity of dual bin packing in the tape-advice model of
online algorithms. We make progress on this question. Let $s$ be the maximum
bit size of an input item weight. We present a conceptually simple online
algorithm that with total advice $O\left(\frac{s + \log n}{\epsilon^2}\right)$
approximates the dual bin packing to within a $1+\epsilon$ factor. To this end,
we describe and analyze a simple offline PTAS for the dual bin packing problem.
Although a PTAS for a more general problem was known prior to our work
(Kellerer 1999, Chekuri and Khanna 2006), our PTAS is arguably simpler to state
and analyze. As a result, we could easily adapt our PTAS to obtain the
advice-complexity result.
  We also consider whether the dependence on $s$ is necessary in our algorithm.
We show that if $s$ is unrestricted then for small enough $\epsilon &gt; 0$
obtaining a $1+\epsilon$ approximation to the dual bin packing requires
$\Omega_\epsilon(n)$ bits of advice. To establish this lower bound we analyze
an online reduction that preserves the advice complexity and approximation
ratio from the binary separation problem due to Boyar et al. (2016). We define
two natural advice complexity classes that capture the distinction similar to
the Turing machine world distinction between pseudo polynomial time algorithms
and polynomial time algorithms. Our results on the dual bin packing problem
imply the separation of the two classes in the advice complexity world.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01658</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Features for Predicting Policy Citations</dc:title>
 <dc:creator>Bailey, Christian</dc:creator>
 <dc:creator>Kale, Bharat</dc:creator>
 <dc:creator>Walker, Jamieson</dc:creator>
 <dc:creator>Siravuri, Harish Varma</dc:creator>
 <dc:creator>Alhoori, Hamed</dc:creator>
 <dc:creator>Papka, Micheal E.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  In this study we performed an initial investigation and evaluation of
altmetrics and their relationship with public policy citation of research
papers. We examined methods for using altmetrics and other data to predict
whether a research paper is cited in public policy and applied receiver
operating characteristic curve on various feature groups in order to evaluate
their potential usefulness. From the methods we tested, classifying based on
tweet count provided the best results, achieving an area under the ROC curve of
0.91.
</dc:description>
 <dc:description>Comment: 2 pages, accepted to JCDL '17</dc:description>
 <dc:date>2017-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01659</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HTM-MAT: An online prediction software toolbox based on cortical machine
  learning algorithm</dc:title>
 <dc:creator>Anireh, V. I.</dc:creator>
 <dc:creator>Osegi, EN</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  HTM-MAT is a MATLAB based toolbox for implementing cortical learning
algorithms (CLA) including related cortical-like algorithms that possesses
spatiotemporal properties. CLA is a suite of predictive machine learning
algorithms developed by Numenta Inc. and is based on the hierarchical temporal
memory (HTM). This paper presents an implementation of HTM-MAT with several
illustrative examples including several toy datasets and compared with two
sequence learning applications employing state-of-the-art algorithms - the
recurrentjs based on the Long Short-Term Memory (LSTM) algorithm and OS-ELM
which is based on an online sequential version of the Extreme Learning Machine.
The performance of HTM-MAT using two historical benchmark datasets and one real
world dataset is also compared with one of the existing sequence learning
applications, the OS-ELM. The results indicate that HTM-MAT predictions are
indeed competitive and can outperform OS-ELM in sequential prediction tasks.
</dc:description>
 <dc:description>Comment: This research is currently under review in a Journal. Contents might
  vary from final published version</dc:description>
 <dc:date>2017-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01663</identifier>
 <datestamp>2017-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerated Image Reconstruction for Nonlinear Diffractive Imaging</dc:title>
 <dc:creator>Ma, Yanting</dc:creator>
 <dc:creator>Mansour, Hassan</dc:creator>
 <dc:creator>Liu, Dehong</dc:creator>
 <dc:creator>Boufounos, Petros T.</dc:creator>
 <dc:creator>Kamilov, Ulugbek S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The problem of reconstructing an object from the measurements of the light it
scatters is common in numerous imaging applications. While the most popular
formulations of the problem are based on linearizing the object-light
relationship, there is an increased interest in considering nonlinear
formulations that can account for multiple light scattering. In this paper, we
propose an image reconstruction method, called CISOR, for nonlinear diffractive
imaging, based on a nonconvex optimization formulation with total variation
(TV) regularization. The nonconvex solver used in CISOR is our new variant of
fast iterative shrinkage/thresholding algorithm (FISTA). We provide fast and
memory-efficient implementation of the new FISTA variant and prove that it
reliably converges for our nonconvex optimization problem. In addition, we
systematically compare our method with other state-of-the-art methods on
simulated as well as experimentally measured data in both 2D and 3D settings.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01664</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Waveform and Spectrum Management for Unmanned Aerial Systems Beyond 2025</dc:title>
 <dc:creator>Kakar, Jaber</dc:creator>
 <dc:creator>Marojevic, Vuk</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The application domains of civilian unmanned aerial systems (UASs) include
agriculture, exploration, transportation, and entertainment. The expected
growth of the UAS industry brings along new challenges: Unmanned aerial vehicle
(UAV) flight control signaling requires low throughput, but extremely high
reliability, whereas the data rate for payload data can be significant. This
paper develops UAV number projections and concludes that small and micro UAVs
will dominate the US airspace with accelerated growth between 2028 and 2032. We
analyze the orthogonal frequency division multiplexing (OFDM) waveform because
it can provide the much needed flexibility, spectral efficiency, and,
potentially, reliability and derive suitable OFDM waveform parameters as a
function of UAV flight characteristics. OFDM also lends itself to agile
spectrum access. Based on our UAV growth predictions, we conclude that dynamic
spectrum access is needed and discuss the applicability of spectrum sharing
techniques for future UAS communications.
</dc:description>
 <dc:description>Comment: 5 pages, PIMRC 2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01666</identifier>
 <datestamp>2017-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Effective Training Method For Deep Convolutional Neural Network</dc:title>
 <dc:creator>Jiang, Yang</dc:creator>
 <dc:creator>Dou, Zeyang</dc:creator>
 <dc:creator>Hao, Qun</dc:creator>
 <dc:creator>Cao, Jie</dc:creator>
 <dc:creator>Gao, Kun</dc:creator>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose the nonlinearity generation method to speed up and
stabilize the training of deep convolutional neural networks. The proposed
method modifies a family of activation functions as nonlinearity generators
(NGs). NGs make the activation functions linear symmetric for their inputs to
lower model capacity, and automatically introduce nonlinearity to enhance the
capacity of the model during training. The proposed method can be considered an
unusual form of regularization: the model parameters are obtained by training a
relatively low-capacity model, that is relatively easy to optimize at the
beginning, with only a few iterations, and these parameters are reused for the
initialization of a higher-capacity model. We derive the upper and lower bounds
of variance of the weight variation, and show that the initial symmetric
structure of NGs helps stabilize training. We evaluate the proposed method on
different frameworks of convolutional neural networks over two object
recognition benchmark tasks (CIFAR-10 and CIFAR-100). Experimental results
showed that the proposed method allows us to (1) speed up the convergence of
training, (2) allow for less careful weight initialization, (3) improve or at
least maintain the performance of the model at negligible extra computational
cost, and (4) easily train a very deep model.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01670</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intrinsic3D: High-Quality 3D Reconstruction by Joint Appearance and
  Geometry Optimization with Spatially-Varying Lighting</dc:title>
 <dc:creator>Maier, Robert</dc:creator>
 <dc:creator>Kim, Kihwan</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:creator>Kautz, Jan</dc:creator>
 <dc:creator>Nie&#xdf;ner, Matthias</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a novel method to obtain high-quality 3D reconstructions from
consumer RGB-D sensors. Our core idea is to simultaneously optimize for
geometry encoded in a signed distance field (SDF), textures from
automatically-selected keyframes, and their camera poses along with material
and scene lighting. To this end, we propose a joint surface reconstruction
approach that is based on Shape-from-Shading (SfS) techniques and utilizes the
estimation of spatially-varying spherical harmonics (SVSH) from subvolumes of
the reconstructed scene. Through extensive examples and evaluations, we
demonstrate that our method dramatically increases the level of detail in the
reconstructed scene geometry and contributes highly to consistent surface
texture recovery.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01673</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Resource Pooling and Separation for LRU Caching</dc:title>
 <dc:creator>Tan, Jian</dc:creator>
 <dc:creator>Quan, Guocong</dc:creator>
 <dc:creator>Ji, Kaiyi</dc:creator>
 <dc:creator>Shroff, Ness</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Caching systems using the Least Recently Used (LRU) principle have now become
ubiquitous. A fundamental question for these systems is whether the cache space
should be pooled together or divided to serve multiple flows of data item
requests in order to minimize the miss probabilities. In this paper, we show
that there is no straight yes or no answer to this question, depending on
complex combinations of critical factors, including, e.g., request rates,
overlapped data items across different request flows, data item popularities
and their sizes. Specifically, we characterize the asymptotic miss
probabilities for multiple competing request flows under resource pooling and
separation for LRU caching when the cache size is large.
  Analytically, we show that it is asymptotically optimal to jointly serve
multiple flows if their data item sizes and popularity distributions are
similar and their arrival rates do not differ significantly; the
self-organizing property of LRU caching automatically optimizes the resource
allocation among them asymptotically. Otherwise, separating these flows could
be better, e.g., when data sizes vary significantly. We also quantify critical
points beyond which resource pooling is better than separation for each of the
flows when the overlapped data items exceed certain levels. Technically, we
generalize existing results on the asymptotic miss probability of LRU caching
for a broad class of heavy-tailed distributions and extend them to multiple
competing flows with varying data item sizes, which also validates the Che
approximation under certain conditions. These results provide new insights on
improving the performance of caching systems.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01673</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01676</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query-guided Regression Network with Context Policy for Phrase Grounding</dc:title>
 <dc:creator>Chen, Kan</dc:creator>
 <dc:creator>Kovvuri, Rama</dc:creator>
 <dc:creator>Nevatia, Ram</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given a textual description of an image, phrase grounding localizes objects
in the image referred by query phrases in the description. State-of-the-art
methods address the problem by ranking a set of proposals based on the
relevance to each query, which are limited by the performance of independent
proposal generation systems and ignore useful cues from context in the
description. In this paper, we adopt a spatial regression method to break the
performance limit, and introduce reinforcement learning techniques to further
leverage semantic context information. We propose a novel Query-guided
Regression network with Context policy (QRC Net) which jointly learns a
Proposal Generation Network (PGN), a Query-guided Regression Network (QRN) and
a Context Policy Network (CPN). Experiments show QRC Net provides a significant
improvement in accuracy on two popular datasets: Flickr30K Entities and Referit
Game, with 14.25% and 17.14% increase over the state-of-the-arts respectively.
</dc:description>
 <dc:description>Comment: Spotlight in ICCV 2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01677</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A network approach to topic models</dc:title>
 <dc:creator>Gerlach, Martin</dc:creator>
 <dc:creator>Peixoto, Tiago P.</dc:creator>
 <dc:creator>Altmann, Eduardo G.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  One of the main computational and scientific challenges in the modern age is
to extract useful information from unstructured texts. Topic models are one
popular machine-learning approach which infers the latent topical structure of
a collection of documents. Despite their success --- in particular of its most
widely used variant called Latent Dirichlet Allocation (LDA) --- and numerous
applications in sociology, history, and linguistics, topic models are known to
suffer from severe conceptual and practical problems, e.g. a lack of
justification for the Bayesian priors, discrepancies with statistical
properties of real texts, and the inability to properly choose the number of
topics. Here, we approach the problem of identifying topical structures by
representing text corpora as bipartite networks of documents and words and
using methods from community detection in complex networks, in particular
stochastic block models (SBM). We show that our SBM-based approach constitutes
a more principled and versatile framework for topic modeling solving the
intrinsic limitations of Dirichlet-based models through a more general choice
of nonparametric priors. It automatically detects the number of topics and
hierarchically clusters both the words and documents. In practice, we
demonstrate through the analysis of artificial and real corpora that our
approach outperforms LDA in terms of statistical model selection.
</dc:description>
 <dc:description>Comment: 19 pages, 8 figures</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01679</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scoped Extension Methods in Dynamically-Typed Languages</dc:title>
 <dc:creator>Polito, Guillermo</dc:creator>
 <dc:creator>Teruel, Camille</dc:creator>
 <dc:creator>Ducasse, St&#xe9;phane</dc:creator>
 <dc:creator>Fabresse, Luc</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Context. An extension method is a method declared in a package other than the
package of its host class. Thanks to extension methods, developers can adapt to
their needs classes they do not own: adding methods to core classes is a
typical use case. This is particularly useful for adapting software and
therefore to increase reusability.
  Inquiry. In most dynamically-typed languages, extension methods are globally
visible. Because any developer can define extension methods for any class,
naming conflicts occur: if two developers define an extension method with the
same signature in the same class, only one extension method is visible and
overwrites the other. Similarly, if two developers each define an extension
method with the same name in a class hierarchy, one overrides the other. To
avoid such &quot;accidental overrides&quot;, some dynamically-typed languages limit the
visibility of an extension method to a particular scope. However, their
semantics have not been fully described and compared. In addition, these
solutions typically rely on a dedicated and slow method lookup algorithm to
resolve conflicts at runtime.
  Approach. In this article, we present a formalization of the underlying
models of Ruby refinements, Groovy categories, Classboxes, and Method Shelters
that are scoping extension method solutions in dynamically-typed languages.
  Knowledge. Our formal framework allows us to objectively compare and analyze
the shortcomings of the studied solutions and other different approaches such
as MultiJava. In addition, language designers can use our formal framework to
determine which mechanism has less risk of &quot;accidental overrides&quot;.
  Grounding. Our comparison and analysis of existing solutions is grounded
because it is based on denotational semantics formalizations.
  Importance. Extension methods are widely used in programming languages that
support them, especially dynamically-typed languages such as Pharo, Ruby or
Python. However, without a carefully designed mechanism, this feature can cause
insidious hidden bugs or can be voluntarily used to gain access to protected
operations, violate encapsulation or break fundamental invariants.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01679</dc:identifier>
 <dc:identifier>The Art, Science, and Engineering of Programming, 2018, Vol. 2,
  Issue 1, Article 1</dc:identifier>
 <dc:identifier>doi:10.22152/programming-journal.org/2018/2/1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01680</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Effect of Semantically Enriched Context Models on Software
  Modularization</dc:title>
 <dc:creator>Saeidi, Amir</dc:creator>
 <dc:creator>Hage, Jurriaan</dc:creator>
 <dc:creator>Khadka, Ravi</dc:creator>
 <dc:creator>Jansen, Slinger</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Many of the existing approaches for program comprehension rely on the
linguistic information found in source code, such as identifier names and
comments. Semantic clustering is one such technique for modularization of the
system that relies on the informal semantics of the program, encoded in the
vocabulary used in the source code. Treating the source code as a collection of
tokens loses the semantic information embedded within the identifiers. We try
to overcome this problem by introducing context models for source code
identifiers to obtain a semantic kernel, which can be used for both deriving
the topics that run through the system as well as their clustering. In the
first model, we abstract an identifier to its type representation and build on
this notion of context to construct contextual vector representation of the
source code. The second notion of context is defined based on the flow of data
between identifiers to represent a module as a dependency graph where the nodes
correspond to identifiers and the edges represent the data dependencies between
pairs of identifiers. We have applied our approach to 10 medium-sized open
source Java projects, and show that by introducing contexts for identifiers,
the quality of the modularization of the software systems is improved. Both of
the context models give results that are superior to the plain vector
representation of documents. In some cases, the authoritativeness of
decompositions is improved by 67%. Furthermore, a more detailed evaluation of
our approach on JEdit, an open source editor, demonstrates that inferred topics
through performing topic analysis on the contextual representations are more
meaningful compared to the plain representation of the documents. The proposed
approach in introducing a context model for source code identifiers paves the
way for building tools that support developers in program comprehension tasks
such as application and domain concept location, software modularization and
topic analysis.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01680</dc:identifier>
 <dc:identifier>The Art, Science, and Engineering of Programming, 2018, Vol. 2,
  Issue 1, Article 2</dc:identifier>
 <dc:identifier>doi:10.22152/programming-journal.org/2018/2/2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01681</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting the Law Area and Decisions of French Supreme Court Cases</dc:title>
 <dc:creator>Sulea, Octavia-Maria</dc:creator>
 <dc:creator>Zampieri, Marcos</dc:creator>
 <dc:creator>Vela, Mihaela</dc:creator>
 <dc:creator>van Genabith, Josef</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we investigate the application of text classification methods
to predict the law area and the decision of cases judged by the French Supreme
Court. We also investigate the influence of the time period in which a ruling
was made over the textual form of the case description and the extent to which
it is necessary to mask the judge's motivation for a ruling to emulate a
real-world test scenario. We report results of 96% f1 score in predicting a
case ruling, 90% f1 score in predicting the law area of a case, and 75.9% f1
score in estimating the time span when a ruling has been issued using a linear
Support Vector Machine (SVM) classifier trained on lexical features.
</dc:description>
 <dc:description>Comment: RANLP 2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01682</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Metric Learning with Angular Loss</dc:title>
 <dc:creator>Wang, Jian</dc:creator>
 <dc:creator>Zhou, Feng</dc:creator>
 <dc:creator>Wen, Shilei</dc:creator>
 <dc:creator>Liu, Xiao</dc:creator>
 <dc:creator>Lin, Yuanqing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The modern image search system requires semantic understanding of image, and
a key yet under-addressed problem is to learn a good metric for measuring the
similarity between images. While deep metric learning has yielded impressive
performance gains by extracting high level abstractions from image data, a
proper objective loss function becomes the central issue to boost the
performance. In this paper, we propose a novel angular loss, which takes angle
relationship into account, for learning better similarity metric. Whereas
previous metric learning methods focus on optimizing the similarity
(contrastive loss) or relative similarity (triplet loss) of image pairs, our
proposed method aims at constraining the angle at the negative point of triplet
triangles. Several favorable properties are observed when compared with
conventional methods. First, scale invariance is introduced, improving the
robustness of objective against feature variance. Second, a third-order
geometric constraint is inherently imposed, capturing additional local
structure of triplet triangles than contrastive loss or triplet loss. Third,
better convergence has been demonstrated by experiments on three publicly
available datasets.
</dc:description>
 <dc:description>Comment: International Conference on Computer Vision 2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01688</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Abstract Hidden Markov Models: a monadic account of quantitative
  information flow</dc:title>
 <dc:creator>McIver, Annabelle</dc:creator>
 <dc:creator>Morgan, Carroll</dc:creator>
 <dc:creator>Rabehaja, Tahiry</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Hidden Markov Models, \HMM's, are mathematical models of Markov processes
with state that is hidden, but from which information can leak. They are
typically represented as 3-way joint-probability distributions.
  We use HMM's as denotations of probabilistic hidden-state sequential
programs: for that, we recast them as &quot;abstract&quot; HMM's, computations in the
Giry monad D, and equip we them with a partial order of increasing security.
However to encode the monadic type with hiding over some state X we use DX-&gt;D2X
rather than the conventional X-&gt;DX that suffices for Markov models whose state
is not hidden. We illustrate the DX-&gt;D2X construction with a small Haskell
prototype.
  We then present uncertainty measures as a generalisation of the extant
diversity of probabilistic entropies, with characteristic analytic properties
for them, and show how the new entropies interact with the order of increasing
security. Furthermore, we give a &quot;backwards&quot; uncertainty-transformer semantics
for HMM's that is dual to the &quot;forwards&quot; abstract HMM's --- it is an analogue
of the duality between forwards, relational semantics and backwards,
predicate-transformer semantics for imperative programs with demonic choice.
  Finally, we argue that, from this new denotational-semantic viewpoint, one
can see that the Dalenius desideratum for statistical databases is actually an
issue in compositionality. We propose a means for taking it into account.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01692</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Frame Interpolation via Adaptive Separable Convolution</dc:title>
 <dc:creator>Niklaus, Simon</dc:creator>
 <dc:creator>Mai, Long</dc:creator>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Standard video frame interpolation methods first estimate optical flow
between input frames and then synthesize an intermediate frame guided by
motion. Recent approaches merge these two steps into a single convolution
process by convolving input frames with spatially adaptive kernels that account
for motion and re-sampling simultaneously. These methods require large kernels
to handle large motion, which limits the number of pixels whose kernels can be
estimated at once due to the large memory demand. To address this problem, this
paper formulates frame interpolation as local separable convolution over input
frames using pairs of 1D kernels. Compared to regular 2D kernels, the 1D
kernels require significantly fewer parameters to be estimated. Our method
develops a deep fully convolutional neural network that takes two input frames
and estimates pairs of 1D kernels for all pixels simultaneously. Since our
method is able to estimate kernels and synthesizes the whole video frame at
once, it allows for the incorporation of perceptual loss to train the neural
network to produce visually pleasing frames. This deep neural network is
trained end-to-end using widely available video data without any human
annotation. Both qualitative and quantitative experiments show that our method
provides a practical solution to high-quality video frame interpolation.
</dc:description>
 <dc:description>Comment: ICCV 2017, http://graphics.cs.pdx.edu/project/sepconv/</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01696</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study of Sparsity-Aware Set-Membership Adaptive Algorithms with
  Adjustable Penalties</dc:title>
 <dc:creator>Flores, Andr&#xe9;</dc:creator>
 <dc:creator>de Lamare, Rodrigo C.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we propose sparsity-aware data-selective adaptive filtering
algorithms with adjustable penalties. Prior work incorporates a penalty
function into the cost function used in the optimization that originates the
algorithms to improve their performance by exploiting sparsity. However, the
strength of the penalty function is controlled by a scalar that is often a
fixed parameter. In contrast to prior work, we develop a framework to derive
algorithms that automatically adjust the penalty function parameter and the
step size to achieve a better performance. Simulations for a system
identification application show that the proposed algorithms outperform in
convergence speed existing sparsity-aware algorithms.
</dc:description>
 <dc:description>Comment: 4 figures, 2 tables</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01697</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Robustness: Softmax versus Openmax</dc:title>
 <dc:creator>Rozsa, Andras</dc:creator>
 <dc:creator>G&#xfc;nther, Manuel</dc:creator>
 <dc:creator>Boult, Terrance E.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep neural networks (DNNs) provide state-of-the-art results on various tasks
and are widely used in real world applications. However, it was discovered that
machine learning models, including the best performing DNNs, suffer from a
fundamental problem: they can unexpectedly and confidently misclassify examples
formed by slightly perturbing otherwise correctly recognized inputs. Various
approaches have been developed for efficiently generating these so-called
adversarial examples, but those mostly rely on ascending the gradient of loss.
In this paper, we introduce the novel logits optimized targeting system (LOTS)
to directly manipulate deep features captured at the penultimate layer. Using
LOTS, we analyze and compare the adversarial robustness of DNNs using the
traditional Softmax layer with Openmax, which was designed to provide open set
recognition by defining classes derived from deep representations, and is
claimed to be more robust to adversarial perturbations. We demonstrate that
Openmax provides less vulnerable systems than Softmax to traditional attacks,
however, we show that it can be equally susceptible to more sophisticated
adversarial generation techniques that directly work on deep representations.
</dc:description>
 <dc:description>Comment: Accepted to British Machine Vision Conference (BMVC) 2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01703</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The tightly super 3-extra connectivity and 3-extra diagnosability of
  crossed cubes</dc:title>
 <dc:creator>Wang, Shiying</dc:creator>
 <dc:creator>Ma, Xiaolei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Many multiprocessor systems have interconnection networks as underlying
topologies and an interconnection network is usually represented by a graph
where nodes represent processors and links represent communication links
between processors. In 2016, Zhang et al. proposed the $g$-extra diagnosability
of $G$, which restrains that every component of $G-S$ has at least $(g +1)$
vertices. As an important variant of the hypercube, the $n$-dimensional crossed
cube $CQ_{n}$ has many good properties. In this paper, we prove that $CQ_{n}$
is tightly $(4n-9)$ super 3-extra connected for $n\geq 7$ and the 3-extra
diagnosability of $CQ_{n}$ is $4n-6$ under the PMC model $(n\geq5)$ and MM$^*$
model $(n\geq7)$.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01706</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparative Analysis and Framework Evaluating Mimicry-Resistant and
  Invisible Web Authentication Schemes</dc:title>
 <dc:creator>Alaca, Furkan</dc:creator>
 <dc:creator>Abdou, AbdelRahman</dc:creator>
 <dc:creator>van Oorschot, Paul C.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In web authentication, the many password alternatives proposed over the
years, despite having different designs and objectives, all predominantly rely
on an element of secrecy. This motivates us, herein, to provide the first
detailed exploration of the integration of a fundamentally different element of
defense into the design of web authentication schemes: a mimicry resistance
dimension. We analyze web authentication mechanisms with respect to new
properties related to mimicry-resistance, and in particular evaluate invisible
techniques that provide some mimicry-resistance (unlike those relying solely on
static secrets), including device fingerprinting schemes, PUFs (physically
unclonable functions), and a subset of Internet geolocation mechanisms.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01713</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Question-Answering Using A Deep Similarity Neural Network</dc:title>
 <dc:creator>Minaee, Shervin</dc:creator>
 <dc:creator>Liu, Zhu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Automatic question-answering is a classical problem in natural language
processing, which aims at designing systems that can automatically answer a
question, in the same way as human does. In this work, we propose a deep
learning based model for automatic question-answering. First the questions and
answers are embedded using neural probabilistic modeling. Then a deep
similarity neural network is trained to find the similarity score of a pair of
answer and question. Then for each question, the best answer is found as the
one with the highest similarity score. We first train this model on a
large-scale public question-answering database, and then fine-tune it to
transfer to the customer-care chat data. We have also tested our framework on a
public question-answering database and achieved very good performance.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01715</identifier>
 <datestamp>2017-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Deep AutoEncoders for Collaborative Filtering</dc:title>
 <dc:creator>Kuchaiev, Oleksii</dc:creator>
 <dc:creator>Ginsburg, Boris</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper proposes a novel model for the rating prediction task in
recommender systems which significantly outperforms previous state-of-the art
models on a time-split Netflix data set. Our model is based on deep autoencoder
with 6 layers and is trained end-to-end without any layer-wise pre-training. We
empirically demonstrate that: a) deep autoencoder models generalize much better
than the shallow ones, b) non-linear activation functions with negative parts
are crucial for training deep models, and c) heavy use of regularization
techniques such as dropout is necessary to prevent over-fiting. We also propose
a new training algorithm based on iterative output re-feeding to overcome
natural sparseness of collaborate filtering. The new algorithm significantly
speeds up training and improves model performance. Our code is available at
https://github.com/NVIDIA/DeepRecommender
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:date>2017-10-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01723</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Region Selection for Weakly Supervised Object Detection</dc:title>
 <dc:creator>Jiang, Wenhui</dc:creator>
 <dc:creator>Ngo, Thuyen</dc:creator>
 <dc:creator>Manjunath, B. S.</dc:creator>
 <dc:creator>Zhao, Zhicheng</dc:creator>
 <dc:creator>Su, Fei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Training object detectors with only image-level annotations is very
challenging because the target objects are often surrounded by a large number
of background clutters. Many existing approaches tackle this problem through
object proposal mining. However, the collected positive regions are either low
in precision or lack of diversity, and the strategy of collecting negative
regions is not carefully designed, neither. Moreover, training is often slow
because region selection and object detector training are processed separately.
In this context, the primary contribution of this work is to improve weakly
supervised detection with an optimized region selection strategy. The proposed
method collects purified positive training regions by progressively removing
easy background clutters, and selects discriminative negative regions by mining
class-specific hard samples. This region selection procedure is further
integrated into a CNN-based weakly supervised detection (WSD) framework, and
can be performed in each stochastic gradient descent mini-batch during
training. Therefore, the entire model can be trained end-to-end efficiently.
Extensive evaluation results on PASCAL VOC 2007, VOC 2010 and VOC 2012 datasets
are presented which demonstrate that the proposed method effectively improves
WSD.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01723</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01724</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social contagions with communication channels alternation on multiplex
  networks</dc:title>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:creator>Tang, Ming</dc:creator>
 <dc:creator>Stanley, H. Eugene</dc:creator>
 <dc:creator>Braunstein, Lidia A.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Internet communication channels, e.g., Facebook, Twitter, and email, are
multiplex networks that facilitate interaction and information-sharing among
individuals. During brief time periods users often use a single communication
channel, and communication channel alteration (CCA) occurs, which means that
our understanding of the dynamics of social contagions must be redefined. We
propose a non-Markovian behavior spreading model that takes into account the
CCA mechanism in multiplex networks, and we develop a generalized edge-based
compartmental theory to describe the spreading dynamics. Through extensive
numerical simulations and theoretical analyses, we find that the time-delays
induced by the CCA characteristic slows the behavior spreading but does not
affect the final adoption size. We also find that the CCA characteristic
suppresses behavior spreading and that the information transmission probability
in ER-SF multiplex networks introduces a crossover in adoption size from
continuous to discontinuous behavior. Our results extend our understanding of
the role of the CCA characteristic in spreading dynamics, and may elicit
further research.
</dc:description>
 <dc:description>Comment: 17 pages, 6 figures</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01728</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privileged Data within Digital Evidence</dc:title>
 <dc:creator>Fleurbaaij, Dominique</dc:creator>
 <dc:creator>Scanlon, Mark</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In recent years the use of digital communication has increased. This also
increased the chance to find privileged data in the digital evidence.
Privileged data is protected by law from viewing by anyone other than the
client. It is up to the digital investigator to handle this privileged data
properly without being able to view the contents. Procedures on handling this
information are available, but do not provide any practical information nor is
it known how effective filtering is. The objective of this paper is to describe
the handling of privileged data in the current digital forensic tools and the
creation of a script within the digital forensic tool Nuix. The script
automates the handling of privileged data to minimize the exposure of the
contents to the digital investigator. The script also utilizes technology
within Nuix that extends the automated search of identical privileged document
to relate files based on their contents. A comparison of the 'traditional' ways
of filtering within the digital forensic tools and the script written in Nuix
showed that digital forensic tools are still limited when used on privileged
data. The script manages to increase the effectiveness as direct result of the
use of relations based on file content.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01728</dc:identifier>
 <dc:identifier>doi:10.1109/Trustcom/BigDataSE/ICESS.2017.307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01729</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inception Score, Label Smoothing, Gradient Vanishing and -log(D(x))
  Alternative</dc:title>
 <dc:creator>Zhou, Zhiming</dc:creator>
 <dc:creator>Zhang, Weinan</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we study several GAN related topics mathematically, including
Inception score, label smoothing, gradient vanishing and the -log(D(x))
alternative. We show that Inception score is actually equivalent to Mode score,
both consisting of two entropy terms, which has the drawback of ignoring the
prior distribution of the labels. We thus propose AM score as an alternative
that leverages cross-entropy and takes the reference distribution into account.
Empirical results indicate that AM score outperforms Inception score. We study
label smoothing, gradient vanishing and -log(D(x)) alternative from the
perspective of class-aware gradient, with which we show the exact problems when
applying label smoothing to fake samples along with the log(1-D(x)) generator
loss, which is previously unclear, and more importantly show that the problem
does not exist when using the -log(D(x)) generator loss.
</dc:description>
 <dc:description>Comment: It is originally being an appendix of arXiv:1703.02000 &quot;Activation
  Maximization Generative Adversarial Nets&quot;, but due to its importance to the
  community and independence of the &quot;Activation Maximization Generative
  Adversarial Nets&quot;, we put it here as an independent article for ease of
  reference</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01730</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Digital Forensic Process Models with Respect to Digital
  Forensics as a Service</dc:title>
 <dc:creator>Du, Xiaoyu</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Scanlon, Mark</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Digital forensic science is very much still in its infancy, but is becoming
increasingly invaluable to investigators. A popular area for research is
seeking a standard methodology to make the digital forensic process accurate,
robust, and efficient. The first digital forensic process model proposed
contains four steps: Acquisition, Identification, Evaluation and Admission.
Since then, numerous process models have been proposed to explain the steps of
identifying, acquiring, analysing, storage, and reporting on the evidence
obtained from various digital devices. In recent years, an increasing number of
more sophisticated process models have been proposed. These models attempt to
speed up the entire investigative process or solve various of problems commonly
encountered in the forensic investigation. In the last decade, cloud computing
has emerged as a disruptive technological concept, and most leading enterprises
such as IBM, Amazon, Google, and Microsoft have set up their own cloud-based
services. In the field of digital forensic investigation, moving to a
cloud-based evidence processing model would be extremely beneficial and
preliminary attempts have been made in its implementation. Moving towards a
Digital Forensics as a Service model would not only expedite the investigative
process, but can also result in significant cost savings - freeing up digital
forensic experts and law enforcement personnel to progress their caseload. This
paper aims to evaluate the applicability of existing digital forensic process
models and analyse how each of these might apply to a cloud-based evidence
processing paradigm.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01731</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integration of Ether Unpacker into Ragpicker for plugin-based Malware
  Analysis and Identification</dc:title>
 <dc:creator>Schaefer, Erik</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Scanlon, Mark</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Malware is a pervasive problem in both personal computing devices and
distributed computing systems. Identification of malware variants and their
families others a great benefit in early detection resulting in a reduction of
the analyses time needed. In order to classify malware, most of the current
approaches are based on the analysis of the unpacked and unencrypted binaries.
However, most of the unpacking solutions in the literature have a low unpacking
rate. This results in a low contribution towards the identification of
transferred code and re-used code. To develop a new malware analysis solution
based on clusters of binary code sections, it is required to focus on
increasing of the unpacking rate of malware samples to extend the underlying
code database. In this paper, we present a new approach of analysing malware by
integrating Ether Unpacker into the plugin-based malware analysis tool,
Ragpicker. We also evaluate our approach against real-world malware patterns.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01732</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private Web Browser Forensics: A Case Study of the Epic Privacy Browser</dc:title>
 <dc:creator>Reed, Alan</dc:creator>
 <dc:creator>Scanlon, Mark</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Organised crime, as well as individual criminals, is benefiting from the
protection of private browsers provide to those who would carry out illegal
activity, such as money laundering, drug trafficking, the online exchange of
child-abuse material, etc. The protection afforded to users of the Epic Privacy
Browser illustrates these benefits. This browser is currently in use in
approximately 180 countries worldwide. This paper outlines the location and
type of evidence available through live and post-mortem state analyses of the
Epic Privacy Browser. This study identifies the manner in which the browser
functions during use, where evidence can be recovered after use, as well as the
tools and effective presentation of the recovered material.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01733</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting Variational Inference: an Optimization Perspective</dc:title>
 <dc:creator>Locatello, Francesco</dc:creator>
 <dc:creator>Khanna, Rajiv</dc:creator>
 <dc:creator>Ghosh, Joydeep</dc:creator>
 <dc:creator>R&#xe4;tsch, Gunnar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Variational Inference is a popular technique to approximate a possibly
intractable Bayesian posterior with a more tractable one. Recently, Boosting
Variational Inference has been proposed as a new paradigm to approximate the
posterior by a mixture of densities by greedily adding components to the
mixture. In the present work, we study the convergence properties of this
approach from a modern optimization viewpoint by establishing connections to
the classic Frank-Wolfe algorithm. Our analyses yields novel theoretical
insights on the Boosting of Variational Inference regarding the sufficient
conditions for convergence, explicit sublinear/linear rates, and algorithmic
simplifications.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01741</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Discriminative Alpha-Beta-divergence for Positive Definite
  Matrices (Extended Version)</dc:title>
 <dc:creator>Cherian, Anoop</dc:creator>
 <dc:creator>Stanitsas, Panagiotis</dc:creator>
 <dc:creator>Harandi, Mehrtash</dc:creator>
 <dc:creator>Morellas, Vassilios</dc:creator>
 <dc:creator>Papanikolopoulos, Nikolaos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Symmetric positive definite (SPD) matrices are useful for capturing
second-order statistics of visual data. To compare two SPD matrices, several
measures are available, such as the affine-invariant Riemannian metric,
Jeffreys divergence, Jensen-Bregman logdet divergence, etc.; however, their
behaviors may be application dependent, raising the need of manual selection to
achieve the best possible performance. Further and as a result of their
overwhelming complexity for large-scale problems, computing pairwise
similarities by clever embedding of SPD matrices is often preferred to direct
use of the aforementioned measures. In this paper, we propose a discriminative
metric learning framework, Information Divergence and Dictionary Learning
(IDDL), that not only learns application specific measures on SPD matrices
automatically, but also embeds them as vectors using a learned dictionary. To
learn the similarity measures (which could potentially be distinct for every
dictionary atom), we use the recently introduced alpha-beta-logdet divergence,
which is known to unify the measures listed above. We propose a novel IDDL
objective, that learns the parameters of the divergence and the dictionary
atoms jointly in a discriminative setup and is solved efficiently using
Riemannian optimization. We showcase extensive experiments on eight computer
vision datasets, demonstrating state-of-the-art performances.
</dc:description>
 <dc:description>Comment: Accepted at the International Conference on Computer Vision (ICCV)</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01744</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An aggregating strategy for shifting experts in discrete sequence
  prediction</dc:title>
 <dc:creator>Raj, Vishnu</dc:creator>
 <dc:creator>Kalyani, Sheetal</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study how we can adapt a predictor to a non-stationary environment with
advises from multiple experts. We study the problem under complete feedback
when the best expert changes over time from a decision theoretic point of view.
Proposed algorithm is based on popular exponential weighing method with
exponential discounting. We provide theoretical results bounding regret under
the exponential discounting setting. Upper bound on regret is derived for
finite time horizon problem. Numerical verification of different real life
datasets are provided to show the utility of proposed algorithm.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01744</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01745</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Quest for an Acyclic Graph</dc:title>
 <dc:creator>Janota, Mikolas</dc:creator>
 <dc:creator>Grigore, Radu</dc:creator>
 <dc:creator>Manquinho, Vasco</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The paper aims at finding acyclic graphs under a given set of constraints.
More specifically, given a propositional formula {\phi} over edges of a
fixed-size graph, the objective is to find a model of {\phi} that corresponds
to a graph that is acyclic. The paper proposes several encodings of the problem
and compares them in an experimental evaluation using stateof-the-art SAT
solvers.
</dc:description>
 <dc:description>Comment: RCRA2017</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:date>2017-10-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01749</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SurfaceNet: An End-to-end 3D Neural Network for Multiview Stereopsis</dc:title>
 <dc:creator>Ji, Mengqi</dc:creator>
 <dc:creator>Gall, Juergen</dc:creator>
 <dc:creator>Zheng, Haitian</dc:creator>
 <dc:creator>Liu, Yebin</dc:creator>
 <dc:creator>Fang, Lu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes an end-to-end learning framework for multiview
stereopsis. We term the network SurfaceNet. It takes a set of images and their
corresponding camera parameters as input and directly infers the 3D model. The
key advantage of the framework is that both photo-consistency as well geometric
relations of the surface structure can be directly learned for the purpose of
multiview stereopsis in an end-to-end fashion. SurfaceNet is a fully 3D
convolutional network which is achieved by encoding the camera parameters
together with the images in a 3D voxel representation. We evaluate SurfaceNet
on the large-scale DTU benchmark.
</dc:description>
 <dc:description>Comment: 2017 iccv poster</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01751</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DNA Sequence Complexity Reveals Structure Beyond GC Content in
  Nucleosome Occupancy</dc:title>
 <dc:creator>Zenil, Hector</dc:creator>
 <dc:creator>Minary, Peter</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:description>  We introduce methods that rapidly evaluate a battery of information-theoretic
and algorithmic complexity measures on DNA sequences in application to
potential binding sites for nucleosomes. The first application of this new tool
demonstrates structure beyond GC content on DNA sequences in the context of
nucleosome binding. We tested the measures on well-studied genomic sequences of
size 20K and 100K bps. The measures reveal the known in vivo versus in vitro
predictive discrepancies, but they also uncover the internal structure of G and
C within the nucleosome length, thus disclosing more than simply GC content
when one examines alphabet transformations that separate and scramble the GC
content signal and the DNA sequence. Most current prediction methods are based
upon training (e.g. $k$-mer discovery), the one here advanced, however, is a
training-free approach to investigating informative measures of DNA information
content in connection with structural nucleosomic packing.
</dc:description>
 <dc:description>Comment: 23 pages, 4 figures</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01751</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01759</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Referenceless Quality Estimation for Natural Language Generation</dc:title>
 <dc:creator>Du&#x161;ek, Ond&#x159;ej</dc:creator>
 <dc:creator>Novikova, Jekaterina</dc:creator>
 <dc:creator>Rieser, Verena</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Traditional automatic evaluation measures for natural language generation
(NLG) use costly human-authored references to estimate the quality of a system
output. In this paper, we propose a referenceless quality estimation (QE)
approach based on recurrent neural networks, which predicts a quality score for
a NLG system output by comparing it to the source meaning representation only.
Our method outperforms traditional metrics and a constant baseline in most
respects; we also show that synthetic data helps to increase correlation
results by 21% compared to the base system. Our results are comparable to
results obtained in similar QE tasks despite the more challenging setting.
</dc:description>
 <dc:description>Comment: Accepted as a regular paper to 1st Workshop on Learning to Generate
  Natural Language (LGNL), Sydney, 10 August 2017</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01761</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization of Non Binary Parity Check Coefficients</dc:title>
 <dc:creator>Boutillon, Emmanuel</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper generalizes the method proposed by Pouillat et al. for the
determination of the optimal Galois Field coefficients of a Non-Binary LDPC
parity check constraint based on the binary image of the code. Optimal, or
almost-optimal, parity check coefficients are given for check degree varying
from 4 to 20 and Galois Field varying from GF(64) up to GF(1024). For all given
sets of coefficients, no codeword of Hamming weight two exists. A reduced
complexity algorithm to compute the binary Hamming weight 3 of a parity check
is proposed. When the number of sets of coefficients is too high for an
exhaustive search and evaluation, a local greedy search is performed. Explicit
tables of coefficients are given. The proposed sets of coefficients can
effectively replace the random selection of coefficients often used in NB-LDPC
construction.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Information Theory, August the 5,
  2017</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01765</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grid obstacle representation of graphs</dc:title>
 <dc:creator>Bishnu, Arijit</dc:creator>
 <dc:creator>Ghosh, Arijit</dc:creator>
 <dc:creator>Mathew, Rogers</dc:creator>
 <dc:creator>Mishra, Gopinath</dc:creator>
 <dc:creator>Paul, Subhabrata</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>05C62</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  The grid obstacle representation of a graph $G=(V,E)$ is an injective
function $f:V \rightarrow \mathbb{Z}^2$ and a set of point obstacles
$\mathcal{O}$ on the grid points of $\mathbb{Z}^2$ (where $V$ has not been
mapped) such that $uv$ is an edge in $G$ if and only if there exists a
Manhattan path between $f(u)$ and $f(v)$ in $\mathbb{Z}^2$ avoiding the
obstacles of $\mathcal{O}$. The grid obstacle number of a graph is the smallest
number of obstacles needed for the grid obstacle representation of $G$. This
work shows that planar graphs admit such a representation while there exists
some non-planar graphs that do not admit such a representation. Moreover, we
show that every graph admits grid obstacle representation in $\mathbb{Z}^3$. We
also show NP-hardness result for the point set embeddability of an
$\ell_1$-obstacle representation.
</dc:description>
 <dc:description>Comment: 15 figures and 16 pages</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01766</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Syllable-based Technique for Word Embeddings of Korean Words</dc:title>
 <dc:creator>Choi, Sanghyuk</dc:creator>
 <dc:creator>Kim, Taeuk</dc:creator>
 <dc:creator>Seol, Jinseok</dc:creator>
 <dc:creator>Lee, Sang-goo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Word embedding has become a fundamental component to many NLP tasks such as
named entity recognition and machine translation. However, popular models that
learn such embeddings are unaware of the morphology of words, so it is not
directly applicable to highly agglutinative languages such as Korean. We
propose a syllable-based learning model for Korean using a convolutional neural
network, in which word representation is composed of trained syllable vectors.
Our model successfully produces morphologically meaningful representation of
Korean words compared to the original Skip-gram embeddings. The results also
show that it is quite robust to the Out-of-Vocabulary problem.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, 1 table. Accepted for EMNLP 2017 Workshop - The
  1st Workshop on Subword and Character level models in NLP (SCLeM)</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01767</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coverage Analysis in Millimeter Wave Cellular Networks with Reflections</dc:title>
 <dc:creator>Narayanan, Aroon</dc:creator>
 <dc:creator>T. V, Sreejith</dc:creator>
 <dc:creator>Ganti, Radha Krishna</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  The coverage probability of a user in a mmwave system depends on the
availability of line-of-sight paths or reflected paths from any base station.
Many prior works modelled blockages using random shape theory and analyzed the
SIR distribution with and without interference. While, it is intuitive that the
reflected paths do not significantly contribute to the coverage (because of
longer path lengths), there are no works which provide a model and study the
coverage with reflections. In this paper, we model and analyze the impact of
reflectors using stochastic geometry. We observe that the reflectors have very
little impact on the coverage probability.
</dc:description>
 <dc:description>Comment: Accepted for presentation in Globecom 2017</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01769</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extractive Multi Document Summarization using Dynamical Measurements of
  Complex Networks</dc:title>
 <dc:creator>Tohalino, Jorge V.</dc:creator>
 <dc:creator>Amancio, Diego R.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Due to the large amount of textual information available on Internet, it is
of paramount relevance to use techniques that find relevant and concise
content. A typical task devoted to the identification of informative sentences
in documents is the so called extractive document summarization task. In this
paper, we use complex network concepts to devise an extractive Multi Document
Summarization (MDS) method, which extracts the most central sentences from
several textual sources. In the proposed model, texts are represented as
networks, where nodes represent sentences and the edges are established based
on the number of shared words. Differently from previous works, the
identification of relevant terms is guided by the characterization of nodes via
dynamical measurements of complex networks, including symmetry, accessibility
and absorption time. The evaluation of the proposed system revealed that
excellent results were obtained with particular dynamical measurements,
including those based on the exploration of networks via random walks.
</dc:description>
 <dc:description>Comment: Accepted for publication in BRACIS 2017 (Brazilian Conference on
  Intelligent Systems)</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01769</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01771</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Machine Translation with Word Predictions</dc:title>
 <dc:creator>Weng, Rongxiang</dc:creator>
 <dc:creator>Huang, Shujian</dc:creator>
 <dc:creator>Zheng, Zaixiang</dc:creator>
 <dc:creator>Dai, Xinyu</dc:creator>
 <dc:creator>Chen, Jiajun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In the encoder-decoder architecture for neural machine translation (NMT), the
hidden states of the recurrent structures in the encoder and decoder carry the
crucial information about the sentence.These vectors are generated by
parameters which are updated by back-propagation of translation errors through
time. We argue that propagating errors through the end-to-end recurrent
structures are not a direct way of control the hidden vectors. In this paper,
we propose to use word predictions as a mechanism for direct supervision. More
specifically, we require these vectors to be able to predict the vocabulary in
target sentence. Our simple mechanism ensures better representations in the
encoder and decoder without using any extra data or annotation. It is also
helpful in reducing the target side vocabulary and improving the decoding
efficiency. Experiments on Chinese-English and German-English machine
translation tasks show BLEU improvements by 4.53 and 1.3, respectively
</dc:description>
 <dc:description>Comment: Accepted at EMNLP2017</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01773</identifier>
 <datestamp>2017-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FEMPAR: An object-oriented parallel finite element framework</dc:title>
 <dc:creator>Badia, Santiago</dc:creator>
 <dc:creator>Mart&#xed;n, Alberto F.</dc:creator>
 <dc:creator>Principe, Javier</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  FEMPAR is an open source object oriented Fortran200X scientific software
library for the high-performance scalable simulation of complex multiphysics
problems governed by partial differential equations at large scales, by
exploiting state-of-the-art supercomputing resources. It is a highly
modularized, flexible, and extensible library, that provides a set of modules
that can be combined to carry out the different steps of the simulation
pipeline. FEMPAR includes a rich set of algorithms for the discretization step,
namely (arbitrary-order) grad, div, and curl-conforming finite element methods,
discontinuous Galerkin methods, B-splines, and unfitted finite element
techniques on cut cells, combined with $h$-adaptivity. The linear solver module
relies on state-of-the-art bulk-asynchronous implementations of multilevel
domain decomposition solvers for the different discretization alternatives and
block-preconditioning techniques for multiphysics problems. FEMPAR is a
framework that provides users with out-of-the-box state-of-the-art
discretization techniques and highly scalable solvers for the simulation of
complex applications, hiding the dramatic complexity of the underlying
algorithms. But it is also a framework for researchers that want to experience
with new algorithms and solvers, by providing a highly extensible framework. In
this work, the first one in a series of articles about FEMPAR, we provide a
detailed introduction to the software abstractions used in the discretization
module and the related geometrical module. We also provide some ingredients
about the assembly of linear systems arising from finite element
discretizations, but the software design of complex scalable multilevel solvers
is postponed to a subsequent work.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:date>2017-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01776</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>e-QRAQ: A Multi-turn Reasoning Dataset and Simulator with Explanations</dc:title>
 <dc:creator>Rosenbaum, Clemens</dc:creator>
 <dc:creator>Gao, Tian</dc:creator>
 <dc:creator>Klinger, Tim</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we present a new dataset and user simulator e-QRAQ (explainable
Query, Reason, and Answer Question) which tests an Agent's ability to read an
ambiguous text; ask questions until it can answer a challenge question; and
explain the reasoning behind its questions and answer. The User simulator
provides the Agent with a short, ambiguous story and a challenge question about
the story. The story is ambiguous because some of the entities have been
replaced by variables. At each turn the Agent may ask for the value of a
variable or try to answer the challenge question. In response the User
simulator provides a natural language explanation of why the Agent's query or
answer was useful in narrowing down the set of possible answers, or not. To
demonstrate one potential application of the e-QRAQ dataset, we train a new
neural architecture based on End-to-End Memory Networks to successfully
generate both predictions and partial explanations of its current understanding
of the problem. We observe a strong correlation between the quality of the
prediction and explanation.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures, presented at 2017 ICML Workshop on Human
  Interpretability in Machine Learning (WHI 2017), Sydney, NSW, Australia</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01778</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The strong ring of simplicial complexes</dc:title>
 <dc:creator>Knill, Oliver</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>05C99, 13F55, 55U10, 68R05</dc:subject>
 <dc:description>  We define a ring R of geometric objects G generated by finite abstract
simplicial complexes. To every G belongs Hodge Laplacian H as the square of the
Dirac operator determining its cohomology and a unimodular connection matrix
L). The sum of the matrix entries of the inverse of L is the Euler
characteristic. The spectra of H as well as inductive dimension add under
multiplication while the spectra of L multiply. The nullity of the Hodge of H
are the Betti numbers which can now be signed. The map assigning to G its
Poincare polynomial is a ring homomorphism from R the polynomials. Especially
the Euler characteristic is a ring homomorphism. Also Wu characteristic
produces a ring homomorphism. The Kuenneth correspondence between cohomology
groups is explicit as a basis for the product can be obtained from a basis of
the factors. The product in R produces the strong product for the connection
graphs and leads to tensor products of connection Laplacians. The strong ring R
is also a subring of the full Stanley-Reisner ring S Every element G can be
visualized by its Barycentric refinement graph G1 and its connection graph G'.
Gauss-Bonnet, Poincare-Hopf or the Brouwer-Lefschetz extend to the strong ring.
The isomorphism of R with a subring of the strong Sabidussi ring shows that the
multiplicative primes in R are the simplicial complexes and that every
connected element in the strong ring has a unique prime factorization. The
Sabidussi ring is dual to the Zykov ring, in which the Zykov join is the
addition. The connection Laplacian of the d-dimensional lattice remains
invertible in the infinite volume limit: there is a mass gap in any dimension.
</dc:description>
 <dc:description>Comment: 40 pages, 8 figures</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01778</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01783</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interactively Transferring CNN Patterns for Part Localization</dc:title>
 <dc:creator>Zhang, Quanshi</dc:creator>
 <dc:creator>Cao, Ruiming</dc:creator>
 <dc:creator>Zhang, Shengming</dc:creator>
 <dc:creator>Redmonds, Mark</dc:creator>
 <dc:creator>Wu, Ying Nian</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In the scenario of one/multi-shot learning, conventional end-to-end learning
strategies without sufficient supervision are usually not powerful enough to
learn correct patterns from noisy signals. Thus, given a CNN pre-trained for
object classification, this paper proposes a method that first summarizes the
knowledge hidden inside the CNN into a dictionary of latent activation
patterns, and then builds a new model for part localization by manually
assembling latent patterns related to the target part via human interactions.
We use very few (e.g., three) annotations of a semantic object part to retrieve
certain latent patterns from conv-layers to represent the target part. We then
visualize these latent patterns and ask users to further remove incorrect
patterns, in order to refine part representation. With the guidance of human
interactions, our method exhibited superior performance of part localization in
experiments.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01785</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpreting CNN Knowledge via an Explanatory Graph</dc:title>
 <dc:creator>Zhang, Quanshi</dc:creator>
 <dc:creator>Cao, Ruiming</dc:creator>
 <dc:creator>Shi, Feng</dc:creator>
 <dc:creator>Wu, Ying Nian</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper learns a graphical model, namely an explanatory graph, which
reveals the knowledge hierarchy hidden inside a pre-trained CNN. Considering
that each filter in a conv-layer of a pre-trained CNN usually represents a
mixture of object parts, we propose a simple yet efficient method to
automatically disentangles different part patterns from each filter, and
construct an explanatory graph. In the explanatory graph, each node represents
a part pattern, and each edge encodes co-activation relationships and spatial
relationships between patterns. More importantly, we learn the explanatory
graph for a pre-trained CNN in an unsupervised manner, i.e., without a need of
annotating object parts. Experiments show that each graph node consistently
represents the same object part through different images. We transfer part
patterns in the explanatory graph to the task of part localization, and our
method significantly outperforms other approaches.
</dc:description>
 <dc:description>Comment: in AAAI 2018</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01787</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Round-Trip Sketches: Supporting the Lifecycle of Software Development
  Sketches from Analog to Digital and Back</dc:title>
 <dc:creator>Baltes, Sebastian</dc:creator>
 <dc:creator>Hollerich, Fabrice</dc:creator>
 <dc:creator>Diehl, Stephan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Sketching is an important activity for understanding, designing, and
communicating different aspects of software systems such as their requirements
or architecture. Often, sketches start on paper or whiteboards, are revised,
and may evolve into a digital version. Users may then print a revised sketch,
change it on paper, and digitize it again. Existing tools focus on a paperless
workflow, i.e., archiving analog documents, or rely on special hardware - they
do not focus on integrating digital versions into the analog-focused workflow
that many users follow. In this paper, we present the conceptual design and a
prototype of LivelySketches, a tool that supports the &quot;round-trip&quot; lifecycle of
sketches from analog to digital and back. The proposed workflow includes
capturing both analog and digital sketches as well as relevant context
information. In addition, users can link sketches to other related sketches or
documents. They may access the linked artifacts and captured information using
digital as well as augmented analog versions of the sketches. We further
present results from a formative user study with four students and outline
possible directions for future work.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, 2017 IEEE Working Conference on Software
  Visualization (VISSOFT 2017), IEEE, 2017</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01791</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Thompson Sampling Guided Stochastic Searching on the Line for Deceptive
  Environments with Applications to Root-Finding Problems</dc:title>
 <dc:creator>Glimsdal, Sondre</dc:creator>
 <dc:creator>Granmo, Ole-Christoffer</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The multi-armed bandit problem forms the foundation for solving a wide range
of on-line stochastic optimization problems through a simple, yet effective
mechanism. One simply casts the problem as a gambler that repeatedly pulls one
out of N slot machine arms, eliciting random rewards. Learning of reward
probabilities is then combined with reward maximization, by carefully balancing
reward exploration against reward exploitation. In this paper, we address a
particularly intriguing variant of the multi-armed bandit problem, referred to
as the {\it Stochastic Point Location (SPL) Problem}. The gambler is here only
told whether the optimal arm (point) lies to the &quot;left&quot; or to the &quot;right&quot; of
the arm pulled, with the feedback being erroneous with probability $1-\pi$.
This formulation thus captures optimization in continuous action spaces with
both {\it informative} and {\it deceptive} feedback. To tackle this class of
problems, we formulate a compact and scalable Bayesian representation of the
solution space that simultaneously captures both the location of the optimal
arm as well as the probability of receiving correct feedback. We further
introduce the accompanying Thompson Sampling guided Stochastic Point Location
(TS-SPL) scheme for balancing exploration against exploitation. By learning
$\pi$, TS-SPL also supports {\it deceptive} environments that are lying about
the direction of the optimal arm. This, in turn, allows us to solve the
fundamental Stochastic Root Finding (SRF) Problem. Empirical results
demonstrate that our scheme deals with both deceptive and informative
environments, significantly outperforming competing algorithms both for SRF and
SPL.
</dc:description>
 <dc:description>Comment: 17 pages, 2 figures. A preliminary version of some of the results of
  this paper appears in the Proceedings of AIAI'15</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01796</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic generation of analysis class diagrams from use case
  specifications</dc:title>
 <dc:creator>Thakur, Jitendra Singh</dc:creator>
 <dc:creator>Gupta, Atul</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In object oriented software development, the analysis modeling is concerned
with the task of identifying problem level objects along with the relationships
between them from software requirements. The software requirements are usually
written in some natural language, and the analysis modeling is normally
performed by experienced human analysts. The huge gap between the software
requirements which are unstructured texts and analysis models which are usually
structured UML diagrams, along with human slip-ups inevitably makes the
transformation process error prone. The automation of this process can help in
reducing the errors in the transformation. In this paper we propose a tool
supported approach for automated transformation of use case specifications
documented in English language into analysis class diagrams. The approach works
in four steps. It first takes the textual specification of a use case as input,
and then using a natural language parser generates type dependencies and parts
of speech tags for each sentence in the specification. Then, it identifies the
sentence structure of each sentence using a set of comprehensive sentence
structure rules. Next, it applies a set of transformation rules on the type
dependencies and parts of speech tags of the sentences to discover the problem
level objects and the relationships between them. Finally, it generates and
visualizes the analysis class diagram. We conducted a controlled experiment to
compare the correctness, completeness and redundancy of the analysis class
diagrams generated by our approach with those generated by the existing
automated approaches. The results showed that the analysis class diagrams
generated by our approach were more correct, more complete, and less redundant
than those generated by the other approaches.
</dc:description>
 <dc:description>Comment: 38 pages, 5 figures, 20 tables</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01797</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reuse, don't Recycle: Transforming Lock-free Algorithms that Throw Away
  Descriptors</dc:title>
 <dc:creator>Arbel-Raviv, Maya</dc:creator>
 <dc:creator>Brown, Trevor</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  In many lock-free algorithms, threads help one another, and each operation
creates a descriptor that describes how other threads should help it.
Allocating and reclaiming descriptors introduces significant space and time
overhead. We introduce the first descriptor abstract data type (ADT), which
captures the usage of descriptors by lock-free algorithms. We then develop a
weak descriptor ADT which has weaker semantics, but can be implemented
significantly more efficiently. We show how a large class of lock-free
algorithms can be transformed to use weak descriptors, and demonstrate our
technique by transforming several algorithms, including the leading
k-compare-and-swap (k-CAS) algorithm. The original k-CAS algorithm allocates at
least k+1 new descriptors per k-CAS. In contrast, our implementation allocates
two descriptors per process, and each process simply reuses its two
descriptors. Experiments on a variety of workloads show significant performance
improvements over implementations that reclaim descriptors, and reductions of
up to three orders of magnitude in peak memory usage.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01799</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Contextual Bandits in Non-stationary Worlds</dc:title>
 <dc:creator>Luo, Haipeng</dc:creator>
 <dc:creator>Agarwal, Alekh</dc:creator>
 <dc:creator>Langford, John</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Most contextual bandit algorithms minimize regret to the best fixed policy--a
questionable benchmark for non-stationary environments ubiquitous in
applications. In this work, we obtain efficient contextual bandit algorithms
with strong guarantees for alternate notions of regret suited to these
non-stationary environments. Two of our algorithms equip existing methods for
i.i.d problems with sophisticated statistical tests, dynamically adapting to a
change in distribution. The third approach uses a recent technique for
combining multiple bandit algorithms, with each copy starting at a different
round so as to learn over different data segments. We analyze several notions
of regret for these methods, including the first results on dynamic regret for
efficient contextual bandit algorithms.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01806</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Noteheads in Handwritten Scores with ConvNets and Bounding Box
  Regression</dc:title>
 <dc:creator>Haji&#x10d; Jr., Jan</dc:creator>
 <dc:creator>Pecina, Pavel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.7.5, I.5.4, I.4.6, I.5.1</dc:subject>
 <dc:description>  Noteheads are the interface between the written score and music. Each
notehead on the page signifies one note to be played, and detecting noteheads
is thus an unavoidable step for Optical Music Recognition. Noteheads are
clearly distinct objects, however, the variety of music notation handwriting
makes noteheads harder to identify, and while handwritten music notation symbol
{\em classification} is a well-studied task, symbol {\em detection} has usually
been limited to heuristics and rule-based systems instead of machine learning
methods better suited to deal with the uncertainties in handwriting. We present
ongoing work on a simple notehead detector using convolutional neural networks
for pixel classification and bounding box regression that achieves a detection
f-score of 0.97 on binary score images in the MUSCIMA++ dataset, does not
require staff removal, and is applicable to a variety of handwriting styles and
levels of musical complexity.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01809</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparison of Neural Models for Word Ordering</dc:title>
 <dc:creator>Hasler, Eva</dc:creator>
 <dc:creator>Stahlberg, Felix</dc:creator>
 <dc:creator>Tomalin, Marcus</dc:creator>
 <dc:creator>de Gispert, Adri`a</dc:creator>
 <dc:creator>Byrne, Bill</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We compare several language models for the word-ordering task and propose a
new bag-to-sequence neural model based on attention-based sequence-to-sequence
models. We evaluate the model on a large German WMT data set where it
significantly outperforms existing models. We also describe a novel search
strategy for LM-based word ordering and report results on the English Penn
Treebank. Our best model setup outperforms prior work both in terms of speed
and quality.
</dc:description>
 <dc:description>Comment: Accepted for publication at INLG 2017</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01817</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Review and Analysis of Eye-Gaze Estimation Systems, Algorithms and
  Performance Evaluation Methods in Consumer Platforms</dc:title>
 <dc:creator>Kar, Anuradha</dc:creator>
 <dc:creator>Corcoran, Peter</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In this paper a review is presented of the research on eye gaze estimation
techniques and applications, that has progressed in diverse ways over the past
two decades. Several generic eye gaze use-cases are identified: desktop, TV,
head-mounted, automotive and handheld devices. Analysis of the literature leads
to the identification of several platform specific factors that influence gaze
tracking accuracy. A key outcome from this review is the realization of a need
to develop standardized methodologies for performance evaluation of gaze
tracking systems and achieve consistency in their specification and comparative
evaluation. To address this need, the concept of a methodological framework for
practical evaluation of different gaze tracking systems is proposed.
</dc:description>
 <dc:description>Comment: 25 pages, 13 figures, Accepted for publication in IEEE Access in July
  2017</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01817</dc:identifier>
 <dc:identifier>doi:10.1109/ACCESS.2017.2735633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01818</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Depth Adaptive Deep Neural Network for Semantic Segmentation</dc:title>
 <dc:creator>Kang, Byeongkeun</dc:creator>
 <dc:creator>Lee, Yeejin</dc:creator>
 <dc:creator>Nguyen, Truong Q.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we present the depth-adaptive deep neural network using a depth
map for semantic segmentation. Typical deep neural networks receive inputs at
the predetermined locations regardless of the distance from the camera. This
fixed receptive field presents a challenge to generalize the features of
objects at various distances in neural networks. Specifically, the
predetermined receptive fields are too small at a short distance, and vice
versa. To overcome this challenge, we develop a neural network which is able to
adapt the receptive field not only for each layer but also for each neuron at
spatial locations. To adjust the receptive field, we propose the adaptive
perception neuron and the in-layer multiscale neuron. The adaptive perception
neuron is to adjust the receptive field at each spatial location using the
corresponding depth information. The in-layer multiscale neuron is to apply the
different size of the receptive field at each feature space to learn features
at multiple scales. By the combination of these neurons, we propose the three
fully convolutional neural networks. We demonstrate the effectiveness of the
proposed neural networks on the novel hand segmentation dataset for hand-object
interaction and publicly available RGB-D dataset for semantic segmentation. The
experimental results show that the proposed method outperforms the
state-of-the-art methods without any additional layers or pre/post-processing.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01824</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Blind Sparse-Channel Equalization</dc:title>
 <dc:creator>Abrar, Shafayat</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this article, a fractional-norm constrained blind adaptive algorithm is
presented for sparse channel equalization. In essence, the algorithm improves
on the minimization of the constant modulus (CM) criteria by adding a sparsity
inducing \(\ell_p\)-norm penalty. Simulation results demonstrate that the
proposed regularized equalizer exploits the inherent channel sparsity
effectively and exhibits faster convergence compared to its counterparts.
</dc:description>
 <dc:description>Comment: First appeared in: S. Abrar, &quot;Blind Equalization and Carrier
  Recovery: Adaptive Solutions and Analysis&quot;, LAP LAMBERT Academic Publishing
  (March 11, 2016), ISBN-10: 3659834769</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01824</dc:identifier>
 <dc:identifier>Chapter 11 in: S. Abrar, &quot;Blind Equalization and Carrier Recovery:
  Adaptive Solutions and Analysis&quot;, LAP LAMBERT Academic Publishing (March 11,
  2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01829</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Declarative Statistics</dc:title>
 <dc:creator>Rossi, Roberto</dc:creator>
 <dc:creator>Akg&#xfc;n, &#xd6;zg&#xfc;r</dc:creator>
 <dc:creator>Prestwich, Steven</dc:creator>
 <dc:creator>Tarim, S. Armagan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  In this work we introduce declarative statistics, a suite of declarative
modelling tools for statistical analysis. Statistical constraints represent the
key building block of declarative statistics. First, we introduce a range of
relevant counting and matrix constraints and associated decompositions, some of
which novel, that are instrumental in the design of statistical constraints.
Second, we introduce a selection of novel statistical constraints and
associated decompositions, which constitute a self-contained toolbox that can
be used to tackle a wide range of problems typically encountered by
statisticians. Finally, we deploy these statistical constraints to a wide range
of application areas drawn from classical statistics and we contrast our
framework against established practices.
</dc:description>
 <dc:description>Comment: The modeling framework and the examples used in this work are
  available at https://gwr3n.github.io/syat-choco/</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01834</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Physical Dynamics to Detect Actuator and Sensor Attacks in
  Mobile Robots</dc:title>
 <dc:creator>Guo, Pinyao</dc:creator>
 <dc:creator>Kim, Hunmin</dc:creator>
 <dc:creator>Virani, Nurali</dc:creator>
 <dc:creator>Xu, Jun</dc:creator>
 <dc:creator>Zhu, Minghui</dc:creator>
 <dc:creator>Liu, Peng</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Mobile robots are cyber-physical systems where the cyberspace and the
physical world are strongly coupled. Attacks against mobile robots can
transcend cyber defenses and escalate into disastrous consequences in the
physical world. In this paper, we focus on the detection of active attacks that
are capable of directly influencing robot mission operation. Through leveraging
physical dynamics of mobile robots, we develop RIDS, a novel robot intrusion
detection system that can detect actuator attacks as well as sensor attacks for
nonlinear mobile robots subject to stochastic noises. We implement and evaluate
a RIDS on Khepera mobile robot against concrete attack scenarios via various
attack channels including signal interference, sensor spoofing, logic bomb, and
physical damage. Evaluation of 20 experiments shows that the averages of false
positive rates and false negative rates are both below 1%. Average detection
delay for each attack remains within 0.40s.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01837</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CodeSum: Translate Program Language to Natural Language</dc:title>
 <dc:creator>Hu, Xing</dc:creator>
 <dc:creator>Wei, Yuhan</dc:creator>
 <dc:creator>Li, Ge</dc:creator>
 <dc:creator>Jin, Zhi</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  During software maintenance, programmers spend a lot of time on code
comprehension. Reading comments is an effective way for programmers to reduce
the reading and navigating time when comprehending source code. Therefore, as a
critical task in software engineering, code summarization aims to generate
brief natural language descriptions for source code. In this paper, we propose
a new code summarization model named CodeSum. CodeSum exploits the
attention-based sequence-to-sequence (Seq2Seq) neural network with
Structure-based Traversal (SBT) of Abstract Syntax Trees (AST). The AST
sequences generated by SBT can better present the structure of ASTs and keep
unambiguous. We conduct experiments on three large-scale corpora in different
program languages, i.e., Java, C#, and SQL, in which Java corpus is our new
proposed industry code extracted from Github. Experimental results show that
our method CodeSum outperforms the state-of-the-art significantly.
</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01838</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maneuver Regulation for Accelerating Bodies in Atmospheric Environments</dc:title>
 <dc:creator>Afman, Juan-Pablo</dc:creator>
 <dc:creator>Feron, Eric</dc:creator>
 <dc:creator>Hauser, John</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In order to address the need for an affordable reduced gravity test platform,
this work focuses on the analysis and implementation of atmospheric
acceleration tracking with an autonomous aerial vehicle. As proof of concept,
the vehicle is designed with the objective of flying accurate reduced-gravity
parabolas. Suggestions from both academia and industry were taken into account,
as well as requirements imposed by a regulatory agency. The novelty of this
work is the Proportional Integral Ramp Quadratic PIRQ controller, which is
employed to counteract the aerodynamic forces impeding the vehicles constant
acceleration during the maneuver. The stability of the free-fall maneuver under
this controller is studied in detail via the formation of the transverse
dynamics and the application of the circle criterion. The implementation of
such a controller is then outlined, and the PIRQ controller is validated
through a flight test, where the vehicle successfully tracks Martian gravity
0.378 G's with a standard deviation of 0.0426.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01841</identifier>
 <datestamp>2017-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ComplementMe: Weakly-Supervised Component Suggestions for 3D Modeling</dc:title>
 <dc:creator>Sung, Minhyuk</dc:creator>
 <dc:creator>Su, Hao</dc:creator>
 <dc:creator>Kim, Vladimir G.</dc:creator>
 <dc:creator>Chaudhuri, Siddhartha</dc:creator>
 <dc:creator>Guibas, Leonidas</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  Assembly-based tools provide a powerful modeling paradigm for non-expert
shape designers. However, choosing a component from a large shape repository
and aligning it to a partial assembly can become a daunting task. In this paper
we describe novel neural network architectures for suggesting complementary
components and their placement for an incomplete 3D part assembly. Unlike most
existing techniques, our networks are trained on unlabeled data obtained from
public online repositories, and do not rely on consistent part segmentations or
labels. Absence of labels poses a challenge in indexing the database of parts
for the retrieval. We address it by jointly training embedding and retrieval
networks, where the first indexes parts by mapping them to a low-dimensional
feature space, and the second maps partial assemblies to appropriate
complements. The combinatorial nature of part arrangements poses another
challenge, since the retrieval network is not a function: several complements
can be appropriate for the same input. Thus, instead of predicting a single
output, we train our network to predict a probability distribution over the
space of part embeddings. This allows our method to deal with ambiguities and
naturally enables a UI that seamlessly integrates user preferences into the
design process. We demonstrate that our method can be used to design complex
shapes with minimal or no user input. To evaluate our approach we develop a
novel benchmark for component suggestion systems demonstrating significant
improvement over state-of-the-art techniques.
</dc:description>
 <dc:description>Comment: SIGGRAPH Asia 2017. 12 pages</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:date>2017-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01844</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Assessment of Facial Wrinkling: a case study on the effect of
  smoking</dc:title>
 <dc:creator>Osman, Omaima FathElrahman</dc:creator>
 <dc:creator>Elbashir, Remah Mutasim Ibrahim</dc:creator>
 <dc:creator>Abbass, Imad Eldain</dc:creator>
 <dc:creator>Kendrick, Connah</dc:creator>
 <dc:creator>Goyal, Manu</dc:creator>
 <dc:creator>Yap, Moi Hoon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Facial wrinkle is one of the most prominent biological changes that
accompanying the natural aging process. However, there are some external
factors contributing to premature wrinkles development, such as sun exposure
and smoking. Clinical studies have shown that heavy smoking causes premature
wrinkles development. However, there is no computerised system that can
automatically assess the facial wrinkles on the whole face. This study
investigates the effect of smoking on facial wrinkling using a social habit
face dataset and an automated computerised computer vision algorithm. The
wrinkles pattern represented in the intensity of 0-255 was first extracted
using a modified Hybrid Hessian Filter. The face was divided into ten
predefined regions, where the wrinkles in each region was extracted. Then the
statistical analysis was performed to analyse which region is effected mainly
by smoking. The result showed that the density of wrinkles for smokers in two
regions around the mouth was significantly higher than the non-smokers, at
p-value of 0.05. Other regions are inconclusive due to lack of large scale
dataset. Finally, the wrinkle was visually compared between smoker and
non-smoker faces by generating a generic 3D face model.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, Accepted in 2017 IEEE SMC International
  Conference</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:date>2017-12-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01844</dc:identifier>
 <dc:identifier>2017 IEEE International Conference on Systems, Man, and
  Cybernetics (SMC), Banff, AB, 2017, pp. 1081-1086</dc:identifier>
 <dc:identifier>doi:10.1109/SMC.2017.8122755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01846</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Manifold Constrained Low-Rank Decomposition</dc:title>
 <dc:creator>Chen, Chen</dc:creator>
 <dc:creator>Zhang, Baochang</dc:creator>
 <dc:creator>Del Bue, Alessio</dc:creator>
 <dc:creator>Murino, Vittorio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Low-rank decomposition (LRD) is a state-of-the-art method for visual data
reconstruction and modelling. However, it is a very challenging problem when
the image data contains significant occlusion, noise, illumination variation,
and misalignment from rotation or viewpoint changes. We leverage the specific
structure of data in order to improve the performance of LRD when the data are
not ideal. To this end, we propose a new framework that embeds manifold priors
into LRD. To implement the framework, we design an alternating direction method
of multipliers (ADMM) method which efficiently integrates the manifold
constraints during the optimization process. The proposed approach is
successfully used to calculate low-rank models from face images, hand-written
digits and planar surface images. The results show a consistent increase of
performance when compared to the state-of-the-art over a wide range of
realistic image misalignments and corruptions.
</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01856</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context of Visual Information Seeking</dc:title>
 <dc:creator>Sedghi, Shahram</dc:creator>
 <dc:creator>Shourmeij, Zeinab</dc:creator>
 <dc:creator>Tahamtan, Iman</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Information seeking is an interactive behavior of the end users with
information systems, which occurs in a real environment known as context.
Context affects information seeking behavior in many different ways. The aim of
this article was to investigate the factors that potentially constitute the
context of visual information seeking. We utilized Straussian version of
grounded theory, a qualitative approach, to conduct the study. Using a
purposive sampling method, twenty-eight subjects participated in the study. The
data was analyzed using open, axial and selective coding in MAXQDA software.
The contextual factors influencing visual information seeking were classified
into seven categories, including: user characteristics, general search
features, visual search features, display of results, accessibility and
usability of results, task type, and environmental factors. This study
contributes to a better understanding of how people conduct searches in and
interact with visual search interfaces. Results have important implications for
the designers of information retrieval systems.
</dc:description>
 <dc:description>Comment: 24 pages, 0 figures</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01859</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power-law citation distributions are not scale-free</dc:title>
 <dc:creator>Golosovsky, Michael</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  We analyze time evolution of statistical distributions of citations to
scientific papers published in one year. While these distributions can be
fitted by a power-law dependence we find that they are nonstationary and the
exponent of the power law fit decreases with time and does not come to
saturation. We attribute the nonstationarity of citation distributions to
different longevity of the low-cited and highly-cited papers. By measuring
citation trajectories of papers we found that citation careers of the low-cited
papers come to saturation after 10-15 years while those of the highly-cited
papers continue to increase indefinitely: the papers that exceed some citation
threshold become runaways. Thus, we show that although citation distribution
can look as a power-law, it is not scale-free and there is a hidden dynamic
scale associated with the onset of runaways. We compare our measurements to our
recently developed model of citation dynamics based on
copying/redirection/triadic closure and find explanations to our empirical
observations.
</dc:description>
 <dc:description>Comment: 30 pages, 12 figures</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01859</dc:identifier>
 <dc:identifier>Phys. Rev. E 96, 032306 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.96.032306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01861</identifier>
 <datestamp>2017-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Normalized Maximum Likelihood with Luckiness for Multivariate Normal
  Distributions</dc:title>
 <dc:creator>Miyaguchi, Kohei</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The normalized maximum likelihood (NML) is one of the most important
distribution in coding theory and statistics. NML is the unique solution (if
exists) to the pointwise minimax regret problem. However, NML is not defined
even for simple family of distributions such as the normal distributions. Since
there does not exist any meaningful minimax-regret distribution for such case,
it is pointed out that NML with luckiness (LNML) can be employed as an
alternative to NML. In this paper, we develop the closed form of LNMLs for
multivariate normal distributions.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:date>2017-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01862</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A combination chaotic system and application in color image encryption</dc:title>
 <dc:creator>Parvaz, R.</dc:creator>
 <dc:creator>Zarebnia, M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, by using Logistic, Sine and Tent systems we define a
combination chaotic system. Some properties of the chaotic system are studied
by using figures and numerical results. A color image encryption algorithm is
introduced based on new chaotic system. Also this encryption algorithm can be
used for gray scale or binary images.
  The experimental results of the encryption algorithm show that the encryption
algorithm is secure and practical.
</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01862</dc:identifier>
 <dc:identifier>doi:10.1016/j.optlastec.2017.10.024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01864</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Latent Attack Semantics for Intelligent Malware Detection</dc:title>
 <dc:creator>Kazdagli, Mkhail</dc:creator>
 <dc:creator>Caramanis, Constantine</dc:creator>
 <dc:creator>Shakkottai, Sanjay</dc:creator>
 <dc:creator>Tiwari, Mohit</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Behavioral malware detectors promise to expose previously unknown malware and
are an important security primitive. However, even the best behavioral
detectors suffer from high false positives and negatives. In this paper, we
address the challenge of aggregating weak per-device behavioral detectors in
noisy communities (i.e., ones that produce alerts at unpredictable rates) into
an accurate and robust global anomaly detector (GD).
  Our system - Shape GD - combines two insights: Structural: actions such as
visiting a website (waterhole attack) or membership in a shared email thread
(phishing attack) by nodes correlate well with malware spread, and create
dynamic neighborhoods of nodes that were exposed to the same attack vector; and
Statistical: feature vectors corresponding to true and false positives of local
detectors have markedly different conditional distributions. We use
neighborhoods to amplify the transient low-dimensional structure that is latent
in high-dimensional feature vectors - but neighborhoods vary unpredictably, and
we use shape to extract robust neighborhood-level features that identify
infected neighborhoods.
  Unlike prior works that aggregate local detectors' alert bitstreams or
cluster the feature vectors, Shape GD analyzes the feature vectors that led to
local alerts (alert-FVs) to separate true and false positives. Shape GD first
filters these alert-FVs into neighborhoods and efficiently maps a
neighborhood's alert-FVs' statistical shapes into a scalar score. Shape GD then
acts as a neighborhood level anomaly detector - training on benign program
traces to learn the ShapeScore of false positive neighborhoods, and classifying
neighborhoods with anomalous ShapeScores as malicious.
  Shape GD detects malware early (~100 infected nodes in a ~100K node system
for waterhole and ~10 of 1000 for phishing) and robustly (with ~100% global TP
and ~1% global FP rates).
</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01866</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pattern Generation for Walking on Slippery Terrains</dc:title>
 <dc:creator>Khadiv, Majid</dc:creator>
 <dc:creator>Moosavian, S. Ali A.</dc:creator>
 <dc:creator>Herzog, Alexander</dc:creator>
 <dc:creator>Righetti, Ludovic</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, we extend state of the art Model Predictive Control (MPC)
approaches to generate safe bipedal walking on slippery surfaces. In this
setting, we formulate walking as a trade off between realizing a desired
walking velocity and preserving robust foot-ground contact. Exploiting this
formulation inside MPC, we show that safe walking on various flat terrains can
be achieved by compromising three main attributes, i. e. walking velocity
tracking, the Zero Moment Point (ZMP) modulation, and the Required Coefficient
of Friction (RCoF) regulation. Simulation results show that increasing the
walking velocity increases the possibility of slippage, while reducing the
slippage possibility conflicts with reducing the tip-over possibility of the
contact and vice versa.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:date>2017-10-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01867</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Information-Theoretic Optimality Principle for Deep Reinforcement
  Learning</dc:title>
 <dc:creator>Leibfried, Felix</dc:creator>
 <dc:creator>Grau-Moya, Jordi</dc:creator>
 <dc:creator>Bou-Ammar, Haitham</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we methodologically address the problem of cumulative reward
overestimation in deep reinforcement learning. We generalise notions from
information-theoretic bounded rationality to handle high-dimensional state
spaces efficiently. The resultant algorithm encompasses a wide range of
learning outcomes that can be demonstrated by tuning a Lagrange multiplier that
intrinsically penalises rewards. We show that deep Q-networks arise as a
special case of our proposed approach. We introduce a novel scheduling scheme
for bounded-rational behaviour that ensures sample efficiency and robustness.
In experiments on Atari games, we show that our algorithm outperforms other
deep reinforcement learning algorithms (e.g., deep and double deep Q-networks)
in terms of both game-play performance and sample complexity.
</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01868</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concealing IMSI in 5G Network Using Identity Based Encryption</dc:title>
 <dc:creator>Khan, Mohsin</dc:creator>
 <dc:creator>Niemi, Valtteri</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Subscription privacy of a user has been a historical concern with all the
previous generation mobile networks, namely, GSM, UMTS,and LTE. While a little
improvement have been achieved in securing the privacy of the long-term
identity of a subscriber, the so called IMSI catchers are still in existence
even in the LTE and advanced LTE networks. Proposals have been published to
tackle this problem in 5G based on pseudonyms, and different public-key
technologies. This paper looks into the problem of concealing long-term
identity of a subscriber and presents a technique based on identity based
encryption (IBE) to tackle it. The proposed solution can be extended to a
mutual authentication and key agreement protocol between a serving network (SN)
and a user equipment (UE). This mutual authentication and key agreement
protocol does not need to connect with the home network (HN) on every run. A
qualitative comparison of the advantages and disadvantages of different
techniques show that our solution is competitive for securing the long-term
identity privacy of a user in the 5G network.
</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01870</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Challenges for Transparency</dc:title>
 <dc:creator>Weller, Adrian</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Transparency is often deemed critical to enable effective real-world
deployment of intelligent systems. Yet the motivations for and benefits of
different types of transparency can vary significantly depending on context,
and objective measurement criteria are difficult to identify. We provide a
brief survey, suggesting challenges and related concerns. We highlight and
review settings where transparency may cause harm, discussing connections
across privacy, multi-agent game theory, economics, fairness and trust.
</dc:description>
 <dc:description>Comment: Presented at 2017 ICML Workshop on Human Interpretability in Machine
  Learning (WHI 2017), Sydney, NSW, Australia</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01871</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Motility Tracking of Calcium Dynamics in Toxoplasma gondii</dc:title>
 <dc:creator>Fazli, Mojtaba Sedigh</dc:creator>
 <dc:creator>Vella, Stephen Andrew</dc:creator>
 <dc:creator>Moreno, Silvia N. J.</dc:creator>
 <dc:creator>Quinn, Shannon</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Cell Behavior</dc:subject>
 <dc:description>  Toxoplasma gondii is the causative agent responsible for toxoplasmosis and
serves as one of the most common parasites in the world. For a successful lytic
cycle, T. gondii must traverse biological barriers in order to invade host
cells, and as such, motility is critical for its virulence. Calcium signaling,
governed by fluctuations in cytosolic calcium (Ca2+) concentrations, is
utilized universally across life and regulates many cellular processes,
including the stimulation of T. gondii virulence factors such as motility.
Therefore, increases in cytosolic calcium, called calcium oscillations, serve
as a means to link and quantify the intracellular signaling processes that lead
to T. gondii motility and invasion. Here, we describe our work extracting,
quantifying and modeling motility patterns of T. gondii before and after the
addition of pharmacological drugs and/or extracellular calcium. We demonstrate
a computational pipeline including a robust tracking system using optical flow
and dense trajectory features to extract T. gondii motility patterns. Using
this pipeline, we were able to track changes in T.gondii motility in response
to cytosolic Ca2+ fluxes in extracellular parasites. This allows us to study
how Ca2+ signaling via release from intracellular Ca2+ stores and/or from
extracellular Ca2+ entry relates to motility patterns, a crucial first step in
developing countermeasures for T. gondii virulence.
</dc:description>
 <dc:description>Comment: 7 pages, 13 figures, KDDBigDas Workshop</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01871</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01872</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TrafficNet: An Open Naturalistic Driving Scenario Library</dc:title>
 <dc:creator>Zhao, Ding</dc:creator>
 <dc:creator>Guo, Yaohui</dc:creator>
 <dc:creator>Jia, Yunhan Jack</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The enormous efforts spent on collecting naturalistic driving data in the
recent years has resulted in an expansion of publicly available traffic
datasets, which has the potential to assist the development of the self-driving
vehicles. However, we found that many of the attempts to utilize these datasets
have failed in practice due to a lack of usability concern from the
organizations that host these collected data. For example, extracting data
associated with certain critical conditions from naturalistic driving data
organized in chronological order may not be convenient for a vehicle engineer
that doesn't have big data analytics experiences.
  To address the general usability challenges of these publicly available
traffic datasets, we propose TrafficNet, a large-scale and extensible library
of naturalistic driving scenarios, aiming at bridging the gap between research
datasets and practically usable information for vehicle engineers and
researchers. The proposed web-based driving scenario database preprocesses
massive raw traffic data collected in chronological order into an organized
scenario-based dataset by applying a set of categorization algorithms to label
the naturalistic driving data with six different critical driving scenarios.
TrafficNet opens not only the scenario library but also the source code of
these categorization methods to the public, which will foster more
sophisticated and accurate scenario-based categorization algorithms to advance
the intelligent transportation research. The source code and the scenario
database can be accessed at https://github.com/TrafficNet.
</dc:description>
 <dc:description>Comment: IEEE 20th International Conference on Intelligent Transportation</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01873</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practically efficient methods for performing bit-reversed permutation in
  C++11 on the x86-64 architecture</dc:title>
 <dc:creator>Knauth, Christian</dc:creator>
 <dc:creator>Adas, Boran</dc:creator>
 <dc:creator>Whitfield, Daniel</dc:creator>
 <dc:creator>Wang, Xuesong</dc:creator>
 <dc:creator>Ickler, Lydia</dc:creator>
 <dc:creator>Conrad, Tim</dc:creator>
 <dc:creator>Serang, Oliver</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  The bit-reversed permutation is a famous task in signal processing and is key
to efficient implementation of the fast Fourier transform. This paper presents
optimized C++11 implementations of five extant methods for computing the
bit-reversed permutation: Stockham auto-sort, naive bitwise swapping, swapping
via a table of reversed bytes, local pairwise swapping of bits, and swapping
via a cache-localized matrix buffer. Three new strategies for performing the
bit-reversed permutation in C++11 are proposed: an inductive method using the
bitwise XOR operation, a template-recursive closed form, and a cache-oblivious
template-recursive approach, which reduces the bit-reversed permutation to
smaller bit-reversed permutations and a square matrix transposition. These new
methods are compared to the extant approaches in terms of theoretical runtime,
empirical compile time, and empirical runtime. The template-recursive
cache-oblivious method is shown to be competitive with the fastest known
method; however, we demonstrate that the cache-oblivious method can more
readily benefit from parallelization on multiple cores and on the GPU.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01873</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01876</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Countries' Relation Formation Problem: I and II</dc:title>
 <dc:creator>Li, Yuke</dc:creator>
 <dc:creator>Morse, A. Stephen</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This paper integrates the studies of various countries' behaviors, e.g.,
waging wars and entering into military alliances, into a general framework of
\emph{countries' relation formation}, which consists of two components, i.e., a
static game and a dynamical system. Aside from being a stand-alone framework
itself, this paper can also be seen as a necessary extension of a recently
developed \emph{countries' power allocation game} in \cite{allocation}. We
establish certain theoretical results, such as pure strategy Nash equilibrium
existence in the static game, and propose several applications of interest made
possible by combining both frameworks of countries' power allocation and
relation formation.
</dc:description>
 <dc:description>Comment: Proceedings of IFAC World Congress 2017, pp 14141-14146</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01876</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01884</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differential Privacy By Sampling</dc:title>
 <dc:creator>Joy, Josh</dc:creator>
 <dc:creator>Gerla, Mario</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper we present the Sampling Privacy mechanism for privately
releasing personal data. Sampling Privacy is a sampling based privacy mechanism
that satisfies differential privacy.
</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01885</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Long Short-Term Memory Kalman Filters:Recurrent Neural Estimators for
  Pose Regularization</dc:title>
 <dc:creator>Coskun, Huseyin</dc:creator>
 <dc:creator>Achilles, Felix</dc:creator>
 <dc:creator>DiPietro, Robert</dc:creator>
 <dc:creator>Navab, Nassir</dc:creator>
 <dc:creator>Tombari, Federico</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  One-shot pose estimation for tasks such as body joint localization, camera
pose estimation, and object tracking are generally noisy, and temporal filters
have been extensively used for regularization. One of the most widely-used
methods is the Kalman filter, which is both extremely simple and general.
However, Kalman filters require a motion model and measurement model to be
specified a priori, which burdens the modeler and simultaneously demands that
we use explicit models that are often only crude approximations of reality. For
example, in the pose-estimation tasks mentioned above, it is common to use
motion models that assume constant velocity or constant acceleration, and we
believe that these simplified representations are severely inhibitive. In this
work, we propose to instead learn rich, dynamic representations of the motion
and noise models. In particular, we propose learning these models from data
using long short term memory, which allows representations that depend on all
previous observations and all previous states. We evaluate our method using
three of the most popular pose estimation tasks in computer vision, and in all
cases we obtain state-of-the-art performance.
</dc:description>
 <dc:description>Comment: Accepted ICCV 2017</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01885</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01886</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Generative Adversarial Networks</dc:title>
 <dc:creator>Eghbal-zadeh, Hamid</dc:creator>
 <dc:creator>Widmer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce the Probabilistic Generative Adversarial Network (PGAN), a new
GAN variant based on a new kind of objective function. The central idea is to
integrate a probabilistic model (a Gaussian Mixture Model, in our case) into
the GAN framework which supports a new kind of loss function (based on
likelihood rather than classification loss), and at the same time gives a
meaningful measure of the quality of the outputs generated by the network.
Experiments with MNIST show that the model learns to generate realistic images,
and at the same time computes likelihoods that are correlated with the quality
of the generated images. We show that PGAN is better able to cope with
instability problems that are usually observed in the GAN training procedure.
We investigate this from three aspects: the probability landscape of the
discriminator, gradients of the generator, and the perfect discriminator
problem.
</dc:description>
 <dc:description>Comment: Submitted to NIPS 2017</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01891</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Behavioral Analysis on the Reselection of Seed Nodes in Independent
  Cascade Based Influence Maximization</dc:title>
 <dc:creator>Vardasbi, Ali</dc:creator>
 <dc:creator>Faili, Heshaam</dc:creator>
 <dc:creator>Asadpour, Masoud</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Influence maximization serves as the main goal of a variety of social network
activities such as viral marketing and campaign advertising. The independent
cascade model for the influence spread assumes a one-time chance for each
activated node to influence its neighbors. This reasonable assumption cannot be
bypassed, since otherwise the influence probabilities of the nodes, modeled by
the edge weights, would be altered. On the other hand, the manually activated
seed set nodes can be reselected without violating the model parameters or
assumptions. The reselection of a seed set node, simply means paying extra
budget to a previously paid node in order for it to retry its influential
skills on its uninfluenced neighbors. This view divides the influence
maximization process into two cases: the simple case where the reselection of
the nodes is not considered and the reselection case. In this study we will
analyze the behavior of real world networks on the difference between these two
influence maximization cases. First we will show that the difference between
the simple and the reselection cases constitutes a wide spectrum of networks
ranging from the reselection-independent ones, where the reselection case has
no noticeable advantage to the simple case, to the reselection-friendly ones,
where the influence spread in the reselection case is twice the one in the
simple case. Then we will correlate this dynamic to other influence
maximization dynamics of the network. Finally, a significant entanglement
between this dynamic and the network structure is shown and verified by the
experiments. In other words, a series of conditions on the network structure is
specified whose fulfilment is a sign for a reselection-friendly network. As a
result of this entanglement, reselection-friendly networks can be spotted
without performing the time consuming influence maximization algorithms.
</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01892</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end learning potentials for structured attribute prediction</dc:title>
 <dc:creator>Yamaguchi, Kota</dc:creator>
 <dc:creator>Okatani, Takayuki</dc:creator>
 <dc:creator>Umeda, Takayuki</dc:creator>
 <dc:creator>Murasaki, Kazuhiko</dc:creator>
 <dc:creator>Sudo, Kyoko</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a structured inference approach in deep neural networks for
multiple attribute prediction. In attribute prediction, a common approach is to
learn independent classifiers on top of a good feature representation. However,
such classifiers assume conditional independence on features and do not
explicitly consider the dependency between attributes in the inference process.
We propose to formulate attribute prediction in terms of marginal inference in
the conditional random field. We model potential functions by deep neural
networks and apply the sum-product algorithm to solve for the approximate
marginal distribution in feed-forward networks. Our message passing layer
implements sparse pairwise potentials by a softplus-linear function that is
equivalent to a higher-order classifier, and learns all the model parameters by
end-to-end back propagation. The experimental results using SUN attributes and
CelebA datasets suggest that the structured inference improves the attribute
prediction performance, and possibly uncovers the hidden relationship between
attributes.
</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01893</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Effective Generator Impedance for Forced Oscillation Source
  Location</dc:title>
 <dc:creator>Chevalier, Samuel</dc:creator>
 <dc:creator>Vorobev, Petr</dc:creator>
 <dc:creator>Turitsyn, Konstantin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Locating the sources of forced low-frequency oscillations in power systems is
an important problem. A number of proposed methods demonstrate their practical
usefulness, but all of them rely on strong modeling assumptions and provide
poor performance in certain cases for reasons still not well understood. This
paper proposes a systematic method for locating the source of a forced
oscillation by considering a generator response to fluctuations of its terminal
voltage and turbine and exciter inputs. It is shown that a generator can be
represented as an effective admittance matrix with respect to low-frequency
oscillations, and an explicit form for this matrix, for various generator
models, is derived. Furthermore, it is shown that a source generator, in
addition to its effective admittance, is characterized by the presence of an
effective current source thus giving a natural qualitative distinction between
source and nonsource generators. Detailed descriptions are given of a source
detection procedure based on this developed representation, and the method's
efficiency is confirmed by simulations on the recommended testbeds (eg. WECC
179-bus system). This method is free of strong modeling assumptions and is also
shown to be robust in the presence of measurement noise and generator parameter
uncertainty.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01894</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EndNet: Sparse AutoEncoder Network for Endmember Extraction and
  Hyperspectral Unmixing</dc:title>
 <dc:creator>Ozkan, Savas</dc:creator>
 <dc:creator>Kaya, Berk</dc:creator>
 <dc:creator>Esen, Ersin</dc:creator>
 <dc:creator>Akar, Gozde Bozdagi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Data acquired from multi-channel sensors is a highly valuable asset to
interpret the environment for a variety of remote sensing applications.
However, low spatial resolution is a critical limitation for the sensors and
the constituent materials of a scene can be mixed in different fractions due to
their spatial interactions. Spectral unmixing is a technique that allows us to
obtain the material spectral signatures with their fractions from data. In this
paper, we propose a novel hyperspectral unmixing scheme, called EndNet, that is
based on a two-staged autoencoder network. This well-known structure is
completely enhanced and restructured by introducing additional layers and a
projection metric (i.e spectral angle distance (SAD) instead of inner product)
to achieve an optimum solution. Moreover, we present a novel loss function that
is composed of Kullback-Leibler divergence term with SAD similarity and
additional penalty terms to improve the sparsity of the estimates. These
modifications enable us to set the common properties of endmembers such as
nonlinearity and sparsity for autoencoder networks. Lastly, due to the
stochastic-gradient based approach, the method is scalable for large-scale data
and it can be accelerated on Graphical Processing Units (GPUs). To demonstrate
the superiority of our method, we conduct extensive experiments on several
wellknown datasets. The obtained results confirm that our method considerably
improves the performance compared to the state-of-the-art techniques in
literature.
</dc:description>
 <dc:description>Comment: Submitted to Journal</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01897</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine learning in sentiment reconstruction of the simulated stock
  market</dc:title>
 <dc:creator>Goykhman, Mikhail</dc:creator>
 <dc:creator>Teimouri, Ali</dc:creator>
 <dc:subject>Quantitative Finance - Trading and Market Microstructure</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper we continue the study of the simulated stock market framework
defined by the driving sentiment processes. We focus on the market environment
driven by the buy/sell trading sentiment process of the Markov chain type. We
apply the methodology of the Hidden Markov Models and the Recurrent Neural
Networks to reconstruct the transition probabilities matrix of the Markov
sentiment process and recover the underlying sentiment states from the observed
stock price behavior.
</dc:description>
 <dc:description>Comment: 18 pages, 6 figures</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01897</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2017.11.093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01902</identifier>
 <datestamp>2017-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universally consistent predictive distributions</dc:title>
 <dc:creator>Vovk, Vladimir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>68Q32, 62G20 (Primary) 68M20, 68T05 (Secondary)</dc:subject>
 <dc:description>  This paper describes simple universally consistent procedures of probability
forecasting that satisfy a natural property of small-sample validity, under the
assumption that the observations are produced independently in the IID fashion.
</dc:description>
 <dc:description>Comment: 26 pages</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:date>2017-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01903</identifier>
 <datestamp>2017-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grid-Obstacle Representations with Connections to Staircase Guarding</dc:title>
 <dc:creator>Biedl, Therese</dc:creator>
 <dc:creator>Mehrabi, Saeed</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  In this paper, we study grid-obstacle representations of graphs where we
assign grid-points to vertices and define obstacles such that an edge exists if
and only if an $xy$-monotone grid path connects the two endpoints without
hitting an obstacle or another vertex. It was previously argued that all planar
graphs have a grid-obstacle representation in 2D, and all graphs have a
grid-obstacle representation in 3D. In this paper, we show that such
constructions are possible with significantly smaller grid-size than previously
achieved. Then we study the variant where vertices are not blocking, and show
that then grid-obstacle representations exist for bipartite graphs. The latter
has applications in so-called staircase guarding of orthogonal polygons; using
our grid-obstacle representations, we show that staircase guarding is
\textsc{NP}-hard in 2D.
</dc:description>
 <dc:description>Comment: To appear in the proceedings of the 25th International Symposium on
  Graph Drawing and Network Visualization (GD 2017)</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:date>2017-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01910</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empathy in Bimatrix Games</dc:title>
 <dc:creator>Powers, Brian</dc:creator>
 <dc:creator>Smyrnakis, Michalis</dc:creator>
 <dc:creator>Tembine, Hamidou</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Although the definition of what empathetic preferences exactly are is still
evolving, there is a general consensus in the psychology, science and
engineering communities that the evolution toward players' behaviors in
interactive decision-making problems will be accompanied by the exploitation of
their empathy, sympathy, compassion, antipathy, spitefulness, selfishness,
altruism, and self-abnegating states in the payoffs. In this article, we study
one-shot bimatrix games from a psychological game theory viewpoint. A new
empathetic payoff model is calculated to fit empirical observations and both
pure and mixed equilibria are investigated. For a realized empathy structure,
the bimatrix game is categorized among four generic class of games. Number of
interesting results are derived. A notable level of involvement can be observed
in the empathetic one-shot game compared the non-empathetic one and this holds
even for games with dominated strategies. Partial altruism can help in breaking
symmetry, in reducing payoff-inequality and in selecting social welfare and
more efficient outcomes. By contrast, partial spite and self-abnegating may
worsen payoff equity. Empathetic evolutionary game dynamics are introduced to
capture the resulting empathetic evolutionarily stable strategies under wide
range of revision protocols including Brown-von Neumann-Nash, Smith, imitation,
replicator, and hybrid dynamics. Finally, mutual support and Berge solution are
investigated and their connection with empathetic preferences are established.
We show that pure altruism is logically inconsistent, only by balancing it with
some partial selfishness does it create a consistent psychology.
</dc:description>
 <dc:description>Comment: 24 pages, 9 figures</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01911</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training of Deep Neural Networks based on Distance Measures using
  RMSProp</dc:title>
 <dc:creator>Kurbiel, Thomas</dc:creator>
 <dc:creator>Khaleghian, Shahrzad</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The vanishing gradient problem was a major obstacle for the success of deep
learning. In recent years it was gradually alleviated through multiple
different techniques. However the problem was not really overcome in a
fundamental way, since it is inherent to neural networks with activation
functions based on dot products. In a series of papers, we are going to analyze
alternative neural network structures which are not based on dot products. In
this first paper, we revisit neural networks built up of layers based on
distance measures and Gaussian activation functions. These kinds of networks
were only sparsely used in the past since they are hard to train when using
plain stochastic gradient descent methods. We show that by using Root Mean
Square Propagation (RMSProp) it is possible to efficiently learn multi-layer
neural networks. Furthermore we show that when appropriately initialized these
kinds of neural networks suffer much less from the vanishing and exploding
gradient problem than traditional neural networks even for deep networks.
</dc:description>
 <dc:description>Comment: 6 pages, 14 figure</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01925</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing Autonomous Vehicles: Evaluating the Role of Human Emotions and
  Social Norms</dc:title>
 <dc:creator>Riaz, Faisal</dc:creator>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>I.6</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:subject>D.4.8</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  Humans are going to delegate the rights of driving to the autonomous vehicles
in near future. However, to fulfill this complicated task, there is a need for
a mechanism, which enforces the autonomous vehicles to obey the road and social
rules that have been practiced by well-behaved drivers. This task can be
achieved by introducing social norms compliance mechanism in the autonomous
vehicles. This research paper is proposing an artificial society of autonomous
vehicles as an analogy of human social society. Each AV has been assigned a
social personality having different social influence. Social norms have been
introduced which help the AVs in making the decisions, influenced by emotions,
regarding road collision avoidance. Furthermore, social norms compliance
mechanism, by artificial social AVs, has been proposed using prospect based
emotion i.e. fear, which is conceived from OCC model. Fuzzy logic has been
employed to compute the emotions quantitatively. Then, using SimConnect
approach, fuzzy values of fear has been provided to the Netlogo simulation
environment to simulate artificial society of AVs. Extensive testing has been
performed using the behavior space tool to find out the performance of the
proposed approach in terms of the number of collisions. For comparison, the
random-walk model based artificial society of AVs has been proposed as well. A
comparative study with a random walk, prove that proposed approach provides a
better option to tailor the autopilots of future AVS, Which will be more
socially acceptable and trustworthy by their riders in terms of safe road
travel.
</dc:description>
 <dc:description>Comment: 42 pages, 12 figures</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01925</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01927</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emotion Controlled Spectrum Mobility Scheme for Efficient Syntactic
  Interoperability In Cognitive Radio Based Internet of Vehicles</dc:title>
 <dc:creator>Riaz, Faisal</dc:creator>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>C.2.5</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:description>  Blind spots are one of the causes of road accidents in the hilly and flat
areas. These blind spot accidents can be decreased by establishing an Internet
of Vehicles (IoV) using Vehicle-2-Vehicle (V2V) and Vehicle-2-Infrastrtructure
(V2I) communication systems. But the problem with these IoV is that most of
them are using DSRC or single Radio Access Technology (RAT) as a wireless
technology, which has been proven to be failed for efficient communication
between vehicles. Recently, Cognitive Radio (CR) based IoV have to be proven
best wireless communication systems for vehicular networks. However, the
spectrum mobility is a challenging task to keep CR based vehicular networks
interoperable and has not been addressed sufficiently in existing research. In
our previous research work, the Cognitive Radio Site (CR-Site) has been
proposed as in-vehicle CR-device, which can be utilized to establish efficient
IoV systems. H In this paper, we have introduced the Emotions Inspired
Cognitive Agent (EIC_Agent) based spectrum mobility mechanism in CR-Site and
proposed a novel emotions controlled spectrum mobility scheme for efficient
syntactic interoperability between vehicles. For this purpose, a probabilistic
deterministic finite automaton using fear factor is proposed to perform
efficient spectrum mobility using fuzzy logic. In addition, the quantitative
computation of different fear intensity levels has been performed with the help
of fuzzy logic. The system has been tested using active data from different GSM
service providers on Mangla-Mirpur road. This is supplemented by extensive
simulation experiments which validate the proposed scheme for CR based
high-speed vehicular networks. The qualitative comparison with the
existing-state-of the-art has proven the superiority of the proposed emotions
controlled syntactic interoperable spectrum mobility scheme within cognitive
radio based IoV systems.
</dc:description>
 <dc:description>Comment: 33 pages, 16 figures</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01928</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully Convolutional Networks for Diabetic Foot Ulcer Segmentation</dc:title>
 <dc:creator>Goyal, Manu</dc:creator>
 <dc:creator>Reeves, Neil D.</dc:creator>
 <dc:creator>Rajbhandari, Satyan</dc:creator>
 <dc:creator>Spragg, Jennifer</dc:creator>
 <dc:creator>Yap, Moi Hoon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Diabetic Foot Ulcer (DFU) is a major complication of Diabetes, which if not
managed properly can lead to amputation. DFU can appear anywhere on the foot
and can vary in size, colour, and contrast depending on various pathologies.
Current clinical approaches to DFU treatment rely on patients and clinician
vigilance, which has significant limitations such as the high cost involved in
the diagnosis, treatment and lengthy care of the DFU. We introduce a dataset of
705 foot images. We provide the ground truth of ulcer region and the
surrounding skin that is an important indicator for clinicians to assess the
progress of ulcer. Then, we propose a two-tier transfer learning from bigger
datasets to train the Fully Convolutional Networks (FCNs) to automatically
segment the ulcer and surrounding skin. Using 5-fold cross-validation, the
proposed two-tier transfer learning FCN Models achieve a Dice Similarity
Coefficient of 0.794 ($\pm$0.104) for ulcer region, 0.851 ($\pm$0.148) for
surrounding skin region, and 0.899 ($\pm$0.072) for the combination of both
regions. This demonstrates the potential of FCNs in DFU segmentation, which can
be further improved with a larger dataset.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, 2017 IEEE SMC International Conference (To
  appear)</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01930</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhanced Emotion Enabled Cognitive Agent Based Rear End Collision
  Avoidance Controller for Autonomous Vehicles</dc:title>
 <dc:creator>Riaz, Faisal</dc:creator>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>I.2.9, I.2.8, I.2.11, I.6, I.6.1, I.6.6</dc:subject>
 <dc:description>  Rear end collisions are deadliest in nature and cause most of traffic
casualties and injuries. In the existing research, many rear end collision
avoidance solutions have been proposed. However, the problem with these
proposed solutions is that they are highly dependent on precise mathematical
models. Whereas, the real road driving is influenced by non-linear factors such
as road surface situations, driver reaction time, pedestrian flow and vehicle
dynamics, hence obtaining the accurate mathematical model of the vehicle
control system is challenging. This problem with precise control based rear end
collision avoidance schemes has been addressed using fuzzy logic, but the
excessive number of fuzzy rules straightforwardly prejudice their efficiency.
Furthermore, these fuzzy logic based controllers have been proposed without
using proper agent based modeling that helps in mimicking the functions of an
artificial human driver executing these fuzzy rules. Keeping in view these
limitations, we have proposed an Enhanced Emotion Enabled Cognitive Agent
(EEEC_Agent) based controller that helps the Autonomous Vehicles (AVs) to
perform rear end collision avoidance with less number of rules, designed after
fear emotion, and high efficiency. To introduce a fear emotion generation
mechanism in EEEC_Agent, Orton, Clore &amp; Collins (OCC) model has been employed.
The fear generation mechanism of EEEC_Agent has been verified using NetLogo
simulation. Furthermore, practical validation of EEEC_Agent functions has been
performed using specially built prototype AV platform. Eventually, the
qualitative comparative study with existing state of the art research works
reflect that proposed model outperforms recent research.
</dc:description>
 <dc:description>Comment: 39 pages, 17 figures</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01930</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01931</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Social Autonomous Vehicles: Efficient Collision Avoidance Scheme
  Using Richardson's Arms Race Model</dc:title>
 <dc:creator>Riaz, Faisal</dc:creator>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>I.2.9, I.6.6, I.6.1, I.6.8, I.2.11</dc:subject>
 <dc:description>  Background Road collisions and casualties pose a serious threat to commuters
around the globe. Autonomous Vehicles (AVs) aim to make the use of technology
to reduce the road accidents. However, the most of research work in the context
of collision avoidance has been performed to address, separately, the rear end,
front end and lateral collisions in less congested and with high
inter-vehicular distances. Purpose The goal of this paper is to introduce the
concept of a social agent, which interact with other AVs in social manners like
humans are social having the capability of predicting intentions, i.e.
mentalizing and copying the actions of each other, i.e. mirroring. The proposed
social agent is based on a human-brain inspired mentalizing and mirroring
capabilities and has been modelled for collision detection and avoidance under
congested urban road traffic.
  Method We designed our social agent having the capabilities of mentalizing
and mirroring and for this purpose we utilized Exploratory Agent Based Modeling
(EABM) level of Cognitive Agent Based Computing (CABC) framework proposed by
Niazi and Hussain.
  Results Our simulation and practical experiments reveal that by embedding
Richardson's arms race model within AVs, collisions can be avoided while
travelling on congested urban roads in a flock like topologies. The performance
of the proposed social agent has been compared at two different levels.
</dc:description>
 <dc:description>Comment: 48 pages, 21 figures</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01931</dc:identifier>
 <dc:identifier>PLoS ONE12(10): e0186103 (2017)</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0186103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01936</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Face Parsing via Recurrent Propagation</dc:title>
 <dc:creator>Liu, Sifei</dc:creator>
 <dc:creator>Shi, Jianping</dc:creator>
 <dc:creator>Liang, Ji</dc:creator>
 <dc:creator>Yang, Ming-Hsuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face parsing is an important problem in computer vision that finds numerous
applications including recognition and editing. Recently, deep convolutional
neural networks (CNNs) have been applied to image parsing and segmentation with
the state-of-the-art performance. In this paper, we propose a face parsing
algorithm that combines hierarchical representations learned by a CNN, and
accurate label propagations achieved by a spatially variant recurrent neural
network (RNN). The RNN-based propagation approach enables efficient inference
over a global space with the guidance of semantic edges generated by a local
convolutional model. Since the convolutional architecture can be shallow and
the spatial RNN can have few parameters, the framework is much faster and more
light-weighted than the state-of-the-art CNNs for the same task. We apply the
proposed model to coarse-grained and fine-grained face parsing. For
fine-grained face parsing, we develop a two-stage approach by first identifying
the main regions and then segmenting the detail components, which achieves
better performance in terms of accuracy and efficiency. With a single GPU, the
proposed algorithm parses face images accurately at 300 frames per second,
which facilitates real-time applications.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures, BMVC 2017</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01938</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Visually Realistic Multi-robot Simulation in Natural
  Environment</dc:title>
 <dc:creator>Ganoni, Ori</dc:creator>
 <dc:creator>Mukundan, Ramakrishnan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a generalized framework for the simulation of multiple
robots and drones in highly realistic models of natural environments. The
proposed simulation architecture uses the Unreal Engine4 for generating both
optical and depth sensor outputs from any position and orientation within the
environment and provides several key domain specific simulation capabilities.
Various components and functionalities of the system have been discussed in
detail. The simulation engine also allows users to test and validate a wide
range of computer vision algorithms involving different drone configurations
under many types of environmental effects such as wind gusts. The paper
demonstrates the effectiveness of the system by giving experimental results for
a test scenario where one drone tracks the simulated motion of another in a
complex natural environment.
</dc:description>
 <dc:description>Comment: WSCG 2017 conference</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01944</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rookie: A unique approach for exploring news archives</dc:title>
 <dc:creator>Handler, Abram</dc:creator>
 <dc:creator>O'Connor, Brendan</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  News archives are an invaluable primary source for placing current events in
historical context. But current search engine tools do a poor job at uncovering
broad themes and narratives across documents. We present Rookie: a practical
software system which uses natural language processing (NLP) to help readers,
reporters and editors uncover broad stories in news archives. Unlike prior
work, Rookie's design emerged from 18 months of iterative development in
consultation with editors and computational journalists. This process lead to a
dramatically different approach from previous academic systems with similar
goals. Our efforts offer a generalizable case study for others building
real-world journalism software using NLP.
</dc:description>
 <dc:description>Comment: Presented at KDD 2017: Data Science + Journalism workshop</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01945</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bootstrap Method for Error Estimation in Randomized Matrix
  Multiplication</dc:title>
 <dc:creator>Lopes, Miles E.</dc:creator>
 <dc:creator>Wang, Shusen</dc:creator>
 <dc:creator>Mahoney, Michael W.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  In recent years, randomized methods for numerical linear algebra have
received growing interest as a general approach to large-scale problems.
Typically, the essential ingredient of these methods is some form of randomized
dimension reduction, which accelerates computations, but also creates random
approximation error. In this way, the dimension reduction step encodes a
tradeoff between cost and accuracy. However, the exact numerical relationship
between cost and accuracy is typically unknown, and consequently, it may be
difficult for the user to precisely know (1) how accurate a given solution is,
or (2) how much computation is needed to achieve a given level of accuracy. In
the current paper, we study randomized matrix multiplication (sketching) as a
prototype setting for addressing these general problems. As a solution, we
develop a bootstrap method for {directly estimating} the accuracy as a function
of the reduced dimension (as opposed to deriving worst-case bounds on the
accuracy in terms of the reduced dimension). From a computational standpoint,
the proposed method does not substantially increase the cost of standard
sketching methods, and this is made possible by an &quot;extrapolation&quot; technique.
In addition, we provide both theoretical and empirical results to demonstrate
the effectiveness of the proposed method.
</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01946</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intensity Video Guided 4D Fusion for Improved Highly Dynamic 3D
  Reconstruction</dc:title>
 <dc:creator>Zhang, Jie</dc:creator>
 <dc:creator>Maniatis, Christos</dc:creator>
 <dc:creator>Horna, Luis</dc:creator>
 <dc:creator>Fisher, Robert B.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The availability of high-speed 3D video sensors has greatly facilitated 3D
shape acquisition of dynamic and deformable objects, but high frame rate 3D
reconstruction is always degraded by spatial noise and temporal fluctuations.
This paper presents a simple yet powerful intensity video guided multi-frame 4D
fusion pipeline. Temporal tracking of intensity image points (of moving and
deforming objects) allows registration of the corresponding 3D data points,
whose 3D noise and fluctuations are then reduced by spatio-temporal multi-frame
4D fusion. We conducted simulated noise tests and real experiments on four 3D
objects using a 1000 fps 3D video sensor. The results demonstrate that the
proposed algorithm is effective at reducing 3D noise and is robust against
intensity noise. It outperforms existing algorithms with good scalability on
both stationary and dynamic objects.
</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01955</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wasserstein Dictionary Learning: Optimal Transport-based unsupervised
  non-linear dictionary learning</dc:title>
 <dc:creator>Schmitz, Morgan A.</dc:creator>
 <dc:creator>Heitz, Matthieu</dc:creator>
 <dc:creator>Bonneel, Nicolas</dc:creator>
 <dc:creator>Mboula, Fred Maurice Ngol&#xe8;</dc:creator>
 <dc:creator>Coeurjolly, David</dc:creator>
 <dc:creator>Cuturi, Marco</dc:creator>
 <dc:creator>Peyr&#xe9;, Gabriel</dc:creator>
 <dc:creator>Starck, Jean-Luc</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This article introduces a new non-linear dictionary learning method for
histograms in the probability simplex. The method leverages optimal transport
theory, in the sense that our aim is to reconstruct histograms using so called
displacement interpolations (a.k.a. Wasserstein barycenters) between dictionary
atoms; such atoms are themselves synthetic histograms in the probability
simplex. Our method simultaneously estimates such atoms, and, for each
datapoint, the vector of weights that can optimally reconstruct it as an
optimal transport barycenter of such atoms. Our method is computationally
tractable thanks to the addition of an entropic regularization to the usual
optimal transportation problem, leading to an approximation scheme that is
efficient, parallel and simple to differentiate. Both atoms and weights are
learned using a gradient-based descent method. Gradients are obtained by
automatic differentiation of the generalized Sinkhorn iterations that yield
barycenters with entropic smoothing. Because of its formulation relying on
Wasserstein barycenters instead of the usual matrix product between dictionary
and codes, our method allows for non-linear relationships between atoms and the
reconstruction of input data. We illustrate its application in several
different image processing settings.
</dc:description>
 <dc:description>Comment: Accepted for publication in SIAM SIIMS. 46 pages, 24 figures</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01956</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PPR-FCN: Weakly Supervised Visual Relation Detection via Parallel
  Pairwise R-FCN</dc:title>
 <dc:creator>Zhang, Hanwang</dc:creator>
 <dc:creator>Kyaw, Zawlin</dc:creator>
 <dc:creator>Yu, Jinyang</dc:creator>
 <dc:creator>Chang, Shih-Fu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We aim to tackle a novel vision task called Weakly Supervised Visual Relation
Detection (WSVRD) to detect &quot;subject-predicate-object&quot; relations in an image
with object relation groundtruths available only at the image level. This is
motivated by the fact that it is extremely expensive to label the combinatorial
relations between objects at the instance level. Compared to the extensively
studied problem, Weakly Supervised Object Detection (WSOD), WSVRD is more
challenging as it needs to examine a large set of regions pairs, which is
computationally prohibitive and more likely stuck in a local optimal solution
such as those involving wrong spatial context. To this end, we present a
Parallel, Pairwise Region-based, Fully Convolutional Network (PPR-FCN) for
WSVRD. It uses a parallel FCN architecture that simultaneously performs pair
selection and classification of single regions and region pairs for object and
relation detection, while sharing almost all computation shared over the entire
image. In particular, we propose a novel position-role-sensitive score map with
pairwise RoI pooling to efficiently capture the crucial context associated with
a pair of objects. We demonstrate the superiority of PPR-FCN over all baselines
in solving the WSVRD challenge by using results of extensive experiments over
two visual relation benchmarks.
</dc:description>
 <dc:description>Comment: To appear in International Conference on Computer Vision (ICCV) 2017,
  Venice, Italy</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01960</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Theory of Distributed Regression with Bias Corrected
  Regularization Kernel Network</dc:title>
 <dc:creator>Guo, Zhengchu</dc:creator>
 <dc:creator>Shi, Lei</dc:creator>
 <dc:creator>Wu, Qiang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68T05</dc:subject>
 <dc:description>  Distributed learning is an effective way to analyze big data. In distributed
regression, a typical approach is to divide the big data into multiple blocks,
apply a base regression algorithm on each of them, and then simply average the
output functions learnt from these blocks. Since the average process will
decrease the variance, not the bias, bias correction is expected to improve the
learning performance if the base regression algorithm is a biased one.
Regularization kernel network is an effective and widely used method for
nonlinear regression analysis. In this paper we will investigate a bias
corrected version of regularization kernel network. We derive the error bounds
when it is applied to a single data set and when it is applied as a base
algorithm in distributed regression. We show that, under certain appropriate
conditions, the optimal learning rates can be reached in both situations.
</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01964</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accurate Light Field Depth Estimation with Superpixel Regularization
  over Partially Occluded Regions</dc:title>
 <dc:creator>Chen, Jie</dc:creator>
 <dc:creator>Hou, Junhui</dc:creator>
 <dc:creator>Ni, Yun</dc:creator>
 <dc:creator>Chau, Lap-Pui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Depth estimation is a fundamental problem for light field photography
applications. Numerous methods have been proposed in recent years, which either
focus on crafting cost terms for more robust matching, or on analyzing the
geometry of scene structures embedded in the epipolar-plane images. Significant
improvements have been made in terms of overall depth estimation error;
however, current state-of-the-art methods still show limitations in handling
intricate occluding structures and complex scenes with multiple occlusions. To
address these challenging issues, we propose a very effective depth estimation
framework which focuses on regularizing the initial label confidence map and
edge strength weights. Specifically, we first detect partially occluded
boundary regions (POBR) via superpixel based regularization. Series of
shrinkage/reinforcement operations are then applied on the label confidence map
and edge strength weights over the POBR. We show that after weight
manipulations, even a low-complexity weighted least squares model can produce
much better depth estimation than state-of-the-art methods in terms of average
disparity error rate, occlusion boundary precision-recall rate, and the
preservation of intricate visual features.
</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01967</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fake News Detection on Social Media: A Data Mining Perspective</dc:title>
 <dc:creator>Shu, Kai</dc:creator>
 <dc:creator>Sliva, Amy</dc:creator>
 <dc:creator>Wang, Suhang</dc:creator>
 <dc:creator>Tang, Jiliang</dc:creator>
 <dc:creator>Liu, Huan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  Social media for news consumption is a double-edged sword. On the one hand,
its low cost, easy access, and rapid dissemination of information lead people
to seek out and consume news from social media. On the other hand, it enables
the wide spread of &quot;fake news&quot;, i.e., low quality news with intentionally false
information. The extensive spread of fake news has the potential for extremely
negative impacts on individuals and society. Therefore, fake news detection on
social media has recently become an emerging research that is attracting
tremendous attention. Fake news detection on social media presents unique
characteristics and challenges that make existing detection algorithms from
traditional news media ineffective or not applicable. First, fake news is
intentionally written to mislead readers to believe false information, which
makes it difficult and nontrivial to detect based on news content; therefore,
we need to include auxiliary information, such as user social engagements on
social media, to help make a determination. Second, exploiting this auxiliary
information is challenging in and of itself as users' social engagements with
fake news produce data that is big, incomplete, unstructured, and noisy.
Because the issue of fake news detection on social media is both challenging
and relevant, we conducted this survey to further facilitate research on the
problem. In this survey, we present a comprehensive review of detecting fake
news on social media, including fake news characterizations on psychology and
social theories, existing algorithms from a data mining perspective, evaluation
metrics and representative datasets. We also discuss related research areas,
open problems, and future research directions for fake news detection on social
media.
</dc:description>
 <dc:description>Comment: ACM SIGKDD Explorations Newsletter, 2017</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:date>2017-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01977</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why Adaptively Collected Data Have Negative Bias and How to Correct for
  It</dc:title>
 <dc:creator>Nie, Xinkun</dc:creator>
 <dc:creator>Tian, Xiaoying</dc:creator>
 <dc:creator>Taylor, Jonathan</dc:creator>
 <dc:creator>Zou, James</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  From scientific experiments to online A/B testing, the previously observed
data often affects how future experiments are performed, which in turn affects
which data will be collected. Such adaptivity introduces complex correlations
between the data and the collection procedure. In this paper, we prove that
when the data collection procedure satisfies natural conditions, then sample
means of the data have systematic \emph{negative} biases. As an example,
consider an adaptive clinical trial where additional data points are more
likely to be tested for treatments that show initial promise. Our surprising
result implies that the average observed treatment effects would underestimate
the true effects of each treatment. We quantitatively analyze the magnitude and
behavior of this negative bias in a variety of settings. We also propose a
novel debiasing algorithm based on selective inference techniques. In
experiments, our method can effectively reduce bias and estimation error.
</dc:description>
 <dc:description>Comment: Accepted to the 21st International Conference on Artificial
  Intelligence and Statistics (AISTATS) 2018, Lanzarote, Spain</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:date>2017-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01980</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Translating Phrases in Neural Machine Translation</dc:title>
 <dc:creator>Wang, Xing</dc:creator>
 <dc:creator>Tu, Zhaopeng</dc:creator>
 <dc:creator>Xiong, Deyi</dc:creator>
 <dc:creator>Zhang, Min</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Phrases play an important role in natural language understanding and machine
translation (Sag et al., 2002; Villavicencio et al., 2005). However, it is
difficult to integrate them into current neural machine translation (NMT) which
reads and generates sentences word by word. In this work, we propose a method
to translate phrases in NMT by integrating a phrase memory storing target
phrases from a phrase-based statistical machine translation (SMT) system into
the encoder-decoder architecture of NMT. At each decoding step, the phrase
memory is first re-written by the SMT model, which dynamically generates
relevant target phrases with contextual information provided by the NMT model.
Then the proposed model reads the phrase memory to make probability estimations
for all phrases in the phrase memory. If phrase generation is carried on, the
NMT decoder selects an appropriate phrase from the memory to perform phrase
translation and updates its decoding state by consuming the words in the
selected phrase. Otherwise, the NMT decoder generates a word from the
vocabulary as the general NMT decoder does. Experiment results on the Chinese
to English translation show that the proposed model achieves significant
improvements over the baseline on various test sets.
</dc:description>
 <dc:description>Comment: Accepted by EMNLP 2017</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01986</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying 3 moss species by deep learning, using the &quot;chopped picture&quot;
  method</dc:title>
 <dc:creator>Ise, Takeshi</dc:creator>
 <dc:creator>Minagawa, Mari</dc:creator>
 <dc:creator>Onishi, Masanori</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In general, object identification tends not to work well on ambiguous,
amorphous objects such as vegetation. In this study, we developed a simple but
effective approach to identify ambiguous objects and applied the method to
several moss species. As a result, the model correctly classified test images
with accuracy more than 90%. Using this approach will help progress in computer
vision studies.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, 1 table</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01988</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identity-Aware Textual-Visual Matching with Latent Co-attention</dc:title>
 <dc:creator>Li, Shuang</dc:creator>
 <dc:creator>Xiao, Tong</dc:creator>
 <dc:creator>Li, Hongsheng</dc:creator>
 <dc:creator>Yang, Wei</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Textual-visual matching aims at measuring similarities between sentence
descriptions and images. Most existing methods tackle this problem without
effectively utilizing identity-level annotations. In this paper, we propose an
identity-aware two-stage framework for the textual-visual matching problem. Our
stage-1 CNN-LSTM network learns to embed cross-modal features with a novel
Cross-Modal Cross-Entropy (CMCE) loss. The stage-1 network is able to
efficiently screen easy incorrect matchings and also provide initial training
point for the stage-2 training. The stage-2 CNN-LSTM network refines the
matching results with a latent co-attention mechanism. The spatial attention
relates each word with corresponding image regions while the latent semantic
attention aligns different sentence structures to make the matching results
more robust to sentence structure variations. Extensive experiments on three
datasets with identity-level annotations show that our framework outperforms
state-of-the-art approaches by large margins.
</dc:description>
 <dc:description>Comment: Accepted to ICCV 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01997</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Research on Human Dynamics of Information Release of WeChat Users</dc:title>
 <dc:creator>Zhang, Juliang</dc:creator>
 <dc:creator>Zhang, Shengtai</dc:creator>
 <dc:creator>Duo, Fan</dc:creator>
 <dc:creator>Wang, Feifei</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The information release behavior of WeChat users is influenced by many
factors, and studying the rules of the behavior of users in WeChat can provide
theoretical help for the dynamic research of mobile social network users. By
crawling WeChat moments information of nine users within 5 years, we used the
human behavioral dynamics system to analyze users' behavior. The results show
that the information distribution behavior of WeChat users is consistent with
the power-law distribution for a certain period of time. Meanwhile, there is an
anti-memory characteristic in information release behavior of WeChat users,
which is significantly different from other user behavior patterns in online
social networks. The results of the study provide theoretical support for the
further study of information release behavior of Wechat users.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02000</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Social Group Dynamics</dc:title>
 <dc:creator>Saganowski, Stanis&#x142;aw</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In this thesis the method for social group evolution discovery, called GED,
is analyzed. Especially, GED method is compared with other methods tracking
changes in groups over time with focus on accuracy, computational cost, ease of
implementation and flexibility of the methods. The methods are evaluated on
overlapping and disjoint social groups. Finally, GED method is run with
different user importance measures.
</dc:description>
 <dc:description>Comment: My MSc thesis defended in June 2011. Please cite as: Saganowski S.
  Analysis of Social Group Dynamics, MSc thesis 2011</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02001</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Amulet: Aggregating Multi-level Convolutional Features for Salient
  Object Detection</dc:title>
 <dc:creator>Zhang, Pingping</dc:creator>
 <dc:creator>Wang, Dong</dc:creator>
 <dc:creator>Lu, Huchuan</dc:creator>
 <dc:creator>Wang, Hongyu</dc:creator>
 <dc:creator>Ruan, Xiang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Fully convolutional neural networks (FCNs) have shown outstanding performance
in many dense labeling problems. One key pillar of these successes is mining
relevant information from features in convolutional layers. However, how to
better aggregate multi-level convolutional feature maps for salient object
detection is underexplored. In this work, we present Amulet, a generic
aggregating multi-level convolutional feature framework for salient object
detection. Our framework first integrates multi-level feature maps into
multiple resolutions, which simultaneously incorporate coarse semantics and
fine details. Then it adaptively learns to combine these feature maps at each
resolution and predict saliency maps with the combined features. Finally, the
predicted results are efficiently fused to generate the final saliency map. In
addition, to achieve accurate boundary inference and semantic enhancement,
edge-aware feature maps in low-level layers and the predicted results of low
resolution features are recursively embedded into the learning framework. By
aggregating multi-level convolutional features in this efficient and flexible
manner, the proposed saliency model provides accurate salient object labeling.
Comprehensive experiments demonstrate that our method performs favorably
against state-of-the art approaches in terms of near all compared evaluation
metrics.
</dc:description>
 <dc:description>Comment: Accepted as a poster in ICCV 2017, including 10 pages, 5 figures and
  2 tables</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02002</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Focal Loss for Dense Object Detection</dc:title>
 <dc:creator>Lin, Tsung-Yi</dc:creator>
 <dc:creator>Goyal, Priya</dc:creator>
 <dc:creator>Girshick, Ross</dc:creator>
 <dc:creator>He, Kaiming</dc:creator>
 <dc:creator>Doll&#xe1;r, Piotr</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The highest accuracy object detectors to date are based on a two-stage
approach popularized by R-CNN, where a classifier is applied to a sparse set of
candidate object locations. In contrast, one-stage detectors that are applied
over a regular, dense sampling of possible object locations have the potential
to be faster and simpler, but have trailed the accuracy of two-stage detectors
thus far. In this paper, we investigate why this is the case. We discover that
the extreme foreground-background class imbalance encountered during training
of dense detectors is the central cause. We propose to address this class
imbalance by reshaping the standard cross entropy loss such that it
down-weights the loss assigned to well-classified examples. Our novel Focal
Loss focuses training on a sparse set of hard examples and prevents the vast
number of easy negatives from overwhelming the detector during training. To
evaluate the effectiveness of our loss, we design and train a simple dense
detector we call RetinaNet. Our results show that when trained with the focal
loss, RetinaNet is able to match the speed of previous one-stage detectors
while surpassing the accuracy of all existing state-of-the-art two-stage
detectors.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02005</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory-augmented Neural Machine Translation</dc:title>
 <dc:creator>Feng, Yang</dc:creator>
 <dc:creator>Zhang, Shiyue</dc:creator>
 <dc:creator>Zhang, Andi</dc:creator>
 <dc:creator>Wang, Dong</dc:creator>
 <dc:creator>Abel, Andrew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Neural machine translation (NMT) has achieved notable success in recent
times, however it is also widely recognized that this approach has limitations
with handling infrequent words and word pairs. This paper presents a novel
memory-augmented NMT (M-NMT) architecture, which stores knowledge about how
words (usually infrequently encountered ones) should be translated in a memory
and then utilizes them to assist the neural model. We use this memory mechanism
to combine the knowledge learned from a conventional statistical machine
translation system and the rules learned by an NMT system, and also propose a
solution for out-of-vocabulary (OOV) words based on this framework. Our
experiments on two Chinese-English translation tasks demonstrated that the
M-NMT architecture outperformed the NMT baseline by $9.0$ and $2.7$ BLEU points
on the two tasks, respectively. Additionally, we found this architecture
resulted in a much more effective OOV treatment compared to competitive
methods.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02018</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SmartMTD: A Graph-Based Approach for Effective Multi-Truth Discovery</dc:title>
 <dc:creator>Fang, Xiu Susie</dc:creator>
 <dc:creator>Sheng, Quan Z.</dc:creator>
 <dc:creator>Wang, Xianzhi</dc:creator>
 <dc:creator>Ngu, Anne H. H.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The Big Data era features a huge amount of data that are contributed by
numerous sources and used by many critical data-driven applications. Due to the
varying reliability of sources, it is common to see conflicts among the
multi-source data, making it difficult to determine which data sources to
trust. Recently, truth discovery has emerged as a means of addressing this
challenging issue by determining data veracity jointly with estimating the
reliability of data sources. A fundamental issue with current truth discovery
methods is that they generally assume only one true value for each object,
while in reality, objects may have multiple true values. In this paper, we
propose a graph-based approach, called SmartMTD, to unravel the truth discovery
problem beyond the single-truth assumption, or the multi-truth discovery
problem. SmartMTD models and quantifies two types of source relations to
estimate source reliability precisely and to detect malicious agreement among
sources for effective multi-truth discovery. In particular, two graphs are
constructed based on the modeled source relations. They are further used to
derive the two aspects of source reliability (i.e., positive precision and
negative precision) via random walk computation. Empirical studies on two large
real-world datasets demonstrate the effectiveness of our approach.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02019</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Outage Probability and Rate for $\kappa$-$\mu$ Shadowed Fading in
  Interference Limited Scenario</dc:title>
 <dc:creator>Kumar, Suman</dc:creator>
 <dc:creator>Kalyani, Sheetal</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The $\kappa$-$\mu$ shadowed fading model is a very general fading model as it
includes both $\kappa$-$\mu$ and $\eta$-$\mu$ as special cases. In this work,
we derive the expression for outage probability when the signal-of-interest
(SoI) and interferers both experience $\kappa$-$\mu$ shadowed fading in an
interference limited scenario. The derived expression is valid for arbitrary
SoI parameters, arbitrary $\kappa$ and $\mu$ parameters for all interferers and
any value of the parameter $m$ for the interferers excepting the limiting value
of $m\rightarrow \infty$. The expression can be expressed in terms of
Pochhammer integral where the integrands of integral only contains elementary
functions. The outage probability expression is then simplified for various
special cases, especially when SoI experiences $\eta$-$\mu$ or $\kappa$-$\mu$
fading. Further, the rate expression is derived when the SoI experiences
$\kappa$-$\mu$ shadowed fading with integer values of $\mu$, and interferers
experience $\kappa$-$\mu$ shadowed fading with arbitrary parameters. The rate
expression can be expressed in terms of sum of Lauricella's function of the
fourth kind. The utility of our results is demonstrated by using the derived
expression to study and compare FFR and SFR in the presence of $\kappa$-$\mu$
shadowed fading. Extensive simulation results are provided and these further
validate our theoretical results.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02029</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Appearance to Essence: Comparing Truth Discovery Methods without
  Using Ground Truth</dc:title>
 <dc:creator>Fang, Xiu Susie</dc:creator>
 <dc:creator>Sheng, Quan Z.</dc:creator>
 <dc:creator>Wang, Xianzhi</dc:creator>
 <dc:creator>Zhang, Wei Emma</dc:creator>
 <dc:creator>Ngu, Anne H. H.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Truth discovery has been widely studied in recent years as a fundamental
means for resolving the conflicts in multi-source data. Although many truth
discovery methods have been proposed based on different considerations and
intuitions, investigations show that no single method consistently outperforms
the others. To select the right truth discovery method for a specific
application scenario, it becomes essential to evaluate and compare the
performance of different methods. A drawback of current research efforts is
that they commonly assume the availability of certain ground truth for the
evaluation of methods. However, the ground truth may be very limited or even
out-of-reach in practice, rendering the evaluation biased by the small ground
truth or even unfeasible. In this paper, we present CompTruthHyp, a general
approach for comparing the performance of truth discovery methods without using
ground truth. In particular, our approach calculates the probability of
observations in a dataset based on the output of different methods. The
probability is then ranked to reflect the performance of these methods. We
review and compare twelve existing truth discovery methods and consider both
single-valued and multi-valued objects. Empirical studies on both real-world
and synthetic datasets demonstrate the effectiveness of our approach for
comparing truth discovery methods.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02030</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CRAFT: A library for easier application-level Checkpoint/Restart and
  Automatic Fault Tolerance</dc:title>
 <dc:creator>Shahzad, Faisal</dc:creator>
 <dc:creator>Thies, Jonas</dc:creator>
 <dc:creator>Kreutzer, Moritz</dc:creator>
 <dc:creator>Zeiser, Thomas</dc:creator>
 <dc:creator>Hager, Georg</dc:creator>
 <dc:creator>Wellein, Gerhard</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In order to efficiently use the future generations of supercomputers, fault
tolerance and power consumption are two of the prime challenges anticipated by
the High Performance Computing (HPC) community. Checkpoint/Restart (CR) has
been and still is the most widely used technique to deal with hard failures.
Application-level CR is the most effective CR technique in terms of overhead
efficiency but it takes a lot of implementation effort. This work presents the
implementation of our C++ based library CRAFT (Checkpoint-Restart and Automatic
Fault Tolerance), which serves two purposes. First, it provides an extendable
library that significantly eases the implementation of application-level
checkpointing. The most basic and frequently used checkpoint data types are
already part of CRAFT and can be directly used out of the box. The library can
be easily extended to add more data types. As means of overhead reduction, the
library offers a build-in asynchronous checkpointing mechanism and also
supports the Scalable Checkpoint/Restart (SCR) library for node level
checkpointing. Second, CRAFT provides an easier interface for User-Level
Failure Mitigation (ULFM) based dynamic process recovery, which significantly
reduces the complexity and effort of failure detection and communication
recovery mechanism. By utilizing both functionalities together, applications
can write application-level checkpoints and recover dynamically from process
failures with very limited programming effort. This work presents the design
and use of our library in detail. The associated overheads are thoroughly
analyzed using several benchmarks.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02031</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Uncertain Convolutional Features for Accurate Saliency
  Detection</dc:title>
 <dc:creator>Zhang, Pingping</dc:creator>
 <dc:creator>Wang, Dong</dc:creator>
 <dc:creator>Lu, Huchuan</dc:creator>
 <dc:creator>Wang, Hongyu</dc:creator>
 <dc:creator>Yin, Baocai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep convolutional neural networks (CNNs) have delivered superior performance
in many computer vision tasks. In this paper, we propose a novel deep fully
convolutional network model for accurate salient object detection. The key
contribution of this work is to learn deep uncertain convolutional features
(UCF), which encourage the robustness and accuracy of saliency detection. We
achieve this via introducing a reformulated dropout (R-dropout) after specific
convolutional layers to construct an uncertain ensemble of internal feature
units. In addition, we propose an effective hybrid upsampling method to reduce
the checkerboard artifacts of deconvolution operators in our decoder network.
The proposed methods can also be applied to other deep convolutional networks.
Compared with existing saliency detection methods, the proposed UCF model is
able to incorporate uncertainties for more accurate object boundary inference.
Extensive experiments demonstrate that our proposed saliency model performs
favorably against state-of-the-art approaches. The uncertain feature learning
mechanism as well as the upsampling method can significantly improve
performance on other pixel-wise vision tasks.
</dc:description>
 <dc:description>Comment: Accepted as a poster in ICCV 2017,including 10 pages, 7 figures and 3
  tables</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02033</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Solution for Crime Scene Reconstruction using Time-of-Flight Cameras</dc:title>
 <dc:creator>Giancola, Silvio</dc:creator>
 <dc:creator>Piron, Daniele</dc:creator>
 <dc:creator>Poppa, Pasquale</dc:creator>
 <dc:creator>Sala, Remo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we propose a method for three-dimensional (3D) reconstruction
of wide crime scene, based on a Simultaneous Localization and Mapping (SLAM)
approach. We used a Kinect V2 Time-of-Flight (TOF) RGB-D camera to provide
colored dense point clouds at a 30 Hz frequency. This device is moved freely (6
degrees of freedom) during the scene exploration. The implemented SLAM solution
aligns successive point clouds using an 3D keypoints description and matching
approach. This type of approach exploits both colorimetric and geometrical
information, and permits reconstruction under poor illumination conditions. Our
solution has been tested for indoor crime scene and outdoor archaeological site
reconstruction, returning a mean error around one centimeter. It is less
precise than environmental laser scanner solution, but more practical and
portable as well as less cumbersome. Also, the hardware is definitively
cheaper.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02037</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unbalancing Sets and an Almost Quadratic Lower Bound for Syntactically
  Multilinear Arithmetic Circuits</dc:title>
 <dc:creator>Alon, Noga</dc:creator>
 <dc:creator>Kumar, Mrinal</dc:creator>
 <dc:creator>Volk, Ben Lee</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We prove a lower bound of $\Omega(n^2/\log^2 n)$ on the size of any
syntactically multilinear arithmetic circuit computing some explicit
multilinear polynomial $f(x_1, \ldots, x_n)$. Our approach expands and improves
upon a result of Raz, Shpilka and Yehudayoff ([RSY08]), who proved a lower
bound of $\Omega(n^{4/3}/\log^2 n)$ for the same polynomial. Our improvement
follows from an asymptotically optimal lower bound for a generalized version of
Galvin's problem in extremal set theory.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02043</identifier>
 <datestamp>2017-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption
  Generator?</dc:title>
 <dc:creator>Tanti, Marc</dc:creator>
 <dc:creator>Gatt, Albert</dc:creator>
 <dc:creator>Camilleri, Kenneth P.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In neural image captioning systems, a recurrent neural network (RNN) is
typically viewed as the primary `generation' component. This view suggests that
the image features should be `injected' into the RNN. This is in fact the
dominant view in the literature. Alternatively, the RNN can instead be viewed
as only encoding the previously generated words. This view suggests that the
RNN should only be used to encode linguistic features and that only the final
representation should be `merged' with the image features at a later stage.
This paper compares these two architectures. We find that, in general, late
merging outperforms injection, suggesting that RNNs are better viewed as
encoders, rather than generators.
</dc:description>
 <dc:description>Comment: Appears in: Proceedings of the 10th International Conference on
  Natural Language Generation (INLG'17)</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02044</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unconstrained Fashion Landmark Detection via Hierarchical Recurrent
  Transformer Networks</dc:title>
 <dc:creator>Yan, Sijie</dc:creator>
 <dc:creator>Liu, Ziwei</dc:creator>
 <dc:creator>Luo, Ping</dc:creator>
 <dc:creator>Qiu, Shi</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:creator>Tang, Xiaoou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Fashion landmarks are functional key points defined on clothes, such as
corners of neckline, hemline, and cuff. They have been recently introduced as
an effective visual representation for fashion image understanding. However,
detecting fashion landmarks are challenging due to background clutters, human
poses, and scales. To remove the above variations, previous works usually
assumed bounding boxes of clothes are provided in training and test as
additional annotations, which are expensive to obtain and inapplicable in
practice. This work addresses unconstrained fashion landmark detection, where
clothing bounding boxes are not provided in both training and test. To this
end, we present a novel Deep LAndmark Network (DLAN), where bounding boxes and
landmarks are jointly estimated and trained iteratively in an end-to-end
manner. DLAN contains two dedicated modules, including a Selective Dilated
Convolution for handling scale discrepancies, and a Hierarchical Recurrent
Spatial Transformer for handling background clutters. To evaluate DLAN, we
present a large-scale fashion landmark dataset, namely Unconstrained Landmark
Database (ULD), consisting of 30K images. Statistics show that ULD is more
challenging than existing datasets in terms of image scales, background
clutters, and human poses. Extensive experiments demonstrate the effectiveness
of DLAN over the state-of-the-art methods. DLAN also exhibits excellent
generalization across different clothing categories and modalities, making it
extremely suitable for real-world fashion analysis.
</dc:description>
 <dc:description>Comment: To appear in ACM Multimedia (ACM MM) 2017 as a full research paper.
  More details at the project page:
  http://personal.ie.cuhk.edu.hk/~lz013/projects/UnconstrainedLandmarks.html</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02048</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Continuous Power Modulation for Exchanging Local Channel State
  Information</dc:title>
 <dc:creator>Zhang, Chao</dc:creator>
 <dc:creator>Lasaulce, Samson</dc:creator>
 <dc:creator>Varma, Vineeth S.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter provides a simple but efficient technique, which allows each
transmitter of an interference network, to exchange local channel state
information with the other transmitters. One salient feature of the proposed
technique is that a transmitter only needs measurements of the signal power at
its intended receiver to implement it, making direct inter-transmitter
signaling channels unnecessary. The key idea to achieve this is to use a
transient period during which the continuous power level of a transmitter is
taken to be the linear combination of the channel gains to be exchanged.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02048</dc:identifier>
 <dc:identifier>IEEE Communications Letters ( Volume: 21, Issue: 5, May 2017 )</dc:identifier>
 <dc:identifier>doi:10.1109/LCOMM.2017.2650919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02052</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VART: A Tool for the Automatic Detection of Regression Faults</dc:title>
 <dc:creator>Pastore, Fabrizio</dc:creator>
 <dc:creator>Mariani, Leonardo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this paper we present VART, a tool for automatically revealing regression
faults missed by regression test suites. Interestingly, VART is not limited to
faults causing crashing or exceptions, but can reveal faults that cause the
violation of application-specific correctness properties. VART achieves this
goal by combining static and dynamic program analysis.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02052</dc:identifier>
 <dc:identifier>doi:10.1145/3106237.3122819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02054</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pseudorandom Bits for Oblivious Branching Programs</dc:title>
 <dc:creator>Gurjar, Rohit</dc:creator>
 <dc:creator>Volk, Ben Lee</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We construct a pseudorandom generator which fools read-$k$ oblivious
branching programs and, more generally, any linear length oblivious branching
program, assuming that the sequence according to which the bits are read is
known in advance. For polynomial width branching programs, the seed lengths in
our constructions are $\tilde{O}(n^{1-1/2^{k-1}})$ (for the read-$k$ case) and
$O(n/ \log \log n)$ (for the linear length case). Previously, the best
construction for these models required seed length $(1-\Omega(1))n$.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02054</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02059</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonconvex Sparse Logistic Regression with Weakly Convex Regularization</dc:title>
 <dc:creator>Shen, Xinyue</dc:creator>
 <dc:creator>Gu, Yuantao</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this work we propose to fit a sparse logistic regression model by a weakly
convex regularized nonconvex optimization problem. The idea is based on the
finding that a weakly convex function as an approximation of the $\ell_0$
pseudo norm is able to better induce sparsity than the commonly used $\ell_1$
norm. For a class of weakly convex sparsity inducing functions, we prove the
nonconvexity of the corresponding sparse logistic regression problem, and study
its local optimality conditions and the choice of the regularization parameter
to exclude trivial solutions. Despite the nonconvexity, a method based on
proximal gradient descent is used to solve the general weakly convex sparse
logistic regression, and its convergence behavior is studied theoretically.
Then the general framework is applied to a specific weakly convex function, and
a necessary and sufficient local optimality condition is provided. The solution
method is instantiated in this case as an iterative firm-shrinkage algorithm,
and its effectiveness is demonstrated in numerical experiments by both randomly
generated and real datasets.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02062</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fishing in the Stream: Similarity Search over Endless Data</dc:title>
 <dc:creator>Kraus, Naama</dc:creator>
 <dc:creator>Carmel, David</dc:creator>
 <dc:creator>Keidar, Idit</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Similarity search is the task of retrieving data items that are similar to a
given query. In this paper, we introduce the time-sensitive notion of
similarity search over endless data-streams (SSDS), which takes into account
data quality and temporal characteristics in addition to similarity. SSDS is
challenging as it needs to process unbounded data, while computation resources
are bounded. We propose Stream-LSH, a randomized SSDS algorithm that bounds the
index size by retaining items according to their freshness, quality, and
dynamic popularity attributes. We analytically show that Stream-LSH increases
the probability to find similar items compared to alternative approaches using
the same space capacity. We further conduct an empirical study using real world
stream datasets, which confirms our theoretical results.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02068</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Noisy Optimisation with the Sliding Window Compact Genetic
  Algorithm</dc:title>
 <dc:creator>Lucas, Simon M.</dc:creator>
 <dc:creator>Liu, Jialin</dc:creator>
 <dc:creator>P&#xe9;rez-Li&#xe9;bana, Diego</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The compact genetic algorithm is an Estimation of Distribution Algorithm for
binary optimisation problems. Unlike the standard Genetic Algorithm, no
cross-over or mutation is involved. Instead, the compact Genetic Algorithm uses
a virtual population represented as a probability distribution over the set of
binary strings. At each optimisation iteration, exactly two individuals are
generated by sampling from the distribution, and compared exactly once to
determine a winner and a loser. The probability distribution is then adjusted
to increase the likelihood of generating individuals similar to the winner.
  This paper introduces two straightforward variations of the compact Genetic
Algorithm, each of which lead to a significant improvement in performance. The
main idea is to make better use of each fitness evaluation, by ensuring that
each evaluated individual is used in multiple win/loss comparisons. The first
variation is to sample $n&gt;2$ individuals at each iteration to make $n(n-1)/2$
comparisons. The second variation only samples one individual at each iteration
but keeps a sliding history window of previous individuals to compare with. We
evaluate methods on two noisy test problems and show that in each case they
significantly outperform the compact Genetic Algorithm, while maintaining the
simplicity of the algorithm.
</dc:description>
 <dc:description>Comment: 11 pages, 2 tables, 8 figures</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02071</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured Attentions for Visual Question Answering</dc:title>
 <dc:creator>Zhu, Chen</dc:creator>
 <dc:creator>Zhao, Yanpeng</dc:creator>
 <dc:creator>Huang, Shuaiyi</dc:creator>
 <dc:creator>Tu, Kewei</dc:creator>
 <dc:creator>Ma, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual attention, which assigns weights to image regions according to their
relevance to a question, is considered as an indispensable part by most Visual
Question Answering models. Although the questions may involve complex relations
among multiple regions, few attention models can effectively encode such
cross-region relations. In this paper, we demonstrate the importance of
encoding such relations by showing the limited effective receptive field of
ResNet on two datasets, and propose to model the visual attention as a
multivariate distribution over a grid-structured Conditional Random Field on
image regions. We demonstrate how to convert the iterative inference
algorithms, Mean Field and Loopy Belief Propagation, as recurrent layers of an
end-to-end neural network. We empirically evaluated our model on 3 datasets, in
which it surpasses the best baseline model of the newly released CLEVR dataset
by 9.5%, and the best published model on the VQA dataset by 1.25%. Source code
is available at https: //github.com/zhuchen03/vqa-sva.
</dc:description>
 <dc:description>Comment: ICCV2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02072</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Catastrophic Forgetting in Neural Networks</dc:title>
 <dc:creator>Kemker, Ronald</dc:creator>
 <dc:creator>McClure, Marc</dc:creator>
 <dc:creator>Abitino, Angelina</dc:creator>
 <dc:creator>Hayes, Tyler</dc:creator>
 <dc:creator>Kanan, Christopher</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks are used in many state-of-the-art systems for machine
perception. Once a network is trained to do a specific task, e.g., bird
classification, it cannot easily be trained to do new tasks, e.g.,
incrementally learning to recognize additional bird species or learning an
entirely different task such as flower recognition. When new tasks are added,
typical deep neural networks are prone to catastrophically forgetting previous
tasks. Networks that are capable of assimilating new information incrementally,
much like how humans form new memories over time, will be more efficient than
re-training the model from scratch each time a new task needs to be learned.
There have been multiple attempts to develop schemes that mitigate catastrophic
forgetting, but these methods have not been directly compared, the tests used
to evaluate them vary considerably, and these methods have only been evaluated
on small-scale problems (e.g., MNIST). In this paper, we introduce new metrics
and benchmarks for directly comparing five different mechanisms designed to
mitigate catastrophic forgetting in neural networks: regularization,
ensembling, rehearsal, dual-memory, and sparse-coding. Our experiments on
real-world images and sounds show that the mechanism(s) that are critical for
optimal performance vary based on the incremental training paradigm and type of
data being used, but they all demonstrate that the catastrophic forgetting
problem has yet to be solved.
</dc:description>
 <dc:description>Comment: To appear in AAAI 2018</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02074</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning for Active 3D Mapping</dc:title>
 <dc:creator>Zimmermann, Karel</dc:creator>
 <dc:creator>Petricek, Tomas</dc:creator>
 <dc:creator>Salansky, Vojtech</dc:creator>
 <dc:creator>Svoboda, Tomas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose an active 3D mapping method for depth sensors, which allow
individual control of depth-measuring rays, such as the newly emerging
solid-state lidars. The method simultaneously (i) learns to reconstruct a dense
3D occupancy map from sparse depth measurements, and (ii) optimizes the
reactive control of depth-measuring rays. To make the first step towards the
online control optimization, we propose a fast prioritized greedy algorithm,
which needs to update its cost function in only a small fraction of pos- sible
rays. The approximation ratio of the greedy algorithm is derived. An
experimental evaluation on the subset of the KITTI dataset demonstrates
significant improve- ment in the 3D map accuracy when learning-to-reconstruct
from sparse measurements is coupled with the optimization of depth-measuring
rays.
</dc:description>
 <dc:description>Comment: ICCV 2017 (oral). See video:
  https://www.youtube.com/watch?v=KNex0zjeGYE</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02077</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Crossing Lemma for Jordan Curves</dc:title>
 <dc:creator>Pach, J&#xe1;nos</dc:creator>
 <dc:creator>Rubin, Natan</dc:creator>
 <dc:creator>Tardos, G&#xe1;bor</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>05C10, 05C35, 05D99, 52C30, 52C45, 52C10</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  If two Jordan curves in the plane have precisely one point in common, and
there they do not properly cross, then the common point is called a {\em
touching point}. The main result of this paper is a Crossing Lemma for simple
curves: Let $X$ and $T$ stand for the sets of intersection points and touching
points, respectively, in a family of $n$ simple curves in the plane, no three
of which pass through the same point. If $|T|&gt;cn$, for some fixed constant
$c&gt;0$, then we prove that $|X|=\Omega(|T|(\log\log(|T|/n))^{1/504})$. In
particular, if $|T|/n\rightarrow\infty$, then the number of intersection points
is much larger than the number of touching points.
  As a corollary, we confirm the following long-standing conjecture of Richter
and Thomassen: The total number of intersection points between $n$ pairwise
intersecting simple closed (i.e., Jordan) curves in the plane, no three of
which pass through the same point, is at least $(1-o(1))n^2$.
</dc:description>
 <dc:description>Comment: A preliminary version [arXiv:1504.08250], with a somewhat too
  optimistic bound for the pairwise-intersecting case, has appeared in
  proceedings of SODA 2016</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02086</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Insight on the Ratio of Transmission of Motion (RoToM) and its
  Relation to the Centroidal Inertia Matrix</dc:title>
 <dc:creator>Moro, Federico L.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper analyses the dynamic response of a robot when subject to an
external force that is applied to its Center of Mass (CoM). The Ratio of
Transmission of Motion (RoToM) is proposed as a novel indicator of what part of
the applied force generates motion, and what part is dissipated by the passive
forces due to mechanical constraints. It depends on the configuration of the
robot and on the direction of the force, and is always between 0 and 1.
Extending this concept, a transmissibility ellipsoid is used to describe the
behavior of the robot given a certain configuration, and varying the direction
of the applied force. Another physical measure that is related to the
transmissibility ellipsoid is the transmissibility index: it provides an
indication on how similarly the system behaves when subject to forces coming
from different directions. The presented analysis aims to provide a deeper
insight on the centroidal dynamics of a robot, and on its dependence on the
configuration. It can be beneficial for developing whole-body controllers of
redundant robots for e.g., reducing the effort in terms of joint torques to
compensate for gravity, and more in general for designing interaction control
architectures.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02091</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MoPS: A Modular Protection Scheme for Long-Term Storage</dc:title>
 <dc:creator>Weinert, Christian</dc:creator>
 <dc:creator>Demirel, Denise</dc:creator>
 <dc:creator>Vigil, Mart&#xed;n</dc:creator>
 <dc:creator>Geihs, Matthias</dc:creator>
 <dc:creator>Buchmann, Johannes</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Current trends in technology, such as cloud computing, allow outsourcing the
storage, backup, and archiving of data. This provides efficiency and
flexibility, but also poses new risks for data security. It in particular
became crucial to develop protection schemes that ensure security even in the
long-term, i.e. beyond the lifetime of keys, certificates, and cryptographic
primitives. However, all current solutions fail to provide optimal performance
for different application scenarios. Thus, in this work, we present MoPS, a
modular protection scheme to ensure authenticity and integrity for data stored
over long periods of time. MoPS does not come with any requirements regarding
the storage architecture and can therefore be used together with existing
archiving or storage systems. It supports a set of techniques which can be
plugged together, combined, and migrated in order to create customized
solutions that fulfill the requirements of different application scenarios in
the best possible way. As a proof of concept we implemented MoPS and provide
performance measurements. Furthermore, our implementation provides additional
features, such as guidance for non-expert users and export functionalities for
external verifiers.
</dc:description>
 <dc:description>Comment: Original Publication (in the same form): ASIACCS 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02091</dc:identifier>
 <dc:identifier>ASIACCS 2017, pages 436-448</dc:identifier>
 <dc:identifier>doi:10.1145/3052973.3053025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02096</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extraction of Airways with Probabilistic State-space Models and Bayesian
  Smoothing</dc:title>
 <dc:creator>Selvan, Raghavendra</dc:creator>
 <dc:creator>Petersen, Jens</dc:creator>
 <dc:creator>Pedersen, Jesper H.</dc:creator>
 <dc:creator>de Bruijne, Marleen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Segmenting tree structures is common in several image processing
applications. In medical image analysis, reliable segmentations of airways,
vessels, neurons and other tree structures can enable important clinical
applications. We present a framework for tracking tree structures comprising of
elongated branches using probabilistic state-space models and Bayesian
smoothing. Unlike most existing methods that proceed with sequential tracking
of branches, we present an exploratory method, that is less sensitive to local
anomalies in the data due to acquisition noise and/or interfering structures.
The evolution of individual branches is modelled using a process model and the
observed data is incorporated into the update step of the Bayesian smoother
using a measurement model that is based on a multi-scale blob detector.
Bayesian smoothing is performed using the RTS (Rauch-Tung-Striebel) smoother,
which provides Gaussian density estimates of branch states at each tracking
step. We select likely branch seed points automatically based on the response
of the blob detection and track from all such seed points using the RTS
smoother. We use covariance of the marginal posterior density estimated for
each branch to discriminate false positive and true positive branches. The
method is evaluated on 3D chest CT scans to track airways. We show that the
presented method results in additional branches compared to a baseline method
based on region growing on probability images.
</dc:description>
 <dc:description>Comment: 10 pages. Pre-print of the paper accepted at Workshop on Graphs in
  Biomedical Image Analysis. MICCAI 2017. Quebec City</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02099</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal Classification for Analysing Social Media</dc:title>
 <dc:creator>Duong, Chi Thang</dc:creator>
 <dc:creator>Lebret, Remi</dc:creator>
 <dc:creator>Aberer, Karl</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Classification of social media data is an important approach in understanding
user behavior on the Web. Although information on social media can be of
different modalities such as texts, images, audio or videos, traditional
approaches in classification usually leverage only one prominent modality.
Techniques that are able to leverage multiple modalities are often complex and
susceptible to the absence of some modalities. In this paper, we present simple
models that combine information from different modalities to classify social
media content and are able to handle the above problems with existing
techniques. Our models combine information from different modalities using a
pooling layer and an auxiliary learning task is used to learn a common feature
space. We demonstrate the performance of our models and their robustness to the
missing of some modalities in the emotion classification domain. Our
approaches, although being simple, can not only achieve significantly higher
accuracies than traditional fusion approaches but also have comparable results
when only one modality is available.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02100</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aktuelle Entwicklungen in der Automatischen Musikverfolgung</dc:title>
 <dc:creator>Arzt, Andreas</dc:creator>
 <dc:creator>Dorfer, Matthias</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  In this paper we present current trends in real-time music tracking (a.k.a.
score following). Casually speaking, these algorithms &quot;listen&quot; to a live
performance of music, compare the audio signal to an abstract representation of
the score, and &quot;read&quot; along in the sheet music. In this way at any given time
the exact position of the musician(s) in the sheet music is computed. Here, we
focus on the aspects of flexibility and usability of these algorithms. This
comprises work on automatic identification and flexible tracking of the piece
being played as well as current approaches based on Deep Learning. The latter
enables direct learning of correspondences between complex audio data and
images of the sheet music, avoiding the complicated and time-consuming
definition of a mid-level representation.
  -----
  Diese Arbeit befasst sich mit aktuellen Entwicklungen in der automatischen
Musikverfolgung durch den Computer. Es handelt sich dabei um Algorithmen, die
einer musikalischen Auff\&quot;uhrung &quot;zuh\&quot;oren&quot;, das aufgenommene Audiosignal mit
einer (abstrakten) Repr\&quot;asentation des Notentextes vergleichen und sozusagen
in diesem mitlesen. Der Algorithmus kennt also zu jedem Zeitpunkt die Position
der Musiker im Notentext. Neben der Vermittlung eines generellen \&quot;Uberblicks,
liegt der Schwerpunkt dieser Arbeit auf der Beleuchtung des Aspekts der
Flexibilit\&quot;at und der einfacheren Nutzbarkeit dieser Algorithmen. Es wird
dargelegt, welche Schritte get\&quot;atigt wurden (und aktuell get\&quot;atigt werden) um
den Prozess der automatischen Musikverfolgung einfacher zug\&quot;anglich zu machen.
Dies umfasst Arbeiten zur automatischen Identifikation von gespielten St\&quot;ucken
und deren flexible Verfolgung ebenso wie aktuelle Ans\&quot;atze mithilfe von Deep
Learning, die es erlauben Bild und Ton direkt zu verbinden, ohne Umwege \&quot;uber
abstrakte und nur unter gro{\ss}em Zeitaufwand zu erstellende
Zwischenrepr\&quot;asentationen.
</dc:description>
 <dc:description>Comment: In German. Published in Maximilian Eibl, Martin Gaedke (Hrsg.):
  INFORMATIK 2017. Lecture Notes in Informatics (LNI), Gesellschaft f\&quot;ur
  Informatik, Bonn 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02100</dc:identifier>
 <dc:language>de</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02105</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Convergence of a Frank-Wolfe Type Algorithm over Trace-Norm Balls</dc:title>
 <dc:creator>Allen-Zhu, Zeyuan</dc:creator>
 <dc:creator>Hazan, Elad</dc:creator>
 <dc:creator>Hu, Wei</dc:creator>
 <dc:creator>Li, Yuanzhi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a rank-$k$ variant of the classical Frank-Wolfe algorithm to solve
convex optimization over a trace-norm ball. Our algorithm replaces the top
singular-vector computation ($1$-SVD) in Frank-Wolfe with a top-$k$
singular-vector computation ($k$-SVD), which can be done by repeatedly applying
$1$-SVD $k$ times. Alternatively, our algorithm can be viewed as a rank-$k$
restricted version of projected gradient descent. We show that our algorithm
has a linear convergence rate when the objective function is smooth and
strongly convex, and the optimal solution has rank at most $k$. This improves
the convergence rate and the total time complexity of the Frank-Wolfe method
and its variants.
</dc:description>
 <dc:description>Comment: In NIPS 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02108</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-Phase Learning for Weakly Supervised Object Localization</dc:title>
 <dc:creator>Kim, Dahun</dc:creator>
 <dc:creator>Cho, Donghyeon</dc:creator>
 <dc:creator>Yoo, Donggeun</dc:creator>
 <dc:creator>Kweon, In So</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Weakly supervised semantic segmentation and localiza- tion have a problem of
focusing only on the most important parts of an image since they use only
image-level annota- tions. In this paper, we solve this problem fundamentally
via two-phase learning. Our networks are trained in two steps. In the first
step, a conventional fully convolutional network (FCN) is trained to find the
most discriminative parts of an image. In the second step, the activations on
the most salient parts are suppressed by inference conditional feedback, and
then the second learning is performed to find the area of the next most
important parts. By combining the activations of both phases, the entire
portion of the tar- get object can be captured. Our proposed training scheme is
novel and can be utilized in well-designed techniques for weakly supervised
semantic segmentation, salient region detection, and object location
prediction. Detailed experi- ments demonstrate the effectiveness of our
two-phase learn- ing in each task.
</dc:description>
 <dc:description>Comment: Accepted at ICCV 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02114</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Layouts for Plane Graphs on Constant Number of Tracks</dc:title>
 <dc:creator>Wang, Jiun-Jie</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  A \emph{$k$-track} layout of a graph consists of a vertex $k$ colouring, and
a total order of each vertex colour class, such that between each pair of
colour classes no two edges cross. A \emph{$k$-queue} layout of a graph
consists of a total order of the vertices, and a partition of the edges into
$k$ sets such that no two edges that are in the same set are nested with
respect to the vertex ordering. The \emph{track number} (\emph{queue number})
of a graph $G$, is the minimum $k$ such that $G$ has a $k$-track ($k$-queue)
layout. This paper proves that every $n$-vertex plane graph has constant-bound
track and queue numbers. The result implies that every plane has a 3D
crossing-free straight-line grid drawing in $O(n)$ volume. The proof utilizes a
novel graph partition technique.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1302.0304 by other authors</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02125</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>T-Crowd: Effective Crowdsourcing for Tabular Data</dc:title>
 <dc:creator>Shan, Caihua</dc:creator>
 <dc:creator>Mamoulis, Nikos</dc:creator>
 <dc:creator>Li, Guoliang</dc:creator>
 <dc:creator>Cheng, Reynold</dc:creator>
 <dc:creator>Huang, Zhipeng</dc:creator>
 <dc:creator>Zheng, Yudian</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Crowdsourcing employs human workers to solve computer-hard problems, such as
data cleaning, entity resolution, and sentiment analysis. When crowdsourcing
tabular data, e.g., the attribute values of an entity set, a worker's answers
on the different attributes (e.g., the nationality and age of a celebrity star)
are often treated independently. This assumption is not always true and can
lead to suboptimal crowdsourcing performance. In this paper, we present the
T-Crowd system, which takes into consideration the intricate relationships
among tasks, in order to converge faster to their true values. Particularly,
T-Crowd integrates each worker's answers on different attributes to effectively
learn his/her trustworthiness and the true data values. The attribute
relationship information is also used to guide task allocation to workers.
Finally, T-Crowd seamlessly supports categorical and continuous attributes,
which are the two main datatypes found in typical databases. Our extensive
experiments on real and synthetic datasets show that T-Crowd outperforms
state-of-the-art methods in terms of truth inference and reducing the cost of
crowdsourcing.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02130</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classical Homomorphic Encryption for Quantum Circuits</dc:title>
 <dc:creator>Mahadev, Urmila</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present a computationally secure classical homomorphic encryption scheme
for quantum circuits. The scheme allows a classical server to blindly delegate
a quantum computation to a quantum server; the server is able to run the
computation without learning about the computation itself. We show that it is
possible to construct such a scheme directly from quantum secure classical
homomorphic encryption schemes with certain properties. Finally, we show that
an existing classical homomorphic encryption scheme has the required
properties, and can therefore be used to homomorphically evaluate quantum
circuits.
</dc:description>
 <dc:description>Comment: The first version of this paper relied on sub exponentially secure
  indistinguishability obfuscation. In this version, we weaken the
  cryptographic assumption to quantum secure classical homomorphic encryption.
  Although the high level ideas have remained the same, most of the paper has
  been rewritten</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02136</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MonoPerfCap: Human Performance Capture from Monocular Video</dc:title>
 <dc:creator>Xu, Weipeng</dc:creator>
 <dc:creator>Chatterjee, Avishek</dc:creator>
 <dc:creator>Zollh&#xf6;fer, Michael</dc:creator>
 <dc:creator>Rhodin, Helge</dc:creator>
 <dc:creator>Mehta, Dushyant</dc:creator>
 <dc:creator>Seidel, Hans-Peter</dc:creator>
 <dc:creator>Theobalt, Christian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present the first marker-less approach for temporally coherent 3D
performance capture of a human with general clothing from monocular video. Our
approach reconstructs articulated human skeleton motion as well as medium-scale
non-rigid surface deformations in general scenes. Human performance capture is
a challenging problem due to the large range of articulation, potentially fast
motion, and considerable non-rigid deformations, even from multi-view data.
Reconstruction from monocular video alone is drastically more challenging,
since strong occlusions and the inherent depth ambiguity lead to a highly
ill-posed reconstruction problem. We tackle these challenges by a novel
approach that employs sparse 2D and 3D human pose detections from a
convolutional neural network using a batch-based pose estimation strategy.
Joint recovery of per-batch motion allows to resolve the ambiguities of the
monocular reconstruction problem based on a low dimensional trajectory
subspace. In addition, we propose refinement of the surface geometry based on
fully automatically extracted silhouettes to enable medium-scale non-rigid
alignment. We demonstrate state-of-the-art performance capture results that
enable exciting applications such as video editing and free viewpoint video,
previously infeasible from monocular video. Our qualitative and quantitative
evaluation demonstrates that our approach significantly outperforms previous
monocular methods in terms of accuracy, robustness and scene complexity that
can be handled.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02139</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>STARDATA: A StarCraft AI Research Dataset</dc:title>
 <dc:creator>Lin, Zeming</dc:creator>
 <dc:creator>Gehring, Jonas</dc:creator>
 <dc:creator>Khalidov, Vasil</dc:creator>
 <dc:creator>Synnaeve, Gabriel</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We release a dataset of 65646 StarCraft replays that contains 1535 million
frames and 496 million player actions. We provide full game state data along
with the original replays that can be viewed in StarCraft. The game state data
was recorded every 3 frames which ensures suitability for a wide variety of
machine learning tasks such as strategy classification, inverse reinforcement
learning, imitation learning, forward modeling, partial information extraction,
and others. We use TorchCraft to extract and store the data, which standardizes
the data format for both reading from replays and reading directly from the
game. Furthermore, the data can be used on different operating systems and
platforms. The dataset contains valid, non-corrupted replays only and its
quality and diversity was ensured by a number of heuristics. We illustrate the
diversity of the data with various statistics and provide examples of tasks
that benefit from the dataset. We make the dataset available at
https://github.com/TorchCraft/StarData . En Taro Adun!
</dc:description>
 <dc:description>Comment: To be presented at AIIDE17</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02142</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Transition in the Maximal Influence Problem: When Do We Need
  Optimization?</dc:title>
 <dc:creator>Kolumbus, Yoav</dc:creator>
 <dc:creator>Solomon, Sorin</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>E.0</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  Considerable efforts were made in recent years in devising optimization
algorithms for influence maximization in networks. Here we ask: &quot;When do we
need optimization?&quot; and apply insights from statistical mechanics, and direct
simulations, to characterize the parameter-space region where optimization is
required. We find that this region is due to a well known physical phase
transition of the network, and that it vanishes as a power-law with the network
size. We show that also from a utility-maximization perspective (when
considering the optimization costs), for large networks standard optimization
is profitable only in a vanishing parameter region near the phase transition.
Finally, we introduce a constant-time optimization approach, and demonstrate it
through a simple algorithm that manages to give similar results to standard
optimization methods in terms of the influenced-set size, while improving the
results in terms of the net utility.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02143</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lewis meets Brouwer: constructive strict implication</dc:title>
 <dc:creator>Litak, Tadeusz</dc:creator>
 <dc:creator>Visser, Albert</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  C. I. Lewis invented modern modal logic as a theory of &quot;strict implication&quot;.
Over the classical propositional calculus one can as well work with the unary
box connective. Intuitionistically, however, the strict implication has greater
expressive power than the box and allows to make distinctions invisible in the
ordinary syntax. In particular, the logic determined by the most popular
semantics of intuitionistic K becomes a proper extension of the minimal normal
logic of the binary connective. Even an extension of this minimal logic with
the &quot;strength&quot; axiom, classically near-trivial, preserves the distinction
between the binary and the unary setting. In fact, this distinction and the
strong constructive strict implication itself has been also discovered by the
functional programming community in their study of &quot;arrows&quot; as contrasted with
&quot;idioms&quot;. Our particular focus is on arithmetical interpretations of the
intuitionistic strict implication in terms of preservativity in extensions of
Heyting's Arithmetic.
</dc:description>
 <dc:description>Comment: Our invited contribution to the collection &quot;L.E.J. Brouwer, 50 years
  later&quot;</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02143</dc:identifier>
 <dc:identifier>doi:10.1016/j.indag.2017.10.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02146</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rank modulation codes for DNA storage</dc:title>
 <dc:creator>Raviv, Netanel</dc:creator>
 <dc:creator>Schwartz, Moshe</dc:creator>
 <dc:creator>Yaakobi, Eitan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Synthesis of DNA molecules offers unprecedented advances in storage
technology. Yet, the microscopic world in which these molecules reside induces
error patterns that are fundamentally different from their digital
counterparts. Hence, to maintain reliability in reading and writing, new coding
schemes must be developed. In a reading technique called shotgun sequencing, a
long DNA string is read in a sliding window fashion, and a profile vector is
produced. It was recently suggested by Kiah et al. that such a vector can
represent the permutation which is induced by its entries, and hence a
rank-modulation scheme arises. Although this interpretation suggests high error
tolerance, it is unclear which permutations are feasible, and how to produce a
DNA string whose profile vector induces a given permutation. In this paper, by
observing some necessary conditions, an upper bound for the number of feasible
permutations is given. Further, a technique for deciding the feasibility of a
permutation is devised. By using insights from this technique, an algorithm for
producing a considerable number of feasible permutations is given, which
applies to any alphabet size and any window length.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02147</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fundamental Diagram of Rail Transit and Its Application to Dynamic
  Assignment</dc:title>
 <dc:creator>Seo, Toru</dc:creator>
 <dc:creator>Wada, Kentaro</dc:creator>
 <dc:creator>Fukuda, Daisuke</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Urban rail transit often operates with high service frequencies to serve
heavy passenger demand during rush hours. Such operations can be delayed by
train congestion, passenger congestion, and the interaction of the two. Delays
are problematic for many transit systems, as they become amplified by this
interactive feedback. However, there are no tractable models to describe
transit systems with dynamical delays, making it difficult to analyze the
management strategies of congested transit systems in general, solvable ways.
To fill this gap, this article proposes simple yet physical and dynamic models
of urban rail transit. First, a fundamental diagram of a transit system
(3-dimensional relation among train-flow, train-density, and passenger-flow) is
analytically derived by considering the physical interactions in delays and
congestion based on microscopic operation principles. Then, a macroscopic model
of a transit system with time-varying demand and supply is developed as a
continuous approximation based on the fundamental diagram. Finally, the
accuracy of the macroscopic model is investigated using a microscopic
simulation, and applicable range of the model is confirmed.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02151</identifier>
 <datestamp>2017-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reverse Engineering Human Mobility in Large-scale Natural Disasters</dc:title>
 <dc:creator>Stute, Milan</dc:creator>
 <dc:creator>Maass, Max</dc:creator>
 <dc:creator>Schons, Tom</dc:creator>
 <dc:creator>Hollick, Matthias</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Delay/Disruption-Tolerant Networks (DTNs) have been around for more than a
decade and have especially been proposed to be used in scenarios where
communication infrastructure is unavailable. In such scenarios, DTNs can offer
a best-effort communication service by exploiting user mobility. Natural
disasters are an important application scenario for DTNs when the cellular
network is destroyed by natural forces. To assess the performance of such
networks before deployment, we require appropriate knowledge of human mobility.
  In this paper, we address this problem by designing, implementing, and
evaluating a novel mobility model for large-scale natural disasters. Due to the
lack of GPS traces, we reverse-engineer human mobility of past natural
disasters (focusing on 2010 Haiti earthquake and 2013 Typhoon Haiyan) by
leveraging knowledge of 126 experts from 71 Disaster Response Organizations
(DROs). By means of simulation-based experiments, we compare and contrast our
mobility model to other well-known models, and evaluate their impact on DTN
performance. Finally, we make our source code available to the public.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of MSWiM '17. 8 Pages, 9 Figures. Source
  code and data available at
  https://github.com/seemoo-lab/natural-disaster-mobility</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02151</dc:identifier>
 <dc:identifier>doi:10.1145/3127540.3127542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02153</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Characterization of Monotone Influence Measures for Data
  Classification</dc:title>
 <dc:creator>Sliwinski, Jakub</dc:creator>
 <dc:creator>Strobel, Martin</dc:creator>
 <dc:creator>Zick, Yair</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this work we focus on the following question: how important was the i-th
feature in determining the outcome for a given datapoint? We identify a family
of influence measures; functions that, given a datapoint x, assign a value
phi_i(x) to every feature i, which roughly corresponds to that i's importance
in determining the outcome for x. This family is uniquely derived from a set of
axioms: desirable properties that any reasonable influence measure should
satisfy. Departing from prior work on influence measures, we assume no
knowledge of - or access to - the underlying classifier labelling the dataset.
In other words, our influence measures are based on the dataset alone, and do
not make any queries to the classifier. While this requirement naturally limits
the scope of explanations we provide, we show that it is effective on real
datasets.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02165</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to segment on tiny datasets: a new shape model</dc:title>
 <dc:creator>Tremblay, Maxime</dc:creator>
 <dc:creator>Zaccarin, Andr&#xe9;</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current object segmentation algorithms are based on the hypothesis that one
has access to a very large amount of data. In this paper, we aim to segment
objects using only tiny datasets. To this extent, we propose a new automatic
part-based object segmentation algorithm for non-deformable and semi-deformable
objects in natural backgrounds. We have developed a novel shape descriptor
which models the local boundaries of an object's part. This shape descriptor is
used in a bag-of-words approach for object detection. Once the detection
process is performed, we use the background and foreground likelihood given by
our trained shape model, and the information from the image content, to define
a dense CRF model. We use a mean field approximation to solve it and thus
segment the object of interest. Performance evaluated on different datasets
shows that our approach can sometimes achieve results near state-of-the-art
techniques based on big data while requiring only a tiny training set.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, ICIP2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02167</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regulating Highly Automated Robot Ecologies: Insights from Three User
  Studies</dc:title>
 <dc:creator>Shen, Wen</dc:creator>
 <dc:creator>Khemeiri, Alanoud Al</dc:creator>
 <dc:creator>Almehrezi, Abdulla</dc:creator>
 <dc:creator>Enezi, Wael Al</dc:creator>
 <dc:creator>Rahwan, Iyad</dc:creator>
 <dc:creator>Crandall, Jacob W.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Highly automated robot ecologies (HARE), or societies of independent
autonomous robots or agents, are rapidly becoming an important part of much of
the world's critical infrastructure. As with human societies, regulation,
wherein a governing body designs rules and processes for the society, plays an
important role in ensuring that HARE meet societal objectives. However, to
date, a careful study of interactions between a regulator and HARE is lacking.
In this paper, we report on three user studies which give insights into how to
design systems that allow people, acting as the regulatory authority, to
effectively interact with HARE. As in the study of political systems in which
governments regulate human societies, our studies analyze how interactions
between HARE and regulators are impacted by regulatory power and individual
(robot or agent) autonomy. Our results show that regulator power, decision
support, and adaptive autonomy can each diminish the social welfare of HARE,
and hint at how these seemingly desirable mechanisms can be designed so that
they become part of successful HARE.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures, to appear in the 5th International Conference on
  Human Agent Interaction (HAI-2017), Bielefeld, Germany</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02167</dc:identifier>
 <dc:identifier>In Proceedings of the 5th International Conference on Human Agent
  Interaction (HAI 2017). ACM, New York, NY, USA, 111-120</dc:identifier>
 <dc:identifier>doi:10.1145/3125739.3125758</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02171</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase-Aware Single-Channel Speech Enhancement with Modulation-Domain
  Kalman Filtering</dc:title>
 <dc:creator>Dionelis, Nikolaos</dc:creator>
 <dc:creator>Brookes, Mike</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  We present a single-channel phase-sensitive speech enhancement algorithm that
is based on modulation-domain Kalman filtering and on tracking the speech phase
using circular statistics. With Kalman filtering, using that speech and noise
are additive in the complex STFT domain, the algorithm tracks the speech
log-spectrum, the noise log-spectrum and the speech phase. Joint amplitude and
phase estimation of speech is performed. Given the noisy speech signal,
conventional algorithms use the noisy phase for signal reconstruction
approximating the speech phase with the noisy phase. In the proposed Kalman
filtering algorithm, the speech phase posterior is used to create an enhanced
speech phase spectrum for signal reconstruction. The Kalman filter prediction
models the temporal/inter-frame correlation of the speech and noise log-spectra
and of the speech phase, while the Kalman filter update models their nonlinear
relations. With the proposed algorithm, speech is tracked and estimated both in
the log-spectral and spectral phase domains. The algorithm is evaluated in
terms of speech quality and different algorithm configurations, dependent on
the signal model, are compared in different noise types. Experimental results
show that the proposed algorithm outperforms traditional enhancement algorithms
over a range of SNRs for various noise types.
</dc:description>
 <dc:description>Comment: 13 pages, 17 figures, Submitted to IEEE/ACM Transactions on Audio,
  Speech and Language Processing</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02174</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Code Park: A New 3D Code Visualization Tool</dc:title>
 <dc:creator>Khaloo, Pooya</dc:creator>
 <dc:creator>Maghoumi, Mehran</dc:creator>
 <dc:creator>Taranta II, Eugene</dc:creator>
 <dc:creator>Bettner, David</dc:creator>
 <dc:creator>Laviola Jr, Joseph</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  We introduce Code Park, a novel tool for visualizing codebases in a 3D
game-like environment. Code Park aims to improve a programmer's understanding
of an existing codebase in a manner that is both engaging and intuitive,
appealing to novice users such as students. It achieves these goals by laying
out the codebase in a 3D park-like environment. Each class in the codebase is
represented as a 3D room-like structure. Constituent parts of the class
(variable, member functions, etc.) are laid out on the walls, resembling a
syntax-aware &quot;wallpaper&quot;. The users can interact with the codebase using an
overview, and a first-person viewer mode. We conducted two user studies to
evaluate Code Park's usability and suitability for organizing an existing
project. Our results indicate that Code Park is easy to get familiar with and
significantly helps in code understanding compared to a traditional IDE.
Further, the users unanimously believed that Code Park was a fun tool to work
with.
</dc:description>
 <dc:description>Comment: Accepted for publication in 2017 IEEE Working Conference on Software
  Visualization (VISSOFT 2017); Supplementary video:
  https://www.youtube.com/watch?v=LUiy1M9hUKU</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02175</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification and Analysis of Communication Protection Policy Anomalies</dc:title>
 <dc:creator>Valenza, Fulvio</dc:creator>
 <dc:creator>Basile, Cataldo</dc:creator>
 <dc:creator>Canavese, Daniele</dc:creator>
 <dc:creator>Lioy, Antonio</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper presents a classification of the anomalies that can appear when
designing or implementing communication protection policies. Together with the
already known intra- and inter-policy anomaly types, we introduce a novel
category, the inter-technology anomalies, related to security controls
implementing different technologies, both within the same network node and
among different network nodes. Through an empirical assessment, we prove the
practical significance of detecting this new anomaly class. Furthermore, this
paper introduces a formal model, based on first-order logic rules that analyses
the network topology and the security controls at each node to identify the
detected anomalies and suggest the strategies to resolve them. This formal
model has manageable computational complexity and its implementation has shown
excellent performance and good scalability.
</dc:description>
 <dc:description>Comment: Published on IEEE/ACM Transactions on Networking</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02175</dc:identifier>
 <dc:identifier>doi:10.1109/TNET.2017.2708096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02179</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-supervised Learning of Pose Embeddings from Spatiotemporal
  Relations in Videos</dc:title>
 <dc:creator>S&#xfc;mer, &#xd6;mer</dc:creator>
 <dc:creator>Dencker, Tobias</dc:creator>
 <dc:creator>Ommer, Bj&#xf6;rn</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human pose analysis is presently dominated by deep convolutional networks
trained with extensive manual annotations of joint locations and beyond. To
avoid the need for expensive labeling, we exploit spatiotemporal relations in
training videos for self-supervised learning of pose embeddings. The key idea
is to combine temporal ordering and spatial placement estimation as auxiliary
tasks for learning pose similarities in a Siamese convolutional network. Since
the self-supervised sampling of both tasks from natural videos can result in
ambiguous and incorrect training labels, our method employs a curriculum
learning idea that starts training with the most reliable data samples and
gradually increases the difficulty. To further refine the training process we
mine repetitive poses in individual videos which provide reliable labels while
removing inconsistencies. Our pose embeddings capture visual characteristics of
human pose that can boost existing supervised representations in human pose
estimation and retrieval. We report quantitative and qualitative results on
these tasks in Olympic Sports, Leeds Pose Sports and MPII Human Pose datasets.
</dc:description>
 <dc:description>Comment: To appear in ICCV 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02182</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularizing and Optimizing LSTM Language Models</dc:title>
 <dc:creator>Merity, Stephen</dc:creator>
 <dc:creator>Keskar, Nitish Shirish</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recurrent neural networks (RNNs), such as long short-term memory networks
(LSTMs), serve as a fundamental building block for many sequence learning
tasks, including machine translation, language modeling, and question
answering. In this paper, we consider the specific problem of word-level
language modeling and investigate strategies for regularizing and optimizing
LSTM-based models. We propose the weight-dropped LSTM which uses DropConnect on
hidden-to-hidden weights as a form of recurrent regularization. Further, we
introduce NT-ASGD, a variant of the averaged stochastic gradient method,
wherein the averaging trigger is determined using a non-monotonic condition as
opposed to being tuned by the user. Using these and other regularization
strategies, we achieve state-of-the-art word level perplexities on two data
sets: 57.3 on Penn Treebank and 65.8 on WikiText-2. In exploring the
effectiveness of a neural cache in conjunction with our proposed model, we
achieve an even lower state-of-the-art perplexity of 52.8 on Penn Treebank and
52.0 on WikiText-2.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02188</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PowerAI DDL</dc:title>
 <dc:creator>Cho, Minsik</dc:creator>
 <dc:creator>Finkler, Ulrich</dc:creator>
 <dc:creator>Kumar, Sameer</dc:creator>
 <dc:creator>Kung, David</dc:creator>
 <dc:creator>Saxena, Vaibhav</dc:creator>
 <dc:creator>Sreedhar, Dheeraj</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  As deep neural networks become more complex and input datasets grow larger,
it can take days or even weeks to train a deep neural network to the desired
accuracy. Therefore, distributed Deep Learning at a massive scale is a critical
capability, since it offers the potential to reduce the training time from
weeks to hours. In this paper, we present a software-hardware co-optimized
distributed Deep Learning system that can achieve near-linear scaling up to
hundreds of GPUs. The core algorithm is a multi-ring communication pattern that
provides a good tradeoff between latency and bandwidth and adapts to a variety
of system configurations. The communication algorithm is implemented as a
library for easy use. This library has been integrated into Tensorflow, Caffe,
and Torch. We train Resnet-101 on Imagenet 22K with 64 IBM Power8 S822LC
servers (256 GPUs) in about 7 hours to an accuracy of 33.8 % validation
accuracy. Microsoft's ADAM and Google's DistBelief results did not reach 30 %
validation accuracy for Imagenet 22K. Compared to Facebook AI Research's recent
paper on 256 GPU training, we use a different communication algorithm, and our
combined software and hardware system offers better communication overhead for
Resnet-50. A PowerAI DDL enabled version of Torch completed 90 epochs of
training on Resnet 50 for 1K classes in 50 minutes using 64 IBM Power8 S822LC
servers (256 GPUs).
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02190</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intrinsically Motivated Goal Exploration Processes with Automatic
  Curriculum Learning</dc:title>
 <dc:creator>Forestier, S&#xe9;bastien</dc:creator>
 <dc:creator>Mollard, Yoan</dc:creator>
 <dc:creator>Oudeyer, Pierre-Yves</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Intrinsically motivated spontaneous exploration is a key enabler of
autonomous lifelong learning in human children. It allows them to discover and
acquire large repertoires of skills through self-generation, self-selection,
self-ordering and self-experimentation of learning goals. We present the
unsupervised multi-goal reinforcement learning formal framework as well as an
algorithmic approach called intrinsically motivated goal exploration processes
(IMGEP) to enable similar properties of autonomous learning in machines. The
IMGEP algorithmic architecture relies on several principles: 1) self-generation
of goals as parameterized reinforcement learning problems; 2) selection of
goals based on intrinsic rewards; 3) exploration with parameterized
time-bounded policies and fast incremental goal-parameterized policy search; 4)
systematic reuse of information acquired when targeting a goal for improving
other goals. We present a particularly efficient form of IMGEP that uses a
modular representation of goal spaces as well as intrinsic rewards based on
learning progress. We show how IMGEPs automatically generate a learning
curriculum within an experimental setup where a real humanoid robot can explore
multiple spaces of goals with several hundred continuous dimensions. While no
particular target goal is provided to the system beforehand, this curriculum
allows the discovery of skills of increasing complexity, that act as stepping
stone for learning more complex skills (like nested tool use). We show that
learning several spaces of diverse problems can be more efficient for learning
complex skills than only trying to directly learn these complex skills. We
illustrate the computational efficiency of IMGEPs as these robotic experiments
use a simple memory-based low-level policy representations and search
algorithm, enabling the whole system to learn online and incrementally on a
Raspberry Pi 3.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02191</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Domain Adaptation for Face Recognition in Unlabeled Videos</dc:title>
 <dc:creator>Sohn, Kihyuk</dc:creator>
 <dc:creator>Liu, Sifei</dc:creator>
 <dc:creator>Zhong, Guangyu</dc:creator>
 <dc:creator>Yu, Xiang</dc:creator>
 <dc:creator>Yang, Ming-Hsuan</dc:creator>
 <dc:creator>Chandraker, Manmohan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Despite rapid advances in face recognition, there remains a clear gap between
the performance of still image-based face recognition and video-based face
recognition, due to the vast difference in visual quality between the domains
and the difficulty of curating diverse large-scale video datasets. This paper
addresses both of those challenges, through an image to video feature-level
domain adaptation approach, to learn discriminative video frame
representations. The framework utilizes large-scale unlabeled video data to
reduce the gap between different domains while transferring discriminative
knowledge from large-scale labeled still images. Given a face recognition
network that is pretrained in the image domain, the adaptation is achieved by
(i) distilling knowledge from the network to a video adaptation network through
feature matching, (ii) performing feature restoration through synthetic data
augmentation and (iii) learning a domain-invariant feature through a domain
adversarial discriminator. We further improve performance through a
discriminator-guided feature fusion that boosts high-quality frames while
eliminating those degraded by video domain-specific factors. Experiments on the
YouTube Faces and IJB-A datasets demonstrate that each module contributes to
our feature-level domain adaptation framework and substantially improves video
face recognition performance to achieve state-of-the-art accuracy. We
demonstrate qualitatively that the network learns to suppress diverse artifacts
in videos such as pose, illumination or occlusion without being explicitly
trained for them.
</dc:description>
 <dc:description>Comment: accepted for publication at International Conference on Computer
  Vision (ICCV) 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02196</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Smoothing, Tracking, and Forecasting Based on Continuous-Time
  Target Trajectory Fitting</dc:title>
 <dc:creator>Li, Tiancheng</dc:creator>
 <dc:creator>Chen, Huimin</dc:creator>
 <dc:creator>Sun, Shudong</dc:creator>
 <dc:creator>Corchado, Juan M</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We present a continuous time state estimation framework that unifies
traditionally individual tasks of smoothing, tracking, and forecasting (STF),
for a class of targets subject to smooth motion processes, e.g., the target
moves with nearly constant acceleration or affected by insignificant noises.
Fundamentally different from the conventional Markov transition formulation,
the state process is modeled by a continuous trajectory function of time (FoT)
and the STF problem is formulated as an online data fitting problem with the
goal of finding the trajectory FoT that best fits the observations in a sliding
time-window. Then, the state of the target, whether the past (namely,
smoothing), the current (filtering) or the near-future (forecasting), can be
inferred from the FoT. Our framework releases stringent statistical modeling of
the target motion in real time, and is applicable to a broad range of real
world targets of significance such as passenger aircraft and ships which move
on scheduled, (segmented) smooth paths but little statistical knowledge is
given about their real time movement and even about the sensors. In addition,
the proposed STF framework inherits the advantages of data fitting for
accommodating arbitrary sensor revisit time, target maneuvering and missed
detection. The proposed method is compared with state of the art estimators in
scenarios of either maneuvering or non-maneuvering target.
</dc:description>
 <dc:description>Comment: 16 pages, 8 figures, 5 tables, 80 references; Codes available</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02199</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Early Evaluation of Intel Optane Non-Volatile Memory with HPC I/O
  Workloads</dc:title>
 <dc:creator>Wu, Kai</dc:creator>
 <dc:creator>Ober, Frank</dc:creator>
 <dc:creator>Hamlin, Shari</dc:creator>
 <dc:creator>Li, Dong</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  High performance computing (HPC) applications have a high requirement on
storage speed and capacity. Non-volatile memory is a promising technology to
replace traditional storage devices to improve HPC performance. Earlier in
2017, Intel and Micron released first NVM product -- Intel Optane SSDs. Optane
is much faster and more durable than the traditional storage device. It creates
a bridge to narrow the performance gap between DRAM and storage. But is the
existing HPC I/O stack still suitable for new NVM devices like Intel Optane?
How does HPC I/O workload perform with Intel Optane?
  In this paper, we analyze the performance of I/O intensive HPC applications
with Optane as a block device and try to answer the above questions. We study
the performance from three perspectives: (1) basic read and write bandwidth of
Optane, (2) a performance comparison study between Optane and HDD, including
checkpoint workload, MPI individual I/O vs. POSIX I/O, and MPI individual I/O
vs. MPI collective I/O, and (3) the impact of Optane on the performance of a
parallel file system, PVFS2.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02201</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-uniform EWMA-PCA based cache size allocation scheme in Named Data
  Networks</dc:title>
 <dc:creator>Mehran, Narges</dc:creator>
 <dc:creator>Movahhedinia, Naser</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  As a data-centric cache-enabled architecture, Named Data Networking (NDN) is
considered to be an appropriate alternative to the current host-centric
IP-based Internet infrastructure. Leveraging in-network caching, name-based
routing, and receiver-driven sessions, NDN can greatly enhance the way Internet
resources are being used. A critical issue in NDN is the procedure of cache
allocation and management. Our main contribution in this research is the
analysis of memory requirements to allocate suitable Content-Store size to NDN
routers, with respect to combined impacts of long-term centrality-based metric
and Exponential Weighted Moving Average (EWMA) of short-term parameters such as
users behaviors and outgoing traffic. To determine correlations in such large
data sets, data mining methods can prove valuable to researchers. In this
paper, we apply a data-fusion approach, namely Principal Component Analysis
(PCA), to discover relations from short- and long-term parameters of the
router. The output of PCA, exploited to mine out raw data sets, is used to
allocate a proper cache size to the router. Evaluation results show an increase
in the hit ratio of Content-Stores in sources, and NDN routers. Moreover, for
the proposed cache size allocation scheme, the number of unsatisfied and
pending Interests in NDN routers is smaller than the Degree-Centrality cache
size scheme.
</dc:description>
 <dc:description>Comment: Accepted by Sci China Inf Sci, Science China Information Sciences,
  2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02201</dc:identifier>
 <dc:identifier>Sci China Inf Sci, 61(1) (2018)</dc:identifier>
 <dc:identifier>doi:10.1007/s11432-016-0501-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02205</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Dynamic Locomotion via Reinforcement Learning and Novel Whole
  Body Controller</dc:title>
 <dc:creator>Kim, Donghyun</dc:creator>
 <dc:creator>Lee, Jaemin</dc:creator>
 <dc:creator>Sentis, Luis</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We propose a robust dynamic walking controller consisting of a dynamic
locomotion planner, a reinforcement learning process for robustness, and a
novel whole-body locomotion controller (WBLC). Previous approaches specify
either the position or the timing of steps, however, the proposed locomotion
planner simultaneously computes both of these parameters as locomotion outputs.
Our locomotion strategy relies on devising a reinforcement learning (RL)
approach for robust walking. The learned policy generates multi step walking
patterns, and the process is quick enough to be suitable for real-time
controls. For learning, we devise an RL strategy that uses a phase space
planner (PSP) and a linear inverted pendulum model to make the problem
tractable and very fast. Then, the learned policy is used to provide goal-based
commands to the WBLC, which calculates the torque commands to be executed in
full-humanoid robots. The WBLC combines multiple prioritized tasks and
calculates the associated reaction forces based on practical inequality
constraints. The novel formulation includes efficient calculation of the time
derivatives of various Jacobians. This provides high-fidelity dynamic control
of fast motions. More specifically, we compute the time derivative of the
Jacobian for various tasks and the Jacobian of the centroidal momentum task by
utilizing Lie group operators and operational space dynamics respectively. The
integration of RL-PSP and the WBLC provides highly robust, versatile, and
practical locomotion including steering while walking and handling push
disturbances of up to 520 N during an interval of 0.1 sec. Theoretical and
numerical results are tested through a 3D physics-based simulation of the
humanoid robot Valkyrie.
</dc:description>
 <dc:description>Comment: 15 pages, 12 figures</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02209</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MemNet: A Persistent Memory Network for Image Restoration</dc:title>
 <dc:creator>Tai, Ying</dc:creator>
 <dc:creator>Yang, Jian</dc:creator>
 <dc:creator>Liu, Xiaoming</dc:creator>
 <dc:creator>Xu, Chunyan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, very deep convolutional neural networks (CNNs) have been attracting
considerable attention in image restoration. However, as the depth grows, the
long-term dependency problem is rarely realized for these very deep models,
which results in the prior states/layers having little influence on the
subsequent ones. Motivated by the fact that human thoughts have persistency, we
propose a very deep persistent memory network (MemNet) that introduces a memory
block, consisting of a recursive unit and a gate unit, to explicitly mine
persistent memory through an adaptive learning process. The recursive unit
learns multi-level representations of the current state under different
receptive fields. The representations and the outputs from the previous memory
blocks are concatenated and sent to the gate unit, which adaptively controls
how much of the previous states should be reserved, and decides how much of the
current state should be stored. We apply MemNet to three image restoration
tasks, i.e., image denosing, super-resolution and JPEG deblocking.
Comprehensive experiments demonstrate the necessity of the MemNet and its
unanimous superiority on all three tasks over the state of the arts. Code is
available at https://github.com/tyshiwo/MemNet.
</dc:description>
 <dc:description>Comment: Accepted by ICCV 2017 (Spotlight presentation)</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02210</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Highlights Detection and Summarization with Lag-Calibration based
  on Concept-Emotion Mapping of Crowd-sourced Time-Sync Comments</dc:title>
 <dc:creator>Ping, Qing</dc:creator>
 <dc:creator>Chen, Chaomei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  With the prevalence of video sharing, there are increasing demands for
automatic video digestion such as highlight detection. Recently, platforms with
crowdsourced time-sync video comments have emerged worldwide, providing a good
opportunity for highlight detection. However, this task is non-trivial: (1)
time-sync comments often lag behind their corresponding shot; (2) time-sync
comments are semantically sparse and noisy; (3) to determine which shots are
highlights is highly subjective. The present paper aims to tackle these
challenges by proposing a framework that (1) uses concept-mapped lexical-chains
for lag calibration; (2) models video highlights based on comment intensity and
combination of emotion and concept concentration of each shot; (3) summarize
each detected highlight using improved SumBasic with emotion and concept
mapping. Experiments on large real-world datasets show that our highlight
detection method and summarization method both outperform other benchmarks with
considerable margins.
</dc:description>
 <dc:description>Comment: Accepted in EMNLP 2017 Workshop on New Frontiers in Summarization.
  Please include &quot;EMNLP 2017 Workshop on New Frontiers in Summarization&quot; in any
  citations</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02212</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Deep Networks to be Spatially Sensitive</dc:title>
 <dc:creator>Kolkin, Nicholas</dc:creator>
 <dc:creator>Shakhnarovich, Gregory</dc:creator>
 <dc:creator>Shechtman, Eli</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In many computer vision tasks, for example saliency prediction or semantic
segmentation, the desired output is a foreground map that predicts pixels where
some criteria is satisfied. Despite the inherently spatial nature of this task
commonly used learning objectives do not incorporate the spatial relationships
between misclassified pixels and the underlying ground truth. The Weighted
F-measure, a recently proposed evaluation metric, does reweight errors
spatially, and has been shown to closely correlate with human evaluation of
quality, and stably rank predictions with respect to noisy ground truths (such
as a sloppy human annotator might generate). However it suffers from
computational complexity which makes it intractable as an optimization
objective for gradient descent, which must be evaluated thousands or millions
of times while learning a model's parameters. We propose a differentiable and
efficient approximation of this metric. By incorporating spatial information
into the objective we can use a simpler model than competing methods without
sacrificing accuracy, resulting in faster inference speeds and alleviating the
need for pre/post-processing. We match (or improve) performance on several
tasks compared to prior state of the art by traditional metrics, and in many
cases significantly improve performance by the weighted F-measure.
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02214</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LitStoryTeller: An Interactive System for Visual Exploration of
  Scientific Papers Leveraging Named entities and Comparative Sentences</dc:title>
 <dc:creator>Ping, Qing</dc:creator>
 <dc:creator>Chen, Chaomei</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The present study proposes LitStoryTeller, an interactive system for visually
exploring the semantic structure of a scientific article. We demonstrate how
LitStoryTeller could be used to answer some of the most fundamental research
questions, such as how a new method was built on top of existing methods, based
on what theoretical proof and experimental evidences. More importantly,
LitStoryTeller can assist users to understand the full and interesting story a
scientific paper, with a concise outline and important details. The proposed
system borrows a metaphor from screen play, and visualizes the storyline of a
scientific paper by arranging its characters (scientific concepts or
terminologies) and scenes (paragraphs/sentences) into a progressive and
interactive storyline. Such storylines help to preserve the semantic structure
and logical thinking process of a scientific paper. Semantic structures, such
as scientific concepts and comparative sentences, are extracted using existing
named entity recognition APIs and supervised classifiers, from a scientific
paper automatically. Two supplementary views, ranked entity frequency view and
entity co-occurrence network view, are provided to help users identify the
&quot;main plot&quot; of such scientific storylines. When collective documents are ready,
LitStoryTeller also provides a temporal entity evolution view and entity
community view for collection digestion.
</dc:description>
 <dc:description>Comment: Accepted at the 16th International Conference On Scientometrics &amp;
  Informetrics (ISSI 2017). Please include ISSI 2017 in any citations</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02215</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a CNN-based End-to-End Controller for a Formula SAE Racecar</dc:title>
 <dc:creator>Koppula, Skanda</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a set of CNN-based end-to-end models for controls of a Formula SAE
racecar, along with various benchmarking and visualization tools to understand
model performance. We tackled three main problems in the context of
cone-delineated racetrack driving: (1) discretized steering, which translates a
first-person frame along to the track to a predicted steering direction. (2)
real-value steering, which translates a frame view to a real-value steering
angle, and (3) a network design for predicting brake and throttle. We
demonstrate high accuracy on our discretization task, low theoretical testing
errors with our model for real-value steering, and a starting point for future
work regarding a controller for our vehicle's brake and throttle. Timing
benchmarks suggests that the networks we propose have the latency and
throughput required for real-time controllers, when run on GPU-enabled
hardware.
</dc:description>
 <dc:date>2017-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02216</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trace reconstruction with varying deletion probabilities</dc:title>
 <dc:creator>Hartung, Lisa</dc:creator>
 <dc:creator>Holden, Nina</dc:creator>
 <dc:creator>Peres, Yuval</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  In the trace reconstruction problem an unknown string ${\bf
x}=(x_0,\dots,x_{n-1})\in\{0,1,...,m-1\}^n$ is observed through the deletion
channel, which deletes each $x_k$ with a certain probability, yielding a
contracted string $\widetilde{\bf X}$. Earlier works have proved that if each
$x_k$ is deleted with the same probability $q\in[0,1)$, then $\exp(O(n^{1/3}))$
independent copies of the contracted string $\widetilde{\bf X}$ suffice to
reconstruct $\bf x$ with high probability. We extend this upper bound to the
setting where the deletion probabilities vary, assuming certain regularity
conditions. First we consider the case where $x_k$ is deleted with some known
probability $q_k$. Then we consider the case where each letter $\zeta\in
\{0,1,...,m-1\}$ is associated with some possibly unknown deletion probability
$q_\zeta$.
</dc:description>
 <dc:description>Comment: 10 pages, 1 figure</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02218</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classifying Graphs as Images with Convolutional Neural Networks</dc:title>
 <dc:creator>Tixier, Antoine Jean-Pierre</dc:creator>
 <dc:creator>Nikolentzos, Giannis</dc:creator>
 <dc:creator>Meladianos, Polykarpos</dc:creator>
 <dc:creator>Vazirgiannis, Michalis</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The task of graph classification is currently dominated by graph kernels,
which, while powerful, scale poorly to large graphs and datasets. Convolutional
Neural Networks (CNNs) offer a very appealing alternative. However, feeding
graphs to CNNs is not trivial. To address this challenge, many sophisticated
extensions of CNNs have recently been proposed. In this paper, we show that a
classical 2D CNN architecture designed for images can also be used for graph
processing in a completely off-the-shelf manner; the only prerequisite being to
encode graphs as stacks of two-dimensional histograms of their node embeddings.
Despite its simplicity, our method proves very competitive to state-of-the-art
graph kernels, and even outperforms them by a wide margin on some datasets.
</dc:description>
 <dc:description>Comment: Added details, fixed typos</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02222</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Isolating a Vertex via Lattices: Polytopes with Totally Unimodular Faces</dc:title>
 <dc:creator>Gurjar, Rohit</dc:creator>
 <dc:creator>Thierauf, Thomas</dc:creator>
 <dc:creator>Vishnoi, Nisheeth K.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We derandomize the famous Isolation Lemma by Mulmuley, Vazirani, and Vazirani
for polytopes given by totally unimodular constraints. That is, we construct a
weight assignment such that one vertex in such a polytope is isolated, i.e.,
there is a unique minimum weight vertex. Our weights are quasi-polynomially
bounded and can be constructed in quasi-polynomial time. In fact, our isolation
technique works even under the weaker assumption that every face of the
polytope lies in an affine space defined by a totally unimodular matrix. This
generalizes the recent derandomization results for bipartite perfect matching
and matroid intersection.
  We prove our result by associating a lattice to each face of the polytope and
showing that if there is a totally unimodular kernel matrix for this lattice,
then the number of near-shortest vectors in it is polynomially bounded. The
proof of this latter geometric fact is combinatorial and follows from a
polynomial bound on the number of near-shortest circuits in a regular matroid.
This is the technical core of the paper and relies on a variant of Seymour's
decomposition theorem for regular matroids. It generalizes an influential
result by Karger on the number of minimum cuts in a graph to regular matroids.
Both of our results, on lattices and matroids, should be of independent
interest.
</dc:description>
 <dc:description>Comment: Added a proof overview; restructured some of the sections</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02237</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Quality Assessment Techniques Show Improved Training and
  Evaluation of Autoencoder Generative Adversarial Networks</dc:title>
 <dc:creator>Vertolli, Michael O.</dc:creator>
 <dc:creator>Davies, Jim</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a training and evaluation approach for autoencoder Generative
Adversarial Networks (GANs), specifically the Boundary Equilibrium Generative
Adversarial Network (BEGAN), based on methods from the image quality assessment
literature. Our approach explores a multidimensional evaluation criterion that
utilizes three distance functions: an $l_1$ score, the Gradient Magnitude
Similarity Mean (GMSM) score, and a chrominance score. We show that each of the
different distance functions captures a slightly different set of properties in
image space and, consequently, requires its own evaluation criterion to
properly assess whether the relevant property has been adequately learned. We
show that models using the new distance functions are able to produce better
images than the original BEGAN model in predicted ways.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures, 2 tables</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02238</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Convolutional Neural Network for Search Term Detection</dc:title>
 <dc:creator>Salehinejad, Hojjat</dc:creator>
 <dc:creator>Barfett, Joseph</dc:creator>
 <dc:creator>Aarabi, Parham</dc:creator>
 <dc:creator>Valaee, Shahrokh</dc:creator>
 <dc:creator>Colak, Errol</dc:creator>
 <dc:creator>Gray, Bruce</dc:creator>
 <dc:creator>Dowdell, Tim</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Pathfinding in hospitals is challenging for patients, visitors, and even
employees. Many people have experienced getting lost due to lack of clear
guidance, large footprint of hospitals, and confusing array of hospital wings.
In this paper, we propose Halo; An indoor navigation application based on
voice-user interaction to help provide directions for users without assistance
of a localization system. The main challenge is accurate detection of origin
and destination search terms. A custom convolutional neural network (CNN) is
proposed to detect origin and destination search terms from transcription of a
submitted speech query. The CNN is trained based on a set of queries tailored
specifically for hospital and clinic environments. Performance of the proposed
model is studied and compared with Levenshtein distance-based word matching.
</dc:description>
 <dc:description>Comment: This paper is accepted for presentation at 2017 IEEE 28th Annual
  International Symposium on Personal, Indoor, and Mobile Radio Communications</dc:description>
 <dc:date>2017-08-06</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02254</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asking Too Much? The Rhetorical Role of Questions in Political Discourse</dc:title>
 <dc:creator>Zhang, Justine</dc:creator>
 <dc:creator>Spirling, Arthur</dc:creator>
 <dc:creator>Danescu-Niculescu-Mizil, Cristian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Questions play a prominent role in social interactions, performing rhetorical
functions that go beyond that of simple informational exchange. The surface
form of a question can signal the intention and background of the person asking
it, as well as the nature of their relation with the interlocutor. While the
informational nature of questions has been extensively examined in the context
of question-answering applications, their rhetorical aspects have been largely
understudied.
  In this work we introduce an unsupervised methodology for extracting surface
motifs that recur in questions, and for grouping them according to their latent
rhetorical role. By applying this framework to the setting of question sessions
in the UK parliament, we show that the resulting typology encodes key aspects
of the political discourse---such as the bifurcation in questioning behavior
between government and opposition parties---and reveals new insights into the
effects of a legislator's tenure and political career ambitions.
</dc:description>
 <dc:description>Comment: To appear at EMNLP 2017; 15 pages including appendix; 3 figures;
  parliament data and code available at
  http://www.cs.cornell.edu/~cristian/Asking_too_much.html</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02255</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Statistical Models with Self-Emergent Grammar of Chord
  Sequences</dc:title>
 <dc:creator>Tsushima, Hiroaki</dc:creator>
 <dc:creator>Nakamura, Eita</dc:creator>
 <dc:creator>Itoyama, Katsutoshi</dc:creator>
 <dc:creator>Yoshii, Kazuyoshi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Generative statistical models of chord sequences play crucial roles in music
processing. To capture syntactic similarities among certain chords (e.g. in C
major key, between G and G7 and between F and Dm), we study hidden Markov
models and probabilistic context-free grammar models with latent variables
describing syntactic categories of chord symbols and their unsupervised
learning techniques for inducing the latent grammar from data. Surprisingly, we
find that these models often outperform conventional Markov models in
predictive power, and the self-emergent categories often correspond to
traditional harmonic functions. This implies the need for chord categories in
harmony models from the informatics perspective.
</dc:description>
 <dc:description>Comment: 18 pages, 14 figures, version submitted to JNMR, minor revision,
  reference added</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02266</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing Boltzmann Samplers for Bose-Einstein Condensates with
  Dirichlet Generating Functions</dc:title>
 <dc:creator>Bernstein, Megan</dc:creator>
 <dc:creator>Fahrbach, Matthew</dc:creator>
 <dc:creator>Randall, Dana</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Boltzmann sampling is commonly used to uniformly sample objects of a
particular size from large combinatorial sets. For this technique to be
effective, one needs to prove that (1) the sampling procedure is efficient and
(2) objects of the desired size are generated with sufficiently high
probability. We use this approach to give a provably efficient sampling
algorithm for a class of weighted integer partitions related to Bose-Einstein
condensation from statistical physics. Our sampling algorithm is a
probabilistic interpretation of the ordinary generating function for these
objects, derived from the symbolic method of analytic combinatorics. Using the
Khintchine-Meinardus probabilistic method to bound the rejection rate of our
Boltzmann sampler through singularity analysis of Dirichlet generating
functions, we offer an alternative approach to analyze Boltzmann samplers for
objects with multiplicative structure.
</dc:description>
 <dc:description>Comment: 20 pages, 1 figure</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02266</dc:identifier>
 <dc:identifier>Proceedings of the Fifteenth Workshop on Analytic Algorithmics and
  Combinatorics (ANALCO 2018)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02267</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ISS-MULT: Intelligent Sample Selection for Multi-Task Learning in
  Question Answering</dc:title>
 <dc:creator>Ahmadvand, Ali</dc:creator>
 <dc:creator>Choi, Jinho D.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Transferring knowledge from a source domain to another domain is useful,
especially when gathering new data is very expensive and time-consuming. Deep
networks have been well-studied for question answering tasks in recent years;
however, no prominent research for transfer learning through deep neural
networks exists in the question answering field. In this paper, two main
methods (INIT and MULT) in this field are examined. Then, a new method named
Intelligent sample selection (ISS-MULT) is proposed to improve the MULT method
for question answering tasks. Different datasets, specificay SQuAD, SelQA,
WikiQA, NewWikiQA and InforBoxQA, are used for evaluation. Moreover, two
different tasks of question answering - answer selection and answer triggering
- are evaluated to examine the effectiveness of transfer learning. The results
show that using transfer learning generally improves the performance if the
corpora are related and are based on the same policy. In addition, using
ISS-MULT could finely improve the MULT method for question answering tasks, and
these improvements prove more significant in the answer triggering task.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02271</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementation of Torque Controller for Brushless Motors on the
  Omni-directional Wheeled Mobile Robot</dc:title>
 <dc:creator>Wasuntapichaikul, Piyamate</dc:creator>
 <dc:creator>Sukvichai, Kanjanapan</dc:creator>
 <dc:creator>Tipsuwan, Yodyium</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The major issue for the wheeled mobile robot is the low level controller
gains tuning up especially in the robot competition. The floor surface can be
damaged by the robot wheels during the competition, therefore the surface
coefficient can be changed over time. PI gains have to be tuned before every
match along the competition. In this research, the torque controller is defined
and implemented in order to solve this problem. Torque controller consists of a
PI controller for the robot wheel's angular velocity and a dynamic equation of
brushless motor. The motor dynamics can be derived from the energy conservation
law. Three different carpets, which have the different friction coefficients,
are used in the experiments. The robot wheel's angular velocity profiles are
generated from the robot kinematics with different initial conditions. The
output paths of the robot with the torque controller are compared with the
output paths of the robot with regular PI controller when the same wheel
angular velocity profiles are applied. The results show that the torque
controller can provide a better robot path than the normal PI controller.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02274</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FixMyStreet Brussels: Socio-Demographic Inequality in Crowdsourced Civic
  Participation</dc:title>
 <dc:creator>Pak, Burak</dc:creator>
 <dc:creator>Chua, Alvin</dc:creator>
 <dc:creator>Moere, Andrew Vande</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  FixMyStreet (FMS) is a web-based civic participation platform that allows
inhabitants to report environmental defects like potholes and damaged pavements
to the government. In this paper, we examine the use of FMS in Brussels, the
capital city of Belgium. Analyzing a total of 30,041 reports since its
inception in 2013, we demonstrate how civic participation on FMS varies between
the ethnically diverse districts in Brussels. We compare FMS use to a range of
sociodemographic indicators derived from official city statistics as well as
geotagged social media data from Twitter. Our statistical analysis revealed
several significant differences between the districts that suggested that
crowdsourced civic participation platforms tend to marginalize low-income and
ethnically diverse communities. In this respect, our findings provide timely
evidence to inform the design of more inclusive crowdsourced, civic
participation platforms in the future.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02274</dc:identifier>
 <dc:identifier>Journal of Urban Technology 2017 Volume 24 No 2 65 to 87</dc:identifier>
 <dc:identifier>doi:10.1080/10630732.2016.1270047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02275</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Corpus-level Fine-grained Entity Typing</dc:title>
 <dc:creator>Yaghoobzadeh, Yadollah</dc:creator>
 <dc:creator>Adel, Heike</dc:creator>
 <dc:creator>Sch&#xfc;tze, Hinrich</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper addresses the problem of corpus-level entity typing, i.e.,
inferring from a large corpus that an entity is a member of a class such as
&quot;food&quot; or &quot;artist&quot;. The application of entity typing we are interested in is
knowledge base completion, specifically, to learn which classes an entity is a
member of. We propose FIGMENT to tackle this problem. FIGMENT is embedding-
based and combines (i) a global model that scores based on aggregated
contextual information of an entity and (ii) a context model that first scores
the individual occurrences of an entity and then aggregates the scores. Each of
the two proposed models has some specific properties. For the global model,
learning high quality entity representations is crucial because it is the only
source used for the predictions. Therefore, we introduce representations using
name and contexts of entities on the three levels of entity, word, and
character. We show each has complementary information and a multi-level
representation is the best. For the context model, we need to use distant
supervision since the context-level labels are not available for entities.
Distant supervised labels are noisy and this harms the performance of models.
Therefore, we introduce and apply new algorithms for noise mitigation using
multi-instance learning. We show the effectiveness of our models in a large
entity typing dataset, built from Freebase.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02276</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallelizing Over Artificial Neural Network Training Runs with
  Multigrid</dc:title>
 <dc:creator>Schroder, Jacob B.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Artificial neural networks are a popular and effective machine learning
technique. Great progress has been made parallelizing the expensive training
phase of an individual network, leading to highly specialized pieces of
hardware, many based on GPU-type architectures, and more concurrent algorithms
such as synthetic gradients. However, the training phase continues to be a
bottleneck, where the training data must be processed serially over thousands
of individual training runs. This work considers a multigrid reduction in time
(MGRIT) algorithm that is able to parallelize over the thousands of training
runs and converge to the exact same solution as traditional training would
provide. MGRIT was originally developed to provide parallelism for time
evolution problems that serially step through a finite number of time-steps.
This work recasts the training of a neural network similarly, treating neural
network training as an evolution equation that evolves the network weights from
one step to the next. Thus, this work concerns distributed computing approaches
for neural networks, but is distinct from other approaches which seek to
parallelize only over individual training runs. The work concludes with
supporting numerical results for two model problems.
</dc:description>
 <dc:description>Comment: Version 2: - Added more complete references to basic neural network
  literature - Corrected typos - Condensed results in Section 3 to be more
  concise - 22 pages</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-10-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02279</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Dimensionality of Noise-Free RSS and its Application in Distributed
  Massive MIMO</dc:title>
 <dc:creator>Prasad, K. N. R. Surya Vara</dc:creator>
 <dc:creator>Hossain, Ekram</dc:creator>
 <dc:creator>Bhargava, Vijay K.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We examine the dimensionality of noise-free uplink received signal strength
(RSS) data in a distributed multiuser massive multiple-input multiple-output
system. Specifically, we apply principal component analysis to the noise-free
uplink RSS and observe that it has a low-dimensional principal subspace. We
make use of this unique property to propose RecGP - a reconstruction-based
Gaussian process regression (GP) method which predicts user locations from
uplink RSS data. Considering noise-free RSS for training and noisy test RSS for
location prediction, RecGP reconstructs the noisy test RSS from a low-
dimensional principal subspace of the noise-free training RSS. The
reconstructed RSS is input to a trained GP model for location prediction. Noise
reduction facilitated by the reconstruction step allows RecGP to achieve lower
prediction error than standard GP methods which directly use the test RSS for
location prediction.
</dc:description>
 <dc:description>Comment: submitted to IEEE Wireless Communication Letters, July 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02282</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic segmentation of the intracranialvolume in fetal MR images</dc:title>
 <dc:creator>Khalili, N.</dc:creator>
 <dc:creator>Moeskops, P.</dc:creator>
 <dc:creator>Claessens, N. H. P.</dc:creator>
 <dc:creator>Scherpenzeel, S.</dc:creator>
 <dc:creator>Turk, E.</dc:creator>
 <dc:creator>de Heus, R.</dc:creator>
 <dc:creator>Benders, M. J. N. L.</dc:creator>
 <dc:creator>Viergever, M. A.</dc:creator>
 <dc:creator>Pluim, J. P. W.</dc:creator>
 <dc:creator>I&#x161;gum, I.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  MR images of the fetus allow non-invasive analysis of the fetal brain.
Quantitative analysis of fetal brain development requires automatic brain
tissue segmentation that is typically preceded by segmentation of the
intracranial volume (ICV). This is challenging because fetal MR images
visualize the whole moving fetus and in addition partially visualize the
maternal body. This paper presents an automatic method for segmentation of the
ICV in fetal MR images. The method employs a multi-scale convolutional neural
network in 2D slices to enable learning spatial information from larger context
as well as detailed local information. The method is developed and evaluated
with 30 fetal T2-weighted MRI scans (average age $33.2\pm1.2$ weeks
postmenstrual age). The set contains $10$ scans acquired in axial, $10$ in
coronal and $10$ in sagittal imaging planes. A reference standard was defined
in all images by manual annotation of the intracranial volume in $10$
equidistantly distributed slices. The automatic analysis was performed by
training and testing the network using scans acquired in the representative
imaging plane as well as combining the training data from all imaging planes.
On average, the automatic method achieved Dice coefficients of 0.90 for the
axial images, 0.90 for the coronal images and 0.92 for the sagittal images.
Combining the training sets resulted in average Dice coefficients of 0.91 for
the axial images, 0.95 for the coronal images, and 0.92 for the sagittal
images. The results demonstrate that the evaluated method achieved good
performance in extracting ICV in fetal MR scans regardless of the imaging
plane.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02283</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Visual Localisation in a Tagged Environment</dc:title>
 <dc:creator>Taquet, J&#xe9;r&#xe9;my</dc:creator>
 <dc:creator>&#xc9;corchard, Ga&#xeb;l</dc:creator>
 <dc:creator>P&#x159;eu&#x10d;il, Libor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In a robotised warehouse a major issue is the safety of human operators in
case of intervention in the work area of the robots. The current solution is to
shut down every robot but it causes a loss of productivity, especially for
large robotised warehouses. In order to avoid this loss we need to ensure the
operator's security during his/her intervention in the warehouse without
powering off the robots. The human operator needs to be localised in the
warehouse and the trajectories of the robots have to be modified so that they
do not interfere with the human. The purpose of this paper is to demonstrate a
visual localisation method with visual elements that are already available in
the current warehouse setup.
</dc:description>
 <dc:description>Comment: Student Conference on Planning in Artificial Intelligence and
  Robotics, Sept. 2016</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02285</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Adaptive Cluster-based Wiener Filter for Speckle Reduction of OCT
  Skin Images</dc:title>
 <dc:creator>Rashedi, Elaheh</dc:creator>
 <dc:creator>Adabi, Saba</dc:creator>
 <dc:creator>Mehregan, Darius</dc:creator>
 <dc:creator>Chen, Xue-wen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Optical coherence tomography (OCT) has become a favorable device in the
dermatology discipline due to its moderate resolution and penetration depth.
OCT images, however, contain a grainy pattern, called speckle, due to the use
of a broadband source in the configuration of OCT. So far, a variety of
filtering techniques is introduced to reduce speckle in OCT images. Most of
these methods are generic and can be applied to OCT images of different
tissues. In this paper, we present an adaptive filtering method, optimized for
speckle reduction of OCT skin images. Considering the architectural structure
of skin layers, OCT skin images can be segmented into differentiable clusters.
The image in each cluster is then filtered by a Wiener filter. The proposed
method was tested on optical solid phantoms with predetermined optical
properties. The algorithm was also tested on healthy human skin images. The
results show that the proposed cluster-based filtering method can effectively
reduce the speckle and increase the signal-to-noise ratio and contrast while
preserving the edges in the image.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02286</identifier>
 <datestamp>2017-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Jointly Attentive Spatial-Temporal Pooling Networks for Video-based
  Person Re-Identification</dc:title>
 <dc:creator>Xu, Shuangjie</dc:creator>
 <dc:creator>Cheng, Yu</dc:creator>
 <dc:creator>Gu, Kang</dc:creator>
 <dc:creator>Yang, Yang</dc:creator>
 <dc:creator>Chang, Shiyu</dc:creator>
 <dc:creator>Zhou, Pan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Person Re-Identification (person re-id) is a crucial task as its applications
in visual surveillance and human-computer interaction. In this work, we present
a novel joint Spatial and Temporal Attention Pooling Network (ASTPN) for
video-based person re-identification, which enables the feature extractor to be
aware of the current input video sequences, in a way that interdependency from
the matching items can directly influence the computation of each other's
representation. Specifically, the spatial pooling layer is able to select
regions from each frame, while the attention temporal pooling performed can
select informative frames over the sequence, both pooling guided by the
information from distance matching. Experiments are conduced on the iLIDS-VID,
PRID-2011 and MARS datasets and the results demonstrate that this approach
outperforms existing state-of-art methods. We also analyze how the joint
pooling in both dimensions can boost the person re-id performance more
effectively than using either of them separately.
</dc:description>
 <dc:description>Comment: To appear in ICCV 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2017-09-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02287</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monocular Depth Estimation with Hierarchical Fusion of Dilated CNNs and
  Soft-Weighted-Sum Inference</dc:title>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Dai, Yuchao</dc:creator>
 <dc:creator>He, Mingyi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Monocular depth estimation is a challenging task in complex compositions
depicting multiple objects of diverse scales. Albeit the recent great progress
thanks to the deep convolutional neural networks (CNNs), the state-of-the-art
monocular depth estimation methods still fall short to handle such real-world
challenging scenarios. In this paper, we propose a deep end-to-end learning
framework to tackle these challenges, which learns the direct mapping from a
color image to the corresponding depth map. First, we represent monocular depth
estimation as a multi-category dense labeling task by contrast to the
regression based formulation. In this way, we could build upon the recent
progress in dense labeling such as semantic segmentation. Second, we fuse
different side-outputs from our front-end dilated convolutional neural network
in a hierarchical way to exploit the multi-scale depth cues for depth
estimation, which is critical to achieve scale-aware depth estimation. Third,
we propose to utilize soft-weighted-sum inference instead of the hard-max
inference, transforming the discretized depth score to continuous depth value.
Thus, we reduce the influence of quantization error and improve the robustness
of our method. Extensive experiments on the NYU Depth V2 and KITTI datasets
show the superiority of our method compared with current state-of-the-art
methods. Furthermore, experiments on the NYU V2 dataset reveal that our model
is able to learn the probability distribution of depth.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02288</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Low-Rank Representations: Orthogonal Clustering Basis
  Reconstruction with Optimized Graph Structure for Multi-view Spectral
  Clustering</dc:title>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:creator>Wu, Lin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Low-Rank Representation (LRR) is arguably one of the most powerful paradigms
for Multi-view spectral clustering, which elegantly encodes the multi-view
local graph/manifold structures into an intrinsic low-rank self-expressive data
similarity embedded in high-dimensional space, to yield a better graph
partition than their single-view counterparts. In this paper we revisit it with
a fundamentally different perspective by discovering LRR as essentially a
latent clustered orthogonal projection based representation winged with an
optimized local graph structure for spectral clustering; each column of the
representation is fundamentally a cluster basis orthogonal to others to
indicate its members, which intuitively projects the view-specific feature
representation to be the one spanned by all orthogonal basis to characterize
the cluster structures. Upon this finding, we propose our technique with the
followings: (1) We decompose LRR into latent clustered orthogonal
representation via low-rank matrix factorization, to encode the more flexible
cluster structures than LRR over primal data objects; (2) We convert the
problem of LRR into that of simultaneously learning orthogonal clustered
representation and optimized local graph structure for each view; (3) The
learned orthogonal clustered representations and local graph structures enjoy
the same magnitude for multi-view, so that the ideal multi-view consensus can
be readily achieved. The experiments over multi-view datasets validate its
superiority.
</dc:description>
 <dc:description>Comment: Third Round Review with Minor Revision</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02288</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02300</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforced Video Captioning with Entailment Rewards</dc:title>
 <dc:creator>Pasunuru, Ramakanth</dc:creator>
 <dc:creator>Bansal, Mohit</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Sequence-to-sequence models have shown promising improvements on the temporal
task of video captioning, but they optimize word-level cross-entropy loss
during training. First, using policy gradient and mixed-loss methods for
reinforcement learning, we directly optimize sentence-level task-based metrics
(as rewards), achieving significant improvements over the baseline, based on
both automatic metrics and human evaluation on multiple datasets. Next, we
propose a novel entailment-enhanced reward (CIDEnt) that corrects
phrase-matching based metrics (such as CIDEr) to only allow for
logically-implied partial matches and avoid contradictions, achieving further
significant improvements over the CIDEr-reward model. Overall, our
CIDEnt-reward model achieves the new state-of-the-art on the MSR-VTT dataset.
</dc:description>
 <dc:description>Comment: EMNLP 2017 (9 pages)</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02312</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shortcut-Stacked Sentence Encoders for Multi-Domain Inference</dc:title>
 <dc:creator>Nie, Yixin</dc:creator>
 <dc:creator>Bansal, Mohit</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a simple sequential sentence encoder for multi-domain natural
language inference. Our encoder is based on stacked bidirectional LSTM-RNNs
with shortcut connections and fine-tuning of word embeddings. The overall
supervised model uses the above encoder to encode two input sentences into two
vectors, and then uses a classifier over the vector combination to label the
relationship between these two sentences as that of entailment, contradiction,
or neural. Our Shortcut-Stacked sentence encoders achieve strong improvements
over existing encoders on matched and mismatched multi-domain natural language
inference (top non-ensemble single-model result in the EMNLP RepEval 2017
Shared Task (Nangia et al., 2017)). Moreover, they achieve the new
state-of-the-art encoding result on the original SNLI dataset (Bowman et al.,
2015).
</dc:description>
 <dc:description>Comment: EMNLP 2017 RepEval Multi-NLI Shared Task (6 pages)</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02313</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GPLAC: Generalizing Vision-Based Robotic Skills using Weakly Labeled
  Images</dc:title>
 <dc:creator>Singh, Avi</dc:creator>
 <dc:creator>Yang, Larry</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We tackle the problem of learning robotic sensorimotor control policies that
can generalize to visually diverse and unseen environments. Achieving broad
generalization typically requires large datasets, which are difficult to obtain
for task-specific interactive processes such as reinforcement learning or
learning from demonstration. However, much of the visual diversity in the world
can be captured through passively collected datasets of images or videos. In
our method, which we refer to as GPLAC (Generalized Policy Learning with
Attentional Classifier), we use both interaction data and weakly labeled image
data to augment the generalization capacity of sensorimotor policies. Our
method combines multitask learning on action selection and an auxiliary binary
classification objective, together with a convolutional neural network
architecture that uses an attentional mechanism to avoid distractors. We show
that pairing interaction data from just a single environment with a diverse
dataset of weakly labeled data results in greatly improved generalization to
unseen environments, and show that this generalization depends on both the
auxiliary objective and the attentional architecture that we propose. We
demonstrate our results in both simulation and on a real robotic manipulator,
and demonstrate substantial improvement over standard convolutional
architectures and domain adaptation methods.
</dc:description>
 <dc:description>Comment: ICCV 2017. Also accepted at ICML 2017 Workshop on Lifelong Learning:
  A Reinforcement Learning Approach. Webpage:
  https://people.eecs.berkeley.edu/~avisingh/iccv17/</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02314</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multibiometric Secure System Based on Deep Learning</dc:title>
 <dc:creator>Talreja, Veeru</dc:creator>
 <dc:creator>Valenti, Matthew C.</dc:creator>
 <dc:creator>Nasrabadi, Nasser M.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a secure multibiometric system that uses deep
neural networks and error-correction coding. We present a feature-level fusion
framework to generate a secure multibiometric template from each user's
multiple biometrics. Two fusion architectures, fully connected architecture and
bilinear architecture, are implemented to develop a robust multibiometric
shared representation. The shared representation is used to generate a
cancelable biometric template that involves the selection of a different set of
reliable and discriminative features for each user. This cancelable template is
a binary vector and is passed through an appropriate error-correcting decoder
to find a closest codeword and this codeword is hashed to generate the final
secure template. The efficacy of the proposed approach is shown using a
multimodal database where we achieve state-of-the-art matching performance,
along with cancelability and security.
</dc:description>
 <dc:description>Comment: To be published in Proc. IEEE Global SIP 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02316</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Approach to Quad Meshing Based on Harmonic Cross-Valued Maps and the
  Ginzburg-Landau Theory</dc:title>
 <dc:creator>Viertel, Ryan</dc:creator>
 <dc:creator>Osting, Braxton</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:description>  A generalization of vector fields, referred to as $N$-direction fields or
cross fields when $N = 4$, has been recently introduced and studied for
geometry processing, with applications in quadrilateral (quad) meshing, texture
mapping, and parameterization. We make the observation that cross field design
for two-dimensional quad meshing is related to the well-known Ginzburg-Landau
problem from mathematical physics. This identification yields a variety of
theoretical tools for efficiently computing boundary-aligned quad meshes, with
provable guarantees on the resulting mesh, for example, the number of mesh
defects and bounds on the defect locations. The procedure for generating the
quad mesh is to (i) find a complex-valued &quot;representation&quot; field that minimizes
the Dirichlet energy subject to a boundary constraint, (ii) convert the
representation field into a boundary-aligned, smooth cross field, (iii) use
separatrices of the cross field to partition the domain into four sided
regions, and (iv) mesh each of these four-sided regions using standard
techniques. Under certain assumptions on the geometry of the domain, we prove
that this procedure can be used to produce a cross field whose separatrices
partition the domain into four sided regions. To solve the energy minimization
problem for the representation field, we use an extension of the
Merriman-Bence-Osher (MBO) threshold dynamics method, originally conceived as
an algorithm to simulate motion by mean curvature, to minimize the
Ginzburg-Landau energy for the optimal representation field. Finally, we
demonstrate the method on a variety of test domains.
</dc:description>
 <dc:description>Comment: 27 pages, 12 figures</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02318</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Lock-Free Data Structures in Haskell: A General Method for
  Concurrent Implementation Swapping</dc:title>
 <dc:creator>Chen, Chao-Hong</dc:creator>
 <dc:creator>Choudhury, Vikraman</dc:creator>
 <dc:creator>Newton, Ryan R.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>D.1.1</dc:subject>
 <dc:description>  A key part of implementing high-level languages is providing built-in and
default data structures. Yet selecting good defaults is hard. A mutable data
structure's workload is not known in advance, and it may shift over its
lifetime - e.g., between read-heavy and write-heavy, or from heavy contention
by multiple threads to single-threaded or low-frequency use. One idea is to
switch implementations adaptively, but it is nontrivial to switch the
implementation of a concurrent data structure at runtime. Performing the
transition requires a concurrent snapshot of data structure contents, which
normally demands special engineering in the data structure's design. However,
in this paper we identify and formalize an relevant property of lock-free
algorithms. Namely, lock-freedom is sufficient to guarantee that freezing
memory locations in an arbitrary order will result in a valid snapshot. Several
functional languages have data structures that freeze and thaw, transitioning
between mutable and immutable, such as Haskell vectors and Clojure transients,
but these enable only single-threaded writers. We generalize this approach to
augment an arbitrary lock-free data structure with the ability to gradually
freeze and optionally transition to a new representation. This augmentation
doesn't require changing the algorithm or code for the data structure, only
replacing its datatype for mutable references with a freezable variant. In this
paper, we present an algorithm for lifting plain to adaptive data and prove
that the resulting hybrid data structure is itself lock-free, linearizable, and
simulates the original. We also perform an empirical case study in the context
of heating up and cooling down concurrent maps.
</dc:description>
 <dc:description>Comment: To be published in ACM SIGPLAN Haskell Symposium 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02318</dc:identifier>
 <dc:identifier>doi:10.1145/3122955.3122973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02319</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Learnability of Programming Language Semantics</dc:title>
 <dc:creator>Ghica, Dan R.</dc:creator>
 <dc:creator>Alyahya, Khulood</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Game semantics is a powerful method of semantic analysis for programming
languages. It gives mathematically accurate models (&quot;fully abstract&quot;) for a
wide variety of programming languages. Game semantic models are combinatorial
characterisations of all possible interactions between a term and its syntactic
context. Because such interactions can be concretely represented as sets of
sequences, it is possible to ask whether they can be learned from examples.
Concretely, we are using long short-term memory neural nets (LSTM), a technique
which proved effective in learning natural languages for automatic translation
and text synthesis, to learn game-semantic models of sequential and concurrent
versions of Idealised Algol (IA), which are algorithmically complex yet can be
concisely described. We will measure how accurate the learned models are as a
function of the degree of the term and the number of free variables involved.
Finally, we will show how to use the learned model to perform latent semantic
analysis between concurrent and sequential Idealised Algol.
</dc:description>
 <dc:description>Comment: In Proceedings ICE 2017, arXiv:1711.10708</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02319</dc:identifier>
 <dc:identifier>EPTCS 261, 2017, pp. 57-75</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.261.7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02321</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Approximate ML Detector for MIMO Channels Corrupted by Phase Noise</dc:title>
 <dc:creator>Combes, Richard</dc:creator>
 <dc:creator>Yang, Sheng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the multiple-input multiple-output (MIMO) communication channel
impaired by phase noises at both the transmitter and receiver. We focus on the
maximum likelihood (ML) detection problem for uncoded single-carrier
transmission. We derive an approximation of the likelihood function, based on
which we propose an efficient detection algorithm. The proposed algorithm,
named self-interference whitening (SIW), consists in 1) estimating the
self-interference caused by the phase noise perturbation, then 2) whitening the
said interference, and finally 3) detecting the transmitted vector. While the
exact ML solution is computationally intractable, we construct a
simulation-based lower bound on the error probability of ML detection.
Leveraging this lower bound, we perform extensive numerical experiments
demonstrating that SIW is, in most cases of interest, very close to optimal
with moderate phase noise. More importantly and perhaps surprisingly, such
near-ML performance can be achieved by applying only twice the nearest neighbor
detection algorithm. In this sense, our results reveal a striking fact: near-ML
detection of phase noise corrupted MIMO channels can be done as efficiently as
for conventional MIMO channels without phase noise.
</dc:description>
 <dc:description>Comment: 30 pages, 8 figures</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02322</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Raga Recognition in Hindustani Classical Music</dc:title>
 <dc:creator>Alekh, Sanchit</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Raga is the central melodic concept in Hindustani Classical Music. It has a
complex structure, often characterized by pathos. In this paper, we describe a
technique for Automatic Raga Recognition, based on pitch distributions. We are
able to successfully classify ragas with a commendable accuracy on our test
dataset.
</dc:description>
 <dc:description>Comment: Seminar on Computer Music, RWTH Aachen,
  http://hpac.rwth-aachen.de/teaching/sem-mus-17/Reports/Alekh.pdf</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02323</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Odd Multiway Cut in Directed Acyclic Graphs</dc:title>
 <dc:creator>Chandrasekaran, Karthekeyan</dc:creator>
 <dc:creator>Mozaffari, Sahand</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:description>  We investigate the odd multiway node (edge) cut problem where the input is a
graph with a specified collection of terminal nodes and the goal is to find a
smallest subset of non-terminal nodes (edges) to delete so that the terminal
nodes do not have an odd length path between them. In an earlier work,
Lokshtanov and Ramanujan showed that both odd multiway node cut and odd
multiway edge cut are fixed-parameter tractable (FPT) when parameterized by the
size of the solution in undirected graphs. In this work, we focus on directed
acyclic graphs (DAGs) and design a fixed-parameter algorithm. Our main
contribution is an extension of the shadow-removal framework for parity
problems in DAGs. We complement our FPT results with tight approximability as
well as polyhedral results for 2 terminals in DAGs. Additionally, we show
inapproximability results for odd multiway edge cut in undirected graphs even
for 2 terminals.
</dc:description>
 <dc:description>Comment: 21 pages, 4 figures</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02328</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deriving Law-Abiding Instances</dc:title>
 <dc:creator>Scott, Ryan</dc:creator>
 <dc:creator>Choudhury, Vikraman</dc:creator>
 <dc:creator>Newton, Ryan</dc:creator>
 <dc:creator>Vazou, Niki</dc:creator>
 <dc:creator>Jhala, Ranjit</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.1.1</dc:subject>
 <dc:description>  Liquid Haskell's refinement-reflection feature augments the Haskell language
with theorem proving capabilities, allowing programmers to retrofit their
existing code with proofs. But many of these proofs require routine,
boilerplate code that is tedious to write. Moreover, many such proofs do not
scale well, as the size of proof terms can grow superlinearly with the size of
the datatypes involved in the proofs.
  We present a technique for programming with refinement reflection which
solves this problem by leveraging datatype-generic programming. Our observation
is that we can take any algebraic datatype, generate an equivalent
representation type, and have Liquid Haskell automatically construct (and
prove) an isomorphism between the original type and the representation type.
This reduces many proofs down to easy theorems over simple algebraic &quot;building
block&quot; types, allowing programmers to write generic proofs cheaply and
cheerfully.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02330</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Makes a Place? Building Bespoke Place Dependent Object Detectors
  for Robotics</dc:title>
 <dc:creator>Hawke, Jeffrey</dc:creator>
 <dc:creator>Bewley, Alex</dc:creator>
 <dc:creator>Posner, Ingmar</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper is about enabling robots to improve their perceptual performance
through repeated use in their operating environment, creating local expert
detectors fitted to the places through which a robot moves. We leverage the
concept of 'experiences' in visual perception for robotics, accounting for bias
in the data a robot sees by fitting object detector models to a particular
place. The key question we seek to answer in this paper is simply: how do we
define a place? We build bespoke pedestrian detector models for autonomous
driving, highlighting the necessary trade off between generalisation and model
capacity as we vary the extent of the place we fit to. We demonstrate a
sizeable performance gain over a current state-of-the-art detector when using
computationally lightweight bespoke place-fitted detector models.
</dc:description>
 <dc:description>Comment: IROS 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02330</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02337</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unconstrained Face Detection and Open-Set Face Recognition Challenge</dc:title>
 <dc:creator>G&#xfc;nther, Manuel</dc:creator>
 <dc:creator>Hu, Peiyun</dc:creator>
 <dc:creator>Herrmann, Christian</dc:creator>
 <dc:creator>Chan, Chi Ho</dc:creator>
 <dc:creator>Jiang, Min</dc:creator>
 <dc:creator>Yang, Shufan</dc:creator>
 <dc:creator>Dhamija, Akshay Raj</dc:creator>
 <dc:creator>Ramanan, Deva</dc:creator>
 <dc:creator>Beyerer, J&#xfc;rgen</dc:creator>
 <dc:creator>Kittler, Josef</dc:creator>
 <dc:creator>Jazaery, Mohamad Al</dc:creator>
 <dc:creator>Nouyed, Mohammad Iqbal</dc:creator>
 <dc:creator>Guo, Guodong</dc:creator>
 <dc:creator>Stankiewicz, Cezary</dc:creator>
 <dc:creator>Boult, Terrance E.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face detection and recognition benchmarks have shifted toward more difficult
environments. The challenge presented in this paper addresses the next step in
the direction of automatic detection and identification of people from outdoor
surveillance cameras. While face detection has shown remarkable success in
images collected from the web, surveillance cameras include more diverse
occlusions, poses, weather conditions and image blur. Although face
verification or closed-set face identification have surpassed human
capabilities on some datasets, open-set identification is much more complex as
it needs to reject both unknown identities and false accepts from the face
detector. We show that unconstrained face detection can approach high detection
rates albeit with moderate false accept rates. By contrast, open-set face
recognition is currently weak and requires much more attention.
</dc:description>
 <dc:description>Comment: Accepted for oral presentation at IJCB 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02337</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02347</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-triggering in Vehicular Networked Systems with State-dependent
  Bursty Fading Channels</dc:title>
 <dc:creator>Hu, Bin</dc:creator>
 <dc:creator>Lemmon, Michael</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Vehicular Networked Systems (VNS) are mobile ad hoc networks where vehicles
exchange information over wireless communication networks to ensure safe and
efficient operation. It is, however, challenging to ensure system safety and
efficiency as the wireless channels in VNS are often subject to state-dependent
deep fades where the data rate suffers a severe drop and changes as a function
of vehicle states. Such couplings between vehicle states and channel states in
VNS thereby invalidate the use of separation principle to design event-based
control strategies. By adopting a state-dependent fading channel model that was
proposed to capture the interaction between vehicle and channel states, this
paper presents a novel self-triggered scheme under which the VNS ensures
efficient use of communication bandwidth while preserving stochastic stability.
The novelty of the proposed scheme lies in its use of the state-dependent
fading channel model in the event design that enables an adaptive and effective
adjustment on transmission frequency in response to dynamic variations on
channel and vehicle states. Under the proposed self-triggered scheme, this
paper presents a novel source coding scheme that tracks vehicle's states with
performance guarantee in the presence of state-dependent fading channels. The
efficacy and advantages of the proposed scheme over other event-based
strategies are verified through both simulation and experimental results of a
leader-follower example.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02349</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Context Network for Activity Localization in Videos</dc:title>
 <dc:creator>Dai, Xiyang</dc:creator>
 <dc:creator>Singh, Bharat</dc:creator>
 <dc:creator>Zhang, Guyue</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:creator>Chen, Yan Qiu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a Temporal Context Network (TCN) for precise temporal localization
of human activities. Similar to the Faster-RCNN architecture, proposals are
placed at equal intervals in a video which span multiple temporal scales. We
propose a novel representation for ranking these proposals. Since pooling
features only inside a segment is not sufficient to predict activity
boundaries, we construct a representation which explicitly captures context
around a proposal for ranking it. For each temporal segment inside a proposal,
features are uniformly sampled at a pair of scales and are input to a temporal
convolutional neural network for classification. After ranking proposals,
non-maximum suppression is applied and classification is performed to obtain
final detections. TCN outperforms state-of-the-art methods on the ActivityNet
dataset and the THUMOS14 dataset.
</dc:description>
 <dc:description>Comment: To appear in ICCV 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02354</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>2D SLAM Quality Evaluation Methods</dc:title>
 <dc:creator>Filatov, Anton</dc:creator>
 <dc:creator>Filatov, Artyom</dc:creator>
 <dc:creator>Krinkin, Kirill</dc:creator>
 <dc:creator>Chen, Baian</dc:creator>
 <dc:creator>Molodan, Diana</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  SLAM (Simultaneous Localization and mapping) is one of the most challenging
problems for mobile platforms and there is a huge amount of modern SLAM
algorithms. The choice of the algorithm that might be used in every particular
problem requires prior knowledge about advantages and disadvantages of each
algorithm. This paper presents the approach for comparison of SLAM algorithms
that allows to find the most accurate one. The accent of research is made on 2D
SLAM algorithms and the focus of analysis is 2D map that is built after
algorithm performance. Three metrics for evaluation of maps are presented in
this paper
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02357</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards A Novel Unified Framework for Developing Formal, Network and
  Validated Agent-Based Simulation Models of Complex Adaptive Systems</dc:title>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>I.6</dc:subject>
 <dc:subject>I.6.5</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:subject>D.2</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:subject>D.1.5</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>C.2</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  Literature on the modeling and simulation of complex adaptive systems (cas)
has primarily advanced vertically in different scientific domains with
scientists developing a variety of domain-specific approaches and applications.
However, while cas researchers are inher-ently interested in an
interdisciplinary comparison of models, to the best of our knowledge, there is
currently no single unified framework for facilitating the development,
comparison, communication and validation of models across different scientific
domains. In this thesis, we propose first steps towards such a unified
framework using a combination of agent-based and complex network-based modeling
approaches and guidelines formulated in the form of a set of four levels of
usage, which allow multidisciplinary researchers to adopt a suitable framework
level on the basis of available data types, their research study objectives and
expected outcomes, thus allowing them to better plan and conduct their
respective re-search case studies.
</dc:description>
 <dc:description>Comment: PhD Thesis, University of Stirling, Scotland, UK. (2011), 93 figures,
  23 tables, 292 pages</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02361</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verification &amp; Validation of Agent Based Simulations using the VOMAS
  (Virtual Overlay Multi-agent System) approach</dc:title>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:creator>Hussain, Amir</dc:creator>
 <dc:creator>Kolberg, Mario</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>B.2.2</dc:subject>
 <dc:subject>B.4.4</dc:subject>
 <dc:subject>B.5.2</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>I.6.4</dc:subject>
 <dc:description>  Agent Based Models are very popular in a number of different areas. For
example, they have been used in a range of domains ranging from modeling of
tumor growth, immune systems, molecules to models of social networks, crowds
and computer and mobile self-organizing networks. One reason for their success
is their intuitiveness and similarity to human cognition. However, with this
power of abstraction, in spite of being easily applicable to such a wide number
of domains, it is hard to validate agent-based models. In addition, building
valid and credible simulations is not just a challenging task but also a
crucial exercise to ensure that what we are modeling is, at some level of
abstraction, a model of our conceptual system; the system that we have in mind.
In this paper, we address this important area of validation of agent based
models by presenting a novel technique which has broad applicability and can be
applied to all kinds of agent-based models. We present a framework, where a
virtual overlay multi-agent system can be used to validate simulation models.
In addition, since agent-based models have been typically growing, in parallel,
in multiple domains, to cater for all of these, we present a new single
validation technique applicable to all agent based models. Our technique, which
allows for the validation of agent based simulations uses VOMAS: a Virtual
Overlay Multi-agent System. This overlay multi-agent system can comprise
various types of agents, which form an overlay on top of the agent based
simulation model that needs to be validated. Other than being able to watch and
log, each of these agents contains clearly defined constraints, which, if
violated, can be logged in real time. To demonstrate its effectiveness, we show
its broad applicability in a wide variety of simulation models ranging from
social sciences to computer networks in spatial and non-spatial conceptual
models.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, cite as Muaz Niazi, Amir Hussain and Mario
  Kolberg , Verification and Validation of Agent-Based Simulation using the
  VOMAS approach, Proceedings of the Third Workshop on Multi-Agent Systems and
  Simulation'09 (MASS '09), as part of MALLOW 09, Sep 7-11, 2009, Torino, Italy</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02363</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond the technical challenges for deploying Machine Learning solutions
  in a software company</dc:title>
 <dc:creator>Flaounas, Ilias</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recently software development companies started to embrace Machine Learning
(ML) techniques for introducing a series of advanced functionality in their
products such as personalisation of the user experience, improved search,
content recommendation and automation. The technical challenges for tackling
these problems are heavily researched in literature. A less studied area is a
pragmatic approach to the role of humans in a complex modern industrial
environment where ML based systems are developed. Key stakeholders affect the
system from inception and up to operation and maintenance. Product managers
want to embed &quot;smart&quot; experiences for their users and drive the decisions on
what should be built next; software engineers are challenged to build or
utilise ML software tools that require skills that are well outside of their
comfort zone; legal and risk departments may influence design choices and data
access; operations teams are requested to maintain ML systems which are
non-stationary in their nature and change behaviour over time; and finally ML
practitioners should communicate with all these stakeholders to successfully
build a reliable system. This paper discusses some of the challenges we faced
in Atlassian as we started investing more in the ML space.
</dc:description>
 <dc:description>Comment: Human in the Loop Machine Learning Workshop, International Conference
  on Machine Learning, Sydney, Australia, 2017</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02368</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic feature learning for vulnerability prediction</dc:title>
 <dc:creator>Dam, Hoa Khanh</dc:creator>
 <dc:creator>Tran, Truyen</dc:creator>
 <dc:creator>Pham, Trang</dc:creator>
 <dc:creator>Ng, Shien Wee</dc:creator>
 <dc:creator>Grundy, John</dc:creator>
 <dc:creator>Ghose, Aditya</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Code flaws or vulnerabilities are prevalent in software systems and can
potentially cause a variety of problems including deadlock, information loss,
or system failure. A variety of approaches have been developed to try and
detect the most likely locations of such code vulnerabilities in large code
bases. Most of them rely on manually designing features (e.g. complexity
metrics or frequencies of code tokens) that represent the characteristics of
the code. However, all suffer from challenges in sufficiently capturing both
semantic and syntactic representation of source code, an important capability
for building accurate prediction models. In this paper, we describe a new
approach, built upon the powerful deep learning Long Short Term Memory model,
to automatically learn both semantic and syntactic features in code. Our
evaluation on 18 Android applications demonstrates that the prediction power
obtained from our learned features is equal or even superior to what is
achieved by state of the art vulnerability prediction models: 3%--58%
improvement for within-project prediction and 85% for cross-project prediction.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02377</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural patterns of information cascades and their implications for
  dynamics and semantics</dc:title>
 <dc:creator>Zang, Chengxi</dc:creator>
 <dc:creator>Cui, Peng</dc:creator>
 <dc:creator>Song, Chaoming</dc:creator>
 <dc:creator>Faloutsos, Christos</dc:creator>
 <dc:creator>Zhu, Wenwu</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Information cascades are ubiquitous in both physical society and online
social media, taking on large variations in structures, dynamics and semantics.
Although the dynamics and semantics of information cascades have been studied,
the structural patterns and their correlations with dynamics and semantics are
largely unknown. Here we explore a large-scale dataset including $432$ million
information cascades with explicit records of spreading traces, spreading
behaviors, information content as well as user profiles. We find that the
structural complexity of information cascades is far beyond the previous
conjectures. We first propose a ten-dimensional metric to quantify the
structural characteristics of information cascades, reflecting cascade size,
silhouette, direction and activity aspects. We find that bimodal law governs
majority of the metrics, information flows in cascades have four directions,
and the self-loop number and average activity of cascades follows power law. We
then analyze the high-order structural patterns of information cascades.
Finally, we evaluate to what extent the structural features of information
cascades can explain its dynamic patterns and semantics, and finally uncover
some notable implications of structural patterns in information cascades. Our
discoveries also provide a foundation for the microscopic mechanisms for
information spreading, potentially leading to implications for cascade
prediction and outlier detection.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02378</identifier>
 <datestamp>2017-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating Reinforcement Learning Agents for Continuous State Space
  Environments</dc:title>
 <dc:creator>Von Dollen, David</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Given an environment with continuous state spaces and discrete actions, we
investigate using a Double Deep Q-learning Reinforcement Agent to find optimal
policies using the LunarLander-v2 OpenAI gym environment.
</dc:description>
 <dc:description>Comment: Withdrawn per request of Georgia Tech. The reason this this
  withdrawal, is that the research was done using GATech class materials
  provided, and may be in violation with GATech academic policy</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02380</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ghera: A Repository of Android App Vulnerability Benchmarks</dc:title>
 <dc:creator>Mitra, Joydeep</dc:creator>
 <dc:creator>Ranganath, Venkatesh-Prasad</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>K.6.m</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:description>  Security of mobile apps affects the security of their users. This has fueled
the development of techniques to automatically detect vulnerabilities in mobile
apps and help developers secure their apps; specifically, in the context of
Android platform due to openness and ubiquitousness of the platform. Despite a
slew of research efforts in this space, there is no comprehensive repository of
up-to-date and lean benchmarks that contain most of the known Android app
vulnerabilities and, consequently, can be used to rigorously evaluate both
existing and new vulnerability detection techniques and help developers learn
about Android app vulnerabilities. In this paper, we describe Ghera, an open
source repository of benchmarks that capture 25 known vulnerabilities in
Android apps (as pairs of exploited/benign and exploiting/malicious apps). We
also present desirable characteristics of vulnerability benchmarks and
repositories that we uncovered while creating Ghera.
</dc:description>
 <dc:description>Comment: 10 pages. Accepted at PROMISE'17</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02380</dc:identifier>
 <dc:identifier>doi:10.1145/3127005.3127010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02382</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual-inertial self-calibration on informative motion segments</dc:title>
 <dc:creator>Schneider, Thomas</dc:creator>
 <dc:creator>Li, Mingyang</dc:creator>
 <dc:creator>Burri, Michael</dc:creator>
 <dc:creator>Nieto, Juan</dc:creator>
 <dc:creator>Siegwart, Roland</dc:creator>
 <dc:creator>Gilitschenski, Igor</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Environmental conditions and external effects, such as shocks, have a
significant impact on the calibration parameters of visual-inertial sensor
systems. Thus long-term operation of these systems cannot fully rely on factory
calibration. Since the observability of certain parameters is highly dependent
on the motion of the device, using short data segments at device initialization
may yield poor results. When such systems are additionally subject to energy
constraints, it is also infeasible to use full-batch approaches on a big
dataset and careful selection of the data is of high importance. In this paper,
we present a novel approach for resource efficient self-calibration of
visual-inertial sensor systems. This is achieved by casting the calibration as
a segment-based optimization problem that can be run on a small subset of
informative segments. Consequently, the computational burden is limited as only
a predefined number of segments is used. We also propose an efficient
information-theoretic selection to identify such informative motion segments.
In evaluations on a challenging dataset, we show our approach to significantly
outperform state-of-the-art in terms of computational burden while maintaining
a comparable accuracy.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02382</dc:identifier>
 <dc:identifier>Robotics and Automation (ICRA), 2017 IEEE International Conference
  on</dc:identifier>
 <dc:identifier>doi:10.1109/ICRA.2017.7989766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02383</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning how to Active Learn: A Deep Reinforcement Learning Approach</dc:title>
 <dc:creator>Fang, Meng</dc:creator>
 <dc:creator>Li, Yuan</dc:creator>
 <dc:creator>Cohn, Trevor</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Active learning aims to select a small subset of data for annotation such
that a classifier learned on the data is highly accurate. This is usually done
using heuristic selection methods, however the effectiveness of such methods is
limited and moreover, the performance of heuristics varies between datasets. To
address these shortcomings, we introduce a novel formulation by reframing the
active learning as a reinforcement learning problem and explicitly learning a
data selection policy, where the policy takes the role of the active learning
heuristic. Importantly, our method allows the selection policy learned using
simulation on one language to be transferred to other languages. We demonstrate
our method using cross-lingual named entity recognition, observing uniform
improvements over traditional active learning.
</dc:description>
 <dc:description>Comment: To appear in EMNLP 2017</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02386</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a Repression Network for Precise Vehicle Search</dc:title>
 <dc:creator>Xu, Qiantong</dc:creator>
 <dc:creator>Yan, Ke</dc:creator>
 <dc:creator>Tian, Yonghong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The growing explosion in the use of surveillance cameras in public security
highlights the importance of vehicle search from large-scale image databases.
Precise vehicle search, aiming at finding out all instances for a given query
vehicle image, is a challenging task as different vehicles will look very
similar to each other if they share same visual attributes. To address this
problem, we propose the Repression Network (RepNet), a novel multi-task
learning framework, to learn discriminative features for each vehicle image
from both coarse-grained and detailed level simultaneously. Besides, benefited
from the satisfactory accuracy of attribute classification, a bucket search
method is proposed to reduce the retrieval time while still maintaining
competitive performance. We conduct extensive experiments on the revised
VehcileID dataset. Experimental results show that our RepNet achieves the
state-of-the-art performance and the bucket search method can reduce the
retrieval time by about 24 times.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02392</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Human-Robot Collaboration Insights through the Integration of
  Muscle Activity in Interaction Motion Models</dc:title>
 <dc:creator>Chen, Longxin</dc:creator>
 <dc:creator>Rojas, Juan</dc:creator>
 <dc:creator>Duan, Shuangda</dc:creator>
 <dc:creator>Guan, Yisheng</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Recent progress in human-robot collaboration makes fast and fluid
interactions possible, even when human observations are partial and occluded.
Methods like Interaction Probabilistic Movement Primitives (ProMP) model human
trajectories through motion capture systems. However, such representation does
not properly model tasks where similar motions handle different objects. Under
current approaches, a robot would not adapt its pose and dynamics for proper
handling. We integrate the use of Electromyography (EMG) into the Interaction
ProMP framework and utilize muscular signals to augment the human observation
representation. The contribution of our paper is increased task discernment
when trajectories are similar but tools are different and require the robot to
adjust its pose for proper handling. Interaction ProMPs are used with an
augmented vector that integrates muscle activity. Augmented time-normalized
trajectories are used in training to learn correlation parameters and robot
motions are predicted by finding the best weight combination and temporal
scaling for a task. Collaborative single task scenarios with similar motions
but different objects were used and compared. For one experiment only joint
angles were recorded, for the other EMG signals were additionally integrated.
Task recognition was computed for both tasks. Observation state vectors with
augmented EMG signals were able to completely identify differences across
tasks, while the baseline method failed every time. Integrating EMG signals
into collaborative tasks significantly increases the ability of the system to
recognize nuances in the tasks that are otherwise imperceptible, up to 74.6% in
our studies. Furthermore, the integration of EMG signals for collaboration also
opens the door to a wide class of human-robot physical interactions based on
haptic communication that has been largely unexploited in the field.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures, 2 tables. As submitted to Humanoids 2017</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02392</dc:identifier>
 <dc:identifier>doi:10.1109/HUMANOIDS.2017.8246917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02393</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cherry-Picking of Code Commits in Long-Running, Multi-release Software</dc:title>
 <dc:creator>Bunyakiati, Panuchart</dc:creator>
 <dc:creator>Phipathananunth, Chadarat</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This paper presents Tartarian, a tool that supports maintenance of software
with long-running, multi-release branches in distributed version control
systems. When new maintenance code, such as bug fixes and code improvement, is
committed into a branch, it is likely that such code can be applied or reused
with some other branches. To do so, a developer may manually identify a commit
and cherry pick it. Tartarian can support this activity by providing commit
hashtags, which the developer uses as metadata to specify their intentions when
committing the code. With these tags, Tartarian uses dependency graph, that
represents the dependency constraints of the branches, and Branch Identifier,
which matches the commit hashtags with the dependency graph, to identify the
applicable branches for the commits. Using Tartarian, developers may be able to
maintain software with multiple releases more efficiently.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02393</dc:identifier>
 <dc:identifier>doi:10.1145/3106237.3122818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02406</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Conditional Probabilities</dc:title>
 <dc:creator>Wald, Yoav</dc:creator>
 <dc:creator>Globerson, Amir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Conditional probabilities are a core concept in machine learning. For
example, optimal prediction of a label $Y$ given an input $X$ corresponds to
maximizing the conditional probability of $Y$ given $X$. A common approach to
inference tasks is learning a model of conditional probabilities. However,
these models are often based on strong assumptions (e.g., log-linear models),
and hence their estimate of conditional probabilities is not robust and is
highly dependent on the validity of their assumptions.
  Here we propose a framework for reasoning about conditional probabilities
without assuming anything about the underlying distributions, except knowledge
of their second order marginals, which can be estimated from data. We show how
this setting leads to guaranteed bounds on conditional probabilities, which can
be calculated efficiently in a variety of settings, including
structured-prediction. Finally, we apply them to semi-supervised deep learning,
obtaining results competitive with variational autoencoders.
</dc:description>
 <dc:description>Comment: 24 pages, 1 figure</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02409</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling of a Permanent Magnet Synchronous Machine Using Isogeometric
  Analysis</dc:title>
 <dc:creator>Bontinck, Zeger</dc:creator>
 <dc:creator>Corno, Jacopo</dc:creator>
 <dc:creator>Bhat, Prithvi</dc:creator>
 <dc:creator>De Gersem, Herbert</dc:creator>
 <dc:creator>Sch&#xf6;ps, Sebastian</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:description>  Isogeometric analysis (IGA) is used to simulate a permanent magnet
synchronous machine. IGA uses non-uniform rational B-splines to parametrise the
domain and to approximate the solution space, thus allowing for the exact
description of the geometries even on the coarsest level of mesh refinement.
Given the properties of the isogeometric basis functions, this choice
guarantees a higher accuracy than the classical finite element method.
  For dealing with the different stator and rotor topologies, the domain is
split into two non-overlapping parts on which Maxwell's equations are solved
independently in the context of a classical Dirichlet-to-Neumann domain
decomposition scheme. The results show good agreement with the ones obtained by
the classical finite element approach.
</dc:description>
 <dc:description>Comment: 4 pages, 7 figures, 18th International Symposium on Electromagnetic
  Fields in Mechatronics, Electrical and Electronic Engineering, 14-16
  September 2017, Lodz, Poland</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02412</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wasserstein CNN: Learning Invariant Features for NIR-VIS Face
  Recognition</dc:title>
 <dc:creator>He, Ran</dc:creator>
 <dc:creator>Wu, Xiang</dc:creator>
 <dc:creator>Sun, Zhenan</dc:creator>
 <dc:creator>Tan, Tieniu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Heterogeneous face recognition (HFR) aims to match facial images acquired
from different sensing modalities with mission-critical applications in
forensics, security and commercial sectors. However, HFR is a much more
challenging problem than traditional face recognition because of large
intra-class variations of heterogeneous face images and limited training
samples of cross-modality face image pairs. This paper proposes a novel
approach namely Wasserstein CNN (convolutional neural networks, or WCNN for
short) to learn invariant features between near-infrared and visual face images
(i.e. NIR-VIS face recognition). The low-level layers of WCNN are trained with
widely available face images in visual spectrum. The high-level layer is
divided into three parts, i.e., NIR layer, VIS layer and NIR-VIS shared layer.
The first two layers aims to learn modality-specific features and NIR-VIS
shared layer is designed to learn modality-invariant feature subspace.
Wasserstein distance is introduced into NIR-VIS shared layer to measure the
dissimilarity between heterogeneous feature distributions. So W-CNN learning
aims to achieve the minimization of Wasserstein distance between NIR
distribution and VIS distribution for invariant deep feature representation of
heterogeneous face images. To avoid the over-fitting problem on small-scale
heterogeneous face data, a correlation prior is introduced on the
fully-connected layers of WCNN network to reduce parameter space. This prior is
implemented by a low-rank constraint in an end-to-end network. The joint
formulation leads to an alternating minimization for deep feature
representation at training stage and an efficient computation for heterogeneous
data at testing stage. Extensive experiments on three challenging NIR-VIS face
recognition databases demonstrate the significant superiority of Wasserstein
CNN over state-of-the-art methods.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02417</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evidence from web-based dietary search patterns to the role of B12
  deficiency in chronic pain</dc:title>
 <dc:creator>Giat, Eitan</dc:creator>
 <dc:creator>Yom-Tov, Elad</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Quantitative Biology - Tissues and Organs</dc:subject>
 <dc:description>  Profound vitamin B12 deficiency is a known cause of disease, but the role of
low or intermediate levels of B12 in the development of neuropathy and other
neuropsychiatric symptoms as well as the relationship of eating meat and B12
levels is unclear. Here we use food-related internet search patterns from a
sample of 8.5 million US-based people as a proxy to B12 intake and correlate
these searches with internet searches related to possible effects of B12
deficiency. Food-related search patterns are highly correlated with known
consumption and food-related searches (Spearman 0.69). Awareness of B12
deficiency was associated with a higher consumption of B12-rich foods and with
queries for B12 supplements. Searches for terms related to neurological
disorders were correlated with searches for B12-poor foods, in contrast with
control terms. Popular medicines, those having fewer indications, and those
which are predominantly used to treat pain are more strongly correlated with
the ability to predict neuropathic pain queries using the B12 contents of food.
Our findings provide evidence for the utility of using Internet search patterns
to investigate health questions in large populations and suggest that low B12
intake may be associated with a broader spectrum of neurological disorders than
currently appreciated.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02419</identifier>
 <datestamp>2017-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Concurrent and Distributed Route Selection for Payment Channel
  Networks</dc:title>
 <dc:creator>Rohrer, Elias</dc:creator>
 <dc:creator>La&#xdf;, Jann-Frederik</dc:creator>
 <dc:creator>Tschorsch, Florian</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Payment channel networks use off-chain transactions to provide virtually
arbitrary transaction rates. In this paper, we provide a new perspective on
payment channels and consider them as a flow network. We propose an extended
push-relabel algorithm to find payment flows in a payment channel network. Our
algorithm enables a distributed and concurrent execution without violating
capacity constraints. To this end, we introduce the concept of capacity
locking. We prove that flows are valid and present first results.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02419</dc:identifier>
 <dc:identifier>ESORICS 2017, DPM 2017, CBT 2017. Lecture Notes in Computer
  Science, vol 10436</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-67816-0_23</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02420</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining fine-grained opinions on closed captions of YouTube videos with
  an attention-RNN</dc:title>
 <dc:creator>Marrese-Taylor, Edison</dc:creator>
 <dc:creator>Balazs, Jorge A.</dc:creator>
 <dc:creator>Matsuo, Yutaka</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Video reviews are the natural evolution of written product reviews. In this
paper we target this phenomenon and introduce the first dataset created from
closed captions of YouTube product review videos as well as a new attention-RNN
model for aspect extraction and joint aspect extraction and sentiment
classification. Our model provides state-of-the-art performance on aspect
extraction without requiring the usage of hand-crafted features on the SemEval
ABSA corpus, while it outperforms the baseline on the joint task. In our
dataset, the attention-RNN model outperforms the baseline for both tasks, but
we observe important performance drops for all models in comparison to SemEval.
These results, as well as further experiments on domain adaptation for aspect
extraction, suggest that differences between speech and written text, which
have been discussed extensively in the literature, also extend to the domain of
product reviews, where they are relevant for fine-grained opinion mining.
</dc:description>
 <dc:description>Comment: 8th Workshop on Computational Approaches to Subjectivity, Sentiment &amp;
  Social Media Analysis (WASSA)</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02421</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FoveaNet: Perspective-aware Urban Scene Parsing</dc:title>
 <dc:creator>Li, Xin</dc:creator>
 <dc:creator>Jie, Zequn</dc:creator>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:creator>Liu, Changsong</dc:creator>
 <dc:creator>Yang, Jimei</dc:creator>
 <dc:creator>Shen, Xiaohui</dc:creator>
 <dc:creator>Lin, Zhe</dc:creator>
 <dc:creator>Chen, Qiang</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Parsing urban scene images benefits many applications, especially
self-driving. Most of the current solutions employ generic image parsing models
that treat all scales and locations in the images equally and do not consider
the geometry property of car-captured urban scene images. Thus, they suffer
from heterogeneous object scales caused by perspective projection of cameras on
actual scenes and inevitably encounter parsing failures on distant objects as
well as other boundary and recognition errors. In this work, we propose a new
FoveaNet model to fully exploit the perspective geometry of scene images and
address the common failures of generic parsing models. FoveaNet estimates the
perspective geometry of a scene image through a convolutional network which
integrates supportive evidence from contextual objects within the image. Based
on the perspective geometry information, FoveaNet &quot;undoes&quot; the camera
perspective projection analyzing regions in the space of the actual scene, and
thus provides much more reliable parsing results. Furthermore, to effectively
address the recognition errors, FoveaNet introduces a new dense CRFs model that
takes the perspective geometry as a prior potential. We evaluate FoveaNet on
two urban scene parsing datasets, Cityspaces and CamVid, which demonstrates
that FoveaNet can outperform all the well-established baselines and provide new
state-of-the-art performance.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02439</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prune the Convolutional Neural Networks with Sparse Shrink</dc:title>
 <dc:creator>Li, Xin</dc:creator>
 <dc:creator>Liu, Changsong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Nowadays, it is still difficult to adapt Convolutional Neural Network (CNN)
based models for deployment on embedded devices. The heavy computation and
large memory footprint of CNN models become the main burden in real
application. In this paper, we propose a &quot;Sparse Shrink&quot; algorithm to prune an
existing CNN model. By analyzing the importance of each channel via sparse
reconstruction, the algorithm is able to prune redundant feature maps
accordingly. The resulting pruned model thus directly saves computational
resource. We have evaluated our algorithm on CIFAR-100. As shown in our
experiments, we can reduce 56.77% parameters and 73.84% multiplication in total
with only minor decrease in accuracy. These results have demonstrated the
effectiveness of our &quot;Sparse Shrink&quot; algorithm.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02443</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Effective Feature Selection Method Based on Pair-Wise Feature
  Proximity for High Dimensional Low Sample Size Data</dc:title>
 <dc:creator>Happy, S L</dc:creator>
 <dc:creator>Mohanty, Ramanarayan</dc:creator>
 <dc:creator>Routray, Aurobinda</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Feature selection has been studied widely in the literature. However, the
efficacy of the selection criteria for low sample size applications is
neglected in most cases. Most of the existing feature selection criteria are
based on the sample similarity. However, the distance measures become
insignificant for high dimensional low sample size (HDLSS) data. Moreover, the
variance of a feature with a few samples is pointless unless it represents the
data distribution efficiently. Instead of looking at the samples in groups, we
evaluate their efficiency based on pairwise fashion. In our investigation, we
noticed that considering a pair of samples at a time and selecting the features
that bring them closer or put them far away is a better choice for feature
selection. Experimental results on benchmark data sets demonstrate the
effectiveness of the proposed method with low sample size, which outperforms
many other state-of-the-art feature selection methods.
</dc:description>
 <dc:description>Comment: European Signal Processing Conference 2017</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02444</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scheduling and Power Control for V2V Broadcast Communications with
  Adjacent Channel Interference</dc:title>
 <dc:creator>Hisham, Anver</dc:creator>
 <dc:creator>Str&#xf6;m, Erik G.</dc:creator>
 <dc:creator>Br&#xe4;nnstr&#xf6;m, Fredrik</dc:creator>
 <dc:creator>Yan, Li</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates how to mitigate the impact of adjacent channel
interference (ACI) on vehicle-to-vehicle (V2V) broadcast communication by
scheduling and power control. The optimal joint scheduling and power control
problem, with the objective to maximize the number of connected vehicles, is
formulated as a mixed integer programming problem with a linear objective and a
quadratic constraint. From the joint formulation, we derive (a) the optimal
scheduling problem for fixed transmit powers as a Boolean linear programming
problem and (b) the optimal power control problem for a fixed schedule as a
mixed integer linear programming problem. Near-optimal schedules and power
values can, for smaller instances of the problem, be computed by solving first
(a) and then (b). To handle larger instances of the problem, we propose
heuristic scheduling and power control algorithms with reduced computational
complexity. Simulation results indicate that the heuristic scheduling algorithm
yields significant performance improvements compared to the baseline
block-interleaver scheduler and that performance is further improved by the
heuristic power control algorithm. Moreover, the heuristic algorithms perform
close to the near-optimal scheme for small instances of the problem.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02455</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Low-Rank Bayesian Matrix Completion with Hierarchical Gaussian
  Prior Models</dc:title>
 <dc:creator>Yang, Linxiao</dc:creator>
 <dc:creator>Fang, Jun</dc:creator>
 <dc:creator>Duan, Huiping</dc:creator>
 <dc:creator>Li, Hongbin</dc:creator>
 <dc:creator>Zeng, Bing</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The problem of low rank matrix completion is considered in this paper. To
exploit the underlying low-rank structure of the data matrix, we propose a
hierarchical Gaussian prior model, where columns of the low-rank matrix are
assumed to follow a Gaussian distribution with zero mean and a common precision
matrix, and a Wishart distribution is specified as a hyperprior over the
precision matrix. We show that such a hierarchical Gaussian prior has the
potential to encourage a low-rank solution. Based on the proposed hierarchical
prior model, a variational Bayesian method is developed for matrix completion,
where the generalized approximate massage passing (GAMP) technique is embedded
into the variational Bayesian inference in order to circumvent cumbersome
matrix inverse operations. Simulation results show that our proposed method
demonstrates superiority over existing state-of-the-art matrix completion
methods.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02459</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly Supervised Image Annotation and Segmentation with Objects and
  Attributes</dc:title>
 <dc:creator>Shi, Zhiyuan</dc:creator>
 <dc:creator>Yang, Yongxin</dc:creator>
 <dc:creator>Hospedales, Timothy M.</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose to model complex visual scenes using a non-parametric Bayesian
model learned from weakly labelled images abundant on media sharing sites such
as Flickr. Given weak image-level annotations of objects and attributes without
locations or associations between them, our model aims to learn the appearance
of object and attribute classes as well as their association on each object
instance. Once learned, given an image, our model can be deployed to tackle a
number of vision problems in a joint and coherent manner, including recognising
objects in the scene (automatic object annotation), describing objects using
their attributes (attribute prediction and association), and localising and
delineating the objects (object detection and semantic segmentation). This is
achieved by developing a novel Weakly Supervised Markov Random Field Stacked
Indian Buffet Process (WS-MRF-SIBP) that models objects and attributes as
latent factors and explicitly captures their correlations within and across
superpixels. Extensive experiments on benchmark datasets demonstrate that our
weakly supervised model significantly outperforms weakly supervised
alternatives and is often comparable with existing strongly supervised models
on a variety of tasks including semantic segmentation, automatic image
annotation and retrieval based on object-attribute associations.
</dc:description>
 <dc:description>Comment: Accepted in IEEE Transaction on Pattern Analysis and Machine
  Intelligence</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02469</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiscale Strategies for Computing Optimal Transport</dc:title>
 <dc:creator>Gerber, Samuel</dc:creator>
 <dc:creator>Maggioni, Mauro</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents a multiscale approach to efficiently compute approximate
optimal transport plans between point sets. It is particularly well-suited for
point sets that are in high-dimensions, but are close to being intrinsically
low-dimensional. The approach is based on an adaptive multiscale decomposition
of the point sets. The multiscale decomposition yields a sequence of optimal
transport problems, that are solved in a top-to-bottom fashion from the
coarsest to the finest scale. We provide numerical evidence that this
multiscale approach scales approximately linearly, in time and memory, in the
number of nodes, instead of quadratically or worse for a direct solution.
Empirically, the multiscale approach results in less than one percent relative
error in the objective function. Furthermore, the multiscale plans constructed
are of interest by themselves as they may be used to introduce novel features
and notions of distances between point sets. An analysis of sets of brain MRI
based on optimal transport distances illustrates the effectiveness of the
proposed method on a real world data set. The application demonstrates that
multiscale optimal transport distances have the potential to improve on
state-of-the-art metrics currently used in computational anatomy.
</dc:description>
 <dc:description>Comment: Accepted to JMLR</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02472</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible Multiple Base Station Association and Activation for Downlink
  Heterogeneous Networks</dc:title>
 <dc:creator>Shen, Kaiming</dc:creator>
 <dc:creator>Liu, Ya-Feng</dc:creator>
 <dc:creator>Ding, David Yiwei</dc:creator>
 <dc:creator>Yu, Wei</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter shows that the flexible association of possibly multiple base
stations (BSs) to each user over multiple frequency bands, along with the joint
optimization of BS transmit power that encourages the turning-off of the BSs at
off-peak time, can significantly improve the performance of a downlink
heterogeneous wireless cellular network. We propose a gradient projection
algorithm for optimizing BS association and an iteratively reweighting scheme
together with a novel proximal gradient method for optimizing power in order to
find the optimal tradeoff between network utility and power consumption.
Simulation results reveal significant performance improvement as compared to
the conventional single-BS association.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02472</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2017.2738027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02476</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Unsupervised Game-Theoretic Approach to Saliency Detection</dc:title>
 <dc:creator>Zeng, Yu</dc:creator>
 <dc:creator>Lu, Huchuan</dc:creator>
 <dc:creator>Borji, Ali</dc:creator>
 <dc:creator>Feng, Mengyang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel unsupervised game-theoretic salient object detection
algorithm that does not require labeled training data. First, saliency
detection problem is formulated as a non-cooperative game, hereinafter referred
to as Saliency Game, in which image regions are players who choose to be
&quot;background&quot; or &quot;foreground&quot; as their pure strategies. A payoff function is
constructed by exploiting multiple cues and combining complementary features.
Saliency maps are generated according to each region's strategy in the Nash
equilibrium of the proposed Saliency Game. Second, we explore the complementary
relationship between color and deep features and propose an Iterative Random
Walk algorithm to combine saliency maps produced by the Saliency Game using
different features. Iterative random walk allows sharing information across
feature spaces, and detecting objects that are otherwise very hard to detect.
Extensive experiments over 6 challenging datasets demonstrate the superiority
of our proposed unsupervised algorithm compared to several state of the art
supervised algorithms.
</dc:description>
 <dc:description>Comment: This paper has been submitted to IEEE Transactions on Image
  Processing</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02478</identifier>
 <datestamp>2017-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Deterministic to Generative: Multi-Modal Stochastic RNNs for Video
  Captioning</dc:title>
 <dc:creator>Song, Jingkuan</dc:creator>
 <dc:creator>Guo, Yuyu</dc:creator>
 <dc:creator>Gao, Lianli</dc:creator>
 <dc:creator>Li, Xuelong</dc:creator>
 <dc:creator>Hanjalic, Alan</dc:creator>
 <dc:creator>Shen, Heng Tao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Video captioning in essential is a complex natural process, which is affected
by various uncertainties stemming from video content, subjective judgment, etc.
In this paper we build on the recent progress in using encoder-decoder
framework for video captioning and address what we find to be a critical
deficiency of the existing methods, that most of the decoders propagate
deterministic hidden states. Such complex uncertainty cannot be modeled
efficiently by the deterministic models. In this paper, we propose a generative
approach, referred to as multi-modal stochastic RNNs networks (MS-RNN), which
models the uncertainty observed in the data using latent stochastic variables.
Therefore, MS-RNN can improve the performance of video captioning, and generate
multiple sentences to describe a video considering different random factors.
Specifically, a multi-modal LSTM (M-LSTM) is first proposed to interact with
both visual and textual features to capture a high-level representation. Then,
a backward stochastic LSTM (S-LSTM) is proposed to support uncertainty
propagation by introducing latent variables. Experimental results on the
challenging datasets MSVD and MSR-VTT show that our proposed MS-RNN approach
outperforms the state-of-the-art video captioning benchmarks.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-10-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02484</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of Mobility-on-Demand on Traffic Congestion: Simulation-based
  Study</dc:title>
 <dc:creator>Fiedler, David</dc:creator>
 <dc:creator>&#x10c;&#xe1;p, Michal</dc:creator>
 <dc:creator>&#x10c;ertick&#xfd;, Michal</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The increasing use of private vehicles for transportation in cities results
in a growing demand for parking space and road network capacity. In many
densely populated urban areas, however, the capacity of existing infrastructure
is insufficient and extremely difficult to expand. Mobility-on-demand systems
have been proposed as a remedy to the problem of limited parking space because
they are able to satisfy the existing transportation demand with fewer shared
vehicles and consequently require less parking space. Yet, the impact of
large-scale vehicle sharing on traffic patterns is not well understood. In this
work, we perform a simulation-based analysis of consequences of a hypothetical
deployment of a large-scale station-based mobility-on-demand system in Prague
and measure the traffic intensity generated by the system and its effects on
the formation of congestion. We find that such a mobility-on-demand system
would lead to significantly increased total driven distance and it would also
increase levels of congestion due to extra trips without passengers. In fact,
38% kilometers traveled in such an MoD system would be driven empty.
</dc:description>
 <dc:description>Comment: accepted for ITSC 2017</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02497</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning non-parametric Markov networks with mutual information</dc:title>
 <dc:creator>Lepp&#xe4;-aho, Janne</dc:creator>
 <dc:creator>R&#xe4;is&#xe4;nen, Santeri</dc:creator>
 <dc:creator>Yang, Xiao</dc:creator>
 <dc:creator>Roos, Teemu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a method for learning Markov network structures for continuous
data without invoking any assumptions about the distribution of the variables.
The method makes use of previous work on a non-parametric estimator for mutual
information which is used to create a non-parametric test for multivariate
conditional independence. This independence test is then combined with an
efficient constraint-based algorithm for learning the graph structure. The
performance of the method is evaluated on several synthetic data sets and it is
shown to learn considerably more accurate structures than competing methods
when the dependencies between the variables involve non-linearities.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02501</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Covert Communication with Channel-State Information at the Transmitter</dc:title>
 <dc:creator>Lee, Si-Hyeon</dc:creator>
 <dc:creator>Wang, Ligong</dc:creator>
 <dc:creator>Khisti, Ashish</dc:creator>
 <dc:creator>Wornell, Gregory W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of covert communication over a state-dependent
channel, where the transmitter has causal or noncausal knowledge of the channel
states. Here, &quot;covert&quot; means that a warden on the channel should observe
similar statistics when the transmitter is sending a message and when it is
not. When a sufficiently long secret key is shared between the transmitter and
the receiver, we derive closed-form formulas for the maximum achievable covert
communication rate (&quot;covert capacity&quot;) for discrete memoryless channels and,
when the transmitter's channel-state information (CSI) is noncausal, for
additive white Gaussian noise (AWGN) channels. For certain channel models,
including the AWGN channel, we show that the covert capacity is positive with
CSI at the transmitter, but is zero without CSI. We also derive lower bounds on
the rate of the secret key that is needed for the transmitter and the receiver
to achieve the covert capacity.
</dc:description>
 <dc:description>Comment: 20 pages, 3 figures, a shorter version presented at IEEE ISIT 2017,
  submitted to IEEE Transactions on Information Forensics and Security</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02511</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parametric Adversarial Divergences are Good Task Losses for Generative
  Modeling</dc:title>
 <dc:creator>Huang, Gabriel</dc:creator>
 <dc:creator>Berard, Hugo</dc:creator>
 <dc:creator>Touati, Ahmed</dc:creator>
 <dc:creator>Gidel, Gauthier</dc:creator>
 <dc:creator>Vincent, Pascal</dc:creator>
 <dc:creator>Lacoste-Julien, Simon</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Generative modeling of high dimensional data like images is a notoriously
difficult and ill-defined problem. In particular, how to evaluate a learned
generative model is unclear. In this paper, we argue that *adversarial
learning*, pioneered with generative adversarial networks (GANs), provides an
interesting framework to implicitly define more meaningful task losses for
unsupervised tasks, such as for generating &quot;visually realistic&quot; images. By
relating GANs and structured prediction under the framework of statistical
decision theory, we put into light links between recent advances in structured
prediction theory and the choice of the divergence in GANs. We argue that the
insights about the notions of &quot;hard&quot; and &quot;easy&quot; to learn losses can be
analogously extended to adversarial divergences. We also discuss the attractive
properties of parametric adversarial divergences for generative modeling, and
perform experiments to show the importance of choosing a divergence that
reflects the final task.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02512</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On-Stack Replacement \`a la Carte</dc:title>
 <dc:creator>D'Elia, Daniele Cono</dc:creator>
 <dc:creator>Demetrescu, Camil</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  On-stack replacement (OSR) dynamically transfers execution between different
code versions. This mechanism is used in mainstream runtime systems to support
adaptive and speculative optimizations by running code tailored to provide the
best expected performance for the actual workload. Current approaches either
restrict the program points where OSR can be fired or require complex
optimization-specific operations to realign the program's state during a
transition. The engineering effort to implement OSR and the lack of
abstractions make it rarely accessible to the research community, leaving
fundamental question regarding its flexibility largely unexplored.
  In this article we make a first step towards a provably sound abstract
framework for OSR. We show that compiler optimizations can be made OSR-aware in
isolation, and then safely composed. We identify a class of transformations,
which we call live-variable equivalent (LVE), that captures a natural property
of fundamental compiler optimizations, and devise an algorithm to automatically
generate the OSR machinery required for an LVE transition at arbitrary program
locations.
  We present an implementation of our ideas in LLVM and evaluate it against
prominent benchmarks, showing that bidirectional OSR transitions are possible
almost everywhere in the code in the presence of common, unhindered global
optimizations. We then discuss the end-to-end utility of our techniques in
source-level debugging of optimized code, showing how our algorithms can
provide novel building blocks for debuggers for both executables and managed
runtimes.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02518</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model Predictive Control Based Trajectory Generation for Autonomous
  Vehicles - An Architectural Approach</dc:title>
 <dc:creator>Nolte, Marcus</dc:creator>
 <dc:creator>Rose, Marcel</dc:creator>
 <dc:creator>Stolte, Torben</dc:creator>
 <dc:creator>Maurer, Markus</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Research in the field of automated driving has created promising results in
the last years. Some research groups have shown perception systems which are
able to capture even complicated urban scenarios in great detail. Yet, what is
often missing are general-purpose path- or trajectory planners which are not
designed for a specific purpose. In this paper we look at path- and trajectory
planning from an architectural point of view and show how model predictive
frameworks can contribute to generalized path- and trajectory generation
approaches for generating safe trajectories even in cases of system failures.
</dc:description>
 <dc:description>Comment: Presented at IEEE Intelligent Vehicles Symposium 2017, Los Angeles,
  CA, USA</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02518</dc:identifier>
 <dc:identifier>doi:10.1109/IVS.2017.7995814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02524</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Critical threshold for ancestral reconstruction by maximum parsimony on
  general phylogenies</dc:title>
 <dc:creator>Roch, Sebastien</dc:creator>
 <dc:creator>Wang, Kun-Chieh</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  We consider the problem of inferring an ancestral state from observations at
the leaves of a tree, assuming the state evolves along the tree according to a
two-state symmetric Markov process. We establish a general branching rate
condition under which maximum parsimony, a common reconstruction method
requiring only the knowledge of the tree, succeeds better than random guessing
uniformly in the depth of the tree. We thereby generalize previous results of
(Zhang et al., 2010) and (Gascuel and Steel, 2010). Our results apply to both
deterministic and i.i.d. edge weights.
</dc:description>
 <dc:description>Comment: Submitted</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02531</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Binaries: Encoding Semantic-Rich Cues for Efficient Textual-Visual
  Cross Retrieval</dc:title>
 <dc:creator>Shen, Yuming</dc:creator>
 <dc:creator>Liu, Li</dc:creator>
 <dc:creator>Shao, Ling</dc:creator>
 <dc:creator>Song, Jingkuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Cross-modal hashing is usually regarded as an effective technique for
large-scale textual-visual cross retrieval, where data from different
modalities are mapped into a shared Hamming space for matching. Most of the
traditional textual-visual binary encoding methods only consider holistic image
representations and fail to model descriptive sentences. This renders existing
methods inappropriate to handle the rich semantics of informative cross-modal
data for quality textual-visual search tasks. To address the problem of hashing
cross-modal data with semantic-rich cues, in this paper, a novel integrated
deep architecture is developed to effectively encode the detailed semantics of
informative images and long descriptive sentences, named as Textual-Visual Deep
Binaries (TVDB). In particular, region-based convolutional networks with long
short-term memory units are introduced to fully explore image regional details
while semantic cues of sentences are modeled by a text convolutional network.
Additionally, we propose a stochastic batch-wise training routine, where
high-quality binary codes and deep encoding functions are efficiently optimized
in an alternating manner. Experiments are conducted on three multimedia
datasets, i.e. Microsoft COCO, IAPR TC-12, and INRIA Web Queries, where the
proposed TVDB model significantly outperforms state-of-the-art binary coding
methods in the task of cross-modal retrieval.
</dc:description>
 <dc:description>Comment: Accepted by ICCV 2017 as a conference paper</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02532</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Skill- And Ability-Based Development Process for Self-Aware
  Automated Road Vehicles</dc:title>
 <dc:creator>Nolte, Marcus</dc:creator>
 <dc:creator>Bagschik, Gerrit</dc:creator>
 <dc:creator>Jatzkowski, Inga</dc:creator>
 <dc:creator>Stolte, Torben</dc:creator>
 <dc:creator>Reschka, Andreas</dc:creator>
 <dc:creator>Maurer, Markus</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The development of fully automated vehicles imposes new challenges in the
development process and during the operation of such vehicles. As traditional
design methods are not sufficient to account for the huge variety of scenarios
which will be encountered by (fully) automated vehicles, approaches for
designing safe systems must be extended in order to allow for an ISO~26262
compliant development process. During operation of vehicles implementing SAE
Levels 3+ safe behavior must always be guaranteed, as the human driver is not
or not immediately available as a fall-back. Thus, the vehicle must be aware of
its current performance and remaining abilities at all times. In this paper we
combine insights from two research projects for showing how a skill- and
ability-based approach can provide a basis for the development phase and
operation of self-aware automated road vehicles.
</dc:description>
 <dc:description>Comment: Preprint: Accepted for IEEE Conference on Intelligent Transportation
  Systems 2017, Yokohama, Japan</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02536</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Inferring Causality from Multi-Relational Observational
  Data using Conditional Independence</dc:title>
 <dc:creator>Roy, Sudeepa</dc:creator>
 <dc:creator>Salimi, Babak</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The study of causality or causal inference - how much a given treatment
causally affects a given outcome in a population - goes way beyond correlation
or association analysis of variables, and is critical in making sound data
driven decisions and policies in a multitude of applications. The gold standard
in causal inference is performing &quot;controlled experiments&quot;, which often is not
possible due to logistical or ethical reasons. As an alternative, inferring
causality on &quot;observational data&quot; based on the &quot;Neyman-Rubin potential outcome
model&quot; has been extensively used in statistics, economics, and social sciences
over several decades. In this paper, we present a formal framework for sound
causal analysis on observational datasets that are given as multiple relations
and where the population under study is obtained by joining these base
relations. We study a crucial condition for inferring causality from
observational data, called the &quot;strong ignorability assumption&quot; (the treatment
and outcome variables should be independent in the joined relation given the
observed covariates), using known conditional independences that hold in the
base relations. We also discuss how the structure of the conditional
independences in base relations given as graphical models help infer new
conditional independences in the joined relation. The proposed framework
combines concepts from databases, statistics, and graphical models, and aims to
initiate new research directions spanning these fields to facilitate powerful
data-driven decisions in today's big data world.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02537</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proving Expected Sensitivity of Probabilistic Programs</dc:title>
 <dc:creator>Barthe, Gilles</dc:creator>
 <dc:creator>Espitau, Thomas</dc:creator>
 <dc:creator>Gr&#xe9;goire, Benjamin</dc:creator>
 <dc:creator>Hsu, Justin</dc:creator>
 <dc:creator>Strub, Pierre-Yves</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Program sensitivity, also known as Lipschitz continuity, describes how small
changes in a program's input lead to bounded changes in the output. We propose
an average notion of program sensitivity for probabilistic programs---expected
sensitivity---that averages a distance function over a probabilistic coupling
of two output distributions from two similar inputs. By varying the distance,
expected sensitivity recovers useful notions of probabilistic function
sensitivity, including stability of machine learning algorithms and convergence
of Markov chains.
  Furthermore, expected sensitivity satisfies clean compositional properties
and is amenable to formal verification. We develop a relational program logic
called $\mathbb{E}$pRHL for proving expected sensitivity properties. Our logic
features two key ideas. First, relational pre-conditions and post-conditions
are expressed using distances, a real-valued generalization of typical
boolean-valued (relational) assertions. Second, judgments are interpreted in
terms of expectation coupling, a novel, quantitative generalization of
probabilistic couplings which supports compositional reasoning.
  We demonstrate our logic on examples beyond the reach of prior relational
logics. Our main example formalizes uniform stability of the stochastic
gradient method. Furthermore, we prove rapid mixing for a probabilistic model
of population dynamics. We also extend our logic with a transitivity principle
for expectation couplings to capture the path coupling proof technique by
Bubley and Dyer, and formalize rapid mixing of the Glauber dynamics from
statistical physics.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02537</dc:identifier>
 <dc:identifier>doi:10.1145/3158145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02543</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impossibility of $n-1$-strong-equllibrium for Distributed Consensus with
  Rational Agents</dc:title>
 <dc:creator>Fanani, Amit Jacob</dc:creator>
 <dc:creator>Harel, Itay</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  An algorithm for $n-1$-strong-equillibrium for distributed consensus in a
ring with rational agents was proposed by Afek et al. (2014). A proof of
impossibility of $n-1$-strong-equillibrium for distributed consensus in every
topology with rational agents, when $n$ is even, is presented. Furthermore, we
show that the algorithm proposed by Afek et al. is the only algorithm which can
solve the problem when $n$ is odd. Finally, we prove that the proposed
algorithm provides a $n-2$-strong-equillibrium in a synchronous ring when $n$
is even.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02544</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Optimization with Bandit Sampling</dc:title>
 <dc:creator>Salehi, Farnood</dc:creator>
 <dc:creator>Celis, L. Elisa</dc:creator>
 <dc:creator>Thiran, Patrick</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many stochastic optimization algorithms work by estimating the gradient of
the cost function on the fly by sampling datapoints uniformly at random from a
training set. However, the estimator might have a large variance, which
inadvertently slows down the convergence rate of the algorithms. One way to
reduce this variance is to sample the datapoints from a carefully selected
non-uniform distribution. In this work, we propose a novel non-uniform sampling
approach that uses the multi-armed bandit framework. Theoretically, we show
that our algorithm asymptotically approximates the optimal variance within a
factor of 3. Empirically, we show that using this datapoint-selection technique
results in a significant reduction in the convergence time and variance of
several stochastic optimization algorithms such as SGD, SVRG and SAGA. This
approach for sampling datapoints is general, and can be used in conjunction
with any algorithm that uses an unbiased gradient estimation -- we expect it to
have broad applicability beyond the specific examples explored in this work.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02550</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Scene Understanding for Autonomous Driving</dc:title>
 <dc:creator>Neven, Davy</dc:creator>
 <dc:creator>De Brabandere, Bert</dc:creator>
 <dc:creator>Georgoulis, Stamatios</dc:creator>
 <dc:creator>Proesmans, Marc</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Most approaches for instance-aware semantic labeling traditionally focus on
accuracy. Other aspects like runtime and memory footprint are arguably as
important for real-time applications such as autonomous driving. Motivated by
this observation and inspired by recent works that tackle multiple tasks with a
single integrated architecture, in this paper we present a real-time efficient
implementation based on ENet that solves three autonomous driving related tasks
at once: semantic scene segmentation, instance segmentation and monocular depth
estimation. Our approach builds upon a branched ENet architecture with a shared
encoder but different decoder branches for each of the three tasks. The
presented method can run at 21 fps at a resolution of 1024x512 on the
Cityscapes dataset without sacrificing accuracy compared to running each task
separately.
</dc:description>
 <dc:description>Comment: Published at &quot;Deep Learning for Vehicle Perception&quot;, workshop at the
  IEEE Symposium on Intelligent Vehicles 2017</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02551</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Instance Segmentation with a Discriminative Loss Function</dc:title>
 <dc:creator>De Brabandere, Bert</dc:creator>
 <dc:creator>Neven, Davy</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Semantic instance segmentation remains a challenging task. In this work we
propose to tackle the problem with a discriminative loss function, operating at
the pixel level, that encourages a convolutional network to produce a
representation of the image that can easily be clustered into instances with a
simple post-processing step. The loss function encourages the network to map
each pixel to a point in feature space so that pixels belonging to the same
instance lie close together while different instances are separated by a wide
margin. Our approach of combining an off-the-shelf network with a principled
loss function inspired by a metric learning objective is conceptually simple
and distinct from recent efforts in instance segmentation. In contrast to
previous works, our method does not rely on object proposals or recurrent
mechanisms. A key contribution of our work is to demonstrate that such a simple
setup without bells and whistles is effective and can perform on par with more
complex methods. Moreover, we show that it does not suffer from some of the
limitations of the popular detect-and-segment approaches. We achieve
competitive performance on the Cityscapes and CVPPP leaf segmentation
benchmarks.
</dc:description>
 <dc:description>Comment: Published at &quot;Deep Learning for Robotic Vision&quot;, workshop at CVPR
  2017</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02553</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Computer Algebra, Theorem Proving, and Oracle AI</dc:title>
 <dc:creator>Sarma, Gopal P.</dc:creator>
 <dc:creator>Hay, Nick J.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  In the context of superintelligent AI systems, the term &quot;oracle&quot; has two
meanings. One refers to modular systems queried for domain-specific tasks.
Another usage, referring to a class of systems which may be useful for
addressing the value alignment and AI control problems, is a superintelligent
AI system that only answers questions. The aim of this manuscript is to survey
contemporary research problems related to oracles which align with long-term
research goals of AI safety. We examine existing question answering systems and
argue that their high degree of architectural heterogeneity makes them poor
candidates for rigorous analysis as oracles. On the other hand, we identify
computer algebra systems (CASs) as being primitive examples of domain-specific
oracles for mathematics and argue that efforts to integrate computer algebra
systems with theorem provers, systems which have largely been developed
independent of one another, provide a concrete set of problems related to the
notion of provable safety that has emerged in the AI safety community. We
review approaches to interfacing CASs with theorem provers, describe
well-defined architectural deficiencies that have been identified with CASs,
and suggest possible lines of research and practical software projects for
scientists interested in AI safety.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-12-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02553</dc:identifier>
 <dc:identifier>Informatica Vol. 41 No. 3 (2017)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02556</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Generator Generative Adversarial Nets</dc:title>
 <dc:creator>Hoang, Quan</dc:creator>
 <dc:creator>Nguyen, Tu Dinh</dc:creator>
 <dc:creator>Le, Trung</dc:creator>
 <dc:creator>Phung, Dinh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new approach to train the Generative Adversarial Nets (GANs)
with a mixture of generators to overcome the mode collapsing problem. The main
intuition is to employ multiple generators, instead of using a single one as in
the original GAN. The idea is simple, yet proven to be extremely effective at
covering diverse data modes, easily overcoming the mode collapse and delivering
state-of-the-art results. A minimax formulation is able to establish among a
classifier, a discriminator, and a set of generators in a similar spirit with
GAN. Generators create samples that are intended to come from the same
distribution as the training data, whilst the discriminator determines whether
samples are true data or generated by generators, and the classifier specifies
which generator a sample comes from. The distinguishing feature is that
internal samples are created from multiple generators, and then one of them
will be randomly selected as final output similar to the mechanism of a
probabilistic mixture model. We term our method Mixture GAN (MGAN). We develop
theoretical analysis to prove that, at the equilibrium, the Jensen-Shannon
divergence (JSD) between the mixture of generators' distributions and the
empirical data distribution is minimal, whilst the JSD among generators'
distributions is maximal, hence effectively avoiding the mode collapse. By
utilizing parameter sharing, our proposed model adds minimal computational cost
to the standard GAN, and thus can also efficiently scale to large-scale
datasets. We conduct extensive experiments on synthetic 2D data and natural
image databases (CIFAR-10, STL-10 and ImageNet) to demonstrate the superior
performance of our MGAN in achieving state-of-the-art Inception scores over
latest baselines, generating diverse and appealing recognizable objects at
different resolutions, and specializing in capturing different types of objects
by generators.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02556</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02557</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overview of Millimeter Wave Communications for Fifth-Generation (5G)
  Wireless Networks-with a focus on Propagation Models</dc:title>
 <dc:creator>Rappaport, Theodore S.</dc:creator>
 <dc:creator>Xing, Yunchou</dc:creator>
 <dc:creator>MacCartney, Jr., George R.</dc:creator>
 <dc:creator>Molisch, Andreas F.</dc:creator>
 <dc:creator>Mellios, Evangelos</dc:creator>
 <dc:creator>Zhang, Jianhua</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper provides an overview of the features of fifth generation (5G)
wireless communication systems now being developed for use in the millimeter
wave (mmWave) frequency bands. Early results and key concepts of 5G networks
are presented, and the channel modeling efforts of many international groups
for both licensed and unlicensed applications are described here. Propagation
parameters and channel models for understanding mmWave propagation, such as
line-of-sight (LOS) probabilities, large-scale path loss, and building
penetration loss, as modeled by various standardization bodies, are compared
over the 0.5-100 GHz range.
</dc:description>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02561</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural-based Context Representation Learning for Dialog Act
  Classification</dc:title>
 <dc:creator>Ortega, Daniel</dc:creator>
 <dc:creator>Vu, Ngoc Thang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We explore context representation learning methods in neural-based models for
dialog act classification. We propose and compare extensively different methods
which combine recurrent neural network architectures and attention mechanisms
(AMs) at different context levels. Our experimental results on two benchmark
datasets show consistent improvements compared to the models without contextual
information and reveal that the most suitable AM in the architecture depends on
the nature of the dataset.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, SIGDIAL 2017</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02562</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Low Latency Towards 5G: RAN, Core Network and Caching
  Solutions</dc:title>
 <dc:creator>Parvez, Imtiaz</dc:creator>
 <dc:creator>Rahmati, Ali</dc:creator>
 <dc:creator>Guvenc, Ismail</dc:creator>
 <dc:creator>Sarwat, Arif I.</dc:creator>
 <dc:creator>Dai, Huaiyu</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The fifth generation (5G) wireless network technology is to be standardized
by 2020, where main goals are to improve capacity, reliability, and energy
efficiency, while reducing latency and massively increasing connection density.
An integral part of 5G is the capability to transmit touch perception type
real-time communication empowered by applicable robotics and haptics equipment
at the network edge. In this regard, we need drastic changes in network
architecture including core and radio access network (RAN) for achieving
end-to-end latency on the order of 1 ms. In this paper, we present a detailed
survey on the emerging technologies to achieve low latency communications
considering three different solution domains: RAN, core network, and caching.
We also present a general overview of 5G cellular networks composed of software
defined network (SDN), network function virtualization (NFV), caching, and
mobile edge computing (MEC) capable of meeting latency and other 5G
requirements.
</dc:description>
 <dc:description>Comment: Submitted in IEEE Communications Surveys and Tutorials</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02574</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TPA: Fast, Scalable, and Accurate Method for Approximate Random Walk
  with Restart on Billion Scale Graphs</dc:title>
 <dc:creator>Yoon, Minji</dc:creator>
 <dc:creator>Jung, Jinhong</dc:creator>
 <dc:creator>Kang, U</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>68W25</dc:subject>
 <dc:description>  Given a large graph, how can we determine similarity between nodes in a fast
and accurate way? Random walk with restart (RWR) is a popular measure for this
purpose and has been exploited in numerous data mining applications including
ranking, anomaly detection, link prediction, and community detection. However,
previous methods for computing exact RWR require prohibitive storage sizes and
computational costs, and alternative methods which avoid such costs by
computing approximate RWR have limited accuracy. In this paper, we propose TPA,
a fast, scalable, and highly accurate method for computing approximate RWR on
large graphs. TPA exploits two important properties in RWR: 1) nodes close to a
seed node are likely to be revisited in following steps due to block-wise
structure of many real-world graphs, and 2) RWR scores of nodes which reside
far from the seed node are proportional to their PageRank scores. Based on
these two properties, TPA divides approximate RWR problem into two subproblems
called neighbor approximation and stranger approximation. In the neighbor
approximation, TPA estimates RWR scores of nodes close to the seed based on
scores of few early steps from the seed. In the stranger approximation, TPA
estimates RWR scores for nodes far from the seed using their PageRank. The
stranger and neighbor approximations are conducted in the preprocessing phase
and the online phase, respectively. Through extensive experiments, we show that
TPA requires up to 3.5x less time with up to 40x less memory space than other
state-of-the-art methods for the preprocessing phase. In the online phase, TPA
computes approximate RWR up to 30x faster than existing methods while
maintaining high accuracy.
</dc:description>
 <dc:description>Comment: 12pages, 10 figures</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02579</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Snowflake: A Model Agnostic Accelerator for Deep Convolutional Neural
  Networks</dc:title>
 <dc:creator>Gokhale, Vinayak</dc:creator>
 <dc:creator>Zaidy, Aliasger</dc:creator>
 <dc:creator>Chang, Andre Xian Ming</dc:creator>
 <dc:creator>Culurciello, Eugenio</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Deep convolutional neural networks (CNNs) are the deep learning model of
choice for performing object detection, classification, semantic segmentation
and natural language processing tasks. CNNs require billions of operations to
process a frame. This computational complexity, combined with the inherent
parallelism of the convolution operation make CNNs an excellent target for
custom accelerators. However, when optimizing for different CNN hierarchies and
data access patterns, it is difficult for custom accelerators to achieve close
to 100% computational efficiency. In this work, we present Snowflake, a
scalable and efficient accelerator that is agnostic to CNN workloads, and was
designed to always perform at near-peak hardware utilization. Snowflake is able
to achieve a computational efficiency of over 91% on modern CNN models.
Snowflake, implemented on a Xilinx Zynq XC7Z045 SoC is capable of achieving a
peak throughput of 128G-ops/s and a measured throughput of 100 frames per
second and 120 G-ops/s on the AlexNet CNN model, 36 frames per second and 116G-
ops/s on the GoogLeNet CNN model and 17 frames per second and 122 G-ops/s on
the ResNet-50 CNN model. To the best of our knowledge, Snowflake is the only
implemented system capable of achieving over 91% efficiency on modern CNNs and
the only implemented system with GoogLeNet and ResNet as part of the benchmark
suite.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02579</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02581</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Belief Propagation, Bethe Approximation and Polynomials</dc:title>
 <dc:creator>Straszak, Damian</dc:creator>
 <dc:creator>Vishnoi, Nisheeth K.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Factor graphs are important models for succinctly representing probability
distributions in machine learning, coding theory, and statistical physics.
Several computational problems, such as computing marginals and partition
functions, arise naturally when working with factor graphs. Belief propagation
is a widely deployed iterative method for solving these problems. However,
despite its significant empirical success, not much is known about the
correctness and efficiency of belief propagation.
  Bethe approximation is an optimization-based framework for approximating
partition functions. While it is known that the stationary points of the Bethe
approximation coincide with the fixed points of belief propagation, in general,
the relation between the Bethe approximation and the partition function is not
well understood. It has been observed that for a few classes of factor graphs,
the Bethe approximation always gives a lower bound to the partition function,
which distinguishes them from the general case, where neither a lower bound,
nor an upper bound holds universally. This has been rigorously proved for
permanents and for attractive graphical models.
  Here we consider bipartite normal factor graphs and show that if the local
constraints satisfy a certain analytic property, the Bethe approximation is a
lower bound to the partition function. We arrive at this result by viewing
factor graphs through the lens of polynomials. In this process, we reformulate
the Bethe approximation as a polynomial optimization problem. Our sufficient
condition for the lower bound property to hold is inspired by recent
developments in the theory of real stable polynomials. We believe that this way
of viewing factor graphs and its connection to real stability might lead to a
better understanding of belief propagation and factor graphs in general.
</dc:description>
 <dc:description>Comment: Invited to Allerton 2017</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02582</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cascade Adversarial Machine Learning Regularized with a Unified
  Embedding</dc:title>
 <dc:creator>Na, Taesik</dc:creator>
 <dc:creator>Ko, Jong Hwan</dc:creator>
 <dc:creator>Mukhopadhyay, Saibal</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural network classifiers are vulnerable to small input perturbations
carefully generated by the adversaries. Injecting adversarial inputs during
training, known as adversarial training, can improve robustness against
one-step attacks, but not for unknown iterative attacks. To address this
challenge, we propose to utilize embedding space for both classification and
low-level (pixel-level) similarity learning to ignore unknown pixel level
perturbation. During training, we inject adversarial images without replacing
their corresponding clean images and penalize the distance between the two
embeddings (clean and adversarial). This additional regularization encourages
two similar images (clean and perturbed versions) to produce the same outputs,
not necessarily the true labels, enhancing classifier's robustness against
pixel level perturbation. Next, we show iteratively generated adversarial
images easily transfer between networks trained with the same strategy.
Inspired by this observation, we also propose cascade adversarial training,
which transfers the knowledge of the end results of adversarial training. We
train a network from scratch by injecting iteratively generated adversarial
images crafted from already defended networks in addition to one-step
adversarial images from the network being trained. Experimental results show
that cascade adversarial training together with our proposed low-level
similarity learning efficiently enhance the robustness against iterative
attacks, but at the expense of decreased robustness against one-step attacks.
We show that combining those two techniques can also improve robustness under
the worst case black box attack scenario.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02582</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02596</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Network Dynamics for Model-Based Deep Reinforcement Learning with
  Model-Free Fine-Tuning</dc:title>
 <dc:creator>Nagabandi, Anusha</dc:creator>
 <dc:creator>Kahn, Gregory</dc:creator>
 <dc:creator>Fearing, Ronald S.</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Model-free deep reinforcement learning algorithms have been shown to be
capable of learning a wide range of robotic skills, but typically require a
very large number of samples to achieve good performance. Model-based
algorithms, in principle, can provide for much more efficient learning, but
have proven difficult to extend to expressive, high-capacity models such as
deep neural networks. In this work, we demonstrate that medium-sized neural
network models can in fact be combined with model predictive control (MPC) to
achieve excellent sample complexity in a model-based reinforcement learning
algorithm, producing stable and plausible gaits to accomplish various complex
locomotion tasks. We also propose using deep neural network dynamics models to
initialize a model-free learner, in order to combine the sample efficiency of
model-based approaches with the high task-specific performance of model-free
methods. We empirically demonstrate on MuJoCo locomotion tasks that our pure
model-based approach trained on just random action data can follow arbitrary
trajectories with excellent sample efficiency, and that our hybrid algorithm
can accelerate model-free learning on high-speed benchmark tasks, achieving
sample efficiency gains of 3-5x on swimmer, cheetah, hopper, and ant agents.
Videos can be found at https://sites.google.com/view/mbmf
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02597</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtualized 5G Air Interface Protocol Stack for Multi-Cell Coordination</dc:title>
 <dc:creator>Carrasco, &#xd3;scar</dc:creator>
 <dc:creator>D&#xed;az, Salva</dc:creator>
 <dc:creator>Calabug, Jordi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This article proposes a novel virtualized air interface protocol stack for
next-generation wireless networks, that natively supports multiple radio access
technologies and multi-point transmissions. Leveraging upon the concepts of
softwarization of the air interface and virtualization, this design provides
flexibility and scalability towards future advances in the radio access, whilst
at the same time being backwards compatible with legacy technologies. This
proposal enables the aggregation of multiple frequency bands and multiple
technologies, without the need of modifying the operating procedures or the
protocol of each supported technology. In the end, some challenges that have
still to be addressed in future works are provided.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02599</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Error Detection and Correction Framework for Connectomics</dc:title>
 <dc:creator>Zung, Jonathan</dc:creator>
 <dc:creator>Tartavull, Ignacio</dc:creator>
 <dc:creator>Lee, Kisuk</dc:creator>
 <dc:creator>Seung, H. Sebastian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We define and study error detection and correction tasks that are useful for
3D reconstruction of neurons from electron microscopic imagery, and for image
segmentation more generally. Both tasks take as input the raw image and a
binary mask representing a candidate object. For the error detection task, the
desired output is a map of split and merge errors in the object. For the error
correction task, the desired output is the true object. We call this object
mask pruning, because the candidate object mask is assumed to be a superset of
the true object. We train multiscale 3D convolutional networks to perform both
tasks. We find that the error-detecting net can achieve high accuracy. The
accuracy of the error-correcting net is enhanced if its input object mask is
&quot;advice&quot; (union of erroneous objects) from the error-detecting net.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02603</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Feedforward and Recurrent Deterministic Spiking Neuron Network
  Feedback Controllers</dc:title>
 <dc:creator>Kang, Tae Seung</dc:creator>
 <dc:creator>Banerjee, Arunava</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We consider the problem of feedback control when the controller is
constructed solely of deterministic spiking neurons. Although spiking neurons
and networks have been the subject of several previous studies, analysis has
primarily been restricted to a firing rate model. In contrast, we construct a
spike timing based deterministic spiking neuron controller whose control output
is one or multiple sparse spike trains. We model the problem formally as a
hybrid dynamical system comprised of a closed loop between a plant and a
spiking neuron network controller. The construction differs from classical
controllers owing to the fact that the control feedback to the plant is
generated by convolving the spike trains with fixed kernels, resulting in a
highly constrained and stereotyped control signal. We derive a novel synaptic
weight update rule via which the spiking neuron network controller to hold
process variables at desired set points. We demonstrate the efficacy of the
rule by applying it to the classical control problem of the cart-pole (inverted
pendulum). Experiments demonstrate that the proposed controller has a larger
region of stability as compared to the traditional PID controller, and its
trajectories differ qualitatively from those of the PID controller. In
addition, the proposed controller with a recurrent network generates sparse
spike trains with rates as low as 1.99Hz.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02618</identifier>
 <datestamp>2017-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Comparison of Developer Retention in the RubyGems and npm
  Software Ecosystems</dc:title>
 <dc:creator>Constantinou, Eleni</dc:creator>
 <dc:creator>Mens, Tom</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Software ecosystems can be viewed as socio-technical networks consisting of
technical components (software packages) and social components (communities of
developers) that maintain the technical components. Ecosystems evolve over time
through socio-technical changes that may greatly impact the ecosystem's
sustainability. Social changes like developer turnover may lead to technical
degradation. This motivates the need to identify those factors leading to
developer abandonment, in order to automate the process of identifying
developers with high abandonment risk. This paper compares such factors for two
software package ecosystems, RubyGems and npm. We analyse the evolution of
their packages hosted on GitHub, considering development activity in terms of
commits, and social interaction with other developers in terms of comments
associated to commits, issues or pull requests. We analyse this socio-technical
activity for more than 30k and 60k developers for RubyGems and npm
respectively. We use survival analysis to identify which factors coincide with
a lower survival probability. Our results reveal that developers with a higher
probability to abandon an ecosystem: do not engage in discussions with other
developers; do not have strong social and technical activity intensity;
communicate or commit less frequently; and do not participate to both technical
and social activities for long periods of time. Such observations could be used
to automate the identification of developers with a high probability of
abandoning the ecosystem and, as such, reduce the risks associated to knowledge
loss.
</dc:description>
 <dc:description>Comment: This paper is a preprint of a paper that has been accepted for
  publication in the Springer's journal Innovations in Systems and Software
  Engineering</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02618</dc:identifier>
 <dc:identifier>Innovations in Systems and Software Engineering 2017, Volume 13,
  Issue 2-3, pp 101-115</dc:identifier>
 <dc:identifier>doi:10.1007/s1133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02620</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilayer Spectral Graph Clustering via Convex Layer Aggregation:
  Theory and Algorithms</dc:title>
 <dc:creator>Chen, Pin-Yu</dc:creator>
 <dc:creator>Hero, Alfred O.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Multilayer graphs are commonly used for representing different relations
between entities and handling heterogeneous data processing tasks. Non-standard
multilayer graph clustering methods are needed for assigning clusters to a
common multilayer node set and for combining information from each layer. This
paper presents a multilayer spectral graph clustering (SGC) framework that
performs convex layer aggregation. Under a multilayer signal plus noise model,
we provide a phase transition analysis of clustering reliability. Moreover, we
use the phase transition criterion to propose a multilayer iterative model
order selection algorithm (MIMOSA) for multilayer SGC, which features automated
cluster assignment and layer weight adaptation, and provides statistical
clustering reliability guarantees. Numerical simulations on synthetic
multilayer graphs verify the phase transition analysis, and experiments on
real-world multilayer graphs show that MIMOSA is competitive or better than
other clustering methods.
</dc:description>
 <dc:description>Comment: Published at IEEE Transactions on Signal and Information Processing
  over Networks</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02620</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02621</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real Time Analytics: Algorithms and Systems</dc:title>
 <dc:creator>Kejariwal, Arun</dc:creator>
 <dc:creator>Kulkarni, Sanjeev</dc:creator>
 <dc:creator>Ramasamy, Karthik</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Velocity is one of the 4 Vs commonly used to characterize Big Data. In this
regard, Forrester remarked the following in Q3 2014: &quot;The high velocity,
white-water flow of data from innumerable real-time data sources such as market
data, Internet of Things, mobile, sensors, click-stream, and even transactions
remain largely unnavigated by most firms. The opportunity to leverage streaming
analytics has never been greater.&quot; Example use cases of streaming analytics
include, but not limited to: (a) visualization of business metrics in real-time
(b) facilitating highly personalized experiences (c) expediting response during
emergencies. Streaming analytics is extensively used in a wide variety of
domains such as healthcare, e-commerce, financial services, telecommunications,
energy and utilities, manufacturing, government and transportation.
  In this tutorial, we shall present an in-depth overview of streaming
analytics - applications, algorithms and platforms - landscape. We shall walk
through how the field has evolved over the last decade and then discuss the
current challenges - the impact of the other three Vs, viz., Volume, Variety
and Veracity, on Big Data streaming analytics. The tutorial is intended for
both researchers and practitioners in the industry. We shall also present
state-of-the-affairs of streaming analytics at Twitter.
</dc:description>
 <dc:description>Comment: Extended version of VLDB'15 tutorial proposal</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02621</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02622</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kinematic interpretation of the Study quadric's ambient space</dc:title>
 <dc:creator>Nawratil, Georg</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  It is well known that real points of the Study quadric (sliced along a
3-dimensional generator space) correspond to displacements of the Euclidean
3-space. But we still lack of a kinematic meaning for the points of the ambient
7-dimensional projective space $P^7$. This paper gives one possible
interpretation in terms of displacements of the Euclidean 4-space. From this
point of view we also discuss the extended inverse kinematic map, motions
corresponding to straight lines in $P^7$ and linear complexes of
SE(3)-displacements. Moreover we present an application of this interpretation
in the context of interactive motion design.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02629</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Protecting Genomic Privacy by a Sequence-Similarity Based Obfuscation
  Method</dc:title>
 <dc:creator>Wan, Shibiao</dc:creator>
 <dc:creator>Mak, Man-Wai</dc:creator>
 <dc:creator>Kung, Sun-Yuan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In the post-genomic era, large-scale personal DNA sequences are produced and
collected for genetic medical diagnoses and new drug discovery, which, however,
simultaneously poses serious challenges to the protection of personal genomic
privacy. Existing genomic privacy-protection methods are either time-consuming
or with low accuracy. To tackle these problems, this paper proposes a sequence
similarity-based obfuscation method, namely IterMegaBLAST, for fast and
reliable protection of personal genomic privacy. Specifically, given a randomly
selected sequence from a dataset of DNA sequences, we first use MegaBLAST to
find its most similar sequence from the dataset. These two aligned sequences
form a cluster, for which an obfuscated sequence was generated via a DNA
generalization lattice scheme. These procedures are iteratively performed until
all of the sequences in the dataset are clustered and their obfuscated
sequences are generated. Experimental results on two benchmark datasets
demonstrate that under the same degree of anonymity, IterMegaBLAST
significantly outperforms existing state-of-the-art approaches in terms of both
utility accuracy and time complexity.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02635</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anomaly Detection in Multivariate Non-stationary Time Series for
  Automatic DBMS Diagnosis</dc:title>
 <dc:creator>Lee, Doyup</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Anomaly detection in database management systems (DBMSs) is difficult because
of increasing number of statistics (stat) and event metrics in big data system.
In this paper, I propose an automatic DBMS diagnosis system that detects
anomaly periods with abnormal DB stat metrics and finds causal events in the
periods. Reconstruction error from deep autoencoder and statistical process
control approach are applied to detect time period with anomalies. Related
events are found using time series similarity measures between events and
abnormal stat metrics. After training deep autoencoder with DBMS metric data,
efficacy of anomaly detection is investigated from other DBMSs containing
anomalies. Experiment results show effectiveness of proposed model, especially,
batch temporal normalization layer. Proposed model is used for publishing
automatic DBMS diagnosis reports in order to determine DBMS configuration and
SQL tuning.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-10-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02635</dc:identifier>
 <dc:identifier>doi:10.1109/ICMLA.2017.0-126</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02637</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TensorFlow Estimators: Managing Simplicity vs. Flexibility in High-Level
  Machine Learning Frameworks</dc:title>
 <dc:creator>Cheng, Heng-Tze</dc:creator>
 <dc:creator>Haque, Zakaria</dc:creator>
 <dc:creator>Hong, Lichan</dc:creator>
 <dc:creator>Ispir, Mustafa</dc:creator>
 <dc:creator>Mewald, Clemens</dc:creator>
 <dc:creator>Polosukhin, Illia</dc:creator>
 <dc:creator>Roumpos, Georgios</dc:creator>
 <dc:creator>Sculley, D</dc:creator>
 <dc:creator>Smith, Jamie</dc:creator>
 <dc:creator>Soergel, David</dc:creator>
 <dc:creator>Tang, Yuan</dc:creator>
 <dc:creator>Tucker, Philipp</dc:creator>
 <dc:creator>Wicke, Martin</dc:creator>
 <dc:creator>Xia, Cassandra</dc:creator>
 <dc:creator>Xie, Jianwei</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a framework for specifying, training, evaluating, and deploying
machine learning models. Our focus is on simplifying cutting edge machine
learning for practitioners in order to bring such technologies into production.
Recognizing the fast evolution of the field of deep learning, we make no
attempt to capture the design space of all possible model architectures in a
domain- specific language (DSL) or similar configuration language. We allow
users to write code to define their models, but provide abstractions that guide
develop- ers to write models in ways conducive to productionization. We also
provide a unifying Estimator interface, making it possible to write downstream
infrastructure (e.g. distributed training, hyperparameter tuning) independent
of the model implementation. We balance the competing demands for flexibility
and simplicity by offering APIs at different levels of abstraction, making
common model architectures available out of the box, while providing a library
of utilities designed to speed up experimentation with model architectures. To
make out of the box models flexible and usable across a wide range of problems,
these canned Estimators are parameterized not only over traditional
hyperparameters, but also using feature columns, a declarative specification
describing how to interpret input data. We discuss our experience in using this
framework in re- search and production environments, and show the impact on
code health, maintainability, and development speed.
</dc:description>
 <dc:description>Comment: 8 pages, Appeared at KDD 2017, August 13--17, 2017, Halifax, NS,
  Canada</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02637</dc:identifier>
 <dc:identifier>doi:10.1145/3097983.3098171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02638</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed rank-1 dictionary learning: Towards fast and scalable
  solutions for fMRI big data analytics</dc:title>
 <dc:creator>Makkie, Milad</dc:creator>
 <dc:creator>Li, Xiang</dc:creator>
 <dc:creator>Lin, Binbin</dc:creator>
 <dc:creator>Ye, Jieping</dc:creator>
 <dc:creator>Fazli, Mojtaba Sedigh</dc:creator>
 <dc:creator>Liu, Tianming</dc:creator>
 <dc:creator>Quinn, Shannon</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  The use of functional brain imaging for research and diagnosis has benefitted
greatly from the recent advancements in neuroimaging technologies, as well as
the explosive growth in size and availability of fMRI data. While it has been
shown in literature that using multiple and large scale fMRI datasets can
improve reproducibility and lead to new discoveries, the computational and
informatics systems supporting the analysis and visualization of such fMRI big
data are extremely limited and largely under-discussed. We propose to address
these shortcomings in this work, based on previous success in using dictionary
learning method for functional network decomposition studies on fMRI data. We
presented a distributed dictionary learning framework based on rank-1 matrix
decomposition with sparseness constraint (D-r1DL framework). The framework was
implemented using the Spark distributed computing engine and deployed on three
different processing units: an in-house server, in-house high performance
clusters, and the Amazon Elastic Compute Cloud (EC2) service. The whole
analysis pipeline was integrated with our neuroinformatics system for data
management, user input/output, and real-time visualization. Performance and
accuracy of D-r1DL on both individual and group-wise fMRI Human Connectome
Project (HCP) dataset shows that the proposed framework is highly scalable. The
resulting group-wise functional network decompositions are highly accurate, and
the fast processing time confirm this claim. In addition, D-r1DL can provide
real-time user feedback and results visualization which are vital for
large-scale data analysis.
</dc:description>
 <dc:description>Comment: One of the authors name, Mojtaba Sedigh Fazli, has been mistakenly
  missed from this paper presented at the IEEE Big Data confrence. In result we
  are submitting this verison to correct the authors' names</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02638</dc:identifier>
 <dc:identifier>doi:10.1109/BigData.2016.7841000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02639</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extractor-Based Time-Space Lower Bounds for Learning</dc:title>
 <dc:creator>Garg, Sumegha</dc:creator>
 <dc:creator>Raz, Ran</dc:creator>
 <dc:creator>Tal, Avishay</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  A matrix $M: A \times X \rightarrow \{-1,1\}$ corresponds to the following
learning problem: An unknown element $x \in X$ is chosen uniformly at random. A
learner tries to learn $x$ from a stream of samples, $(a_1, b_1), (a_2, b_2)
\ldots$, where for every $i$, $a_i \in A$ is chosen uniformly at random and
$b_i = M(a_i,x)$.
  Assume that $k,\ell, r$ are such that any submatrix of $M$ of at least
$2^{-k} \cdot |A|$ rows and at least $2^{-\ell} \cdot |X|$ columns, has a bias
of at most $2^{-r}$. We show that any learning algorithm for the learning
problem corresponding to $M$ requires either a memory of size at least
$\Omega\left(k \cdot \ell \right)$, or at least $2^{\Omega(r)}$ samples. The
result holds even if the learner has an exponentially small success probability
(of $2^{-\Omega(r)}$).
  In particular, this shows that for a large class of learning problems, any
learning algorithm requires either a memory of size at least $\Omega\left((\log
|X|) \cdot (\log |A|)\right)$ or an exponential number of samples, achieving a
tight $\Omega\left((\log |X|) \cdot (\log |A|)\right)$ lower bound on the size
of the memory, rather than a bound of $\Omega\left(\min\left\{(\log
|X|)^2,(\log |A|)^2\right\}\right)$ obtained in previous works [R17,MM17b].
  Moreover, our result implies all previous memory-samples lower bounds, as
well as a number of new applications.
  Our proof builds on [R17] that gave a general technique for proving
memory-samples lower bounds.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02640</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-Space Tradeoffs for Learning from Small Test Spaces: Learning Low
  Degree Polynomial Functions</dc:title>
 <dc:creator>Beame, Paul</dc:creator>
 <dc:creator>Gharan, Shayan Oveis</dc:creator>
 <dc:creator>Yang, Xin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We develop an extension of recently developed methods for obtaining
time-space tradeoff lower bounds for problems of learning from random test
samples to handle the situation where the space of tests is signficantly
smaller than the space of inputs, a class of learning problems that is not
handled by prior work. This extension is based on a measure of how matrices
amplify the 2-norms of probability distributions that is more refined than the
2-norms of these matrices.
  As applications that follow from our new technique, we show that any
algorithm that learns $m$-variate homogeneous polynomial functions of degree at
most $d$ over $\mathbb{F}_2$ from evaluations on randomly chosen inputs either
requires space $\Omega(mn)$ or $2^{\Omega(m)}$ time where $n=m^{\Theta(d)}$ is
the dimension of the space of such functions. These bounds are asymptotically
optimal since they match the tradeoffs achieved by natural learning algorithms
for the problems.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02645</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embracing a new era of highly efficient and productive quantum Monte
  Carlo simulations</dc:title>
 <dc:creator>Mathuriya, Amrita</dc:creator>
 <dc:creator>Luo, Ye</dc:creator>
 <dc:creator>Clay III, Raymond C.</dc:creator>
 <dc:creator>Benali, Anouar</dc:creator>
 <dc:creator>Shulenburger, Luke</dc:creator>
 <dc:creator>Kim, Jeongnim</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  QMCPACK has enabled cutting-edge materials research on supercomputers for
over a decade. It scales nearly ideally but has low single-node efficiency due
to the physics-based abstractions using array-of-structures objects, causing
inefficient vectorization. We present a systematic approach to transform
QMCPACK to better exploit the new hardware features of modern CPUs in portable
and maintainable ways. We develop miniapps for fast prototyping and
optimizations. We implement new containers in structure-of-arrays data layout
to facilitate vectorizations by the compilers. Further speedup and smaller
memory-footprints are obtained by computing data on the fly with the vectorized
routines and expanding single-precision use. All these are seamlessly
incorporated in production QMCPACK. We demonstrate upto 4.5x speedups on recent
Intel processors and IBM Blue Gene/Q for representative workloads. Energy
consumption is reduced significantly commensurate to the speedup factor.
Memory-footprints are reduced by up-to 3.8x, opening the possibility to solve
much larger problems of future.
</dc:description>
 <dc:description>Comment: 12 pages, 10 figures, 2 tables, to be published at SC17</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02645</dc:identifier>
 <dc:identifier>doi:10.1145/3126908.3126952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02651</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When rule-based models need to count</dc:title>
 <dc:creator>Boutillier, Pierre</dc:creator>
 <dc:creator>Cristescu, Ioana</dc:creator>
 <dc:subject>Quantitative Biology - Other Quantitative Biology</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Rule-based modelers dislike direct enumeration of cases when more efficient
means of enumeration are available. We present an extension of the Kappa
language which attaches to agents a notion of level. We detail two encodings
that are more concise than the former practice.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02654</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cheryl's Birthday</dc:title>
 <dc:creator>van Ditmarsch, Hans</dc:creator>
 <dc:creator>Hartley, Michael Ian</dc:creator>
 <dc:creator>Kooi, Barteld</dc:creator>
 <dc:creator>Welton, Jonathan</dc:creator>
 <dc:creator>Yeo, Joseph B. W.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - General Literature</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present four logic puzzles and after that their solutions. Joseph Yeo
designed 'Cheryl's Birthday'. Mike Hartley came up with a novel solution for
'One Hundred Prisoners and a Light Bulb'. Jonathan Welton designed 'A Blind
Guess' and 'Abby's Birthday'. Hans van Ditmarsch and Barteld Kooi authored the
puzzlebook 'One Hundred Prisoners and a Light Bulb' that contains other
knowledge puzzles, and that can also be found on the webpage
http://personal.us.es/hvd/lightbulb.html dedicated to the book.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02654</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 1-9</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02657</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Which Encoding is the Best for Text Classification in Chinese, English,
  Japanese and Korean?</dc:title>
 <dc:creator>Zhang, Xiang</dc:creator>
 <dc:creator>LeCun, Yann</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This article offers an empirical study on the different ways of encoding
Chinese, Japanese, Korean (CJK) and English languages for text classification.
Different encoding levels are studied, including UTF-8 bytes, characters,
words, romanized characters and romanized words. For all encoding levels,
whenever applicable, we provide comparisons with linear models, fastText and
convolutional networks. For convolutional networks, we compare between encoding
mechanisms using character glyph images, one-hot (or one-of-n) encoding, and
embedding. In total there are 473 models, using 14 large-scale text
classification datasets in 4 languages including Chinese, English, Japanese and
Korean. Some conclusions from these results include that byte-level one-hot
encoding based on UTF-8 consistently produces competitive results for
convolutional networks, that word-level n-grams linear models are competitive
even without perfect word segmentation, and that fastText provides the best
result using character-level n-gram encoding but can overfit when the features
are overly rich.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02660</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Visual Importance for Graphic Designs and Data Visualizations</dc:title>
 <dc:creator>Bylinskii, Zoya</dc:creator>
 <dc:creator>Kim, Nam Wook</dc:creator>
 <dc:creator>O'Donovan, Peter</dc:creator>
 <dc:creator>Alsheikh, Sami</dc:creator>
 <dc:creator>Madan, Spandan</dc:creator>
 <dc:creator>Pfister, Hanspeter</dc:creator>
 <dc:creator>Durand, Fredo</dc:creator>
 <dc:creator>Russell, Bryan</dc:creator>
 <dc:creator>Hertzmann, Aaron</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:description>  Knowing where people look and click on visual designs can provide clues about
how the designs are perceived, and where the most important or relevant content
lies. The most important content of a visual design can be used for effective
summarization or to facilitate retrieval from a database. We present automated
models that predict the relative importance of different elements in data
visualizations and graphic designs. Our models are neural networks trained on
human clicks and importance annotations on hundreds of designs. We collected a
new dataset of crowdsourced importance, and analyzed the predictions of our
models with respect to ground truth importance and human eye movements. We
demonstrate how such predictions of importance can be used for automatic design
retargeting and thumbnailing. User studies with hundreds of MTurk participants
validate that, with limited post-processing, our importance-driven applications
are on par with, or outperform, current state-of-the-art methods, including
natural image saliency. We also provide a demonstration of how our importance
predictions can be built into interactive design tools to offer immediate
feedback during the design process.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02660</dc:identifier>
 <dc:identifier>UIST 2017</dc:identifier>
 <dc:identifier>doi:10.1145/3126594.3126653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02662</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online unit clustering in higher dimensions</dc:title>
 <dc:creator>Dumitrescu, Adrian</dc:creator>
 <dc:creator>T&#xf3;th, Csaba D.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  We revisit the online Unit Clustering problem in higher dimensions: Given a
set of $n$ points in $\mathbb{R}^d$, that arrive one by one, partition the
points into clusters (subsets) of diameter at most one, so as to minimize the
number of clusters used. In this paper, we work in $\mathbb{R}^d$ using the
$L_\infty$ norm. We show that the competitive ratio of any algorithm
(deterministic or randomized) for this problem must depend on the dimension
$d$. This resolves an open problem raised by Epstein and van Stee (WAOA 2008).
We also give a randomized online algorithm with competitive ratio $O(d^2)$ for
Unit Clustering of integer points (i.e., points in $\mathbb{Z}^d$, $d\in
\mathbb{N}$, under $L_{\infty}$ norm). We complement these results with some
additional lower bounds for related problems in higher dimensions.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures, to appear in the Proceedings of the 15th
  Workshop on Approximation and Online Algorithms (WAOA 2017)</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02663</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradient-enhanced kriging for high-dimensional problems</dc:title>
 <dc:creator>Bouhlel, Mohamed Amine</dc:creator>
 <dc:creator>Martins, Joaquim R. R. A.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Surrogate models provide a low computational cost alternative to evaluating
expensive functions. The construction of accurate surrogate models with large
numbers of independent variables is currently prohibitive because it requires a
large number of function evaluations. Gradient-enhanced kriging has the
potential to reduce the number of function evaluations for the desired accuracy
when efficient gradient computation, such as an adjoint method, is available.
However, current gradient-enhanced kriging methods do not scale well with the
number of sampling points due to the rapid growth in the size of the
correlation matrix where new information is added for each sampling point in
each direction of the design space. They do not scale well with the number of
independent variables either due to the increase in the number of
hyperparameters that needs to be estimated. To address this issue, we develop a
new gradient-enhanced surrogate model approach that drastically reduced the
number of hyperparameters through the use of the partial-least squares method
that maintains accuracy. In addition, this method is able to control the size
of the correlation matrix by adding only relevant points defined through the
information provided by the partial-least squares method. To validate our
method, we compare the global accuracy of the proposed method with conventional
kriging surrogate models on two analytic functions with up to 100 dimensions,
as well as engineering problems of varied complexity with up to 15 dimensions.
We show that the proposed method requires fewer sampling points than
conventional methods to obtain the desired accuracy, or provides more accuracy
for a fixed budget of sampling points. In some cases, we get over 3 times more
accurate models than a bench of surrogate models from the literature, and also
over 3200 times faster than standard gradient-enhanced kriging models.
</dc:description>
 <dc:description>Comment: 27 pages, 5 figures</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02664</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Internet of Tangible Things (IoTT): Challenges and Opportunities for
  Tangible Interaction with IoT</dc:title>
 <dc:creator>Angelini, Leonardo</dc:creator>
 <dc:creator>Couture, Nadine</dc:creator>
 <dc:creator>Khaled, Omar Abou</dc:creator>
 <dc:creator>Mugellini, Elena</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In the Internet of Things era, an increasing number of household devices and
everyday objects are able to send to and retrieve information from the
Internet, offering innovative services to the user. However, most of these
devices provide only smartphone or web interfaces to control the IoT object
properties and functions. As a result, generally, the interaction is
disconnected from the physical world, decreasing the user experience and
increasing the risk of isolating the user in digital bubbles. We argue that
tangible interaction can counteract this trend and this paper discusses the
potential benefits and the still open challenges of tangible interaction
applied to the Internet of Things. To underline this need, we introduce the
term Internet of Tangible Things. In the article, after an analysis of current
open challenges for Human-Computer Interaction in IoT, we summarize current
trends in tangible interaction and extrapolate eight tangible interaction
properties that could be exploited for designing novel interactions with IoT
objects. Through a systematic literature review of tangible interaction applied
to IoT, we show what has been already explored in the systems that pioneered
the field and the future explorations that still have to be conducted.
</dc:description>
 <dc:description>Comment: Suibmitted to MDPI Informatics, Special Issue on Tangible and
  Embodied Interaction</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02666</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the 2017 ICML Workshop on Human Interpretability in
  Machine Learning (WHI 2017)</dc:title>
 <dc:creator>Kim, Been</dc:creator>
 <dc:creator>Malioutov, Dmitry M.</dc:creator>
 <dc:creator>Varshney, Kush R.</dc:creator>
 <dc:creator>Weller, Adrian</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This is the Proceedings of the 2017 ICML Workshop on Human Interpretability
in Machine Learning (WHI 2017), which was held in Sydney, Australia, August 10,
2017. Invited speakers were Tony Jebara, Pang Wei Koh, and David Sontag.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02668</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A discriminative view of MRF pre-processing algorithms</dc:title>
 <dc:creator>Wang, Chen</dc:creator>
 <dc:creator>Herrmann, Charles</dc:creator>
 <dc:creator>Zabih, Ramin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While Markov Random Fields (MRFs) are widely used in computer vision, they
present a quite challenging inference problem. MRF inference can be accelerated
by pre-processing techniques like Dead End Elimination (DEE) or QPBO-based
approaches which compute the optimal labeling of a subset of variables. These
techniques are guaranteed to never wrongly label a variable but they often
leave a large number of variables unlabeled. We address this shortcoming by
interpreting pre-processing as a classification problem, which allows us to
trade off false positives (i.e., giving a variable an incorrect label) versus
false negatives (i.e., failing to label a variable). We describe an efficient
discriminative rule that finds optimal solutions for a subset of variables. Our
technique provides both per-instance and worst-case guarantees concerning the
quality of the solution. Empirical studies were conducted over several
benchmark datasets. We obtain a speedup factor of 2 to 12 over expansion moves
without preprocessing, and on difficult non-submodular energy functions produce
slightly lower energy.
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02675</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inheritance of Convexity for the $\mathcal{P}_{\min}$-Restricted Game</dc:title>
 <dc:creator>Skoda, Alexandre</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We consider restricted games on weighted graphs associated with minimum
partitions. We replace in the classical definition of Myerson restricted game
the connected components of any subgraph by the subcomponents corresponding to
a minimum partition. This minimum partition $\mathcal{P}_{\min}$ is induced by
the deletion of the minimum weight edges. We provide a characterization of the
graphs satisfying inheritance of convexity from the underlying game to the
restricted game associated with Pmin.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02676</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power packet transferability via symbol propagation matrix</dc:title>
 <dc:creator>Nawata, Shinya</dc:creator>
 <dc:creator>Maki, Atsuto</dc:creator>
 <dc:creator>Hikihara, Takashi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Power packet is a unit of electric power transferred by a power pulse with an
information tag. In Shannon's information theory, messages are represented by
symbol sequences in a digitized manner. Referring to this formulation, we
define symbols in power packetization as a minimum unit of power transferred by
a tagged pulse. Here, power is digitized and quantized. In this paper, we
consider packetized power in networks for a finite duration, giving symbols and
their energies to the networks. A network structure is defined using a graph
whose nodes represent routers, sources, and destinations. First, we introduce
symbol propagation matrix (SPM) in which symbols are transferred at links
during unit times. Packetized power is described as a network flow in a
spatio-temporal structure. Then, we study the problem of selecting an SPM in
terms of transferability, that is, the possibility to represent given energies
at sources and destinations during the finite duration. To select an SPM, we
consider a network flow problem of packetized power. The problem is formulated
as an M-convex submodular flow problem which is known as generalization of the
minimum cost flow problem and solvable. Finally, through examples, we verify
that this formulation provides reasonable packetized power.
</dc:description>
 <dc:description>Comment: Submitted to Proceedings of the Royal Society A: Mathematical,
  Physical and Engineering Sciences</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02677</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomly coloring graphs of bounded treewidth</dc:title>
 <dc:creator>Vardi, Shai</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the problem of sampling a proper $k$-coloring of a graph of
maximal degree $\Delta$ uniformly at random. We describe a new Markov chain for
sampling colorings, and show that it mixes rapidly on graphs of bounded
treewidth if $k\geq(1+\epsilon)\Delta$, for any $\epsilon&gt;0$.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02681</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Adversarial Network-based Synthesis of Visible Faces from
  Polarimetric Thermal Faces</dc:title>
 <dc:creator>Zhang, He</dc:creator>
 <dc:creator>Patel, Vishal M.</dc:creator>
 <dc:creator>Riggan, Benjamin S.</dc:creator>
 <dc:creator>Hu, Shuowen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The large domain discrepancy between faces captured in polarimetric (or
conventional) thermal and visible domain makes cross-domain face recognition
quite a challenging problem for both human-examiners and computer vision
algorithms. Previous approaches utilize a two-step procedure (visible feature
estimation and visible image reconstruction) to synthesize the visible image
given the corresponding polarimetric thermal image. However, these are regarded
as two disjoint steps and hence may hinder the performance of visible face
reconstruction. We argue that joint optimization would be a better way to
reconstruct more photo-realistic images for both computer vision algorithms and
human-examiners to examine. To this end, this paper proposes a Generative
Adversarial Network-based Visible Face Synthesis (GAN-VFS) method to synthesize
more photo-realistic visible face images from their corresponding polarimetric
images. To ensure that the encoded visible-features contain more semantically
meaningful information in reconstructing the visible face image, a guidance
sub-network is involved into the training procedure. To achieve photo realistic
property while preserving discriminative characteristics for the reconstructed
outputs, an identity loss combined with the perceptual loss are optimized in
the framework. Multiple experiments evaluated on different experimental
protocols demonstrate that the proposed method achieves state-of-the-art
performance.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02688</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistics of Deep Generated Images</dc:title>
 <dc:creator>Zeng, Yu</dc:creator>
 <dc:creator>Lu, Huchuan</dc:creator>
 <dc:creator>Borji, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Here, we explore the low-level statistics of images generated by
state-of-the-art deep generative models. First, Wasserstein generative
adversarial network (WGAN) and deep convolutional generative adversarial
network (DCGAN) are trained on the ImageNet dataset and a large set of cartoon
frames from animations. Then, for images generated by these models as well as
natural scenes and cartoons, statistics including mean power spectrum, the
number of connected components in a given image area, distribution of random
filter responses, and contrast distribution are computed. Our analyses on
training images support current findings on scale invariance, non-Gaussianity,
and Weibull contrast distribution of natural scenes. We find that although
similar results hold over cartoon images, there is still a significant
difference between statistics of natural scenes and images generated by both
DCGAN and WGAN models. In particular, generated images do not have scale
invariant mean power spectrum magnitude, which indicates existence of extra
structures in these images caused by deconvolution operations. We also find
that replacing deconvolution layers in the deep generative models by sub-pixel
convolution helps them generate images with a mean power spectrum more similar
to the mean power spectrum of natural images. Inspecting how well the
statistics of deep generated images match the known statistical properties of
natural images, such as scale invariance, non-Gaussianity, and Weibull contrast
distribution, can a) reveal the degree to which deep learning models capture
the essence of the natural scenes, b) provide a new dimension to evaluate
models, and c) allow possible improvement of image generative models (e.g., via
defining new loss functions).
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02691</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal Function Approximation by Deep Neural Nets with Bounded Width
  and ReLU Activations</dc:title>
 <dc:creator>Hanin, Boris</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  This article concerns the expressive power of depth in neural nets with ReLU
activations and bounded width. We are particularly interested in the following
questions: what is the minimal width $w_{\text{min}}(d)$ so that ReLU nets of
width $w_{\text{min}}(d)$ (and arbitrary depth) can approximate any continuous
function on the unit cube $[0,1]^d$ aribitrarily well? For ReLU nets near this
minimal width, what can one say about the depth necessary to approximate a
given function? Our approach to this paper is based on the observation that,
due to the convexity of the ReLU activation, ReLU nets are particularly
well-suited for representing convex functions. In particular, we prove that
ReLU nets with width $d+1$ can approximate any continuous convex function of
$d$ variables arbitrarily well. These results then give quantitative depth
estimates for the rate of approximation of any continuous scalar function on
the $d$-dimensional cube $[0,1]^d$ by ReLU nets with width $d+3.$
</dc:description>
 <dc:description>Comment: v3. Theorem 3 removed. Comments Welcome. 9p</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02693</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Entropy Agglomeration</dc:title>
 <dc:creator>Fidaner, I&#x15f;&#x131;k Bar&#x131;&#x15f;</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Entropy Agglomeration (EA) is a hierarchical clustering algorithm introduced
in 2013. Here, we generalize it to define Generalized Entropy Agglomeration
(GEA) that can work with multiset blocks and blocks with rational occurrence
numbers. We also introduce a numerical categorization procedure to apply GEA to
numerical datasets. The software REBUS 2.0 is published with these
capabilities: http://fidaner.wordpress.com/science/rebus2
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02694</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human Skin Detection Using RGB, HSV and YCbCr Color Models</dc:title>
 <dc:creator>Kolkur, S.</dc:creator>
 <dc:creator>Kalbande, D.</dc:creator>
 <dc:creator>Shimpi, P.</dc:creator>
 <dc:creator>Bapat, C.</dc:creator>
 <dc:creator>Jatakia, J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Other Quantitative Biology</dc:subject>
 <dc:description>  Human Skin detection deals with the recognition of skin-colored pixels and
regions in a given image. Skin color is often used in human skin detection
because it is invariant to orientation and size and is fast to process. A new
human skin detection algorithm is proposed in this paper. The three main
parameters for recognizing a skin pixel are RGB (Red, Green, Blue), HSV (Hue,
Saturation, Value) and YCbCr (Luminance, Chrominance) color models. The
objective of proposed algorithm is to improve the recognition of skin pixels in
given images. The algorithm not only considers individual ranges of the three
color parameters but also takes into ac- count combinational ranges which
provide greater accuracy in recognizing the skin area in a given image.
</dc:description>
 <dc:description>Comment: ICCASP/ICMMD-2016. Published by Atlantic Press. Part of series: AISR
  ISBN: 978-94-6252-305-0 ISSN: 1951-6851</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02694</dc:identifier>
 <dc:identifier>doi:10.2991/iccasp-16.2017.51</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02696</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Actions are Needed for Understanding Human Actions in Videos?</dc:title>
 <dc:creator>Sigurdsson, Gunnar A.</dc:creator>
 <dc:creator>Russakovsky, Olga</dc:creator>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  What is the right way to reason about human activities? What directions
forward are most promising? In this work, we analyze the current state of human
activity understanding in videos. The goal of this paper is to examine
datasets, evaluation metrics, algorithms, and potential future directions. We
look at the qualitative attributes that define activities such as pose
variability, brevity, and density. The experiments consider multiple
state-of-the-art algorithms and multiple datasets. The results demonstrate that
while there is inherent ambiguity in the temporal extent of activities, current
datasets still permit effective benchmarking. We discover that fine-grained
understanding of objects and pose when combined with temporal reasoning is
likely to yield substantial improvements in algorithmic accuracy. We present
the many kinds of information that will be needed to achieve substantial gains
in activity understanding: objects, verbs, intent, and sequential reasoning.
The software and additional information will be made available to provide other
researchers detailed diagnostics to understand their own algorithms.
</dc:description>
 <dc:description>Comment: ICCV2017</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02702</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Vector Spaces for Unsupervised Information Retrieval</dc:title>
 <dc:creator>Van Gysel, Christophe</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:creator>Kanoulas, Evangelos</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose the Neural Vector Space Model (NVSM), a method that learns
representations of documents in an unsupervised manner for news article
retrieval. In the NVSM paradigm, we learn low-dimensional representations of
words and documents from scratch using gradient descent and rank documents
according to their similarity with query representations that are composed from
word representations. We show that NVSM performs better at document ranking
than existing latent semantic vector space methods. The addition of NVSM to a
mixture of lexical language models and a state-of-the-art baseline vector space
model yields a statistically significant increase in retrieval effectiveness.
Consequently, NVSM adds a complementary relevance signal. Next to semantic
matching, we find that NVSM performs well in cases where lexical matching is
needed.
  NVSM learns a notion of term specificity directly from the document
collection without feature engineering. We also show that NVSM learns
regularities related to Luhn significance. Finally, we give advice on how to
deploy NVSM in situations where model selection (e.g., cross-validation) is
infeasible. We find that an unsupervised ensemble of multiple models trained
with different hyperparameter values performs better than a single
cross-validated model. Therefore, NVSM can safely be used for ranking documents
without supervised relevance judgments.
</dc:description>
 <dc:description>Comment: Under review</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02709</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recent Trends in Deep Learning Based Natural Language Processing</dc:title>
 <dc:creator>Young, Tom</dc:creator>
 <dc:creator>Hazarika, Devamanyu</dc:creator>
 <dc:creator>Poria, Soujanya</dc:creator>
 <dc:creator>Cambria, Erik</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Deep learning methods employ multiple processing layers to learn hierarchical
representations of data, and have produced state-of-the-art results in many
domains. Recently, a variety of model designs and methods have blossomed in the
context of natural language processing (NLP). In this paper, we review
significant deep learning related models and methods that have been employed
for numerous NLP tasks and provide a walk-through of their evolution. We also
summarize, compare and contrast the various models and put forward a detailed
understanding of the past, present and future of deep learning in NLP.
</dc:description>
 <dc:description>Comment: 22 pages, 28 figures</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02710</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Reversible Programs to Univalent Universes and Back</dc:title>
 <dc:creator>Carette, Jacques</dc:creator>
 <dc:creator>Chen, Chao-Hong</dc:creator>
 <dc:creator>Choudhury, Vikraman</dc:creator>
 <dc:creator>Sabry, Amr</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:description>  We establish a close connection between a reversible programming language
based on type isomorphisms and a formally presented univalent universe. The
correspondence relates combinators witnessing type isomorphisms in the
programming language to paths in the univalent universe; and combinator
optimizations in the programming language to 2-paths in the univalent universe.
The result suggests a simple computational interpretation of paths and of
univalence in terms of familiar programming constructs whenever the universe in
question is computable.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02711</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tips and Tricks for Visual Question Answering: Learnings from the 2017
  Challenge</dc:title>
 <dc:creator>Teney, Damien</dc:creator>
 <dc:creator>Anderson, Peter</dc:creator>
 <dc:creator>He, Xiaodong</dc:creator>
 <dc:creator>Hengel, Anton van den</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents a state-of-the-art model for visual question answering
(VQA), which won the first place in the 2017 VQA Challenge. VQA is a task of
significant importance for research in artificial intelligence, given its
multimodal nature, clear evaluation protocol, and potential real-world
applications. The performance of deep neural networks for VQA is very dependent
on choices of architectures and hyperparameters. To help further research in
the area, we describe in detail our high-performing, though relatively simple
model. Through a massive exploration of architectures and hyperparameters
representing more than 3,000 GPU-hours, we identified tips and tricks that lead
to its success, namely: sigmoid outputs, soft training targets, image features
from bottom-up attention, gated tanh activations, output embeddings initialized
using GloVe and Google Images, large mini-batches, and smart shuffling of
training data. We provide a detailed analysis of their impact on performance to
assist others in making an appropriate selection.
</dc:description>
 <dc:description>Comment: Winner of the 2017 Visual Question Answering (VQA) Challenge at CVPR</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02716</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequential Dual Deep Learning with Shape and Texture Features for Sketch
  Recognition</dc:title>
 <dc:creator>Jia, Qi</dc:creator>
 <dc:creator>Yu, Meiyu</dc:creator>
 <dc:creator>Fan, Xin</dc:creator>
 <dc:creator>Li, Haojie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68T10</dc:subject>
 <dc:subject>I.5.2</dc:subject>
 <dc:description>  Recognizing freehand sketches with high arbitrariness is greatly challenging.
Most existing methods either ignore the geometric characteristics or treat
sketches as handwritten characters with fixed structural ordering.
Consequently, they can hardly yield high recognition performance even though
sophisticated learning techniques are employed. In this paper, we propose a
sequential deep learning strategy that combines both shape and texture
features. A coded shape descriptor is exploited to characterize the geometry of
sketch strokes with high flexibility, while the outputs of constitutional
neural networks (CNN) are taken as the abstract texture feature. We develop
dual deep networks with memorable gated recurrent units (GRUs), and
sequentially feed these two types of features into the dual networks,
respectively. These dual networks enable the feature fusion by another gated
recurrent unit (GRU), and thus accurately recognize sketches invariant to
stroke ordering. The experiments on the TU-Berlin data set show that our method
outperforms the average of human and state-of-the-art algorithms even when
significant shape and appearance variations occur.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02721</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Face Feature for Face Alignment and Reconstruction</dc:title>
 <dc:creator>Jiang, Boyi</dc:creator>
 <dc:creator>Zhang, Juyong</dc:creator>
 <dc:creator>Deng, Bailin</dc:creator>
 <dc:creator>Guo, Yudong</dc:creator>
 <dc:creator>Liu, Ligang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel face feature extraction method based on
deep learning. Using synthesized multi-view face images, we train a deep face
feature (DFF) extractor based on the correlation between projections of a face
point on images from different views. A feature vector can be extracted for
each pixel of the face image based on the trained DFF model, and it is more
effective than general purpose feature descriptors for face-related tasks such
as alignment, matching, and reconstruction. Based on the DFF, we develop an
effective face alignment method with single or multiple face images as input,
which iteratively updates landmarks, pose and 3D shape. Experiments demonstrate
that our method can achieve state-of-the-art results for face alignment with a
single image, and the alignment can be further improved with multi-view face
images.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02728</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sample-Optimal Identity Testing with High Probability</dc:title>
 <dc:creator>Diakonikolas, Ilias</dc:creator>
 <dc:creator>Gouleakis, Themis</dc:creator>
 <dc:creator>Peebles, John</dc:creator>
 <dc:creator>Price, Eric</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We study the problem of testing identity against a given distribution (a.k.a.
goodness-of-fit) with a focus on the high confidence regime. More precisely,
given samples from an unknown distribution $p$ over $n$ elements, an explicitly
given distribution $q$, and parameters $0&lt; \epsilon, \delta &lt; 1$, we wish to
distinguish, with probability at least $1-\delta$, whether the distributions
are identical versus $\epsilon$-far in total variation (or statistical)
distance. Existing work has focused on the constant confidence regime, i.e.,
the case that $\delta = \Omega(1)$, for which the sample complexity of identity
testing is known to be $\Theta(\sqrt{n}/\epsilon^2)$.
  Typical applications of distribution property testing require small values of
the confidence parameter $\delta$ (which correspond to small &quot;$p$-values&quot; in
the statistical hypothesis testing terminology). Prior work achieved
arbitrarily small values of $\delta$ via black-box amplification, which
multiplies the required number of samples by $\Theta(\log(1/\delta))$. We show
that this upper bound is suboptimal for any $\delta = o(1)$, and give a new
identity tester that achieves the optimal sample complexity. Our new upper and
lower bounds show that the optimal sample complexity of identity testing is \[
  \Theta\left( \frac{1}{\epsilon^2}\left(\sqrt{n \log(1/\delta)} +
\log(1/\delta) \right)\right) \] for any $n, \epsilon$, and $\delta$. For the
special case of uniformity testing, where the given distribution is the uniform
distribution $U_n$ over the domain, our new tester is surprisingly simple: to
test whether $p = U_n$ versus $\mathrm{d}_{TV}(p, U_n) \geq \epsilon$, we
simply threshold $\mathrm{d}_{TV}(\hat{p}, U_n)$, where $\hat{p}$ is the
empirical probability distribution. We believe that our novel analysis
techniques may be useful for other distribution testing problems as well.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02731</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly- and Self-Supervised Learning for Content-Aware Deep Image
  Retargeting</dc:title>
 <dc:creator>Cho, Donghyeon</dc:creator>
 <dc:creator>Park, Jinsun</dc:creator>
 <dc:creator>Oh, Tae-Hyun</dc:creator>
 <dc:creator>Tai, Yu-Wing</dc:creator>
 <dc:creator>Kweon, In So</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a weakly- and self-supervised deep convolutional neural
network (WSSDCNN) for content-aware image retargeting. Our network takes a
source image and a target aspect ratio, and then directly outputs a retargeted
image. Retargeting is performed through a shift map, which is a pixel-wise
mapping from the source to the target grid. Our method implicitly learns an
attention map, which leads to a content-aware shift map for image retargeting.
As a result, discriminative parts in an image are preserved, while background
regions are adjusted seamlessly. In the training phase, pairs of an image and
its image-level annotation are used to compute content and structure losses. We
demonstrate the effectiveness of our proposed method for a retargeting
application with insightful analyses.
</dc:description>
 <dc:description>Comment: 10 pages, 11 figures. To appear in ICCV 2017, Spotlight Presentation</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02733</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Neural Network with Complex Exponential Activation
  Functions in Image Recognition using Deep Learning Framework</dc:title>
 <dc:creator>Savchenko, Andrey</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68T10</dc:subject>
 <dc:description>  If the training dataset is not very large, image recognition is usually
implemented with the transfer learning methods. In these methods the features
are extracted using a deep convolutional neural network, which was
preliminarily trained with an external very-large dataset. In this paper we
consider the nonparametric classification of extracted feature vectors with the
probabilistic neural network (PNN). The number of neurons at the pattern layer
of the PNN is equal to the database size, which causes the low recognition
performance and high memory space complexity of this network. We propose to
overcome these drawbacks by replacing the exponential activation function in
the Gaussian Parzen kernel to the complex exponential functions in the Fej\'er
kernel. We demonstrate that in this case it is possible to implement the
network with the number of neurons in the pattern layer proportional to the
cubic root of the database size. Thus, the proposed modification of the PNN
makes it possible to significantly decrease runtime and memory complexities
without loosing its main advantages, namely, extremely fast training procedure
and the convergence to the optimal Bayesian decision. An experimental study in
visual object category classification and unconstrained face recognition with
contemporary deep neural networks have shown, that our approach obtains very
efficient and rather accurate decisions for the small training sample in
comparison with the well-known classifiers.
</dc:description>
 <dc:description>Comment: 14 pages, 13 figures, 5 tables, 69 references</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02734</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Face Alignment and 3D Face Reconstruction with Application to Face
  Recognition</dc:title>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:creator>Zhao, Qijun</dc:creator>
 <dc:creator>Liu, Xiaoming</dc:creator>
 <dc:creator>Zeng, Dan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face alignment and 3D face reconstruction are traditionally accomplished as
separated tasks. By exploring the strong correlation between 2D landmarks and
3D shapes, in contrast, we propose a joint face alignment and 3D face
reconstruction method to simultaneously solve these two problems for 2D face
images of arbitrary poses and expressions. This method, based on a summation
model of 3D face shapes and cascaded regression in 2D and 3D face shape spaces,
iteratively and alternately applies two cascaded regressors, one for updating
2D landmarks and the other for 3D face shape.The 3D face shape and the
landmarks are correlated via a 3D-to-2D mapping matrix, which is updated in
each iteration to refine the location and visibility of 2D landmarks. Unlike
existing methods, the proposed method can fully automatically generate both
pose-and-expression-normalized (PEN) and expressive 3D face shapes and localize
both visible and invisible 2D landmarks. Based on the PEN 3D face shapes, we
devise a method to enhance face recognition accuracy across poses and
expressions. Extensive experiments show that the proposed method can achieve
the state-of-the-art accuracy in both face alignment and 3D face
reconstruction, and benefit face recognition owing to its reconstructed PEN 3D
face shapes.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02735</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Prototypical Networks for Few-Shot Learning on Omniglot</dc:title>
 <dc:creator>Fort, Stanislav</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a novel architecture for $k$-shot classification on the Omniglot
dataset. Building on prototypical networks, we extend their architecture to
what we call Gaussian prototypical networks. Prototypical networks learn a map
between images and embedding vectors, and use their clustering for
classification. In our model, a part of the encoder output is interpreted as a
confidence region estimate about the embedding point, and expressed as a
Gaussian covariance matrix. Our network then constructs a direction and class
dependent distance metric on the embedding space, using uncertainties of
individual data points as weights. We show that Gaussian prototypical networks
are a preferred architecture over vanilla prototypical networks with an
equivalent number of parameters. We report state-of-the-art performance in
1-shot and 5-shot classification both in 5-way and 20-way regime (for 5-shot
5-way, we are comparable to previous state-of-the-art) on the Omniglot dataset.
We explore artificially down-sampling a fraction of images in the training set,
which improves our performance even further. We therefore hypothesize that
Gaussian prototypical networks might perform better in less homogeneous,
noisier datasets, which are commonplace in real world applications.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02737</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demand-Independent Tolls</dc:title>
 <dc:creator>Colini-Baldeschi, Riccardo</dc:creator>
 <dc:creator>Klimm, Max</dc:creator>
 <dc:creator>Scarsini, Marco</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>91A13, 91A43</dc:subject>
 <dc:description>  Wardrop equilibria in nonatomic congestion games are in general inefficient
as they do not induce an optimal flow that minimizes the total travel time.
Tolls can be used to induce an optimum flow in equilibrium. The classical
approach to find such tolls is marginal cost pricing. This requires the exact
knowledge of the demand on the network. In this paper, we investigate under
which conditions tolls exist that are independent of the demand in the network.
We call them demand-independent optimum tolls (DIOTs). We show that such tolls
exist when the cost functions are shifted monomials. Moreover non-negative
DIOTs exist when the network is a directed acyclic multi-graph. Finally, we
show that any network with a single origin-destination pair admits DIOTs that,
although not necessarily non-negative, satisfy a budget constraint.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02740</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Data Prism: Semi-Verified Learning in the Small-Alpha Regime</dc:title>
 <dc:creator>Meister, Michela</dc:creator>
 <dc:creator>Valiant, Gregory</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a model of unreliable or crowdsourced data where there is an
underlying set of $n$ binary variables, each evaluator contributes a (possibly
unreliable or adversarial) estimate of the values of some subset of $r$ of the
variables, and the learner is given the true value of a constant number of
variables. We show that, provided an $\alpha$-fraction of the evaluators are
&quot;good&quot; (either correct, or with independent noise rate $p &lt; 1/2$), then the
true values of a $(1-\epsilon)$ fraction of the $n$ underlying variables can be
deduced as long as $\alpha &gt; 1/(2-2p)^r$. This setting can be viewed as an
instance of the semi-verified learning model introduced in [CSV17], which
explores the tradeoff between the number of items evaluated by each worker and
the fraction of good evaluators. Our results require the number of evaluators
to be extremely large, $&gt;n^r$, although our algorithm runs in linear time,
$O_{r,\epsilon}(n)$, given query access to the large dataset of evaluations.
This setting and results can also be viewed as examining a general class of
semi-adversarial CSPs with a planted assignment.
  This parameter regime where the fraction of reliable data is small, is
relevant to a number of practical settings. For example, settings where one has
a large dataset of customer preferences, with each customer specifying
preferences for a small (constant) number of items, and the goal is to
ascertain the preferences of a specific demographic of interest. Our results
show that this large dataset (which lacks demographic information) can be
leveraged together with the preferences of the demographic of interest for a
constant number of randomly selected items, to recover an accurate estimate of
the entire set of preferences. In this sense, our results can be viewed as a
&quot;data prism&quot; allowing one to extract the behavior of specific cohorts from a
large, mixed, dataset.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02747</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An automatic water detection approach based on Dempster-Shafer theory
  for multi spectral images</dc:title>
 <dc:creator>Li, Na</dc:creator>
 <dc:creator>Martin, Arnaud</dc:creator>
 <dc:creator>Estival, R&#xe9;mi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Detection of surface water in natural environment via multi-spectral imagery
has been widely utilized in many fields, such land cover identification.
However, due to the similarity of the spectra of water bodies, built-up areas,
approaches based on high-resolution satellites sometimes confuse these
features. A popular direction to detect water is spectral index, often
requiring the ground truth to find appropriate thresholds manually. As for
traditional machine learning methods, they identify water merely via
differences of spectra of various land covers, without taking specific
properties of spectral reflection into account. In this paper, we propose an
automatic approach to detect water bodies based on Dempster-Shafer theory,
combining supervised learning with specific property of water in spectral band
in a fully unsupervised context. The benefits of our approach are twofold. On
the one hand, it performs well in mapping principle water bodies, including
little streams and branches. On the other hand, it labels all objects usually
confused with water as `ignorance', including half-dry watery areas, built-up
areas and semi-transparent clouds and shadows. `Ignorance' indicates not only
limitations of the spectral properties of water and supervised learning itself
but insufficiency of information from multi-spectral bands as well, providing
valuable information for further land cover classification.
</dc:description>
 <dc:description>Comment: 20th International Conference on Information Fusion, Jul 2017, XI'AN,
  China</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02749</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rise of the HaCRS: Augmenting Autonomous Cyber Reasoning Systems with
  Human Assistance</dc:title>
 <dc:creator>Shoshitaishvili, Yan</dc:creator>
 <dc:creator>Weissbacher, Michael</dc:creator>
 <dc:creator>Dresel, Lukas</dc:creator>
 <dc:creator>Salls, Christopher</dc:creator>
 <dc:creator>Wang, Ruoyu</dc:creator>
 <dc:creator>Kruegel, Christopher</dc:creator>
 <dc:creator>Vigna, Giovanni</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  As the size and complexity of software systems increase, the number and
sophistication of software security flaws increase as well. The analysis of
these flaws began as a manual approach, but it soon became apparent that tools
were necessary to assist human experts in this task, resulting in a number of
techniques and approaches that automated aspects of the vulnerability analysis
process.
  Recently, DARPA carried out the Cyber Grand Challenge, a competition among
autonomous vulnerability analysis systems designed to push the tool-assisted
human-centered paradigm into the territory of complete automation. However,
when the autonomous systems were pitted against human experts it became clear
that certain tasks, albeit simple, could not be carried out by an autonomous
system, as they require an understanding of the logic of the application under
analysis.
  Based on this observation, we propose a shift in the vulnerability analysis
paradigm, from tool-assisted human-centered to human-assisted tool-centered. In
this paradigm, the automated system orchestrates the vulnerability analysis
process, and leverages humans (with different levels of expertise) to perform
well-defined sub-tasks, whose results are integrated in the analysis. As a
result, it is possible to scale the analysis to a larger number of programs,
and, at the same time, optimize the use of expensive human resources.
  In this paper, we detail our design for a human-assisted automated
vulnerability analysis system, describe its implementation atop an open-sourced
autonomous vulnerability analysis system that participated in the Cyber Grand
Challenge, and evaluate and discuss the significant improvements that
non-expert human assistance can offer to automated analysis approaches.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02750</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extreme clicking for efficient object annotation</dc:title>
 <dc:creator>Papadopoulos, Dim P.</dc:creator>
 <dc:creator>Uijlings, Jasper R. R.</dc:creator>
 <dc:creator>Keller, Frank</dc:creator>
 <dc:creator>Ferrari, Vittorio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Manually annotating object bounding boxes is central to building computer
vision datasets, and it is very time consuming (annotating ILSVRC [53] took 35s
for one high-quality box [62]). It involves clicking on imaginary corners of a
tight box around the object. This is difficult as these corners are often
outside the actual object and several adjustments are required to obtain a
tight box. We propose extreme clicking instead: we ask the annotator to click
on four physical points on the object: the top, bottom, left- and right-most
points. This task is more natural and these points are easy to find. We
crowd-source extreme point annotations for PASCAL VOC 2007 and 2012 and show
that (1) annotation time is only 7s per box, 5x faster than the traditional way
of drawing boxes [62]; (2) the quality of the boxes is as good as the original
ground-truth drawn the traditional way; (3) detectors trained on our
annotations are as accurate as those trained on the original ground-truth.
Moreover, our extreme clicking strategy not only yields box coordinates, but
also four accurate boundary points. We show (4) how to incorporate them into
GrabCut to obtain more accurate segmentations than those delivered when
initializing it from bounding boxes; (5) semantic segmentations models trained
on these segmentations outperform those trained on segmentations derived from
bounding boxes.
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02750</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02755</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Analog Network Coding noise in Multiuser Cooperative
  Relaying for Spatially Correlated Environment</dc:title>
 <dc:creator>Darshi, Sam</dc:creator>
 <dc:creator>Shailendra, Samar</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Analog Network Coding (ANC) is proposed in literature to improve the network
throughput by exploiting channel diversity. In practical scenarios, due to the
difference in channel characteristics, an extra residual component, termed as
ANC noise, appears during the processing of the received signal. This ANC noise
component may suppress the ANC gain. None of the existing literature to our
knowledge considers the effect of spatial correlation among channels on ANC
noise. This paper develops a generic framework to investigate the effect of
channel characteristics on ANC noise. We have modelled the channels as
spatially correlated to take the (dis)similarity among them into account. Per
node power constraint is also taken into consideration. In this work, we have
characterized the behaviour of ANC noise and presented the results to analyze
the network performance in terms of outage probability. Outcomes of our
investigation show that spatial correlation among channels significantly
affects the variance of ANC noise as well as the outage performance of the
system. The proposed framework can provide better insights while selecting the
system parameters in a correlated environment.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02756</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trade-Offs in Stochastic Event-Triggered Control</dc:title>
 <dc:creator>Demirel, Burak</dc:creator>
 <dc:creator>Leong, Alex S.</dc:creator>
 <dc:creator>Gupta, Vijay</dc:creator>
 <dc:creator>Quevedo, Daniel E.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper studies the optimal output-feedback control of a linear
time-invariant system where a stochastic event-based scheduler triggers the
communication between the sensor and the controller. The primary goal of the
use of this type of scheduling strategy is to provide significant reductions in
the usage of the sensor-to-controller communication and, in turn, improve
energy expenditure in the network. In this paper, we aim to design an
admissible control policy, which is a function of the observed output, to
minimize a quadratic cost function while employing a stochastic event-triggered
scheduler that preserves the Gaussian property of the plant state and the
estimation error. For the infinite horizon case, we present analytical
expressions that quantify the trade-off between the communication cost and
control performance of such event-triggered control systems. This trade-off is
confirmed quantitatively via numerical examples.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02757</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Isointense infant brain MRI segmentation with a dilated convolutional
  neural network</dc:title>
 <dc:creator>Moeskops, Pim</dc:creator>
 <dc:creator>Pluim, Josien P. W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Quantitative analysis of brain MRI at the age of 6 months is difficult
because of the limited contrast between white matter and gray matter. In this
study, we use a dilated triplanar convolutional neural network in combination
with a non-dilated 3D convolutional neural network for the segmentation of
white matter, gray matter and cerebrospinal fluid in infant brain MR images, as
provided by the MICCAI grand challenge on 6-month infant brain MRI
segmentation.
</dc:description>
 <dc:description>Comment: MICCAI grand challenge on 6-month infant brain MRI segmentation</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02758</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Algorithm for Finding Maximum Distance with Space Subdivision in E2</dc:title>
 <dc:creator>Skala, Vaclav</dc:creator>
 <dc:creator>Majdisova, Zuzana</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Finding an exact maximum distance of two points in the given set is a
fundamental computational problem which is solved in many applications. This
paper presents a fast, simple to implement and robust algorithm for finding
this maximum distance of two points in E2. This algorithm is based on a polar
subdivision followed by division of remaining points into uniform grid. The
main idea of the algorithm is to eliminate as many input points as possible
before finding the maximum distance. The proposed algorithm gives the
significant speed up compared to the standard algorithm.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02758</dc:identifier>
 <dc:identifier>ICIG 2015 Proceedings Part II, China, pp.261-274, Springer, 2015</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-21963-9_24</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02760</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Disambiguate by Asking Discriminative Questions</dc:title>
 <dc:creator>Li, Yining</dc:creator>
 <dc:creator>Huang, Chen</dc:creator>
 <dc:creator>Tang, Xiaoou</dc:creator>
 <dc:creator>Loy, Chen-Change</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The ability to ask questions is a powerful tool to gather information in
order to learn about the world and resolve ambiguities. In this paper, we
explore a novel problem of generating discriminative questions to help
disambiguate visual instances. Our work can be seen as a complement and new
extension to the rich research studies on image captioning and question
answering. We introduce the first large-scale dataset with over 10,000
carefully annotated images-question tuples to facilitate benchmarking. In
particular, each tuple consists of a pair of images and 4.6 discriminative
questions (as positive samples) and 5.9 non-discriminative questions (as
negative samples) on average. In addition, we present an effective method for
visual discriminative question generation. The method can be trained in a
weakly supervised manner without discriminative images-question tuples but just
existing visual question answering datasets. Promising results are shown
against representative baselines through quantitative evaluations and user
studies.
</dc:description>
 <dc:description>Comment: 14 pages, 12 figures, ICCV2017</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02763</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Has the Online Discussion Been Manipulated? Quantifying Online
  Discussion Authenticity within Online Social Media</dc:title>
 <dc:creator>Elyashar, Aviad</dc:creator>
 <dc:creator>Bendahan, Jorge</dc:creator>
 <dc:creator>Puzis, Rami</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Online social media (OSM) has a enormous influence in today's world. Some
individuals view OSM as fertile ground for abuse and use it to disseminate
misinformation and political propaganda, slander competitors, and spread spam.
The crowdturfing industry employs large numbers of bots and human workers to
manipulate OSM and misrepresent public opinion. The detection of online
discussion topics manipulated by OSM \emph{abusers} is an emerging issue
attracting significant attention. In this paper, we propose an approach for
quantifying the authenticity of online discussions based on the similarity of
OSM accounts participating in the discussion to known abusers and legitimate
accounts. Our method uses several similarity functions for the analysis and
classification of OSM accounts. The proposed methods are demonstrated using
Twitter data collected for this study and previously published \emph{Arabic
honeypot dataset}. The former includes manually labeled accounts and abusers
who participated in crowdturfing platforms. Evaluation of the topic's
authenticity, derived from account similarity functions, shows that the
suggested approach is effective for discriminating between topics that were
strongly promoted by abusers and topics that attracted authentic public
interest.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02765</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ephemeral Context to Support Robust and Diverse Music Recommendations</dc:title>
 <dc:creator>Kucherbaev, Pavel</dc:creator>
 <dc:creator>Tintarev, Nava</dc:creator>
 <dc:creator>Rodriguez, Carlos</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  While prior work on context-based music recommendation focused on fixed set
of contexts (e.g. walking, driving, jogging), we propose to use multiple
sensors and external data sources to describe momentary (ephemeral) context in
a rich way with a very large number of possible states (e.g. jogging fast along
in downtown of Sydney under a heavy rain at night being tired and angry). With
our approach, we address the problems which current approaches face: 1) a
limited ability to infer context from missing or faulty sensor data; 2) an
inability to use contextual information to support novel content discovery.
</dc:description>
 <dc:description>Comment: 3 pages, 1 figure, Machine Learning for Music Discovery workshop at
  ICML2017</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02766</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-dimensional Gated Recurrent Units for Automated Anatomical
  Landmark Localization</dc:title>
 <dc:creator>Andermatt, Simon</dc:creator>
 <dc:creator>Pezold, Simon</dc:creator>
 <dc:creator>Amann, Michael</dc:creator>
 <dc:creator>Cattin, Philippe C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an automated method for localizing an anatomical landmark in
three-dimensional medical images. The method combines two recurrent neural
networks in a coarse-to-fine approach: The first network determines a candidate
neighborhood by analyzing the complete given image volume. The second network
localizes the actual landmark precisely and accurately in the candidate
neighborhood. Both networks take advantage of multi-dimensional gated recurrent
units in their main layers, which allow for high model complexity with a
comparatively small set of parameters. We localize the medullopontine sulcus in
3D magnetic resonance images of the head and neck. We show that the proposed
approach outperforms similar localization techniques both in terms of mean
distance in millimeters and voxels w.r.t. manual labelings of the data. With a
mean localization error of 1.7 mm, the proposed approach performs on par with
neurological experts, as we demonstrate in an interrater comparison.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures, 1 table</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02769</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space Subdivision to Speed-up Convex Hull Construction in E3</dc:title>
 <dc:creator>Skala, Vaclav</dc:creator>
 <dc:creator>Majdisova, Zuzana</dc:creator>
 <dc:creator>Smolik, Michal</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Convex hulls are fundamental geometric tools used in a number of algorithms.
This paper presents a fast, simple to implement and robust Smart Convex Hull
(S-CH) algorithm for computing the convex hull of a set of points in E3. This
algorithm is based on &quot;spherical&quot; space subdivision. The main idea of the S-CH
algorithm is to eliminate as many input points as possible before the convex
hull construction. The experimental results show that only a very small number
of points are used for the final convex hull calculation. Experiments made also
proved that the proposed S-CH algorithm achieves a better time complexity in
comparison with other algorithms in E3.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02769</dc:identifier>
 <dc:identifier>Advances in Engineering Software, Vol.91, pp.12-22, ISSN
  0965-9978, Elsevier, January 2016</dc:identifier>
 <dc:identifier>doi:10.1016/j.advengsoft.2015.09.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02772</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Maximum Common Subgraph Problems in Series-Parallel Graphs</dc:title>
 <dc:creator>Kriege, Nils</dc:creator>
 <dc:creator>Kurpicz, Florian</dc:creator>
 <dc:creator>Mutzel, Petra</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The complexity of the maximum common connected subgraph problem in partial
$k$-trees is still not fully understood. Polynomial-time solutions are known
for degree-bounded outerplanar graphs, a subclass of the partial $2$-trees. On
the other hand, the problem is known to be ${\bf NP}$-hard in vertex-labeled
partial $11$-trees of bounded degree. We consider series-parallel graphs, i.e.,
partial $2$-trees. We show that the problem remains ${\bf NP}$-hard in
biconnected series-parallel graphs with all but one vertex of degree $3$ or
less. A positive complexity result is presented for a related problem of high
practical relevance which asks for a maximum common connected subgraph that
preserves blocks and bridges of the input graphs. We present a polynomial time
algorithm for this problem in series-parallel graphs, which utilizes a
combination of BC- and SP-tree data structures to decompose both graphs.
</dc:description>
 <dc:description>Comment: accepted for publication in the European Journal of Combinatorics</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02772</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02787</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Adaptive Randomized Algorithm for Group Testing</dc:title>
 <dc:creator>Bshouty, Nader H.</dc:creator>
 <dc:creator>Diab, Nuha</dc:creator>
 <dc:creator>Kawar, Shada R.</dc:creator>
 <dc:creator>Shahla, Robert J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the problem of group testing with a non-adaptive randomized
algorithm in the random incidence design (RID) model where each entry in the
test is chosen randomly independently from $\{0,1\}$ with a fixed probability
$p$.
  The property that is sufficient and necessary for a unique decoding is the
separability of the tests, but unfortunately no linear time algorithm is known
for such tests. In order to achieve linear-time decodable tests, the algorithms
in the literature use the disjunction property that gives almost optimal number
of tests.
  We define a new property for the tests which we call semi-disjunction
property. We show that there is a linear time decoding for such test and for
$d\to \infty$ the number of tests converges to the number of tests with the
separability property and is therefore optimal (in the RID model). Our analysis
shows that, in the RID model, the number of tests in our algorithm is better
than the one with the disjunction property even for small $d$.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02793</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diffusion and confusion of chaotic iteration based hash functions</dc:title>
 <dc:creator>Lin, Zhuosheng</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Wang, Qianxue</dc:creator>
 <dc:creator>Yu, Simin</dc:creator>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  To guarantee the integrity and security of data transmitted through the
Internet, hash functions are fundamental tools. But recent researches have
shown that security flaws exist in the most widely used hash functions. So a
new way to improve their security performance is urgently demanded. In this
article, we propose new hash functions based on chaotic iterations, which have
chaotic properties as defined by Devaney. The corresponding diffusion and
confusion analyzes are provided and a comparative study between the proposed
hash functions is carried out, to make their use more applicable in any
security context.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02798</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impacts of Culture and Socio-Economic Circumstances on Users' Behavior
  and Mobile Broadband Technology Diffusion Trends</dc:title>
 <dc:creator>Miraz, Mahdi H</dc:creator>
 <dc:creator>Bhuiyan, Monir</dc:creator>
 <dc:creator>Hossain, Md. Emran</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The use of Internet and Internet-based services on PCs, Laptops, Net Pads,
Mobile Phones, PDAs etc have not only changed the global economy but also the
way people communicate and their life styles. It also has evolved people from
different origins, cultures, beliefs across the national boundaries. As a
result it has become an absolute necessity to address the cross-cultural issues
of information systems (IS) reflecting the user behaviours and influencing the
way the mobile broadband technology is being accepted as well as the way it is
changing the life styles of different groups of people. This paper reports on
an on-going research effort which studies the impacts of culture and
socio-economic circumstances on users' behavior and mobile broadband technology
diffusion trends.
</dc:description>
 <dc:description>Comment: Cross-cultural IS issues, Users' behavior, Mobile Broadband,
  Internet-based services, Wireless Broadband Access (WBA), Proceedings of the
  fourth international conferences on Internet Technologies and Applications
  2011 (ITA 11)</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02801</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safety Verification of Phaser Programs</dc:title>
 <dc:creator>Ganjei, Zeinab</dc:creator>
 <dc:creator>Rezine, Ahmed</dc:creator>
 <dc:creator>Eles, Petru</dc:creator>
 <dc:creator>Peng, Zebo</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We address the problem of statically checking control state reachability (as
in possibility of assertion violations, race conditions or runtime errors) and
plain reachability (as in deadlock-freedom) of phaser programs. Phasers are a
modern non-trivial synchronization construct that supports dynamic parallelism
with runtime registration and deregistration of spawned tasks. They allow for
collective and point-to-point synchronizations. For instance, phasers can
enforce barriers or producer-consumer synchronization schemes among all or
subsets of the running tasks. Implementations %of these recent and dynamic
synchronization are found in modern languages such as X10 or Habanero Java.
Phasers essentially associate phases to individual tasks and use their runtime
values to restrict possible concurrent executions. Unbounded phases may result
in infinite transition systems even in the case of programs only creating
finite numbers of tasks and phasers. We introduce an exact gap-order based
procedure that always terminates when checking control reachability for
programs generating bounded numbers of coexisting tasks and phasers. We also
show verifying plain reachability is undecidable even for programs generating
few tasks and phasers. We then explain how to turn our procedure into a sound
analysis for checking plain reachability (including deadlock freedom). We
report on preliminary experiments with our open source tool.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02808</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing Cellular M2M Random Access with Binary Countdown Contention
  Resolution</dc:title>
 <dc:creator>Vilgelm, Mikhail</dc:creator>
 <dc:creator>Li&#xf1;ares, Sergio Rueda</dc:creator>
 <dc:creator>Kellerer, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Accommodating Machine-to-Machine applications and their requirements is one
of the challenges on the way from LTE towards 5G networks. The envisioned high
density of devices, alongside with their sporadic and synchronized transmission
patterns, might create signaling storms and overload in the current LTE
network. Here, we address the notorious random access (RA) challenge, namely,
scalability of the radio link connection establishment protocol in LTE
networks. We revisit the binary countdown technique for contention resolution
(BCCR), and apply it to the LTE RA procedure. We analytically investigate the
performance gains and trade-offs of applying BCCR in LTE. We further
simulatively compare BCCR RA with the state-of-the-art RA techniques, and
demonstrate its advantages in terms of delay and throughput.
</dc:description>
 <dc:description>Comment: Accepted for presentation in IEEE International Symposium on
  Personal, Indoor and Mobile Radio Communications (PIMRC) 2017</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02813</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BlitzNet: A Real-Time Deep Network for Scene Understanding</dc:title>
 <dc:creator>Dvornik, Nikita</dc:creator>
 <dc:creator>Shmelkov, Konstantin</dc:creator>
 <dc:creator>Mairal, Julien</dc:creator>
 <dc:creator>Schmid, Cordelia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Real-time scene understanding has become crucial in many applications such as
autonomous driving. In this paper, we propose a deep architecture, called
BlitzNet, that jointly performs object detection and semantic segmentation in
one forward pass, allowing real-time computations. Besides the computational
gain of having a single network to perform several tasks, we show that object
detection and semantic segmentation benefit from each other in terms of
accuracy. Experimental results for VOC and COCO datasets show state-of-the-art
performance for object detection and segmentation among real time systems.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02816</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Passivity-based Concurrent Whole-Body Control (cWBC) of Persistently
  Interacting Human-Exoskeleton Systems</dc:title>
 <dc:creator>Moro, Federico L.</dc:creator>
 <dc:creator>Iannacci, Niccol&#xf2;</dc:creator>
 <dc:creator>Legnani, Giovanni</dc:creator>
 <dc:creator>Tosatti, Lorenzo Molinari</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a concurrent whole-body control (cWBC) for
human-exoskeleton systems that are tightly coupled at a Cartesian level (e.g.,
feet, hands, torso). The exoskeleton generates joint torques that i) cancel the
effects of gravity on the coupled system, ii) perform a primary task (e.g.,
maintaining the balance of the system), and iii) exploit the kinematic
redundancy of the system to amplify the forces exerted by the human operator.
The coupled dynamic system is demonstrated to be passive, as its overall energy
always goes dissipated until a minimum is reached. The proposed method is
designed specifically to control exoskeletons for power augmentation worn by
healthy operators in applications such as manufacturing, as it allows to
increase the worker's capabilities, therefore reducing the risk of injuries.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02825</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mutual Visibility by Robots with Persistent Memory</dc:title>
 <dc:creator>Bhagat, Subhash</dc:creator>
 <dc:creator>Mukhopadhyaya, Krishnendu</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper addresses the mutual visibility problem for a set of
semi-synchronous, opaque robots occupying distinct positions in the Euclidean
plane. Since robots are opaque, if three robots lie on a line, the middle robot
obstructs the visions of the two other robots. The mutual visibility problem
asks the robots to coordinate their movements to form a configuration, within
finite time and without collision, in which no three robots are collinear.
Robots are endowed with a constant bits of persistent memory. In this work, we
consider the FSTATE computational model in which the persistent memory is used
by the robots only to remember their previous internal states. Except from this
persistent memory, robots are oblivious i.e., they do not carry forward any
other information from their previous computational cycles. The paper presents
a distributed algorithm to solve the mutual visibility problem for a set of
semi-synchronous robots using only 1 bit of persistent memory. The proposed
algorithm does not impose any other restriction on the capability of the robots
and guarantees collision-free movements for the robots.
</dc:description>
 <dc:description>Comment: 10</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02831</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anveshak - A Groundtruth Generation Tool for Foreground Regions of
  Document Images</dc:title>
 <dc:creator>Dey, Soumyadeep</dc:creator>
 <dc:creator>Mukherjee, Jayanta</dc:creator>
 <dc:creator>Sural, Shamik</dc:creator>
 <dc:creator>Nandedkar, Amit Vijay</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a graphical user interface based groundtruth generation tool in
this paper. Here, annotation of an input document image is done based on the
foreground pixels. Foreground pixels are grouped together with user interaction
to form labeling units. These units are then labeled by the user with the user
defined labels. The output produced by the tool is an image with an XML file
containing its metadata information. This annotated data can be further used in
different applications of document image analysis.
</dc:description>
 <dc:description>Comment: Accepted in DAR 2016</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02831</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-68124-5_22</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02835</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ExaGeoStat: A High Performance Unified Framework for Geostatistics on
  Manycore Systems</dc:title>
 <dc:creator>Abdulah, Sameh</dc:creator>
 <dc:creator>Ltaief, Hatem</dc:creator>
 <dc:creator>Sun, Ying</dc:creator>
 <dc:creator>Genton, Marc G.</dc:creator>
 <dc:creator>Keyes, David E.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present ExaGeoStat, a high performance framework for geospatial statistics
in climate and environment modeling. In contrast to simulation based on partial
differential equations derived from first-principles modeling, ExaGeoStat
employs a statistical model based on the evaluation of the Gaussian
log-likelihood function, which operates on a large dense covariance matrix.
Generated by the parametrizable Matern covariance function, the resulting
matrix is symmetric and positive definite. The computational tasks involved
during the evaluation of the Gaussian log-likelihood function become daunting
as the number n of geographical locations grows, as O(n2) storage and O(n3)
operations are required. While many approximation methods have been devised
from the side of statistical modeling to ameliorate these polynomial
complexities, we are interested here in the complementary approach of
evaluating the exact algebraic result by exploiting advances in solution
algorithms and many-core computer architectures. Using state-of-the-art high
performance dense linear algebra libraries associated with various leading edge
parallel architectures (Intel KNLs, NVIDIA GPUs, and distributed-memory
systems), ExaGeoStat raises the game for statistical applications from climate
and environmental science. ExaGeoStat provides a reference evaluation of
statistical parameters, with which to assess the validity of the various
approaches based on approximation. The framework takes a first step in the
merger of large-scale data analytics and extreme computing for geospatial
statistical applications, to be followed by additional complexity reducing
improvements from the solver side that can be implemented under the same
interface. Thus, a single uncompromised statistical model can ultimately be
executed in a wide variety of emerging exascale environments.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures,</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02837</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SPLODE: Semi-Probabilistic Point and Line Odometry with Depth Estimation
  from RGB-D Camera Motion</dc:title>
 <dc:creator>Proen&#xe7;a, Pedro F.</dc:creator>
 <dc:creator>Gao, Yang</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Active depth cameras suffer from several limitations, which cause incomplete
and noisy depth maps, and may consequently affect the performance of RGB-D
Odometry. To address this issue, this paper presents a visual odometry method
based on point and line features that leverages both measurements from a depth
sensor and depth estimates from camera motion. Depth estimates are generated
continuously by a probabilistic depth estimation framework for both types of
features to compensate for the lack of depth measurements and inaccurate
feature depth associations. The framework models explicitly the uncertainty of
triangulating depth from both point and line observations to validate and
obtain precise estimates. Furthermore, depth measurements are exploited by
propagating them through a depth map registration module and using a
frame-to-frame motion estimation method that considers 3D-to-2D and 2D-to-3D
reprojection errors, independently. Results on RGB-D sequences captured on
large indoor and outdoor scenes, where depth sensor limitations are critical,
show that the combination of depth measurements and estimates through our
approach is able to overcome the absence and inaccuracy of depth measurements.
</dc:description>
 <dc:description>Comment: IROS 2017</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02838</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoupled Learning of Environment Characteristics for Safe Exploration</dc:title>
 <dc:creator>Van Molle, Pieter</dc:creator>
 <dc:creator>Verbelen, Tim</dc:creator>
 <dc:creator>Bohez, Steven</dc:creator>
 <dc:creator>Leroux, Sam</dc:creator>
 <dc:creator>Simoens, Pieter</dc:creator>
 <dc:creator>Dhoedt, Bart</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Reinforcement learning is a proven technique for an agent to learn a task.
However, when learning a task using reinforcement learning, the agent cannot
distinguish the characteristics of the environment from those of the task. This
makes it harder to transfer skills between tasks in the same environment.
Furthermore, this does not reduce risk when training for a new task. In this
paper, we introduce an approach to decouple the environment characteristics
from the task-specific ones, allowing an agent to develop a sense of survival.
We evaluate our approach in an environment where an agent must learn a sequence
of collection tasks, and show that decoupled learning allows for a safer
utilization of prior knowledge.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, ICML 2017 workshop on Reliable Machine Learning
  in the Wild</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02840</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Speaker Diarization using Deep Recurrent Convolutional Neural Networks
  for Speaker Embeddings</dc:title>
 <dc:creator>Cyrta, Pawel</dc:creator>
 <dc:creator>Trzci&#x144;ski, Tomasz</dc:creator>
 <dc:creator>Stokowiec, Wojciech</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper we propose a new method of speaker diarization that employs a
deep learning architecture to learn speaker embeddings. In contrast to the
traditional approaches that build their speaker embeddings using manually
hand-crafted spectral features, we propose to train for this purpose a
recurrent convolutional neural network applied directly on magnitude
spectrograms. To compare our approach with the state of the art, we collect and
release for the public an additional dataset of over 6 hours of fully annotated
broadcast material. The results of our evaluation on the new dataset and three
other benchmark datasets show that our proposed method significantly
outperforms the competitors and reduces diarization error rate by a large
margin of over 30% with respect to the baseline.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02840</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-67220-5_10</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02843</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Multi-Object Tracking Using CNN-based Single Object Tracker with
  Spatial-Temporal Attention Mechanism</dc:title>
 <dc:creator>Chu, Qi</dc:creator>
 <dc:creator>Ouyang, Wanli</dc:creator>
 <dc:creator>Li, Hongsheng</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:creator>Liu, Bin</dc:creator>
 <dc:creator>Yu, Nenghai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a CNN-based framework for online MOT. This
framework utilizes the merits of single object trackers in adapting appearance
models and searching for target in the next frame. Simply applying single
object tracker for MOT will encounter the problem in computational efficiency
and drifted results caused by occlusion. Our framework achieves computational
efficiency by sharing features and using ROI-Pooling to obtain individual
features for each target. Some online learned target-specific CNN layers are
used for adapting the appearance model for each target. In the framework, we
introduce spatial-temporal attention mechanism (STAM) to handle the drift
caused by occlusion and interaction among targets. The visibility map of the
target is learned and used for inferring the spatial attention map. The spatial
attention map is then applied to weight the features. Besides, the occlusion
status can be estimated from the visibility map, which controls the online
updating process via weighted loss on training samples with different occlusion
statuses in different frames. It can be considered as temporal attention
mechanism. The proposed algorithm achieves 34.3% and 46.0% in MOTA on
challenging MOT15 and MOT16 benchmark dataset respectively.
</dc:description>
 <dc:description>Comment: Accepted at International Conference on Computer Vision (ICCV) 2017</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02844</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A simple way to reduce factorization problems to SAT</dc:title>
 <dc:creator>Maran, Davide</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03D15, 68Q15</dc:subject>
 <dc:description>  As Cook-Levin theorem showed, every NP problem can be reduced to SAT in
polynomial time. In this paper I show a simpler and more efficent method to
reduce some factorization problems to the satisfability of a boolean formula.
</dc:description>
 <dc:date>2017-06-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02845</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Path Planning with Divergence-Based Distance Functions</dc:title>
 <dc:creator>Chen, Renjie</dc:creator>
 <dc:creator>Gotsman, Craig</dc:creator>
 <dc:creator>Hormann, Kai</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Distance functions between points in a domain are sometimes used to
automatically plan a gradient-descent path towards a given target point in the
domain, avoiding obstacles that may be present. A key requirement from such
distance functions is the absence of spurious local minima, which may foil such
an approach, and this has led to the common use of harmonic potential
functions. Based on the planar Laplace operator, the potential function
guarantees the absence of spurious minima, but is well known to be slow to
numerically compute and prone to numerical precision issues. To alleviate the
first of these problems, we propose a family of novel divergence distances.
These are based on f-divergence of the Poisson kernel of the domain. We define
the divergence distances and compare them to the harmonic potential function
and other related distance functions.
  Our first result is theoretical: We show that the family of divergence
distances are equivalent to the harmonic potential function on simply-connected
domains, namely generate paths which are identical to those generated by the
potential function. The proof is based on the concept of conformal invariance.
  Our other results are more practical and relate to two special cases of
divergence distances, one based on the Kullback-Leibler divergence and one
based on the total variation divergence. We show that using divergence
distances instead of the potential function and other distances has a
significant computational advantage, as, following a pre-processing stage, they
may be computed up to an order of magnitude faster than the others when taking
advantage of certain sparsity properties of the Poisson kernel. Furthermore,
the computation is &quot;embarrassingly parallel&quot;, so may be implemented on a GPU
with up to three orders of magnitude speedup.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02851</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Inconsistency in Argument Graphs</dc:title>
 <dc:creator>Hunter, Anthony</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  There have been a number of developments in measuring inconsistency in
logic-based representations of knowledge. In contrast, the development of
inconsistency measures for computational models of argument has been limited.
To address this shortcoming, this paper provides a general framework for
measuring inconsistency in abstract argumentation, together with some proposals
for specific measures, and a consideration of measuring inconsistency in
logic-based instantiations of argument graphs, including a review of some
existing proposals and a consideration of how existing logic-based measures of
inconsistency can be applied.
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02851</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02859</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Optimization of QoE and Fairness Through Network Assisted Adaptive
  Mobile Video Streaming</dc:title>
 <dc:creator>Mehrabi, Abbas</dc:creator>
 <dc:creator>Siekkinen, Matti</dc:creator>
 <dc:creator>Yl&#xe4;-J&#xe4;&#xe4;ski, Antti</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  MPEG has recently proposed Server and Network Assisted Dynamic Adaptive
Streaming over HTTP (SAND-DASH) for video streaming over the Internet. In
contrast to the purely client-based video streaming in which each client makes
its own decision to adjust its bitrate, SAND-DASH enables a group of
simultaneous clients to select their bitrates in a coordinated fashion in order
to improve resource utilization and quality of experience. In this paper, we
study the performance of such an adaptation strategy compared to the
traditional approach with large number of clients having mobile Internet
access. We propose a multi-servers multi-coordinators (MSs-MCs) framework to
model groups of remote clients accessing video content replicated to spatially
distributed edge servers. We then formulate an optimization problem to maximize
jointly the QoE of individual clients, proportional fairness in allocating the
limited resources of base stations as well as balancing the utilized resources
among multiple serves. We then present an efficient heuristic-based solution to
the problem and perform simulations in order to explore parameter space of the
scheme as well as to compare the performance to purely client-based DASH.
</dc:description>
 <dc:description>Comment: Accepted, IEEE International Conference on Wireless and Mobile
  Computing, Networking and Communications (WiMob) 2017</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02859</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02861</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Cell-Aware Opportunistic Random Access for Machine-Type
  Communications</dc:title>
 <dc:creator>Lin, Huifa</dc:creator>
 <dc:creator>Shin, Won-Yong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Due to the difficulty of coordination in multi-cell random access, it is a
practical challenge how to achieve the optimal throughput with decentralized
transmission. In this paper, we propose a decentralized multi-cell-aware
opportunistic random access (MA-ORA) protocol that achieves the optimal
throughput scaling in an ultra-dense $K$-cell random access network with one
access point (AP) and $N$ users in each cell, which is suited for machine-type
communications. Unlike opportunistic scheduling for cellular multiple access
where users are selected by base stations, under our MA-ORA protocol, each user
opportunistically transmits with a predefined physical layer data rate in a
decentralized manner if the desired signal power to the serving AP is
sufficiently large and the generating interference leakage power to the other
APs is sufficiently small (i.e., two threshold conditions are fulfilled). As a
main result, it is proved that the aggregate throughput scales as
$\frac{K}{e}(1-\epsilon) \log (\textsf{snr} \log N)$ in a high signal-to-noise
ratio (SNR) regime if $N$ scales faster than
$\textsf{snr}^{\frac{K-1}{1-\delta}}$ for small constants $\epsilon, \delta&gt;0$.
Our analytical result is validated by computer simulations. In addition,
numerical evaluation confirms that under a practical setting, the proposed
MA-ORA protocol outperforms conventional opportunistic random access protocols
in terms of throughput.
</dc:description>
 <dc:description>Comment: 17 pages, 9 figures, Submitted to the IEEE Transactions on Mobile
  Computing for possible publication</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02862</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WebVision Database: Visual Learning and Understanding from Web Data</dc:title>
 <dc:creator>Li, Wen</dc:creator>
 <dc:creator>Wang, Limin</dc:creator>
 <dc:creator>Li, Wei</dc:creator>
 <dc:creator>Agustsson, Eirikur</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present a study on learning visual recognition models from
large scale noisy web data. We build a new database called WebVision, which
contains more than $2.4$ million web images crawled from the Internet by using
queries generated from the 1,000 semantic concepts of the benchmark ILSVRC 2012
dataset. Meta information along with those web images (e.g., title,
description, tags, etc.) are also crawled. A validation set and test set
containing human annotated images are also provided to facilitate algorithmic
development. Based on our new database, we obtain a few interesting
observations: 1) the noisy web images are sufficient for training a good deep
CNN model for visual recognition; 2) the model learnt from our WebVision
database exhibits comparable or even better generalization ability than the one
trained from the ILSVRC 2012 dataset when being transferred to new datasets and
tasks; 3) a domain adaptation issue (a.k.a., dataset bias) is observed, which
means the dataset can be used as the largest benchmark dataset for visual
domain adaptation. Our new WebVision database and relevant studies in this work
would benefit the advance of learning state-of-the-art visual models with
minimum supervision based on web data.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02863</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CoupleNet: Coupling Global Structure with Local Parts for Object
  Detection</dc:title>
 <dc:creator>Zhu, Yousong</dc:creator>
 <dc:creator>Zhao, Chaoyang</dc:creator>
 <dc:creator>Wang, Jinqiao</dc:creator>
 <dc:creator>Zhao, Xu</dc:creator>
 <dc:creator>Wu, Yi</dc:creator>
 <dc:creator>Lu, Hanqing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The region-based Convolutional Neural Network (CNN) detectors such as Faster
R-CNN or R-FCN have already shown promising results for object detection by
combining the region proposal subnetwork and the classification subnetwork
together. Although R-FCN has achieved higher detection speed while keeping the
detection performance, the global structure information is ignored by the
position-sensitive score maps. To fully explore the local and global
properties, in this paper, we propose a novel fully convolutional network,
named as CoupleNet, to couple the global structure with local parts for object
detection. Specifically, the object proposals obtained by the Region Proposal
Network (RPN) are fed into the the coupling module which consists of two
branches. One branch adopts the position-sensitive RoI (PSRoI) pooling to
capture the local part information of the object, while the other employs the
RoI pooling to encode the global and context information. Next, we design
different coupling strategies and normalization ways to make full use of the
complementary advantages between the global and local branches. Extensive
experiments demonstrate the effectiveness of our approach. We achieve
state-of-the-art results on all three challenging datasets, i.e. a mAP of 82.7%
on VOC07, 80.4% on VOC12, and 34.4% on COCO. Codes will be made publicly
available.
</dc:description>
 <dc:description>Comment: Accepted by ICCV 2017</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02867</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulated Annealing with Levy Distribution for Fast Matrix
  Factorization-Based Collaborative Filtering</dc:title>
 <dc:creator>Shehata, Mostafa A.</dc:creator>
 <dc:creator>Nassef, Mohammad</dc:creator>
 <dc:creator>Badr, Amr A.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Matrix factorization is one of the best approaches for collaborative
filtering, because of its high accuracy in presenting users and items latent
factors. The main disadvantages of matrix factorization are its complexity, and
being very hard to be parallelized, specially with very large matrices. In this
paper, we introduce a new method for collaborative filtering based on Matrix
Factorization by combining simulated annealing with levy distribution. By using
this method, good solutions are achieved in acceptable time with low
computations, compared to other methods like stochastic gradient descent,
alternating least squares, and weighted non-negative matrix factorization.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02872</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy Preserving Face Retrieval in the Cloud for Mobile Users</dc:title>
 <dc:creator>Jin, Xin</dc:creator>
 <dc:creator>Ge, Shiming</dc:creator>
 <dc:creator>Song, Chenggen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Recently, cloud storage and processing have been widely adopted. Mobile users
in one family or one team may automatically backup their photos to the same
shared cloud storage space. The powerful face detector trained and provided by
a 3rd party may be used to retrieve the photo collection which contains a
specific group of persons from the cloud storage server. However, the privacy
of the mobile users may be leaked to the cloud server providers. In the
meanwhile, the copyright of the face detector should be protected. Thus, in
this paper, we propose a protocol of privacy preserving face retrieval in the
cloud for mobile users, which protects the user photos and the face detector
simultaneously. The cloud server only provides the resources of storage and
computing and can not learn anything of the user photos and the face detector.
We test our protocol inside several families and classes. The experimental
results reveal that our protocol can successfully retrieve the proper photos
from the cloud server and protect the user photos and the face detector.
</dc:description>
 <dc:description>Comment: Abuse Preventive Data Mining (APDM2017, IJCAI Workshop), 19-25
  August, 2017 Melbourne, Australia</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02884</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting and Evaluating Software Model Growth in the Automotive
  Industry</dc:title>
 <dc:creator>Schroeder, Jan</dc:creator>
 <dc:creator>Berger, Christian</dc:creator>
 <dc:creator>Knauss, Alessia</dc:creator>
 <dc:creator>Preenja, Harri</dc:creator>
 <dc:creator>Ali, Mohammad</dc:creator>
 <dc:creator>Staron, Miroslaw</dc:creator>
 <dc:creator>Herpel, Thomas</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The size of a software artifact influences the software quality and impacts
the development process. In industry, when software size exceeds certain
thresholds, memory errors accumulate and development tools might not be able to
cope anymore, resulting in a lengthy program start up times, failing builds, or
memory problems at unpredictable times. Thus, foreseeing critical growth in
software modules meets a high demand in industrial practice. Predicting the
time when the size grows to the level where maintenance is needed prevents
unexpected efforts and helps to spot problematic artifacts before they become
critical.
  Although the amount of prediction approaches in literature is vast, it is
unclear how well they fit with prerequisites and expectations from practice. In
this paper, we perform an industrial case study at an automotive manufacturer
to explore applicability and usability of prediction approaches in practice. In
a first step, we collect the most relevant prediction approaches from
literature, including both, approaches using statistics and machine learning.
Furthermore, we elicit expectations towards predictions from practitioners
using a survey and stakeholder workshops. At the same time, we measure software
size of 48 software artifacts by mining four years of revision history,
resulting in 4,547 data points. In the last step, we assess the applicability
of state-of-the-art prediction approaches using the collected data by
systematically analyzing how well they fulfill the practitioners' expectations.
  Our main contribution is a comparison of commonly used prediction approaches
in a real world industrial setting while considering stakeholder expectations.
We show that the approaches provide significantly different results regarding
prediction accuracy and that the statistical approaches fit our data best.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02888</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-message Authentication over Noisy Channel with Secure Channel
  Codes</dc:title>
 <dc:creator>Chen, Dajiang</dc:creator>
 <dc:creator>Zhang, Ning</dc:creator>
 <dc:creator>Cheng, Nan</dc:creator>
 <dc:creator>Zhang, Kuan</dc:creator>
 <dc:creator>Yang, Kan</dc:creator>
 <dc:creator>Qin, Zhiguang</dc:creator>
 <dc:creator>Xuemin</dc:creator>
 <dc:creator>Shen</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate multi-message authentication to combat
adversaries with infinite computational capacity. An authentication framework
over a wiretap channel $(W_1,W_2)$ is proposed to achieve information-theoretic
security with the same key. The proposed framework bridges the two research
areas in physical (PHY) layer security: secure transmission and message
authentication. Specifically, the sender Alice first transmits message $M$ to
the receiver Bob over $(W_1,W_2)$ with an error correction code; then Alice
employs a hash function (i.e., $\varepsilon$-AWU$_2$ hash functions) to
generate a message tag $S$ of message $M$ using key $K$, and encodes $S$ to a
codeword $X^n$ by leveraging an existing strongly secure channel coding with
exponentially small (in code length $n$) average probability of error; finally,
Alice sends $X^n$ over $(W_1,W_2)$ to Bob who authenticates the received
messages. We develop a theorem regarding the requirements/conditions for the
authentication framework to be information-theoretic secure for authenticating
a polynomial number of messages in terms of $n$. Based on this theorem, we
propose an authentication protocol that can guarantee the security
requirements, and prove its authentication rate can approach infinity when $n$
goes to infinity. Furthermore, we design and implement an efficient and
feasible authentication protocol over binary symmetric wiretap channel (BSWC)
by using \emph{Linear Feedback Shifting Register} based (LFSR-based) hash
functions and strong secure polar code. Through extensive experiments, it is
demonstrated that the proposed protocol can achieve low time cost, high
authentication rate, and low authentication error rate.
</dc:description>
 <dc:description>Comment: 15 Pages, 15figures</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02893</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Client-Side Routing-Agnostic Gateway Selection for heterogeneous
  Wireless Mesh Networks</dc:title>
 <dc:creator>Dimogerontakis, Emmanouil</dc:creator>
 <dc:creator>Neto, Jo&#xe3;o</dc:creator>
 <dc:creator>Meseguer, Roc</dc:creator>
 <dc:creator>Navarro, Leandro</dc:creator>
 <dc:creator>Veiga, Lu&#xed;s</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Citizens develop Wireless Mesh Networks (WMN) in many areas as an alternative
or their only way for local interconnection and access to the Internet. This
access is often achieved through the use of several shared web proxy gateways.
These network infrastructures consist of heterogeneous technologies and combine
diverse routing protocols. Network-aware state-of-art proxy selection schemes
for WMNs do not work in this heterogeneous environment. We developed a
client-side gateway selection mechanism that optimizes the client-gateway
selection, agnostic to underlying infrastructure and protocols, requiring no
modification of proxies nor the underlying network. The choice is sensitive to
network congestion and proxy load, without requiring a minimum number of
participating nodes. Extended Vivaldi network coordinates are used to estimate
client-proxy network performance. The load of each proxy is estimated passively
by collecting the Time-to-First-Byte of HTTP requests, and shared across
clients. Our proposal was evaluated experimentally with clients and proxies
deployed in guifi.net, the largest community wireless network in the world. Our
selection mechanism avoids proxies with heavy load and slow internal network
paths, with overhead linear to the number of clients and proxies.
</dc:description>
 <dc:description>Comment: IFIP/IEEE International Symposium on Integrated Network Management
  (IM) Date: 05/2017, Lisbon, Portugal</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02893</dc:identifier>
 <dc:identifier>doi:10.23919/INM.2017.7987301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02895</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interacting with Acoustic Simulation and Fabrication</dc:title>
 <dc:creator>Li, Dingzeyu</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Incorporating accurate physics-based simulation into interactive design tools
is challenging. However, adding the physics accurately becomes crucial to
several emerging technologies. For example, in virtual/augmented reality
(VR/AR) videos, the faithful reproduction of surrounding audios is required to
bring the immersion to the next level. Similarly, as personal fabrication is
made possible with accessible 3D printers, more intuitive tools that respect
the physical constraints can help artists to prototype designs. One main hurdle
is the sheer amount of computation complexity to accurately reproduce the
real-world phenomena through physics-based simulation. In my thesis research, I
develop interactive tools that implement efficient physics-based simulation
algorithms for automatic optimization and intuitive user interaction.
</dc:description>
 <dc:description>Comment: ACM UIST 2017 Doctoral Symposium</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02895</dc:identifier>
 <dc:identifier>doi:10.1145/3131785.3131842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02898</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An evaluation of large-scale methods for image instance and class
  discovery</dc:title>
 <dc:creator>Douze, Matthijs</dc:creator>
 <dc:creator>J&#xe9;gou, Herv&#xe9;</dc:creator>
 <dc:creator>Johnson, Jeff</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  This paper aims at discovering meaningful subsets of related images from
large image collections without annotations. We search groups of images related
at different levels of semantic, i.e., either instances or visual classes.
While k-means is usually considered as the gold standard for this task, we
evaluate and show the interest of diffusion methods that have been neglected by
the state of the art, such as the Markov Clustering algorithm.
  We report results on the ImageNet and the Paris500k instance dataset, both
enlarged with images from YFCC100M. We evaluate our methods with a labelling
cost that reflects how much effort a human would require to correct the
generated clusters.
  Our analysis highlights several properties. First, when powered with an
efficient GPU implementation, the cost of the discovery process is small
compared to computing the image descriptors, even for collections as large as
100 million images. Second, we show that descriptions selected for instance
search improve the discovery of object classes. Third, the Markov Clustering
technique consistently outperforms other methods; to our knowledge it has never
been considered in this large scale scenario.
</dc:description>
 <dc:description>Comment: Published at ACM Multimedia workshop</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02900</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Do People Differ? A Social Media Approach</dc:title>
 <dc:creator>Wong, Vincent</dc:creator>
 <dc:creator>Bar-Yam, Yaneer</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Research from a variety of fields including psychology and linguistics have
found correlations and patterns in personal attributes and behavior, but
efforts to understand the broader heterogeneity in human behavior have not yet
integrated these approaches and perspectives with a cohesive methodology. Here
we extract patterns in behavior and relate those patterns together in a
high-dimensional picture. We use dimension reduction to analyze word usage in
text data from the online discussion platform Reddit. We find that pronouns can
be used to characterize the space of the two most prominent dimensions that
capture the greatest differences in word usage, even though pronouns were not
included in the determination of those dimensions. These patterns overlap with
patterns of topics of discussion to reveal relationships between pronouns and
topics that can describe the user population. This analysis corroborates
findings from past research that have identified word use differences across
populations and synthesizes them relative to one another. We believe this is a
step toward understanding how differences between people are related to each
other.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02901</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transitive Invariance for Self-supervised Visual Representation Learning</dc:title>
 <dc:creator>Wang, Xiaolong</dc:creator>
 <dc:creator>He, Kaiming</dc:creator>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning visual representations with self-supervised learning has become
popular in computer vision. The idea is to design auxiliary tasks where labels
are free to obtain. Most of these tasks end up providing data to learn specific
kinds of invariance useful for recognition. In this paper, we propose to
exploit different self-supervised approaches to learn representations invariant
to (i) inter-instance variations (two objects in the same class should have
similar features) and (ii) intra-instance variations (viewpoint, pose,
deformations, illumination, etc). Instead of combining two approaches with
multi-task learning, we argue to organize and reason the data with multiple
variations. Specifically, we propose to generate a graph with millions of
objects mined from hundreds of thousands of videos. The objects are connected
by two types of edges which correspond to two types of invariance: &quot;different
instances but a similar viewpoint and category&quot; and &quot;different viewpoints of
the same instance&quot;. By applying simple transitivity on the graph with these
edges, we can obtain pairs of images exhibiting richer visual invariance. We
use this data to train a Triplet-Siamese network with VGG16 as the base
architecture and apply the learned representations to different recognition
tasks. For object detection, we achieve 63.2% mAP on PASCAL VOC 2007 using Fast
R-CNN (compare to 67.3% with ImageNet pre-training). For the challenging COCO
dataset, our method is surprisingly close (23.5%) to the ImageNet-supervised
counterpart (24.4%) using the Faster R-CNN framework. We also show that our
network can perform significantly better than the ImageNet network in the
surface normal estimation task.
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02906</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementing $\Diamond P$ with Bounded Messages on a Network of ADD
  Channels</dc:title>
 <dc:creator>Kumar, Saptaparni</dc:creator>
 <dc:creator>Welch, Jennifer</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present an implementation of the eventually perfect failure detector
($\Diamond P$) from the original hierarchy of the Chandra-Toueg oracles on an
arbitrary partitionable network composed of unreliable channels that can lose
and reorder messages. Prior implementations of $\Diamond P$ have assumed
different partially synchronous models ranging from bounded point-to-point
message delay and reliable communication to unbounded message size and known
network topologies. We implement $\Diamond P$ under very weak assumptions on an
arbitrary, partitionable network composed of Average Delayed/Dropped (ADD)
channels to model unreliable communication. Unlike older implementations, our
failure detection algorithm uses bounded-sized messages to eventually detect
all nodes that are unreachable (crashed or disconnected) from it.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02906</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02910</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TPC Together with Overlapped Time Domain Multiplexing System Based on
  Turbo Structure</dc:title>
 <dc:creator>Zheng, Hao</dc:creator>
 <dc:creator>Xing, Mingjun</dc:creator>
 <dc:creator>Yue, Yutao</dc:creator>
 <dc:creator>Li, Xue</dc:creator>
 <dc:creator>Li, Daoben</dc:creator>
 <dc:creator>Ji, Chunlin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Overlapped time domain multiplexing (OvTDM) is a novel technique for
utilizing inter-symbol interference (ISI) to benefit a communication system. We
implement the OvTDM technique based on turbo structure and associate a turbo
product code (TPC) to construct a novel coded turbo-structure OvTDM system. Two
schemes of the iterative receiver and soft input and soft output (SISO)
decoding algorithms are presented. Simulation results show the advantage of
structures in this paper. In addition, an attractive transmission rate and
symbol efficiency of the designed system can also be observed.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02912</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>KeyXtract Twitter Model - An Essential Keywords Extraction Model for
  Twitter Designed using NLP Tools</dc:title>
 <dc:creator>Weerasooriya, Tharindu</dc:creator>
 <dc:creator>Perera, Nandula</dc:creator>
 <dc:creator>Liyanage, S. R.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Since a tweet is limited to 140 characters, it is ambiguous and difficult for
traditional Natural Language Processing (NLP) tools to analyse. This research
presents KeyXtract which enhances the machine learning based Stanford CoreNLP
Part-of-Speech (POS) tagger with the Twitter model to extract essential
keywords from a tweet. The system was developed using rule-based parsers and
two corpora. The data for the research was obtained from a Twitter profile of a
telecommunication company. The system development consisted of two stages. At
the initial stage, a domain specific corpus was compiled after analysing the
tweets. The POS tagger extracted the Noun Phrases and Verb Phrases while the
parsers removed noise and extracted any other keywords missed by the POS
tagger. The system was evaluated using the Turing Test. After it was tested and
compared against Stanford CoreNLP, the second stage of the system was developed
addressing the shortcomings of the first stage. It was enhanced using Named
Entity Recognition and Lemmatization. The second stage was also tested using
the Turing test and its pass rate increased from 50.00% to 83.33%. The
performance of the final system output was measured using the F1 score.
Stanford CoreNLP with the Twitter model had an average F1 of 0.69 while the
improved system had a F1 of 0.77. The accuracy of the system could be improved
by using a complete domain specific corpus. Since the system used linguistic
features of a sentence, it could be applied to other NLP tools.
</dc:description>
 <dc:description>Comment: 7 Pages, 5 Figures, Proceedings of the 10th KDU International
  Research Conference</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02917</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Dynamics of Learning Restricted Boltzmann Machines</dc:title>
 <dc:creator>Decelle, Aur&#xe9;lien</dc:creator>
 <dc:creator>Fissore, Giancarlo</dc:creator>
 <dc:creator>Furtlehner, Cyril</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The Restricted Boltzmann Machine (RBM), an important tool used in machine
learning in particular for unsupervized learning tasks, is investigated from
the perspective of its spectral properties. Starting from empirical
observations, we propose a generic statistical ensemble for the weight matrix
of the RBM and characterize its mean evolution. This let us show how in the
linear regime, in which the RBM is found to operate at the beginning of the
training, the statistical properties of the data drive the selection of the
unstable modes of the weight matrix. A set of equations characterizing the
non-linear regime is then derived, unveiling in some way how the selected modes
interact in later stages of the learning procedure and defining a deterministic
learning curve for the RBM.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02917</dc:identifier>
 <dc:identifier>EPL 119 (2017) 60001</dc:identifier>
 <dc:identifier>doi:10.1209/0295-5075/119/60001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02918</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Tensor Memory Hypothesis</dc:title>
 <dc:creator>Tresp, Volker</dc:creator>
 <dc:creator>Ma, Yunpu</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We discuss memory models which are based on tensor decompositions using
latent representations of entities and events. We show how episodic memory and
semantic memory can be realized and discuss how new memory traces can be
generated from sensory input: Existing memories are the basis for perception
and new memories are generated via perception. We relate our mathematical
approach to the hippocampal memory indexing theory. We describe the first
detailed mathematical models for the complete processing pipeline from sensory
input and its semantic decoding, i.e., perception, to the formation of episodic
and semantic memories and their declarative semantic decodings. Our main
hypothesis is that perception includes an active semantic decoding process,
which relies on latent representations of entities and predicates, and that
episodic and semantic memories depend on the same decoding process. We
contribute to the debate between the leading memory consolidation theories,
i.e., the standard consolidation theory (SCT) and the multiple trace theory
(MTT). The latter is closely related to the complementary learning systems
(CLS) framework. In particular, we show explicitly how episodic memory can
teach the neocortex to form a semantic memory, which is a core issue in MTT and
CLS.
</dc:description>
 <dc:description>Comment: Presented at MLINI-2016 workshop, 2016 (arXiv:1701.01437) Report-no:
  MLINI/2016/06</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02921</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymmetric Quantum Codes on Toric Surfaces</dc:title>
 <dc:creator>Hansen, Johan P.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>14M25, 11T71, 68P30</dc:subject>
 <dc:description>  Asymmetric quantum error-correcting codes are quantum codes defined over
biased quantum channels: qubit-flip and phase-shift errors may have equal or
different probabilities. The code construction is the Calderbank-Shor-Steane
construction based on two linear codes.
  We present families of toric surfaces, toric codes and associated asymmetric
quantum error-correcting codes.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02922</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Long-endurance Flight: Design and Implementation of a
  Variable-pitch Gasoline-engine Quadrotor</dc:title>
 <dc:creator>Pang, T.</dc:creator>
 <dc:creator>Peng, K.</dc:creator>
 <dc:creator>Lin, F.</dc:creator>
 <dc:creator>Chen, B. M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Majority of today's fixed-pitch, electric-power quadrotors have short flight
endurance ($&lt;$ 1 hour) which greatly limits their applications. This paper
presents a design methodology for the construction of a long-endurance
quadrotor using variable-pitch rotors and a gasoline-engine. The methodology
consists of three aspects. Firstly, the rotor blades and gasoline engine are
selected as a pair, so that sufficient lift can be comfortably provided by the
engine. Secondly, drivetrain and airframe are designed. Major challenges
include airframe vibration minimization and power transmission from one engine
to four rotors while keeping alternate rotors contra-rotating. Lastly, a PD
controller is tuned to facilitate preliminary flight tests. The methodology has
been verified by the construction and successful flight of our gasoline
quadrotor prototype, which is designed to have a flight time of 2 to 3 hours
and a maximum take-off weight of 10 kg.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02922</dc:identifier>
 <dc:identifier>Control and Automation (ICCA), 2016 12th IEEE International
  Conference on, page 767-772</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02924</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Medication non adherence: finding solutions through design thinking
  approach</dc:title>
 <dc:creator>Iurchenko, Anna</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Medical non-adherence increasingly is recognized as a major medical health
problem. Approximately 50% of patients do not take their medications as
prescribed and such poor adherence has been shown to result in complications,
death, and increased health care costs. This problem becomes even more
significant for patients with chronic illness and those who need to take
medications lifetime, like transplant patients. Studies show that one-half of
rejection episodes and 15% of graft losses happen due to immunosuppression
medications non-adherence. This article explores factors that have an impact on
non-compliant behavior among transplant patients: patient factors, illness
factor, therapeutic regimen factors. Using user-centered design thinking
approach a set of hypotheses are defined and discussed strategies to enhance
adherence by using mobile technology and gamification techniques.
</dc:description>
 <dc:description>Comment: 4 pages, 1 table</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02932</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SUBIC: A supervised, structured binary code for image search</dc:title>
 <dc:creator>Jain, Himalaya</dc:creator>
 <dc:creator>Zepeda, Joaquin</dc:creator>
 <dc:creator>P&#xe9;rez, Patrick</dc:creator>
 <dc:creator>Gribonval, R&#xe9;mi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  For large-scale visual search, highly compressed yet meaningful
representations of images are essential. Structured vector quantizers based on
product quantization and its variants are usually employed to achieve such
compression while minimizing the loss of accuracy. Yet, unlike binary hashing
schemes, these unsupervised methods have not yet benefited from the
supervision, end-to-end learning and novel architectures ushered in by the deep
learning revolution. We hence propose herein a novel method to make deep
convolutional neural networks produce supervised, compact, structured binary
codes for visual search. Our method makes use of a novel block-softmax
non-linearity and of batch-based entropy losses that together induce structure
in the learned encodings. We show that our method outperforms state-of-the-art
compact representations based on deep hashing or structured quantization in
single and cross-domain category retrieval, instance retrieval and
classification. We make our code and models publicly available online.
</dc:description>
 <dc:description>Comment: Accepted at ICCV 2017 (Spotlight)</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02934</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>D4M 3.0: Extended Database and Language Capabilities</dc:title>
 <dc:creator>Milechin, Lauren</dc:creator>
 <dc:creator>Gadepally, Vijay</dc:creator>
 <dc:creator>Samsi, Siddharth</dc:creator>
 <dc:creator>Kepner, Jeremy</dc:creator>
 <dc:creator>Chen, Alexander</dc:creator>
 <dc:creator>Hutchison, Dylan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The D4M tool was developed to address many of today's data needs. This tool
is used by hundreds of researchers to perform complex analytics on unstructured
data. Over the past few years, the D4M toolbox has evolved to support
connectivity with a variety of new database engines, including SciDB.
D4M-Graphulo provides the ability to do graph analytics in the Apache Accumulo
database. Finally, an implementation using the Julia programming language is
also now available. In this article, we describe some of our latest additions
to the D4M toolbox and our upcoming D4M 3.0 release. We show through
benchmarking and scaling results that we can achieve fast SciDB ingest using
the D4M-SciDB connector, that using Graphulo can enable graph algorithms on
scales that can be memory limited, and that the Julia implementation of D4M
achieves comparable performance or exceeds that of the existing MATLAB(R)
implementation.
</dc:description>
 <dc:description>Comment: IEEE HPEC 2017</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02934</dc:identifier>
 <dc:identifier>doi:10.1109/HPEC.2017.8091083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02937</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Massive Deep Neural Networks with the GraphBLAS</dc:title>
 <dc:creator>Kepner, Jeremy</dc:creator>
 <dc:creator>Kumar, Manoj</dc:creator>
 <dc:creator>Moreira, Jos&#xe9;</dc:creator>
 <dc:creator>Pattnaik, Pratap</dc:creator>
 <dc:creator>Serrano, Mauricio</dc:creator>
 <dc:creator>Tufo, Henry</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep Neural Networks (DNNs) have emerged as a core tool for machine learning.
The computations performed during DNN training and inference are dominated by
operations on the weight matrices describing the DNN. As DNNs incorporate more
stages and more nodes per stage, these weight matrices may be required to be
sparse because of memory limitations. The GraphBLAS.org math library standard
was developed to provide high performance manipulation of sparse weight
matrices and input/output vectors. For sufficiently sparse matrices, a sparse
matrix library requires significantly less memory than the corresponding dense
matrix implementation. This paper provides a brief description of the
mathematics underlying the GraphBLAS. In addition, the equations of a typical
DNN are rewritten in a form designed to use the GraphBLAS. An implementation of
the DNN is given using a preliminary GraphBLAS C library. The performance of
the GraphBLAS implementation is measured relative to a standard dense linear
algebra library implementation. For various sizes of DNN weight matrices, it is
shown that the GraphBLAS sparse implementation outperforms a BLAS dense
implementation as the weight matrix becomes sparser.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures, to appear in the 2017 IEEE High Performance
  Extreme Computing (HPEC) conference</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02937</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02938</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Formal Agent-based Simulation Modeling Framework of an AIDS
  Complex Adaptive System</dc:title>
 <dc:creator>Siddiqa, Amnah</dc:creator>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Pattern Formation and Solitons</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>K.4.2</dc:subject>
 <dc:description>  HIV/AIDS spread depends upon complex patterns of interaction among various
sub-sets emerging at population level. This added complexity makes it difficult
to study and model AIDS and its dynamics. AIDS is therefore a natural candidate
to be modeled using agent-based modeling, a paradigm well-known for modeling
Complex Adaptive Systems (CAS). While agent-based models are also well-known to
effectively model CAS, often times models can tend to be ambiguous and the use
of purely text-based specifications (such as ODD) can make models difficult to
be replicated. Previous work has shown how formal specification may be used in
conjunction with agent-based modeling to develop models of various CAS.
However, to the best of our knowledge, no such model has been developed in
conjunction with AIDS. In this paper, we present a Formal Agent-Based
Simulation modeling framework (FABS-AIDS) for an AIDS-based CAS. FABS-AIDS
employs the use of a formal specification model in conjunction with an
agent-based model to reduce ambiguity as well as improve clarity in the model
definition. The proposed model demonstrates the effectiveness of using formal
specification in conjunction with agent-based simulation for developing models
of CAS in general and, social network-based agent-based models, in particular.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02938</dc:identifier>
 <dc:identifier>International Journal of Agent Technologies and Systems (IJATS),
  5(3), 33-53 (2013)</dc:identifier>
 <dc:identifier>doi:10.4018/ijats.2013070103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02939</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence of Unregularized Online Learning Algorithms</dc:title>
 <dc:creator>Lei, Yunwen</dc:creator>
 <dc:creator>Shi, Lei</dc:creator>
 <dc:creator>Guo, Zheng-Chu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper we study the convergence of online gradient descent algorithms
in reproducing kernel Hilbert spaces (RKHSs) without regularization. We
establish a sufficient condition and a necessary condition for the convergence
of excess generalization errors in expectation. A sufficient condition for the
almost sure convergence is also given. With high probability, we provide
explicit convergence rates of the excess generalization errors for both
averaged iterates and the last iterate, which in turn also imply convergence
rates with probability one. To our best knowledge, this is the first
high-probability convergence rate for the last iterate of online gradient
descent algorithms without strong convexity. Without any boundedness
assumptions on iterates, our results are derived by a novel use of two measures
of the algorithm's one-step progress, respectively by generalization errors and
by distances in RKHSs, where the variances of the involved martingales are
cancelled out by the descent property of the algorithm.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02940</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Role of Secondary Attributes to Boost the Prediction Accuracy of
  Students Employability Via Data Mining</dc:title>
 <dc:creator>Thakar, Pooja</dc:creator>
 <dc:creator>Mehta, Anil</dc:creator>
 <dc:creator>Manisha</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Data Mining is best-known for its analytical and prediction capabilities. It
is used in several areas such as fraud detection, predicting client behavior,
money market behavior, bankruptcy prediction. It can also help in establishing
an educational ecosystem, which discovers useful knowledge, and assist
educators to take proactive decisions to boost student performance and
employability. This paper presents an empirical study that compares varied
classification algorithms on two datasets of MCA (Masters in Computer
Applications) students collected from various affiliated colleges of a reputed
state university in India. One dataset includes only primary attributes,
whereas other dataset is feeded with secondary psychometric attributes in it.
The results showcase that solely primary academic attributes do not lead to
smart prediction accuracy of students employability, once they square measure
within the initial year of their education. The study analyzes and stresses the
role of secondary psychometric attributes for better prediction accuracy and
analysis of students performance. Timely prediction and analysis of students
performance can help Management, Teachers and Students to work on their gray
areas for better results and employment opportunities.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02940</dc:identifier>
 <dc:identifier>(IJACSA) International Journal of Advanced Computer Science and
  Applications, Vol. 6, No. 11, 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02941</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Python Open Source Waveform Extractor (POWER): An open source, Python
  package to monitor and post-process numerical relativity simulations</dc:title>
 <dc:creator>Johnson, Daniel</dc:creator>
 <dc:creator>Huerta, E. A.</dc:creator>
 <dc:creator>Haas, Roland</dc:creator>
 <dc:subject>General Relativity and Quantum Cosmology</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>C.0</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  Numerical simulations of Einstein's field equations provide unique insights
into the physics of compact objects moving at relativistic speeds, and which
are driven by strong gravitational interactions. Numerical relativity has
played a key role to firmly establish gravitational wave astrophysics as a new
field of research, and it is now paving the way to establish whether
gravitational wave radiation emitted from compact binary mergers is accompanied
by electromagnetic and astro-particle counterparts. As numerical relativity
continues to blend in with routine gravitational wave data analyses to validate
the discovery of gravitational wave events, it is essential to develop open
source tools to streamline these studies. Motivated by our own experience as
users and developers of the open source, community software, the Einstein
Toolkit, we present an open source, Python package that is ideally suited to
monitor and post-process the data products of numerical relativity simulations,
and compute the gravitational wave strain at future null infinity in high
performance environments. We showcase the application of this new package to
post-process a large numerical relativity catalog and extract higher-order
waveform modes from numerical relativity simulations of eccentric binary black
hole mergers and neutron star mergers. This new software fills a critical void
in the arsenal of tools provided by the Einstein Toolkit Consortium to the
numerical relativity community.
</dc:description>
 <dc:description>Comment: v2: minor corrections. Accepted to Classical and Quantum Gravity</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02941</dc:identifier>
 <dc:identifier>Class. Quantum Grav. (2017)</dc:identifier>
 <dc:identifier>doi:10.1088/1361-6382/aa9cad</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02963</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Last Meter Indoor Terahertz Wireless Access: Performance Insights and
  Implementation Roadmap</dc:title>
 <dc:creator>Petrov, Vitaly</dc:creator>
 <dc:creator>Kokkoniemi, Joonas</dc:creator>
 <dc:creator>Moltchanov, Dmitri</dc:creator>
 <dc:creator>Lehtomaki, Janne</dc:creator>
 <dc:creator>Koucheryavy, Yevgeni</dc:creator>
 <dc:creator>Juntti, Markku</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The terahertz (THz) band, 0.1-10 THz, has sufficient resources not only to
satisfy the 5G requirements of 10 Gbit/s peak data rate but to enable a number
of tempting rate-greedy applications. However, it brings novel challenges,
never addressed at lower frequencies. Among others, the scattering of THz waves
from any object, including walls and furniture, and ultra-wideband highly
directional links lead to fundamentally new propagation and interference
structures. In this article, we review the recent progress in THz propagation
modeling, antenna and testbed designs, and propose a step-by-step roadmap for
wireless THz Ethernet extension for indoor environments. As a side effect, the
described concept provides a second life to the currently underutilized
Ethernet infrastructure by using it as a universally available backbone. By
applying real THz band propagation, reflection, and scattering measurements as
well as ray-tracing simulations of a typical office, we analyze two
representative scenarios at 300 GHz and 1.25 THz frequencies illustrating that
extremely high rates can be achieved with realistic system parameters at room
scales.
</dc:description>
 <dc:description>Comment: To appear in IEEE Communications Magazine, 2017. 8 pages, 5 figures,
  1 table</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02966</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple Analysis of Sparse, Sign-Consistent JL</dc:title>
 <dc:creator>Jagadeesan, Meena</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Allen-Zhu, Gelashvili, Micali, and Shavit constructed a sparse,
sign-consistent Johnson Lindenstrauss distribution, and proved that this
distribution yields an essentially optimal dimension for the correct choice of
sparsity. However, their analysis of the upper bound on the dimension and
sparsity required a complicated combinatorial graph-based argument similar to
Kane and Nelson's analysis of sparse JL. We present a simple,
combinatorics-free analysis of sparse, sign-consistent JL that yields the same
dimension and sparsity upper bounds as the original analysis. Our proof also
yields dimension/sparsity tradeoffs, which were not previously known.
  As with previous proofs in this area, our analysis is based on applying
Markov's inequality to the $p$th moment of an error term that can be expressed
as a quadratic form of Rademacher variables. Interestingly, we show that,
unlike in previous work in the area, the traditionally used Hanson-Wright bound
is not strong enough to yield our desired result. Indeed, although the
Hanson-Wright bound is known to be optimal for gaussian degree-2 chaos, it was
already shown to be suboptimal for Rademachers. Surprisingly, we are able to
show a simple moment bound for quadratic forms of Rademachers that is
sufficiently tight to achieve our desired result, which given the ubiquity of
moment and tail bounds in theoretical computer science, is likely to be of
broader interest.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02970</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Personalized Cinemagraphs using Semantic Understanding and Collaborative
  Learning</dc:title>
 <dc:creator>Oh, Tae-Hyun</dc:creator>
 <dc:creator>Joo, Kyungdon</dc:creator>
 <dc:creator>Joshi, Neel</dc:creator>
 <dc:creator>Wang, Baoyuan</dc:creator>
 <dc:creator>Kweon, In So</dc:creator>
 <dc:creator>Kang, Sing Bing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Cinemagraphs are a compelling way to convey dynamic aspects of a scene. In
these media, dynamic and still elements are juxtaposed to create an artistic
and narrative experience. Creating a high-quality, aesthetically pleasing
cinemagraph requires isolating objects in a semantically meaningful way and
then selecting good start times and looping periods for those objects to
minimize visual artifacts (such a tearing). To achieve this, we present a new
technique that uses object recognition and semantic segmentation as part of an
optimization method to automatically create cinemagraphs from videos that are
both visually appealing and semantically meaningful. Given a scene with
multiple objects, there are many cinemagraphs one could create. Our method
evaluates these multiple candidates and presents the best one, as determined by
a model trained to predict human preferences in a collaborative way. We
demonstrate the effectiveness of our approach with multiple results and a user
study.
</dc:description>
 <dc:description>Comment: To appear in ICCV 2017. Total 17 pages including the supplementary
  material</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02973</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Policies for Adaptive Tracking with Deep Feature Cascades</dc:title>
 <dc:creator>Huang, Chen</dc:creator>
 <dc:creator>Lucey, Simon</dc:creator>
 <dc:creator>Ramanan, Deva</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual object tracking is a fundamental and time-critical vision task. Recent
years have seen many shallow tracking methods based on real-time pixel-based
correlation filters, as well as deep methods that have top performance but need
a high-end GPU. In this paper, we learn to improve the speed of deep trackers
without losing accuracy. Our fundamental insight is to take an adaptive
approach, where easy frames are processed with cheap features (such as pixel
values), while challenging frames are processed with invariant but expensive
deep features. We formulate the adaptive tracking problem as a decision-making
process, and learn an agent to decide whether to locate objects with high
confidence on an early layer, or continue processing subsequent layers of a
network. This significantly reduces the feed-forward cost for easy frames with
distinct or slow-moving objects. We train the agent offline in a reinforcement
learning fashion, and further demonstrate that learning all deep layers (so as
to provide good features for adaptive tracking) can lead to near real-time
average tracking speed of 23 fps on a single CPU while achieving
state-of-the-art performance. Perhaps most tellingly, our approach provides a
100X speedup for almost 50% of the time, indicating the power of an adaptive
approach.
</dc:description>
 <dc:description>Comment: ICCV 2017 Spotlight, with Supplementary Material</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02975</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anomaly Detection on Graph Time Series</dc:title>
 <dc:creator>Hsu, Daniel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we use variational recurrent neural network to investigate the
anomaly detection problem on graph time series. The temporal correlation is
modeled by the combination of recurrent neural network (RNN) and variational
inference (VI), while the spatial information is captured by the graph
convolutional network. In order to incorporate external factors, we use feature
extractor to augment the transition of latent variables, which can learn the
influence of external factors. With the target function as accumulative ELBO,
it is easy to extend this model to on-line method. The experimental study on
traffic flow data shows the detection capability of the proposed method.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02975</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02976</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Binary Trees for Approximate Nearest Neighbour Search in Binary
  Space</dc:title>
 <dc:creator>Komorowski, Michal</dc:creator>
 <dc:creator>Trzcinski, Tomasz</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Approximate nearest neighbour (ANN) search is one of the most important
problems in computer science fields such as data mining or computer vision. In
this paper, we focus on ANN for high-dimensional binary vectors and we propose
a simple yet powerful search method that uses Random Binary Search Trees
(RBST). We apply our method to a dataset of 1.25M binary local feature
descriptors obtained from a real-life image-based localisation system provided
by Google as a part of Project Tango. An extensive evaluation of our method
against the state-of-the-art variations of Locality Sensitive Hashing (LSH),
namely Uniform LSH and Multi-probe LSH, shows the superiority of our method in
terms of retrieval precision with performance boost of over 20%
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02977</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchically-Attentive RNN for Album Summarization and Storytelling</dc:title>
 <dc:creator>Yu, Licheng</dc:creator>
 <dc:creator>Bansal, Mohit</dc:creator>
 <dc:creator>Berg, Tamara L.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We address the problem of end-to-end visual storytelling. Given a photo
album, our model first selects the most representative (summary) photos, and
then composes a natural language story for the album. For this task, we make
use of the Visual Storytelling dataset and a model composed of three
hierarchically-attentive Recurrent Neural Nets (RNNs) to: encode the album
photos, select representative (summary) photos, and compose the story.
Automatic and human evaluations show our model achieves better performance on
selection, generation, and retrieval than baselines.
</dc:description>
 <dc:description>Comment: To appear at EMNLP-2017 (7 pages)</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02979</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tikhonov Regularization for Long Short-Term Memory Networks</dc:title>
 <dc:creator>Turkin, Andrei</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  It is a well-known fact that adding noise to the input data often improves
network performance. While the dropout technique may be a cause of memory loss,
when it is applied to recurrent connections, Tikhonov regularization, which can
be regarded as the training with additive noise, avoids this issue naturally,
though it implies regularizer derivation for different architectures. In case
of feedforward neural networks this is straightforward, while for networks with
recurrent connections and complicated layers it leads to some difficulties. In
this paper, a Tikhonov regularizer is derived for Long-Short Term Memory (LSTM)
networks. Although it is independent of time for simplicity, it considers
interaction between weights of the LSTM unit, which in theory makes it possible
to regularize the unit with complicated dependences by using only one parameter
that measures the input data perturbation. The regularizer that is proposed in
this paper has three parameters: one to control the regularization process, and
other two to maintain computation stability while the network is being trained.
The theory developed in this paper can be applied to get such regularizers for
different recurrent neural networks with Hadamard products and Lipschitz
continuous functions.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02982</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ChromaTag: A Colored Marker and Fast Detection Algorithm</dc:title>
 <dc:creator>DeGol, Joseph</dc:creator>
 <dc:creator>Bretl, Timothy</dc:creator>
 <dc:creator>Hoiem, Derek</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current fiducial marker detection algorithms rely on marker IDs for false
positive rejection. Time is wasted on potential detections that will eventually
be rejected as false positives. We introduce ChromaTag, a fiducial marker and
detection algorithm designed to use opponent colors to limit and quickly reject
initial false detections and grayscale for precise localization. Through
experiments, we show that ChromaTag is significantly faster than current
fiducial markers while achieving similar or better detection accuracy. We also
show how tag size and viewing direction effect detection accuracy. Our
contribution is significant because fiducial markers are often used in
real-time applications (e.g. marker assisted robot navigation) where heavy
computation is required by other parts of the system.
</dc:description>
 <dc:description>Comment: International Conference on Computer Vision (ICCV '17)</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02983</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scaling Deep Learning on GPU and Knights Landing clusters</dc:title>
 <dc:creator>You, Yang</dc:creator>
 <dc:creator>Buluc, Aydin</dc:creator>
 <dc:creator>Demmel, James</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The speed of deep neural networks training has become a big bottleneck of
deep learning research and development. For example, training GoogleNet by
ImageNet dataset on one Nvidia K20 GPU needs 21 days. To speed up the training
process, the current deep learning systems heavily rely on the hardware
accelerators. However, these accelerators have limited on-chip memory compared
with CPUs. To handle large datasets, they need to fetch data from either CPU
memory or remote processors. We use both self-hosted Intel Knights Landing
(KNL) clusters and multi-GPU clusters as our target platforms. From an
algorithm aspect, current distributed machine learning systems are mainly
designed for cloud systems. These methods are asynchronous because of the slow
network and high fault-tolerance requirement on cloud systems. We focus on
Elastic Averaging SGD (EASGD) to design algorithms for HPC clusters. Original
EASGD used round-robin method for communication and updating. The communication
is ordered by the machine rank ID, which is inefficient on HPC clusters.
  First, we redesign four efficient algorithms for HPC systems to improve
EASGD's poor scaling on clusters. Async EASGD, Async MEASGD, and Hogwild EASGD
are faster \textcolor{black}{than} their existing counterparts (Async SGD,
Async MSGD, and Hogwild SGD, resp.) in all the comparisons. Finally, we design
Sync EASGD, which ties for the best performance among all the methods while
being deterministic. In addition to the algorithmic improvements, we use some
system-algorithm codesign techniques to scale up the algorithms. By reducing
the percentage of communication from 87% to 14%, our Sync EASGD achieves 5.3x
speedup over original EASGD on the same platform. We get 91.5% weak scaling
efficiency on 4253 KNL cores, which is higher than the state-of-the-art
implementation.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02983</dc:identifier>
 <dc:identifier>doi:10.1145/3126908.3126912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02989</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying Reference Spans: Topic Modeling and Word Embeddings help IR</dc:title>
 <dc:creator>Moraes, Luis</dc:creator>
 <dc:creator>Baki, Shahryar</dc:creator>
 <dc:creator>Verma, Rakesh</dc:creator>
 <dc:creator>Lee, Daniel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The CL-SciSumm 2016 shared task introduced an interesting problem: given a
document D and a piece of text that cites D, how do we identify the text spans
of D being referenced by the piece of text? The shared task provided the first
annotated dataset for studying this problem. We present an analysis of our
continued work in improving our system's performance on this task. We
demonstrate how topic models and word embeddings can be used to surpass the
previously best performing system.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02989</dc:identifier>
 <dc:identifier>doi:10.1007/s00799-017-0220-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02991</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Video Watermarking against H.264 and H.265 Compression Attacks</dc:title>
 <dc:creator>Zarmehi, Nematollah</dc:creator>
 <dc:creator>Barikbin, Mohammad Javad</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  This paper proposes a robust watermarking method for uncompressed video data
against H.264/AVC and H.265/HEVC compression standards. We embed the watermark
data in the mid-range transform coefficients of a block that is less similar to
its corresponding block in the previous and next frames. This idea makes the
watermark robust against the compression standards that use the inter
prediction technique. The last two video compression standards also use inter
prediction for motion compensation like previous video compression standards.
Therefore, the proposed method is also well suited with these standards.
Simulation results show the adequate robustness and transparency of our
watermarking scheme.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.02993</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note about Euler's inequality and automated reasoning with dynamic
  geometry</dc:title>
 <dc:creator>Kov&#xe1;cs, Zolt&#xe1;n</dc:creator>
 <dc:creator>Vajda, R&#xf3;bert</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - History and Overview</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  Using implicit loci in GeoGebra Euler's $R\geq 2r$ inequality can be
investigated in a novel way. Some unavoidable side effects of the implicit
locus computation introduce unexpected algebraic curves. By using a mixture of
symbolic and numerical methods a possible approach is sketched up to
investigate the situation.
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.02993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03015</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Study on Team Formation in Online Games</dc:title>
 <dc:creator>Alhazmi, Essa</dc:creator>
 <dc:creator>Horawalavithana, Sameera</dc:creator>
 <dc:creator>Iamnitchi, Adriana</dc:creator>
 <dc:creator>Skvoretz, John</dc:creator>
 <dc:creator>Blackburn, Jeremy</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Online games provide a rich recording of interactions that can contribute to
our understanding of human behavior. One potential lesson is to understand what
motivates people to choose their teammates and how their choices leadto
performance. We examine several hypotheses about team formation using a large,
longitudinal dataset from a team-based online gaming environment. Specifically,
we test how positive familiarity, homophily, and competence determine team
formationin Battlefield 4, a popular team-based game in which players choose
one of two competing teams to play on. Our dataset covers over two months of
in-game interactions between over 380,000 players. We show that familiarity is
an important factorin team formation, while homophily is not. Competence
affects team formation in more nuanced ways: players with similarly high
competence team-up repeatedly, but large variations in competence discourage
repeated interactions.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03015</dc:identifier>
 <dc:identifier>doi:10.1145/3110025.3110094</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03019</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Addendum to: Summary Information for Reasoning About Hierarchical Plans</dc:title>
 <dc:creator>de Silva, Lavindra</dc:creator>
 <dc:creator>Sardina, Sebastian</dc:creator>
 <dc:creator>Padgham, Lin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Hierarchically structured agent plans are important for efficient planning
and acting, and they also serve (among other things) to produce &quot;richer&quot;
classical plans, composed not just of a sequence of primitive actions, but also
&quot;abstract&quot; ones representing the supplied hierarchies. A crucial step for this
and other approaches is deriving precondition and effect &quot;summaries&quot; from a
given plan hierarchy. This paper provides mechanisms to do this for more
pragmatic and conventional hierarchies than in the past. To this end, we
formally define the notion of a precondition and an effect for a hierarchical
plan; we present data structures and algorithms for automatically deriving this
information; and we analyse the properties of the presented algorithms. We
conclude the paper by detailing how our algorithms may be used together with a
classical planner in order to obtain abstract plans.
</dc:description>
 <dc:description>Comment: This paper is a more detailed version of the following publication:
  Lavindra de Silva, Sebastian Sardina, Lin Padgham: Summary Information for
  Reasoning About Hierarchical Plans. ECAI 2016: 1300-1308</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03020</identifier>
 <datestamp>2017-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-stationary Stochastic Optimization with Local Spatial and Temporal
  Changes</dc:title>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Wang, Yining</dc:creator>
 <dc:creator>Wang, Yu-Xiang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider a non-stationary sequential stochastic optimization problem, in
which the underlying cost functions change over time under a variation budget
constraint. We propose an $L_{p,q}$-variation functional to quantify the
change, which captures local spatial and temporal variations of the sequence of
functions. Under the $L_{p,q}$-variation functional constraint, we derive both
upper and matching lower regret bounds for smooth and strongly convex function
sequences, which generalize previous results in (Besbes et al., 2015). Our
results reveal some surprising phenomena under this general variation
functional, such as the curse of dimensionality of the function domain. The key
technical novelties in our analysis include an affinity lemma that
characterizes the distance of the minimizers of two convex functions with
bounded $L_p$ difference, and a cubic spline based construction that attains
matching lower bounds.
</dc:description>
 <dc:description>Comment: 31 pages, 2 figures. Slight relaxation of assumptions</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03027</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Deep Neural Networks to Automate Large Scale Statistical Analysis
  for Big Data Applications</dc:title>
 <dc:creator>Zhang, Rongrong</dc:creator>
 <dc:creator>Deng, Wei</dc:creator>
 <dc:creator>Zhu, Michael Yu</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  Statistical analysis (SA) is a complex process to deduce population
properties from analysis of data. It usually takes a well-trained analyst to
successfully perform SA, and it becomes extremely challenging to apply SA to
big data applications. We propose to use deep neural networks to automate the
SA process. In particular, we propose to construct convolutional neural
networks (CNNs) to perform automatic model selection and parameter estimation,
two most important SA tasks. We refer to the resulting CNNs as the neural model
selector and the neural model estimator, respectively, which can be properly
trained using labeled data systematically generated from candidate models.
Simulation study shows that both the selector and estimator demonstrate
excellent performances. The idea and proposed framework can be further extended
to automate the entire SA process and have the potential to revolutionize how
SA is performed in big data analytics.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03030</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Above and Beyond the Landauer Bound: Thermodynamics of Modularity</dc:title>
 <dc:creator>Boyd, Alexander B.</dc:creator>
 <dc:creator>Mandal, Dibyendu</dc:creator>
 <dc:creator>Crutchfield, James P.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  Information processing typically occurs via the composition of modular units,
such as universal logic gates. The benefit of modular information processing,
in contrast to globally integrated information processing, is that complex
global computations are more easily and flexibly implemented via a series of
simpler, localized information processing operations which only control and
change local degrees of freedom. We show that, despite these benefits, there
are unavoidable thermodynamic costs to modularity---costs that arise directly
from the operation of localized processing and that go beyond Landauer's
dissipation bound for erasing information. Integrated computations can achieve
Landauer's bound, however, when they globally coordinate the control of all of
an information reservoir's degrees of freedom. Unfortunately, global
correlations among the information-bearing degrees of freedom are easily lost
by modular implementations. This is costly since such correlations are a
thermodynamic fuel. We quantify the minimum irretrievable dissipation of
modular computations in terms of the difference between the change in global
nonequilibrium free energy, which captures these global correlations, and the
local (marginal) change in nonequilibrium free energy, which bounds modular
work production. This modularity dissipation is proportional to the amount of
additional work required to perform the computational task modularly. It has
immediate consequences for physically embedded transducers, known as
information ratchets. We show how to circumvent modularity dissipation by
designing internal ratchet states that capture the global correlations and
patterns in the ratchet's information reservoir. Designed in this way,
information ratchets match the optimum thermodynamic efficiency of globally
integrated computations.
</dc:description>
 <dc:description>Comment: 17 pages, 9 figures;
  http://csc.ucdavis.edu/~cmg/compmech/pubs/idolip.htm</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03035</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Model for Near and Remote Sensing</dc:title>
 <dc:creator>Workman, Scott</dc:creator>
 <dc:creator>Zhai, Menghua</dc:creator>
 <dc:creator>Crandall, David J.</dc:creator>
 <dc:creator>Jacobs, Nathan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel convolutional neural network architecture for estimating
geospatial functions such as population density, land cover, or land use. In
our approach, we combine overhead and ground-level images in an end-to-end
trainable neural network, which uses kernel regression and density estimation
to convert features extracted from the ground-level images into a dense feature
map. The output of this network is a dense estimate of the geospatial function
in the form of a pixel-level labeling of the overhead image. To evaluate our
approach, we created a large dataset of overhead and ground-level images from a
major urban area with three sets of labels: land use, building function, and
building age. We find that our approach is more accurate for all tasks, in some
cases dramatically so.
</dc:description>
 <dc:description>Comment: International Conference on Computer Vision (ICCV) 2017</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03044</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Is there anything else I can help you with?&quot;: Challenges in Deploying
  an On-Demand Crowd-Powered Conversational Agent</dc:title>
 <dc:creator>Huang, Ting-Hao Kenneth</dc:creator>
 <dc:creator>Lasecki, Walter S.</dc:creator>
 <dc:creator>Azaria, Amos</dc:creator>
 <dc:creator>Bigham, Jeffrey P.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Intelligent conversational assistants, such as Apple's Siri, Microsoft's
Cortana, and Amazon's Echo, have quickly become a part of our digital life.
However, these assistants have major limitations, which prevents users from
conversing with them as they would with human dialog partners. This limits our
ability to observe how users really want to interact with the underlying
system. To address this problem, we developed a crowd-powered conversational
assistant, Chorus, and deployed it to see how users and workers would interact
together when mediated by the system. Chorus sophisticatedly converses with end
users over time by recruiting workers on demand, which in turn decide what
might be the best response for each user sentence. Up to the first month of our
deployment, 59 users have held conversations with Chorus during 320
conversational sessions. In this paper, we present an account of Chorus'
deployment, with a focus on four challenges: (i) identifying when conversations
are over, (ii) malicious users and workers, (iii) on-demand recruiting, and
(iv) settings in which consensus is not enough. Our observations could assist
the deployment of crowd-powered conversation systems and crowd-powered systems
in general.
</dc:description>
 <dc:description>Comment: 10 pages. In Proceedings of Conference on Human Computation &amp;
  Crowdsourcing (HCOMP 2016), 2016, Austin, TX, USA</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03052</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication-Free Parallel Supervised Topic Models</dc:title>
 <dc:creator>Gao, Lee</dc:creator>
 <dc:creator>Zheng, Ronghuo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Embarrassingly (communication-free) parallel Markov chain Monte Carlo (MCMC)
methods are commonly used in learning graphical models. However, MCMC cannot be
directly applied in learning topic models because of the quasi-ergodicity
problem caused by multimodal distribution of topics. In this paper, we develop
an embarrassingly parallel MCMC algorithm for sLDA. Our algorithm works by
switching the order of sampled topics combination and labeling variable
prediction in sLDA, in which it overcomes the quasi-ergodicity problem because
high-dimension topics that follow a multimodal distribution are projected into
one-dimension document labels that follow a unimodal distribution. Our
empirical experiments confirm that the out-of-sample prediction performance
using our embarrassingly parallel algorithm is comparable to non-parallel sLDA
while the computation time is significantly reduced.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03053</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application Level High Speed Transfer Optimization Based on Historical
  Analysis and Real-time Tuning</dc:title>
 <dc:creator>Arslan, Engin</dc:creator>
 <dc:creator>Kosar, Tevfik</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Data-intensive scientific and commercial applications increasingly require
frequent movement of large datasets from one site to the other(s). Despite
growing network capacities, these data movements rarely achieve the promised
data transfer rates of the underlying physical network due to poorly tuned data
transfer protocols. Accurately and efficiently tuning the data transfer
protocol parameters in a dynamically changing network environment is a major
challenge and remains as an open research problem. In this paper, we present
predictive end-to-end data transfer optimization algorithms based on historical
data analysis and real-time background traffic probing, dubbed HARP. Most of
the previous work in this area are solely based on real time network probing
which results either in an excessive sampling overhead or fails to accurately
predict the optimal transfer parameters. Combining historical data analysis
with real time sampling enables our algorithms to tune the application level
data transfer parameters accurately and efficiently to achieve close-to-optimal
end-to-end data transfer throughput with very low overhead. Our experimental
analysis over a variety of network settings shows that HARP outperforms
existing solutions by up to 50% in terms of the achieved throughput.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03055</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Control for Constrained Coverage Path Planning</dc:title>
 <dc:creator>Manerikar, Ankit</dc:creator>
 <dc:creator>Das, Debasmit</dc:creator>
 <dc:creator>Banerjee, Pranay</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The problem of constrained coverage path planning involves a robot trying to
cover maximum area of an environment under some constraints that appear as
obstacles in the map. Out of the several coverage path planning methods, we
consider augmenting the linear sweep-based coverage method to achieve minimum
energy/ time optimality along with maximum area coverage. In addition, we also
study the effects of variation of different parameters on the performance of
the modified method.
</dc:description>
 <dc:description>Comment: Report for AAE 568 (Applied Optimal Control) at Purdue</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03058</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Interactive Collaborative Filtering Using Multi-Armed Bandit with
  Dependent Arms</dc:title>
 <dc:creator>Wang, Qing</dc:creator>
 <dc:creator>Zeng, Chunqiu</dc:creator>
 <dc:creator>Zhou, Wubai</dc:creator>
 <dc:creator>Li, Tao</dc:creator>
 <dc:creator>Shwartz, Larisa</dc:creator>
 <dc:creator>Grabarnik, Genady Ya.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Online interactive recommender systems strive to promptly suggest to
consumers appropriate items (e.g., movies, news articles) according to the
current context including both the consumer and item content information.
However, such context information is often unavailable in practice for the
recommendation, where only the users' interaction data on items can be
utilized. Moreover, the lack of interaction records, especially for new users
and items, worsens the performance of recommendation further. To address these
issues, collaborative filtering (CF), one of the recommendation techniques
relying on the interaction data only, as well as the online multi-armed bandit
mechanisms, capable of achieving the balance between exploitation and
exploration, are adopted in the online interactive recommendation settings, by
assuming independent items (i.e., arms). Nonetheless, the assumption rarely
holds in reality, since the real-world items tend to be correlated with each
other (e.g., two articles with similar topics). In this paper, we study online
interactive collaborative filtering problems by considering the dependencies
among items. We explicitly formulate the item dependencies as the clusters on
arms, where the arms within a single cluster share the similar latent topics.
In light of the topic modeling techniques, we come up with a generative model
to generate the items from their underlying topics. Furthermore, an efficient
online algorithm based on particle learning is developed for inferring both
latent parameters and states of our model. Additionally, our inferred model can
be naturally integrated with existing multi-armed selection strategies in the
online interactive collaborating setting. Empirical studies on two real-world
applications, online recommendations of movies and news, demonstrate both the
effectiveness and efficiency of the proposed approach.
</dc:description>
 <dc:description>Comment: Recommender systems; Interactive collaborative filtering; Topic
  modeling; Cold-start problem; Particle learning; 10 pages</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03059</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opportunistic Scheduling of Machine Type Communications as Underlay to
  Cellular Networks</dc:title>
 <dc:creator>Ali, Samad</dc:creator>
 <dc:creator>Rajatheva, Nandana</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we present a simple method to exploit the diversity of
interference in heterogenous wireless communication systems with large number
of machine-type-devices (MTD). We consider a system with a
machine-type-aggregator (MTA) as underlay to cellular network with a multi
antenna base station (BS). Cellular users share uplink radio resources with
MTDs. Handling the interference from MTDs on the BS is the focus of this
article. Our method takes advantage of received interference diversity on BS at
each time on each resource block and allocates the radio resources to the MTD
with the minimum interference on the BS. In this method, BS does not need to
take the interference from MTD into account in the design of the receive
beamformer for uplink cellular user, hence, the degrees of freedom is not used
for interference management. Our simulation results show that each resource
block can be shared between a cellular user and an MTD, with almost no harmful
interference on the cellular user.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03065</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heterogeneous Networks with Power-Domain NOMA: Coverage, Throughput and
  Power Allocation Analysis</dc:title>
 <dc:creator>Liu, Chun-Hung</dc:creator>
 <dc:creator>Liang, Di-Chun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In a heterogeneous cellular network (HetNet), consider that a base station in
the HetNet is able to simultaneously schedule and serve K users in the downlink
by performing the power-domain non-orthogonal multiple access (NOMA) scheme.
This paper aims at the preliminary study on the downlink coverage and
throughput performances of the HetNet with the non-cooperative and the
(proposed) cooperative NOMA schemes. First, the coverage probability and link
throughput of K users in each cell are studied and their accurate expressions
are derived for the non-cooperative NOMA scheme in which no BSs are coordinated
to jointly transmit the NOMA signals for a particular user. We show that the
coverage and link throughput can be largely reduced if transmit power
allocations among the K users do not satisfy the constraint derived. Next, we
analyze the coverage and link throughput of K users for the cooperative NOMA
scheme in which the void BSs without users are coordinated to enhance the
farthest NOMA user in a cell. The derived accurate results show that
cooperative NOMA can significantly improve the coverage and link throughput of
all users. Finally, we show that there exist optimal power allocation schemes
that maximize the average cell coverage and throughput under some derived power
allocation constraints and numerical results validate our analytical findings.
</dc:description>
 <dc:description>Comment: 31 pages, 4 figures</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03066</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Optimization of VoD schemes with Client Caching in Wireless
  Multicast Networks</dc:title>
 <dc:creator>Feng, Hao</dc:creator>
 <dc:creator>Chen, Zhiyong</dc:creator>
 <dc:creator>Liu, Hui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Due to the explosive growth in multimedia traffic, the scalability of
video-on-demand (VoD) services becomes increasingly important. By exploiting
the potential cache ability at the client side, the performance of VoD
multicast delivery can be improved through video segment pre-caching. In this
paper, we address the performance limits of client caching enabled VoD schemes
in wireless multicast networks with asynchronous requests. Both reactive and
proactive systems are investigated. Specifically, for the reactive system where
videos are transmitted on demand, we propose a joint cache allocation and
multicast delivery scheme to minimize the average bandwidth consumption under
the zero-delay constraint. For the proactive system where videos are
periodically broadcasted, a joint design of the cache-bandwidth allocation
algorithm and the delivery mechanism is developed to minimize the average
waiting time under the total bandwidth constraint. In addition to the full
access pattern where clients view videos in their entirety, we further consider
the access patterns with random endpoints, fixed-size intervals and downloading
demand, respectively. The impacts of different access patterns on the
resource-allocation algorithm and the delivery mechanism are elaborated.
Simulation results validate the accuracy of the analytical results and also
provide useful insights in designing VoD networks with client caching.
</dc:description>
 <dc:description>Comment: accepted by IEEE Transactions on Vehicular Technology</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03070</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TandemNet: Distilling Knowledge from Medical Images Using Diagnostic
  Reports as Optional Semantic References</dc:title>
 <dc:creator>Zhang, Zizhao</dc:creator>
 <dc:creator>Chen, Pingjun</dc:creator>
 <dc:creator>Sapkota, Manish</dc:creator>
 <dc:creator>Yang, Lin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we introduce the semantic knowledge of medical images from
their diagnostic reports to provide an inspirational network training and an
interpretable prediction mechanism with our proposed novel multimodal neural
network, namely TandemNet. Inside TandemNet, a language model is used to
represent report text, which cooperates with the image model in a tandem
scheme. We propose a novel dual-attention model that facilitates high-level
interactions between visual and semantic information and effectively distills
useful features for prediction. In the testing stage, TandemNet can make
accurate image prediction with an optional report text input. It also
interprets its prediction by producing attention on the image and text
informative feature pieces, and further generating diagnostic report
paragraphs. Based on a pathological bladder cancer images and their diagnostic
reports (BCIDR) dataset, sufficient experiments demonstrate that our method
effectively learns and integrates knowledge from multimodalities and obtains
significantly improved performance than comparing baselines.
</dc:description>
 <dc:description>Comment: MICCAI2017 Oral</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03074</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Machine Learning Approach to Routing</dc:title>
 <dc:creator>Valadarsky, Asaf</dc:creator>
 <dc:creator>Schapira, Michael</dc:creator>
 <dc:creator>Shahaf, Dafna</dc:creator>
 <dc:creator>Tamar, Aviv</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:description>  Can ideas and techniques from machine learning be leveraged to automatically
generate &quot;good&quot; routing configurations? We investigate the power of data-driven
routing protocols. Our results suggest that applying ideas and techniques from
deep reinforcement learning to this context yields high performance, motivating
further research along these lines.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03077</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on the vertex arboricity of signed graphs</dc:title>
 <dc:creator>Liu, Weichan</dc:creator>
 <dc:creator>Gong, Chen</dc:creator>
 <dc:creator>Wu, Lifang</dc:creator>
 <dc:creator>Zhang, Xin</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C15</dc:subject>
 <dc:description>  A signed tree-coloring of a signed graph $(G,\sigma)$ is a vertex coloring
$c$ so that $G^{c}(i,\pm)$ is a forest for every $i\in c(u)$ and $u\in V(G)$,
where $G^{c}(i,\pm)$ is the subgraph of $(G,\sigma)$ whose vertex set is the
set of vertices colored by $i$ or $-i$ and edge set is the set of positive
edges with two end-vertices colored both by $i$ or both by $-i$, along with the
set of negative edges with one end-vertex colored by $i$ and the other colored
by $-i$. If $c$ is a function from $V(G)$ to $M_n$, where $M_n$ is $\{\pm 1,\pm
2,\ldots,\pm k\}$ if $n=2k$, and $\{0,\pm 1,\pm 2,\ldots,\pm k\}$ if $n=2k+1$,
then $c$ a signed tree-$n$-coloring of $(G,\sigma)$. The minimum integer $n$
such that $(G,\sigma)$ admits a signed tree-$n$-coloring is the signed vertex
arboricity of $(G,\sigma)$, denoted by $va(G,\sigma)$. In this paper, we first
show that two switching equivalent signed graphs have the same signed vertex
arboricity, and then prove that $va(G,\sigma)\leq 3$ for every balanced signed
triangulation and for every edge-maximal $K_5$-minor-free graph with balanced
signature. This generalizes the well-known result that the vertex arboricity of
every planar graph is at most 3.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure, will be published in Utilitas Mathematica</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03080</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple and Realistic Pedestrian Model for Crowd Simulation and
  Application</dc:title>
 <dc:creator>Kang, Wonho</dc:creator>
 <dc:creator>Han, Youngnam</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:description>  The simulation of pedestrian crowd that reflects reality is a major challenge
for researches. Several crowd simulation models have been proposed such as
cellular automata model, agent-based model, fluid dynamic model, etc. It is
important to note that agent-based model is able, over others approaches, to
provide a natural description of the system and then to capture complex human
behaviors. In this paper, we propose a multi-agent simulation model in which
pedestrian positions are updated at discrete time intervals. It takes into
account the major normal conditions of a simple pedestrian situated in a crowd
such as preferences, realistic perception of environment, etc. Our objective is
to simulate the pedestrian crowd realistically towards a simulation of
believable pedestrian behaviors. Typical pedestrian phenomena, including the
unidirectional and bidirectional movement in a corridor as well as the flow
through bottleneck, are simulated. The conducted simulations show that our
model is able to produce realistic pedestrian behaviors. The obtained
fundamental diagram and flow rate at bottleneck agree very well with classic
conclusions and empirical study results. It is hoped that the idea of this
study may be helpful in promoting the modeling and simulation of pedestrian
crowd in a simple way.
</dc:description>
 <dc:description>Comment: https://scholar.google.co.kr/citations?user=HHP3UrYAAAAJ</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03081</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distance-preserving Subgraphs of Interval Graphs</dc:title>
 <dc:creator>Gajjar, Kshitij</dc:creator>
 <dc:creator>Radhakrishnan, Jaikumar</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the problem of finding small distance-preserving subgraphs of
undirected, unweighted interval graphs with $k$ terminal vertices.
  To start with, we show that finding an optimal distance-preserving subgraph
is $\mathsf{NP}$-hard for general graphs. Then, we show that every interval
graph admits a subgraph with $O(k)$ branching vertices that approximates
pairwise terminal distances up to an additive term of $+1$. We also present an
interval graph $G_{\mathrm{int}}$ for which the $+1$ approximation is necessary
to obtain the $O(k)$ upper bound on the number of branching vertices. In
particular, any distance-preserving subgraph of $G_{\mathrm{int}}$ has
$\Omega(k\log k)$ branching vertices. Furthermore, we prove that every interval
graph admits a distance-preserving subgraph with $O(k\log k)$ branching
vertices, implying that the $\Omega(k\log k)$ lower bound for interval graphs
is tight. To conclude, we show that there exists an interval graph such that
every optimal distance-preserving subgraph of it has $O(k)$ branching vertices
and $\Omega(k\log k)$ branching edges, thereby providing a separation between
branching vertices and branching edges.
  The $O(k)$ bound for distance-approximating subgraphs follows from a na\&quot;ive
analysis of shortest paths in interval graphs. $G_{\mathrm{int}}$ is
constructed using bit-reversal permutation matrices. The $O(k\log k)$ bound for
distance-preserving subgraphs uses a divide-and-conquer approach. Finally, the
separation between branching vertices and branching edges employs Hansel's
lemma for graph covering.
</dc:description>
 <dc:description>Comment: 19 pages, 6 figures. A concise version of this paper to appear in the
  proceedings ALGO (ESA) 2017 with the same title</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03088</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Video CNNs through Representation Warping</dc:title>
 <dc:creator>Gadde, Raghudeep</dc:creator>
 <dc:creator>Jampani, Varun</dc:creator>
 <dc:creator>Gehler, Peter V.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we propose a technique to convert CNN models for semantic
segmentation of static images into CNNs for video data. We describe a warping
method that can be used to augment existing architectures with very little
extra computational cost. This module is called NetWarp and we demonstrate its
use for a range of network architectures. The main design principle is to use
optical flow of adjacent frames for warping internal network representations
across time. A key insight of this work is that fast optical flow methods can
be combined with many different CNN architectures for improved performance and
end-to-end training. Experiments validate that the proposed approach incurs
only little extra computational cost, while improving performance, when video
streams are available. We achieve new state-of-the-art results on the CamVid
and Cityscapes benchmark datasets and show consistent improvements over
different baseline networks. Our code and models will be available at
http://segmentation.is.tue.mpg.de
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03097</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Approximate Welfare- and Revenue-Maximizing Equilibria for
  Size-Interchangeable Bidders</dc:title>
 <dc:creator>Viqueira, Enrique Areyan</dc:creator>
 <dc:creator>Greenwald, Amy</dc:creator>
 <dc:creator>Naroditskiy, Victor</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In a Walrasian equilibrium (WE), all bidders are envy-free (EF), meaning that
their allocation maximizes their utility; and the market clears (MC), meaning
that the price of unallocated goods is zero. EF is desirable to ensure the
long-term viability of the market. MC ensures that demand meets supply. Any
allocation that is part of a WE is also welfare-maximizing; however, it need
not be revenue-maximizing. Furthermore, WE need not exist, e.g., in markets
where bidders have combinatorial valuations. The traditional approach to
simultaneously addressing both existence and low revenue is to relax the MC
condition and instead require the price of unallocated goods be some, positive
reserve price. The resulting solution concept, known as Envy-Free Pricing
(EFP), has been studied in some special cases, e.g., single-minded bidders. In
this paper, we go one step further; we relax EF as well as MC. We propose a
relaxation of the EF condition where only winners are envy-free, and further
relax the MC condition so that unallocated goods are priced at least at the
reserve. We call this new solution concept Restricted Envy-Free Pricing (REFP).
We investigate what REFP entails for single-minded bidders, and show that for
size-interchangeable bidders (a generalization of single-minded introduced in
this paper) we can compute a REFP in polynomial time, given a fixed allocation.
As in the study of EFP, we remain interested in maximizing seller revenue.
Instead of computing an outcome that simultaneously yields an allocation and
corresponding prices, one could first solve for an allocation that respects a
reserve price, and then solve for a corresponding set of supporting prices,
each one at least the reserve. This two-step process fails in the case of EFP
since, given a fixed allocation, envy-free prices need not exist. However,
restricted envy-free prices always exist...
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03102</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounds on the Capacity of Memoryless Simplified Fiber-Optical Channel
  Models</dc:title>
 <dc:creator>Keykhosravi, Kamran</dc:creator>
 <dc:creator>Durisi, Giuseppe</dc:creator>
 <dc:creator>Agrell, Erik</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A number of simplified models have been proposed for the fiber-optical
channel and have been extensively used in the literature. Although these models
are mainly developed for the low-power regime, they are used at moderate or
high powers as well. It remains unclear to what extend the capacity of these
models is affected by the simplifying assumptions under which they are derived.
In this paper, the capacity of three memoryless channel models, which are
obtained applying different simplifying assumptions to the same physical
fiber-optical channel, is investigated. First, the capacity of a memoryless
model that is obtained through a perturbation method is bounded tightly and its
capacity pre-log is proven to be 3. Second, a channel model based on the
logarithmic perturbation method is considered. The capacity is proven to be
$\log(1+\mathrm{SNR})$, where $\mathrm{SNR}$ is the signal-to-noise ratio. This
implies that the capacity pre-log is one. Third, a memoryless nonlinear
Schr\&quot;odinger channel is studied. The capacity pre-log of this model is known
to be $1/2$. We establish a novel upper bound that confines the capacity of
this channel to a much narrower range than the previously known upper bound.
Since all three models represent the same physical channel, the fact that each
model yields a different capacity pre-log highlights that care must be
exercised in using simplified channel models in the high-power regime.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03105</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Location Name Extraction from Targeted Text Streams using
  Gazetteer-based Statistical Language Models</dc:title>
 <dc:creator>Al-Olimat, Hussein S.</dc:creator>
 <dc:creator>Thirunarayan, Krishnaprasad</dc:creator>
 <dc:creator>Shalin, Valerie</dc:creator>
 <dc:creator>Sheth, Amit</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Extracting location names from informal and unstructured texts requires the
identification of referent boundaries and partitioning of compound names in the
presence of variation in location referents. Instead of analyzing semantic,
syntactic, and/or orthographic features, our Location Name Extraction tool
(LNEx) exploits a region-specific statistical language model to evaluate an
observed n-gram in Twitter targeted text as a legitimate location name variant.
LNEx handles abbreviations, and automatically filters and augments the location
names in gazetteers from OpenStreetMap, Geonames, and DBpedia. Consistent with
Carroll [4], LNEx addresses two kinds of location name contractions: category
ellipsis and location ellipsis, which produces alternate name forms of location
names (i.e., Nameheads of location names). The modified gazetteers and
dictionaries of abbreviations help detect the boundaries of multi-word location
names delimiting them in texts using n-gram statistics.
  We evaluated the extent to which using an augmented and filtered
region-specific gazetteer can successfully extract location names from a
targeted text stream. We used 4,500 event-specific tweets from three targeted
streams of different flooding disasters to compare LNEx performance against
eight state-of-the-art taggers. LNEx improved the average F-Score by 98-145%
outperforming these taggers convincingly on the three manually annotated
Twitter streams. Furthermore, LNEx is capable of stream processing.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03111</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modality-bridge Transfer Learning for Medical Image Classification</dc:title>
 <dc:creator>Kim, Hak Gu</dc:creator>
 <dc:creator>Choi, Yeoreum</dc:creator>
 <dc:creator>Ro, Yong Man</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a new approach of transfer learning-based medical image
classification to mitigate insufficient labeled data problem in medical domain.
Instead of direct transfer learning from source to small number of labeled
target data, we propose a modality-bridge transfer learning which employs the
bridge database in the same medical imaging acquisition modality as target
database. By learning the projection function from source to bridge and from
bridge to target, the domain difference between source (e.g., natural images)
and target (e.g., X-ray images) can be mitigated. Experimental results show
that the proposed method can achieve a high classification performance even for
a small number of labeled target medical images, compared to various transfer
learning approaches.
</dc:description>
 <dc:description>Comment: accepted at CISP-BMEI 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03115</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Downlink Power Control for Dense Networks with Carrier
  Aggregation</dc:title>
 <dc:creator>Fazliu, Zana Limani</dc:creator>
 <dc:creator>Chiasserini, Carla-Fabiana</dc:creator>
 <dc:creator>Dell'Aera, Gian Michele</dc:creator>
 <dc:creator>Hamiti, Enver</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Given the proven benefits cell densification brings in terms of capacity and
coverage, it is certain that 5G networks will be even more heterogeneous and
dense. However, as smaller cells are introduced in the network, interference
will inevitably become a serious problem as they are expected to share the same
radio resources. Another central feature envisioned for future cellular
networks is carrier aggregation (CA), which allows users to simultaneously use
several component carriers of various widths and frequency bands. By exploiting
the diversity of the different carriers, CA can also be used to effectively
mitigate the interference in the network. In this paper, we leverage the above
key features of next-generation cellular networks and formulate a downlink
power setting problem for the different available carriers. Using game theory,
we design a distributed algorithm that lets cells dynamically adjust different
transmit powers for the different carriers. The proposed solution greatly
improves network performance by reducing interference and power consumption,
while ensuring coverage for as many users as possible. We compare our scheme to
other interference mitigation techniques, in a realistic large-scale scenario.
Numerical results show that our solution outperforms the existing schemes in
terms of user throughput, energy and spectral efficiency.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Transactions of Wireless
  Communications</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03115</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2017.2737998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03131</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hypotheses testing on infinite random graphs</dc:title>
 <dc:creator>Ryabko, Daniil</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Drawing on some recent results that provide the formalism necessary to
definite stationarity for infinite random graphs, this paper initiates the
study of statistical and learning questions pertaining to these objects.
Specifically, a criterion for the existence of a consistent test for complex
hypotheses is presented, generalizing the corresponding results on time series.
As an application, it is shown how one can test that a tree has the Markov
property, or, more generally, to estimate its memory.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03132</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attention-Aware Face Hallucination via Deep Reinforcement Learning</dc:title>
 <dc:creator>Cao, Qingxing</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:creator>Shi, Yukai</dc:creator>
 <dc:creator>Liang, Xiaodan</dc:creator>
 <dc:creator>Li, Guanbin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face hallucination is a domain-specific super-resolution problem with the
goal to generate high-resolution (HR) faces from low-resolution (LR) input
images. In contrast to existing methods that often learn a single
patch-to-patch mapping from LR to HR images and are regardless of the
contextual interdependency between patches, we propose a novel Attention-aware
Face Hallucination (Attention-FH) framework which resorts to deep reinforcement
learning for sequentially discovering attended patches and then performing the
facial part enhancement by fully exploiting the global interdependency of the
image. Specifically, in each time step, the recurrent policy network is
proposed to dynamically specify a new attended region by incorporating what
happened in the past. The state (i.e., face hallucination result for the whole
image) can thus be exploited and updated by the local enhancement network on
the selected region. The Attention-FH approach jointly learns the recurrent
policy network and local enhancement network through maximizing the long-term
reward that reflects the hallucination performance over the whole image.
Therefore, our proposed Attention-FH is capable of adaptively personalizing an
optimal searching path for each face image according to its own characteristic.
Extensive experiments show our approach significantly surpasses the
state-of-the-arts on in-the-wild faces with large pose and illumination
variations.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03151</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Static and Stochastic VRPTW with both random Customers and Reveal
  Times: algorithms and recourse strategies</dc:title>
 <dc:creator>Saint-Guillain, Michael</dc:creator>
 <dc:creator>Solnon, Christine</dc:creator>
 <dc:creator>Deville, Yves</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Unlike its deterministic counterpart, static and stochastic vehicle routing
problems (SS-VRP) aim at modeling and solving real-life operational problems by
considering uncertainty on data. We consider the SS-VRPTW-CR introduced in
Saint-Guillain et al. (2017). Like the SS-VRP introduced by Bertsimas (1992),
we search for optimal first stage routes for a fleet of vehicles to handle a
set of stochastic customer demands, i.e., demands are uncertain and we only
know their probabilities. In addition to capacity constraints, customer demands
are also constrained by time windows. Unlike all SS-VRP variants, the
SS-VRPTW-CR does not make any assumption on the time at which a stochastic
demand is revealed, i.e., the reveal time is stochastic as well. To handle this
new problem, we introduce waiting locations: Each vehicle is assigned a
sequence of waiting locations from which it may serve some associated demands,
and the objective is to minimize the expected number of demands that cannot be
satisfied in time. In this paper, we propose two new recourse strategies for
the SS-VRPTW-CR, together with their closed-form expressions for efficiently
computing their expectations: The first one allows us to take vehicle
capacities into account; The second one allows us to optimize routes by
avoiding some useless trips. We propose two algorithms for searching for routes
with optimal expected costs: The first one is an extended branch-and-cut
algorithm, based on a stochastic integer formulation, and the second one is a
local search based heuristic method. We also introduce a new public benchmark
for the SS-VRPTW-CR, based on real-world data coming from the city of Lyon. We
evaluate our two algorithms on this benchmark and empirically demonstrate the
expected superiority of the SS-VRPTW-CR anticipative actions over a basic
&quot;wait-and-serve&quot; policy.
</dc:description>
 <dc:description>Comment: Preprint version submitted to Transportation Research Part E</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03152</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Neural Speaker Modeling in Multi-Party Conversation: The Task,
  Dataset, and Models</dc:title>
 <dc:creator>Meng, Zhao</dc:creator>
 <dc:creator>Mou, Lili</dc:creator>
 <dc:creator>Jin, Zhi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Neural network-based dialog systems are attracting increasing attention in
both academia and industry. Recently, researchers have begun to realize the
importance of speaker modeling in neural dialog systems, but there lacks
established tasks and datasets. In this paper, we propose speaker
classification as a surrogate task for general speaker modeling, and collect
massive data to facilitate research in this direction. We further investigate
temporal-based and content-based models of speakers, and propose several
hybrids of them. Experiments show that speaker classification is feasible, and
that hybrid models outperform each single component.
</dc:description>
 <dc:description>Comment: Submitted (unsuccessfully) to EMNLP17, with 244 reviews</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03157</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TensorFlow Enabled Genetic Programming</dc:title>
 <dc:creator>Staats, Kai</dc:creator>
 <dc:creator>Pantridge, Edward</dc:creator>
 <dc:creator>Cavaglia, Marco</dc:creator>
 <dc:creator>Milovanov, Iurii</dc:creator>
 <dc:creator>Aniyan, Arun</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Genetic Programming, a kind of evolutionary computation and machine learning
algorithm, is shown to benefit significantly from the application of vectorized
data and the TensorFlow numerical computation library on both CPU and GPU
architectures. The open source, Python Karoo GP is employed for a series of 190
tests across 6 platforms, with real-world datasets ranging from 18 to 5.5M data
points. This body of tests demonstrates that datasets measured in tens and
hundreds of data points see 2-15x improvement when moving from the scalar/SymPy
configuration to the vector/TensorFlow configuration, with a single core
performing on par or better than multiple CPU cores and GPUs. A dataset
composed of 90,000 data points demonstrates a single vector/TensorFlow CPU core
performing 875x better than 40 scalar/Sympy CPU cores. And a dataset containing
5.5M data points sees GPU configurations out-performing CPU configurations on
average by 1.3x.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures; presented at GECCO 2017, Berlin, Germany</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03157</dc:identifier>
 <dc:identifier>Proceedings of the Genetic and Evolutionary Computation Conference
  (GECCO) Companion, ACM 2017, pp. 1872-1879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03167</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric Multiscale Community Detection: Markov Stability and Vector
  Partitioning</dc:title>
 <dc:creator>Liu, Zijing</dc:creator>
 <dc:creator>Barahona, Mauricio</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Multiscale community detection can be viewed from a dynamical perspective
within the Markov Stability framework, which uses the diffusion of a Markov
process on the graph to uncover intrinsic network substructures across all
scales. Here we reformulate multiscale community detection as a max-sum length
vector partitioning problem with respect to the set of time-dependent node
vectors expressed in terms of eigenvectors of the transition matrix. This
formulation provides a geometric interpretation of Markov Stability in terms of
a time-dependent spectral embedding, where the Markov time acts as an
inhomogeneous geometric resolution factor that zooms the components of the node
vectors at different rates. Our geometric formulation encompasses both
modularity and the multi-resolution Potts model, which are shown to correspond
to vector partitioning in a pseudo-Euclidean space, and is also linked to
spectral partitioning methods, where the number of eigenvectors used
corresponds to the dimensionality of the underlying embedding vector space.
Inspired by the Louvain optimisation for community detection, we then propose
an algorithm based on a graph-theoretical heuristic for the vector partitioning
problem. We apply the algorithm to the spectral optimisation of modularity and
Markov Stability community detection. The spectral embedding based on the
transition matrix eigenvectors leads to improved partitions with higher
information content and higher modularity than the eigen-decomposition of the
modularity matrix. We illustrate the results with random network benchmarks.
</dc:description>
 <dc:description>Comment: 16 pages, 7 figures</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03178</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>More Accurate Recommendations for Method-Level Changes</dc:title>
 <dc:creator>Dotzler, Georg</dc:creator>
 <dc:creator>Kamp, Marius</dc:creator>
 <dc:creator>Kreutzer, Patrick</dc:creator>
 <dc:creator>Philippsen, Michael</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  During the life span of large software projects, developers often apply the
same code changes to different code locations in slight variations. Since the
application of these changes to all locations is time-consuming and
error-prone, tools exist that learn change patterns from input examples, search
for possible pattern applications, and generate corresponding recommendations.
In many cases, the generated recommendations are syntactically or semantically
wrong due to code movements in the input examples. Thus, they are of low
accuracy and developers cannot directly copy them into their projects without
adjustments.
  We present the Accurate REcommendation System (ARES) that achieves a higher
accuracy than other tools because its algorithms take care of code movements
when creating patterns and recommendations. On average, the recommendations by
ARES have an accuracy of 96% with respect to code changes that developers have
manually performed in commits of source code archives. At the same time ARES
achieves precision and recall values that are on par with other tools.
</dc:description>
 <dc:description>Comment: 11 pages, 11 figures</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03178</dc:identifier>
 <dc:identifier>doi:10.1145/3106237.3106276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03181</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Utilizing Embeddings for Ad-hoc Retrieval by Document-to-document
  Similarity</dc:title>
 <dc:creator>Yang, Chenhao</dc:creator>
 <dc:creator>He, Ben</dc:creator>
 <dc:creator>Ran, Yanhua</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Latent semantic representations of words or paragraphs, namely the
embeddings, have been widely applied to information retrieval (IR). One of the
common approaches of utilizing embeddings for IR is to estimate the
document-to-query (D2Q) similarity in their embeddings. As words with similar
syntactic usage are usually very close to each other in the embeddings space,
although they are not semantically similar, the D2Q similarity approach may
suffer from the problem of &quot;multiple degrees of similarity&quot;. To this end, this
paper proposes a novel approach that estimates a semantic relevance score (SEM)
based on document-to-document (D2D) similarity of embeddings. As Word or
Para2Vec generates embeddings by the context of words/paragraphs, the D2D
similarity approach turns the task of document ranking into the estimation of
similarity between content within different documents. Experimental results on
standard TREC test collections show that our proposed approach outperforms
strong baselines.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03183</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Tiling of Unstructured Mesh Computations with Application to
  Seismological Modelling</dc:title>
 <dc:creator>Luporini, Fabio</dc:creator>
 <dc:creator>Lange, Michael</dc:creator>
 <dc:creator>Jacobs, Christian T.</dc:creator>
 <dc:creator>Gorman, Gerard J.</dc:creator>
 <dc:creator>Ramanujam, J.</dc:creator>
 <dc:creator>Kelly, Paul H. J.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Geophysics</dc:subject>
 <dc:subject>D.1.2</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  Sparse tiling is a technique to fuse loops that access common data, thus
increasing data locality. Unlike traditional loop fusion or blocking, the loops
may have different iteration spaces and access shared datasets through indirect
memory accesses, such as A[map[i]] -- hence the name &quot;sparse&quot;. One notable
example of such loops arises in discontinuous-Galerkin finite element methods,
because of the computation of numerical integrals over different domains (e.g.,
cells, facets). The major challenge with sparse tiling is implementation -- not
only is it cumbersome to understand and synthesize, but it is also onerous to
maintain and generalize, as it requires a complete rewrite of the bulk of the
numerical computation. In this article, we propose an approach to extend the
applicability of sparse tiling based on raising the level of abstraction.
Through a sequence of compiler passes, the mathematical specification of a
problem is progressively lowered, and eventually sparse-tiled C for-loops are
generated. Besides automation, we advance the state-of-the-art by introducing:
a revisited, more efficient sparse tiling algorithm; support for
distributed-memory parallelism; a range of fine-grained optimizations for
increased run-time performance; implementation in a publicly-available library,
SLOPE; and an in-depth study of the performance impact in Seigen, a real-world
elastic wave equation solver for seismological problems, which shows speed-ups
up to 1.28x on a platform consisting of 896 Intel Broadwell cores.
</dc:description>
 <dc:description>Comment: 29 pages including supplementary materials and references</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03184</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-efficient Analytics for Geographically Distributed Big Data</dc:title>
 <dc:creator>Zhao, Peng</dc:creator>
 <dc:creator>Yang, Shusen</dc:creator>
 <dc:creator>Yang, Xinyu</dc:creator>
 <dc:creator>Yu, Wei</dc:creator>
 <dc:creator>Lin, Jie</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Big data analytics on geographically distributed datasets (across data
centers or clusters) has been attracting increasing interests from both
academia and industry, but also significantly complicates the system and
algorithm designs. In this article, we systematically investigate the
geo-distributed big-data analytics framework by analyzing the fine-grained
paradigm and the key design principles. We present a dynamic global manager
selection algorithm (GMSA) to minimize energy consumption cost by fully
exploiting the system diversities in geography and variation over time. The
algorithm makes real-time decisions based on the measurable system parameters
through stochastic optimization methods, while achieving the performance
balances between energy cost and latency. Extensive trace-driven simulations
verify the effectiveness and efficiency of the proposed algorithm. We also
highlight several potential research directions that remain open and require
future elaborations in analyzing geo-distributed big data.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03184</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03186</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural and Statistical Methods for Leveraging Meta-information in
  Machine Translation</dc:title>
 <dc:creator>Khadivi, Shahram</dc:creator>
 <dc:creator>Wilken, Patrick</dc:creator>
 <dc:creator>Dahlmann, Leonard</dc:creator>
 <dc:creator>Matusov, Evgeny</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we discuss different methods which use meta information and
richer context that may accompany source language input to improve machine
translation quality. We focus on category information of input text as meta
information, but the proposed methods can be extended to all textual and
non-textual meta information that might be available for the input text or
automatically predicted using the text content. The main novelty of this work
is to use state-of-the-art neural network methods to tackle this problem within
a statistical machine translation (SMT) framework. We observe translation
quality improvements up to 3% in terms of BLEU score in some text categories.
</dc:description>
 <dc:description>Comment: To appear in MT Summit 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03200</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achieving an Efficient and Fair Equilibrium Through Taxation</dc:title>
 <dc:creator>Gao, Lin</dc:creator>
 <dc:creator>Huang, Jianwei</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  It is well known that a game equilibrium can be far from efficient or fair,
due to the misalignment between individual and social objectives. The focus of
this paper is to design a new mechanism framework that induces an efficient and
fair equilibrium in a general class of games. To achieve this goal, we propose
a taxation framework, which first imposes a tax on each player based on the
perceived payoff (income), and then redistributes the collected tax to other
players properly. By turning the tax rate, this framework spans the continuum
space between strategic interactions (of selfish players) and altruistic
interactions (of unselfish players), hence provides rich modeling
possibilities. The key challenge in the design of this framework is the proper
taxing rule (i.e., the tax exemption and tax rate) that induces the desired
equilibrium in a wide range of games. First, we propose a flat tax rate (i.e.,
a single tax rate for all players), which is necessary and sufficient for
achieving an efficient equilibrium in any static strategic game with common
knowledge. Then, we provide several tax exemption rules that achieve some
typical fairness criterions (such as the Max-min fairness) at the equilibrium.
We further illustrate the implementation of the framework in the game of
Prisoners' Dilemma.
</dc:description>
 <dc:description>Comment: This manuscript serves as the technical report for the paper with the
  same title published in APCC 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03201</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Cyber-physical Attack with Leveraging Detection in Smart Grid</dc:title>
 <dc:creator>Chung, Hwei-Ming</dc:creator>
 <dc:creator>Li, Wen-Tai</dc:creator>
 <dc:creator>Yuen, Chau</dc:creator>
 <dc:creator>Chung, Wei-Ho</dc:creator>
 <dc:creator>Wen, Chao-Kai</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A well-designed attack in the power system can cause an initial failure and
then results in large-scale cascade failure. Several works have discussed power
system attack through false data injection, line-maintaining attack, and
line-removing attack. However, the existing methods need to continuously attack
the system for a long time, and, unfortunately, the performance cannot be
guaranteed if the system states vary. To overcome this issue, we consider a new
type of attack strategy called combinational attack which masks a line-outage
at one position but misleads the control center on line outage at another
position. Therefore, the topology information in the control center is
interfered by our attack. We also offer a procedure of selecting the vulnerable
lines of its kind. The proposed method can effectively and continuously deceive
the control center in identifying the actual position of line-outage. The
system under attack will be exposed to increasing risks as the attack
continuously. Simulation results validate the efficiency of the proposed attack
strategy.
</dc:description>
 <dc:description>Comment: Accepted by IEEE SmartGridComm 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03209</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tosca: Operationalizing Commitments Over Information Protocols</dc:title>
 <dc:creator>King, Thomas C.</dc:creator>
 <dc:creator>G&#xfc;nay, Ak&#x131;n</dc:creator>
 <dc:creator>Chopra, Amit K.</dc:creator>
 <dc:creator>Singh, Munindar P.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The notion of commitment is widely studied as a high-level abstraction for
modeling multiagent interaction. An important challenge is supporting flexible
decentralized enactments of commitment specifications. In this paper, we
combine recent advances on specifying commitments and information protocols.
Specifically, we contribute Tosca, a technique for automatically synthesizing
information protocols from commitment specifications. Our main result is that
the synthesized protocols support commitment alignment, which is the idea that
agents must make compatible inferences about their commitments despite
decentralization.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03209</dc:identifier>
 <dc:identifier>doi:10.24963/ijcai.2017/37</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03211</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DNN and CNN with Weighted and Multi-task Loss Functions for Audio Event
  Detection</dc:title>
 <dc:creator>Phan, Huy</dc:creator>
 <dc:creator>Krawczyk-Becker, Martin</dc:creator>
 <dc:creator>Gerkmann, Timo</dc:creator>
 <dc:creator>Mertins, Alfred</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This report presents our audio event detection system submitted for Task 2,
&quot;Detection of rare sound events&quot;, of DCASE 2017 challenge. The proposed system
is based on convolutional neural networks (CNNs) and deep neural networks
(DNNs) coupled with novel weighted and multi-task loss functions and
state-of-the-art phase-aware signal enhancement. The loss functions are
tailored for audio event detection in audio streams. The weighted loss is
designed to tackle the common issue of imbalanced data in background/foreground
classification while the multi-task loss enables the networks to simultaneously
model the class distribution and the temporal structures of the target events
for recognition. Our proposed systems significantly outperform the challenge
baseline, improving F-score from 72.7% to 90.0% and reducing detection error
rate from 0.53 to 0.18 on average on the development data. On the evaluation
data, our submission obtains an average F1-score of 88.3% and an error rate of
0.22 which are significantly better than those obtained by the DCASE baseline
(i.e. an F1-score of 64.1% and an error rate of 0.64).
</dc:description>
 <dc:description>Comment: DCASE 2017 technical report</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03214</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identification of Dynamic Systems with Interval Arithmetic</dc:title>
 <dc:creator>Peixoto, M&#xe1;rcia L. C.</dc:creator>
 <dc:creator>Matos, Marco T. R.</dc:creator>
 <dc:creator>J&#xfa;nior, Wilson R. Lacerda</dc:creator>
 <dc:creator>Martins, Samir A. M.</dc:creator>
 <dc:creator>Nepomuceno, Erivelton G.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper aims to identify three electrical systems: a series RLC circuit, a
motor/generator coupled system, and the Duffing-Ueda oscillator. In order to
obtain the system's models was used the error reduction ratio and the Akaike
information criterion. Our approach to handle the numerical errors was the
interval arithmetic by means of the resolution of the least squares estimation.
The routines was implemented in Intlab, a Matlab toolbox devoted to arithmetic
interval. Finally, the interval RMSE was calculated to verify the quality of
the obtained models. The applied methodology was satisfactory, since the
obtained intervals encompass the system's data and allow to demonstrate how the
numerical errors affect the answers.
</dc:description>
 <dc:description>Comment: SBAI 2017 - XIII Simp\'osio Brasileiro de Automa\c{c}\~ao
  Inteligente, Porto Alegre, p. 1-6, In Portuguese. arXiv admin note: text
  overlap with arXiv:1612.02674</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03214</dc:identifier>
 <dc:language>pt</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03218</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Fixed-Rank Nystr\&quot;om Approximation via QR Decomposition:
  Practical and Theoretical Aspects</dc:title>
 <dc:creator>Pourkamali-Anaraki, Farhad</dc:creator>
 <dc:creator>Becker, Stephen</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The Nystr\&quot;om method is a popular technique for computing fixed-rank
approximations of large kernel matrices using a small number of landmark
points. In practice, to ensure high quality approximations, the number of
landmark points is chosen to be greater than the target rank. However, the
standard Nystr\&quot;om method uses a sub-optimal procedure for rank reduction
mainly due to its simplicity. In this paper, we highlight the drawbacks of
standard Nystr\&quot;om in terms of poor performance and lack of theoretical
guarantees. To address these issues, we present an efficient method for
generating improved fixed-rank Nystr\&quot;om approximations. Theoretical analysis
and numerical experiments are provided to demonstrate the advantages of the
modified method over the standard Nystr\&quot;om method. Overall, the aim of this
paper is to convince researchers to use the modified method, as it has nearly
identical computational complexity, is easy to code, and has greatly improved
accuracy in many cases.
</dc:description>
 <dc:description>Comment: 12 pages. arXiv admin note: text overlap with arXiv:1612.06470</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03228</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower bounds for several online variants of bin packing</dc:title>
 <dc:creator>Balogh, J&#xe1;nos</dc:creator>
 <dc:creator>B&#xe9;k&#xe9;si, J&#xf3;zsef</dc:creator>
 <dc:creator>D&#xf3;sa, Gy&#xf6;rgy</dc:creator>
 <dc:creator>Epstein, Leah</dc:creator>
 <dc:creator>Levin, Asaf</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider several previously studied online variants of bin packing and
prove new and improved lower bounds on the asymptotic competitive ratios for
them. For that, we use a method of fully adaptive constructions. In particular,
we improve the lower bound for the asymptotic competitive ratio of online
square packing significantly, raising it from roughly 1.68 to above 1.75.
</dc:description>
 <dc:description>Comment: WAOA 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03229</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Selection of t-SNE Perplexity</dc:title>
 <dc:creator>Cao, Yanshuai</dc:creator>
 <dc:creator>Wang, Luyu</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  t-Distributed Stochastic Neighbor Embedding (t-SNE) is one of the most widely
used dimensionality reduction methods for data visualization, but it has a
perplexity hyperparameter that requires manual selection. In practice, proper
tuning of t-SNE perplexity requires users to understand the inner working of
the method as well as to have hands-on experience. We propose a model selection
objective for t-SNE perplexity that requires negligible extra computation
beyond that of the t-SNE itself. We empirically validate that the perplexity
settings found by our approach are consistent with preferences elicited from
human experts across a number of datasets. The similarities of our approach to
Bayesian information criteria (BIC) and minimum description length (MDL) are
also analyzed.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03236</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hint-Based Technique for System Level Model-Based Test Case
  Prioritization</dc:title>
 <dc:creator>Ouriques, Jo&#xe3;o Felipe Silva</dc:creator>
 <dc:creator>Cartaxo, Emanuela Gadelha</dc:creator>
 <dc:creator>Alves, Everton Leandro Galdino</dc:creator>
 <dc:creator>Machado, Patr&#xed;cia Duarte Lima</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Test Case Prioritization (TCP) techniques aim at proposing new test case
execution orders to favor the achievement of certain testing goal, such as
fault detection. Current TCP research focus mainly on code-based regression
testing; however in the Model-Based Testing (MBT) context, we still need more
investigation. General TCP techniques do not use historical information, since
this information is often unavailable. Therefore, techniques use different
sources of information to guide prioritization. We propose a novel technique
that guides its operation using provided hints, the Hint-Based Adaptive Random
Prioritization - HARP. Hints are indications or suggestions provided by
developers about error-prone functionalities. As hints may be hard to collect
automatically, we also propose an approach of collecting them. To validate our
findings, we performed an experiment measuring the effect of introducing hints
to HARP. It shows that hints can improve HARP's performance comparing to its
baseline. Then, we investigated the ability of developers/managers to provide
good hints and used them in a case study. This analysis showed that developers
and managers are able to provide useful hints, which improves HARP's fault
detection comparing to its baseline. Nonetheless, the provided hints should be
consensual among the development team members.
</dc:description>
 <dc:description>Comment: This is our manuscript submitted to JCST and rejected!</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03240</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Test Case Prioritization Techniques for Model-Based Testing: A
  Replicated Study</dc:title>
 <dc:creator>Ouriques, Jo&#xe3;o Felipe Silva</dc:creator>
 <dc:creator>Cartaxo, Emanuela Gadelha</dc:creator>
 <dc:creator>Machado, Patr&#xed;cia Duarte Lima</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Recently, several Test Case Prioritization (TCP) techniques have been
proposed to order test cases for achieving a goal during test execution,
particularly, revealing faults sooner. In the Model-Based Testing (MBT)
context, such techniques are usually based on heuristics related to structural
elements of the model and derived test cases. In this sense, techniques'
performance may vary due to a number of factors. While empirical studies
comparing the performance of TCP techniques have already been presented in
literature, there is still little knowledge, particularly in the MBT context,
about which factors may influence the outcomes suggested by a TCP technique. In
a previous family of empirical studies focusing on labeled transition systems,
we identified that the model layout, i.e. amount of branches, joins, and loops
in the model, alone may have little influence on the performance of TCP
techniques investigated, whereas characteristics of test cases that actually
fail definitely influences their performance. However, we considered only
synthetic artifacts in the study, which reduced the ability of representing
properly the reality. In this paper, we present a replication of one of these
studies, now with a larger and more representative selection of techniques and
considering test suites from industrial applications as experimental objects.
Our objective is to find out whether the results remain while increasing the
validity in comparison to the original study. Results reinforce that there is
no best performer among the investigated techniques and characteristics of test
cases that fail represent an important factor, although adaptive random based
techniques are less affected by it.
</dc:description>
 <dc:description>Comment: This manuscript is under review on Software Quality Journal - SQJ</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03243</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Summary of Topological Study of Chaotic CBC Mode of Operation</dc:title>
 <dc:creator>Abidi, Abdessalem</dc:creator>
 <dc:creator>Tawbi, Samar</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Bouall&#xe8;gue, Belgacem</dc:creator>
 <dc:creator>Machhout, Mohsen</dc:creator>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In cryptography, block ciphers are the most fundamental elements in many
symmetric-key encryption systems. The Cipher Block Chaining, denoted CBC,
presents one of the most famous mode of operation that uses a block cipher to
provide confidentiality or authenticity. In this research work, we intend to
summarize our results that have been detailed in our previous series of
articles. The goal of this series has been to obtain a complete topological
study of the CBC block cipher mode of operation after proving his chaotic
behavior according to the reputed definition of Devaney.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1605.02950,
  arXiv:1608.05838, arXiv:1601.08139</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03246</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SESA: Supervised Explicit Semantic Analysis</dc:title>
 <dc:creator>Bogdanova, Dasha</dc:creator>
 <dc:creator>Yazdani, Majid</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In recent years supervised representation learning has provided state of the
art or close to the state of the art results in semantic analysis tasks
including ranking and information retrieval. The core idea is to learn how to
embed items into a latent space such that they optimize a supervised objective
in that latent space. The dimensions of the latent space have no clear
semantics, and this reduces the interpretability of the system. For example, in
personalization models, it is hard to explain why a particular item is ranked
high for a given user profile. We propose a novel model of representation
learning called Supervised Explicit Semantic Analysis (SESA) that is trained in
a supervised fashion to embed items to a set of dimensions with explicit
semantics. The model learns to compare two objects by representing them in this
explicit space, where each dimension corresponds to a concept from a knowledge
base. This work extends Explicit Semantic Analysis (ESA) with a supervised
model for ranking problems. We apply this model to the task of Job-Profile
relevance in LinkedIn in which a set of skills defines our explicit dimensions
of the space. Every profile and job are encoded to this set of skills their
similarity is calculated in this space. We use RNNs to embed text input into
this space. In addition to interpretability, our model makes use of the
web-scale collaborative skills data that is provided by users for each LinkedIn
profile. Our model provides state of the art result while it remains
interpretable.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03252</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust scheduling to minimize the weighted number of late jobs with
  interval due-date uncertainty</dc:title>
 <dc:creator>Drwal, Maciej</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the class of single machine scheduling problems with the
objective to minimize the weighted number of late jobs, under the assumption
that completion due-dates are not known precisely at the time when
decision-maker must provide a schedule. It is assumed that only the intervals
to which the due-dates belong are known. The concept of maximum regret is used
to define robust solution. A polynomial time algorithm is given for the case
when weights of jobs are all equal. A mixed-integer linear programming
formulation is provided for the general case, and computational experiments are
reported.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03257</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust polynomial regression up to the information theoretic limit</dc:title>
 <dc:creator>Kane, Daniel</dc:creator>
 <dc:creator>Karmalkar, Sushrut</dc:creator>
 <dc:creator>Price, Eric</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of robust polynomial regression, where one receives
samples $(x_i, y_i)$ that are usually within $\sigma$ of a polynomial $y =
p(x)$, but have a $\rho$ chance of being arbitrary adversarial outliers.
Previously, it was known how to efficiently estimate $p$ only when $\rho &lt;
\frac{1}{\log d}$. We give an algorithm that works for the entire feasible
range of $\rho &lt; 1/2$, while simultaneously improving other parameters of the
problem. We complement our algorithm, which gives a factor 2 approximation,
with impossibility results that show, for example, that a $1.09$ approximation
is impossible even with infinitely many samples.
</dc:description>
 <dc:description>Comment: 19 Pages. To appear in FOCS 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03259</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preference fusion and Condorcet's Paradox under uncertainty</dc:title>
 <dc:creator>Zhang, Yiru</dc:creator>
 <dc:creator>Bouadi, Tassadit</dc:creator>
 <dc:creator>Martin, Arnaud</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Facing an unknown situation, a person may not be able to firmly elicit
his/her preferences over different alternatives, so he/she tends to express
uncertain preferences. Given a community of different persons expressing their
preferences over certain alternatives under uncertainty, to get a collective
representative opinion of the whole community, a preference fusion process is
required. The aim of this work is to propose a preference fusion method that
copes with uncertainty and escape from the Condorcet paradox. To model
preferences under uncertainty, we propose to develop a model of preferences
based on belief function theory that accurately describes and captures the
uncertainty associated with individual or collective preferences. This work
improves and extends the previous results. This work improves and extends the
contribution presented in a previous work. The benefits of our contribution are
twofold. On the one hand, we propose a qualitative and expressive preference
modeling strategy based on belief-function theory which scales better with the
number of sources. On the other hand, we propose an incremental distance-based
algorithm (using Jousselme distance) for the construction of the collective
preference order to avoid the Condorcet Paradox.
</dc:description>
 <dc:description>Comment: International Conference on Information Fusion, Jul 2017, Xi'an,
  China</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03264</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextuality from missing and versioned data</dc:title>
 <dc:creator>Morton, Jason</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  Traditionally categorical data analysis (e.g. generalized linear models)
works with simple, flat datasets akin to a single table in a database with no
notion of missing data or conflicting versions. In contrast, modern data
analysis must deal with distributed databases with many partial local tables
that need not always agree. The computational agents tabulating these tables
are spatially separated, with binding speed-of-light constraints and data
arriving too rapidly for these distributed views ever to be fully informed and
globally consistent. Contextuality is a mathematical property which describes a
kind of inconsistency arising in quantum mechanics (e.g. in Bell's theorem). In
this paper we show how contextuality can arise in common data collection
scenarios, including missing data and versioning (as in low-latency distributed
databases employing snapshot isolation). In the companion paper, we develop
statistical models adapted to this regime.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03269</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Routing Unmanned Vehicles in GPS-Denied Environments</dc:title>
 <dc:creator>Sundar, Kaarthik</dc:creator>
 <dc:creator>Misra, Sohum</dc:creator>
 <dc:creator>Rathinam, Sivakumar</dc:creator>
 <dc:creator>Sharma, Rajnikant</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Most of the routing algorithms for unmanned vehicles, that arise in data
gathering and monitoring applications in the literature, rely on the Global
Positioning System (GPS) information for localization. However, disruption of
GPS signals either intentionally or unintentionally could potentially render
these algorithms not applicable. In this article, we present a novel method to
address this difficulty by combining methods from cooperative localization and
routing. In particular, the article formulates a fundamental combinatorial
optimization problem to plan routes for an unmanned vehicle in a GPS-restricted
environment while enabling localization for the vehicle. We also develop
algorithms to compute optimal paths for the vehicle using the proposed
formulation. Extensive simulation results are also presented to corroborate the
effectiveness and performance of the proposed formulation and algorithms.
</dc:description>
 <dc:description>Comment: Publised in International Conference on Umanned Aerial Systems</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03269</dc:identifier>
 <dc:identifier>doi:10.1109/ICUAS.2017.7991488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03271</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Machine Translation Leveraging Phrase-based Models in a Hybrid
  Search</dc:title>
 <dc:creator>Dahlmann, Leonard</dc:creator>
 <dc:creator>Matusov, Evgeny</dc:creator>
 <dc:creator>Petrushkov, Pavel</dc:creator>
 <dc:creator>Khadivi, Shahram</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we introduce a hybrid search for attention-based neural
machine translation (NMT). A target phrase learned with statistical MT models
extends a hypothesis in the NMT beam search when the attention of the NMT model
focuses on the source words translated by this phrase. Phrases added in this
way are scored with the NMT model, but also with SMT features including
phrase-level translation probabilities and a target language model.
Experimental results on German-&gt;English news domain and English-&gt;Russian
e-commerce domain translation tasks show that using phrase-based models in NMT
search improves MT quality by up to 2.3% BLEU absolute as compared to a strong
NMT baseline.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of EMNLP 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03273</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Convolutional Neural Networks for Document Image
  Classification</dc:title>
 <dc:creator>Tensmeyer, Chris</dc:creator>
 <dc:creator>Martinez, Tony</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional Neural Networks (CNNs) are state-of-the-art models for document
image classification tasks. However, many of these approaches rely on
parameters and architectures designed for classifying natural images, which
differ from document images. We question whether this is appropriate and
conduct a large empirical study to find what aspects of CNNs most affect
performance on document images. Among other results, we exceed the
state-of-the-art on the RVL-CDIP dataset by using shear transform data
augmentation and an architecture designed for a larger input image.
Additionally, we analyze the learned features and find evidence that CNNs
trained on RVL-CDIP learn region-specific layout features.
</dc:description>
 <dc:description>Comment: Accepted ICDAR 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03274</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulating a Shared Register in a System that Never Stops Changing</dc:title>
 <dc:creator>Attiya, Hagit</dc:creator>
 <dc:creator>Chung, Hyun Chul</dc:creator>
 <dc:creator>Ellen, Faith</dc:creator>
 <dc:creator>Kumar, Saptaparni</dc:creator>
 <dc:creator>Welch, Jennifer L.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Simulating a shared register can mask the intricacies of designing algorithms
for asynchronous message-passing systems subject to crash failures, since it
allows them to run algorithms designed for the simpler shared-memory model.
Typically such simulations replicate the value of the register in multiple
servers and require readers and writers to communicate with a majority of
servers. The success of this approach for static systems, where the set of
nodes (readers, writers, and servers) is fixed, has motivated several similar
simulations for dynamic systems, where nodes may enter and leave. However,
existing simulations need to assume that the system eventually stops changing
for a long enough period or that the system size is bounded. This paper
presents the first simulation of an atomic read/write register in a crash-prone
asynchronous system that can change size and withstand nodes continually
entering and leaving. The simulation allows the system to keep changing,
provided that the number of nodes entering and leaving during a fixed time
interval is at most a constant fraction of the current system size. The
simulation also tolerates node crashes as long as the number of failed nodes in
the system is at most a constant fraction of the current system size.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03274</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03275</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental 3D Line Segments Extraction from Semi-dense SLAM</dc:title>
 <dc:creator>He, Shida</dc:creator>
 <dc:creator>Qin, Xuebin</dc:creator>
 <dc:creator>Zhang, Zichen</dc:creator>
 <dc:creator>Jagersand, Martin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite much interest in Simultaneous Localization and Mapping (SLAM), there
is a lack of efficient methods for representing and processing their large
scale point clouds. In this paper, we propose to simplify the point clouds
generated by the semi-dense SLAM using three-dimensional (3D) line segments.
Specifically, we present a novel incremental approach for 3D line segments
extraction. This approach reduces a 3D line segment fitting problem into two
two-dimensional (2D) line segment fitting problems, which take advantage of
both image edge segments and depth maps. We first detect edge segments, which
are one-pixel-width pixel chains from keyframes. We then search 3D line
segments of each keyframe along their detected edge pixel chains by minimizing
the fitting error on both image plane and depth plane. By incrementally
clustering the detected line segments, we show that the resulting 3D
representation for the scene achieves a good balance between compactness and
completeness. Our experimental results show that the 3D line segments generated
by our method are highly accurate in terms of the location of their end points.
Additionally, we also demonstrate that these line segments greatly improve the
quality of 3D surface reconstruction compared to a feature point based
baseline.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03276</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Document Image Binarization with Fully Convolutional Neural Networks</dc:title>
 <dc:creator>Tensmeyer, Chris</dc:creator>
 <dc:creator>Martinez, Tony</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Binarization of degraded historical manuscript images is an important
pre-processing step for many document processing tasks. We formulate
binarization as a pixel classification learning task and apply a novel Fully
Convolutional Network (FCN) architecture that operates at multiple image
scales, including full resolution. The FCN is trained to optimize a continuous
version of the Pseudo F-measure metric and an ensemble of FCNs outperform the
competition winners on 4 of 7 DIBCO competitions. This same binarization
technique can also be applied to different domains such as Palm Leaf
Manuscripts with good performance. We analyze the performance of the proposed
model w.r.t. the architectural hyperparameters, size and diversity of training
data, and the input features chosen.
</dc:description>
 <dc:description>Comment: ICDAR 2017 (oral)</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03278</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Motion Feature Augmented Recurrent Neural Network for Skeleton-based
  Dynamic Hand Gesture Recognition</dc:title>
 <dc:creator>Chen, Xinghao</dc:creator>
 <dc:creator>Guo, Hengkai</dc:creator>
 <dc:creator>Wang, Guijin</dc:creator>
 <dc:creator>Zhang, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Dynamic hand gesture recognition has attracted increasing interests because
of its importance for human computer interaction. In this paper, we propose a
new motion feature augmented recurrent neural network for skeleton-based
dynamic hand gesture recognition. Finger motion features are extracted to
describe finger movements and global motion features are utilized to represent
the global movement of hand skeleton. These motion features are then fed into a
bidirectional recurrent neural network (RNN) along with the skeleton sequence,
which can augment the motion features for RNN and improve the classification
performance. Experiments demonstrate that our proposed method is effective and
outperforms start-of-the-art methods.
</dc:description>
 <dc:description>Comment: Accepted by ICIP 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03280</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Temporal Preservation Networks for Precise Temporal Action
  Localization</dc:title>
 <dc:creator>Yang, Ke</dc:creator>
 <dc:creator>Qiao, Peng</dc:creator>
 <dc:creator>Li, Dongsheng</dc:creator>
 <dc:creator>Lv, Shaohe</dc:creator>
 <dc:creator>Dou, Yong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Temporal action localization is an important task of computer vision. Though
a variety of methods have been proposed, it still remains an open question how
to predict the temporal boundaries of action segments precisely. Most works use
segment-level classifiers to select video segments pre-determined by action
proposal or dense sliding windows. However, in order to achieve more precise
action boundaries, a temporal localization system should make dense predictions
at a fine granularity. A newly proposed work exploits
Convolutional-Deconvolutional-Convolutional (CDC) filters to upsample the
predictions of 3D ConvNets, making it possible to perform per-frame action
predictions and achieving promising performance in terms of temporal action
localization. However, CDC network loses temporal information partially due to
the temporal downsampling operation. In this paper, we propose an elegant and
powerful Temporal Preservation Convolutional (TPC) Network that equips 3D
ConvNets with TPC filters. TPC network can fully preserve temporal resolution
and downsample the spatial resolution simultaneously, enabling frame-level
granularity action localization. TPC network can be trained in an end-to-end
manner. Experiment results on public datasets show that TPC network achieves
significant improvement on per-frame action prediction and competing results on
segment-level temporal action localization.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03280</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03292</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Synthesize a 4D RGBD Light Field from a Single Image</dc:title>
 <dc:creator>Srinivasan, Pratul P.</dc:creator>
 <dc:creator>Wang, Tongzhou</dc:creator>
 <dc:creator>Sreelal, Ashwin</dc:creator>
 <dc:creator>Ramamoorthi, Ravi</dc:creator>
 <dc:creator>Ng, Ren</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present a machine learning algorithm that takes as input a 2D RGB image
and synthesizes a 4D RGBD light field (color and depth of the scene in each ray
direction). For training, we introduce the largest public light field dataset,
consisting of over 3300 plenoptic camera light fields of scenes containing
flowers and plants. Our synthesis pipeline consists of a convolutional neural
network (CNN) that estimates scene geometry, a stage that renders a Lambertian
light field using that geometry, and a second CNN that predicts occluded rays
and non-Lambertian effects. Our algorithm builds on recent view synthesis
methods, but is unique in predicting RGBD for each light field ray and
improving unsupervised single image depth estimation by enforcing consistency
of ray depths that should intersect the same scene point. Please see our
supplementary video at https://youtu.be/yLCvWoQLnms
</dc:description>
 <dc:description>Comment: International Conference on Computer Vision (ICCV) 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03295</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multicarrier Relay Selection for Full-Duplex Relay-Assisted OFDM D2D
  Systems</dc:title>
 <dc:creator>Dang, Shuping</dc:creator>
 <dc:creator>Chen, Gaojie</dc:creator>
 <dc:creator>Coon, Justin P.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a full-duplex orthogonal frequency-division
multiplexing (OFDM) device-to-device (D2D) system in two-hop networks, where
multiple full-duplex decode-and-forward (DF) relays assist the transmission
from D2D user equipment (DUE) transmitter to DUE receiver. By such a
transmission mechanism, the signal transmitted by the DUE transmitter does not
need to go through a base station (BS). Meanwhile, due to the adoption of
underlay D2D communication protocol, power control mechanisms are thereby
necessary to be applied to mitigate the interference to conventional cellular
communications. Based on these considerations, we analyze the outage
performance of the proposed system, and derive the exact expressions of outage
probabilities when bulk and per-subcarrier relay selection criteria are
applied. Furthermore, closed-form expressions of outage probabilities are also
obtained for special cases when the instantaneous channel state information
(CSI) between BS and cellular user equipments (CUEs) is not accessible, so that
a static power control mechanism is applied. Subsequently, we also investigate
the outage performance optimization problem by coordinating transmit power
among DUE transmitter and relays, and provide a suboptimal solution, which is
capable of improving the outage performance. All analysis is substantiated by
numerical results provided by Monte Carlo simulations. The analytical and
numerical results demonstrated in this paper can provide an insight into the
full-duplex relay-assisted OFDM D2D systems, and serve as a guideline for its
implementation in next generation networks.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03297</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Outage Performance of Two-Hop OFDM Systems with Spatially Random
  Decode-and-Forward Relays</dc:title>
 <dc:creator>Dang, Shuping</dc:creator>
 <dc:creator>Coon, Justin P.</dc:creator>
 <dc:creator>Chen, Gaojie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we analyze the outage performance of different multicarrier
relay selection schemes for two-hop orthogonal frequency-division multiplexing
(OFDM) systems in a Poisson field of relays. In particular, special emphasis is
placed on decode-and-forward (DF) relay systems, equipped with bulk and
per-subcarrier selection schemes, respectively. The exact expressions for
outage probability are derived in integrals for general cases. In addition,
asymptotic expressions for outage probability in the high signal-to-noise ratio
(SNR) region in the finite circle relay distribution region are determined in
closed forms for both relay selection schemes. Also, the outage probabilities
for free space in the infinite relay distribution region are derived in closed
forms. Meanwhile, a series of important properties related to cooperative
systems in random networks are investigated, including diversity, outage
probability ratio of two selection schemes and optimization of the number of
subcarriers in terms of system throughput. All analysis is numerically verified
by simulations. Finally, a framework for analyzing the outage performance of
OFDM systems with spatially random relays is constructed, which can be easily
modified to analyze other similar cases with different forwarding protocols,
location distributions and/or channel conditions.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03307</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cell Detection with Deep Convolutional Neural Network and Compressed
  Sensing</dc:title>
 <dc:creator>Xue, Yao</dc:creator>
 <dc:creator>Ray, Nilanjan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The ability to automatically detect certain types of cells or cellular
subunits in microscopy images is of significant interest to a wide range of
biomedical research and clinical practices. Cell detection methods have evolved
from employing hand-crafted features to deep learning-based techniques to
locate target cells. The essential idea of these methods is that their cell
classifiers or detectors are trained in the pixel space, where the locations of
target cells are labeled. In this paper, we seek a different route and propose
a convolutional neural network (CNN)-based cell detection method that uses
encoding of the output pixel space. For the cell detection problem, the output
space is the sparsely labeled pixel locations indicating cell centers.
Consequently, we employ random projections to encode the output space to a
compressed vector of fixed dimension. Then, CNN regresses this compressed
vector from the input pixels. Using $L_1$-norm optimization, we recover sparse
cell locations on the output pixel space from the predicted compressed vector.
In the past, output space encoding using compressed sensing (CS) has been used
in conjunction with linear and non-linear predictors. To the best of our
knowledge, this is the first successful use of CNN with CS-based output space
encoding. We experimentally demonstrate that proposed CNN + CS framework
(referred to as CNNCS) exceeds the accuracy of the state-of-the-art methods on
many benchmark datasets for microscopy cell detection. Additionally, we show
that CNNCS can exploit ensemble average by using more than one random encodings
of the output space. In the AMIDA13 MICCAI grand competition, we achieve the
3rd highest F1-score in all the 17 participated teams. More ranking details are
available at http://amida13.isi.uu.nl/?q=node/62. Implementation of CNNCS is
available at https://github.com/yaoxuexa/CNNCS.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03309</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Systematic Testing of Convolutional Neural Networks for Autonomous
  Driving</dc:title>
 <dc:creator>Dreossi, Tommaso</dc:creator>
 <dc:creator>Ghosh, Shromona</dc:creator>
 <dc:creator>Sangiovanni-Vincentelli, Alberto</dc:creator>
 <dc:creator>Seshia, Sanjit A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We present a framework to systematically analyze convolutional neural
networks (CNNs) used in classification of cars in autonomous vehicles. Our
analysis procedure comprises an image generator that produces synthetic
pictures by sampling in a lower dimension image modification subspace and a
suite of visualization tools. The image generator produces images which can be
used to test the CNN and hence expose its vulnerabilities. The presented
framework can be used to extract insights of the CNN classifier, compare across
classification models, or generate training and validation datasets.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03310</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Thinking, Fast and Slow: Combining Vector Spaces and Knowledge Graphs</dc:title>
 <dc:creator>Mittal, Sudip</dc:creator>
 <dc:creator>Joshi, Anupam</dc:creator>
 <dc:creator>Finin, Tim</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Knowledge graphs and vector space models are robust knowledge representation
techniques with individual strengths and weaknesses. Vector space models excel
at determining similarity between concepts, but are severely constrained when
evaluating complex dependency relations and other logic-based operations that
are a strength of knowledge graphs. We describe the VKG structure that helps
unify knowledge graphs and vector representation of entities, and enables
powerful inference methods and search capabilities that combine their
complementary strengths. We analogize this to thinking `fast' in vector space
along with thinking 'slow' and `deeply' by reasoning over the knowledge graph.
We have created a query processing engine that takes complex queries and
decomposes them into subqueries optimized to run on the respective knowledge
graph or vector view of a VKG. We show that the VKG structure can process
specific queries that are not efficiently handled by vector spaces or knowledge
graphs alone. We also demonstrate and evaluate the VKG structure and the query
processing engine by developing a system called Cyber-All-Intel for knowledge
extraction, representation and querying in an end-to-end pipeline grounded in
the cybersecurity informatics domain.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03312</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Radical-level Ideograph Encoder for RNN-based Sentiment Analysis of
  Chinese and Japanese</dc:title>
 <dc:creator>Ke, Yuanzhi</dc:creator>
 <dc:creator>Hagiwara, Masafumi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The character vocabulary can be very large in non-alphabetic languages such
as Chinese and Japanese, which makes neural network models huge to process such
languages. We explored a model for sentiment classification that takes the
embeddings of the radicals of the Chinese characters, i.e, hanzi of Chinese and
kanji of Japanese. Our model is composed of a CNN word feature encoder and a
bi-directional RNN document feature encoder. The results achieved are on par
with the character embedding-based models, and close to the state-of-the-art
word embedding-based models, with 90% smaller vocabulary, and at least 13% and
80% fewer parameters than the character embedding-based models and word
embedding-based models respectively. The results suggest that the radical
embedding-based approach is cost-effective for machine learning on Chinese and
Japanese.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03314</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partial Optimality of Dual Decomposition for MAP Inference in Pairwise
  MRFs</dc:title>
 <dc:creator>Bauer, Alexander</dc:creator>
 <dc:creator>Nakajima, Shinichi</dc:creator>
 <dc:creator>G&#xf6;rnitz, Nico</dc:creator>
 <dc:creator>M&#xfc;ller, Klaus-Robert</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Markov random fields (MRFs) are a powerful tool for modelling statistical
dependencies for a set of random variables using a graphical representation. An
important computational problem related to MRFs, called maximum a posteriori
(MAP) inference, is finding a joint variable assignment with the maximal
probability. It is well known that the two popular optimisation techniques for
this task, linear programming (LP) relaxation and dual decomposition (DD), have
a strong connection both providing an optimal solution to the MAP problem when
a corresponding LP relaxation is tight. However, less is known about their
relationship in the opposite and more realistic case. In this paper, we explain
how the fully integral assignments obtained via DD partially agree with the
optimal fractional assignments via LP relaxation when the latter is not tight.
In particular, for binary pairwise MRFs the corresponding result suggests that
both methods share the partial optimality property of their solutions.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03317</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Loss of community identity in opinion dynamics models as a function of
  inter-group interaction strength</dc:title>
 <dc:creator>Noorazar, Hossein</dc:creator>
 <dc:creator>Sottile, Matthew</dc:creator>
 <dc:creator>Vixie, Kevin</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  Recent technological changes have increased connectivity between individuals
around the world leading to higher frequency interactions between members of
communities that would be otherwise distant and disconnected. This paper
examines a model of opinion dynamics in interacting communities and studies how
increasing interaction frequency affects the ability for communities to retain
distinct identities versus falling into consensus or polarized states in which
community identity is lost. We also study the effect (if any) of opinion noise
related to a tendency for individuals to assert their individuality in
homogenous populations. Our work builds on a model we developed previously [11]
where the dynamics of opinion change is based on individual interactions that
seek to minimize some energy potential based on the differences between
opinions across the population.
</dc:description>
 <dc:date>2017-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03322</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Output Reachable Set Estimation and Verification for Multi-Layer Neural
  Networks</dc:title>
 <dc:creator>Xiang, Weiming</dc:creator>
 <dc:creator>Tran, Hoang-Dung</dc:creator>
 <dc:creator>Johnson, Taylor T.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, the output reachable estimation and safety verification
problems for multi-layer perceptron neural networks are addressed. First, a
conception called maximum sensitivity in introduced and, for a class of
multi-layer perceptrons whose activation functions are monotonic functions, the
maximum sensitivity can be computed via solving convex optimization problems.
Then, using a simulation-based method, the output reachable set estimation
problem for neural networks is formulated into a chain of optimization
problems, which can be efficiently solved by using convex optimization tools.
Finally, an automated safety verification is developed based on the output
reachable set estimation result. An application to the safety verification for
a robotic arm model with two joints is presented to show the effectiveness of
proposed approaches.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03324</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidirectional User Throughput Maximization Based on Feedback Reduction
  in LiFi Networks</dc:title>
 <dc:creator>Soltani, Mohammad Dehghani</dc:creator>
 <dc:creator>Wu, Xiping</dc:creator>
 <dc:creator>Safari, Majid</dc:creator>
 <dc:creator>Haas, Harald</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Channel adaptive signalling, which is based on feedback, can result in almost
any performance metric enhancement. Unlike the radio frequency (RF) channel,
the optical wireless communications (OWCs) channel is fairly static. This
feature enables a potential improvement of the bidirectional user throughput by
reducing the amount of feedback. Light-Fidelity (LiFi) is a subset of OWCs, and
it is a bidirectional, high-speed and fully networked wireless communication
technology where visible light and infrared are used in downlink and uplink
respectively. In this paper, two techniques for reducing the amount of feedback
in LiFi cellular networks are proposed, i) Limited-content feedback (LCF)
scheme based on reducing the content of feedback information and ii)
Limited-frequency feedback (LFF) based on the update interval scheme that lets
the receiver to transmit feedback information after some data frames
transmission. Furthermore, based on the random waypoint (RWP) mobility model,
the optimum update interval which provides maximum bidirectional user equipment
(UE) throughput, has been derived. Results show that the proposed schemes can
achieve better average overall throughput compared to the benchmark one-bit
feedback and full-feedback mechanisms.
</dc:description>
 <dc:description>Comment: 30 pages, 9 figures, submitted to IEEE Transactions on Communications</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03338</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stability of glassy hierarchical networks</dc:title>
 <dc:creator>Zamani, Maryam</dc:creator>
 <dc:creator>Camargo-Forero, Leonardo</dc:creator>
 <dc:creator>Vicsek, Tamas</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The structure of interactions in most of animals and human societies can be
best represented by complex hierarchical networks. In order to maintain close
to optimal functioning both stability and adaptability are necessary. Here we
investigate the stability of hierarchical networks that emerge from the
simulations of an organization-type having an efficiency function reminiscent
of the Hamiltonian of spin-glasses. Using this quantitative approach we find a
number of expected (from everyday observations) and highly non-trivial results
for the obtained locally optimal networks, including such as: i) stability
increases with growing efficiency and level of hierarchy, ii) the same
perturbation results in a larger change for more efficient states, iii)
networks with a lower level of hierarchy become more efficient after
perturbation, iv) due to the huge number of possible optimal states only a
small fraction of them exhibits resilience and, finally, v) &quot;attacks&quot; targeting
the nodes selectively (regarding their position in the hierarchy) can result in
paradoxical outcomes.
</dc:description>
 <dc:description>Comment: 13 pages, 8 figures</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03341</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Technical Problems With &quot;Programmable self-assembly in a thousand-robot
  swarm&quot;</dc:title>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Pattern Formation and Solitons</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  Rubenstein et al. present an interesting system of programmable
self-assembled structure formation using 1000 Kilobot robots. The paper claims
to advance work in artificial swarms similar to capabilities of natural systems
besides being highly robust. However, the system lacks in terms of matching
motility and complex shapes with holes, thereby limiting practical similarity
to self-assembly in living systems.
</dc:description>
 <dc:description>Comment: 5 pages, eLetter response to article in Science 345(6198), pp.
  795-799, 2014</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03341</dc:identifier>
 <dc:identifier>doi:10.6084/m9.figshare.1185186.v1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03346</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lempel-Ziv Jaccard Distance, an Effective Alternative to Ssdeep and
  Sdhash</dc:title>
 <dc:creator>Raff, Edward</dc:creator>
 <dc:creator>Nicholas, Charles K.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Recent work has proposed the Lempel-Ziv Jaccard Distance (LZJD) as a method
to measure the similarity between binary byte sequences for malware
classification. We propose and test LZJD's effectiveness as a similarity digest
hash for digital forensics. To do so we develop a high performance Java
implementation with the same command-line arguments as sdhash, making it easy
to integrate into existing work-flows. Our testing shows that LZJD is effective
for this task, and significantly outperforms sdhash and ssdeep in its ability
to match related file fragments and is faster at comparison time.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03347</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Half-Duplex Routing is NP-hard</dc:title>
 <dc:creator>Ezzeldin, Yahya H.</dc:creator>
 <dc:creator>Cardone, Martina</dc:creator>
 <dc:creator>Fragouli, Christina</dc:creator>
 <dc:creator>Tuninetti, Daniela</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Routing is a widespread approach to transfer information from a source node
to a destination node in many deployed wireless ad-hoc networks. Today's
implemented routing algorithms seek to efficiently find the path/route with the
largest Full-Duplex (FD) capacity, which is given by the minimum among the
point-to-point link capacities in the path. Such an approach may be suboptimal
if then the nodes in the selected path are operated in Half-Duplex (HD) mode.
Recently, the capacity (up to a constant gap that only depends on the number of
nodes in the path) of an HD line network i.e., a path) has been shown to be
equal to half of the minimum of the harmonic means of the capacities of two
consecutive links in the path. This paper asks the questions of whether it is
possible to design a polynomial-time algorithm that efficiently finds the path
with the largest HD capacity in a relay network. This problem of finding that
path is shown to be NP-hard in general. However, if the number of cycles in the
network is polynomial in the number of nodes, then a polynomial-time algorithm
can indeed be designed.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03352</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A discrete event system specification (DEVS)-based model of
  consanguinity</dc:title>
 <dc:creator>Akhtar, Noreen</dc:creator>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:creator>Mustafa, Farah</dc:creator>
 <dc:creator>Hussain, Amir</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>I.2.0</dc:subject>
 <dc:subject>I.6</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:subject>B.1.2</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:description>  Consanguinity or inter-cousin marriage is a phenomenon quite prevalent in
certain regions around the globe. Consanguineous parents have a higher risk of
having offspring with congenital disorders. It is difficult to model large
scale consanguineous parental populations because of disparate cultural issues
unique to regions and cultures across the globe. Although consanguinity, as a
social problem has been studied previously, consanguinity from a biological
perspective has yet to be modeled. Discrete Event System Specification (DEVS)
formalism is a powerful modeling formalism for the study of intricate details
of real-world complex systems. In this article, we develop a DEVS model to get
an insight into the role of consanguineous marriages in the evolution of
congenital disorders in a population. As proof-of-concept, we develop a
consanguinity simulation model in Simio simulation software. Our results show
the effectiveness of DEVS in the modeling of consanguinity effects in causing
congenital defects.
</dc:description>
 <dc:description>Comment: 41 pages, 10 figures</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03352</dc:identifier>
 <dc:identifier>Journal of theoretical biology, 285(1), 103-112 (2011)</dc:identifier>
 <dc:identifier>doi:10.1016/j.jtbi.2011.05.038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03355</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fundamental Limits of PhaseMax for Phase Retrieval: A Replica Analysis</dc:title>
 <dc:creator>Dhifallah, Oussama</dc:creator>
 <dc:creator>Lu, Yue M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a recently proposed convex formulation, known as the PhaseMax
method, for solving the phase retrieval problem. Using the replica method from
statistical mechanics, we analyze the performance of PhaseMax in the
high-dimensional limit. Our analysis predicts the \emph{exact} asymptotic
performance of PhaseMax. In particular, we show that a sharp phase transition
phenomenon takes place, with a simple analytical formula characterizing the
phase transition boundary. This result shows that the oversampling ratio
required by existing performance bounds in the literature can be significantly
reduced. Numerical results confirm the validity of our replica analysis,
showing that the theoretical predictions are in excellent agreement with the
actual performance of the algorithm, even for moderate signal dimensions.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03361</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Writer Identification and Verification from Intra-variable Individual
  Handwriting</dc:title>
 <dc:creator>Adak, Chandranath</dc:creator>
 <dc:creator>Chaudhuri, Bidyut B.</dc:creator>
 <dc:creator>Blumenstein, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The handwriting of an individual may vary excessively with many factors such
as mood, time, space, writing speed, writing medium, utensils etc. Therefore,
it becomes more challenging to perform automated writer verification/
identification on a particular set of handwritten patterns (e.g. speedy
handwriting) of a person, especially when the system is trained using a
different set of writing patterns (e.g. normal/medium speed) of that same
person. However, it would be interesting to experimentally analyze if there
exists any implicit characteristic of individuality which is insensitive to
high intra-variable handwriting. In this paper, we work on writer
identification/ verification from offline Bengali handwriting of high
intra-variability. To this end, we use two separate models for the writer
identification/verification task: (a) hand-crafted features with an SVM model
and (b) auto-derived features with a recurrent neural network. For
experimentation, we have generated a handwriting database from 100 writers and
have obtained some interesting results on training-testing with different
writing speeds.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03366</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resilient Linear Classification: An Approach to Deal with Attacks on
  Training Data</dc:title>
 <dc:creator>Park, Sangdon</dc:creator>
 <dc:creator>Weimer, James</dc:creator>
 <dc:creator>Lee, Insup</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Data-driven techniques are used in cyber-physical systems (CPS) for
controlling autonomous vehicles, handling demand responses for energy
management, and modeling human physiology for medical devices. These
data-driven techniques extract models from training data, where their
performance is often analyzed with respect to random errors in the training
data. However, if the training data is maliciously altered by attackers, the
effect of these attacks on the learning algorithms underpinning data-driven CPS
have yet to be considered. In this paper, we analyze the resilience of
classification algorithms to training data attacks. Specifically, a generic
metric is proposed that is tailored to measure resilience of classification
algorithms with respect to worst-case tampering of the training data. Using the
metric, we show that traditional linear classification algorithms are resilient
under restricted conditions. To overcome these limitations, we propose a linear
classification algorithm with a majority constraint and prove that it is
strictly more resilient than the traditional algorithms. Evaluations on both
synthetic data and a real-world retrospective arrhythmia medical case-study
show that the traditional algorithms are vulnerable to tampered training data,
whereas the proposed algorithm is more resilient (as measured by worst-case
tampering).
</dc:description>
 <dc:description>Comment: Accepted as a conference paper at ICCPS17</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03366</dc:identifier>
 <dc:identifier>doi:10.1145/3055004.3055006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03381</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topical Behavior Prediction from Massive Logs</dc:title>
 <dc:creator>Su, Shih-Chieh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we study the topical behavior in a large scale. We use the
network logs where each entry contains the entity ID, the timestamp, and the
meta data about the activity. Both the temporal and the spatial relationships
of the behavior are explored with the deep learning architectures combing the
recurrent neural network (RNN) and the convolutional neural network (CNN). To
make the behavioral data appropriate for the spatial learning in the CNN, we
propose several reduction steps to form the topical metrics and to place them
homogeneously like pixels in the images. The experimental result shows both
temporal and spatial gains when compared against a multilayer perceptron (MLP)
network. A new learning framework called the spatially connected convolutional
networks (SCCN) is introduced to predict the topical metrics more efficiently.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03383</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Multi-Person Pose Estimation and Semantic Part Segmentation</dc:title>
 <dc:creator>Xia, Fangting</dc:creator>
 <dc:creator>Wang, Peng</dc:creator>
 <dc:creator>Chen, Xianjie</dc:creator>
 <dc:creator>Yuille, Alan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human pose estimation and semantic part segmentation are two complementary
tasks in computer vision. In this paper, we propose to solve the two tasks
jointly for natural multi-person images, in which the estimated pose provides
object-level shape prior to regularize part segments while the part-level
segments constrain the variation of pose locations. Specifically, we first
train two fully convolutional neural networks (FCNs), namely Pose FCN and Part
FCN, to provide initial estimation of pose joint potential and semantic part
potential. Then, to refine pose joint location, the two types of potentials are
fused with a fully-connected conditional random field (FCRF), where a novel
segment-joint smoothness term is used to encourage semantic and spatial
consistency between parts and joints. To refine part segments, the refined pose
and the original part potential are integrated through a Part FCN, where the
skeleton feature from pose serves as additional regularization cues for part
segments. Finally, to reduce the complexity of the FCRF, we induce human
detection boxes and infer the graph inside each box, making the inference forty
times faster.
  Since there's no dataset that contains both part segments and pose labels, we
extend the PASCAL VOC part dataset with human pose joints and perform extensive
experiments to compare our method against several most recent strategies. We
show that on this dataset our algorithm surpasses competing methods by a large
margin in both tasks.
</dc:description>
 <dc:description>Comment: This paper has been accepted by CVPR 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03387</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiparty Routing: Secure Routing for Mixnets</dc:title>
 <dc:creator>Shirazi, Fatemeh</dc:creator>
 <dc:creator>Andreeva, Elena</dc:creator>
 <dc:creator>Kohlweiss, Markulf</dc:creator>
 <dc:creator>Diaz, Claudia</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Anonymous communication networks are important building blocks for online
privacy protection. One approach to achieve anonymity is to relay messages
through multiple routers, where each router shuffles messages independently. To
achieve anonymity, at least one router needs to be honest. In the presence of
an adversary that is controlling a subset of the routers unbiased routing is
important for guaranteeing anonymity. However, the routing strategy also
influenced other factors such as the scalability and the performance of the
system. One solution is to use a fixed route for relaying all messages with
many routers. If the route is not fixed the routing decision can either be made
by the communication initiator or the intermediate routers. However, the
existing routing types each have limitations. For example, one faces
scalability issues when increasing the throughput of systems with fixed routes.
Moreover, when the routing decision is left to the initiator, the initiator
needs to maintain an up-to-date view of the system at all times, which also
does not scale. If the routing decision is left to intermediate routers the
routing of the communication can be influenced by an adversary. In this work,
we propose a novel multiparty routing approach for anonymous communication that
addresses these shortcomings. We distribute the routing decision and verify the
correctness of routing to achieve routing integrity. More concretely, we
provide a mixnet design that uses our routing approach and that in addition,
addresses load balancing. We show that our system is secure against a global
active adversary.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03387</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03389</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Logical Approach to Cloud Federation</dc:title>
 <dc:creator>Cao, Qiang</dc:creator>
 <dc:creator>Yao, Yuanjun</dc:creator>
 <dc:creator>Chase, Jeff</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Federated clouds raise a variety of challenges for managing identity,
resource access, naming, connectivity, and object access control. This paper
shows how to address these challenges in a comprehensive and uniform way using
a data-centric approach. The foundation of our approach is a trust logic in
which participants issue authenticated statements about principals, objects,
attributes, and relationships in a logic language, with reasoning based on
declarative policy rules. We show how to use the logic to implement a trust
infrastructure for cloud federation that extends the model of NSF GENI, a
federated IaaS testbed. It captures shared identity management, GENI authority
services, cross-site interconnection using L2 circuits, and a naming and access
control system similar to AWS Identity and Access Management (IAM), but
extended to a federated system without central control.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03390</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making Sense of Word Embeddings</dc:title>
 <dc:creator>Pelevina, Maria</dc:creator>
 <dc:creator>Arefyev, Nikolay</dc:creator>
 <dc:creator>Biemann, Chris</dc:creator>
 <dc:creator>Panchenko, Alexander</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a simple yet effective approach for learning word sense
embeddings. In contrast to existing techniques, which either directly learn
sense representations from corpora or rely on sense inventories from lexical
resources, our approach can induce a sense inventory from existing word
embeddings via clustering of ego-networks of related words. An integrated WSD
mechanism enables labeling of words in context with learned sense vectors,
which gives rise to downstream applications. Experiments show that the
performance of our method is comparable to state-of-the-art unsupervised WSD
systems.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03392</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Jumping across biomedical contexts using compressive data fusion</dc:title>
 <dc:creator>Zitnik, Marinka</dc:creator>
 <dc:creator>Zupan, Blaz</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Motivation: The rapid growth of diverse biological data allows us to consider
interactions between a variety of objects, such as genes, chemicals, molecular
signatures, diseases, pathways and environmental exposures. Often, any pair of
objects--such as a gene and a disease--can be related in different ways, for
example, directly via gene-disease associations or indirectly via functional
annotations, chemicals and pathways. Different ways of relating these objects
carry different semantic meanings. However, traditional methods disregard these
semantics and thus cannot fully exploit their value in data modeling.
  Results: We present Medusa, an approach to detect size-k modules of objects
that, taken together, appear most significant to another set of objects. Medusa
operates on large-scale collections of heterogeneous data sets and explicitly
distinguishes between diverse data semantics. It advances research along two
dimensions: it builds on collective matrix factorization to derive different
semantics, and it formulates the growing of the modules as a submodular
optimization program. Medusa is flexible in choosing or combining semantic
meanings and provides theoretical guarantees about detection quality. In a
systematic study on 310 complex diseases, we show the effectiveness of Medusa
in associating genes with diseases and detecting disease modules. We
demonstrate that in predicting gene-disease associations Medusa compares
favorably to methods that ignore diverse semantic meanings. We find that the
utility of different semantics depends on disease categories and that, overall,
Medusa recovers disease modules more accurately when combining different
semantics.
</dc:description>
 <dc:description>Comment: In Proceedings of the 24th International Conference on Intelligent
  Systems for Molecular Biology (ISMB), 2016</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03392</dc:identifier>
 <dc:identifier>Bioinformatics, 32 (12): i90-i100 (2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03395</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Transitions, Optimal Errors and Optimality of Message-Passing in
  Generalized Linear Models</dc:title>
 <dc:creator>Barbier, Jean</dc:creator>
 <dc:creator>Krzakala, Florent</dc:creator>
 <dc:creator>Macris, Nicolas</dc:creator>
 <dc:creator>Miolane, L&#xe9;o</dc:creator>
 <dc:creator>Zdeborov&#xe1;, Lenka</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:description>  We consider generalized linear models (GLMs) where an unknown $n$-dimensional
signal vector is observed through the application of a random matrix and a
non-linear (possibly probabilistic) componentwise output function. We consider
the models in the high-dimensional limit, where the observation consists of m
points, and $m/n\to\alpha$ where $\alpha$ stays finite in the limit
$m,n\to\infty$. This situation is ubiquitous in applications ranging from
supervised machine learning to signal processing. A substantial amount of
theoretical work analyzed the model-case when the observation matrix has i.i.d.
elements and the components of the ground-truth signal are taken independently
from some known distribution. While statistical physics provided number of
explicit conjectures for special cases of this model, results existing for
non-linear output functions were so far non-rigorous. At the same time GLMs
with non-linear output functions are used as a basic building block of powerful
multilayer feedforward neural networks. Therefore rigorously establishing the
formulas conjectured for the mutual information is a key open problem that we
solve in this paper. We also provide an explicit asymptotic formula for the
optimal generalization error, and confirm the prediction of phase transitions
in GLMs. Analyzing the resulting formulas for several non-linear output
functions, including the rectified linear unit or modulus functions, we obtain
quantitative descriptions of information-theoretic limitations of
high-dimensional inference. Our proof technique relies on a new version of the
interpolation method with an adaptive interpolation path and is of independent
interest. Furthermore we show that a polynomial-time algorithm referred to as
generalized approximate message-passing reaches the optimal generalization
error for a large set of parameters.
</dc:description>
 <dc:description>Comment: 59 pages, 3 figures</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03395</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03402</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Product Matrix MSR Codes with Bandwidth Adaptive Exact Repair</dc:title>
 <dc:creator>Mahdaviani, Kaveh</dc:creator>
 <dc:creator>Mohajer, Soheil</dc:creator>
 <dc:creator>Khisti, Ashish</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In a distributed storage systems (DSS) with $k$ systematic nodes, robustness
against node failure is commonly provided by storing redundancy in a number of
other nodes and performing repair mechanism to reproduce the content of the
failed nodes. Efficiency is then achieved by minimizing the storage overhead
and the amount of data transmission required for data reconstruction and
repair, provided by coding solutions such as regenerating codes [1]. Common
explicit regenerating code constructions enable efficient repair through
accessing a predefined number, $d$, of arbitrary chosen available nodes, namely
helpers. In practice, however, the state of the system dynamically changes
based on the request load, the link traffic, etc., and the parameters which
optimize system's performance vary accordingly. It is then desirable to have
coding schemes which are able to operate optimally under a range of different
parameters simultaneously. Specifically, adaptivity in the number of helper
nodes for repair is of interest. While robustness requires capability of
performing repair with small number of helpers, it is desirable to use as many
helpers as available to reduce the transmission delay and total repair traffic.
  In this work we focus on the minimum storage regenerating (MSR) codes, where
each node is supposed to store $\alpha$ information units, and the source data
of size $k\alpha$ could be recovered from any arbitrary set of $k$ nodes. We
introduce a class MSR codes that realize optimal repair bandwidth
simultaneously with a set of different choices for the number of helpers,
namely $D=\{d_{1}, \cdots, d_{\delta}\}$. Our coding scheme follows the Product
Matrix (PM) framework introduced in [2], and could be considered as a
generalization of the PM MSR code presented in [2], such that any $d_{i} =
(i+1)(k-1)$ helpers can perform an optimal repair. ...
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03403</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kripke Completeness of Strictly Positive Modal Logics over
  Meet-semilattices with Operators</dc:title>
 <dc:creator>Kikot, S.</dc:creator>
 <dc:creator>Kurucz, A.</dc:creator>
 <dc:creator>Tanaka, Y.</dc:creator>
 <dc:creator>Wolter, F.</dc:creator>
 <dc:creator>Zakharyaschev, M.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Our concern is the completeness problem for strongly positive (SP) theories,
that is, sets of implications between SP-terms built from propositional
variables, conjunction and modal diamond operators. Originated in logic,
algebra and computer science, SP-theories have two natural semantics:
meet-semilattices with monotone operators providing Birkhoff-style calculi, and
first-order relational structures (aka Kripke frames) often used as the
intended structures in applications. Here we lay foundations of a completeness
theory that aims to answer the question whether the two semantics define the
same consequence relations for a given SP-theory.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03416</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pose Guided Structured Region Ensemble Network for Cascaded Hand Pose
  Estimation</dc:title>
 <dc:creator>Chen, Xinghao</dc:creator>
 <dc:creator>Wang, Guijin</dc:creator>
 <dc:creator>Guo, Hengkai</dc:creator>
 <dc:creator>Zhang, Cairong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Hand pose estimation from a single depth image is an essential topic in
computer vision and human computer interaction. Despite recent advancements in
this area promoted by convolutional neural network, accurate hand pose
estimation is still a challenging problem. In this paper we propose a Pose
guided structured Region Ensemble Network (Pose-REN) to boost the performance
of hand pose estimation. The proposed method extracts regions from the feature
maps of convolutional neural network under the guide of an initially estimated
pose, generating more optimal and representative features for hand pose
estimation. The extracted feature regions are then integrated hierarchically
according to the topology of hand joints by employing tree-structured fully
connections. A refined estimation of hand pose is directly regressed by the
proposed network and the final hand pose is obtained by utilizing an iterative
cascaded method. Comprehensive experiments on public hand pose datasets
demonstrate that our proposed method outperforms state-of-the-art algorithms.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03417</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GlobeNet: Convolutional Neural Networks for Typhoon Eye Tracking from
  Remote Sensing Imagery</dc:title>
 <dc:creator>Hong, Seungkyun</dc:creator>
 <dc:creator>Kim, Seongchan</dc:creator>
 <dc:creator>Joh, Minsu</dc:creator>
 <dc:creator>Song, Sa-kwang</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Advances in remote sensing technologies have made it possible to use
high-resolution visual data for weather observation and forecasting tasks. We
propose the use of multi-layer neural networks for understanding complex
atmospheric dynamics based on multichannel satellite images. The capability of
our model was evaluated by using a linear regression task for single typhoon
coordinates prediction. A specific combination of models and different
activation policies enabled us to obtain an interesting prediction result in
the northeastern hemisphere (ENH).
</dc:description>
 <dc:description>Comment: Under review as a workshop paper at CI 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03418</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Attend, Copy, and Generate for Session-Based Query
  Suggestion</dc:title>
 <dc:creator>Dehghani, Mostafa</dc:creator>
 <dc:creator>Rothe, Sascha</dc:creator>
 <dc:creator>Alfonseca, Enrique</dc:creator>
 <dc:creator>Fleury, Pascal</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Users try to articulate their complex information needs during search
sessions by reformulating their queries. To make this process more effective,
search engines provide related queries to help users in specifying the
information need in their search process. In this paper, we propose a
customized sequence-to-sequence model for session-based query suggestion. In
our model, we employ a query-aware attention mechanism to capture the structure
of the session context. is enables us to control the scope of the session from
which we infer the suggested next query, which helps not only handle the noisy
data but also automatically detect session boundaries. Furthermore, we observe
that, based on the user query reformulation behavior, within a single session a
large portion of query terms is retained from the previously submitted queries
and consists of mostly infrequent or unseen terms that are usually not included
in the vocabulary. We therefore empower the decoder of our model to access the
source words from the session context during decoding by incorporating a copy
mechanism. Moreover, we propose evaluation metrics to assess the quality of the
generative models for query suggestion. We conduct an extensive set of
experiments and analysis. e results suggest that our model outperforms the
baselines both in terms of the generating queries and scoring candidate queries
for the task of query suggestion.
</dc:description>
 <dc:description>Comment: Accepted to be published at The 26th ACM International Conference on
  Information and Knowledge Management (CIKM2017)</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03421</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>N-gram and Neural Language Models for Discriminating Similar Languages</dc:title>
 <dc:creator>Cianflone, Andre</dc:creator>
 <dc:creator>Kosseim, Leila</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper describes our submission (named clac) to the 2016 Discriminating
Similar Languages (DSL) shared task. We participated in the closed Sub-task 1
(Set A) with two separate machine learning techniques. The first approach is a
character based Convolution Neural Network with a bidirectional long short term
memory (BiLSTM) layer (CLSTM), which achieved an accuracy of 78.45% with
minimal tuning. The second approach is a character-based n-gram model. This
last approach achieved an accuracy of 88.45% which is close to the accuracy of
89.38% achieved by the best submission, and allowed us to rank #7 overall.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03421</dc:identifier>
 <dc:identifier>Proceedings of the Third Workshop on NLP for Similar Languages,
  Varieties and Dialects (VarDial3). A workshop of the 26th International
  Conference on Computational Linguistics (COLING 2016, Osaka, Japan), pp
  243-250 (2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03423</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Deblurring via Semantic Segmentation and Pixel-Wise Non-Linear
  Kernel</dc:title>
 <dc:creator>Ren, Wenqi</dc:creator>
 <dc:creator>Pan, Jinshan</dc:creator>
 <dc:creator>Cao, Xiaochun</dc:creator>
 <dc:creator>Yang, Ming-Hsuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Video deblurring is a challenging problem as the blur is complex and usually
caused by the combination of camera shakes, object motions, and depth
variations. Optical flow can be used for kernel estimation since it predicts
motion trajectories. However, the estimates are often inaccurate in complex
scenes at object boundaries, which are crucial in kernel estimation. In this
paper, we exploit semantic segmentation in each blurry frame to understand the
scene contents and use different motion models for image regions to guide
optical flow estimation. While existing pixel-wise blur models assume that the
blur kernel is the same as optical flow during the exposure time, this
assumption does not hold when the motion blur trajectory at a pixel is
different from the estimated linear optical flow. We analyze the relationship
between motion blur trajectory and optical flow, and present a novel pixel-wise
non-linear kernel model to account for motion blur. The proposed blur model is
based on the non-linear optical flow, which describes complex motion blur more
effectively. Extensive experiments on challenging blurry videos demonstrate the
proposed algorithm performs favorably against the state-of-the-art methods.
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03425</identifier>
 <datestamp>2017-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Argument Labeling of Explicit Discourse Relations using LSTM Neural
  Networks</dc:title>
 <dc:creator>Hooda, Sohail</dc:creator>
 <dc:creator>Kosseim, Leila</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Argument labeling of explicit discourse relations is a challenging task. The
state of the art systems achieve slightly above 55% F-measure but require
hand-crafted features. In this paper, we propose a Long Short Term Memory
(LSTM) based model for argument labeling. We experimented with multiple
configurations of our model. Using the PDTB dataset, our best model achieved an
F1 measure of 23.05% without any feature engineering. This is significantly
higher than the 20.52% achieved by the state of the art RNN approach, but
significantly lower than the feature based state of the art systems. On the
other hand, because our approach learns only from the raw dataset, it is more
widely applicable to multiple textual genres and languages.
</dc:description>
 <dc:description>Comment: Proceedings of Recent Advances in Natural Language Processing (RANLP
  2017), pp. 309-315, 4-6 September, Varna, Bulgaria</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03429</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nearly Optimal Sparse Group Testing</dc:title>
 <dc:creator>Gandikota, Venkata</dc:creator>
 <dc:creator>Grigorescu, Elena</dc:creator>
 <dc:creator>Jaggi, Sidharth</dc:creator>
 <dc:creator>Zhou, Samson</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Motivated by physical considerations, we study group testing models in which
the testing procedure is constrained to be &quot;sparse&quot;. Specifically, we consider
(separately) scenarios in which (a) items are finitely divisible and hence may
participate in at most $\gamma$ tests; and (b) tests are size-constrained to
pool no more than $\rho$ items per test. For both scenarios we provide
information-theoretic lower bounds on the number of tests required to guarantee
high probability recovery. In particular, one of our main results shows that
$\gamma$-finite divisibility of items forces any group testing algorithm with
probability of recovery error at most $\epsilon$ to perform at least
$\Omega(\gamma d(n/d)^{(1-2\epsilon)/((1+2\epsilon)\gamma)})$ tests.
Analogously, for $\rho$-sized constrained tests, we show an
information-theoretic lower bound of $\Omega(n\log(n/d)/(\rho\log(n/\rho d)))$.
In both scenarios we provide both randomized constructions (under both
$\epsilon$-error and zero-error reconstruction guarantees) and explicit
constructions of computationally efficient group-testing algorithms (under
$\epsilon$-error reconstruction guarantees) that require a number of tests that
are optimal up to constant factors in some regimes of $n, d, \gamma \text{ and
} \rho$. We also investigate the effect of unreliability/noise in test
outcomes.
  For the full abstract, please see the full text PDF.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03431</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Deep Convolutional Encoder-Decoder Network for Medical Image
  Segmentation</dc:title>
 <dc:creator>Kim, Jung Uk</dc:creator>
 <dc:creator>Kim, Hak Gu</dc:creator>
 <dc:creator>Ro, Yong Man</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel medical image segmentation using iterative
deep learning framework. We have combined an iterative learning approach and an
encoder-decoder network to improve segmentation results, which enables to
precisely localize the regions of interest (ROIs) including complex shapes or
detailed textures of medical images in an iterative manner. The proposed
iterative deep convolutional encoder-decoder network consists of two main
paths: convolutional encoder path and convolutional decoder path with iterative
learning. Experimental results show that the proposed iterative deep learning
framework is able to yield excellent medical image segmentation performances
for various medical images. The effectiveness of the proposed method has been
proved by comparing with other state-of-the-art medical image segmentation
methods.
</dc:description>
 <dc:description>Comment: accepted at EMBC 2017</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03436</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Deep Semantic Hashing for Text Documents</dc:title>
 <dc:creator>Chaidaroon, Suthee</dc:creator>
 <dc:creator>Fang, Yi</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  As the amount of textual data has been rapidly increasing over the past
decade, efficient similarity search methods have become a crucial component of
large-scale information retrieval systems. A popular strategy is to represent
original data samples by compact binary codes through hashing. A spectrum of
machine learning methods have been utilized, but they often lack expressiveness
and flexibility in modeling to learn effective representations. The recent
advances of deep learning in a wide range of applications has demonstrated its
capability to learn robust and powerful feature representations for complex
data. Especially, deep generative models naturally combine the expressiveness
of probabilistic generative models with the high capacity of deep neural
networks, which is very suitable for text modeling. However, little work has
leveraged the recent progress in deep learning for text hashing.
  In this paper, we propose a series of novel deep document generative models
for text hashing. The first proposed model is unsupervised while the second one
is supervised by utilizing document labels/tags for hashing. The third model
further considers document-specific factors that affect the generation of
words. The probabilistic generative formulation of the proposed models provides
a principled framework for model extension, uncertainty estimation, simulation,
and interpretability. Based on variational inference and reparameterization,
the proposed models can be interpreted as encoder-decoder deep neural networks
and thus they are capable of learning complex nonlinear distributed
representations of the original documents. We conduct a comprehensive set of
experiments on four public testbeds. The experimental results have demonstrated
the effectiveness of the proposed supervised learning models for text hashing.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03438</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Veamy: an extensible object-oriented C++ library for the virtual element
  method</dc:title>
 <dc:creator>Ortiz-Bernardin, Alejandro</dc:creator>
 <dc:creator>Alvarez, Catalina</dc:creator>
 <dc:creator>Hitschfeld-Kahler, Nancy</dc:creator>
 <dc:creator>Russo, Alessandro</dc:creator>
 <dc:creator>Silva-Valenzuela, Rodrigo</dc:creator>
 <dc:creator>Olate-Sanzana, Edgardo</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  This paper summarizes the development of Veamy, an object-oriented C++
library for the virtual element method (VEM) on general polygonal meshes, whose
modular design is focused on its extensibility. The two-dimensional linear
elastostatic problem has been chosen as the starting stage for the development
of this library. The theory of the VEM in which Veamy is based upon is
presented using a notation and a terminology that resemble the language of the
finite element method in engineering analysis. Several examples are provided to
demonstrate the usage of Veamy, and in particular, one of them features the
interaction between Veamy and the polygonal mesh generator PolyMesher. Veamy is
free and open source software.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03439</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorial Optimization by Decomposition on Hybrid CPU--non-CPU
  Solver Architectures</dc:title>
 <dc:creator>Narimani, Ali</dc:creator>
 <dc:creator>Rezaei, Seyed Saeed Changiz</dc:creator>
 <dc:creator>Zaribafiyan, Arman</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The advent of new special-purpose hardware such as FPGA or ASIC-based
annealers and quantum processors has shown potential in solving certain
families of complex combinatorial optimization problems more efficiently than
conventional CPUs. We show that to address an industrial optimization problem,
a hybrid architecture of CPUs and non-CPU devices is inevitable. In this paper,
we propose problem decomposition as an effective method for designing a hybrid
CPU--non-CPU optimization solver. We introduce the required algorithmic
elements for making problem decomposition a viable approach in meeting the
real-world constraints such as communication time and the potential higher cost
of using non-CPU hardware. We then turn to the well-known maximum clique
problem, and propose a new method of decomposition for this problem. Our method
enables us to solve the maximum clique problem on very large graphs using
non-CPU hardware that is considerably smaller than the size of the graph. As an
example, we show that the maximum clique problem on the com-Amazon graph, with
334,863 vertices and 925,872 edges, can be solved with a single call to a
device that can embed a fully connected graph of size at least 21 nodes, such
as the D-Wave 2000Q. We also show that our proposed problem decomposition
approach can improve the runtime of two of the best-known classical algorithms
for large, sparse graphs, namely PMC and BBMCSP, by orders of magnitude. In the
light of our study, we believe that new non-CPU hardware that is small in size
could become competitive with CPUs if it could be either mass produced and
highly parallelized, or able to provide high-quality solutions to specific,
small-sized problems significantly faster than CPUs.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03446</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What matters in a transferable neural network model for relation
  classification in the biomedical domain?</dc:title>
 <dc:creator>Sahu, Sunil Kumar</dc:creator>
 <dc:creator>Anand, Ashish</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Lack of sufficient labeled data often limits the applicability of advanced
machine learning algorithms to real life problems. However efficient use of
Transfer Learning (TL) has been shown to be very useful across domains. TL
utilizes valuable knowledge learned in one task (source task), where sufficient
data is available, to the task of interest (target task). In biomedical and
clinical domain, it is quite common that lack of sufficient training data do
not allow to fully exploit machine learning models. In this work, we present
two unified recurrent neural models leading to three transfer learning
frameworks for relation classification tasks. We systematically investigate
effectiveness of the proposed frameworks in transferring the knowledge under
multiple aspects related to source and target tasks, such as, similarity or
relatedness between source and target tasks, and size of training data for
source task. Our empirical results show that the proposed frameworks in general
improve the model performance, however these improvements do depend on aspects
related to source and target tasks. This dependence then finally determine the
choice of a particular TL framework.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03447</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unified Neural Architecture for Drug, Disease and Clinical Entity
  Recognition</dc:title>
 <dc:creator>Sahu, Sunil Kumar</dc:creator>
 <dc:creator>Anand, Ashish</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Most existing methods for biomedical entity recognition task rely on explicit
feature engineering where many features either are specific to a particular
task or depends on output of other existing NLP tools. Neural architectures
have been shown across various domains that efforts for explicit feature design
can be reduced. In this work we propose an unified framework using
bi-directional long short term memory network (BLSTM) for named entity
recognition (NER) tasks in biomedical and clinical domains. Three important
characteristics of the framework are as follows - (1) model learns contextual
as well as morphological features using two different BLSTM in hierarchy, (2)
model uses first order linear conditional random field (CRF) in its output
layer in cascade of BLSTM to infer label or tag sequence, (3) model does not
use any domain specific features or dictionary, i.e., in another words, same
set of features are used in the three NER tasks, namely, disease name
recognition (Disease NER), drug name recognition (Drug NER) and clinical entity
recognition (Clinical NER). We compare performance of the proposed model with
existing state-of-the-art models on the standard benchmark datasets of the
three tasks. We show empirically that the proposed framework outperforms all
existing models. Further our analysis of CRF layer and word-embedding obtained
using character based embedding show their importance.
</dc:description>
 <dc:description>Comment: 23 pages, 2 figures</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03453</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for BGP Abnormal Events Detection</dc:title>
 <dc:creator>Allahdadi, Anisa</dc:creator>
 <dc:creator>Morla, Ricardo</dc:creator>
 <dc:creator>Prior, Rui</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Detection of abnormal BGP events is of great importance to preserve the
security and robustness of the Internet inter-domain routing system. In this
paper, we propose an anomaly detection framework based on machine learning
techniques to identify the anomalous events by training a model for normal
BGP-updates and measuring the extent of deviation from the normal model during
the abnormal occasions. Our preliminary results show that the features
generated and selected are capable of improving the classification results to
distinguish between anomalies and normal BGP update messages. Furthermore, the
clustering results demonstrate the effectiveness of formed models to detect the
similar types of BGP anomalies. In a more general context, an interdisciplinary
research is performed between network security and data mining to deal with
real-world problems and the achieved results are promising.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03462</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SkyLens: Visual Analysis of Skyline on Multi-dimensional Data</dc:title>
 <dc:creator>Zhao, Xun</dc:creator>
 <dc:creator>Wu, Yanhong</dc:creator>
 <dc:creator>Cui, Weiwei</dc:creator>
 <dc:creator>Du, Xinnan</dc:creator>
 <dc:creator>Chen, Yuan</dc:creator>
 <dc:creator>Wang, Yong</dc:creator>
 <dc:creator>Lee, Dik Lun</dc:creator>
 <dc:creator>Qu, Huamin</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Skyline queries have wide-ranging applications in fields that involve
multi-criteria decision making, including tourism, retail industry, and human
resources. By automatically removing incompetent candidates, skyline queries
allow users to focus on a subset of superior data items (i.e., the skyline),
thus reducing the decision-making overhead. However, users are still required
to interpret and compare these superior items manually before making a
successful choice. This task is challenging because of two issues. First,
people usually have fuzzy, unstable, and inconsistent preferences when
presented with multiple candidates. Second, skyline queries do not reveal the
reasons for the superiority of certain skyline points in a multi-dimensional
space. To address these issues, we propose SkyLens, a visual analytic system
aiming at revealing the superiority of skyline points from different
perspectives and at different scales to aid users in their decision making. Two
scenarios demonstrate the usefulness of SkyLens on two datasets with a dozen of
attributes. A qualitative study is also conducted to show that users can
efficiently accomplish skyline understanding and comparison tasks with SkyLens.
</dc:description>
 <dc:description>Comment: 10 pages. Accepted for publication at IEEE VIS 2017 (in proceedings
  of VAST)</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03465</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DNN Transfer Learning based Non-linear Feature Extraction for Acoustic
  Event Classification</dc:title>
 <dc:creator>Mun, Seongkyu</dc:creator>
 <dc:creator>Shin, Minkyu</dc:creator>
 <dc:creator>Shon, Suwon</dc:creator>
 <dc:creator>Kim, Wooil</dc:creator>
 <dc:creator>Han, David K.</dc:creator>
 <dc:creator>Ko, Hanseok</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Recent acoustic event classification research has focused on training
suitable filters to represent acoustic events. However, due to limited
availability of target event databases and linearity of conventional filters,
there is still room for improving performance. By exploiting the non-linear
modeling of deep neural networks (DNNs) and their ability to learn beyond
pre-trained environments, this letter proposes a DNN-based feature extraction
scheme for the classification of acoustic events. The effectiveness and
robustness to noise of the proposed method are demonstrated using a database of
indoor surveillance environments.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03465</dc:identifier>
 <dc:identifier>IEICE TRANSACTIONS on Information and Systems, Vol.E100-D, No.9
  (2017)</dc:identifier>
 <dc:identifier>doi:10.1587/transinf.2017EDL8048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03468</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Key exchange with the help of a public ledger</dc:title>
 <dc:creator>Bui, Thanh</dc:creator>
 <dc:creator>Aura, Tuomas</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Blockchains and other public ledger structures promise a new way to create
globally consistent event logs and other records. We make use of this
consistency property to detect and prevent man-in-the-middle attacks in a key
exchange such as Diffie-Hellman or ECDH. Essentially, the MitM attack creates
an inconsistency in the world views of the two honest parties, and they can
detect it with the help of the ledger. Thus, there is no need for prior
knowledge or trusted third parties apart from the distributed ledger. To
prevent impersonation attacks, we require user interaction. It appears that, in
some applications, the required user interaction is reduced in comparison to
other user-assisted key-exchange protocols.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03472</identifier>
 <datestamp>2017-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Message or the Messenger? Inferring Virality and Diffusion Structure
  from Online Petition Signature Data</dc:title>
 <dc:creator>Chan, Chi Ling</dc:creator>
 <dc:creator>Lai, Justin</dc:creator>
 <dc:creator>Hooi, Bryan</dc:creator>
 <dc:creator>Davies, Todd</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>62P25</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>K.4.0</dc:subject>
 <dc:description>  Goel et al. (2016) examined diffusion data from Twitter to conclude that
online petitions are shared more virally than other types of content. Their
definition of structural virality, which measures the extent to which diffusion
follows a broadcast model or is spread person to person (virally), depends on
knowing the topology of the diffusion cascade. But often the diffusion
structure cannot be observed directly. We examined time-stamped signature data
from the Obama White House's We the People petition platform. We developed
measures based on temporal dynamics that, we argue, can be used to infer
diffusion structure as well as the more intrinsic notion of virality sometimes
known as infectiousness. These measures indicate that successful petitions are
likely to be higher in both intrinsic and structural virality than unsuccessful
petitions are. We also investigate threshold effects on petition signing that
challenge simple contagion models, and report simulations for a theoretical
model that are consistent with our data.
</dc:description>
 <dc:description>Comment: 19 pages, 6 figures, 4 tables, to appear in Giovanni Luca Ciampaglia,
  Afra J. Mashhadi, and Taha Yasseri (Editors), Social Informatics: Proceedings
  of the 9th International Conference, SocInfo 2017 (Oxford, UK, September
  13-15), Springer LNCS, 2017</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03472</dc:identifier>
 <dc:identifier>Lecture Notes in Computer Science 10539:499-517, 2017</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-67217-5_30</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03474</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generic Deep Architecture for Single Image Reflection Removal and
  Image Smoothing</dc:title>
 <dc:creator>Fan, Qingnan</dc:creator>
 <dc:creator>Yang, Jiaolong</dc:creator>
 <dc:creator>Hua, Gang</dc:creator>
 <dc:creator>Chen, Baoquan</dc:creator>
 <dc:creator>Wipf, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a deep neural network structure that exploits edge
information in addressing representative low-level vision tasks such as layer
separation and image filtering. Unlike most other deep learning strategies
applied in this context, our approach tackles these challenging problems by
estimating edges and reconstructing images using only cascaded convolutional
layers arranged such that no handcrafted or application-specific
image-processing components are required. We apply the resulting transferrable
pipeline to two different problem domains that are both sensitive to edges,
namely, single image reflection removal and image smoothing. For the former,
using a mild reflection smoothness assumption and a novel synthetic data
generation method that acts as a type of weak supervision, our network is able
to solve much more difficult reflection cases that cannot be handled by
previous methods. For the latter, we also exceed the state-of-the-art
quantitative and qualitative results by wide margins. In all cases, the
proposed framework is simple, fast, and easy to transfer across disparate
domains.
</dc:description>
 <dc:description>Comment: Accepted by ICCV'17 (International Conference on Computer Vision)</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03486</identifier>
 <datestamp>2017-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Solution of the P versus NP Problem</dc:title>
 <dc:creator>Blum, Norbert</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Berg and Ulfberg and Amano and Maruoka have used CNF-DNF-approximators to
prove exponential lower bounds for the monotone network complexity of the
clique function and of Andreev's function. We show that these approximators can
be used to prove the same lower bound for their non-monotone network
complexity. This implies P not equal NP.
</dc:description>
 <dc:description>Comment: The proof is wrong. I shall elaborate precisely what the mistake is.
  For doing this, I need some time. I shall put the explanation on my homepage
  http://theory.cs.uni-bonn.de/blum/blum.var</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03492</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Break it Down for Me: A Study in Automated Lyric Annotation</dc:title>
 <dc:creator>Sterckx, Lucas</dc:creator>
 <dc:creator>Naradowsky, Jason</dc:creator>
 <dc:creator>Byrne, Bill</dc:creator>
 <dc:creator>Demeester, Thomas</dc:creator>
 <dc:creator>Develder, Chris</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Comprehending lyrics, as found in songs and poems, can pose a challenge to
human and machine readers alike. This motivates the need for systems that can
understand the ambiguity and jargon found in such creative texts, and provide
commentary to aid readers in reaching the correct interpretation. We introduce
the task of automated lyric annotation (ALA). Like text simplification, a goal
of ALA is to rephrase the original text in a more easily understandable manner.
However, in ALA the system must often include additional information to clarify
niche terminology and abstract concepts. To stimulate research on this task, we
release a large collection of crowdsourced annotations for song lyrics. We
analyze the performance of translation and retrieval models on this task,
measuring performance with both automated and human evaluation. We find that
each model captures a unique type of information important to the task.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of EMNLP 2017</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03495</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms based on *-algebras, and their applications to isomorphism of
  polynomials with one secret, group isomorphism, and polynomial identity
  testing</dc:title>
 <dc:creator>Ivanyos, G&#xe1;bor</dc:creator>
 <dc:creator>Qiao, Youming</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:description>  We consider two basic algorithmic problems concerning tuples of
(skew-)symmetric matrices. The first problem asks to decide, given two tuples
of (skew-)symmetric matrices $(B_1, \dots, B_m)$ and $(C_1, \dots, C_m)$,
whether there exists an invertible matrix $A$ such that for every $i\in\{1,
\dots, m\}$, $A^tB_iA=C_i$. We show that this problem can be solved in
randomized polynomial time over finite fields of odd size, the real field, and
the complex field. The second problem asks to decide, given a tuple of square
matrices $(B_1, \dots, B_m)$, whether there exist invertible matrices $A$ and
$D$, such that for every $i\in\{1, \dots, m\}$, $AB_iD$ is (skew-)symmetric. We
show that this problem can be solved in deterministic polynomial time over
fields of characteristic not $2$. For both problems we exploit the structure of
the underlying $*$-algebras, and utilize results and methods from the module
isomorphism problem.
  Applications of our results range from multivariate cryptography, group
isomorphism, to polynomial identity testing. Specifically, these results imply
efficient algorithms for the following problems. (1) Test isomorphism of
quadratic forms with one secret over a finite field of odd size. This problem
belongs to a family of problems that serves as the security basis of certain
authentication schemes proposed by Patarin (Eurocrypto 1996). (2) Test
isomorphism of $p$-groups of class 2 and exponent $p$ ($p$ odd) with order
$p^k$ in time polynomial in the group order, when the commutator subgroup is of
order $p^{O(\sqrt{k})}$. (3) Deterministically reveal two families of
singularity witnesses caused by the skew-symmetric structure, which represents
a natural next step for the polynomial identity testing problem following the
direction set up by the recent resolution of the non-commutative rank problem
(Garg et al., FOCS 2016; Ivanyos et al., ITCS 2017).
</dc:description>
 <dc:description>Comment: 36 pages; slightly improved presentation; accepted to SODA 2018</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03496</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Ensemble Classification Algorithm Based on Information Entropy for
  Data Streams</dc:title>
 <dc:creator>Wang, Junhong</dc:creator>
 <dc:creator>Xu, Shuliang</dc:creator>
 <dc:creator>Duan, Bingqian</dc:creator>
 <dc:creator>Liu, Caifeng</dc:creator>
 <dc:creator>Liang, Jiye</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Data stream mining problem has caused widely concerns in the area of machine
learning and data mining. In some recent studies, ensemble classification has
been widely used in concept drift detection, however, most of them regard
classification accuracy as a criterion for judging whether concept drift
happening or not. Information entropy is an important and effective method for
measuring uncertainty. Based on the information entropy theory, a new algorithm
using information entropy to evaluate a classification result is developed. It
uses ensemble classification techniques, and the weight of each classifier is
decided through the entropy of the result produced by an ensemble classifiers
system. When the concept in data streams changing, the classifiers' weight
below a threshold value will be abandoned to adapt to a new concept in one
time. In the experimental analysis section, six databases and four proposed
algorithms are executed. The results show that the proposed method can not only
handle concept drift effectively, but also have a better classification
accuracy and time performance than the contrastive algorithms.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03498</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Expectation Maximization</dc:title>
 <dc:creator>Greff, Klaus</dc:creator>
 <dc:creator>van Steenkiste, Sjoerd</dc:creator>
 <dc:creator>Schmidhuber, J&#xfc;rgen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Many real world tasks such as reasoning and physical interaction require
identification and manipulation of conceptual entities. A first step towards
solving these tasks is the automated discovery of distributed symbol-like
representations. In this paper, we explicitly formalize this problem as
inference in a spatial mixture model where each component is parametrized by a
neural network. Based on the Expectation Maximization framework we then derive
a differentiable clustering method that simultaneously learns how to group and
represent individual entities. We evaluate our method on the (sequential)
perceptual grouping task and find that it is able to accurately recover the
constituent objects. We demonstrate that the learned representations are useful
for next-step prediction.
</dc:description>
 <dc:description>Comment: Accepted to NIPS 2017</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03511</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Technology networks: the autocatalytic origins of innovation</dc:title>
 <dc:creator>Zeppini, Paolo</dc:creator>
 <dc:creator>Evangelou, Evangelos</dc:creator>
 <dc:creator>Pugliese, Emanuele</dc:creator>
 <dc:creator>Napolitano, Lorenzo</dc:creator>
 <dc:creator>Room, Graham</dc:creator>
 <dc:subject>Quantitative Finance - Economics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We search an autocatalytic structure in networks of technological fields and
evaluate its significance for technological change. To this aim we define a
technology network based on the International Patents Classification, and we
study if autocatalytic structures in the network foster innovation as measured
by the rate of production of patents. The network is identified through
patenting activity of geographical regions in different technology fields.
Through our analysis we show how the technological landscape of the patents
database evolves as a self-organising autocatalytic structure that grows in
size, and arrives to cover the most part of the technology network. Technology
classes in the core of the autocatalytic structure perform better in terms of
their innovativeness, as measured by the rate of growth of the number of
patents. Finally, the links between classes that define the autocatalytic
structure of the technology network break the hierarchical structure of the
database, and indicate that recombinant innovation and its autocatalytic
patterns are an important stylised fact of technological change.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03513</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Early Stage Malware Prediction Using Recurrent Neural Networks</dc:title>
 <dc:creator>Rhode, Matilda</dc:creator>
 <dc:creator>Burnap, Pete</dc:creator>
 <dc:creator>Jones, Kevin</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Certain malware variants, such as ransomware, highlight the importance of
detecting malware prior to the execution of the malicious payload. Static code
analysis can be vulnerable to obfuscation techniques. Behavioural data
collected during file execution is more difficult to obfuscate, but typically
takes a long time to capture.
  In this paper we investigate the possibility of predicting whether or not an
executable is malicious. We use sequential dynamic data and find that an
ensemble of recurrent neural networks is able to predict whether an executable
is malicious or benign within the first 4 seconds of execution with 93%
accuracy. This is the first time a file has been predicted to be malicious
during its execution rather than using the complete log file post-execution.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03515</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Tools and Connections for Exponential-time Approximation</dc:title>
 <dc:creator>Bansal, Nikhil</dc:creator>
 <dc:creator>Chalermsook, Parinya</dc:creator>
 <dc:creator>Laekhanukit, Bundit</dc:creator>
 <dc:creator>Nanongkai, Danupon</dc:creator>
 <dc:creator>Nederlof, Jesper</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this paper, we develop new tools and connections for exponential time
approximation. In this setting, we are given a problem instance and a parameter
$\alpha&gt;1$, and the goal is to design an $\alpha$-approximation algorithm with
the fastest possible running time. We show the following results:
  - An $r$-approximation for maximum independent set in $O^*(\exp(\tilde O(n/r
\log^2 r+r\log^2r)))$ time,
  - An $r$-approximation for chromatic number in $O^*(\exp(\tilde{O}(n/r \log
r+r\log^2r)))$ time,
  - A $(2-1/r)$-approximation for minimum vertex cover in
$O^*(\exp(n/r^{\Omega(r)}))$ time, and
  - A $(k-1/r)$-approximation for minimum $k$-hypergraph vertex cover in
$O^*(\exp(n/(kr)^{\Omega(kr)}))$ time.
  (Throughout, $\tilde O$ and $O^*$ omit $\mathrm{polyloglog}(r)$ and factors
polynomial in the input size, respectively.) The best known time bounds for all
problems were $O^*(2^{n/r})$ [Bourgeois et al. 2009, 2011 &amp; Cygan et al. 2008].
For maximum independent set and chromatic number, these bounds were
complemented by $\exp(n^{1-o(1)}/r^{1+o(1)})$ lower bounds (under the
Exponential Time Hypothesis (ETH)) [Chalermsook et al., 2013 &amp; Laekhanukit,
2014 (Ph.D. Thesis)]. Our results show that the naturally-looking
$O^*(2^{n/r})$ bounds are not tight for all these problems. The key to these
algorithmic results is a sparsification procedure, allowing the use of better
approximation algorithms for bounded degree graphs. For obtaining the first two
results, we introduce a new randomized branching rule.
  Finally, we show a connection between PCP parameters and exponential-time
approximation algorithms. This connection together with our independent set
algorithm refute the possibility to overly reduce the size of Chan's PCP [Chan,
2016]. It also implies that a (significant) improvement over our result will
refute the gap-ETH conjecture [Dinur 2016 &amp; Manurangsi and Raghavendra, 2016].
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03518</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementation of the Logistic Map with FPGA using 32 bits fixed point
  standard</dc:title>
 <dc:creator>Silva, Diego A.</dc:creator>
 <dc:creator>Pereira, Eduardo B.</dc:creator>
 <dc:creator>Nepomuceno, Erivelton G.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  This article presents a design of the logistic map by means of FPGA (Field
Programmable Gate Ar-ray) under fixed-point standard and 32-bits of precision.
The design was carried out with Altera Quartus platform. The hardware
description language VHDL-93 has been adopted and the results were simulated by
means of Altera ModelSim package. The main of the project was to produce a
cha-otic system with a low energy and time cost. Using the VHDL, it was
possible to use only 1439 logical gates from 114480 available. The Lyapunov
exponent has been calculated with good agreement with literature reference,
which shows the effectiveness the proposed method.
</dc:description>
 <dc:description>Comment: XIII Simposio Brasileiro de Automacao Inteligente - SBAI2017 - Porto
  Alegre - Brazil. In Portuguese</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03518</dc:identifier>
 <dc:language>pt</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03519</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preconditioning immersed isogeometric finite element methods with
  application to flow problems</dc:title>
 <dc:creator>de Prenter, Frits</dc:creator>
 <dc:creator>Verhoosel, Clemens</dc:creator>
 <dc:creator>van Brummelen, Harald</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Immersed finite element methods generally suffer from conditioning problems
when cut elements intersect the physical domain only on a small fraction of
their volume. De Prenter et al. [Computer Methods in Applied Mechanics and
Engineering, 316 (2017) pp. 297-327] present an analysis for symmetric positive
definite (SPD) immersed problems, and for this class of problems an algebraic
preconditioner is developed. In this contribution the conditioning analysis is
extended to immersed finite element methods for systems that are not SPD and
the preconditioning technique is generalized to a connectivity-based
preconditioner inspired by Additive-Schwarz preconditioning. This
Connectivity-based Additive-Schwarz (CbAS) preconditioner is applicable to
problems that are not SPD and to mixed problems, such as the Stokes and
Navier-Stokes equations. A detailed numerical investigation of the effectivity
of the CbAS preconditioner to a range of flow problems is presented.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03520</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intra-Library Collusion: A Potential Privacy Nightmare on Smartphones</dc:title>
 <dc:creator>Taylor, Vincent F.</dc:creator>
 <dc:creator>Beresford, Alastair R.</dc:creator>
 <dc:creator>Martinovic, Ivan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Smartphones contain a trove of sensitive personal data including our
location, who we talk to, our habits, and our interests. Smartphone users trade
access to this data by permitting apps to use it, and in return obtain
functionality provided by the apps. In many cases, however, users fail to
appreciate the scale or sensitivity of the data that they share with
third-parties when they use apps. To this end, prior work has looked at the
threat to privacy posed by apps and the third-party libraries that they embed.
Prior work, however, fails to paint a realistic picture of the full threat to
smartphone users, as it has typically examined apps and third-party libraries
in isolation.
  In this paper, we describe a novel and potentially devastating privilege
escalation attack that can be performed by third-party libraries. This attack,
which we call intra-library collusion, occurs when a single library embedded in
more than one app on a device leverages the combined set of permissions
available to it to pilfer sensitive user data. The possibility for
intra-library collusion exists because libraries obtain the same privileges as
their host app and popular libraries will likely be used by more than one app
on a device.
  Using a real-world dataset of over 30,000 smartphones, we find that many
popular third-party libraries have the potential to aggregate significant
sensitive data from devices by using intra-library collusion. We demonstrate
that several popular libraries already collect enough data to facilitate this
attack. Using historical data, we show that risks from intra-library collusion
have increased significantly over the last two-and-a-half years. We conclude
with recommendations for mitigating the aforementioned problems.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03523</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower bound for monotone Boolean convolution</dc:title>
 <dc:creator>Paterson, Mike S.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>cs.CC, cs.DM</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Any monotone Boolean circuit computing the $n$-dimensional Boolean
convolution requires at least $n^2$ and-gates. This precisely matches the
obvious upper bound.
</dc:description>
 <dc:description>Comment: Lemma 5 fails and this seems vital to the current approach</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-10-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03529</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantify resilience enhancement of UTS through exploiting connect
  community and internet of everything emerging technologies</dc:title>
 <dc:creator>Bellini, Emanuele</dc:creator>
 <dc:creator>Ceravolo, Paolo</dc:creator>
 <dc:creator>Besi, Paolo</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This work aims at investigating and quantifying the Urban Transport System
(UTS) resilience enhancement enabled by the adoption of emerging technology
such as Internet of Everything (IoE) and the new trend of the Connected
Community (CC). A conceptual extension of Functional Resonance Analysis Method
(FRAM) and its formalization have been proposed and used to model UTS
complexity. The scope is to identify the system functions and their
interdependencies with a particular focus on those that have a relation and
impact on people and communities. Network analysis techniques have been applied
to the FRAM model to identify and estimate the most critical community-related
functions. The notion of Variability Rate (VR) has been defined as the amount
of output variability generated by an upstream function that can be
tolerated/absorbed by a downstream function, without significantly increasing
of its subsequent output variability. A fuzzy based quantification of the VR on
expert judgment has been developed when quantitative data are not available.
Our approach has been applied to a critical scenario (water bomb/flash
flooding) considering two cases: when UTS has CC and IoE implemented or not.
The results show a remarkable VR enhancement if CC and IoE are deployed
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03529</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03535</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Translation of Musical Style</dc:title>
 <dc:creator>Malik, Iman</dc:creator>
 <dc:creator>Ek, Carl Henrik</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Music is an expressive form of communication often used to convey emotion in
scenarios where &quot;words are not enough&quot;. Part of this information lies in the
musical composition where well-defined language exists. However, a significant
amount of information is added during a performance as the musician interprets
the composition. The performer injects expressiveness into the written score
through variations of different musical properties such as dynamics and tempo.
In this paper, we describe a model that can learn to perform sheet music. Our
research concludes that the generated performances are indistinguishable from a
human performance, thereby passing a test in the spirit of a &quot;musical Turing
test&quot;.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03535</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03536</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Confluence in Probabilistic Rewriting</dc:title>
 <dc:creator>D&#xed;az-Caro, Alejandro</dc:creator>
 <dc:creator>Mart&#xed;nez, Guido</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Driven by the interest of reasoning about probabilistic programming
languages, we set out to study a notion of unicity of normal forms for them. To
provide a tractable proof method for it, we define a property of distribution
confluence which is shown to imply the desired unicity (even for infinite
sequences of reduction) and further properties. We then carry over several
criteria from the classical case, such as Newman's lemma, to simplify proving
confluence in concrete languages. Using these criteria, we obtain simple proofs
of confluence for $\lambda_1$, an affine probabilistic lambda-calculus, and for
Q$^*$, a quantum programming language for which a related property has already
been proven in the literature.
</dc:description>
 <dc:description>Comment: To appear in LSFA 2017</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03541</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Identification of AltLexes using Monolingual Parallel Corpora</dc:title>
 <dc:creator>Davoodi, Elnaz</dc:creator>
 <dc:creator>Kosseim, Leila</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The automatic identification of discourse relations is still a challenging
task in natural language processing. Discourse connectives, such as &quot;since&quot; or
&quot;but&quot;, are the most informative cues to identify explicit relations; however
discourse parsers typically use a closed inventory of such connectives. As a
result, discourse relations signaled by markers outside these inventories (i.e.
AltLexes) are not detected as effectively. In this paper, we propose a novel
method to leverage parallel corpora in text simplification and lexical
resources to automatically identify alternative lexicalizations that signal
discourse relation. When applied to the Simple Wikipedia and Newsela corpora
along with WordNet and the PPDB, the method allowed the automatic discovery of
91 AltLexes.
</dc:description>
 <dc:description>Comment: 6 pages, Proceedings of Recent Advances in Natural Language
  Processing (RANLP 2017)</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03549</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic controllers for column synchronization of rotation matrices: a
  QR-factorization approach</dc:title>
 <dc:creator>Thunberg, Johan</dc:creator>
 <dc:creator>Markdahl, Johan</dc:creator>
 <dc:creator>Goncalves, Jorge</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In the multi-agent systems setting, this paper addresses continuous-time
distributed synchronization of columns of rotation matrices. More precisely, k
specific columns shall be synchronized and only the corresponding k columns of
the relative rotations between the agents are assumed to be available for the
control design. When one specific column is considered, the problem is
equivalent to synchronization on the (d-1)-dimensional unit sphere and when all
the columns are considered, the problem is equivalent to synchronization on
SO(d). We design dynamic control laws for these synchronization problems. The
control laws are based on the introduction of auxiliary variables in
combination with a QR-factorization approach. The benefit of this
QR-factorization approach is that we can decouple the dynamics for the k
columns from the remaining d-k ones. Under the control scheme, the closed loop
system achieves almost global convergence to synchronization for quasi-strong
interaction graph topologies.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03558</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison of LZ77-type Parsings</dc:title>
 <dc:creator>Kosolobov, Dmitry</dc:creator>
 <dc:creator>Shur, Arseny M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We investigate the relations between different variants of the LZ77 parsing
existing in the literature. All of them are defined as greedily constructed
parsings encoding each phrase by reference to a string occurring earlier in the
input. They differ by the phrase encodings: encoded by pairs (length + position
of an earlier occurrence) or by triples (length + position of an earlier
occurrence + the letter following the earlier occurring part); and they differ
by allowing or not allowing overlaps between the phrase and its earlier
occurrence. For a given string of length $n$ over an alphabet of size $\sigma$,
denote the numbers of phrases in the parsings allowing (resp., not allowing)
overlaps by $z$ (resp., $\hat{z}$), for &quot;pairs&quot;, and by $z_3$ (resp.,
$\hat{z}_3$), for &quot;triples&quot;. We prove the following bounds and provide series
of examples showing that these bounds are tight:
  $\bullet$ $z \le \hat{z} \le z \cdot O(\log\frac{n}{z\log_\sigma z})$ and
$z_3 \le \hat{z}_3 \le z_3 \cdot O(\log\frac{n}{z_3\log_\sigma z_3})$;
  $\bullet$ $\frac{1}2\hat{z} &lt; \hat{z}_3 \le \hat{z}$ and $\frac{1}2 z &lt; z_3
\le z$.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03569</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Word Clouds with Background Corpus Normalization and
  t-distributed Stochastic Neighbor Embedding</dc:title>
 <dc:creator>Schubert, Erich</dc:creator>
 <dc:creator>Spitz, Andreas</dc:creator>
 <dc:creator>Weiler, Michael</dc:creator>
 <dc:creator>Gei&#xdf;, Johanna</dc:creator>
 <dc:creator>Gertz, Michael</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Many word clouds provide no semantics to the word placement, but use a random
layout optimized solely for aesthetic purposes. We propose a novel approach to
model word significance and word affinity within a document, and in comparison
to a large background corpus. We demonstrate its usefulness for generating more
meaningful word clouds as a visual summary of a given document. We then select
keywords based on their significance and construct the word cloud based on the
derived affinity. Based on a modified t-distributed stochastic neighbor
embedding (t-SNE), we generate a semantic word placement. For words that
cooccur significantly, we include edges, and cluster the words according to
their cooccurrence. For this we designed a scalable and memory-efficient
sketch-based approach usable on commodity hardware to aggregate the required
corpus statistics needed for normalization, and for identifying keywords as
well as significant cooccurences. We empirically validate our approch using a
large Wikipedia corpus.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03583</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Normalized Information Distance and the Oscillation Hierarchy</dc:title>
 <dc:creator>Ambos-Spies, Klaus</dc:creator>
 <dc:creator>Merkle, Wolfgang</dc:creator>
 <dc:creator>Terwijn, Sebastiaan A.</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the complexity of approximations to the normalized information
distance. We introduce a hierarchy of computable approximations by considering
the number of oscillations. This is a function version of the difference
hierarchy for sets. We show that the normalized information distance is not in
any level of this hierarchy, strengthening previous nonapproximability results.
As an ingredient to the proof, we also prove a conditional undecidability
result about independence.
</dc:description>
 <dc:description>Comment: fixed typos version 11-08-2017, added comments</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03591</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formation Control and Network Localization via Distributed Global
  Orientation Estimation in $3$-D</dc:title>
 <dc:creator>Lee, Byung-Hun</dc:creator>
 <dc:creator>Ahn, Hyo-Sung</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  In this paper, we propose a novel distributed formation control strategy,
which is based on the measurements of relative position of neighbors, with
global orientation estimation in 3-dimensional space. Since agents do not share
a common reference frame, orientations of the local reference frame are not
aligned with each other. Under the orientation estimation law, a rotation
matrix that identifies orientation of local frame with respect to a common
frame is obtained by auxiliary variables. The proposed strategy includes a
combination of global orientation estimation and formation control law. Since
orientation of each agent is estimated in the global sense, formation control
strategy ensures that the formation globally exponentially converges to the
desired formation in 3-dimensional space.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03603</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Star Height via Games</dc:title>
 <dc:creator>Bojanczyk, Mikolaj</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  This paper proposes a new algorithm deciding the star height problem. As
shown by Kirsten, the star height problem reduces to a problem concerning
automata with counters, called limitedness. The new contribution is a different
algorithm for the limitedness problem, which reduces it to solving a
Gale-Stewart game with an {\omega}-regular winning condition.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03604</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Porting of the DBCSR library for Sparse Matrix-Matrix Multiplications to
  Intel Xeon Phi systems</dc:title>
 <dc:creator>Bethune, Iain</dc:creator>
 <dc:creator>Gloess, Andeas</dc:creator>
 <dc:creator>Hutter, Juerg</dc:creator>
 <dc:creator>Lazzaro, Alfio</dc:creator>
 <dc:creator>Pabst, Hans</dc:creator>
 <dc:creator>Reid, Fiona</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Multiplication of two sparse matrices is a key operation in the simulation of
the electronic structure of systems containing thousands of atoms and
electrons. The highly optimized sparse linear algebra library DBCSR
(Distributed Block Compressed Sparse Row) has been specifically designed to
efficiently perform such sparse matrix-matrix multiplications. This library is
the basic building block for linear scaling electronic structure theory and low
scaling correlated methods in CP2K. It is parallelized using MPI and OpenMP,
and can exploit GPU accelerators by means of CUDA. We describe a performance
comparison of DBCSR on systems with Intel Xeon Phi Knights Landing (KNL)
processors, with respect to systems with Intel Xeon CPUs (including systems
with GPUs). We find that the DBCSR on Cray XC40 KNL-based systems is 11%-14%
slower than on a hybrid Cray XC50 with Nvidia P100 cards, at the same number of
nodes. When compared to a Cray XC40 system equipped with dual-socket Intel Xeon
CPUs, the KNL is up to 24% faster.
</dc:description>
 <dc:description>Comment: Submitted to the ParCo2017 conference, Bologna, Italy 12-15 September
  2017</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03608</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fast Noniterative Algorithm for Compressive Sensing Using Binary
  Measurement Matrices</dc:title>
 <dc:creator>Lotfi, Mahsa</dc:creator>
 <dc:creator>Vidyasagar, Mathukumalli</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper we present a new algorithm for compressive sensing that makes
use of binary measurement matrices and achieves exact recovery of sparse
vectors, in a single pass, without any iterations. Our algorithm is hundreds of
times faster than $\ell_1$-norm minimization, and methods based on expander
graphs (which require multiple iterations). Moreover, our method requires the
fewest measurements amongst all methods that use binary measurement matrices.
The algorithm can accommodate nearly sparse vectors, in which case it recovers
the largest components, and can also
  Numerical experiments with randomly generated sparse vectors indicate that
the sufficient conditions for our algorithm to work are very close to being
necessary. In contrast, the best known sufficient condition for $\ell_1$-norm
minimization to recover a sparse vector, namely the Restricted Isometry
Property (RIP), is about thirty times away from being necessary. Therefore it
would be worthwhile to explore alternate and improved sufficient conditions for
$\ell_1$-norm minimization to achieve the recovery of sparse vectors.
</dc:description>
 <dc:description>Comment: 21 pages, 7 tables</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03615</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Incremental Learning of Deep Descriptors From Video Streams</dc:title>
 <dc:creator>Pernici, Federico</dc:creator>
 <dc:creator>Del Bimbo, Alberto</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a novel unsupervised method for face identity learning from video
sequences. The method exploits the ResNet deep network for face detection and
VGGface fc7 face descriptors together with a smart learning mechanism that
exploits the temporal coherence of visual data in video streams. We present a
novel feature matching solution based on Reverse Nearest Neighbour and a
feature forgetting strategy that supports incremental learning with memory size
control, while time progresses. It is shown that the proposed learning
procedure is asymptotically stable and can be effectively applied to relevant
applications like multiple face tracking.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03615</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03619</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Bilinear: Generalized Multi-modal Factorized High-order Pooling
  for Visual Question Answering</dc:title>
 <dc:creator>Yu, Zhou</dc:creator>
 <dc:creator>Yu, Jun</dc:creator>
 <dc:creator>Xiang, Chenchao</dc:creator>
 <dc:creator>Fan, Jianping</dc:creator>
 <dc:creator>Tao, Dacheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual question answering (VQA) is challenging because it requires a
simultaneous understanding of both visual content of images and textual content
of questions. To support the VQA task, we need to find good solutions for the
following three issues: 1) fine-grained feature representations for both the
image and the question; 2) multi-modal feature fusion that is able to capture
the complex interactions between multi-modal features; 3) automatic answer
prediction that is able to consider the complex correlations between multiple
diverse answers for the same question. For fine-grained image and question
representations, a `co-attention' mechanism is developed by using a deep neural
network architecture to jointly learn the attentions for both the image and the
question, which can allow us to reduce the irrelevant features effectively and
obtain more discriminative features for image and question representations. For
multi-modal feature fusion, a generalized Multi-modal Factorized High-order
pooling approach (MFH) is developed to achieve more effective fusion of
multi-modal features by exploiting their correlations sufficiently, which can
further result in superior VQA performance as compared with the
state-of-the-art approaches. For answer prediction, the KL (Kullback-Leibler)
divergence is used as the loss function to achieve more accurate
characterization of the complex correlations between multiple diverse answers
with same or similar meaning, which can allow us to achieve faster convergence
rate and obtain slightly better accuracy on answer prediction. A deep neural
network architecture is designed to integrate all these aforementioned modules
into one unified model for achieving superior VQA performance. With an ensemble
of 9 models, we achieve the state-of-the-art performance on the large-scale VQA
datasets and win the runner-up in the VQA Challenge 2017.
</dc:description>
 <dc:description>Comment: Under review. arXiv admin note: substantial text overlap with
  arXiv:1708.01471</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03629</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple and Effective Dimensionality Reduction for Word Embeddings</dc:title>
 <dc:creator>Raunak, Vikas</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Word embeddings have become the basic building blocks for several natural
language processing and information retrieval tasks. Pre-trained word
embeddings are used in several downstream applications as well as for
constructing representations for sentences, paragraphs and documents. Recently,
there has been an emphasis on further improving the pre-trained word vectors
through post-processing algorithms. One such area of improvement is the
dimensionality reduction of the word embeddings. Reducing the size of word
embeddings through dimensionality reduction can improve their utility in memory
constrained devices, benefiting several real-world applications. In this work,
we present a novel algorithm that effectively combines PCA based dimensionality
reduction with a recently proposed post-processing algorithm, to construct word
embeddings of lower dimensions. Empirical evaluations on 12 standard word
similarity benchmarks show that our algorithm reduces the embedding
dimensionality by 50%, while achieving similar or (more often) better
performance than the higher dimension embeddings.
</dc:description>
 <dc:description>Comment: Accepted at NIPS 2017 LLD Workshop</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03655</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communicating Robot Arm Motion Intent Through Mixed Reality Head-mounted
  Displays</dc:title>
 <dc:creator>Rosen, Eric</dc:creator>
 <dc:creator>Whitney, David</dc:creator>
 <dc:creator>Phillips, Elizabeth</dc:creator>
 <dc:creator>Chien, Gary</dc:creator>
 <dc:creator>Tompkin, James</dc:creator>
 <dc:creator>Konidaris, George</dc:creator>
 <dc:creator>Tellex, Stefanie</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Efficient motion intent communication is necessary for safe and collaborative
work environments with collocated humans and robots. Humans efficiently
communicate their motion intent to other humans through gestures, gaze, and
social cues. However, robots often have difficulty efficiently communicating
their motion intent to humans via these methods. Many existing methods for
robot motion intent communication rely on 2D displays, which require the human
to continually pause their work and check a visualization. We propose a mixed
reality head-mounted display visualization of the proposed robot motion over
the wearer's real-world view of the robot and its environment. To evaluate the
effectiveness of this system against a 2D display visualization and against no
visualization, we asked 32 participants to labeled different robot arm motions
as either colliding or non-colliding with blocks on a table. We found a 16%
increase in accuracy with a 62% decrease in the time it took to complete the
task compared to the next best system. This demonstrates that a mixed-reality
HMD allows a human to more quickly and accurately tell where the robot is going
to move than the compared baselines.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03658</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>iTrace: An Implicit Trust Inference Method for Trust-aware Collaborative
  Filtering</dc:title>
 <dc:creator>He, Xu</dc:creator>
 <dc:creator>Liu, Bin</dc:creator>
 <dc:creator>Chen, Ke-Jia</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The growth of Internet commerce has stimulated the use of collaborative
filtering (CF) algorithms as recommender systems. A collaborative filtering
(CF) algorithm recommends items of interest to the target user by leveraging
the votes given by other similar users. In a standard CF framework, it is
assumed that the credibility of every voting user is exactly the same with
respect to the target user. This assumption is not satisfied and thus may lead
to misleading recommendations in many practical applications. A natural
countermeasure is to design a trust-aware CF (TaCF) algorithm, which can take
account of the difference in the credibilities of the voting users when
performing CF. To this end, this paper presents a trust inference approach,
which can predict the implicit trust of the target user on every voting user
from a sparse explicit trust matrix. Then an improved CF algorithm termed
iTrace is proposed, which takes advantage of both the explicit and the
predicted implicit trust to provide recommendations with the CF framework. An
empirical evaluation on a public dataset demonstrates that the proposed
algorithm provides a significant improvement in recommendation quality in terms
of mean absolute error (MAE).
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, 1 table</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03665</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time Series Anomaly Detection; Detection of anomalous drops with limited
  features and sparse examples in noisy highly periodic data</dc:title>
 <dc:creator>Shipmon, Dominique T.</dc:creator>
 <dc:creator>Gurevitch, Jason M.</dc:creator>
 <dc:creator>Piselli, Paolo M.</dc:creator>
 <dc:creator>Edwards, Stephen T.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Google uses continuous streams of data from industry partners in order to
deliver accurate results to users. Unexpected drops in traffic can be an
indication of an underlying issue and may be an early warning that remedial
action may be necessary. Detecting such drops is non-trivial because streams
are variable and noisy, with roughly regular spikes (in many different shapes)
in traffic data. We investigated the question of whether or not we can predict
anomalies in these data streams. Our goal is to utilize Machine Learning and
statistical approaches to classify anomalous drops in periodic, but noisy,
traffic patterns. Since we do not have a large body of labeled examples to
directly apply supervised learning for anomaly classification, we approached
the problem in two parts. First we used TensorFlow to train our various models
including DNNs, RNNs, and LSTMs to perform regression and predict the expected
value in the time series. Secondly we created anomaly detection rules that
compared the actual values to predicted values. Since the problem requires
finding sustained anomalies, rather than just short delays or momentary
inactivity in the data, our two detection methods focused on continuous
sections of activity rather than just single points. We tried multiple
combinations of our models and rules and found that using the intersection of
our two anomaly detection methods proved to be an effective method of detecting
anomalies on almost all of our models. In the process we also found that not
all data fell within our experimental assumptions, as one data stream had no
periodicity, and therefore no time based model could predict it.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03669</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Neural Networks for Font Classification</dc:title>
 <dc:creator>Tensmeyer, Chris</dc:creator>
 <dc:creator>Saunders, Daniel</dc:creator>
 <dc:creator>Martinez, Tony</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Classifying pages or text lines into font categories aids transcription
because single font Optical Character Recognition (OCR) is generally more
accurate than omni-font OCR. We present a simple framework based on
Convolutional Neural Networks (CNNs), where a CNN is trained to classify small
patches of text into predefined font classes. To classify page or line images,
we average the CNN predictions over densely extracted patches. We show that
this method achieves state-of-the-art performance on a challenging dataset of
40 Arabic computer fonts with 98.8\% line level accuracy. This same method also
achieves the highest reported accuracy of 86.6% in predicting paleographic
scribal script classes at the page level on medieval Latin manuscripts.
Finally, we analyze what features are learned by the CNN on Latin manuscripts
and find evidence that the CNN is learning both the defining morphological
differences between scribal script classes as well as overfitting to
class-correlated nuisance factors. We propose a novel form of data augmentation
that improves robustness to text darkness, further increasing classification
performance.
</dc:description>
 <dc:description>Comment: ICDAR 2017</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03684</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Introduction to Quantum Computing, Without the Physics</dc:title>
 <dc:creator>Nannicini, Giacomo</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>68Q12</dc:subject>
 <dc:description>  This paper is a gentle but rigorous introduction to quantum computing
intended for computer scientists. Starting from a small set of assumptions on
the behavior of quantum computing devices, we analyze their main
characteristics, stressing the differences with classical computers, and
finally describe two well-known algorithms (Simon's algorithm and Grover's
algorithm) using the formalism developed in previous sections. This paper does
not touch on the physics of the devices, and therefore does not require any
notion of quantum mechanics.
</dc:description>
 <dc:description>Comment: v2 introduces clearer, more concise notation, and additional
  discussion</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03686</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualizing Time-Varying Particle Flows with Diffusion Geometry</dc:title>
 <dc:creator>Berger, Matthew</dc:creator>
 <dc:creator>Levine, Joshua A.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  The tasks of identifying separation structures and clusters in flow data are
fundamental to flow visualization. Significant work has been devoted to these
tasks in flow represented by vector fields, but there are unique challenges in
addressing these tasks for time-varying particle data. The unstructured nature
of particle data, nonuniform and sparse sampling, and the inability to access
arbitrary particles in space-time make it difficult to define separation and
clustering for particle data. We observe that weaker notions of separation and
clustering through continuous measures of these structures are meaningful when
coupled with user exploration. We achieve this goal by defining a measure of
particle similarity between pairs of particles. More specifically, separation
occurs when spatially-localized particles are dissimilar, while clustering is
characterized by sets of particles that are similar to one another. To be
robust to imperfections in sampling we use diffusion geometry to compute
particle similarity. Diffusion geometry is parameterized by a scale that allows
a user to explore separation and clustering in a continuous manner. We
illustrate the benefits of our technique on a variety of 2D and 3D flow
datasets, from particles integrated in fluid simulations based on time-varying
vector fields, to particle-based simulations in astrophysics.
</dc:description>
 <dc:description>Comment: 14 pages, 16 figures, under review</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03694</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Recurrent Neural Networks for mapping winter vegetation quality
  coverage via multi-temporal SAR Sentinel-1</dc:title>
 <dc:creator>Minh, Dinh Ho Tong</dc:creator>
 <dc:creator>Ienco, Dino</dc:creator>
 <dc:creator>Gaetano, Raffaele</dc:creator>
 <dc:creator>Lalande, Nathalie</dc:creator>
 <dc:creator>Ndikumana, Emile</dc:creator>
 <dc:creator>Osman, Faycal</dc:creator>
 <dc:creator>Maurel, Pierre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Mapping winter vegetation quality coverage is a challenge problem of remote
sensing. This is due to the cloud coverage in winter period, leading to use
radar rather than optical images. The objective of this paper is to provide a
better understanding of the capabilities of radar Sentinel-1 and deep learning
concerning about mapping winter vegetation quality coverage. The analysis
presented in this paper is carried out on multi-temporal Sentinel-1 data over
the site of La Rochelle, France, during the campaign in December 2016. This
dataset were processed in order to produce an intensity radar data stack from
October 2016 to February 2017. Two deep Recurrent Neural Network (RNN) based
classifier methods were employed. We found that the results of RNNs clearly
outperformed the classical machine learning approaches (Support Vector Machine
and Random Forest). This study confirms that the time series radar Sentinel-1
and RNNs could be exploited for winter vegetation quality cover mapping.
</dc:description>
 <dc:description>Comment: In submission to IEEE Geoscience and Remote Sensing Letters</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03696</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emotion Intensities in Tweets</dc:title>
 <dc:creator>Mohammad, Saif M.</dc:creator>
 <dc:creator>Bravo-Marquez, Felipe</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper examines the task of detecting intensity of emotion from text. We
create the first datasets of tweets annotated for anger, fear, joy, and sadness
intensities. We use a technique called best--worst scaling (BWS) that improves
annotation consistency and obtains reliable fine-grained scores. We show that
emotion-word hashtags often impact emotion intensity, usually conveying a more
intense emotion. Finally, we create a benchmark regression system and conduct
experiments to determine: which features are useful for detecting emotion
intensity, and, the extent to which two emotions are similar in terms of how
they manifest in language.
</dc:description>
 <dc:description>Comment: http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html
  http://saifmohammad.com/WebPages/ResearchAreas.html, In Proceedings of the
  Sixth Joint Conference on Lexical and Computational Semantics (*Sem), August
  2017, Vancouver, Canada</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03698</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Rotation for Kernel Correlation Filter</dc:title>
 <dc:creator>Hamdi, Abdullah</dc:creator>
 <dc:creator>Ghanem, Bernard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:description>  Kernel Correlation Filters have shown a very promising scheme for visual
tracking in terms of speed and accuracy on several benchmarks. However it
suffers from problems that affect its performance like occlusion, rotation and
scale change. This paper tries to tackle the problem of rotation by
reformulating the optimization problem for learning the correlation filter.
This modification (RKCF) includes learning rotation filter that utilizes
circulant structure of HOG feature to guesstimate rotation from one frame to
another and enhance the detection of KCF. Hence it gains boost in overall
accuracy in many of OBT50 detest videos with minimal additional computation.
</dc:description>
 <dc:description>Comment: 6 pages, 11 figures, tracking, CVPR, Correlation Filters,KCF, visual
  object tracking</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03699</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Abusive Comment Moderation with User Embeddings</dc:title>
 <dc:creator>Pavlopoulos, John</dc:creator>
 <dc:creator>Malakasiotis, Prodromos</dc:creator>
 <dc:creator>Bakagianni, Juli</dc:creator>
 <dc:creator>Androutsopoulos, Ion</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Experimenting with a dataset of approximately 1.6M user comments from a Greek
news sports portal, we explore how a state of the art RNN-based moderation
method can be improved by adding user embeddings, user type embeddings, user
biases, or user type biases. We observe improvements in all cases, with user
embeddings leading to the biggest performance gains.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03699</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03700</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WASSA-2017 Shared Task on Emotion Intensity</dc:title>
 <dc:creator>Mohammad, Saif M.</dc:creator>
 <dc:creator>Bravo-Marquez, Felipe</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present the first shared task on detecting the intensity of emotion felt
by the speaker of a tweet. We create the first datasets of tweets annotated for
anger, fear, joy, and sadness intensities using a technique called best--worst
scaling (BWS). We show that the annotations lead to reliable fine-grained
intensity scores (rankings of tweets by intensity). The data was partitioned
into training, development, and test sets for the competition. Twenty-two teams
participated in the shared task, with the best system obtaining a Pearson
correlation of 0.747 with the gold intensity scores. We summarize the machine
learning setups, resources, and tools used by the participating teams, with a
focus on the techniques and resources that are particularly useful for the
task. The emotion intensity dataset and the shared task are helping improve our
understanding of how we convey more or less intense emotions through language.
</dc:description>
 <dc:description>Comment: http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html, In
  Proceedings of the EMNLP 2017 Workshop on Computational Approaches to
  Subjectivity, Sentiment, and Social Media (WASSA), September 2017,
  Copenhagen, Denmark</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03703</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The generalized vertex cover problem and some variations</dc:title>
 <dc:creator>Pandey, Pooja</dc:creator>
 <dc:creator>Punnen, Abraham P.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this paper we study the generalized vertex cover problem (GVC), which is a
generalization of various well studied combinatorial optimization problems. GVC
is shown to be equivalent to the unconstrained binary quadratic programming
problem and also equivalent to some other variations of the general GVC. Some
solvable cases are identified and approximation algorithms are suggested for
special cases. We also study GVC on bipartite graphs and identify some
polynomially solvable cases. We show that GVC on bipartite graphs is equivalent
to the bipartite unconstrained 0-1 quadratic programming problem. Integer
programming formulations of GVC and related problems are presented and
establish half-integrality property on some variables for the corresponding
linear programming relaxations. We also discuss special cases of GVC where all
feasible solutions are independent sets or vertex covers. These problems are
observed to be equivalent to the maximum weight independent set problem or
minimum weight vertex cover problem along with some algorithmic results.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03704</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Incremental Boosting</dc:title>
 <dc:creator>Mosca, Alan</dc:creator>
 <dc:creator>Magoulas, George D</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper introduces Deep Incremental Boosting, a new technique derived from
AdaBoost, specifically adapted to work with Deep Learning methods, that reduces
the required training time and improves generalisation. We draw inspiration
from Transfer of Learning approaches to reduce the start-up time to training
each incremental Ensemble member. We show a set of experiments that outlines
some preliminary results on some common Deep Learning datasets and discuss the
potential improvements Deep Incremental Boosting brings to traditional Ensemble
methods in Deep Learning.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03704</dc:identifier>
 <dc:identifier>Christoph Benzm\&quot;uller, Geoff Sutcliffe and Raul Rojas (editors).
  GCAI 2016. 2nd Global Conference on Artificial Intelligence, vol 41, pages
  293--302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03708</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eigenvalue Decay Implies Polynomial-Time Learnability for Neural
  Networks</dc:title>
 <dc:creator>Goel, Surbhi</dc:creator>
 <dc:creator>Klivans, Adam</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the problem of learning function classes computed by neural
networks with various activations (e.g. ReLU or Sigmoid), a task believed to be
computationally intractable in the worst-case. A major open problem is to
understand the minimal assumptions under which these classes admit provably
efficient algorithms. In this work we show that a natural distributional
assumption corresponding to {\em eigenvalue decay} of the Gram matrix yields
polynomial-time algorithms in the non-realizable setting for expressive classes
of networks (e.g. feed-forward networks of ReLUs). We make no assumptions on
the structure of the network or the labels. Given sufficiently-strong
polynomial eigenvalue decay, we obtain {\em fully}-polynomial time algorithms
in {\em all} the relevant parameters with respect to square-loss. Milder decay
assumptions also lead to improved algorithms. This is the first purely
distributional assumption that leads to polynomial-time algorithms for networks
of ReLUs, even with one hidden layer. Further, unlike prior distributional
assumptions (e.g., the marginal distribution is Gaussian), eigenvalue decay has
been observed in practice on common data sets.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03725</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Semantic Contextualization for Interpretation of Human
  Activity in Videos</dc:title>
 <dc:creator>Aakur, Sathyanarayanan N.</dc:creator>
 <dc:creator>de Souza, Fillipe DM</dc:creator>
 <dc:creator>Sarkar, Sudeep</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We use large-scale commonsense knowledge bases, e.g. ConceptNet, to provide
context cues to establish semantic relationships among entities directly
hypothesized from video signal, such as putative object and actions labels, and
infer a deeper interpretation of events than what is directly sensed. One
approach is to learn semantic relationships between objects and actions from
training annotations of videos and as such, depend largely on statistics of the
vocabulary in these annotations. However, the use of prior encoded commonsense
knowledge sources alleviates this dependence on large annotated training
datasets. We represent interpretations using a connected structure of basic
detected (grounded) concepts, such as objects and actions, that are bound by
semantics with other background concepts not directly observed, i.e.
contextualization cues. We mathematically express this using the language of
Grenander's pattern generator theory. Concepts are basic generators and the
bonds are defined by the semantic relationships between concepts. We formulate
an inference engine based on energy minimization using an efficient Markov
Chain Monte Carlo that uses the ConceptNet in its move proposals to find these
structures. Using three different publicly available datasets, Breakfast, CMU
Kitchen and MSVD, whose distribution of possible interpretations span more than
150000 possible solutions for over 5000 videos, we show that the proposed model
can generate video interpretations whose quality are comparable or better than
those reported by approaches such as discriminative approaches, hidden Markov
models, context free grammars, deep learning models, and prior pattern theory
approaches, all of whom rely on learning from domain-specific training data.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03731</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OpenML Benchmarking Suites and the OpenML100</dc:title>
 <dc:creator>Bischl, Bernd</dc:creator>
 <dc:creator>Casalicchio, Giuseppe</dc:creator>
 <dc:creator>Feurer, Matthias</dc:creator>
 <dc:creator>Hutter, Frank</dc:creator>
 <dc:creator>Lang, Michel</dc:creator>
 <dc:creator>Mantovani, Rafael G.</dc:creator>
 <dc:creator>van Rijn, Jan N.</dc:creator>
 <dc:creator>Vanschoren, Joaquin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We advocate the use of curated, comprehensive benchmark suites of machine
learning datasets, backed by standardized OpenML-based interfaces and
complementary software toolkits written in Python, Java and R. Major
distinguishing features of OpenML benchmark suites are (a) ease of use through
standardized data formats, APIs, and existing client libraries; (b)
machine-readable meta-information regarding the contents of the suite; and (c)
online sharing of results, enabling large scale comparisons. As a first such
suite, we propose the OpenML100, a machine learning benchmark suite of
100~classification datasets carefully curated from the thousands of datasets
available on OpenML.org.
</dc:description>
 <dc:description>Comment: Submitted to MLOSS</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03734</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Graph Pattern Matching</dc:title>
 <dc:creator>Almagro-Blanco, Pedro</dc:creator>
 <dc:creator>Sancho-Caparrini, Fernando</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>68T35</dc:subject>
 <dc:subject>H.2.3</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Most of the machine learning algorithms are limited to learn from flat data:
a recordset with prefixed structure. When learning from a record, these types
of algorithms don't take into account other objects even though they are
directly connected to it and can provide valuable information for the learning
task. In this paper we present the concept of Generalized Graph Query, a query
tool over graphs or multi-relational data structures. They are built using the
same graph structure as generalized graphs and allow to express powerful
relational and non-relational restrictions on this type of data. Also, this
paper shows mechanisms to build this kind of queries dynamically and how they
can be used to perform bottom-up discovery processes through machine laerning
techniques.
  -----
  La mayor\'ia de los algoritmos que aprenden a partir de datos est\'an
limitados ya que s\'olo son capaces de aprender a partir de datos estructurados
en forma de tabla en la que cada fila representa un registro y cada columna una
propiedad asociada. Estos algoritmos, no tienen en cuenta los atributos de las
estructuras con las que un registro dado puede estar relacionado, a pesar de
que \'estos pueden aportar informaci\'on \'util a la hora de llevar a cabo la
tarea de aprendizaje. En este art\'iculo presentamos el concepto de Generalized
Graph Query, una herramienta de consulta de patrones en grafos generalizados.
Dicha herramienta ha sido construida utilizando la estructura de Grafo
Generalizado y permite expresar restricciones relacionales y no relacionales
sobre este tipo de estructuras. Adem\'as, en este art\'iculo se presentan
mecanismos para la construcci\'on autom\'atica de este tipo de consultas y se
muestra c\'omo \'estas pueden ser utilizadas en procesos de descubrimiento tipo
bottom-up a trav\'es de t\'ecnicas relacionadas con el Aprendizaje
Autom\'atico.
</dc:description>
 <dc:description>Comment: Multi-lingual Paper Main language: English Additional Language:
  Spanish 23 Figures Engish: 26 pages Spanish: 30 pages</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03735</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Coding and Autoencoders</dc:title>
 <dc:creator>Rangamani, Akshay</dc:creator>
 <dc:creator>Mukherjee, Anirbit</dc:creator>
 <dc:creator>Basu, Amitabh</dc:creator>
 <dc:creator>Ganapathy, Tejaswini</dc:creator>
 <dc:creator>Arora, Ashish</dc:creator>
 <dc:creator>Chin, Sang</dc:creator>
 <dc:creator>Tran, Trac D.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In &quot;Dictionary Learning&quot; one tries to recover incoherent matrices $A^* \in
\mathbb{R}^{n \times h}$ (typically overcomplete and whose columns are assumed
to be normalized) and sparse vectors $x^* \in \mathbb{R}^h$ with a small
support of size $h^p$ for some $0 &lt;p &lt; 1$ while having access to observations
$y \in \mathbb{R}^n$ where $y = A^*x^*$. In this work we undertake a rigorous
analysis of whether gradient descent on the squared loss of an autoencoder can
solve the dictionary learning problem. The &quot;Autoencoder&quot; architecture we
consider is a $\mathbb{R}^n \rightarrow \mathbb{R}^n$ mapping with a single
ReLU activation layer of size $h$.
  Under very mild distributional assumptions on $x^*$, we prove that the norm
of the expected gradient of the standard squared loss function is
asymptotically (in sparse code dimension) negligible for all points in a small
neighborhood of $A^*$. This is supported with experimental evidence using
synthetic data. We also conduct experiments to suggest that $A^*$ is a local
minimum. Along the way we prove that a layer of ReLU gates can be set up to
automatically recover the support of the sparse codes. This property holds
independent of the loss function. We believe that it could be of independent
interest.
</dc:description>
 <dc:description>Comment: In this new version of the paper with a small change in the
  distributional assumptions we are actually able to prove the asymptotic
  criticality of a neighbourhood of the ground truth dictionary for even just
  the standard squared loss of the ReLU autoencoder (unlike the regularized
  loss in the older version)</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-10-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03736</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Face Parsing via a Fully-Convolutional Continuous CRF Neural Network</dc:title>
 <dc:creator>Zhou, Lei</dc:creator>
 <dc:creator>Liu, Zhi</dc:creator>
 <dc:creator>He, Xiangjian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we address the face parsing task with a Fully-Convolutional
continuous CRF Neural Network (FC-CNN) architecture. In contrast to previous
face parsing methods that apply region-based subnetwork hundreds of times, our
FC-CNN is fully convolutional with high segmentation accuracy. To achieve this
goal, FC-CNN integrates three subnetworks, a unary network, a pairwise network
and a continuous Conditional Random Field (C-CRF) network into a unified
framework. The high-level semantic information and low-level details across
different convolutional layers are captured by the convolutional and
deconvolutional structures in the unary network. The semantic edge context is
learnt by the pairwise network branch to construct pixel-wise affinity. Based
on a differentiable superpixel pooling layer and a differentiable C-CRF layer,
the unary network and pairwise network are combined via a novel continuous CRF
network to achieve spatial consistency in both training and test procedure of a
deep neural network. Comprehensive evaluations on LFW-PL and HELEN datasets
demonstrate that FC-CNN achieves better performance over the other
state-of-arts for accurate face labeling on challenging images.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03743</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-Sentence N-ary Relation Extraction with Graph LSTMs</dc:title>
 <dc:creator>Peng, Nanyun</dc:creator>
 <dc:creator>Poon, Hoifung</dc:creator>
 <dc:creator>Quirk, Chris</dc:creator>
 <dc:creator>Toutanova, Kristina</dc:creator>
 <dc:creator>Yih, Wen-tau</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Past work in relation extraction has focused on binary relations in single
sentences. Recent NLP inroads in high-value domains have sparked interest in
the more general setting of extracting n-ary relations that span multiple
sentences. In this paper, we explore a general relation extraction framework
based on graph long short-term memory networks (graph LSTMs) that can be easily
extended to cross-sentence n-ary relation extraction. The graph formulation
provides a unified way of exploring different LSTM approaches and incorporating
various intra-sentential and inter-sentential dependencies, such as sequential,
syntactic, and discourse relations. A robust contextual representation is
learned for the entities, which serves as input to the relation classifier.
This simplifies handling of relations with arbitrary arity, and enables
multi-task learning with related relations. We evaluate this framework in two
important precision medicine settings, demonstrating its effectiveness with
both conventional supervised learning and distant supervision. Cross-sentence
extraction produced larger knowledge bases. and multi-task learning
significantly improved extraction accuracy. A thorough analysis of various LSTM
approaches yielded useful insight the impact of linguistic analysis on
extraction accuracy.
</dc:description>
 <dc:description>Comment: Conditional accepted by TACL in December 2016; published in April
  2017; presented at ACL in August 2017</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03743</dc:identifier>
 <dc:identifier>Transactions of the Association for Computational Linguistics
  (TACL) 2017, Vol 5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03748</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Calipso: Physics-based Image and Video Editing through CAD Model Proxies</dc:title>
 <dc:creator>Haouchine, Nazim</dc:creator>
 <dc:creator>Roy, Frederick</dc:creator>
 <dc:creator>Courtecuisse, Hadrien</dc:creator>
 <dc:creator>Nie&#xdf;ner, Matthias</dc:creator>
 <dc:creator>Cotin, Stephane</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present Calipso, an interactive method for editing images and videos in a
physically-coherent manner. Our main idea is to realize physics-based
manipulations by running a full physics simulation on proxy geometries given by
non-rigidly aligned CAD models. Running these simulations allows us to apply
new, unseen forces to move or deform selected objects, change physical
parameters such as mass or elasticity, or even add entire new objects that
interact with the rest of the underlying scene. In Calipso, the user makes
edits directly in 3D; these edits are processed by the simulation and then
transfered to the target 2D content using shape-to-image correspondences in a
photo-realistic rendering process. To align the CAD models, we introduce an
efficient CAD-to-image alignment procedure that jointly minimizes for rigid and
non-rigid alignment while preserving the high-level structure of the input
shape. Moreover, the user can choose to exploit image flow to estimate scene
motion, producing coherent physical behavior with ambient dynamics. We
demonstrate Calipso's physics-based editing on a wide range of examples
producing myriad physical behavior while preserving geometric and visual
consistency.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03748</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03759</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Accuracy of Cell-based Dynamic Traffic Assignment: Impact of Signal
  Control on System Optimality</dc:title>
 <dc:creator>Islam, Tarikul</dc:creator>
 <dc:creator>Vu, Hai L.</dc:creator>
 <dc:creator>Panda, Manoj</dc:creator>
 <dc:creator>Hoang, Nam</dc:creator>
 <dc:creator>Ngoduy, Dong</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Dynamic Traffic Assignment (DTA) provides an approach to determine the
optimal path and/or departure time based on the transportation network
characteristics and user behavior (e.g., selfish or social). In the literature,
most of the contributions study DTA problems without including traffic signal
control in the framework. The few contributions that report signal control
models are either mixed-integer or nonlinear formulations and computationally
intractable. The only continuous linear signal control method presented in the
literature is the Cycle-length Same as Discrete Time-interval (CSDT) control
scheme. This model entails a trade-off between cycle-length and cell-length.
Furthermore, this approach compromises accuracy and usability of the solutions.
  In this study, we propose a novel signal control model namely, Signal Control
with Realistic Cycle length (SCRC) which overcomes the trade-off between
cycle-length and cell-length and strikes a balance between complexity and
accuracy. The underlying idea of this model is to use a different time scale
for the cycle-length. This time scale can be set to any multiple of the time
slot of the Dynamic Network Loading (DNL) model (e.g. CTM, TTM, and LTM) and
enables us to set realistic lengths for the signal control cycles. Results
show, the SCRC model not only attains accuracy comparable to the CSDT model but
also more resilient against extreme traffic conditions. Furthermore, the
presented approach substantially reduces computational complexity and can
attain solution faster.
</dc:description>
 <dc:description>Comment: 6pages, 3 figures, Published in HKSTS 2015,
  http://www.hksts.org/conf15b.htm</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03760</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Upsampling of Depth Maps Using a Hybrid Camera</dc:title>
 <dc:creator>Yuan, Mingze</dc:creator>
 <dc:creator>Gao, Lin</dc:creator>
 <dc:creator>Fu, Hongbo</dc:creator>
 <dc:creator>Xia, Shihong</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  In recent years consumer-level depth sensors have been adopted in various
applications. However, they often produce depth maps at a not very fast frame
rate (around 30 frames per second), preventing them from being used for
applications like digitizing human performance involving fast motion. On the
other hand there are available low-cost faster-rate video cameras. This
motivates us to develop a hybrid camera that consists of a high-rate video
camera and a low-rate depth camera, and to allow temporal interpolation of
depth maps with the help of auxiliary color images. To achieve this we develop
a novel algorithm that reconstructs intermediate depth frames and estimates
scene flow simultaneously. We have tested our algorithm on various examples
involving fast, non-rigid motions of single or multiple objects. Our
experiments show that our scene flow estimation method is more precise than
purely tracking based method and the state-of-the-art techniques.
</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03763</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flower Categorization using Deep Convolutional Neural Networks</dc:title>
 <dc:creator>Gurnani, Ayesha</dc:creator>
 <dc:creator>Mavani, Viraj</dc:creator>
 <dc:creator>Gajjar, Vandit</dc:creator>
 <dc:creator>Khandhediya, Yash</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We have developed a deep learning network for classification of different
flowers. For this, we have used Visual Geometry Group's 102 category flower
dataset having 8189 images of 102 different flowers from University of Oxford.
The method is basically divided into two parts; Image segmentation and
classification. We have compared the performance of two different Convolutional
Neural Network architectures GoogLeNet and AlexNet for classification purpose.
By keeping the hyper parameters same for both architectures, we have found that
the top 1 and top 5 accuracies of GoogLeNet are 47.15% and 69.17% respectively
whereas the top 1 and top 5 accuracies of AlexNet are 43.39% and 68.68%
respectively. These results are extremely good when compared to random
classification accuracy of 0.98%. This method for classification of flowers can
be implemented in real time applications and can be used to help botanists for
their research as well as camping enthusiasts.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:date>2017-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03766</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Dark Side(-Channel) of Mobile Devices: A Survey on Network Traffic
  Analysis</dc:title>
 <dc:creator>Conti, Mauro</dc:creator>
 <dc:creator>Li, QianQian</dc:creator>
 <dc:creator>Maragno, Alberto</dc:creator>
 <dc:creator>Spolaor, Riccardo</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In recent years, mobile devices (e.g., smartphones and tablets) have met an
increasing commercial success and have become a fundamental element of the
everyday life for billions of people all around the world. Mobile devices are
used not only for traditional communication activities (e.g., voice calls and
messages) but also for more advanced tasks made possible by an enormous amount
of multi-purpose applications (e.g., finance, gaming, and shopping). As a
result, those devices generate a significant network traffic (a consistent part
of overall Internet traffic). For this reason, the research community has been
investigating security and privacy issues that are related to the network
traffic generated by mobile devices, which could be analyzed to obtain
information useful for a variety of goals (ranging from device security and
network optimization, to fine grained user profiling).
  In this paper, we review the works that contributed to the state of the art
of network traffic analysis targeting mobile devices. In particular, we present
a systematic classification of the works in the literature according to three
criteria: (i) the goal of the analysis; (ii) the point where the network
traffic is captured; and (iii) the targeted mobile platforms. In this survey,
we consider points of capturing such as Wi-Fi Access Points, software
simulation, inside physical devices or emulators. We also review and compare
the different models and techniques used in the surveyed works to carry out
their analyses, which could be ported to other emerging domains (e.g., Internet
of Things and Software Defined Networking). We believe our survey will be a
reference work for researchers and practitioners in this research field.
</dc:description>
 <dc:description>Comment: 41 pages, 6 figures, 20 tables</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03769</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noisy Softmax: Improving the Generalization Ability of DCNN via
  Postponing the Early Softmax Saturation</dc:title>
 <dc:creator>Chen, Binghui</dc:creator>
 <dc:creator>Deng, Weihong</dc:creator>
 <dc:creator>Du, Junping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Over the past few years, softmax and SGD have become a commonly used
component and the default training strategy in CNN frameworks, respectively.
However, when optimizing CNNs with SGD, the saturation behavior behind softmax
always gives us an illusion of training well and then is omitted. In this
paper, we first emphasize that the early saturation behavior of softmax will
impede the exploration of SGD, which sometimes is a reason for model converging
at a bad local-minima, then propose Noisy Softmax to mitigating this early
saturation issue by injecting annealed noise in softmax during each iteration.
This operation based on noise injection aims at postponing the early saturation
and further bringing continuous gradients propagation so as to significantly
encourage SGD solver to be more exploratory and help to find a better
local-minima. This paper empirically verifies the superiority of the early
softmax desaturation, and our method indeed improves the generalization ability
of CNN model by regularization. We experimentally find that this early
desaturation helps optimization in many tasks, yielding state-of-the-art or
competitive results on several popular benchmark datasets.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures, CVPR2017</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03769</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03772</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>5G Spectrum Sharing</dc:title>
 <dc:creator>Nekovee, Maziar</dc:creator>
 <dc:creator>Rudd, Richard</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper an overview is given of the current status of 5G industry
standards, spectrum allocation and use cases, followed by initial
investigations of new opportunities for spectrum sharing in 5G using cognitive
radio techniques, considering both licensed and unlicensed scenarios. A
particular attention is given to sharing millimeter-wave frequencies, which are
of prominent importance for 5G.
</dc:description>
 <dc:description>Comment: Keynote, CROWNCOM 2017</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03772</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03778</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chainspace: A Sharded Smart Contracts Platform</dc:title>
 <dc:creator>Al-Bassam, Mustafa</dc:creator>
 <dc:creator>Sonnino, Alberto</dc:creator>
 <dc:creator>Bano, Shehar</dc:creator>
 <dc:creator>Hrycyszyn, Dave</dc:creator>
 <dc:creator>Danezis, George</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Chainspace is a decentralized infrastructure, known as a distributed ledger,
that supports user defined smart contracts and executes user-supplied
transactions on their objects. The correct execution of smart contract
transactions is verifiable by all. The system is scalable, by sharding state
and the execution of transactions, and using S-BAC, a distributed commit
protocol, to guarantee consistency. Chainspace is secure against subsets of
nodes trying to compromise its integrity or availability properties through
Byzantine Fault Tolerance (BFT), and extremely high-auditability,
non-repudiation and `blockchain' techniques. Even when BFT fails, auditing
mechanisms are in place to trace malicious participants. We present the design,
rationale, and details of Chainspace; we argue through evaluating an
implementation of the system about its scaling and other features; we
illustrate a number of privacy-friendly smart contracts for smart metering,
polling and banking and measure their performance.
</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03778</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03783</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FluxMarker: Enhancing Tactile Graphics with Dynamic Tactile Markers</dc:title>
 <dc:creator>Suzuki, Ryo</dc:creator>
 <dc:creator>Stangl, Abigale</dc:creator>
 <dc:creator>Gross, Mark D.</dc:creator>
 <dc:creator>Yeh, Tom</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  For people with visual impairments, tactile graphics are an important means
to learn and explore information. However, raised line tactile graphics created
with traditional materials such as embossing are static. While available
refreshable displays can dynamically change the content, they are still too
expensive for many users, and are limited in size. These factors limit
wide-spread adoption and the representation of large graphics or data sets. In
this paper, we present FluxMaker, an inexpensive scalable system that renders
dynamic information on top of static tactile graphics with movable tactile
markers. These dynamic tactile markers can be easily reconfigured and used to
annotate static raised line tactile graphics, including maps, graphs, and
diagrams. We developed a hardware prototype that actuates magnetic tactile
markers driven by low-cost and scalable electromagnetic coil arrays, which can
be fabricated with standard printed circuit board manufacturing. We evaluate
our prototype with six participants with visual impairments and found positive
results across four application areas: location finding or navigating on
tactile maps, data analysis, and physicalization, feature identification for
tactile graphics, and drawing support. The user study confirms advantages in
application domains such as education and data exploration.
</dc:description>
 <dc:description>Comment: ASSETS 2017</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03786</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TraceDiff: Debugging Unexpected Code Behavior Using Trace Divergences</dc:title>
 <dc:creator>Suzuki, Ryo</dc:creator>
 <dc:creator>Soares, Gustavo</dc:creator>
 <dc:creator>Head, Andrew</dc:creator>
 <dc:creator>Glassman, Elena</dc:creator>
 <dc:creator>Reis, Ruan</dc:creator>
 <dc:creator>Mongiovi, Melina</dc:creator>
 <dc:creator>D'Antoni, Loris</dc:creator>
 <dc:creator>Hartmann, Bjoern</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  Recent advances in program synthesis offer means to automatically debug
student submissions and generate personalized feedback in massive programming
classrooms. When automatically generating feedback for programming assignments,
a key challenge is designing pedagogically useful hints that are as effective
as the manual feedback given by teachers. Through an analysis of teachers'
hint-giving practices in 132 online Q&amp;A posts, we establish three design
guidelines that an effective feedback design should follow. Based on these
guidelines, we develop a feedback system that leverages both program synthesis
and visualization techniques. Our system compares the dynamic code execution of
both incorrect and fixed code and highlights how the error leads to a
difference in behavior and where the incorrect code trace diverges from the
expected solution. Results from our study suggest that our system enables
students to detect and fix bugs that are not caught by students using another
existing visual debugging tool.
</dc:description>
 <dc:description>Comment: VL/HCC 2017</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03788</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Direct-Manipulation Visualization of Deep Networks</dc:title>
 <dc:creator>Smilkov, Daniel</dc:creator>
 <dc:creator>Carter, Shan</dc:creator>
 <dc:creator>Sculley, D.</dc:creator>
 <dc:creator>Vi&#xe9;gas, Fernanda B.</dc:creator>
 <dc:creator>Wattenberg, Martin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The recent successes of deep learning have led to a wave of interest from
non-experts. Gaining an understanding of this technology, however, is
difficult. While the theory is important, it is also helpful for novices to
develop an intuitive feel for the effect of different hyperparameters and
structural variations. We describe TensorFlow Playground, an interactive, open
sourced visualization that allows users to experiment via direct manipulation
rather than coding, enabling them to quickly build an intuition about neural
nets.
</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03792</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evacuating Two Robots from Two Unknown Exits on the Perimeter of a Disk</dc:title>
 <dc:creator>Pattanayak, Debasish</dc:creator>
 <dc:creator>Ramesh, H.</dc:creator>
 <dc:creator>Mandal, Partha Sarathi</dc:creator>
 <dc:creator>Schmid, Stefan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Distributed evacuation of mobile robots is a recent development. We consider
the evacuation problem of two robots which are initially located at the center
of a unit disk. Both the robots have to evacuate the disk through the exits
situated on the perimeter of the disk at an unknown location. The distance
between two exits along the perimeter $d$ is given. We consider two different
communication models. First, in the wireless model, the robots can send a
message to each other over a long distance. Second, in face-to-face
communication model, the robots can exchange information with each other only
when they touch each other. The objective of the evacuation problem is to
design an algorithm which minimizes the evacuation time of both the robots. For
the wireless communication model, we propose a generic algorithm for two robots
moving to two points on the perimeter with an initial separation of $\zeta \leq
d$. We also investigate evacuation problem for both unlabeled and labeled exits
in the wireless communication model. For the face-to-face communication model,
we propose two different algorithms for $\zeta =0$ and $\zeta =d$ for unlabeled
exits. We also propose a generic algorithm for $\zeta \leq d$ for labeled
exits. We provide lower bounds corresponding to different $d$ values in the
face-to-face communication model. We evaluate the performance our algorithms
with simulation for both of the communication models.
</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03795</identifier>
 <datestamp>2017-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kill Two Birds With One Stone: Boosting Both Object Detection Accuracy
  and Speed With adaptive Patch-of-Interest Composition</dc:title>
 <dc:creator>Zhang, Shihao</dc:creator>
 <dc:creator>Lin, Weiyao</dc:creator>
 <dc:creator>Lu, Ping</dc:creator>
 <dc:creator>Li, Weihua</dc:creator>
 <dc:creator>Deng, Shuo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object detection is an important yet challenging task in video understanding
&amp; analysis, where one major challenge lies in the proper balance between two
contradictive factors: detection accuracy and detection speed. In this paper,
we propose a new adaptive patch-of-interest composition approach for boosting
both the accuracy and speed for object detection. The proposed approach first
extracts patches in a video frame which have the potential to include
objects-of-interest. Then, an adaptive composition process is introduced to
compose the extracted patches into an optimal number of sub-frames for object
detection. With this process, we are able to maintain the resolution of the
original frame during object detection (for guaranteeing the accuracy), while
minimizing the number of inputs in detection (for boosting the speed).
Experimental results on various datasets demonstrate the effectiveness of the
proposed approach.
</dc:description>
 <dc:description>Comment: The project page for this paper is available at
  http://min.sjtu.edu.cn/lwydemo/Dete/demo/detection.html</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:date>2017-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03797</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Deep-Semantic Matrix Factorization for Tag-Aware Personalized
  Recommendation</dc:title>
 <dc:creator>Xu, Zhenghua</dc:creator>
 <dc:creator>Chen, Cheng</dc:creator>
 <dc:creator>Lukasiewicz, Thomas</dc:creator>
 <dc:creator>Miao, Yishu</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Matrix factorization has now become a dominant solution for personalized
recommendation on the Social Web. To alleviate the cold start problem, previous
approaches have incorporated various additional sources of information into
traditional matrix factorization models. These upgraded models, however,
achieve only &quot;marginal&quot; enhancements on the performance of personalized
recommendation. Therefore, inspired by the recent development of deep-semantic
modeling, we propose a hybrid deep-semantic matrix factorization (HDMF) model
to further improve the performance of tag-aware personalized recommendation by
integrating the techniques of deep-semantic modeling, hybrid learning, and
matrix factorization. Experimental results show that HDMF significantly
outperforms the state-of-the-art baselines in tag-aware personalized
recommendation, in terms of all evaluation metrics, e.g., its mean reciprocal
rank (resp., mean average precision) is 1.52 (resp., 1.66) times as high as
that of the best baseline.
</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03798</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Steering: Learning End-to-End Driving Model from Spatial and
  Temporal Visual Cues</dc:title>
 <dc:creator>Chi, Lu</dc:creator>
 <dc:creator>Mu, Yadong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In recent years, autonomous driving algorithms using low-cost vehicle-mounted
cameras have attracted increasing endeavors from both academia and industry.
There are multiple fronts to these endeavors, including object detection on
roads, 3-D reconstruction etc., but in this work we focus on a vision-based
model that directly maps raw input images to steering angles using deep
networks. This represents a nascent research topic in computer vision. The
technical contributions of this work are three-fold. First, the model is
learned and evaluated on real human driving videos that are time-synchronized
with other vehicle sensors. This differs from many prior models trained from
synthetic data in racing games. Second, state-of-the-art models, such as
PilotNet, mostly predict the wheel angles independently on each video frame,
which contradicts common understanding of driving as a stateful process.
Instead, our proposed model strikes a combination of spatial and temporal cues,
jointly investigating instantaneous monocular camera observations and vehicle's
historical states. This is in practice accomplished by inserting
carefully-designed recurrent units (e.g., LSTM and Conv-LSTM) at proper network
layers. Third, to facilitate the interpretability of the learned model, we
utilize a visual back-propagation scheme for discovering and visualizing image
regions crucially influencing the final steering prediction. Our experimental
study is based on about 6 hours of human driving data provided by Udacity.
Comprehensive quantitative evaluations demonstrate the effectiveness and
robustness of our model, even under scenarios like drastic lighting changes and
abrupt turning. The comparison with other state-of-the-art models clearly
reveals its superior performance in predicting the due wheel angle for a
self-driving car.
</dc:description>
 <dc:description>Comment: 12 pages, 15 figures</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03800</identifier>
 <datestamp>2017-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy saving for building heating via a simple and efficient model-free
  control design: First steps with computer simulations</dc:title>
 <dc:creator>Aboua&#xef;ssa, Hassane</dc:creator>
 <dc:creator>Hasan, Ola Alhaj</dc:creator>
 <dc:creator>Join, C&#xe9;dric</dc:creator>
 <dc:creator>Fliess, Michel</dc:creator>
 <dc:creator>Defer, Didier</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The model-based control of building heating systems for energy saving
encounters severe physical, mathematical and calibration difficulties in the
numerous attempts that has been published until now. This topic is addressed
here via a new model-free control setting, where the need of any mathematical
description disappears. Several convincing computer simulations are presented.
Comparisons with classic PI controllers and flatness-based predictive control
are provided.
</dc:description>
 <dc:description>Comment: 21st International Conference on System Theory, Control and
  Computing, October 2017, Sinaia, Romania</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:date>2017-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03805</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting the Effectiveness of Off-the-shelf Temporal Modeling
  Approaches for Large-scale Video Classification</dc:title>
 <dc:creator>Bian, Yunlong</dc:creator>
 <dc:creator>Gan, Chuang</dc:creator>
 <dc:creator>Liu, Xiao</dc:creator>
 <dc:creator>Li, Fu</dc:creator>
 <dc:creator>Long, Xiang</dc:creator>
 <dc:creator>Li, Yandong</dc:creator>
 <dc:creator>Qi, Heng</dc:creator>
 <dc:creator>Zhou, Jie</dc:creator>
 <dc:creator>Wen, Shilei</dc:creator>
 <dc:creator>Lin, Yuanqing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper describes our solution for the video recognition task of
ActivityNet Kinetics challenge that ranked the 1st place. Most of existing
state-of-the-art video recognition approaches are in favor of an end-to-end
pipeline. One exception is the framework of DevNet. The merit of DevNet is that
they first use the video data to learn a network (i.e. fine-tuning or training
from scratch). Instead of directly using the end-to-end classification scores
(e.g. softmax scores), they extract the features from the learned network and
then fed them into the off-the-shelf machine learning models to conduct video
classification. However, the effectiveness of this line work has long-term been
ignored and underestimated. In this submission, we extensively use this
strategy. Particularly, we investigate four temporal modeling approaches using
the learned features: Multi-group Shifting Attention Network, Temporal Xception
Network, Multi-stream sequence Model and Fast-Forward Sequence Model.
Experiment results on the challenging Kinetics dataset demonstrate that our
proposed temporal modeling approaches can significantly improve existing
approaches in the large-scale video recognition tasks. Most remarkably, our
best single Multi-group Shifting Attention Network can achieve 77.7% in term of
top-1 accuracy and 93.2% in term of top-5 accuracy on the validation set.
</dc:description>
 <dc:description>Comment: A brief summary of the winner solution on Activity Kinetics challenge
  2017</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03807</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Principle of Need-to-Act</dc:title>
 <dc:creator>Kundu, Ashish</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, we have introduced the notion of &quot;Principle of Need-to- Act&quot;.
This principle is essential towards developing secure systems, security
solutions and analyzing security of a solution.
</dc:description>
 <dc:description>Comment: 2 pages</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03808</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dimension Reduction for Polynomials over Gaussian Space and Applications</dc:title>
 <dc:creator>Ghazi, Badih</dc:creator>
 <dc:creator>Kamath, Pritish</dc:creator>
 <dc:creator>Raghavendra, Prasad</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We introduce a new technique for reducing the dimension of the ambient space
of low-degree polynomials in the Gaussian space while preserving their relative
correlation structure, analogous to the Johnson-Lindenstrauss lemma. As
applications, we address the following problems:
  1. Computability of Approximately Optimal Noise Stable function over Gaussian
space: The goal is to find a partition of $\mathbb{R}^n$ into $k$ parts, that
maximizes the noise stability. An $\delta$-optimal partition is one which is
within additive $\delta$ of the optimal noise stability.
  De, Mossel &amp; Neeman (CCC 2017) raised the question of proving a computable
bound on the dimension $n_0(\delta)$ in which we can find an $\delta$-optimal
partition. While De et al. provide such a bound, using our new technique, we
obtain improved explicit bounds on the dimension $n_0(\delta)$.
  2. Decidability of Non-Interactive Simulation of Joint Distributions: A
&quot;non-interactive simulation&quot; problem is specified by two distributions $P(x,y)$
and $Q(u,v)$: The goal is to determine if two players that observe sequences
$X^n$ and $Y^n$ respectively where $\{(X_i, Y_i)\}_{i=1}^n$ are drawn i.i.d.
from $P(x,y)$ can generate pairs $U$ and $V$ respectively (without
communicating with each other) with a joint distribution that is arbitrarily
close in total variation to $Q(u,v)$. Even when $P$ and $Q$ are extremely
simple, it is open in several cases if $P$ can simulate $Q$.
  In the special where $Q$ is a joint distribution over $\{0,1\} \times
\{0,1\}$, Ghazi, Kamath and Sudan (FOCS 2016) proved a computable bound on the
number of samples $n_0(\delta)$ that can be drawn from $P(x,y)$ to get
$\delta$-close to $Q$ (if it is possible at all). Recently De, Mossel &amp; Neeman
obtained such bounds when $Q$ is a distribution over $[k] \times [k]$ for any
$k \ge 2$. We recover this result with improved explicit bounds on
$n_0(\delta)$.
</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03812</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Offline Dynamic Higher Connectivity</dc:title>
 <dc:creator>Peng, Richard</dc:creator>
 <dc:creator>Sandlund, Bryce</dc:creator>
 <dc:creator>Sleator, Daniel D.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We give the first $O(t\log{t})$ time algorithm for processing a given
sequence of $t$ edge updates and 3-vertex/edge connectivity queries in an
undirected unweighted graph. Our approach builds upon a method by Eppstein
(1994) that reduces graphs to smaller equivalents on a set of key vertices. It
also leads to algorithms for offline 2-vertex/edge connectivity whose
performances match those from Kaczmarz and Lacki (2015).
</dc:description>
 <dc:description>Comment: Revised version of a WADS '13 submission</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03816</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mass Displacement Networks</dc:title>
 <dc:creator>Neverova, Natalia</dc:creator>
 <dc:creator>Kokkinos, Iasonas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite the large improvements in performance attained by using deep learning
in computer vision, one can often further improve results with some additional
post-processing that exploits the geometric nature of the underlying task. This
commonly involves displacing the posterior distribution of a CNN in a way that
makes it more appropriate for the task at hand, e.g. better aligned with local
image features, or more compact. In this work we integrate this geometric
post-processing within a deep architecture, introducing a differentiable and
probabilistically sound counterpart to the common geometric voting technique
used for evidence accumulation in vision. We refer to the resulting neural
models as Mass Displacement Networks (MDNs), and apply them to human pose
estimation in two distinct setups: (a) landmark localization, where we collapse
a distribution to a point, allowing for precise localization of body keypoints
and (b) communication across body parts, where we transfer evidence from one
part to the other, allowing for a globally consistent pose estimate. We
evaluate on large-scale pose estimation benchmarks, such as MPII Human Pose and
COCO datasets, and report systematic improvements when compared to strong
baselines.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03822</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classical Music Composition Using State Space Models</dc:title>
 <dc:creator>Yanchenko, Anna K.</dc:creator>
 <dc:creator>Mukherjee, Sayan</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Algorithmic composition of music has a long history and with the development
of powerful deep learning methods, there has recently been increased interest
in exploring algorithms and models to create art. We explore the utility of
state space models, in particular hidden Markov models (HMMs) and variants, in
composing classical piano pieces from the Romantic era and consider the models'
ability to generate new pieces that sound like they were composed by a human.
We find that the models we explored are fairly successful at generating new
pieces that have largely consonant harmonies, especially when trained on
original pieces with simple harmonic structure. However, we conclude that the
major limitation in using these models to generate music that sounds like it
was composed by a human is the lack of melodic progression in the composed
pieces. We also examine the performance of the models in the context of music
theory.
</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03832</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Level Power-Imbalance Allocation Control for Secondary Frequency
  Control in Power Systems</dc:title>
 <dc:creator>Xi, Kaihua</dc:creator>
 <dc:creator>Lin, Hai Xiang</dc:creator>
 <dc:creator>Shen, Chen</dc:creator>
 <dc:creator>van Schuppen, Jan H.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper focuses on secondary frequency control of large-scale power
systems. First a centralized and a consensus control based distributed control
law are presented, then a multi-level control law, named Multi-Level
Power-Imbalance Allocation Control (MLPIAC), for the large-scale power systems
partitioned into more than one region. The centralized and distributed control
law are applied within each region and over the regions respectively. Besides
restoring nominal frequency with a minimized control cost, MLPIAC also
considers the transient behavior of the system after a disturbance. We present
a control strategy different from the one applied in the Power-Imbalance
Allocation Control (PIAC), which also enhances the transient behavior of the
frequency through an accelerated convergence of the control inputs eliminating
overshoots in MLPIAC. In the level of the distributed control over the regions,
the consensus of the marginal costs can be accelerated through a single
parameter. Furthermore, because the number of regions is smaller than that of
nodes, MLPIAC is more effective to obtain the minimized cost than the purely
distributed control law. The asymptotic stability of MLPIAC is proven using the
Lyapunov method and the performance is evaluated through simulations.
</dc:description>
 <dc:description>Comment: 22 pages, 4 figures. This paper has been submitted to a journal for
  publication</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03835</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Support Vector Machines using Coresets</dc:title>
 <dc:creator>Baykal, Cenk</dc:creator>
 <dc:creator>Liebenwein, Lucas</dc:creator>
 <dc:creator>Schwarting, Wilko</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a novel coreset construction algorithm for solving classification
tasks using Support Vector Machines (SVMs) in a computationally efficient
manner. A coreset is a weighted subset of the original data points that
provably approximates the original set. We show that coresets of size
polylogarithmic in $n$ and polynomial in $d$ exist for a set of $n$ input
points with $d$ features and present an $(\epsilon,\delta)$-FPRAS for
constructing coresets for scalable SVM training. Our method leverages the
insight that data points are often redundant and uses an importance sampling
scheme based on the sensitivity of each data point to construct coresets
efficiently. We evaluate the performance of our algorithm in accelerating SVM
training against real-world data sets and compare our algorithm to
state-of-the-art coreset approaches. Our empirical results show that our
approach outperforms a state-of-the-art coreset approach and uniform sampling
in enabling computational speedups while achieving low approximation error.
</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03850</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure in scientific networks: towards predictions of research
  dynamism</dc:title>
 <dc:creator>Stewart, Benjamin W.</dc:creator>
 <dc:creator>Rivas, Andy</dc:creator>
 <dc:creator>Vuong, Luat T.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Certain areas of scientific research flourish while others lose advocates and
attention. We are interested in whether structural patterns within citation
networks correspond to the growth or decline of the research areas to which
those networks belong. We focus on three topic areas within optical physics as
a set of cases; those areas have developed along different trajectories: one
continues to expand rapidly; another is on the wane after an earlier peak; the
final area has re-emerged after a short waning period. These three areas have
substantial overlaps in the types of equipment they use and general
methodology; at the same time, their citation networks are largely independent
of each other. For each of our three areas, we map the citation networks of the
top-100 most-cited papers, published pre-1999. In order to quantify the
structures of the selected articles' citation networks, we use a modified
version of weak tie theory in tandem with entropy measures. Although the
fortunes of a given research area are most obviously the result of accumulated
innovations and impasses, our preliminary study provides evidence that these
citation networks' emergent structures reflect those developments and may shape
evolving conversations in the scholarly literature.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03852</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State
  Estimator</dc:title>
 <dc:creator>Qin, Tong</dc:creator>
 <dc:creator>Li, Peiliang</dc:creator>
 <dc:creator>Shen, Shaojie</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  A monocular visual-inertial system (VINS), consisting of a camera and a
low-cost inertial measurement unit (IMU), forms the minimum sensor suite for
metric six degrees-of-freedom (DOF) state estimation. However, the lack of
direct distance measurement poses significant challenges in terms of IMU
processing, estimator initialization, extrinsic calibration, and nonlinear
optimization. In this work, we present VINS-Mono: a robust and versatile
monocular visual-inertial state estimator.Our approach starts with a robust
procedure for estimator initialization and failure recovery. A tightly-coupled,
nonlinear optimization-based method is used to obtain high accuracy
visual-inertial odometry by fusing pre-integrated IMU measurements and feature
observations. A loop detection module, in combination with our tightly-coupled
formulation, enables relocalization with minimum computation overhead.We
additionally perform four degrees-of-freedom pose graph optimization to enforce
global consistency. We validate the performance of our system on public
datasets and real-world experiments and compare against other state-of-the-art
algorithms. We also perform onboard closed-loop autonomous flight on the MAV
platform and port the algorithm to an iOS-based demonstration. We highlight
that the proposed work is a reliable, complete, and versatile system that is
applicable for different applications that require high accuracy localization.
We open source our implementations for both PCs and iOS mobile devices.
</dc:description>
 <dc:description>Comment: journal paper</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03853</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Parameterized Complexity of Happy Colorings</dc:title>
 <dc:creator>Misra, Neeldhara</dc:creator>
 <dc:creator>Reddy, I. Vinod</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Consider a graph $G = (V,E)$ and a coloring $c$ of vertices with colors from
$[\ell]$. A vertex $v$ is said to be happy with respect to $c$ if $c(v) = c(u)$
for all neighbors $u$ of $v$. Further, an edge $(u,v)$ is happy if $c(u) =
c(v)$. Given a partial coloring $c$ of $V$, the Maximum Happy Vertex (Edge)
problem asks for a total coloring of $V$ extending $c$ to all vertices of $V$
that maximises the number of happy vertices (edges). Both problems are known to
be NP-hard in general even when $\ell = 3$, and is polynomially solvable when
$\ell = 2$. In [IWOCA 2016] it was shown that both problems are polynomially
solvable on trees, and for arbitrary $k$, it was shown that MHE is \NPH{} on
planar graphs and is \FPT{} parameterized by the number of precolored vertices
and branchwidth.
  We continue the study of this problem from a parameterized prespective. Our
focus is on both structural and standard parameterizations. To begin with, we
establish that the problems are \FPT{} when parameterized by the treewidth and
the number of colors used in the precoloring, which is a potential improvement
over the total number of precolored vertices. Further, we show that both the
vertex and edge variants of the problem is \FPT{} when parameterized by vertex
cover and distance-to-clique parameters. We also show that the problem of
maximizing the number of happy edges is \FPT{} when parameterized by the
standard parameter, the number of happy edges. We show that the maximum happy
vertex (edge) problem is \NPH{} on split graphs and bipartite graphs and
polynomially solvable on cographs.
</dc:description>
 <dc:description>Comment: 16 pages, appears in IWOCA 2017</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03854</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IoT Data Analytics Using Deep Learning</dc:title>
 <dc:creator>Xie, Xiaofeng</dc:creator>
 <dc:creator>Wu, Di</dc:creator>
 <dc:creator>Liu, Siping</dc:creator>
 <dc:creator>Li, Renfa</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Deep learning is a popular machine learning approach which has achieved a lot
of progress in all traditional machine learning areas. Internet of thing (IoT)
and Smart City deployments are generating large amounts of time-series sensor
data in need of analysis. Applying deep learning to these domains has been an
important topic of research. The Long-Short Term Memory (LSTM) network has been
proven to be well suited for dealing with and predicting important events with
long intervals and delays in the time series. LTSM networks have the ability to
maintain long-term memory. In an LTSM network, a stacked LSTM hidden layer also
makes it possible to learn a high level temporal feature without the need of
any fine tuning and preprocessing which would be required by other techniques.
In this paper, we construct a long-short term memory (LSTM) recurrent neural
network structure, use the normal time series training set to build the
prediction model. And then we use the predicted error from the prediction model
to construct a Gaussian naive Bayes model to detect whether the original sample
is abnormal. This method is called LSTM-Gauss-NBayes for short. We use three
real-world data sets, each of which involve long-term time-dependence or
short-term time-dependence, even very weak time dependence. The experimental
results show that LSTM-Gauss-NBayes is an effective and robust model.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03861</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feedback Design for Multi-Antenna K-tier Heterogeneous Downlink Cellular
  Networks</dc:title>
 <dc:creator>Park, Jeonghun</dc:creator>
 <dc:creator>Lee, Namyoon</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We characterize the ergodic spectral efficiency of a non-cooperative and a
cooperative type of K-tier heterogeneous networks with limited feedback. In the
non-cooperative case, a multi-antenna base station (BS) serves a single-antenna
user using maximum-ratio transmission based on limited feedback. In the
cooperative case, a BS coordination set is formed by using dynamic clustering
across the tiers, wherein the intra-cluster interference is mitigated by using
multi-cell zero-forcing also based on limited feedback. Modeling the network
based on stochastic geometry, we derive analytical expressions for the ergodic
spectral efficiency as a function of the system parameters. Leveraging the
obtained expressions, we formulate feedback partition problems and obtain
solutions to improve the ergodic spectral efficiency. Simulations show the
spectral efficiency improvement by using the obtained feedback partitions. Our
major findings are as follows: 1) In the non-cooperative case, the feedback is
only useful in a particular tier if the mean interference is small enough. 2)
In the cooperative case, allocating more feedback to stronger intra-cluster BSs
is efficient. 3) In both cases, the obtained solutions do not change depending
on instantaneous signal-to-interference ratio.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03864</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trust architectures in payment systems: the great bifurcation</dc:title>
 <dc:creator>Boullier, Dominique</dc:creator>
 <dc:creator>Sivakumar, Niranjan</dc:creator>
 <dc:creator>Crepel, Maxime</dc:creator>
 <dc:creator>Juguet, St&#xe9;phane</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Payments architectures are on the verge of a great bifurcation that must be
documented in order to be debated. Google is moving towards a quasi bank while
Apple and Google disseminate payment systems over smartphones. At the same
time, block chain might become a distributed ledger introducing a radical new
model of trusted third-party. The detailed history of credit card systems helps
understand why the game of security has always been trigged by a delegation
process of the risk to third parties and by the cat-and-mouse game of security
and fraud. Technologies were designed to solve these issues but have always
been closely related to innovations in institutional assemblages. These
payments systems shape our social life and the stakes of trust that we put in
these architectures require a truly political examination.
</dc:description>
 <dc:description>Comment: 31 pages, 6 HD figures</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03867</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Pulmonary Nodule Detection via 3D ConvNets with Online Sample
  Filtering and Hybrid-Loss Residual Learning</dc:title>
 <dc:creator>Dou, Qi</dc:creator>
 <dc:creator>Chen, Hao</dc:creator>
 <dc:creator>Jin, Yueming</dc:creator>
 <dc:creator>Lin, Huangjing</dc:creator>
 <dc:creator>Qin, Jing</dc:creator>
 <dc:creator>Heng, Pheng-Ann</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel framework with 3D convolutional networks
(ConvNets) for automated detection of pulmonary nodules from low-dose CT scans,
which is a challenging yet crucial task for lung cancer early diagnosis and
treatment. Different from previous standard ConvNets, we try to tackle the
severe hard/easy sample imbalance problem in medical datasets and explore the
benefits of localized annotations to regularize the learning, and hence boost
the performance of ConvNets to achieve more accurate detections. Our proposed
framework consists of two stages: 1) candidate screening, and 2) false positive
reduction. In the first stage, we establish a 3D fully convolutional network,
effectively trained with an online sample filtering scheme, to sensitively and
rapidly screen the nodule candidates. In the second stage, we design a
hybrid-loss residual network which harnesses the location and size information
as important cues to guide the nodule recognition procedure. Experimental
results on the public large-scale LUNA16 dataset demonstrate superior
performance of our proposed method compared with state-of-the-art approaches
for the pulmonary nodule detection task.
</dc:description>
 <dc:description>Comment: Accepted to MICCAI 2017</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03871</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Game-Theoretic Analysis of the Off-Switch Game</dc:title>
 <dc:creator>W&#xe4;ngberg, Tobias</dc:creator>
 <dc:creator>B&#xf6;&#xf6;rs, Mikael</dc:creator>
 <dc:creator>Catt, Elliot</dc:creator>
 <dc:creator>Everitt, Tom</dc:creator>
 <dc:creator>Hutter, Marcus</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The off-switch game is a game theoretic model of a highly intelligent robot
interacting with a human. In the original paper by Hadfield-Menell et al.
(2016), the analysis is not fully game-theoretic as the human is modelled as an
irrational player, and the robot's best action is only calculated under
unrealistic normality and soft-max assumptions. In this paper, we make the
analysis fully game theoretic, by modelling the human as a rational player with
a random utility function. As a consequence, we are able to easily calculate
the robot's best action for arbitrary belief and irrationality assumptions.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03871</dc:identifier>
 <dc:identifier>Artificial General Intelligence: 10th International Conference,
  AGI 2017, Melbourne, VIC, Australia, August 15-18, 2017, Proceedings, pages
  167-177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03874</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Filter Learning for Visual Tracking</dc:title>
 <dc:creator>Yang, Tianyu</dc:creator>
 <dc:creator>Chan, Antoni B.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently using convolutional neural networks (CNNs) has gained popularity in
visual tracking, due to its robust feature representation of images. Recent
methods perform online tracking by fine-tuning a pre-trained CNN model to the
specific target object using stochastic gradient descent (SGD)
back-propagation, which is usually time-consuming. In this paper, we propose a
recurrent filter generation methods for visual tracking. We directly feed the
target's image patch to a recurrent neural network (RNN) to estimate an
object-specific filter for tracking. As the video sequence is a spatiotemporal
data, we extend the matrix multiplications of the fully-connected layers of the
RNN to a convolution operation on feature maps, which preserves the target's
spatial structure and also is memory-efficient. The tracked object in the
subsequent frames will be fed into the RNN to adapt the generated filters to
appearance variations of the target. Note that once the off-line training
process of our network is finished, there is no need to fine-tune the network
for specific objects, which makes our approach more efficient than methods that
use iterative fine-tuning to online learn the target. Extensive experiments
conducted on widely used benchmarks, OTB and VOT, demonstrate encouraging
results compared to other recent methods.
</dc:description>
 <dc:description>Comment: ICCV2017 Workshop on VOT</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03877</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solar hard X-ray imaging by means of Compressed Sensing and Finite
  Isotropic Wavelet Transform</dc:title>
 <dc:creator>Duval-Poo, M. A.</dc:creator>
 <dc:creator>Piana, M.</dc:creator>
 <dc:creator>Massone, A. M.</dc:creator>
 <dc:subject>Astrophysics - Solar and Stellar Astrophysics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65R32</dc:subject>
 <dc:description>  This paper shows that compressed sensing realized by means of regularized
deconvolution and the Finite Isotropic Wavelet Transform is effective and
reliable in hard X-ray solar imaging.
  The method utilizes the Finite Isotropic Wavelet Transform with Meyer
function as the mother wavelet. Further, compressed sensing is realized by
optimizing a sparsity-promoting regularized objective function by means of the
Fast Iterative Shrinkage-Thresholding Algorithm. Eventually, the regularization
parameter is selected by means of the Miller criterion.
  The method is applied against both synthetic data mimicking the
Spectrometer/Telescope Imaging X-rays (STIX) measurements and experimental
observations provided by the Reuven Ramaty High Energy Solar Spectroscopic
Imager (RHESSI). The performances of the method are compared with the results
provided by standard visibility-based reconstruction methods.
  The results show that the application of the sparsity constraint and the use
of a continuous, isotropic framework for the wavelet transform provide a
notable spatial accuracy and significantly reduce the ringing effects due to
the instrument point spread functions.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03878</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Big Data Model Simulation on a Graph Database for Surveillance in
  Wireless Multimedia Sensor Networks</dc:title>
 <dc:creator>K&#xfc;&#xe7;&#xfc;kke&#xe7;eci, Cihan</dc:creator>
 <dc:creator>Yaz&#x131;c&#x131;, Adnan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Sensors are present in various forms all around the world such as mobile
phones, surveillance cameras, smart televisions, intelligent refrigerators and
blood pressure monitors. Usually, most of the sensors are a part of some other
system with similar sensors that compose a network. One of such networks is
composed of millions of sensors connect to the Internet which is called
Internet of things (IoT). With the advances in wireless communication
technologies, multimedia sensors and their networks are expected to be major
components in IoT. Many studies have already been done on wireless multimedia
sensor networks in diverse domains like fire detection, city surveillance,
early warning systems, etc. All those applications position sensor nodes and
collect their data for a long time period with real-time data flow, which is
considered as big data. Big data may be structured or unstructured and needs to
be stored for further processing and analyzing. Analyzing multimedia big data
is a challenging task requiring a high-level modeling to efficiently extract
valuable information/knowledge from data. In this study, we propose a big
database model based on graph database model for handling data generated by
wireless multimedia sensor networks. We introduce a simulator to generate
synthetic data and store and query big data using graph model as a big
database. For this purpose, we evaluate the well-known graph-based NoSQL
databases, Neo4j and OrientDB, and a relational database, MySQL.We have run a
number of query experiments on our implemented simulator to show that which
database system(s) for surveillance in wireless multimedia sensor networks is
efficient and scalable.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03878</dc:identifier>
 <dc:identifier>doi:10.1016/j.bdr.2017.09.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03880</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Quality Assessment Guided Deep Neural Networks Training</dc:title>
 <dc:creator>Chen, Zhuo</dc:creator>
 <dc:creator>Lin, Weisi</dc:creator>
 <dc:creator>Wang, Shiqi</dc:creator>
 <dc:creator>Xu, Long</dc:creator>
 <dc:creator>Li, Leida</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  For many computer vision problems, the deep neural networks are trained and
validated based on the assumption that the input images are pristine (i.e.,
artifact-free). However, digital images are subject to a wide range of
distortions in real application scenarios, while the practical issues regarding
image quality in high level visual information understanding have been largely
ignored. In this paper, in view of the fact that most widely deployed deep
learning models are susceptible to various image distortions, the distorted
images are involved for data augmentation in the deep neural network training
process to learn a reliable model for practical applications. In particular, an
image quality assessment based label smoothing method, which aims at
regularizing the label distribution of training images, is further proposed to
tune the objective functions in learning the neural network. Experimental
results show that the proposed method is effective in dealing with both low and
high quality images in the typical image classification task.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03882</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monadic Remote Invocation</dc:title>
 <dc:creator>Jolly, Raphael</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  In order to achieve Separation of Concerns in the domain of remote method
invocation, a small functional adapter is added atop Java RMI, eliminating the
need for every remote object to implement java.rmi.Remote and making it
possible to remotely access existing code, unchanged. The Remote monad is
introduced, and its implementation and usage are detailed. Reusing the
existing, proven technology of RMI allows not to re-invent the underlying
network protocol. As a result, orthogonal remote invocation is achieved with
little or no implementation effort.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03888</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large Batch Training of Convolutional Networks</dc:title>
 <dc:creator>You, Yang</dc:creator>
 <dc:creator>Gitman, Igor</dc:creator>
 <dc:creator>Ginsburg, Boris</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A common way to speed up training of large convolutional networks is to add
computational units. Training is then performed using data-parallel synchronous
Stochastic Gradient Descent (SGD) with mini-batch divided between computational
units. With an increase in the number of nodes, the batch size grows. But
training with large batch size often results in the lower model accuracy. We
argue that the current recipe for large batch training (linear learning rate
scaling with warm-up) is not general enough and training may diverge. To
overcome this optimization difficulties we propose a new training algorithm
based on Layer-wise Adaptive Rate Scaling (LARS). Using LARS, we scaled Alexnet
up to a batch size of 8K, and Resnet-50 to a batch size of 32K without loss in
accuracy.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:date>2017-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03889</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualizing the context of citations referencing papers published by
  Eugene Garfield: A new type of keyword co-occurrence analysis</dc:title>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:creator>Haunschild, Robin</dc:creator>
 <dc:creator>Hug, Sven E.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  During Eugene Garfield's (EG's) lengthy career as information scientist, he
published about 1,500 papers. In this study, we use the impressive oeuvre of EG
to introduce a new type of bibliometric networks: keyword co-occurrences
networks based on the context of citations, which are referenced in a certain
paper set (here: the papers published by EG). The citation context is defined
by the words which are located around a specific citation. We retrieved the
citation context from Microsoft Academic. To interpret and compare the results
of the new network type, we generated two further networks: co-occurrence
networks which are based on title and abstract keywords from (1) EG's papers
and (2) the papers citing EG's publications. The comparison of the three
networks suggests that papers of EG and citation contexts of papers citing EG
are semantically more closely related to each other than to titles and
abstracts of papers citing EG. This result accords with the use of citations in
research evaluation that is based on the premise that citations reflect the
cognitive influence of the cited on the citing publication.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03889</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-017-2591-8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03892</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EmoTxt: A Toolkit for Emotion Recognition from Text</dc:title>
 <dc:creator>Calefato, Fabio</dc:creator>
 <dc:creator>Lanubile, Filippo</dc:creator>
 <dc:creator>Novielli, Nicole</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present EmoTxt, a toolkit for emotion recognition from text, trained and
tested on a gold standard of about 9K question, answers, and comments from
online interactions. We provide empirical evidence of the performance of
EmoTxt. To the best of our knowledge, EmoTxt is the first open-source toolkit
supporting both emotion recognition from text and training of custom emotion
classification models.
</dc:description>
 <dc:description>Comment: In Proc. 7th Affective Computing and Intelligent Interaction
  (ACII'17), San Antonio, TX, USA, Oct. 23-26, 2017, p. 79-80, ISBN:
  978-1-5386-0563-9</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03895</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Large deviations for empirical locality measure of typed Random
  Graph Models</dc:title>
 <dc:creator>Doku-Amponsah, Kwabena</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A15, 94A24, 60F10, 05C80</dc:subject>
 <dc:description>  In this article, we prove a local large deviation principle (LLDP) for the
empirical locality measure of typed random networks on $n$ nodes conditioned to
have a given \emph{ empirical type measure} and \emph{ empirical link measure.}
From the LLDP, we deduce a full large deviation principle for the typed random
graph, and the classical Erdos-Renyi graphs, where $nc/2$ links are inserted at
random among $n$ nodes. No topological restrictions are required for these
results.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03898</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Extremely Efficient Chess-board Detection for Non-trivial Photos</dc:title>
 <dc:creator>Czyzewski, Maciej A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a set of algorithms that can be used to locate and crop the
chess-board/chess-pieces from the picture, including every rectangular grid
with any pattern. Our method is non-parametric, and thus does not require the
prior knowledge from computer vision and machine learning, which is instead
inferred from data. We illustrate the application of our method to a variety of
examples, such as chess-board cropping and regular grid-pattern localization.
In addition, we present two independent algorithms: PAMG (vertices detector)
and FAPL (thermal lines) that can be widely used for other tasks in computer
vision.
</dc:description>
 <dc:description>Comment: 11 pages, 14 figures; for implementation, see
  https://github.com/maciejczyzewski/neural-chessboard</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03900</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensitivity Analysis of Core Specialization Techniques</dc:title>
 <dc:creator>Kallurkar, Prathmesh</dc:creator>
 <dc:creator>Sarangi, Smruti R.</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  The instruction footprint of OS-intensive workloads such as web servers,
database servers, and file servers typically exceeds the size of the
instruction cache (32 KB). Consequently, such workloads incur a lot of i-cache
misses, which reduces their performance drastically. Several papers have
proposed to improve the performance of such workloads using core
specialization. In this scheme, tasks with different instruction footprints are
executed on different cores. In this report, we study the performance of five
state of the art core specialization techniques: SelectiveOffload [6], FlexSC
[8], DisAggregateOS [5], SLICC [2], and SchedTask [3] for different system
parameters. Our studies show that for a suite of 8 popular OS-intensive
workloads, SchedTask performs best for all evaluated configurations.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, 4 tables</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03901</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Belief Tree Search for Active Object Recognition</dc:title>
 <dc:creator>Malmir, Mohsen</dc:creator>
 <dc:creator>Cottrell, Garrison W.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Active Object Recognition (AOR) has been approached as an unsupervised
learning problem, in which optimal trajectories for object inspection are not
known and are to be discovered by reducing label uncertainty measures or
training with reinforcement learning. Such approaches have no guarantees of the
quality of their solution. In this paper, we treat AOR as a Partially
Observable Markov Decision Process (POMDP) and find near-optimal policies on
training data using Belief Tree Search (BTS) on the corresponding belief Markov
Decision Process (MDP). AOR then reduces to the problem of knowledge transfer
from near-optimal policies on training set to the test set. We train a Long
Short Term Memory (LSTM) network to predict the best next action on the
training set rollouts. We sho that the proposed AOR method generalizes well to
novel views of familiar objects and also to novel objects. We compare this
supervised scheme against guided policy search, and find that the LSTM network
reaches higher recognition accuracy compared to the guided policy method. We
further look into optimizing the observation function to increase the total
collected reward of optimal policy. In AOR, the observation function is known
only approximately. We propose a gradient-based method update to this
approximate observation function to increase the total reward of any policy. We
show that by optimizing the observation function and retraining the supervised
LSTM network, the AOR performance on the test set improves significantly.
</dc:description>
 <dc:description>Comment: IROS 2017</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03903</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Exact Weighted All-Pairs Shortest Paths in $\tilde
  O(n^{5/4})$ Rounds</dc:title>
 <dc:creator>Huang, Chien-Chung</dc:creator>
 <dc:creator>Nanongkai, Danupon</dc:creator>
 <dc:creator>Saranurak, Thatchaphol</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>F.2.0</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We study computing {\em all-pairs shortest paths} (APSP) on distributed
networks (the CONGEST model). The goal is for every node in the (weighted)
network to know the distance from every other node using communication. The
problem admits $(1+o(1))$-approximation $\tilde O(n)$-time algorithms
~\cite{LenzenP-podc15,Nanongkai-STOC14}, which are matched with $\tilde
\Omega(n)$-time lower
bounds~\cite{Nanongkai-STOC14,LenzenP_stoc13,FrischknechtHW12}\footnote{$\tilde
\Theta$, $\tilde O$ and $\tilde \Omega$ hide polylogarithmic factors. Note that
the lower bounds also hold even in the unweighted case and in the weighted case
with polynomial approximation ratios.}. No $\omega(n)$ lower bound or $o(m)$
upper bound were known for exact computation.
  In this paper, we present an $\tilde O(n^{5/4})$-time randomized (Las Vegas)
algorithm for exact weighted APSP; this provides the first improvement over the
naive $O(m)$-time algorithm when the network is not so sparse. Our result also
holds for the case where edge weights are {\em asymmetric} (a.k.a. the directed
case where communication is bidirectional). Our techniques also yield an
$\tilde O(n^{3/4}k^{1/2}+n)$-time algorithm for the {\em $k$-source shortest
paths} problem where we want every node to know distances from $k$ sources;
this improves Elkin's recent bound~\cite{Elkin-STOC17} when $k=\tilde
\omega(n^{1/4})$.
</dc:description>
 <dc:description>Comment: Minor corrections in Section 4</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03910</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised emotion lexicon expansion with label propagation and
  specialized word embeddings</dc:title>
 <dc:creator>Giulianelli, Mario</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  There exist two main approaches to automatically extract affective
orientation: lexicon-based and corpus-based. In this work, we argue that these
two methods are compatible and show that combining them can improve the
accuracy of emotion classifiers. In particular, we introduce a novel variant of
the Label Propagation algorithm that is tailored to distributed word
representations, we apply batch gradient descent to accelerate the optimization
of label propagation and to make the optimization feasible for large graphs,
and we propose a reproducible method for emotion lexicon expansion. We conclude
that label propagation can expand an emotion lexicon in a meaningful way and
that the expanded emotion lexicon can be leveraged to improve the accuracy of
an emotion classifier.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03911</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Cost-Sensitive Visual Question-Answer Framework for Mining a Deep
  And-OR Object Semantics from Web Images</dc:title>
 <dc:creator>Zhang, Quanshi</dc:creator>
 <dc:creator>Wu, Ying Nian</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a cost-sensitive Question-Answering (QA) framework for
learning a nine-layer And-Or graph (AoG) from web images, which explicitly
represents object categories, poses, parts, and detailed structures within the
parts in a compositional hierarchy. The QA framework is designed to minimize an
overall risk, which trades off the loss and query costs. The loss is defined
for nodes in all layers of the AoG, including the generative loss (measuring
the likelihood for the images) and the discriminative loss (measuring the
fitness to human answers). The cost comprises both human labor of answering
questions and the computational cost of model learning. The cost-sensitive QA
framework iteratively selects different storylines of questions to update
different nodes in the AoG. Experiments showed that our method required much
less human supervision (e.g., labeling parts on 3--10 training objects for each
category) and achieved better performance than baseline methods.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03915</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Beamforming Design and Power Allocation for Full-Duplex NOMA
  Cognitive Relay Systems</dc:title>
 <dc:creator>Mohammadi, Mohammadali</dc:creator>
 <dc:creator>Chalise, Batu K.</dc:creator>
 <dc:creator>Hakimi, Azar</dc:creator>
 <dc:creator>Suraweera, Himal A.</dc:creator>
 <dc:creator>Ding, Zhiguo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider a non-orthogonal multiple access cognitive radio
network, where a full-duplex multi-antenna relay assists transmission from a
base station (BS) to a cognitive far user, whereas, at the same time, the BS
transmits to a cognitive near user. Our objective is to enlarge the far-near
user rate region by maximizing the rate of the near user under a constraint
that the rate of the far user is above a certain threshold. To this end, a
non-convex joint optimization problem of relay beamforming and the transmit
powers at the BS and cognitive relay is solved as a semi-definite relaxation
problem, in conjunction with an efficiently solvable line-search approach. For
comparisons, we also consider low complexity fixed beamformer design, where the
optimum power allocation between the BS and cognitive relay is solved. Our
results demonstrate that the proposed joint optimization can significantly
reduce the impact of the residual self-interference at the FD relay and
inter-user interference in the near user case.
</dc:description>
 <dc:description>Comment: Accepted for IEEE Global Communications Conference (GLOBECOM 2017)</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03917</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>About renegades and outgroup-haters: Modelling the link between social
  influence and intergroup attitudes</dc:title>
 <dc:creator>Flache, Andreas</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Polarization between groups is a major topic of contemporary societal debate
as well as of research into intergroup relations. Formal modelers of opinion
dynamics try to explain how intergroup polarization can arise from simple first
principles of interactions within and between groups. Models have been proposed
in which intergroup attitudes affect social influence in the form of homophily
or xenophobia, elaborated as fixed tendencies of individuals to interact more
with in-group members, be more open to influence from in-group members and
perhaps even distance oneself from attitudes of outgroup members. While these
models can generate polarization between groups, their underlying assumptions
curiously neglect a central insight from research on intergroup attitudes.
Intergroup attitudes are themselves subject to social influence in interactions
with both in- and outgroup members. I extend an existing model of opinion
formation with intergroup attitudes, by adding this feedback-effect. I show how
this changes model predictions about the process and the conditions of
polarization between groups. In particular, it is demonstrated how the model
implies that intergroup polarization can become less likely if intergroup
attitudes change under social influence; and how more complex patterns of
intergroup relations emerge. Especially, a renegade minority (outgroup-lovers)
can have a key role in avoiding mutually negative intergroup relations and even
elicit attitude reversal, resulting in a majority of individuals developing a
negative attitude towards their in-group and a positive one of the outgroup.
Interpretations of these theoretical results and directions for future research
are further discussed.
</dc:description>
 <dc:description>Comment: 33 pages, 21 figures, Paper presented at ODCD 2017. Interdisciplinary
  Workshop on Opinion Dynamics and Collective Decision 2017, July 5-7, 2017 @
  Jacobs University Bremen, Germany</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03918</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Deep Neural Networks for Vehicle Re-ID with
  Visual-spatio-temporal Path Proposals</dc:title>
 <dc:creator>Shen, Yantao</dc:creator>
 <dc:creator>Xiao, Tong</dc:creator>
 <dc:creator>Li, Hongsheng</dc:creator>
 <dc:creator>Yi, Shuai</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Vehicle re-identification is an important problem and has many applications
in video surveillance and intelligent transportation. It gains increasing
attention because of the recent advances of person re-identification
techniques. However, unlike person re-identification, the visual differences
between pairs of vehicle images are usually subtle and even challenging for
humans to distinguish. Incorporating additional spatio-temporal information is
vital for solving the challenging re-identification task. Existing vehicle
re-identification methods ignored or used over-simplified models for the
spatio-temporal relations between vehicle images. In this paper, we propose a
two-stage framework that incorporates complex spatio-temporal information for
effectively regularizing the re-identification results. Given a pair of vehicle
images with their spatio-temporal information, a candidate
visual-spatio-temporal path is first generated by a chain MRF model with a
deeply learned potential function, where each visual-spatio-temporal state
corresponds to an actual vehicle image with its spatio-temporal information. A
Siamese-CNN+Path-LSTM model takes the candidate path as well as the pairwise
queries to generate their similarity score. Extensive experiments and analysis
show the effectiveness of our proposed method and individual components.
</dc:description>
 <dc:description>Comment: To appear in ICCV 2017</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03919</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full-duplex Multi-Antenna Relay Assisted Cooperative Non-Orthogonal
  Multiple Access</dc:title>
 <dc:creator>Mobini, Zahra</dc:creator>
 <dc:creator>Mohammadi, Mohammadali</dc:creator>
 <dc:creator>Suraweera, Himal A.</dc:creator>
 <dc:creator>Ding, Zhiguo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a cooperative non-orthogonal multiple access (NOMA) network in
which a full-duplex (FD) multi-antenna relay assists transmission from a base
station (BS) to a set of far users with poor channel conditions, while at the
same time the BS transmits to a set of near users with strong channel
conditions. We assume imperfect self-interference (SI) cancellation at the FD
relay and imperfect inter-user interference cancellation at the near users. In
order to cancel the SI at the relay a zero-forcing based beamforming scheme is
used and the corresponding outage probability analysis of two user selection
strategies, namely random near user and random far user (RNRF), and nearest
near user and nearest far user (NNNF), are derived. Our finding suggests that
significant performance improvement can be achieved by using the FD
multi-antenna relay compared to the counterpart system with a half-duplex
relay. The achieved performance gain depends on network parameters such as the
user density, user zones, path loss and the strength of the inter-user
interference in case of near users. We also show that the NNNF strategy
exhibits a superior outage performance compared to the RNRF strategy,
especially in the case of near
</dc:description>
 <dc:description>Comment: Accepted for IEEE Global Communications Conference (GLOBECOM 2017)</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03920</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Speech Emotion Recognition &quot;in the wild&quot; using Aggregated
  Corpora and Deep Multi-Task Learning</dc:title>
 <dc:creator>Kim, Jaebok</dc:creator>
 <dc:creator>Englebienne, Gwenn</dc:creator>
 <dc:creator>Truong, Khiet P.</dc:creator>
 <dc:creator>Evers, Vanessa</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  One of the challenges in Speech Emotion Recognition (SER) &quot;in the wild&quot; is
the large mismatch between training and test data (e.g. speakers and tasks). In
order to improve the generalisation capabilities of the emotion models, we
propose to use Multi-Task Learning (MTL) and use gender and naturalness as
auxiliary tasks in deep neural networks. This method was evaluated in
within-corpus and various cross-corpus classification experiments that simulate
conditions &quot;in the wild&quot;. In comparison to Single-Task Learning (STL) based
state of the art methods, we found that our MTL method proposed improved
performance significantly. Particularly, models using both gender and
naturalness achieved more gains than those using either gender or naturalness
separately. This benefit was also found in the high-level representations of
the feature space, obtained from our method proposed, where discriminative
emotional clusters could be observed.
</dc:description>
 <dc:description>Comment: Published in the proceedings of INTERSPEECH, Stockholm, September,
  2017</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03921</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Graph Mining</dc:title>
 <dc:creator>Zhang, Quanshi</dc:creator>
 <dc:creator>Song, Xuan</dc:creator>
 <dc:creator>Shibasaki, Ryosuke</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this study, we formulate the concept of &quot;mining maximal-size frequent
subgraphs&quot; in the challenging domain of visual data (images and videos). In
general, visual knowledge can usually be modeled as attributed relational
graphs (ARGs) with local attributes representing local parts and pairwise
attributes describing the spatial relationship between parts. Thus, from a
practical perspective, such mining of maximal-size subgraphs can be regarded as
a general platform for discovering and modeling the common objects within
cluttered and unlabeled visual data. Then, from a theoretical perspective,
visual graph mining should encode and overcome the great fuzziness of messy
data collected from complex real-world situations, which conflicts with the
conventional theoretical basis of graph mining designed for tabular data.
Common subgraphs hidden in these ARGs usually have soft attributes, with
considerable inter-graph variation. More importantly, we should also discover
the latent pattern space, including similarity metrics for the pattern and
hidden node relations, during the mining process. In this study, we redefine
the visual subgraph pattern that encodes all of these challenges in a general
way, and propose an approximate but efficient solution to graph mining. We
conduct five experiments to evaluate our method with different kinds of visual
data, including videos and RGB/RGB-D images. These experiments demonstrate the
generality of the proposed method.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03940</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Sparse and Dense Feature Combinations for Sentiment
  Classification</dc:title>
 <dc:creator>Yu, Tao</dc:creator>
 <dc:creator>Hidey, Christopher</dc:creator>
 <dc:creator>Rambow, Owen</dc:creator>
 <dc:creator>McKeown, Kathleen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Neural networks are one of the most popular approaches for many natural
language processing tasks such as sentiment analysis. They often outperform
traditional machine learning models and achieve the state-of-art results on
most tasks. However, many existing deep learning models are complex, difficult
to train and provide a limited improvement over simpler methods. We propose a
simple, robust and powerful model for sentiment classification. This model
outperforms many deep learning models and achieves comparable results to other
deep learning models with complex architectures on sentiment analysis datasets.
We publish the code online.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03941</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Hypothesis Testing Against Independence with Multiple Decision
  Centers</dc:title>
 <dc:creator>Salehkalaibar, Sadaf</dc:creator>
 <dc:creator>Wigger, Michele</dc:creator>
 <dc:creator>Timo, Roy</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A distributed binary hypothesis testing problem is studied with one observer
and two decision centers. The type-II error exponents region is derived for
testing against independence when the observer communicates with the two
decision centers over one common and two individual noise-free bit pipes. When
there is only a common noise-free bit pipe, the type-II error exponents region
is derived for testing against conditional independence. Finally, when the
observer can communicate to the two decision centers over a discrete memoryless
broadcast channel, an achievable type-II error exponents region is derived for
testing against conditional independence. The last type-II error exponent is
obtained by splitting the observations into subblocks, having the transmitter
apply hybrid joint source-channel coding with side-information independently to
each subblock, and having each receiver apply a Neyman-Pearson test jointly
over the subblocks. This decision approach avoids introducing further error
exponents due to the binning or the decoding procedures.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03946</identifier>
 <datestamp>2017-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parametric Identification Using Weighted Null-Space Fitting</dc:title>
 <dc:creator>Galrinho, Miguel</dc:creator>
 <dc:creator>Rojas, Cristian R.</dc:creator>
 <dc:creator>Hjalmarsson, Hakan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In system identification of structured models, the prediction error method
provides asymptotically efficient estimates under mild assumptions, but in
general it requires solving a non-convex optimization problem. An alternative
class of methods uses a non-parametric model as intermediate step to obtain the
model of interest. The weighted null-space fitting (WNSF) method belongs to
this class. It is a weighted least-squares method consisting of the following
three steps. In the first step, a high-order ARX model is estimated. In the
second step, this high-order estimate is reduced to a parametric estimate, with
least squares. In the third step, the parametric model is re-estimated, with
weighted least squares. The method is flexible in parametrization and suitable
for both open- and closed-loop data. In this paper, we show that WNSF provides
consistent and asymptotically efficient estimates when the model orders as
chosen according to the true system. Also, simulation studies indicate that
WNSF may be competitive with state-of-the-art methods.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:date>2017-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03947</identifier>
 <datestamp>2017-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic Analysis of Semi-Parametric Weighted Null-Space Fitting
  Identification</dc:title>
 <dc:creator>Galrinho, Miguel</dc:creator>
 <dc:creator>Rojas, Cristian R.</dc:creator>
 <dc:creator>Hjalmarsson, Hakan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Standard system identification methods often provide biased estimates with
closed-loop data. With the prediction error method (PEM), the bias issue is
solved by using a noise model that is flexible enough to capture the noise
spectrum. However, a too flexible noise model (i.e., too many parameters) can
cause additional numerical problems for PEM. In this paper, we perform a
theoretical analysis of the weighted null-space fitting (WNSF) method when a
parametric noise model is not estimated. With this method, the system is first
captured using a non-parametric ARX model, which is then reduced to a
parametric model of interest. In the reduction step, a noise model does not
need to be estimated if it is not of interest. In open loop, this still
provides asymptotically efficient estimates of the dynamic model. In closed
loop, the estimates are consistent, and their covariance is optimal for a
non-parametric noise model. In this paper, we prove these results, which
require additional technical details compared with the case with a full
parametric model structure. In particular, we use a geometric approach for
variance analysis, deriving a new result that will be instrumental to our end.
Finally, we use a simulation study to illustrate the benefits of the method
when the noise model cannot be parametrized by a low-order model.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:date>2017-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03949</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradient Methods for Submodular Maximization</dc:title>
 <dc:creator>Hassani, Hamed</dc:creator>
 <dc:creator>Soltanolkotabi, Mahdi</dc:creator>
 <dc:creator>Karbasi, Amin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we study the problem of maximizing continuous submodular
functions that naturally arise in many learning applications such as those
involving utility functions in active learning and sensing, matrix
approximations and network inference. Despite the apparent lack of convexity in
such functions, we prove that stochastic projected gradient methods can provide
strong approximation guarantees for maximizing continuous submodular functions
with convex constraints. More specifically, we prove that for monotone
continuous DR-submodular functions, all fixed points of projected gradient
ascent provide a factor $1/2$ approximation to the global maxima. We also study
stochastic gradient and mirror methods and show that after
$\mathcal{O}(1/\epsilon^2)$ iterations these methods reach solutions which
achieve in expectation objective values exceeding
$(\frac{\text{OPT}}{2}-\epsilon)$. An immediate application of our results is
to maximize submodular functions that are defined stochastically, i.e. the
submodular function is defined as an expectation over a family of submodular
functions with an unknown distribution. We will show how stochastic gradient
methods are naturally well-suited for this setting, leading to a factor $1/2$
approximation when the function is monotone. In particular, it allows us to
approximately maximize discrete, monotone submodular optimization problems via
projected gradient descent on a continuous relaxation, directly connecting the
discrete and continuous domains. Finally, experiments on real data demonstrate
that our projected gradient methods consistently achieve the best utility
compared to other continuous baselines while remaining competitive in terms of
computational effort.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03950</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>State Evolution for Approximate Message Passing with Non-Separable
  Functions</dc:title>
 <dc:creator>Berthier, Raphael</dc:creator>
 <dc:creator>Montanari, Andrea</dc:creator>
 <dc:creator>Nguyen, Phan-Minh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Given a high-dimensional data matrix ${\boldsymbol A}\in{\mathbb R}^{m\times
n}$, Approximate Message Passing (AMP) algorithms construct sequences of
vectors ${\boldsymbol u}^t\in{\mathbb R}^n$, ${\boldsymbol v}^t\in{\mathbb
R}^m$, indexed by $t\in\{0,1,2\dots\}$ by iteratively applying ${\boldsymbol
A}$ or ${\boldsymbol A}^{{\sf T}}$, and suitable non-linear functions, which
depend on the specific application. Special instances of this approach have
been developed --among other applications-- for compressed sensing
reconstruction, robust regression, Bayesian estimation, low-rank matrix
recovery, phase retrieval, and community detection in graphs. For certain
classes of random matrices ${\boldsymbol A}$, AMP admits an asymptotically
exact description in the high-dimensional limit $m,n\to\infty$, which goes
under the name of `state evolution.'
  Earlier work established state evolution for separable non-linearities (under
certain regularity conditions). Nevertheless, empirical work demonstrated
several important applications that require non-separable functions. In this
paper we generalize state evolution to Lipschitz continuous non-separable
nonlinearities, for Gaussian matrices ${\boldsymbol A}$. Our proof makes use of
Bolthausen's conditioning technique along with several approximation arguments.
In particular, we introduce a modified algorithm (called LAMP for Long AMP)
which is of independent interest.
</dc:description>
 <dc:description>Comment: 41 pages, 4 figures</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03951</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization of Ensemble Supervised Learning Algorithms for Increased
  Sensitivity, Specificity, and AUC of Population-Based Colorectal Cancer
  Screenings</dc:title>
 <dc:creator>Kamath, Anirudh</dc:creator>
 <dc:creator>Singh, Aditya</dc:creator>
 <dc:creator>Ramnani, Raj</dc:creator>
 <dc:creator>Vyas, Ayush</dc:creator>
 <dc:creator>Shenoy, Jay</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Over 150,000 new people in the United States are diagnosed with colorectal
cancer each year. Nearly a third die from it (American Cancer Society). The
only approved noninvasive diagnosis tools currently involve fecal blood count
tests (FOBTs) or stool DNA tests. Fecal blood count tests take only five
minutes and are available over the counter for as low as \$15. They are highly
specific, yet not nearly as sensitive, yielding a high percentage (25%) of
false negatives (Colon Cancer Alliance). Moreover, FOBT results are far too
generalized, meaning that a positive result could mean much more than just
colorectal cancer, and could just as easily mean hemorrhoids, anal fissure,
proctitis, Crohn's disease, diverticulosis, ulcerative colitis, rectal ulcer,
rectal prolapse, ischemic colitis, angiodysplasia, rectal trauma, proctitis
from radiation therapy, and others. Stool DNA tests, the modern benchmark for
CRC screening, have a much higher sensitivity and specificity, but also cost
\$600, take two weeks to process, and are not for high-risk individuals or
people with a history of polyps. To yield a cheap and effective CRC screening
alternative, a unique ensemble-based classification algorithm is put in place
that considers the FIT result, BMI, smoking history, and diabetic status of
patients. This method is tested under ten-fold cross validation to have a .95
AUC, 92% specificity, 89% sensitivity, .88 F1, and 90% precision. Once
clinically validated, this test promises to be cheaper, faster, and potentially
more accurate when compared to a stool DNA test.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03954</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An interactive version of the Lov\'asz local lemma</dc:title>
 <dc:creator>Kirousis, Lefteris</dc:creator>
 <dc:creator>Livieratos, John</dc:creator>
 <dc:creator>Psaromiligkos, Kostas I.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Assume we are given (finitely many) mutually independent variables and
(finitely many) &quot;undesirable&quot; events, each depending on a subset of the
variables of at most $k$ elements, called the scope of the event. Assume that
the probability of a variable belonging to the scope of an occurring event is
bounded by $q$. We prove that if $ekq \leq 1$ then there exists at least one
assignment to the variables for which none of the events occurs. Examples are
given where the criterion $ekq \leq 1$ is applicable, whereas that of the
classical version of the Lov\'asz local lemma is not. The proof of the result
is through an interactive, private-coin implementation of the algorithm by
Moser. The original implementation, which yields the classical result, finds
efficiently, but probabilistically, an assignment to the events that avoids all
undesirable events. Interestingly, the interactive implementation given in this
work does not constitute an efficient, even if probabilistic, algorithm to find
an assignment as desired under the weaker assumption $ekq \leq 1$. We can only
conclude that under the hypothesis that $ekq \leq 1$, the interactive protocol
will produce an assignment as desired within $n$ rounds, with probability high
with respect to $n$; however, the provers' choices remain non-deterministic.
Plausibly finding such an assignment is inherently hard, as the situation is
reminiscent, in a probabilistic framework, of problems complete for syntactic
subclasses of TFNP.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:date>2018-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03958</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lattice Long Short-Term Memory for Human Action Recognition</dc:title>
 <dc:creator>Sun, Lin</dc:creator>
 <dc:creator>Jia, Kui</dc:creator>
 <dc:creator>Chen, Kevin</dc:creator>
 <dc:creator>Yeung, Dit Yan</dc:creator>
 <dc:creator>Shi, Bertram E.</dc:creator>
 <dc:creator>Savarese, Silvio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human actions captured in video sequences are three-dimensional signals
characterizing visual appearance and motion dynamics. To learn action patterns,
existing methods adopt Convolutional and/or Recurrent Neural Networks (CNNs and
RNNs). CNN based methods are effective in learning spatial appearances, but are
limited in modeling long-term motion dynamics. RNNs, especially Long Short-Term
Memory (LSTM), are able to learn temporal motion dynamics. However, naively
applying RNNs to video sequences in a convolutional manner implicitly assumes
that motions in videos are stationary across different spatial locations. This
assumption is valid for short-term motions but invalid when the duration of the
motion is long.
  In this work, we propose Lattice-LSTM (L2STM), which extends LSTM by learning
independent hidden state transitions of memory cells for individual spatial
locations. This method effectively enhances the ability to model dynamics
across time and addresses the non-stationary issue of long-term motion dynamics
without significantly increasing the model complexity. Additionally, we
introduce a novel multi-modal training procedure for training our network.
Unlike traditional two-stream architectures which use RGB and optical flow
information as input, our two-stream model leverages both modalities to jointly
train both input gates and both forget gates in the network rather than
treating the two streams as separate entities with no information about the
other. We apply this end-to-end system to benchmark datasets (UCF-101 and
HMDB-51) of human action recognition. Experiments show that on both datasets,
our proposed method outperforms all existing ones that are based on LSTM and/or
CNNs of similar model complexities.
</dc:description>
 <dc:description>Comment: ICCV2017</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03962</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Minimum Spanning Forest with Subpolynomial Worst-case Update
  Time</dc:title>
 <dc:creator>Nanongkai, Danupon</dc:creator>
 <dc:creator>Saranurak, Thatchaphol</dc:creator>
 <dc:creator>Wulff-Nilsen, Christian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a Las Vegas algorithm for dynamically maintaining a minimum
spanning forest of an $n$-node graph undergoing edge insertions and deletions.
Our algorithm guarantees an $O(n^{o(1)})$ worst-case update time with high
probability. This significantly improves the two recent Las Vegas algorithms by
Wulff-Nilsen [STOC'17] with update time $O(n^{0.5-\epsilon})$ for some constant
$\epsilon&gt;0$ and, independently, by Nanongkai and Saranurak [STOC'17] with
update time $O(n^{0.494})$ (the latter works only for maintaining a spanning
forest).
  Our result is obtained by identifying the common framework that both two
previous algorithms rely on, and then improve and combine the ideas from both
works. There are two main algorithmic components of the framework that are
newly improved and critical for obtaining our result. First, we improve the
update time from $O(n^{0.5-\epsilon})$ in Wulff-Nilsen [STOC'17] to
$O(n^{o(1)})$ for decrementally removing all low-conductance cuts in an
expander undergoing edge deletions. Second, by revisiting the &quot;contraction
technique&quot; by Henzinger and King [1997] and Holm et al. [STOC'98], we show a
new approach for maintaining a minimum spanning forest in connected graphs with
very few (at most $(1+o(1))n$) edges. This significantly improves the previous
approach in [Wulff-Nilsen STOC'17] and [Nanongkai and Saranurak STOC'17] which
is based on Frederickson's 2-dimensional topology tree and illustrates a new
application to this old technique.
</dc:description>
 <dc:description>Comment: Open problems added. To appear at FOCS 2017</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03962</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03963</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>System-Level Performance of mmWave Cellular Networks for Urban Micro
  Environments</dc:title>
 <dc:creator>Rupasinghe, Nadisanka</dc:creator>
 <dc:creator>Kakishima, Yuichi</dc:creator>
 <dc:creator>Guvenc, Ismail</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate the propagation coupling loss (captures all
sources of attenuation between serving cell and mobile station (MS)) and
geometry metric (GM) (downlink average signal-to-interference plus noise ratio)
performance of mmWave cellular networks for outdoor and indoor MSs, considering
urban micro (UMi) environments. Based on these studies, we identify effective
mmWave frequency bands for cellular communication. We consider 3GPP compliant
system-level simulations with two power allocation schemes: 1) transmit power
scaled with communication bandwidth, and 2) constant total transmit power.
Simulation results show that with scaled transmit power allocation, GM
performance degradation is small: 20% of MSs experience GM less than 0 dB at
all mmWave frequencies considered, for outdoor MSs. With constant Tx power
allocation, 20% of MSs experience GM less than 0 dB for frequencies up to 30
GHz. Furthermore, 35% (48%) of outdoor MSs experience GM performance less than
0 dB at 60 GHz (100 GHz). On the other hand, for indoor MSs, even with scaled
Tx power allocation, favorable GM performance is observed only at low
frequencies, i.e., 2 GHz.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03978</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assentication: User Deauthentication and Lunchtime Attack Mitigation
  with Seated Posture Biometric</dc:title>
 <dc:creator>Kaczmarek, Tyler</dc:creator>
 <dc:creator>Ozturk, Ercan</dc:creator>
 <dc:creator>Tsudik, Gene</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Biometric techniques are often used as an extra security factor in
authenticating human users. Numerous biometrics have been proposed and
evaluated, each with its own set of benefits and pitfalls. Static biometrics
(such as fingerprints) are geared for discrete operation, to identify users,
which typically involves some user burden. Meanwhile, behavioral biometrics
(such as keystroke dynamics) are well suited for continuous, and sometimes more
unobtrusive, operation. One important application domain for biometrics is
deauthentication, a means of quickly detecting absence of a previously
authenticated user and immediately terminating that user's active secure
sessions. Deauthentication is crucial for mitigating so called Lunchtime
Attacks, whereby an insider adversary takes over (before any inactivity timeout
kicks in) authenticated state of a careless user who walks away from her
computer. Motivated primarily by the need for an unobtrusive and continuous
biometric to support effective deauthentication, we introduce PoPa, a new
hybrid biometric based on a human user's seated posture pattern. PoPa captures
a unique combination of physiological and behavioral traits. We describe a low
cost fully functioning prototype that involves an office chair instrumented
with 16 tiny pressure sensors. We also explore (via user experiments) how PoPa
can be used in a typical workplace to provide continuous authentication (and
deauthentication) of users. We experimentally assess viability of PoPa in terms
of uniqueness by collecting and evaluating posture patterns of a cohort of
users. Results show that PoPa exhibits very low false positive, and even lower
false negative, rates. In particular, users can be identified with, on average,
91.0% accuracy. Finally, we compare pros and cons of PoPa with those of several
prominent biometric based deauthentication techniques.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03978</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03979</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SSH: Single Stage Headless Face Detector</dc:title>
 <dc:creator>Najibi, Mahyar</dc:creator>
 <dc:creator>Samangouei, Pouya</dc:creator>
 <dc:creator>Chellappa, Rama</dc:creator>
 <dc:creator>Davis, Larry</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce the Single Stage Headless (SSH) face detector. Unlike two stage
proposal-classification detectors, SSH detects faces in a single stage directly
from the early convolutional layers in a classification network. SSH is
headless. That is, it is able to achieve state-of-the-art results while
removing the &quot;head&quot; of its underlying classification network -- i.e. all fully
connected layers in the VGG-16 which contains a large number of parameters.
Additionally, instead of relying on an image pyramid to detect faces with
various scales, SSH is scale-invariant by design. We simultaneously detect
faces with different scales in a single forward pass of the network, but from
different layers. These properties make SSH fast and light-weight.
Surprisingly, with a headless VGG-16, SSH beats the ResNet-101-based
state-of-the-art on the WIDER dataset. Even though, unlike the current
state-of-the-art, SSH does not use an image pyramid and is 5X faster. Moreover,
if an image pyramid is deployed, our light-weight network achieves
state-of-the-art on all subsets of the WIDER dataset, improving the AP by 2.5%.
SSH also reaches state-of-the-art results on the FDDB and Pascal-Faces datasets
while using a small input size, leading to a runtime of 50 ms/image on a GPU.
The code is available at https://github.com/mahyarnajibi/SSH.
</dc:description>
 <dc:description>Comment: International Conference on Computer Vision (ICCV) 2017</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:date>2017-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03981</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PSSE Redux: Convex Relaxation, Decentralized, Robust, and Dynamic
  Approaches</dc:title>
 <dc:creator>Kekatos, Vassilis</dc:creator>
 <dc:creator>Wang, Gang</dc:creator>
 <dc:creator>Zhu, Hao</dc:creator>
 <dc:creator>Giannakis, Georgios B.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This chapter aspires to glean some of the recent advances in power system
state estimation (PSSE), though our collection is not exhaustive by any means.
The Cram{\'e}r-Rao bound, a lower bound on the (co)variance of any unbiased
estimator, is first derived for the PSSE setup. After reviewing the classical
Gauss-Newton iterations, contemporary PSSE solvers leveraging relaxations to
convex programs and successive convex approximations are explored. A
disciplined paradigm for distributed and decentralized schemes is subsequently
exemplified under linear(ized) and exact grid models. Novel bad data processing
models and fresh perspectives linking critical measurements to cyber-attacks on
the state estimator are presented. Finally, spurred by advances in online
convex optimization, model-free and model-based state trackers are reviewed.
</dc:description>
 <dc:description>Comment: 43 Pages, 8 figures</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03984</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperation in 5G HetNets: Advanced Spectrum Access and D2D Assisted
  Communications</dc:title>
 <dc:creator>Tsiropoulos, Georgios I.</dc:creator>
 <dc:creator>Yadav, Animesh</dc:creator>
 <dc:creator>Zeng, Ming</dc:creator>
 <dc:creator>Dobre, Octavia A.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The evolution of conventional wireless communication networks to the fifth
generation (5G) is driven by an explosive increase in the number of wireless
mobile devices and services, as well as their demand for all-time and
everywhere connectivity, high data rates, low latency, high energy-efficiency
and improved quality of service. To address these challenges, 5G relies on key
technologies, such as full duplex (FD), device-to-device (D2D) communications,
and network densification. In this article, a heterogeneous networking
architecture is envisioned, where cells of different sizes and radio access
technologies coexist. Specifically, collaboration for spectrum access is
explored for both FD- and cognitive-based approaches, and cooperation among
devices is discussed in the context of the state-of-the-art D2D assisted
communication paradigm. The presented cooperative framework is expected to
advance the understandings of the critical technical issues towards dynamic
spectrum management for 5G heterogeneous networks.
</dc:description>
 <dc:description>Comment: to appear in IEEE Wireless Communications</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03984</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03985</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AffectNet: A Database for Facial Expression, Valence, and Arousal
  Computing in the Wild</dc:title>
 <dc:creator>Mollahosseini, Ali</dc:creator>
 <dc:creator>Hasani, Behzad</dc:creator>
 <dc:creator>Mahoor, Mohammad H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automated affective computing in the wild setting is a challenging problem in
computer vision. Existing annotated databases of facial expressions in the wild
are small and mostly cover discrete emotions (aka the categorical model). There
are very limited annotated facial databases for affective computing in the
continuous dimensional model (e.g., valence and arousal). To meet this need, we
collected, annotated, and prepared for public distribution a new database of
facial emotions in the wild (called AffectNet). AffectNet contains more than
1,000,000 facial images from the Internet by querying three major search
engines using 1250 emotion related keywords in six different languages. About
half of the retrieved images were manually annotated for the presence of seven
discrete facial expressions and the intensity of valence and arousal. AffectNet
is by far the largest database of facial expression, valence, and arousal in
the wild enabling research in automated facial expression recognition in two
different emotion models. Two baseline deep neural networks are used to
classify images in the categorical model and predict the intensity of valence
and arousal. Various evaluation metrics show that our deep neural network
baselines can perform better than conventional machine learning methods and
off-the-shelf facial expression recognition systems.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Affective Computing, 2017</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:date>2017-10-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03986</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Creating an A Cappella Singing Audio Dataset for Automatic Jingju
  Singing Evaluation Research</dc:title>
 <dc:creator>Gong, Rong</dc:creator>
 <dc:creator>Repetto, Rafael Caro</dc:creator>
 <dc:creator>Serra, Xavier</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The data-driven computational research on automatic jingju (also known as
Beijing or Peking opera) singing evaluation lacks a suitable and comprehensive
a cappella singing audio dataset. In this work, we present an a cappella
singing audio dataset which consists of 120 arias, accounting for 1265 melodic
lines. This dataset is also an extension our existing CompMusic jingju corpus.
Both professional and amateur singers were invited to the dataset recording
sessions, and the most common jingju musical elements have been covered. This
dataset is also accompanied by metadata per aria and melodic line annotated for
automatic singing evaluation research purpose. All the gathered data is openly
available online.
</dc:description>
 <dc:description>Comment: 4th International Digital Libraries for Musicology workshop (DLfM
  2017), Shanghai, China</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03989</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutive Audio Source Separation using Robust ICA and an intelligent
  evolving permutation ambiguity solution</dc:title>
 <dc:creator>Mallis, Dimitrios</dc:creator>
 <dc:creator>Sgouros, Thomas</dc:creator>
 <dc:creator>Mitianoudis, Nikolaos</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Audio source separation is the task of isolating sound sources that are
active simultaneously in a room captured by a set of microphones. Convolutive
audio source separation of equal number of sources and microphones has a number
of shortcomings including the complexity of frequency-domain ICA, the
permutation ambiguity and the problem's scalabity with increasing number of
sensors. In this paper, the authors propose a multiple-microphone audio source
separation algorithm based on a previous work of Mitianoudis and Davies (2003).
Complex FastICA is substituted by Robust ICA increasing robustness and
performance. Permutation ambiguity is solved using two methodologies. The first
is using the Likelihood Ration Jump solution, which is now modified to decrease
computational complexity in the case of multiple microphones. The application
of the MuSIC algorithm, as a preprocessing step to the previous solution, forms
a second methodology with promising results.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03989</dc:identifier>
 <dc:identifier>doi:10.1007/s12530-017-9199-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03993</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Gross Merchandise Volume via DNN-MAB Dynamic Ranking Paradigm</dc:title>
 <dc:creator>Yan, Yan</dc:creator>
 <dc:creator>Guo, Wentao</dc:creator>
 <dc:creator>Zhao, Meng</dc:creator>
 <dc:creator>Hu, Jinghe</dc:creator>
 <dc:creator>Yan, Weipeng P.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  With the transition from people's traditional `brick-and-mortar' shopping to
online mobile shopping patterns in web 2.0 $\mathit{era}$, the recommender
system plays a critical role in E-Commerce and E-Retails. This is especially
true when designing this system for more than $\mathbf{236~million}$ daily
active users. Ranking strategy, the key module of the recommender system, needs
to be precise, accurate, and responsive for estimating customers' intents. We
propose a dynamic ranking paradigm, named as DNN-MAB, that is composed of a
pairwise deep neural network (DNN) $\mathit{pre}$-ranker connecting a revised
multi-armed bandit (MAB) dynamic $\mathit{post}$-ranker. By taking into account
of explicit and implicit user feedbacks such as impressions, clicks,
conversions, etc. DNN-MAB is able to adjust DNN $\mathit{pre}$-ranking scores
to assist customers locating items they are interested in most so that they can
converge quickly and frequently. To the best of our knowledge, frameworks like
DNN-MAB have not been discussed in the previous literature to either E-Commerce
or machine learning audiences. In practice, DNN-MAB has been deployed to
production and it easily outperforms against other state-of-the-art models by
significantly lifting the gross merchandise volume (GMV) which is the objective
metrics at JD.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, accepted by 'IJCAI-17 Workshop AI Applications in
  E-Commerce'</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03994</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Sets: Word Embeddings Learned from Tweets and General Data</dc:title>
 <dc:creator>Li, Quanzhi</dc:creator>
 <dc:creator>Shah, Sameena</dc:creator>
 <dc:creator>Liu, Xiaomo</dc:creator>
 <dc:creator>Nourbakhsh, Armineh</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  A word embedding is a low-dimensional, dense and real- valued vector
representation of a word. Word embeddings have been used in many NLP tasks.
They are usually gener- ated from a large text corpus. The embedding of a word
cap- tures both its syntactic and semantic aspects. Tweets are short, noisy and
have unique lexical and semantic features that are different from other types
of text. Therefore, it is necessary to have word embeddings learned
specifically from tweets. In this paper, we present ten word embedding data
sets. In addition to the data sets learned from just tweet data, we also built
embedding sets from the general data and the combination of tweets with the
general data. The general data consist of news articles, Wikipedia data and
other web data. These ten embedding models were learned from about 400 million
tweets and 7 billion words from the general text. In this paper, we also
present two experiments demonstrating how to use the data sets in some NLP
tasks, such as tweet sentiment analysis and tweet topic classification tasks.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03995</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sentiment Analysis by Joint Learning of Word Embeddings and Classifier</dc:title>
 <dc:creator>Sarma, Prathusha Kameswara</dc:creator>
 <dc:creator>Sethares, Bill</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Word embeddings are representations of individual words of a text document in
a vector space and they are often use- ful for performing natural language pro-
cessing tasks. Current state of the art al- gorithms for learning word
embeddings learn vector representations from large corpora of text documents in
an unsu- pervised fashion. This paper introduces SWESA (Supervised Word
Embeddings for Sentiment Analysis), an algorithm for sentiment analysis via
word embeddings. SWESA leverages document label infor- mation to learn vector
representations of words from a modest corpus of text doc- uments by solving an
optimization prob- lem that minimizes a cost function with respect to both word
embeddings as well as classification accuracy. Analysis re- veals that SWESA
provides an efficient way of estimating the dimension of the word embeddings
that are to be learned. Experiments on several real world data sets show that
SWESA has superior per- formance when compared to previously suggested
approaches to word embeddings and sentiment analysis tasks.
</dc:description>
 <dc:description>Comment: 10 pages. Under submission</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.03999</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ZOO: Zeroth Order Optimization based Black-box Attacks to Deep Neural
  Networks without Training Substitute Models</dc:title>
 <dc:creator>Chen, Pin-Yu</dc:creator>
 <dc:creator>Zhang, Huan</dc:creator>
 <dc:creator>Sharma, Yash</dc:creator>
 <dc:creator>Yi, Jinfeng</dc:creator>
 <dc:creator>Hsieh, Cho-Jui</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks (DNNs) are one of the most prominent technologies of our
time, as they achieve state-of-the-art performance in many machine learning
tasks, including but not limited to image classification, text mining, and
speech processing. However, recent research on DNNs has indicated
ever-increasing concern on the robustness to adversarial examples, especially
for security-critical tasks such as traffic sign identification for autonomous
driving. Studies have unveiled the vulnerability of a well-trained DNN by
demonstrating the ability of generating barely noticeable (to both human and
machines) adversarial images that lead to misclassification. Furthermore,
researchers have shown that these adversarial images are highly transferable by
simply training and attacking a substitute model built upon the target model,
known as a black-box attack to DNNs.
  Similar to the setting of training substitute models, in this paper we
propose an effective black-box attack that also only has access to the input
(images) and the output (confidence scores) of a targeted DNN. However,
different from leveraging attack transferability from substitute models, we
propose zeroth order optimization (ZOO) based attacks to directly estimate the
gradients of the targeted DNN for generating adversarial examples. We use
zeroth order stochastic coordinate descent along with dimension reduction,
hierarchical attack and importance sampling techniques to efficiently attack
black-box models. By exploiting zeroth order optimization, improved attacks to
the targeted DNN can be accomplished, sparing the need for training substitute
models and avoiding the loss in attack transferability. Experimental results on
MNIST, CIFAR10 and ImageNet show that the proposed ZOO attack is as effective
as the state-of-the-art white-box attack and significantly outperforms existing
black-box attacks via substitute models.
</dc:description>
 <dc:description>Comment: Accepted by 10th ACM Workshop on Artificial Intelligence and Security
  (AISEC) with the 24th ACM Conference on Computer and Communications Security
  (CCS)</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.03999</dc:identifier>
 <dc:identifier>doi:10.1145/3128572.3140448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04001</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group-driven Reinforcement Learning for Personalized mHealth
  Intervention</dc:title>
 <dc:creator>Zhu, Feiyun</dc:creator>
 <dc:creator>Guo, Jun</dc:creator>
 <dc:creator>Xu, Zheng</dc:creator>
 <dc:creator>Liao, Peng</dc:creator>
 <dc:creator>Huang, Junzhou</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Due to the popularity of smartphones and wearable devices nowadays, mobile
health (mHealth) technologies are promising to bring positive and wide impacts
on people's health. State-of-the-art decision-making methods for mHealth rely
on some ideal assumptions. Those methods either assume that the users are
completely homogenous or completely heterogeneous. However, in reality, a user
might be similar with some, but not all, users. In this paper, we propose a
novel group-driven reinforcement learning method for the mHealth. We aim to
understand how to share information among similar users to better convert the
limited user information into sharper learned RL policies. Specifically, we
employ the K-means clustering method to group users based on their trajectory
information similarity and learn a shared RL policy for each group. Extensive
experiment results have shown that our method can achieve clear gains over the
state-of-the-art RL methods for mHealth.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04004</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Thermodynamics and computation during collective motion near criticality</dc:title>
 <dc:creator>Crosato, Emanuele</dc:creator>
 <dc:creator>Spinney, Richard E.</dc:creator>
 <dc:creator>Nigmatullin, Ramil</dc:creator>
 <dc:creator>Lizier, Joseph T.</dc:creator>
 <dc:creator>Prokopenko, Mikhail</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study self-organisation of collective motion as a thermodynamic
phenomenon, in the context of the first law of thermodynamics. It is expected
that the coherent ordered motion typically self-organises in the presence of
changes in the (generalised) internal energy and of (generalised) work done on,
or extracted from, the system. We aim to explicitly quantify changes in these
two quantities in a system of simulated self-propelled particles, and contrast
them with changes in the system's configuration entropy. In doing so, we adapt
a thermodynamic formulation of the curvatures of the internal energy and the
work, with respect to two parameters that control the particles' alignment.
This allows us to systematically investigate the behaviour of the system by
varying the two control parameters to drive the system across a kinetic phase
transition. Our results identify critical regimes and show that during the
phase transition, where the configuration entropy of the system decreases, the
rates of change of the work and of the internal energy also decrease, while
their curvatures diverge. Importantly, the reduction of entropy achieved
through expenditure of work is shown to peak at criticality. We relate this
both to a thermodynamic efficiency and the significance of the increased order
with respect to a computational path. Additionally, this study provides an
information-geometric interpretation of the curvature of the internal energy as
the difference between two curvatures: the curvature of the free entropy,
captured by the Fisher information, and the curvature of the configuration
entropy.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04004</dc:identifier>
 <dc:identifier>Phys. Rev. E 97, 012120 (2018)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.97.012120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04006</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast, Accurate Thin-Structure Obstacle Detection for Autonomous Mobile
  Robots</dc:title>
 <dc:creator>Zhou, Chen</dc:creator>
 <dc:creator>Yang, Jiaolong</dc:creator>
 <dc:creator>Zhao, Chunshui</dc:creator>
 <dc:creator>Hua, Gang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Safety is paramount for mobile robotic platforms such as self-driving cars
and unmanned aerial vehicles. This work is devoted to a task that is
indispensable for safety yet was largely overlooked in the past -- detecting
obstacles that are of very thin structures, such as wires, cables and tree
branches. This is a challenging problem, as thin objects can be problematic for
active sensors such as lidar and sonar and even for stereo cameras. In this
work, we propose to use video sequences for thin obstacle detection. We
represent obstacles with edges in the video frames, and reconstruct them in 3D
using efficient edge-based visual odometry techniques. We provide both a
monocular camera solution and a stereo camera solution. The former incorporates
Inertial Measurement Unit (IMU) data to solve scale ambiguity, while the latter
enjoys a novel, purely vision-based solution. Experiments demonstrated that the
proposed methods are fast and able to detect thin obstacles robustly and
accurately under various conditions.
</dc:description>
 <dc:description>Comment: Appeared at IEEE CVPR 2017 Workshop on Embedded Vision</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04013</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pilot Contamination for Wideband Massive MMO: Number of cells Vs
  Multipath</dc:title>
 <dc:creator>Bogale, Tadilo Endeshaw</dc:creator>
 <dc:creator>Le, Long Bao</dc:creator>
 <dc:creator>Wang, Xianbin</dc:creator>
 <dc:creator>Vandendorpe, Luc</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper proposes a novel joint channel estimation and beamforming approach
for multicell wideband massive multiple input multiple output (MIMO) systems.
With the proposed channel estimation and beamforming approach, we determine the
number of cells $N_c$ that can utilize the same time and frequency resource
while mitigating the effect of pilot contamination. The proposed approach
exploits the multipath characteristics of wideband channels. Specifically, when
the channel has a maximum of $L$ multipath taps, \textcolor{red}{it is shown
that $N_c\leq L$ cells can estimate the channels of their user equipments (UEs)
and perform beamforming while mitigating the effect of pilot contamination.} In
a typical long term evolution (LTE) channel environment having delay spread
$T_d=4.69\mu$ second and channel bandwidth $B=2.5$MHz, we have found that
$L=18$ cells can use this band. In practice, $T_d$ is constant for a particular
environment and carrier frequency, and hence $L$ increases as the bandwidth
increases. All the analytical expressions have been validated, and the
superiority of the proposed design over the existing ones is demonstrated using
extensive numerical simulations both for correlated and uncorrelated channels.
The proposed channel estimation and beamforming design is linear and simple to
implement.
</dc:description>
 <dc:description>Comment: IEEE</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04014</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Style2Vec: Representation Learning for Fashion Items from Style Sets</dc:title>
 <dc:creator>Lee, Hanbit</dc:creator>
 <dc:creator>Seol, Jinseok</dc:creator>
 <dc:creator>Lee, Sang-goo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the rapid growth of online fashion market, demand for effective fashion
recommendation systems has never been greater. In fashion recommendation, the
ability to find items that goes well with a few other items based on style is
more important than picking a single item based on the user's entire purchase
history. Since the same user may have purchased dress suits in one month and
casual denims in another, it is impossible to learn the latent style features
of those items using only the user ratings. If we were able to represent the
style features of fashion items in a reasonable way, we will be able to
recommend new items that conform to some small subset of pre-purchased items
that make up a coherent style set. We propose Style2Vec, a vector
representation model for fashion items. Based on the intuition of
distributional semantics used in word embeddings, Style2Vec learns the
representation of a fashion item using other items in matching outfits as
context. Two different convolutional neural networks are trained to maximize
the probability of item co-occurrences. For evaluation, a fashion analogy test
is conducted to show that the resulting representation connotes diverse fashion
related semantics like shapes, colors, patterns and even latent styles. We also
perform style classification using Style2Vec features and show that our method
outperforms other baselines.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04021</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The basic principles and the structure and algorithmically software of
  computing by hypercomplex number</dc:title>
 <dc:creator>Kalinovsky, Ya.</dc:creator>
 <dc:creator>Boyarinova, Yu.</dc:creator>
 <dc:creator>Sukalo, A.</dc:creator>
 <dc:creator>Hitsko, Ya.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In article the basic principles put in a basis of algorithmicallysoftware of
hypercomplex number calculations, structure of a software, structure of
functional subsystems are considered. The most important procedures included in
subsystems are considered, program listings and examples of their application
are given.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04027</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security for 4G and 5G Cellular Networks: A Survey of Existing
  Authentication and Privacy-preserving Schemes</dc:title>
 <dc:creator>Ferrag, Mohamed Amine</dc:creator>
 <dc:creator>Maglaras, Leandros</dc:creator>
 <dc:creator>Argyriou, Antonios</dc:creator>
 <dc:creator>Kosmanos, Dimitrios</dc:creator>
 <dc:creator>Janicke, Helge</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper presents a comprehensive survey of existing authentication and
privacy-preserving schemes for 4G and 5G cellular networks. We start by
providing an overview of existing surveys that deal with 4G and 5G
communications, applications, standardization, and security. Then, we give a
classification of threat models in 4G and 5G cellular networks in four
categories, including, attacks against privacy, attacks against integrity,
attacks against availability, and attacks against authentication. We also
provide a classification of countermeasures into three types of categories,
including, cryptography methods, humans factors, and intrusion detection
methods. The countermeasures and informal and formal security analysis
techniques used by the authentication and privacy preserving schemes are
summarized in form of tables. Based on the categorization of the authentication
and privacy models, we classify these schemes in seven types, including,
handover authentication with privacy, mutual authentication with privacy, RFID
authentication with privacy, deniable authentication with privacy,
authentication with mutual anonymity, authentication and key agreement with
privacy, and three-factor authentication with privacy. In addition, we provide
a taxonomy and comparison of authentication and privacy-preserving schemes for
4G and 5G cellular networks in form of tables. Based on the current survey,
several recommendations for further research are discussed at the end of this
paper.
</dc:description>
 <dc:description>Comment: 24 pages, 14 figures</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04028</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counterexample Guided Inductive Optimization Applied to Mobile Robots
  Path Planning (Extended Version)</dc:title>
 <dc:creator>Ara&#xfa;jo, Rodrigo F.</dc:creator>
 <dc:creator>Ribeiro, Alexandre</dc:creator>
 <dc:creator>Bessa, Iury V.</dc:creator>
 <dc:creator>Cordeiro, Lucas C.</dc:creator>
 <dc:creator>Filho, Jo&#xe3;o E. C.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We describe and evaluate a novel optimization-based off-line path planning
algorithm for mobile robots based on the Counterexample-Guided Inductive
Optimization (CEGIO) technique. CEGIO iteratively employs counterexamples
generated from Boolean Satisfiability (SAT) and Satisfiability Modulo Theories
(SMT) solvers, in order to guide the optimization process and to ensure global
optimization. This paper marks the first application of CEGIO for planning
mobile robot path. In particular, CEGIO has been successfully applied to obtain
optimal two-dimensional paths for autonomous mobile robots using off-the-shelf
SAT and SMT solvers.
</dc:description>
 <dc:description>Comment: 7 pages, 14rd Latin American Robotics Symposium (LARS'2017)</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04030</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Link Classification and Tie Strength Ranking in Online Social Networks
  with Exogenous Interaction Networks</dc:title>
 <dc:creator>Abufouda, Mohammed</dc:creator>
 <dc:creator>Zweig, Katharina A.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Online social networks (OSNs) have become the main medium for connecting
people, sharing knowledge and information, and for communication. The social
connections between people using these OSNs are formed as virtual links (e.g.,
friendship and following connections) that connect people. These links are the
heart of today's OSNs as they facilitate all of the activities that the members
of a social network can do. However, many of these networks suffer from noisy
links, i.e., links that do not reflect a real relationship or links that have a
low intensity, that change the structure of the network and prevent accurate
analysis of these networks. Hence, a process for assessing and ranking the
links in a social network is crucial in order to sustain a healthy and real
network. Here, we define link assessment as the process of identifying noisy
and non-noisy links in a network. In this paper, we address the problem of link
assessment and link ranking in social networks using external interaction
networks. In addition to a friendship social network, additional exogenous
interaction networks are utilized to make the assessment process more
meaningful. We employed machine learning classifiers for assessing and ranking
the links in the social network of interest using the data from exogenous
interaction networks. The method was tested with two different datasets, each
containing the social network of interest, with the ground truth, along with
the exogenous interaction networks. The results show that it is possible to
effectively assess the links of a social network using only the structure of a
single network of the exogenous interaction networks, and also using the
structure of the whole set of exogenous interaction networks. The experiments
showed that some classifiers do better than others regarding both link
classification and link ranking.
</dc:description>
 <dc:description>Comment: preprint for the MSMMUSE post-proceedings</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04033</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reinforcement Learning for High Precision Assembly Tasks</dc:title>
 <dc:creator>Inoue, Tadanobu</dc:creator>
 <dc:creator>De Magistris, Giovanni</dc:creator>
 <dc:creator>Munawar, Asim</dc:creator>
 <dc:creator>Yokoya, Tsuyoshi</dc:creator>
 <dc:creator>Tachibana, Ryuki</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  High precision assembly of mechanical parts requires accuracy exceeding the
robot precision. Conventional part mating methods used in the current
manufacturing requires tedious tuning of numerous parameters before deployment.
We show how the robot can successfully perform a tight clearance peg-in-hole
task through training a recurrent neural network with reinforcement learning.
In addition to saving the manual effort, the proposed technique also shows
robustness against position and angle errors for the peg-in-hole task. The
neural network learns to take the optimal action by observing the robot sensors
to estimate the system state. The advantages of our proposed method is
validated experimentally on a 7-axis articulated robot arm.
</dc:description>
 <dc:description>Comment: Conference: Accepted to IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS), Vancouver, Canada, September 24-28,
  2017. Video: https://youtu.be/b2pC78rBGH4</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04044</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved second-order evaluation complexity for unconstrained nonlinear
  optimization using high-order regularized models</dc:title>
 <dc:creator>Cartis, Coralia</dc:creator>
 <dc:creator>Gould, Nicholas I. M.</dc:creator>
 <dc:creator>Toint, Philippe L.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The unconstrained minimization of a sufficiently smooth objective function
$f(x)$ is considered, for which derivatives up to order $p$, $p\geq 2$, are
assumed to be available. An adaptive regularization algorithm is proposed that
uses Taylor models of the objective of order $p$ and that is guaranteed to find
a first- and second-order critical point in at most $O \left(\max\left(
\epsilon_1^{-\frac{p+1}{p}}, \epsilon_2^{-\frac{p+1}{p-1}} \right) \right)$
function and derivatives evaluations, where $\epsilon_1$ and $\epsilon_2 &gt;0$
are prescribed first- and second-order optimality tolerances. Our approach
extends the method in Birgin et al. (2016) to finding second-order critical
points, and establishes the novel complexity bound for second-order criticality
under identical problem assumptions as for first-order, namely, that the $p$-th
derivative tensor is Lipschitz continuous and that $f(x)$ is bounded from
below. The evaluation-complexity bound for second-order criticality improves on
all such known existing results.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04051</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Secrecy with Nearly Collinear Main and Wiretap Channels via a
  Cooperative Jamming Relay</dc:title>
 <dc:creator>Han, Shuai</dc:creator>
 <dc:creator>Xu, Sai</dc:creator>
 <dc:creator>Meng, Weixiao</dc:creator>
 <dc:creator>Li, Cheng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In physical layer security (PHY-security), the frequently observed high
correlation between the main and wiretap channels can cause a significant loss
of secrecy. This paper investigates a slow fading scenario, where a transmitter
(Alice) sends a confidential message to a legitimate receiver (Bob) while a
passive eavesdropper (Eve) attempts to decode the message from its received
signal. It is assumed that Alice is equipped with multiple antennas while Bob
and Eve each have a single antenna (i.e., a MISOSE system). In a MISOSE system,
high correlation results in nearly collinear main and wiretap channel vectors,
which help Eve to see and intercept confidential information. Unfortunately,
the signal processing techniques at Alice, such as beamforming and artificial
noise (AN), are helpless, especially in the extreme case of completely
collinear main and wiretap channel vectors. On this background, we first
investigate the achievable secrecy outage probability via beamforming and AN at
Alice with the optimal power allocation between the information-bearing signal
and AN. Then, an ingenious model, in which a cooperative jamming relay (Relay)
is introduced, is proposed to effectively mitigate the adverse effects of high
correlation. Based on the proposed model, the power allocation between the
information-bearing signal at Alice and the AN at Relay is also studied to
maximize secrecy. Finally, to validate our proposed schemes, numerical
simulations are conducted, and the results show that a significant performance
gain with respect to secrecy is achieved.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04060</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-scale Community Detection in Temporal Networks Using Spectral
  Graph Wavelets</dc:title>
 <dc:creator>Kuncheva, Zhana</dc:creator>
 <dc:creator>Montana, Giovanni</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Spectral graph wavelets introduce a notion of scale in networks, and are thus
used to obtain a local view of the network from each node. By carefully
constructing a wavelet filter function for these wavelets, a multi-scale
community detection method for monoplex networks has already been developed.
This construction takes advantage of the partitioning properties of the network
Laplacian. In this paper we elaborate on a novel method which uses spectral
graph wavelets to detect multi-scale communities in temporal networks. To do
this we extend the definition of spectral graph wavelets to temporal networks
by adopting a multilayer framework. We use arguments from Perturbation Theory
to investigate the spectral properties of the supra-Laplacian matrix for
clustering purposes in temporal networks. Using these properties, we construct
a new wavelet filter function, which attenuates the influence of uninformative
eigenvalues and centres the filter around eigenvalues which contain information
on the coarsest description of prevalent community structures over time. We use
the spectral graph wavelets as feature vectors in a connectivity-constrained
clustering procedure to detect multi-scale communities at different scales, and
refer to this method as Temporal Multi-Scale Community Detection (TMSCD). We
validate the performance of TMSCD and a competing methodology on various
benchmarks. The advantage of TMSCD is the automated selection of relevant
scales at which communities should be sought.
</dc:description>
 <dc:description>Comment: 22 pages, 8 figures, Conference paper</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04069</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kinship Verification from Videos using Spatio-Temporal Texture Features
  and Deep Learning</dc:title>
 <dc:creator>Boutellaa, Elhocine</dc:creator>
 <dc:creator>L&#xf3;pez, Miguel Bordallo</dc:creator>
 <dc:creator>Ait-Aoudia, Samy</dc:creator>
 <dc:creator>Feng, Xiaoyi</dc:creator>
 <dc:creator>Hadid, Abdenour</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic kinship verification using facial images is a relatively new and
challenging research problem in computer vision. It consists in automatically
predicting whether two persons have a biological kin relation by examining
their facial attributes. While most of the existing works extract shallow
handcrafted features from still face images, we approach this problem from
spatio-temporal point of view and explore the use of both shallow texture
features and deep features for characterizing faces. Promising results,
especially those of deep features, are obtained on the benchmark UvA-NEMO Smile
database. Our extensive experiments also show the superiority of using videos
over still images, hence pointing out the important role of facial dynamics in
kinship verification. Furthermore, the fusion of the two types of features
(i.e. shallow spatio-temporal texture features and deep features) shows
significant performance improvements compared to state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04070</identifier>
 <datestamp>2017-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Timed Epistemic Knowledge Bases for Social Networks (Extended Version)</dc:title>
 <dc:creator>Pardo, Ra&#xfa;l</dc:creator>
 <dc:creator>S&#xe1;nchez, C&#xe9;sar</dc:creator>
 <dc:creator>Schneider, Gerardo</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We present an epistemic logic equipped with time-stamps in the atoms and
epistemic operators, which allows to reason not only about information
available to the different agents, but also about the moments at which events
happens and new knowledge is acquired or deduced. Our logic includes both an
epistemic operator and a belief operator, which allows to model the disclosure
of information that may not be accurate.
  Our main motivation is to model rich privacy policies in online social
networks. Online Social Networks (OSNs) are increasingly used for social
interactions in the modern digital era, which bring new challenges and concerns
in terms of privacy. Most social networks today offer very limited mechanisms
to express the desires of users in terms of how information that affects their
privacy is shared. In particular, most current privacy policy formalisms allow
only static policies, which are not rich enough to express timed properties
like &quot;my location after work should not be disclosed to my boss&quot;. The logic we
present in this paper enables to express rich properties and policies in terms
of the knowledge available to the different users and the precise time of
actions and deductions. Our framework can be instantiated for different OSNs,
by specifying the effect of the actions in the evolution of the social network
and in the knowledge disclosed to each agent.
  We present an algorithm for deducing knowledge, which can also be
instantiated with different variants of how the epistemic information is
preserved through time. Our algorithm allows to model not only social networks
with eternal information but also networks with ephemeral disclosures. Policies
are modelled as formulae in the logic, which are interpreted over timed traces
representing the evolution of the social network.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-09-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04071</identifier>
 <datestamp>2017-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Systematic Encoding of Non-binary VT Codes</dc:title>
 <dc:creator>Abroshan, Mahed</dc:creator>
 <dc:creator>Venkataramanan, Ramji</dc:creator>
 <dc:creator>Fabregas, Albert Guillen i</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Varshamov-Tenengolts (VT) codes are a class of codes which can correct a
single deletion or insertion with a linear-time decoder. This paper addresses
the problem of efficient encoding of non-binary VT codes, defined over an
alphabet of size $q &gt;2$. We propose a simple linear-time encoding method to
systematically map binary message sequences onto VT codewords. The method
provides a new lower bound on the size of $q$-ary VT codes of length $n$.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04073</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Metric Embedding via Shortest Path Decompositions</dc:title>
 <dc:creator>Abraham, Ittai</dc:creator>
 <dc:creator>Filtser, Arnold</dc:creator>
 <dc:creator>Gupta, Anupam</dc:creator>
 <dc:creator>Neiman, Ofer</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the problem of embedding weighted graphs of pathwidth $k$ into
$\ell_p$ spaces. Our main result is an
$O(k^{\min\{\nicefrac{1}{p},\nicefrac{1}{2}\}})$-distortion embedding. For
$p=1$, this is a super-exponential improvement over the best previous bound of
Lee and Sidiropoulos. Our distortion bound is asymptotically tight for any
fixed $p &gt;1$.
  Our result is obtained via a novel embedding technique that is based on low
depth decompositions of a graph via shortest paths. The core new idea is that
given a geodesic shortest path $P$, we can probabilistically embed all points
into 2 dimensions with respect to $P$. For $p&gt;2$ our embedding also implies
improved distortion on bounded treewidth graphs ($O((k\log
n)^{\nicefrac{1}{p}})$). For asymptotically large $p$, our results also implies
improved distortion on graphs excluding a minor.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04078</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>uStash: a Novel Mobile Content Delivery System for Improving User QoE in
  Public Transport</dc:title>
 <dc:creator>Jiang, Fang-Zhou</dc:creator>
 <dc:creator>Thilakarathna, Kanchana</dc:creator>
 <dc:creator>Mrabet, Sirine</dc:creator>
 <dc:creator>Kaafar, Mohamed Ali</dc:creator>
 <dc:creator>Seneviratne, Aruna</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Mobile data traffic is growing exponentially and it is even more challenging
to distribute content efficiently while users are &quot;on the move&quot; such as in
public transport.The use of mobile devices for accessing content (e.g. videos)
while commuting are both expensive and unreliable, although it is becoming
common practice worldwide. Leveraging on the spatial and temporal correlation
of content popularity and users' diverse network connectivity, we propose a
novel content distribution system, \textit{uStash}, which guarantees better QoE
with regards to access delays and cost of usage. The proposed collaborative
download and content stashing schemes provide the uStash provider the
flexibility to control the cost of content access via cellular networks. We
model the uStash system in a probabilistic framework and thereby analytically
derive the optimal portions for collaborative downloading. Then, we validate
the proposed models using real-life trace driven simulations. In particular, we
use dataset from 22 inter-city buses running on 6 different routes and from a
mobile VoD service provider to show that uStash reduces the cost of monthly
cellular data by approximately 50\% and the expected delay for content access
by 60\% compared to content downloaded via users' cellular network connections.
</dc:description>
 <dc:description>Comment: 14 Pages</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04081</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Routing Games in the Wild: Efficiency, Equilibration and Regret
  (Large-Scale Field Experiments in Singapore)</dc:title>
 <dc:creator>Monnot, Barnab&#xe9;</dc:creator>
 <dc:creator>Benita, Francisco</dc:creator>
 <dc:creator>Piliouras, Georgios</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Routing games are amongst the most well studied domains of game theory. How
relevant are these pen-and-paper calculations to understanding the reality of
everyday traffic routing? We focus on a semantically rich dataset that captures
detailed information about the daily behavior of thousands of Singaporean
commuters and examine the following basic questions: (i) Does the traffic
equilibrate? (ii) Is the system behavior consistent with latency minimizing
agents? (iii) Is the resulting system efficient? In order to capture the
efficiency of the traffic network in a way that agrees with our everyday
intuition we introduce a new metric, the stress of catastrophe, which reflects
the combined inefficiencies of both tragedy of the commons as well as price of
anarchy effects.
</dc:description>
 <dc:description>Comment: 22 pages, 9 figures, this article supersedes arXiv:1703.01599v2</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04089</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robustness in Chinese Remainder Theorem</dc:title>
 <dc:creator>Xiao, Hanshen</dc:creator>
 <dc:creator>Huang, Yufeng</dc:creator>
 <dc:creator>Ye, Yu</dc:creator>
 <dc:creator>Xiao, Guoqiang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A12, 94A15</dc:subject>
 <dc:description>  Chinese Remainder Theorem (CRT) has been widely studied with its applications
in frequency estimation, phase unwrapping, coding theory and distributed data
storage. Since traditional CRT is greatly sensitive to the errors in residues
due to noises, the problem of robustly reconstructing integers via the
erroneous residues has been intensively studied in the literature. In order to
robustly reconstruct integers, there are two kinds of traditional methods: the
one is to introduce common divisors in the moduli and the other is to directly
decrease the dynamic range. In this paper, we take further insight into the
geometry property of the linear space associated with CRT. Echoing both ways to
introduce redundancy, we propose a pseudo metric to analyze the trade-off
between the error bound and the dynamic range for robust CRT in general.
Furthermore, we present the first robust CRT for multiple numbers to solve the
problem of the CRT-based undersampling frequency estimation in general cases.
Based on symmetric polynomials, we proved that in most cases, the problem can
be solved in polynomial time efficiently. The work in this paper is towards a
complete theoretical solution to the open problem over 20 years.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04099</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-based Normalization of Histological Stains using Deep
  Convolutional Features</dc:title>
 <dc:creator>Bug, Daniel</dc:creator>
 <dc:creator>Schneider, Steffen</dc:creator>
 <dc:creator>Grote, Anne</dc:creator>
 <dc:creator>Oswald, Eva</dc:creator>
 <dc:creator>Feuerhake, Friedrich</dc:creator>
 <dc:creator>Sch&#xfc;ler, Julia</dc:creator>
 <dc:creator>Merhof, Dorit</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While human observers are able to cope with variations in color and
appearance of histological stains, digital pathology algorithms commonly
require a well-normalized setting to achieve peak performance, especially when
a limited amount of labeled data is available. This work provides a fully
automated, end-to-end learning-based setup for normalizing histological stains,
which considers the texture context of the tissue. We introduce Feature Aware
Normalization, which extends the framework of batch normalization in
combination with gating elements from Long Short-Term Memory units for
normalization among different spatial regions of interest. By incorporating a
pretrained deep neural network as a feature extractor steering a pixelwise
processing pipeline, we achieve excellent normalization results and ensure a
consistent representation of color and texture. The evaluation comprises a
comparison of color histogram deviations, structural similarity and measures
the color volume obtained by the different methods.
</dc:description>
 <dc:description>Comment: In: 3rd Workshop on Deep Learning in Medical Image Analysis (DLMIA
  2017)</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04100</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity of Probabilistic Justification Logic</dc:title>
 <dc:creator>Kokkinis, Ioannis</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Probabilistic justification logic is a modal logic with two kind of
modalities: probability measures and explicit justification terms. We present a
tableau procedure that can be used to decide the satisfiability problem for
this logic in polynomial space. We show that this upper complexity bound is
tight.
</dc:description>
 <dc:description>Comment: presented to the 11th Panhellenic Logic Symposium
  (http://pls11.cs.ntua.gr/)</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04106</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rocket Launching: A Universal and Efficient Framework for Training
  Well-performing Light Net</dc:title>
 <dc:creator>Zhou, Guorui</dc:creator>
 <dc:creator>Fan, Ying</dc:creator>
 <dc:creator>Cui, Runpeng</dc:creator>
 <dc:creator>Bian, Weijie</dc:creator>
 <dc:creator>Zhu, Xiaoqiang</dc:creator>
 <dc:creator>Gai, Kun</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Models applied on real time response task, like click-through rate (CTR)
prediction model, require high accuracy and rigorous response time. Therefore,
top-performing deep models of high depth and complexity are not well suited for
these applications with the limitations on the inference time. In order to
further improve the neural networks' performance given the time and
computational limitations, we propose an approach that exploits a cumbersome
net to help train the lightweight net for prediction. We dub the whole process
rocket launching, where the cumbersome booster net is used to guide the
learning of the target light net throughout the whole training process. We
analyze different loss functions aiming at pushing the light net to behave
similarly to the booster net, and adopt the loss with best performance in our
experiments. We use one technique called gradient block to improve the
performance of the light net and booster net further. Experiments on benchmark
datasets and real-life industrial advertisement data present that our light
model can get performance only previously achievable with more complex models.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04109</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving Hard Stable Matching Problems Involving Groups of Similar Agents</dc:title>
 <dc:creator>Meeks, Kitty</dc:creator>
 <dc:creator>Rastegari, Baharak</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Many important stable matching problems are known to be NP-hard, even when
strong restrictions are placed on the input. In this paper we seek to identify
simple structural properties of instances of stable matching problems which
will allow the design of efficient algorithms. We focus on the setting in which
all agents involved in some matching problem can be partitioned into k
different types, where the type of an agent determines his or her preferences,
and agents have preferences over types (which may be refined by more detailed
preferences within a single type). This situation could arise in practice if
agents form preferences based on some small collection of agents' attributes.
The notion of types could also be used if we are interested in a relaxation of
stability, in which agents will only form a private arrangement if it allows
them to be matched with a partner who differs from the current partner in some
particularly important characteristic. We show that in this setting several
well-studied NP-hard stable matching problems (such as MAX SMTI, MAX SRTI, and
MAX SIZE MIN BP SMTI) belong to the parameterised complexity class FPT when
parameterised by the number of different types of agents, and so admit
efficient algorithms when this number of types is small.
</dc:description>
 <dc:description>Comment: submitted to SODA'18</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04116</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Early Improving Recurrent Elastic Highway Network</dc:title>
 <dc:creator>Park, Hyunsin</dc:creator>
 <dc:creator>Yoo, Chang D.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  To model time-varying nonlinear temporal dynamics in sequential data, a
recurrent network capable of varying and adjusting the recurrence depth between
input intervals is examined. The recurrence depth is extended by several
intermediate hidden state units, and the weight parameters involved in
determining these units are dynamically calculated. The motivation behind the
paper lies on overcoming a deficiency in Recurrent Highway Networks and
improving their performances which are currently at the forefront of RNNs: 1)
Determining the appropriate number of recurrent depth in RHN for different
tasks is a huge burden and just setting it to a large number is computationally
wasteful with possible repercussion in terms of performance degradation and
high latency. Expanding on the idea of adaptive computation time (ACT), with
the use of an elastic gate in the form of a rectified exponentially decreasing
function taking on as arguments as previous hidden state and input, the
proposed model is able to evaluate the appropriate recurrent depth for each
input. The rectified gating function enables the most significant intermediate
hidden state updates to come early such that significant performance gain is
achieved early. 2) Updating the weights from that of previous intermediate
layer offers a richer representation than the use of shared weights across all
intermediate recurrence layers. The weight update procedure is just an
expansion of the idea underlying hypernetworks. To substantiate the
effectiveness of the proposed network, we conducted three experiments:
regression on synthetic data, human activity recognition, and language modeling
on the Penn Treebank dataset. The proposed networks showed better performance
than other state-of-the-art recurrent networks in all three experiments.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04120</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Putting Self-Supervised Token Embedding on the Tables</dc:title>
 <dc:creator>Szafraniec, Marc</dc:creator>
 <dc:creator>Marti, Gautier</dc:creator>
 <dc:creator>Donnat, Philippe</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Information distribution by electronic messages is a privileged means of
transmission for many businesses and individuals, often under the form of
plain-text tables. As their number grows, it becomes necessary to use an
algorithm to extract text and numbers instead of a human. Usual methods are
focused on regular expressions or on a strict structure in the data, but are
not efficient when we have many variations, fuzzy structure or implicit labels.
In this paper we introduce SC2T, a totally self-supervised model for
constructing vector representations of tokens in semi-structured messages by
using characters and context levels that address these issues. It can then be
used for an unsupervised labeling of tokens, or be the basis for a
semi-supervised information extraction system.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:date>2017-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04127</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A branch, price and remember algorithm for the U shaped assembly line
  balancing problem</dc:title>
 <dc:creator>Yolmeh, Abdolmajid</dc:creator>
 <dc:creator>Salehi, Najmeh</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper we propose a branch, price and remember algorithm to solve the
U shaped assembly line balancing problem. Our proposed algorithm uses a column
generation approach to obtain tight lower bounds for this problem. It also
stores generated columns in memory to enhance the speed of column generation
approach. We also develop a modification of Hoffman algorithm to obtain high
quality upper bounds. Our computational results show that our proposed
algorithm is able to optimally solve 255 of Scholl's well-known 269 benchmark
problems. Previous best known exact algorithm, ULINO, is able to solve 233 of
the 269 benchmark problems. We also examined our algorithm on a new data set
and the results show that our algorithm is able to solve 96.48 percent of all
available benchmark problems.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04127</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04133</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reproducibility of Benchmarked Deep Reinforcement Learning Tasks for
  Continuous Control</dc:title>
 <dc:creator>Islam, Riashat</dc:creator>
 <dc:creator>Henderson, Peter</dc:creator>
 <dc:creator>Gomrokchi, Maziar</dc:creator>
 <dc:creator>Precup, Doina</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Policy gradient methods in reinforcement learning have become increasingly
prevalent for state-of-the-art performance in continuous control tasks. Novel
methods typically benchmark against a few key algorithms such as deep
deterministic policy gradients and trust region policy optimization. As such,
it is important to present and use consistent baselines experiments. However,
this can be difficult due to general variance in the algorithms,
hyper-parameter tuning, and environment stochasticity. We investigate and
discuss: the significance of hyper-parameters in policy gradients for
continuous control, general variance in the algorithms, and reproducibility of
reported results. We provide guidelines on reporting novel results as
comparisons against baseline methods such that future researchers can make
informed decisions when investigating novel methods.
</dc:description>
 <dc:description>Comment: Accepted to Reproducibility in Machine Learning Workshop, ICML'17</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04134</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Measure for Dialog Complexity and its Application in Streamlining
  Service Operations</dc:title>
 <dc:creator>Liao, Q Vera</dc:creator>
 <dc:creator>Srivastava, Biplav</dc:creator>
 <dc:creator>Kapanipathi, Pavan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Dialog is a natural modality for interaction between customers and businesses
in the service industry. As customers call up the service provider, their
interactions may be routine or extraordinary. We believe that these
interactions, when seen as dialogs, can be analyzed to obtain a better
understanding of customer needs and how to efficiently address them. We
introduce the idea of a dialog complexity measure to characterize multi-party
interactions, propose a general data-driven method to calculate it, use it to
discover insights in public and enterprise dialog datasets, and demonstrate its
beneficial usage in facilitating better handling of customer requests and
evaluating service agents.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04138</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical simulation of oxidation processes in a cross-flow around tube
  bundles</dc:title>
 <dc:creator>Churbanov, Alexander G.</dc:creator>
 <dc:creator>Iliev, Oleg</dc:creator>
 <dc:creator>Strizhov, Valery F.</dc:creator>
 <dc:creator>Vabishchevich, Petr N.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  An oxidation process is simulated for a bundle of metal tubes in a
cross-flow. A fluid flow is governed by the incompressible Navier-Stokes
equations. To describe the transport of oxygen, the corresponding
convection-diffusion equation is applied. The key point of the model is related
to the description of oxidation processes taking into account the growth of a
thin oxide film in the quasi-stationary approximation. Mathematical modeling of
oxidant transport in a tube bundle is carried out in the 2D approximation. The
numerical algorithm employed in the work is based on the finite-element
discretization in space and the fully implicit discretization in time. The tube
rows of a bundle can be either in-line or staggered in the direction of the
fluid flow velocity. The growth of the oxide film on tube walls is predicted
for various bundle structures using the developed oxidation model.
</dc:description>
 <dc:description>Comment: 33 pages, 26 figures</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04139</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PhyShare: Sharing Physical Interaction in Virtual Reality</dc:title>
 <dc:creator>He, Zhenyi</dc:creator>
 <dc:creator>Zhu, Fengyuan</dc:creator>
 <dc:creator>Perlin, Ken</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We present PhyShare, a new haptic user interface based on actuated robots.
Virtual reality has recently been gaining wide adoption, and an effective
haptic feedback in these scenarios can strongly support user's sensory in
bridging virtual and physical world. Since participants do not directly observe
these robotic proxies, we investigate the multiple mappings between physical
robots and virtual proxies that can utilize the resources needed to provide a
well rounded VR experience. PhyShare bots can act either as directly touchable
objects or invisible carriers of physical objects, depending on different
scenarios. They also support distributed collaboration, allowing remotely
located VR collaborators to share the same physical feedback.
</dc:description>
 <dc:description>Comment: 7 pages. arXiv admin note: text overlap with arXiv:1701.08879</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04146</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Semantic Fast-Forward and Stabilized Egocentric Videos</dc:title>
 <dc:creator>Silva, Michel Melo</dc:creator>
 <dc:creator>Ramos, Washington Luis Souza</dc:creator>
 <dc:creator>Ferreira, Joao Pedro Klock</dc:creator>
 <dc:creator>Campos, Mario Fernando Montenegro</dc:creator>
 <dc:creator>Nascimento, Erickson Rangel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The emergence of low-cost personal mobiles devices and wearable cameras and
the increasing storage capacity of video-sharing websites have pushed forward a
growing interest towards first-person videos. Since most of the recorded videos
compose long-running streams with unedited content, they are tedious and
unpleasant to watch. The fast-forward state-of-the-art methods are facing
challenges of balancing the smoothness of the video and the emphasis in the
relevant frames given a speed-up rate. In this work, we present a methodology
capable of summarizing and stabilizing egocentric videos by extracting the
semantic information from the frames. This paper also describes a dataset
collection with several semantically labeled videos and introduces a new
smoothness evaluation metric for egocentric videos that is used to test our
method.
</dc:description>
 <dc:description>Comment: Accepted for publication and presented in the First International
  Workshop on Egocentric Perception, Interaction and Computing at European
  Conference on Computer Vision (EPIC@ECCV) 2016</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04146</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-46604-0_40</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04150</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Generative Adversarial Networks for Image Retrieval</dc:title>
 <dc:creator>Song, Jingkuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The most striking successes in image retrieval using deep hashing have mostly
involved discriminative models, which require labels. In this paper, we use
binary generative adversarial networks (BGAN) to embed images to binary codes
in an unsupervised way. By restricting the input noise variable of generative
adversarial networks (GAN) to be binary and conditioned on the features of each
input image, BGAN can simultaneously learn a binary representation per image,
and generate an image plausibly similar to the original one. In the proposed
framework, we address two main problems: 1) how to directly generate binary
codes without relaxation? 2) how to equip the binary representation with the
ability of accurate image retrieval? We resolve these problems by proposing new
sign-activation strategy and a loss function steering the learning process,
which consists of new models for adversarial loss, a content loss, and a
neighborhood structure loss. Experimental results on standard datasets
(CIFAR-10, NUSWIDE, and Flickr) demonstrate that our BGAN significantly
outperforms existing hashing methods by up to 107\% in terms of~mAP (See Table
tab.res.map.comp) Our anonymous code is available at:
https://github.com/htconquer/BGAN.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1702.00758 by other authors</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04157</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A global scavenging and circulation ocean model of thorium-230 and
  protactinium-231 with realistic particle dynamics (NEMO-ProThorP 0.1)</dc:title>
 <dc:creator>van Hulten, Marco</dc:creator>
 <dc:creator>Dutay, Jean-Claude</dc:creator>
 <dc:creator>Roy-Barman, Matthieu</dc:creator>
 <dc:subject>Physics - Atmospheric and Oceanic Physics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  In this paper, we set forth a 3-D ocean model of the radioactive trace
isotopes Th-230 and Pa-231. The interest arises from the fact that these
isotopes are extensively used for investigating particle transport in the ocean
and reconstructing past ocean circulation. The tracers are reversibly scavenged
by biogenic and lithogenic particles.
  Our simulations of Th-230 and Pa-231 are based on the NEMO-PISCES ocean
biogeochemistry general circulation model, which includes biogenic particles,
namely small and big particulate organic carbon, calcium carbonate and biogenic
silica. Small and big lithogenic particles from dust deposition are included in
our model as well. Their distributions generally compare well with the small
and big lithogenic particle concentrations from recent observations from the
GEOTRACES programme, except for boundary nepheloid layers for which, as up to
today, there are no non-trivial, prognostic models available on a global scale.
Our simulations reproduce Th-230 and Pa-231 dissolved concentrations: they
compare well with recent GEOTRACES observations in many parts of the ocean.
Particulate Th-230 and Pa-231 concentrations are significantly improved
compared to previous studies, but they are still too low because of missing
particles from nepheloid layers. Our simulation reproduces the main
characteristics of the Pa-231/Th-230 ratio observed in the sediments, and
supports a moderate affinity of Pa-231 to biogenic silica as suggested by
recent observations, relative to Th-230.
  Future model development may further improve understanding, especially when
this will include a more complete representation of all particles, including
different size classes, manganese hydroxides and nepheloid layers. This can be
done based on our model, as its source code is readily available.
</dc:description>
 <dc:description>Comment: submitted to Geoscientific Model Development</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04157</dc:identifier>
 <dc:identifier>doi:10.5194/gmd-2017-274</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04160</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast-Forward Video Based on Semantic Extraction</dc:title>
 <dc:creator>Ramos, Washington Luis Souza</dc:creator>
 <dc:creator>Silva, Michel Melo</dc:creator>
 <dc:creator>Campos, Mario Fernando Montenegro</dc:creator>
 <dc:creator>Nascimento, Erickson Rangel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Thanks to the low operational cost and large storage capacity of smartphones
and wearable devices, people are recording many hours of daily activities,
sport actions and home videos. These videos, also known as egocentric videos,
are generally long-running streams with unedited content, which make them
boring and visually unpalatable, bringing up the challenge to make egocentric
videos more appealing. In this work we propose a novel methodology to compose
the new fast-forward video by selecting frames based on semantic information
extracted from images. The experiments show that our approach outperforms the
state-of-the-art as far as semantic information is concerned and that it is
also able to produce videos that are more pleasant to be watched.
</dc:description>
 <dc:description>Comment: Accepted for publication and presented in 2016 IEEE International
  Conference on Image Processing (ICIP)</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04160</dc:identifier>
 <dc:identifier>doi:10.1109/ICIP.2016.7532977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04164</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence Modelling For Analysing Student Interaction with Educational
  Systems</dc:title>
 <dc:creator>Hansen, Christian</dc:creator>
 <dc:creator>Hansen, Casper</dc:creator>
 <dc:creator>Hjuler, Niklas</dc:creator>
 <dc:creator>Alstrup, Stephen</dc:creator>
 <dc:creator>Lioma, Christina</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The analysis of log data generated by online educational systems is an
important task for improving the systems, and furthering our knowledge of how
students learn. This paper uses previously unseen log data from Edulab, the
largest provider of digital learning for mathematics in Denmark, to analyse the
sessions of its users, where 1.08 million student sessions are extracted from a
subset of their data. We propose to model students as a distribution of
different underlying student behaviours, where the sequence of actions from
each session belongs to an underlying student behaviour. We model student
behaviour as Markov chains, such that a student is modelled as a distribution
of Markov chains, which are estimated using a modified k-means clustering
algorithm. The resulting Markov chains are readily interpretable, and in a
qualitative analysis around 125,000 student sessions are identified as
exhibiting unproductive student behaviour. Based on our results this student
representation is promising, especially for educational systems offering many
different learning usages, and offers an alternative to common approaches like
modelling student behaviour as a single Markov chain often done in the
literature.
</dc:description>
 <dc:description>Comment: The 10th International Conference on Educational Data Mining 2017</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04167</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strange Attractor for Efficient Polar Code Design</dc:title>
 <dc:creator>Kahraman, Sinan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents a definition of a construction for long polar codes.
Recently, we know that partial order is a universal property of the
construction with a sublinear complexity for polar codes. In order to describe
the partial order, addition and left-swap operators are only defined as
universal up to now. In this study, we first propose $1+\log_2 \log_2 N$
universal operators to describe multiple partial order for the block length
$N=2^n$. By using these operators, some known antichains can be universally
ordered.
  Furthermore, by using a simple geometric property of Gaussian approximation,
we define an attractor that is a pre-defined subset of synthetic channels. They
are universally less reliable than the natural channel $W$. Then, we show that
the cardinality of this attractor is $(n+2)$-th Fibonacci number which is a
significantly large number of channels for long codes. The main contribution is
that there are significant number of synthetic channels explicitly defined as
almost useless by the help of attractor and multiple partial order. As a
result, proposed attractor with multiple partial order can be seen as an
efficient tool to investigate and design extremely long codes.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04169</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Divide and Fuse: A Re-ranking Approach for Person Re-identification</dc:title>
 <dc:creator>Yu, Rui</dc:creator>
 <dc:creator>Zhou, Zhichao</dc:creator>
 <dc:creator>Bai, Song</dc:creator>
 <dc:creator>Bai, Xiang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As re-ranking is a necessary procedure to boost person re-identification
(re-ID) performance on large-scale datasets, the diversity of feature becomes
crucial to person reID for its importance both on designing pedestrian
descriptions and re-ranking based on feature fusion. However, in many
circumstances, only one type of pedestrian feature is available. In this paper,
we propose a &quot;Divide and use&quot; re-ranking framework for person re-ID. It
exploits the diversity from different parts of a high-dimensional feature
vector for fusion-based re-ranking, while no other features are accessible.
Specifically, given an image, the extracted feature is divided into
sub-features. Then the contextual information of each sub-feature is
iteratively encoded into a new feature. Finally, the new features from the same
image are fused into one vector for re-ranking. Experimental results on two
person re-ID benchmarks demonstrate the effectiveness of the proposed
framework. Especially, our method outperforms the state-of-the-art on the
Market-1501 dataset.
</dc:description>
 <dc:description>Comment: Accepted by BMVC2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04173</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Markov Processes for Transport in Porous Media: Random Lattice
  Networks</dc:title>
 <dc:creator>Delgoshaie, Amir H.</dc:creator>
 <dc:creator>Jenny, Patrick</dc:creator>
 <dc:creator>Tchelepi, Hamdi A.</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  Monte Carlo (MC) simulations of transport in random porous networks indicate
that for high variances of the log-normal permeability distribution, the
transport of a passive tracer is non-Fickian. Here we model this non-Fickian
dispersion in random porous networks using discrete temporal Markov models. We
show that such temporal models capture the spreading behavior accurately. This
is true despite the fact that the slow velocities are strongly correlated in
time, and some studies have suggested that the persistence of low velocities
would render the temporal Markovian model inapplicable. Compared to previously
proposed temporal stochastic differential equations with case specific drift
and diffusion terms, the models presented here require fewer modeling
assumptions. Moreover, we show that discrete temporal Markov models can be used
to represent dispersion in unstructured networks, which are widely used to
model porous media. A new method is proposed to extend the state space of
temporal Markov models to improve the model predictions in the presence of
extremely low velocities in particle trajectories and extend the applicability
of the model to higher temporal resolutions. Finally, it is shown that by
combining multiple transitions, temporal models are more efficient for
computing particle evolution compared to correlated CTRW with spatial
increments that are equal to the lengths of the links in the network.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04173</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04176</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>10 simple rules to create a serious game, illustrated with examples from
  structural biology</dc:title>
 <dc:creator>Baaden, Marc</dc:creator>
 <dc:creator>Delalande, Olivier</dc:creator>
 <dc:creator>Ferey, Nicolas</dc:creator>
 <dc:creator>Pasquali, Samuela</dc:creator>
 <dc:creator>Waldisp&#xfc;hl, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Taly, Antoine</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Serious scientific games are games whose purpose is not only fun. In the
field of science, the serious goals include crucial activities for scientists:
outreach, teaching and research. The number of serious games is increasing
rapidly, in particular citizen science games, games that allow people to
produce and/or analyze scientific data. Interestingly, it is possible to build
a set of rules providing a guideline to create or improve serious games. We
present arguments gathered from our own experience ( Phylo , DocMolecules ,
HiRE-RNA contest and Pangu) as well as examples from the growing literature on
scientific serious games.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04181</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor Robust Principal Component Analysis: Exact Recovery of Corrupted
  Low-Rank Tensors via Convex Optimization</dc:title>
 <dc:creator>Lu, Canyi</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Chen, Yudong</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:creator>Lin, Zhouchen</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper studies the Tensor Robust Principal Component (TRPCA) problem
which extends the known Robust PCA (Cand${\`e}$s et al. 2011) to the tensor
case. Our model is based on a new tensor Singular Value Decomposition (t-SVD)
(Kilmer and Martin 2011) and its induced tensor tubal rank and tensor nuclear
norm. Consider that we have a 3-way tensor
${\mathcal{X}}\in\mathbb{R}^{n_1\times n_2\times n_3}$ such that
${\mathcal{X}}={\mathcal{L}}_0+{\mathcal{E}}_0$, where ${\mathcal{L}}_0$ has
low tubal rank and ${\mathcal{E}}_0$ is sparse. Is that possible to recover
both components? In this work, we prove that under certain suitable
assumptions, we can recover both the low-rank and the sparse components exactly
by simply solving a convex program whose objective is a weighted combination of
the tensor nuclear norm and the $\ell_1$-norm, i.e.,\min_{{\mathcal{L}},\
{\mathcal{E}}} \ \|{{\mathcal{L}}}\|_*+\lambda\|{{\mathcal{E}}}\|_1, \
\text{s.t.} \ {\mathcal{X}}={\mathcal{L}}+{\mathcal{E}}, where $\lambda=
{1}/{\sqrt{\max(n_1,n_2)n_3}}$. Interestingly, TRPCA involves RPCA as a special
case when $n_3=1$ and thus it is a simple and elegant tensor extension of RPCA.
Also numerical experiments verify our theory and the application for the image
denoising demonstrates the effectiveness of our method.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Computer Vision and Pattern
  Recognition (CVPR, 2016)</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04185</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active vision for dexterous grasping of novel objects</dc:title>
 <dc:creator>Arruda, Ermano</dc:creator>
 <dc:creator>Wyatt, Jeremy</dc:creator>
 <dc:creator>Kopicki, Marek</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  How should a robot direct active vision so as to ensure reliable grasping? We
answer this question for the case of dexterous grasping of unfamiliar objects.
By dexterous grasping we simply mean grasping by any hand with more than two
fingers, such that the robot has some choice about where to place each finger.
Such grasps typically fail in one of two ways, either unmodeled objects in the
scene cause collisions or object reconstruction is insufficient to ensure that
the grasp points provide a stable force closure. These problems can be solved
more easily if active sensing is guided by the anticipated actions. Our
approach has three stages. First, we take a single view and generate candidate
grasps from the resulting partial object reconstruction. Second, we drive the
active vision approach to maximise surface reconstruction quality around the
planned contact points. During this phase, the anticipated grasp is continually
refined. Third, we direct gaze to improve the safety of the planned reach to
grasp trajectory. We show, on a dexterous manipulator with a camera on the
wrist, that our approach (80.4% success rate) outperforms a randomised
algorithm (64.3% success rate).
</dc:description>
 <dc:description>Comment: IROS 2016. Supplementary video: https://youtu.be/uBSOO6tMzwA</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04186</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boundaries can Enhance Physical Layer Security at High Data Rates</dc:title>
 <dc:creator>Koufos, Konstantinos</dc:creator>
 <dc:creator>Dettmann, Carl P.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we study the receiver performance with physical layer security
in a Poisson field of interferers. We compare the performance in two deployment
scenarios: (i) the receiver is located at the corner of a quadrant, (ii) the
receiver is located in the infinite plane. When the channel state information
(CSI) of the eavesdropper is not available at the transmitter, we calculate the
probability of secure connectivity using the Wyner coding scheme, and we show
that hiding the receiver at the corner is beneficial at high rates of the
transmitted codewords and detrimental at low transmission rates. When the CSI
is available, we show that the average secrecy capacity is higher when the
receiver is located at the corner, even if the intensity of interferers over
there is four times higher than the intensity of interferers in the bulk.
Therefore boundaries can also be used as a secrecy enhancement technique for
high data rate applications.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04196</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding and Visualizing the District of Columbia Capital Bikeshare
  System Using Data Analysis for Balancing Purposes</dc:title>
 <dc:creator>Zamir, Kiana Roshan</dc:creator>
 <dc:creator>Shafahi, Ali</dc:creator>
 <dc:creator>Haghani, Ali</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Bike sharing systems' popularity has consistently been rising during the past
years. Managing and maintaining these emerging systems are indispensable parts
of these systems. Visualizing the current operations can assist in getting a
better grasp on the performance of the system. In this paper, a data mining
approach is used to identify and visualize some important factors related to
bike-share operations and management. To consolidate the data, we cluster
stations that have a similar pickup and drop-off profiles during weekdays and
weekends. We provide the temporal profile of the center of each cluster which
can be used as a simple and practical approach for approximating the number of
pickups and drop-offs of the stations. We also define two indices based on
stations' shortages and surpluses that reflect the degree of balancing aid a
station needs. These indices can help stakeholders improve the quality of the
bike-share user experience in at-least two ways. It can act as a complement to
balancing optimization efforts, and it can identify stations that need
expansion. We mine the District of Columbia's regional bike-share data and
discuss the findings of this data set. We examine the bike-share system during
different quarters of the year and during both peak and non-peak hours.
Findings reflect that on weekdays most of the pickups and drop-offs happen
during the morning and evening peaks whereas on weekends pickups and drop-offs
are spread out throughout the day. We also show that throughout the day, more
than 40% of the stations are relatively self-balanced. Not worrying about these
stations during ordinary days can allow the balancing efforts to focus on a
fewer stations and therefore potentially improve the efficiency of the
balancing optimization models.
</dc:description>
 <dc:description>Comment: Submitted to TRB2018</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04198</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A scalable multi-core architecture with heterogeneous memory structures
  for Dynamic Neuromorphic Asynchronous Processors (DYNAPs)</dc:title>
 <dc:creator>Moradi, Saber</dc:creator>
 <dc:creator>Qiao, Ning</dc:creator>
 <dc:creator>Stefanini, Fabio</dc:creator>
 <dc:creator>Indiveri, Giacomo</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Neuromorphic computing systems comprise networks of neurons that use
asynchronous events for both computation and communication. This type of
representation offers several advantages in terms of bandwidth and power
consumption in neuromorphic electronic systems. However, managing the traffic
of asynchronous events in large scale systems is a daunting task, both in terms
of circuit complexity and memory requirements. Here we present a novel routing
methodology that employs both hierarchical and mesh routing strategies and
combines heterogeneous memory structures for minimizing both memory
requirements and latency, while maximizing programming flexibility to support a
wide range of event-based neural network architectures, through parameter
configuration. We validated the proposed scheme in a prototype multi-core
neuromorphic processor chip that employs hybrid analog/digital circuits for
emulating synapse and neuron dynamics together with asynchronous digital
circuits for managing the address-event traffic. We present a theoretical
analysis of the proposed connectivity scheme, describe the methods and circuits
used to implement such scheme, and characterize the prototype chip. Finally, we
demonstrate the use of the neuromorphic processor with a convolutional neural
network for the real-time classification of visual symbols being flashed to a
dynamic vision sensor (DVS) at high speed.
</dc:description>
 <dc:description>Comment: 17 pages, 14 figures</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04198</dc:identifier>
 <dc:identifier>doi:10.1109/TBCAS.2017.2759700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04201</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Submodularity-Based Approach for Multi-Agent Optimal Coverage Problems</dc:title>
 <dc:creator>Sun, Xinmiao</dc:creator>
 <dc:creator>Cassandras, Christos G.</dc:creator>
 <dc:creator>Meng, Xiangyu</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  We consider the optimal coverage problem where a multi-agent network is
deployed in an environment with obstacles to maximize a joint event detection
probability. The objective function of this problem is non-convex and no global
optimum is guaranteed by gradient-based algorithms developed to date. We first
show that the objective function is monotone submodular, a class of functions
for which a simple greedy algorithm is known to be within 0.63 of the optimal
solution. We then derive two tighter lower bounds by exploiting the curvature
information (total curvature and elemental curvature) of the objective
function. We further show that the tightness of these lower bounds is
complementary with respect to the sensing capabilities of the agents. The
greedy algorithm solution can be subsequently used as an initial point for a
gradient-based algorithm to obtain solutions even closer to the global optimum.
Simulation results show that this approach leads to significantly better
performance relative to previously used algorithms.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04202</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Plan Chemical Syntheses</dc:title>
 <dc:creator>Segler, Marwin H. S.</dc:creator>
 <dc:creator>Preuss, Mike</dc:creator>
 <dc:creator>Waller, Mark P.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:description>  From medicines to materials, small organic molecules are indispensable for
human well-being. To plan their syntheses, chemists employ a problem solving
technique called retrosynthesis. In retrosynthesis, target molecules are
recursively transformed into increasingly simpler precursor compounds until a
set of readily available starting materials is obtained. Computer-aided
retrosynthesis would be a highly valuable tool, however, past approaches were
slow and provided results of unsatisfactory quality. Here, we employ Monte
Carlo Tree Search (MCTS) to efficiently discover retrosynthetic routes. MCTS
was combined with an expansion policy network that guides the search, and an
&quot;in-scope&quot; filter network to pre-select the most promising retrosynthetic
steps. These deep neural networks were trained on 12 million reactions, which
represents essentially all reactions ever published in organic chemistry. Our
system solves almost twice as many molecules and is 30 times faster in
comparison to the traditional search method based on extracted rules and
hand-coded heuristics. Finally after a 60 year history of computer-aided
synthesis planning, chemists can no longer distinguish between routes generated
by a computer system and real routes taken from the scientific literature. We
anticipate that our method will accelerate drug and materials discovery by
assisting chemists to plan better syntheses faster, and by enabling fully
automated robot synthesis.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04203</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Separation of a Polyhedron from Its Single-Part Mold</dc:title>
 <dc:creator>Bose, Prosenjit</dc:creator>
 <dc:creator>Halperin, Dan</dc:creator>
 <dc:creator>Shamai, Shahar</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Casting is a manufacturing process where liquid material is poured into a
mold having the shape of a desired product. After the material solidifies, the
product is pulled out of the mold. We study the case in which the mold is made
of a single part and the object to be produced is a three-dimensional
polyhedron. Objects that can be produced this way are called castable with a
single-part mold. A direction in which the object can be removed without
breaking the mold is called a valid pull-out direction. We give an algorithm
that decides whether a given polyhedron with $n$ facets is castable with a
single-part mold, and if so indicates how to orient the polyhedron in the mold
and a direction in which the product can be pulled out without breaking the
mold. Our algorithm runs in $O(n)$ time. The best previously known algorithm
for this problem runs in $O(n^2) $ time.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04208</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Blind Motion Deblurring</dc:title>
 <dc:creator>Wieschollek, Patrick</dc:creator>
 <dc:creator>Hirsch, Michael</dc:creator>
 <dc:creator>Sch&#xf6;lkopf, Bernhard</dc:creator>
 <dc:creator>Lensch, Hendrik P. A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As handheld video cameras are now commonplace and available in every
smartphone, images and videos can be recorded almost everywhere at anytime.
However, taking a quick shot frequently yields a blurry result due to unwanted
camera shake during recording or moving objects in the scene. Removing these
artifacts from the blurry recordings is a highly ill-posed problem as neither
the sharp image nor the motion blur kernel is known. Propagating information
between multiple consecutive blurry observations can help restore the desired
sharp image or video. Solutions for blind deconvolution based on neural
networks rely on a massive amount of ground-truth data which is hard to
acquire. In this work, we propose an efficient approach to produce a
significant amount of realistic training data and introduce a novel recurrent
network architecture to deblur frames taking temporal information into account,
which can efficiently handle arbitrary spatial and temporal input sizes. We
demonstrate the versatility of our approach in a comprehensive comparison on a
number of challening real-world examples.
</dc:description>
 <dc:description>Comment: International Conference on Computer Vision (ICCV) (2017)</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04215</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Constant-Factor Approximation Algorithm for the Asymmetric Traveling
  Salesman Problem</dc:title>
 <dc:creator>Svensson, Ola</dc:creator>
 <dc:creator>Tarnawski, Jakub</dc:creator>
 <dc:creator>V&#xe9;gh, L&#xe1;szl&#xf3; A.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We give a constant-factor approximation algorithm for the asymmetric
traveling salesman problem. Our approximation guarantee is analyzed with
respect to the standard LP relaxation, and thus our result confirms the
conjectured constant integrality gap of that relaxation.
  Our techniques build upon the constant-factor approximation algorithm for the
special case of node-weighted metrics. Specifically, we give a generic
reduction to structured instances that resemble but are more general than those
arising from node-weighted metrics. For those instances, we then solve
Local-Connectivity ATSP, a problem known to be equivalent (in terms of
constant-factor approximation) to the asymmetric traveling salesman problem.
</dc:description>
 <dc:description>Comment: 42 pages, 8 figures</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04218</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Gap-ETH to FPT-Inapproximability: Clique, Dominating Set, and More</dc:title>
 <dc:creator>Chalermsook, Parinya</dc:creator>
 <dc:creator>Cygan, Marek</dc:creator>
 <dc:creator>Kortsarz, Guy</dc:creator>
 <dc:creator>Laekhanukit, Bundit</dc:creator>
 <dc:creator>Manurangsi, Pasin</dc:creator>
 <dc:creator>Nanongkai, Danupon</dc:creator>
 <dc:creator>Trevisan, Luca</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We consider questions that arise from the intersection between the areas of
polynomial-time approximation algorithms, subexponential-time algorithms, and
fixed-parameter tractable algorithms. The questions, which have been asked
several times (e.g., [Marx08, FGMS12, DF13]), are whether there is a
non-trivial FPT-approximation algorithm for the Maximum Clique (Clique) and
Minimum Dominating Set (DomSet) problems parameterized by the size of the
optimal solution. In particular, letting $\text{OPT}$ be the optimum and $N$ be
the size of the input, is there an algorithm that runs in
$t(\text{OPT})\text{poly}(N)$ time and outputs a solution of size
$f(\text{OPT})$, for any functions $t$ and $f$ that are independent of $N$ (for
Clique, we want $f(\text{OPT})=\omega(1)$)?
  In this paper, we show that both Clique and DomSet admit no non-trivial
FPT-approximation algorithm, i.e., there is no
$o(\text{OPT})$-FPT-approximation algorithm for Clique and no
$f(\text{OPT})$-FPT-approximation algorithm for DomSet, for any function $f$
(e.g., this holds even if $f$ is the Ackermann function). In fact, our results
imply something even stronger: The best way to solve Clique and DomSet, even
approximately, is to essentially enumerate all possibilities. Our results hold
under the Gap Exponential Time Hypothesis (Gap-ETH) [Dinur16, MR16], which
states that no $2^{o(n)}$-time algorithm can distinguish between a satisfiable
3SAT formula and one which is not even $(1 - \epsilon)$-satisfiable for some
constant $\epsilon &gt; 0$.
  Besides Clique and DomSet, we also rule out non-trivial FPT-approximation for
Maximum Balanced Biclique, Maximum Subgraphs with Hereditary Properties, and
Maximum Induced Matching in bipartite graphs. Additionally, we rule out
$k^{o(1)}$-FPT-approximation algorithm for Densest $k$-Subgraph although this
ratio does not yet match the trivial $O(k)$-approximation algorithm.
</dc:description>
 <dc:description>Comment: 43 pages. To appear in FOCS'17</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04225</identifier>
 <datestamp>2017-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Object-Centric Representations for Generalizable Robot Learning</dc:title>
 <dc:creator>Devin, Coline</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Robotic manipulation in complex open-world scenarios requires both reliable
physical manipulation skills and effective and generalizable perception. In
this paper, we propose a method where general purpose pretrained visual models
serve as an object-centric prior for the perception system of a learned policy.
We devise an object-level attentional mechanism that can be used to determine
relevant objects from a few trajectories or demonstrations, and then
immediately incorporate those objects into a learned policy. A task-independent
meta-attention locates possible objects in the scene, and a task-specific
attention identifies which objects are predictive of the trajectories. The
scope of the task-specific attention is easily adjusted by showing
demonstrations with distractor objects or with diverse relevant objects. Our
results indicate that this approach exhibits good generalization across object
instances using very few samples, and can be used to learn a variety of
manipulation tasks using reinforcement learning.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04228</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vanishing of Littlewood-Richardson polynomials is in P</dc:title>
 <dc:creator>Adve, Anshul</dc:creator>
 <dc:creator>Robichaux, Colleen</dc:creator>
 <dc:creator>Yong, Alexander</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Representation Theory</dc:subject>
 <dc:description>  J. DeLoera-T. McAllister and K. D. Mulmuley-H. Narayanan-M. Sohoni
independently proved that determining the vanishing of Littlewood-Richardson
coefficients has strongly polynomial time computational complexity. Viewing
these as Schubert calculus numbers, we prove the generalization to the
Littlewood-Richardson polynomials that control equivariant cohomology of
Grassmannians. We construct a polytope using the edge-labeled tableau rule of
H. Thomas-A. Yong. Our proof then combines a saturation theorem of D.
Anderson-E. Richmond-A. Yong, a reading order independence property, and E.
Tardos' algorithm for combinatorial linear programming.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04232</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encoding Multi-Resolution Brain Networks Using Unsupervised Deep
  Learning</dc:title>
 <dc:creator>Rahnama, Arash</dc:creator>
 <dc:creator>Alchihabi, Abdullah</dc:creator>
 <dc:creator>Gupta, Vijay</dc:creator>
 <dc:creator>Antsaklis, Panos</dc:creator>
 <dc:creator>Vural, Fatos T. Yarman</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  The main goal of this study is to extract a set of brain networks in multiple
time-resolutions to analyze the connectivity patterns among the anatomic
regions for a given cognitive task. We suggest a deep architecture which learns
the natural groupings of the connectivity patterns of human brain in multiple
time-resolutions. The suggested architecture is tested on task data set of
Human Connectome Project (HCP) where we extract multi-resolution networks, each
of which corresponds to a cognitive task. At the first level of this
architecture, we decompose the fMRI signal into multiple sub-bands using
wavelet decompositions. At the second level, for each sub-band, we estimate a
brain network extracted from short time windows of the fMRI signal. At the
third level, we feed the adjacency matrices of each mesh network at each
time-resolution into an unsupervised deep learning algorithm, namely, a Stacked
De- noising Auto-Encoder (SDAE). The outputs of the SDAE provide a compact
connectivity representation for each time window at each sub-band of the fMRI
signal. We concatenate the learned representations of all sub-bands at each
window and cluster them by a hierarchical algorithm to find the natural
groupings among the windows. We observe that each cluster represents a
cognitive task with a performance of 93% Rand Index and 71% Adjusted Rand
Index. We visualize the mean values and the precisions of the networks at each
component of the cluster mixture. The mean brain networks at cluster centers
show the variations among cognitive tasks and the precision of each cluster
shows the within cluster variability of networks, across the subjects.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, submitted to The 17th annual IEEE International
  Conference on BioInformatics and BioEngineering</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04233</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast, large-scale hologram calculation in wavelet domain</dc:title>
 <dc:creator>Shimobaba, Tomoyoshi</dc:creator>
 <dc:creator>Matsushima, Kyoji</dc:creator>
 <dc:creator>Takahashi, Takayuki</dc:creator>
 <dc:creator>Nagahama, Yuki</dc:creator>
 <dc:creator>Hasegawa, Satoki</dc:creator>
 <dc:creator>Sano, Marie</dc:creator>
 <dc:creator>Hirayama, Ryuji</dc:creator>
 <dc:creator>Kakue, Takashi</dc:creator>
 <dc:creator>Ito, Tomoyoshi</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  We propose a large-scale hologram calculation using WAvelet ShrinkAge-Based
superpositIon (WASABI), a wavelet transform-based algorithm. An image-type
hologram calculated using the WASABI method is printed on a glass substrate
with the resolution of $65,536 \times 65,536$ pixels and a pixel pitch of $1
\mu$m. The hologram calculation time amounts to approximately 354 s on a
commercial CPU, which is approximately 30 times faster than conventional
methods.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04233</dc:identifier>
 <dc:identifier>doi:10.1016/j.optcom.2017.11.066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04236</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Motion Planning under Partial Observability using Game-Based Abstraction</dc:title>
 <dc:creator>Winterer, Leonore</dc:creator>
 <dc:creator>Junges, Sebastian</dc:creator>
 <dc:creator>Wimmer, Ralf</dc:creator>
 <dc:creator>Jansen, Nils</dc:creator>
 <dc:creator>Topcu, Ufuk</dc:creator>
 <dc:creator>Katoen, Joost-Pieter</dc:creator>
 <dc:creator>Becker, Bernd</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We study motion planning problems where agents move inside environments that
are not fully observable and subject to uncertainties. The goal is to compute a
strategy for an agent that is guaranteed to satisfy certain safety and
performance specifications. Such problems are naturally modelled by partially
observable Markov decision processes (POMDPs). Because of the potentially huge
or even infinite belief space of POMDPs, verification and strategy synthesis is
in general computationally intractable. We tackle this difficulty by exploiting
typical structural properties of such scenarios; for instance, we assume that
agents have the ability to observe their own positions inside an environment.
Ambiguity in the state of the environment is abstracted into non-deterministic
choices over the possible states of the environment. Technically, this
abstraction transforms POMDPs into probabilistic two-player games (PGs). For
these PGs, efficient verification tools are able to determine strategies that
approximate certain measures on the POMDP. If an approximation is too coarse to
provide guarantees, an abstraction refinement scheme further resolves the
belief space of the POMDP. We demonstrate that our method improves the state of
the art by orders of magnitude compared to a direct solution of the POMDP.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04251</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A learning framework for winner-take-all networks with stochastic
  synapses</dc:title>
 <dc:creator>Mostafa, Hesham</dc:creator>
 <dc:creator>Cauwenberghs, Gert</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Many recent generative models make use of neural networks to transform the
probability distribution of a simple low-dimensional noise process into the
complex distribution of the data. This raises the question of whether
biological networks operate along similar principles to implement a
probabilistic model of the environment through transformations of intrinsic
noise processes. The intrinsic neural and synaptic noise processes in
biological networks, however, are quite different from the noise processes used
in current abstract generative networks. This, together with the discrete
nature of spikes and local circuit interactions among the neurons, raises
several difficulties when using recent generative modeling frameworks to train
biologically motivated models. In this paper, we show that a biologically
motivated model based on multi-layer winner-take-all (WTA) circuits and
stochastic synapses admits an approximate analytical description. This allows
us to use the proposed networks in a variational learning setting where
stochastic backpropagation is used to optimize a lower bound on the data log
likelihood, thereby learning a generative model of the data. We illustrate the
generality of the proposed networks and learning technique by using them in a
structured output prediction task, and in a semi-supervised learning task. Our
results extend the domain of application of modern stochastic network
architectures to networks where synaptic transmission failure is the principal
noise mechanism.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04257</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Bounds of Spectral Efficiency of Optimally Beamformed NLOS Millimeter
  Wave Links</dc:title>
 <dc:creator>RT, Rakesh</dc:creator>
 <dc:creator>Sen, Debarati</dc:creator>
 <dc:creator>Das, Goutam</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Beamforming is an indispensable feature for millimeter wave (mmWave) wireless
communications in order to compensate for the severe path loss incurred due to
high frequency operation. In this paper, we introduce a novel framework to
evaluate the spectral efficiency (SE) of non-line-of-sight(NLOS) mmWave links
with optimal analog beamforming. Optimality here implies the joint selection of
antenna beams at the transmitter and receiver which simultaneously maximize the
received power. We develop a mathematical framework based on the extended
Saleh-Valenzuela channel model to embody the impact of optimal analog
beamforming into the performance metrics for NLOS mmWave links. Practical
mmWave channels are characterized by sparsity in terms of number of multi-path
components; we exploit this feature to derive upper and lower bounds on SE of
beamformed directional links. Simulation results reveal that the proposed
approach is fairly accurate to model beamformed links in most practical
operating scenarios. We also study the impact of overhead due to antenna beam
training on the throughput (TP) of a link and obtain an approximate solution
for optimal antenna half power beamwidth which maximizes TP.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Transactions on Vehicular Technology</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04258</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Stochastic-Calculus Approach to Multi-Receiver Poisson Channels</dc:title>
 <dc:creator>Shende, Nirmal V.</dc:creator>
 <dc:creator>Wagner, Aaron B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study two-receiver Poisson channels using tools derived from stochastic
calculus. We obtain a general formula for the mutual information over the
Poisson channel that allows for conditioning and the use of auxiliary random
variables. We then use this formula to compute necessary and sufficient
conditions under which one Poisson channel is less noisy and/or more capable
than another, which turn out to be distinct from the conditions under which
this ordering holds for the discretized versions of the channels. We also use
general formula to determine the capacity region of the more capable Poisson
broadcast channel with independent message sets, the more capable Poisson
wiretap channel, and the general two-decoder Poisson broadcast channel with
degraded message sets.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04278</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling High Throughput Data for Anomaly Detection of Data-Base
  Activity</dc:title>
 <dc:creator>Grushka-Cohen, Hagit</dc:creator>
 <dc:creator>Sofer, Oded</dc:creator>
 <dc:creator>Biller, Ofer</dc:creator>
 <dc:creator>Dymshits, Michael</dc:creator>
 <dc:creator>Rokach, Lior</dc:creator>
 <dc:creator>Shapira, Bracha</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Data leakage and theft from databases is a dangerous threat to organizations.
Data Security and Data Privacy protection systems (DSDP) monitor data access
and usage to identify leakage or suspicious activities that should be
investigated. Because of the high velocity nature of database systems, such
systems audit only a portion of the vast number of transactions that take
place. Anomalies are investigated by a Security Officer (SO) in order to choose
the proper response. In this paper we investigate the effect of sampling
methods based on the risk the transaction poses and propose a new method for
&quot;combined sampling&quot; for capturing a more varied sample.
</dc:description>
 <dc:description>Comment: Proceedings of the 11th Pre-ICIS Workshop on Information Security and
  Privacy, Dublin, Ireland December 10, 2016</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04283</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantically-Secured Message-Key Trade-off over Wiretap Channels with
  Random Parameters</dc:title>
 <dc:creator>Bunin, Alexander</dc:creator>
 <dc:creator>Goldfeld, Ziv</dc:creator>
 <dc:creator>Permuter, Haim H.</dc:creator>
 <dc:creator>Shamai, Shlomo</dc:creator>
 <dc:creator>Cuff, Paul</dc:creator>
 <dc:creator>Piantanida, Pablo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the trade-off between secret message (SM) and secret key (SK) rates,
simultaneously achievable over a state-dependent (SD) wiretap channel (WTC)
with non-causal channel state information (CSI) at the encoder. This model
subsumes other instances of CSI availability as special cases, and calls for
efficient utilization of the state sequence for both reliability and security
purposes. An inner bound on the semantic-security (SS) SM-SK capacity region is
derived based on a superposition coding scheme inspired by a past work of the
authors. The region is shown to attain capacity for a certain class of SD-WTCs.
SS is established by virtue of two versions of the strong soft-covering lemma.
The derived region yields an improvement upon the previously best known SM-SK
trade-off result reported by Prabhakaran et al., and, to the best of our
knowledge, upon all other existing lower bounds for either SM or SK for this
setup, even if the semantic security requirement is relaxed to weak secrecy. It
is demonstrated that our region can be strictly larger than those reported in
the preceding works.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04290</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity of Distributed Edge Coloring with Small Palettes</dc:title>
 <dc:creator>Chang, Yi-Jun</dc:creator>
 <dc:creator>He, Qizheng</dc:creator>
 <dc:creator>Li, Wenzheng</dc:creator>
 <dc:creator>Pettie, Seth</dc:creator>
 <dc:creator>Uitto, Jara</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The complexity of distributed edge coloring depends heavily on the palette
size as a function of the maximum degree $\Delta$. In this paper we explore the
complexity of edge coloring in the LOCAL model in different palette size
regimes.
  1. We simplify the \emph{round elimination} technique of Brandt et al. and
prove that $(2\Delta-2)$-edge coloring requires $\Omega(\log_\Delta \log n)$
time w.h.p. and $\Omega(\log_\Delta n)$ time deterministically, even on trees.
The simplified technique is based on two ideas: the notion of an irregular
running time and some general observations that transform weak lower bounds
into stronger ones.
  2. We give a randomized edge coloring algorithm that can use palette sizes as
small as $\Delta + \tilde{O}(\sqrt{\Delta})$, which is a natural barrier for
randomized approaches. The running time of the algorithm is at most
$O(\log\Delta \cdot T_{LLL})$, where $T_{LLL}$ is the complexity of a
permissive version of the constructive Lovasz local lemma.
  3. We develop a new distributed Lovasz local lemma algorithm for
tree-structured dependency graphs, which leads to a $(1+\epsilon)\Delta$-edge
coloring algorithm for trees running in $O(\log\log n)$ time. This algorithm
arises from two new results: a deterministic $O(\log n)$-time LLL algorithm for
tree-structured instances, and a randomized $O(\log\log n)$-time graph
shattering method for breaking the dependency graph into independent $O(\log
n)$-size LLL instances.
  4. A natural approach to computing $(\Delta+1)$-edge colorings (Vizing's
theorem) is to extend partial colorings by iteratively re-coloring parts of the
graph. We prove that this approach may be viable, but in the worst case
requires recoloring subgraphs of diameter $\Omega(\Delta\log n)$. This stands
in contrast to distributed algorithms for Brooks' theorem, which exploit the
existence of $O(\log_\Delta n)$-length augmenting paths.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04299</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emotion Detection on TV Show Transcripts with Sequence-based
  Convolutional Neural Networks</dc:title>
 <dc:creator>Zahiri, Sayyed M.</dc:creator>
 <dc:creator>Choi, Jinho D.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  While there have been significant advances in detecting emotions from speech
and image recognition, emotion detection on text is still under-explored and
remained as an active research field. This paper introduces a corpus for
text-based emotion detection on multiparty dialogue as well as deep neural
models that outperform the existing approaches for document classification. We
first present a new corpus that provides annotation of seven emotions on
consecutive utterances in dialogues extracted from the show, Friends. We then
suggest four types of sequence-based convolutional neural network models with
attention that leverage the sequence information encapsulated in dialogue. Our
best model shows the accuracies of 37.9% and 54% for fine- and coarse-grained
emotions, respectively. Given the difficulty of this task, this is promising.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04301</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attacking Automatic Video Analysis Algorithms: A Case Study of Google
  Cloud Video Intelligence API</dc:title>
 <dc:creator>Hosseini, Hossein</dc:creator>
 <dc:creator>Xiao, Baicen</dc:creator>
 <dc:creator>Clark, Andrew</dc:creator>
 <dc:creator>Poovendran, Radha</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Due to the growth of video data on Internet, automatic video analysis has
gained a lot of attention from academia as well as companies such as Facebook,
Twitter and Google. In this paper, we examine the robustness of video analysis
algorithms in adversarial settings. Specifically, we propose targeted attacks
on two fundamental classes of video analysis algorithms, namely video
classification and shot detection. We show that an adversary can subtly
manipulate a video in such a way that a human observer would perceive the
content of the original video, but the video analysis algorithm will return the
adversary's desired outputs.
  We then apply the attacks on the recently released Google Cloud Video
Intelligence API. The API takes a video file and returns the video labels
(objects within the video), shot changes (scene changes within the video) and
shot labels (description of video events over time). Through experiments, we
show that the API generates video and shot labels by processing only the first
frame of every second of the video. Hence, an adversary can deceive the API to
output only her desired video and shot labels by periodically inserting an
image into the video at the rate of one frame per second. We also show that the
pattern of shot changes returned by the API can be mostly recovered by an
algorithm that compares the histograms of consecutive frames. Based on our
equivalent model, we develop a method for slightly modifying the video frames,
in order to deceive the API into generating our desired pattern of shot
changes. We perform extensive experiments with different videos and show that
our attacks are consistently successful across videos with different
characteristics. At the end, we propose introducing randomness to video
analysis algorithms as a countermeasure to our attacks.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04308</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MHTN: Modal-adversarial Hybrid Transfer Network for Cross-modal
  Retrieval</dc:title>
 <dc:creator>Huang, Xin</dc:creator>
 <dc:creator>Peng, Yuxin</dc:creator>
 <dc:creator>Yuan, Mingkuan</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Cross-modal retrieval has drawn wide interest for retrieval across different
modalities of data. However, existing methods based on DNN face the challenge
of insufficient cross-modal training data, which limits the training
effectiveness and easily leads to overfitting. Transfer learning is for
relieving the problem of insufficient training data, but it mainly focuses on
knowledge transfer only from large-scale datasets as single-modal source domain
to single-modal target domain. Such large-scale single-modal datasets also
contain rich modal-independent semantic knowledge that can be shared across
different modalities. Besides, large-scale cross-modal datasets are very
labor-consuming to collect and label, so it is significant to fully exploit the
knowledge in single-modal datasets for boosting cross-modal retrieval. This
paper proposes modal-adversarial hybrid transfer network (MHTN), which to the
best of our knowledge is the first work to realize knowledge transfer from
single-modal source domain to cross-modal target domain, and learn cross-modal
common representation. It is an end-to-end architecture with two subnetworks:
(1) Modal-sharing knowledge transfer subnetwork is proposed to jointly transfer
knowledge from a large-scale single-modal dataset in source domain to all
modalities in target domain with a star network structure, which distills
modal-independent supplementary knowledge for promoting cross-modal common
representation learning. (2) Modal-adversarial semantic learning subnetwork is
proposed to construct an adversarial training mechanism between common
representation generator and modality discriminator, making the common
representation discriminative for semantics but indiscriminative for modalities
to enhance cross-modal semantic consistency during transfer process.
Comprehensive experiments on 4 widely-used datasets show its effectiveness and
generality.
</dc:description>
 <dc:description>Comment: 12 pages, submitted to IEEE Transactions on Cybernetics</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04312</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative Filtering using Denoising Auto-Encoders for Market Basket
  Data</dc:title>
 <dc:creator>Abad, Andres G.</dc:creator>
 <dc:creator>Reyes-Castro, Luis I.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recommender systems (RS) help users navigate large sets of items in the
search for &quot;interesting&quot; ones. One approach to RS is Collaborative Filtering
(CF), which is based on the idea that similar users are interested in similar
items. Most model-based approaches to CF seek to train a
machine-learning/data-mining model based on sparse data; the model is then used
to provide recommendations. While most of the proposed approaches are effective
for small-size situations, the combinatorial nature of the problem makes it
impractical for medium-to-large instances. In this work we present a novel
approach to CF that works by training a Denoising Auto-Encoder (DAE) on
corrupted baskets, i.e., baskets from which one or more items have been
removed. The DAE is then forced to learn to reconstruct the original basket
given its corrupted input. Due to recent advancements in optimization and other
technologies for training neural-network models (such as DAE), the proposed
method results in a scalable and practical approach to CF. The contribution of
this work is twofold: (1) to identify missing items in observed baskets and,
thus, directly providing a CF model; and, (2) to construct a generative model
of baskets which may be used, for instance, in simulation analysis or as part
of a more complex analytical method.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04314</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Superadditivity in trade-off capacities of quantum channels</dc:title>
 <dc:creator>Zhu, Elton Yechao</dc:creator>
 <dc:creator>Zhuang, Quntao</dc:creator>
 <dc:creator>Hsieh, Min-Hsiu</dc:creator>
 <dc:creator>Shor, Peter W.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this article, we investigate the additivity phenomenon in the dynamic
capacity of a quantum channel for trading classical communication, quantum
communication and entanglement. Understanding such additivity property is
important if we want to optimally use a quantum channel for general
communication purpose. However, in a lot of cases, the channel one will be
using only has an additive single or double resource capacity, and it is
largely unknown if this could lead to an superadditive double or triple
resource capacity. For example, if a channel has an additive classical and
quantum capacity, can the classical-quantum capacity be superadditive? In this
work, we answer such questions affirmatively.
  We give proof-of-principle requirements for these channels to exist. In most
cases, we can provide an explicit construction of these quantum channels. The
existence of these superadditive phenomena is surprising in contrast to the
result that the additivity of both classical-entanglement and classical-quantum
capacity regions imply the additivity of the triple capacity region.
</dc:description>
 <dc:description>Comment: 15 pages. v2: typo corrected</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04317</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An ELU Network with Total Variation for Image Denoising</dc:title>
 <dc:creator>Wang, Tianyang</dc:creator>
 <dc:creator>Qin, Zhengrui</dc:creator>
 <dc:creator>Zhu, Michelle</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel convolutional neural network (CNN) for
image denoising, which uses exponential linear unit (ELU) as the activation
function. We investigate the suitability by analyzing ELU's connection with
trainable nonlinear reaction diffusion model (TNRD) and residual denoising. On
the other hand, batch normalization (BN) is indispensable for residual
denoising and convergence purpose. However, direct stacking of BN and ELU
degrades the performance of CNN. To mitigate this issue, we design an
innovative combination of activation layer and normalization layer to exploit
and leverage the ELU network, and discuss the corresponding rationale.
Moreover, inspired by the fact that minimizing total variation (TV) can be
applied to image denoising, we propose a TV regularized L2 loss to evaluate the
training effect during the iterations. Finally, we conduct extensive
experiments, showing that our model outperforms some recent and popular
approaches on Gaussian denoising with specific or randomized noise levels for
both gray and color images.
</dc:description>
 <dc:description>Comment: 10 pages, Accepted by the 24th International Conference on Neural
  Information Processing (2017)</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04318</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cyber-Physical Interference Modeling for Predictable Reliability of
  Inter-Vehicle Communications</dc:title>
 <dc:creator>Li, Chuan</dc:creator>
 <dc:creator>Zhang, Hongwei</dc:creator>
 <dc:creator>Rao, Jayanthi</dc:creator>
 <dc:creator>Wang, Le Yi</dc:creator>
 <dc:creator>Yin, George</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Predictable inter-vehicle communication reliability is a basis for the
paradigm shift from the traditional singlevehicle-oriented safety and
efficiency control to networked vehicle control. The lack of predictable
interference control in existing mechanisms of inter-vehicle communications,
however, makes them incapable of ensuring predictable communication
reliability. For predictable interference control, we propose the
Cyber-Physical Scheduling (CPS) framework that leverages the PRK interference
model and addresses the challenges of vehicle mobility to PRK-based scheduling.
In particular, CPS leverage physical locations of vehicles to define the gPRK
interference model, a geometric approximation of the PRK model, for effective
interference relation estimation, and CPS leverages cyber-physical structures
of vehicle traffic flows (particularly, spatiotemporal interference correlation
as well as macro- and micro-scopic vehicle dynamics) for effective use of the
gPRK model. Through experimental analysis with high-fidelity ns-3 and SUMO
simulation, we observe that CPS enables predictable reliability while achieving
high throughput and low delay in communication. To the best of our knowledge,
CPS is the first field deployable method that ensures predictable interference
control and thus reliability in inter-vehicle communications.
</dc:description>
 <dc:description>Comment: 10 page conference version</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04320</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Situation Recognition with Graph Neural Networks</dc:title>
 <dc:creator>Li, Ruiyu</dc:creator>
 <dc:creator>Tapaswi, Makarand</dc:creator>
 <dc:creator>Liao, Renjie</dc:creator>
 <dc:creator>Jia, Jiaya</dc:creator>
 <dc:creator>Urtasun, Raquel</dc:creator>
 <dc:creator>Fidler, Sanja</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We address the problem of recognizing situations in images. Given an image,
the task is to predict the most salient verb (action), and fill its semantic
roles such as who is performing the action, what is the source and target of
the action, etc. Different verbs have different roles (e.g. attacking has
weapon), and each role can take on many possible values (nouns). We propose a
model based on Graph Neural Networks that allows us to efficiently capture
joint dependencies between roles using neural networks defined on a graph.
Experiments with different graph connectivities show that our approach that
propagates information between roles significantly outperforms existing work,
as well as multiple baselines. We obtain roughly 3-5% improvement over previous
work in predicting the full situation. We also provide a thorough qualitative
analysis of our model and influence of different roles in the verbs.
</dc:description>
 <dc:description>Comment: ICCV2017</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04321</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distance and Similarity Measures Effect on the Performance of K-Nearest
  Neighbor Classifier - A Review</dc:title>
 <dc:creator>Prasath, V. B. Surya</dc:creator>
 <dc:creator>Alfeilat, Haneen Arafat Abu</dc:creator>
 <dc:creator>Lasassmeh, Omar</dc:creator>
 <dc:creator>Hassanat, Ahmad B. A.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The K-nearest neighbor (KNN) classifier is one of the simplest and most
common classifiers, yet its performance competes with the most complex
classifiers in the literature. The core of this classifier depends mainly on
measuring the distance or similarity between the tested example and the
training examples. This raises a major question about which distance measures
to be used for the KNN classifier among a large number of distance and
similarity measures? This review attempts to answer the previous question
through evaluating the performance (measured by accuracy, precision and recall)
of the KNN using a large number of distance measures, tested on a number of
real world datasets, with and without adding different levels of noise. The
experimental results show that the performance of KNN classifier depends
significantly on the distance used, the results showed large gaps between the
performances of different distances. We found that a recently proposed
non-convex distance performed the best when applied on most datasets comparing
to the other tested distances. In addition, the performance of the KNN degraded
only about $20\%$ while the noise level reaches $90\%$, this is true for all
the distances used. This means that the KNN classifier using any of the top
$10$ distances tolerate noise to a certain degree. Moreover, the results show
that some distances are less affected by the added noise comparing to other
distances.
</dc:description>
 <dc:description>Comment: 50 pages, 6 figures, 14 tables</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04322</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization of Heterogeneous Coded Caching</dc:title>
 <dc:creator>Daniel, Alexander Michael</dc:creator>
 <dc:creator>Yu, Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper aims to provide an optimization framework for coded caching that
accounts for various heterogeneous aspects of practical systems. An
optimization theoretic perspective on the seminal work on the fundamental
limits of caching by Maddah Ali and Niesen is first developed, whereas it is
proved that the coded caching scheme presented in that work is the optimal
scheme among a large, non-trivial family of possible caching schemes. The
optimization framework is then used to develop a coded caching scheme capable
of handling simultaneous non-uniform file length, non-uniform file popularity,
and non-uniform user cache size. Although the resulting full optimization
problem scales exponentially with the problem size, this paper shows that
tractable simplifications of the problem that scale as a polynomial function of
the problem size can still perform well compared to the original problem. By
considering these heterogeneities both individually and in conjunction with one
another, insights into their interactions and influence on optimal cache
content are obtained.
</dc:description>
 <dc:description>Comment: To be submitted to IEEE Transactions on Information Theory. 26 pages,
  6 figures</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04325</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Review Paper: Inertial Measurement</dc:title>
 <dc:creator>Conlin, William T.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Applications of inertial measurement units are extremely diverse, and are
expected to see a further increase in number due to current trends in robotics
as well as recent advances in Micro Electromechanical sensors (MEMS). The
traditional method of inertial measurement has depended on costly,
power-intensive, error-prone Inertial Measurement Units (IMUs) that represent a
single point of failure. Promising areas of current research include methods
for combining multiple redundant sensors, which collectively provide more
accurate and more dependable estimates of state, and wholly new IMU layouts
that seek to reduce error. New types include: gyro-free, timing, wireless,
distributed redundant IMUs, and IMUs that incorporate MEMS components for
miniaturization in general. This review paper highlights these new research
directions and lays out the design and experimental implementation of a
complementary filter for inertial measurement.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04326</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Answer Selection with Pre-Trained Word Embeddings</dc:title>
 <dc:creator>Chakravarti, Rishav</dc:creator>
 <dc:creator>Navratil, Jiri</dc:creator>
 <dc:creator>Santos, Cicero Nogueira dos</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This paper evaluates existing and newly proposed answer selection methods
based on pre-trained word embeddings. Word embeddings are highly effective in
various natural language processing tasks and their integration into
traditional information retrieval (IR) systems allows for the capture of
semantic relatedness between questions and answers. Empirical results on three
publicly available data sets show significant gains over traditional term
frequency based approaches in both supervised and unsupervised settings. We
show that combining these word embedding features with traditional
learning-to-rank techniques can achieve similar performance to state-of-the-art
neural networks trained for the answer selection task.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04341</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graphettes: Constant-time determination of graphlet and orbit identity
  including (possibly disconnected) graphlets up to size 8</dc:title>
 <dc:creator>Hassan, Adib</dc:creator>
 <dc:creator>Chung, Po-Chien</dc:creator>
 <dc:creator>Hayes, Wayne B.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Graphlets are small connected induced subgraphs of a larger graph $G$.
Graphlets are now commonly used to quantify local and global topology of
networks in the field. Methods exist to exhaustively enumerate all graphlets
(and their orbits) in large networks as efficiently as possible using orbit
counting equations. However, the number of graphlets in $G$ is exponential in
both the number of nodes and edges in $G$. Enumerating them all is already
unacceptably expensive on existing large networks, and the problem will only
get worse as networks continue to grow in size and density. Here we introduce
an efficient method designed to aid statistical sampling of graphlets up to
size $k=8$ from a large network. We define graphettes as the generalization of
graphlets allowing for disconnected graphlets. Given a particular (undirected)
graphette $g$, we introduce the idea of the canonical graphette $\mathcal K(g)$
as a representative member of the isomorphism group $Iso(g)$ of $g$. We compute
the mapping $\mathcal K$, in the form of a lookup table, from all
$2^{k(k-1)/2}$ undirected graphettes $g$ of size $k\le 8$ to their canonical
representatives $\mathcal K(g)$, as well as the permutation that transforms $g$
to $\mathcal K(g)$. We also compute all automorphism orbits for each canonical
graphette. Thus, given any $k\le 8$ nodes in a graph $G$, we can in constant
time infer which graphette it is, as well as which orbit each of the $k$ nodes
belongs to. Sampling a large number $N$ of such $k$-sets of nodes provides an
approximation of both the distribution of graphlets and orbits across $G$, and
the orbit degree vector at each node.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures, 2 tables. Accepted to PLOS ONE</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04343</identifier>
 <datestamp>2017-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Methods for Passive Imaging: Non-asymptotic Performance and
  Robustness</dc:title>
 <dc:creator>Lee, Kiryung</dc:creator>
 <dc:creator>Krahmer, Felix</dc:creator>
 <dc:creator>Romberg, Justin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We study the problem of passive imaging through convolutive channels. A scene
is illuminated with an unknown, unstructured source, and the measured response
is the convolution of this source with multiple channel responses, each of
which is time-limited. Spectral methods based on the commutativity of
convolution, first proposed and analyzed in the 1990s, provide an elegant
mathematical framework for attacking this problem. However, these now classical
methods are very sensitive to noise, especially when working from relatively
small sample sizes.
  In this paper, we show that a linear subspace model on the coefficients of
the impulse responses of the channels can make this problem well-posed. We
derive non-asymptotic error bounds for the generic subspace model by analyzing
the spectral gap of the cross-correlation matrix of the channels relative to
the perturbation introduced by noise. Numerical results show that this modified
spectral method offers significant improvements over the classical method and
outperforms other competing methods for multichannel blind deconvolution.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04347</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Augmentation using Radial Transform for Training Deep Neural
  Networks</dc:title>
 <dc:creator>Salehinejad, Hojjat</dc:creator>
 <dc:creator>Valaee, Shahrokh</dc:creator>
 <dc:creator>Dowdell, Timothy</dc:creator>
 <dc:creator>Barfett, Joseph</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning models have a large number of free parameters that must be
estimated by efficient training of the models on a large number of training
data samples to increase their generalization performance. In real-world
applications, the data available to train these networks is often limited or
imbalanced. We propose a sampling method based on the radial transform in a
polar coordinate system for image augmentation to facilitate the training of
deep learning models from limited source data. This pixel-wise transform
provides representations of the original image in the polar coordinate system
by generating a new image from each pixel. This technique can generate radial
transformed images up to the number of pixels in the original image to increase
the diversity of poorly represented image classes. Our experiments show
improved generalization performance in training deep convolutional neural
networks with radial transformed images.
</dc:description>
 <dc:description>Comment: This paper is submitted for peer-review</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04352</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmark Environments for Multitask Learning in Continuous Domains</dc:title>
 <dc:creator>Henderson, Peter</dc:creator>
 <dc:creator>Chang, Wei-Di</dc:creator>
 <dc:creator>Shkurti, Florian</dc:creator>
 <dc:creator>Hansen, Johanna</dc:creator>
 <dc:creator>Meger, David</dc:creator>
 <dc:creator>Dudek, Gregory</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  As demand drives systems to generalize to various domains and problems, the
study of multitask, transfer and lifelong learning has become an increasingly
important pursuit. In discrete domains, performance on the Atari game suite has
emerged as the de facto benchmark for assessing multitask learning. However, in
continuous domains there is a lack of agreement on standard multitask
evaluation environments which makes it difficult to compare different
approaches fairly. In this work, we describe a benchmark set of tasks that we
have developed in an extendable framework based on OpenAI Gym. We run a simple
baseline using Trust Region Policy Optimization and release the framework
publicly to be expanded and used for the systematic comparison of multitask,
transfer, and lifelong learning in continuous domains.
</dc:description>
 <dc:description>Comment: Accepted at Lifelong Learning: A Reinforcement Learning Approach
  Workshop @ ICML, Sydney, Australia, 2017</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04354</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constrained Community Detection in Social Networks</dc:title>
 <dc:creator>Viles, Weston D.</dc:creator>
 <dc:creator>O'Malley, A. James</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Community detection in networks is the process of identifying unusually
well-connected sub-networks and is a central component of many applied network
analyses. The paradigm of modularity optimization stipulates a partition of the
network's vertices which maximizes the difference between the fraction of edges
within groups (communities) and the expected fraction if edges were randomly
distributed. The modularity objective function incorporates the network's
topology exclusively and has been extensively studied whereas the integration
of constraints or external information on community composition has largely
remained unexplored. We impose a penalty function on the modularity objective
function to regulate the constitution of communities and apply our methodology
in identifying health care communities (HCCs) within a network of hospitals
such that the number of cardiac defibrillator surgeries performed within each
HCC exceeds a minimum threshold. This restriction permits meaningful
comparisons in cardiac care among the resulting health care communities by
standardizing the distribution of cardiac care across the hospital network.
</dc:description>
 <dc:description>Comment: 31 pages, 6 figures</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04357</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Classification via Deep Learning with Virtual Nodes</dc:title>
 <dc:creator>Pham, Trang</dc:creator>
 <dc:creator>Tran, Truyen</dc:creator>
 <dc:creator>Dam, Hoa</dc:creator>
 <dc:creator>Venkatesh, Svetha</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning representation for graph classification turns a variable-size graph
into a fixed-size vector (or matrix). Such a representation works nicely with
algebraic manipulations. Here we introduce a simple method to augment an
attributed graph with a virtual node that is bidirectionally connected to all
existing nodes. The virtual node represents the latent aspects of the graph,
which are not immediately available from the attributes and local connectivity
structures. The expanded graph is then put through any node representation
method. The representation of the virtual node is then the representation of
the entire graph. In this paper, we use the recently introduced Column Network
for the expanded graph, resulting in a new end-to-end graph classification
model dubbed Virtual Column Network (VCN). The model is validated on two tasks:
(i) predicting bio-activity of chemical compounds, and (ii) finding software
vulnerability from source code. Results demonstrate that VCN is competitive
against well-established rivals.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04358</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous Representation of Location for Geolocation and Lexical
  Dialectology using Mixture Density Networks</dc:title>
 <dc:creator>Rahimi, Afshin</dc:creator>
 <dc:creator>Baldwin, Timothy</dc:creator>
 <dc:creator>Cohn, Trevor</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We propose a method for embedding two-dimensional locations in a continuous
vector space using a neural network-based model incorporating mixtures of
Gaussian distributions, presenting two model variants for text-based
geolocation and lexical dialectology. Evaluated over Twitter data, the proposed
model outperforms conventional regression-based geolocation and provides a
better estimate of uncertainty. We also show the effectiveness of the
representation for predicting words from location in lexical dialectology, and
evaluate it using the DARE dataset.
</dc:description>
 <dc:description>Comment: Conference on Empirical Methods in Natural Language Processing (EMNLP
  2017) September 2017, Copenhagen, Denmark</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04366</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Edge-Aware Saliency Detection</dc:title>
 <dc:creator>Zhang, Jing</dc:creator>
 <dc:creator>Dai, Yuchao</dc:creator>
 <dc:creator>Porikli, Fatih</dc:creator>
 <dc:creator>He, Mingyi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  There has been profound progress in visual saliency thanks to the deep
learning architectures, however, there still exist three major challenges that
hinder the detection performance for scenes with complex compositions, multiple
salient objects, and salient objects of diverse scales. In particular, output
maps of the existing methods remain low in spatial resolution causing blurred
edges due to the stride and pooling operations, networks often neglect
descriptive statistical and handcrafted priors that have potential to
complement saliency detection results, and deep features at different layers
stay mainly desolate waiting to be effectively fused to handle multi-scale
salient objects. In this paper, we tackle these issues by a new fully
convolutional neural network that jointly learns salient edges and saliency
labels in an end-to-end fashion. Our framework first employs convolutional
layers that reformulate the detection task as a dense labeling problem, then
integrates handcrafted saliency features in a hierarchical manner into lower
and higher levels of the deep network to leverage available information for
multi-scale response, and finally refines the saliency map through dilated
convolutions by imposing context. In this way, the salient edge priors are
efficiently incorporated and the output resolution is significantly improved
while keeping the memory requirements low, leading to cleaner and sharper
object boundaries. Extensive experimental analyses on ten benchmarks
demonstrate that our framework achieves consistently superior performance and
attains robustness for complex scenes in comparison to the very recent
state-of-the-art approaches.
</dc:description>
 <dc:description>Comment: 13 pages, 11 figures</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04369</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quasi-PTAS for Scheduling with Precedences using LP Hierarchies</dc:title>
 <dc:creator>Garg, Shashwat</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A central problem in scheduling is to schedule $n$ unit size jobs with
precedence constraints on $m$ identical machines so as to minimize the
makespan. For $m=3$, it is not even known if the problem is NP-hard and this is
one of the last open problems from the book of Garey and Johnson.
  We show that for fixed $m$ and $\epsilon$, $(\log n)^{O(1)}$ rounds of
Sherali-Adams hierarchy applied to a natural LP of the problem provides a
$(1+\epsilon)$-approximation algorithm running in quasi-polynomial time. This
improves over the recent result of Levey and Rothvoss, who used $r=(\log
n)^{O(\log \log n)}$ rounds of Sherali-Adams in order to get a
$(1+\epsilon)$-approximation algorithm with a running time of $n^{O(r)}$.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04369</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04370</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dockerface: an easy to install and use Faster R-CNN face detector in a
  Docker container</dc:title>
 <dc:creator>Ruiz, Nataniel</dc:creator>
 <dc:creator>Rehg, James M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face detection is a very important task and a necessary pre-processing step
for many applications such as facial landmark detection, pose estimation,
sentiment analysis and face recognition. Not only is face detection an
important pre-processing step in computer vision applications but also in
computational psychology, behavioral imaging and other fields where researchers
might not be initiated in computer vision frameworks and state-of-the-art
detection applications.
  A large part of existing research that includes face detection as a
pre-processing step uses existing out-of-the-box detectors such as dlib and the
OpenCV Haar face detector which no longer state-of-the-art - they are primarily
used because of their ease of use.
  We introduce Dockerface, a very accurate Faster R-CNN face detector in a
Docker container which requires no training and is easy to install and use.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04378</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Learning Reward Functions from User Interactions</dc:title>
 <dc:creator>Li, Ziming</dc:creator>
 <dc:creator>Kiseleva, Julia</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:creator>Grotov, Artem</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In the physical world, people have dynamic preferences, e.g., the same
situation can lead to satisfaction for some humans and to frustration for
others. Personalization is called for. The same observation holds for online
behavior with interactive systems. It is natural to represent the behavior of
users who are engaging with interactive systems such as a search engine or a
recommender system, as a sequence of actions where each next action depends on
the current situation and the user reward of taking a particular action. By and
large, current online evaluation metrics for interactive systems such as search
engines or recommender systems, are static and do not reflect differences in
user behavior. They rarely capture or model the reward experienced by a user
while interacting with an interactive system. We argue that knowing a user's
reward function is essential for an interactive system as both for learning and
evaluation. We propose to learn users' reward functions directly from observed
interaction traces. In particular, we present how users' reward functions can
be uncovered directly using inverse reinforcement learning techniques. We also
show how to incorporate user features into the learning process. Our main
contribution is a novel and dynamic approach to restore a user's reward
function. We present an analytic approach to this problem and complement it
with initial experiments using the interaction logs of a cultural heritage
institution that demonstrate the feasibility of the approach by uncovering
different reward functions for different user groups.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04378</dc:identifier>
 <dc:identifier>doi:10.1145/3121050.3121098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04381</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Streaming Periodicity with Mismatches</dc:title>
 <dc:creator>Erg&#xfc;n, Funda</dc:creator>
 <dc:creator>Grigorescu, Elena</dc:creator>
 <dc:creator>Azer, Erfan Sadeqi</dc:creator>
 <dc:creator>Zhou, Samson</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the problem of finding all $k$-periods of a length-$n$ string $S$,
presented as a data stream. $S$ is said to have $k$-period $p$ if its prefix of
length $n-p$ differs from its suffix of length $n-p$ in at most $k$ locations.
  We give a one-pass streaming algorithm that computes the $k$-periods of a
string $S$ using $\text{poly}(k, \log n)$ bits of space, for $k$-periods of
length at most $\frac{n}{2}$. We also present a two-pass streaming algorithm
that computes $k$-periods of $S$ using $\text{poly}(k, \log n)$ bits of space,
regardless of period length. We complement these results with comparable lower
bounds.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04390</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fluency-Guided Cross-Lingual Image Captioning</dc:title>
 <dc:creator>Lan, Weiyu</dc:creator>
 <dc:creator>Li, Xirong</dc:creator>
 <dc:creator>Dong, Jianfeng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Image captioning has so far been explored mostly in English, as most
available datasets are in this language. However, the application of image
captioning should not be restricted by language. Only few studies have been
conducted for image captioning in a cross-lingual setting. Different from these
works that manually build a dataset for a target language, we aim to learn a
cross-lingual captioning model fully from machine-translated sentences. To
conquer the lack of fluency in the translated sentences, we propose in this
paper a fluency-guided learning framework. The framework comprises a module to
automatically estimate the fluency of the sentences and another module to
utilize the estimated fluency scores to effectively train an image captioning
model for the target language. As experiments on two bilingual
(English-Chinese) datasets show, our approach improves both fluency and
relevance of the generated captions in Chinese, but without using any manually
written sentences from the target language.
</dc:description>
 <dc:description>Comment: 9 pages, 2 figures, accepted as ORAL by ACM Multimedia 2017</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04390</dc:identifier>
 <dc:identifier>doi:10.1145/3123266.3123366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04391</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning body-affordances to simplify action spaces</dc:title>
 <dc:creator>Guttenberg, Nicholas</dc:creator>
 <dc:creator>Biehl, Martin</dc:creator>
 <dc:creator>Kanai, Ryota</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Controlling embodied agents with many actuated degrees of freedom is a
challenging task. We propose a method that can discover and interpolate between
context dependent high-level actions or body-affordances. These provide an
abstract, low-dimensional interface indexing high-dimensional and time-
extended action policies. Our method is related to recent ap- proaches in the
machine learning literature but is conceptually simpler and easier to
implement. More specifically our method requires the choice of a n-dimensional
target sensor space that is endowed with a distance metric. The method then
learns an also n-dimensional embedding of possibly reactive body-affordances
that spread as far as possible throughout the target sensor space.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04396</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BiRank: Towards Ranking on Bipartite Graphs</dc:title>
 <dc:creator>He, Xiangnan</dc:creator>
 <dc:creator>Gao, Ming</dc:creator>
 <dc:creator>Kan, Min-Yen</dc:creator>
 <dc:creator>Wang, Dingxian</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The bipartite graph is a ubiquitous data structure that can model the
relationship between two entity types: for instance, users and items, queries
and webpages. In this paper, we study the problem of ranking vertices of a
bipartite graph, based on the graph's link structure as well as prior
information about vertices (which we term a query vector). We present a new
solution, BiRank, which iteratively assigns scores to vertices and finally
converges to a unique stationary ranking. In contrast to the traditional random
walk-based methods, BiRank iterates towards optimizing a regularization
function, which smooths the graph under the guidance of the query vector.
Importantly, we establish how BiRank relates to the Bayesian methodology,
enabling the future extension in a probabilistic way. To show the rationale and
extendability of the ranking methodology, we further extend it to rank for the
more generic n-partite graphs. BiRank's generic modeling of both the graph
structure and vertex features enables it to model various ranking hypotheses
flexibly. To illustrate its functionality, we apply the BiRank and TriRank
(ranking for tripartite graphs) algorithms to two real-world applications: a
general ranking scenario that predicts the future popularity of items, and a
personalized ranking scenario that recommends items of interest to users.
Extensive experiments on both synthetic and real-world datasets demonstrate
BiRank's soundness (fast convergence), efficiency (linear in the number of
graph edges) and effectiveness (achieving state-of-the-art in the two
real-world tasks).
</dc:description>
 <dc:description>Comment: 15 pages, 8 figures</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04398</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monocular Dense 3D Reconstruction of a Complex Dynamic Scene from Two
  Perspective Frames</dc:title>
 <dc:creator>Kumar, Suryansh</dc:creator>
 <dc:creator>Dai, Yuchao</dc:creator>
 <dc:creator>Li, Hongdong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a new approach for monocular dense 3D reconstruction of a
complex dynamic scene from two perspective frames. By applying superpixel
over-segmentation to the image, we model a generically dynamic (hence
non-rigid) scene with a piecewise planar and rigid approximation. In this way,
we reduce the dynamic reconstruction problem to a &quot;3D jigsaw puzzle&quot; problem
which takes pieces from an unorganized &quot;soup of superpixels&quot;. We show that our
method provides an effective solution to the inherent relative scale ambiguity
in structure-from-motion. Since our method does not assume a template prior, or
per-object segmentation, or knowledge about the rigidity of the dynamic scene,
it is applicable to a wide range of scenarios. Extensive experiments on both
synthetic and real monocular sequences demonstrate the superiority of our
method compared with the state-of-the-art methods.
</dc:description>
 <dc:description>Comment: International Conference on Computer Vision (ICCV) 2017 pp: 4649-4657</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04399</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous User Authentication via Unlabeled Phone Movement Patterns</dc:title>
 <dc:creator>Kumar, Rajesh</dc:creator>
 <dc:creator>Kundu, Partha Pratim</dc:creator>
 <dc:creator>Shukla, Diksha</dc:creator>
 <dc:creator>Phoha, Vir V.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:description>  In this paper, we propose a novel continuous authentication system for
smartphone users. The proposed system entirely relies on unlabeled phone
movement patterns collected through smartphone accelerometer. The data was
collected in a completely unconstrained environment over five to twelve days.
The contexts of phone usage were identified using k-means clustering. Multiple
profiles, one for each context, were created for every user. Five machine
learning algorithms were employed for classification of genuine and impostors.
The performance of the system was evaluated over a diverse population of 57
users. The mean equal error rates achieved by Logistic Regression, Neural
Network, kNN, SVM, and Random Forest were 13.7%, 13.5%, 12.1%, 10.7%, and 5.6%
respectively. A series of statistical tests were conducted to compare the
performance of the classifiers. The suitability of the proposed system for
different types of users was also investigated using the failure to enroll
policy.
</dc:description>
 <dc:description>Comment: IEEE International Joint Conference on Biometrics (IJCB 2017),
  Denver, Colorado</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04400</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bringing Background into the Foreground: Making All Classes Equal in
  Weakly-supervised Video Semantic Segmentation</dc:title>
 <dc:creator>Saleh, Fatemeh Sadat</dc:creator>
 <dc:creator>Aliakbarian, Mohammad Sadegh</dc:creator>
 <dc:creator>Salzmann, Mathieu</dc:creator>
 <dc:creator>Petersson, Lars</dc:creator>
 <dc:creator>Alvarez, Jose M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pixel-level annotations are expensive and time-consuming to obtain. Hence,
weak supervision using only image tags could have a significant impact in
semantic segmentation. Recent years have seen great progress in
weakly-supervised semantic segmentation, whether from a single image or from
videos. However, most existing methods are designed to handle a single
background class. In practical applications, such as autonomous navigation, it
is often crucial to reason about multiple background classes. In this paper, we
introduce an approach to doing so by making use of classifier heatmaps. We then
develop a two-stream deep architecture that jointly leverages appearance and
motion, and design a loss based on our heatmaps to train it. Our experiments
demonstrate the benefits of our classifier heatmaps and of our two-stream
architecture on challenging urban scene datasets and on the YouTube-Objects
benchmark, where we obtain state-of-the-art results.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures, 7 tables, Accepted in ICCV 2017</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04401</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shared Spectrum Access Communications: A Neutral Host Micro Operator
  Approach</dc:title>
 <dc:creator>Kibria, Mirza Golam</dc:creator>
 <dc:creator>Villardi, Gabriel Porto</dc:creator>
 <dc:creator>Nguyen, Kien</dc:creator>
 <dc:creator>Liao, Wei-Shun</dc:creator>
 <dc:creator>Ishizu, Kentaro</dc:creator>
 <dc:creator>Kojima, Fumihide</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we conceive an advanced neutral host micro operator
(NH-{\mu}O) network approach providing venues with services tailored to their
specialized/specific requirements and/or local context related services that
the mobile network operators (MNOs) are poorly-suited to providing it, as well
as mobile broadband experience to the users from MNOs in a venue where only a
single infrastructure is mandated under shared spectrum access framework. A
radio access network slicing concept is conceived to support and optimize both
the slice instance (SI) use cases independently and efficiently by running all
network implementations in parallel, simultaneously on a common physical
network infrastructure. We devise a common shared architecture for the
NH-{\mu}O small cell base stations and dynamic spectrum assignment control
unit, and their required functionalities supporting coexistence of different
SIs as well as multiple MNOs in shared spectrum access communications. We
devise both inter-SI and intra- SI dynamic spectrum allocation policies
considering time-varying requirements of different SIs. The policies are
capable of taking care of application level priority, -i.e., mixture of
guaranteed quality of service and best-effort service users served by each SI
while ensuring a healthy competition. Our proposed framework serves two-fold
advantages, such as it gives the venue owner its own managed wireless networks
tailored to its very specific requirements, and it also brings out cost savings
and coverage extension for MNOs and efficiency of resources that arise from
sharing wireless networks, and delivering the network capacity into high
density venues.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04401</dc:identifier>
 <dc:identifier>IEEE J. Sel. Areas Commun., vol. 35, no. 8, pp. 1741-1753, Aug.
  2017</dc:identifier>
 <dc:identifier>doi:10.1109/JSAC.2017.2710021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04403</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Theoretical Foundation of Co-Training and Disagreement-Based Algorithms</dc:title>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:creator>Zhou, Zhi-Hua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Disagreement-based approaches generate multiple classifiers and exploit the
disagreement among them with unlabeled data to improve learning performance.
Co-training is a representative paradigm of them, which trains two classifiers
separately on two sufficient and redundant views; while for the applications
where there is only one view, several successful variants of co-training with
two different classifiers on single-view data instead of two views have been
proposed. For these disagreement-based approaches, there are several important
issues which still are unsolved, in this article we present theoretical
analyses to address these issues, which provides a theoretical foundation of
co-training and disagreement-based approaches.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04407</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput Enhancement of Multicarrier Cognitive M2M Networks:
  Universal-Filtered OFDM Systems</dc:title>
 <dc:creator>Kibria, Mirza Golam</dc:creator>
 <dc:creator>Villardi, Gabriel Porto</dc:creator>
 <dc:creator>Ishizu, Kentaro</dc:creator>
 <dc:creator>Kojima, Fumihide</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a cognitive radio network consisting of a primary cellular system
and a secondary cognitive machine-to-machine (M2M) system, and study the
throughput enhancement problem of the latter system employing
universal-filtered orthogonal frequency division multiplexing (UF-OFDM)
modulation. The downlink transmission capacity of the cognitive M2M system is
thereby maximized, while keeping the interference introduced to the primary
users (PUs) below the pre-specified threshold, under total transmit power
budget of the secondary base station (SBS). The performance of UF-OFDM based CR
system is compared to the performances of OFDM-based and filter bank
multicarrier (FBMC)-based CR systems. We also propose a near-optimal resource
allocation method separating the subband and power allocation. The solution is
less complex compared to optimization of the original combinatorial problem. We
present numerical results that show that for given interference thresholds of
the PUs and maximum transmit power limit of the SBS, the UF-OFDM based CR
system exhibits intermediary performance in terms of achievable capacity
compared to OFDM and FBMC-based CR systems. Interestingly, for a certain degree
of robustness of the PUs, the UF-OFDM performs equally well as FBMC.
Furthermore, the percentage rate-gain of UF-OFDM based CR system increases by a
large amount when UF-OFDM modulation with lower sidelobes ripple is employed.
Numerical results also show that the proposed throughput enhancing method
despite having lower computational complexity compared to the optimal solution
achieves near-optimal performance.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04407</dc:identifier>
 <dc:identifier>IEEE Internet of Things Journal, vol. 3, no. 5, pp. 830-838, Oct.
  2016</dc:identifier>
 <dc:identifier>doi:10.1109/JIOT.2015.2509259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04412</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource Allocation in Shared Spectrum Access Communications for
  Operators with Diverse Service Requirements</dc:title>
 <dc:creator>Kibria, Mirza Golam</dc:creator>
 <dc:creator>Villardi, Gabriel Porto</dc:creator>
 <dc:creator>Ishizu, Kentaro</dc:creator>
 <dc:creator>Kojima, Fumihide</dc:creator>
 <dc:creator>Yano, Hiroyuki</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study inter-operator spectrum sharing and intra-operator
resource allocation in shared spectrum access communication systems and propose
efficient dynamic solutions to address both inter-operator and intra-operator
resource allocation optimization problems. For inter-operator spectrum sharing,
we present two competent approaches, namely the subcarrier gain based sharing
and fragmentation based sharing, which carry out fair and flexible allocation
of the available shareable spectrum among the operators subject to certain
well-defined sharing rules, traffic demands and channel propagation
characteristics. Subcarrier gain based spectrum sharing scheme has been found
to be more efficient in terms of achieved throughput. However, fragmentation
based sharing is more attractive in terms of computational complexity. For
intra-operator resource allocation, we consider resource allocation problem
with users' dissimilar service requirements, where the operator supports users
with delay-constraint and non-delay constraint service requirements,
simultaneously. This optimization problem is a mixed integer nonlinear
programming problem and nonconvex, which is computationally very expensive, and
the complexity grows exponentially with the number of integer variables. We
propose less-complex and efficient suboptimal solution based on formulating
exact linearization, linear approximation and convexification techniques for
the nonlinear and/or non-convex objective functions and constraints. Extensive
simulation performance analysis has been carried out that validates the
efficiency of the proposed solution.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04412</dc:identifier>
 <dc:identifier>EURASIP J. Adv. Signal Process., (2016) 2016:83</dc:identifier>
 <dc:identifier>doi:10.1186/s13634-016-0381-8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04415</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A class of cyclotomic linear codes and their generalized Hamming weights</dc:title>
 <dc:creator>Li, Fei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>94B05, 11T22, 11T23</dc:subject>
 <dc:description>  Firstly, we give a formula on the generalized Hamming weight of linear codes
constructed generically by defining sets. Secondly, by choosing properly the
defining set we obtain a class of cyclotomic linear codes and then present two
alternative formulas to calculate their generalized Hamming weights. Lastly, we
determine their weight distribution and generalized Hamming weights partially.
Especially, we solved the generalized Hamming weights completely in one case.
</dc:description>
 <dc:description>Comment: 9</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04418</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Exploratory Study of Health Habit Formation Through Gamification</dc:title>
 <dc:creator>Iurchenko, Anna</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Promotion of healthy habits help maintain and improve people health, reduce
disease risks, and manage chronic illness. Regular healthy activities like
walking, exercising, healthy eating, drinking water or taking medication on
time require forming the new habits. Gamification techniques are promising in
promoting healthy behaviors and delivering health promotion information.
However, using gaming elements such as badges, leader boards, health-related
challenges in mobile applications to motivate and engage people to change
health behavior is quite new. In this exploratory study, we aimed to assess how
game mechanics and dynamics influence formation of a habit through the mobile
application. Results indicate the different level of user engagement depending
on the presence of gamification elements and suggest that there is value in
adding game elements to the user experience.
</dc:description>
 <dc:description>Comment: 5 pages, 2 tables, 2 figures</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04419</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrete time Pontryagin maximum principle for optimal control problems
  under state-action-frequency constraints</dc:title>
 <dc:creator>Paruchuri, Pradyumna</dc:creator>
 <dc:creator>Chatterjee, Debasish</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>49K21</dc:subject>
 <dc:description>  We establish a Pontryagin maximum principle for discrete time optimal control
problems under the following three types of constraints: a) constraints on the
states pointwise in time, b) constraints on the control actions pointwise in
time, and c) constraints on the frequency spectrum of the optimal control
trajectories. While the first two types of constraints are already included in
the existing versions of the Pontryagin maximum principle, it turns out that
the third type of constraints cannot be recast in any of the standard forms of
the existing results for the original control system. We provide two different
proofs of our Pontryagin maximum principle in this article, and include several
special cases fine-tuned to control-affine nonlinear and linear system models.
In particular, for minimization of quadratic cost functions and linear time
invariant control systems, we provide tight conditions under which the optimal
controls under frequency constraints are either normal or abnormal.
</dc:description>
 <dc:description>Comment: 31 pages</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04423</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Weighted Sum-Rate Maximization in Multicell MU-MIMO OFDMA
  Downlink</dc:title>
 <dc:creator>Kibria, Mirza Golam</dc:creator>
 <dc:creator>Murata, Hidekazu</dc:creator>
 <dc:creator>Zheng, Jun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers distributed linear beamforming in downlink multicell
multiuser orthogonal frequency-division multiple access networks. A fast
convergent solution maximizing the weighted sum- rate with per base station
(BS) transmiting power constraint is formulated. We approximate the non- convex
weighted sum-rate maximization (WSRM) problem with a semidefinite relaxed
solvable convex form by means of a series of approximation based on
interference alignment (IA) analysis. The WSRM optimization is a two-stage
optimization process. In the first stage, the IA conditions are satisfied. In
the second stage, the convex approximation of the non-convex WSRM is obtained
based on the consequences of IA, and high signal-to-interference-plus-noise
ratio assumption. Compared to the conventional iterative distributed algorithms
where the BSs exchange additional information at each iteration, the BSs of our
proposed solution optimize their beamformers locally without reporting
additional information during the iterative procedure.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04423</dc:identifier>
 <dc:identifier>Proc. IEEE International Conference on Communications (IEEE ICC).,
  Sydney, Australia, Jun. 2014</dc:identifier>
 <dc:identifier>doi:10.1109/ICC.2014.6884136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04429</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smart Meter Privacy via the Trapdoor Channel</dc:title>
 <dc:creator>Arrieta, Miguel</dc:creator>
 <dc:creator>Esnaola, Inaki</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A battery charging policy that provides privacy guarantees for smart meter
systems with finite capacity battery is proposed. For this policy an upper
bound on the information leakage rate is provided. The upper bound applies for
general random processes modelling the energy consumption of the user. It is
shown that the average energy consumption of the user determines the
information leakage rate to the utility provider. The upper bound is shown to
be tight by deriving the probability law of a random process achieving the
bound.
</dc:description>
 <dc:description>Comment: 2017 IEEE International Conference on Smart Grid Communications
  (SmartGridComm)</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04431</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coexistence of Systems with Different Multicarrier Waveforms in LSA
  Communications</dc:title>
 <dc:creator>Kibria, Mirza Golam</dc:creator>
 <dc:creator>Villardi, Gabriel Porto</dc:creator>
 <dc:creator>Ishizu, Kentaro</dc:creator>
 <dc:creator>Kojima, Fumihide</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the coexistence of different multicarrier waveforms such as
orthogonal frequency division multiplexing (OFDM), filter-bank multicarrier
(FBMC) and universal-filtered multicarrier (UFMC) waveforms in licensed shared
access (LSA) for next-generation communication systems. The fundamental changes
required in the existing physical layer using OFDM towards a hybrid physical
layer (either OFDM-FBMC or OFDM- UFMC) ensuring backward compatibility are
discussed. We also perform mutual interference analysis for the coexisting
asynchronous systems sharing the LSA frequency band. Be- cause of the
non-orthogonality between their respective transmit signals, power is spilled
from a system to the other causing interference. In consideration of analyzing
this interaction, power spectral densities of the multicarrier waveforms are
exploited. We quantify the amount of percentage power-loss experienced by the
interfering systems for not fully exploiting their available power budgets. The
simulation results reveal that the interfering system with FBMC suffers the
least percentage power-power loss due to its very low side-lobes while
conventional OFDM-based system suffers the most. The UFMC-based system exhibits
intermediary performance with respect to achieved throughput and power-loss
when compared with OFDM and FBMC-based systems.
</dc:description>
 <dc:description>Comment: Proc. IEEE Wireless Personal Multimedia Communications (IEEE WPMC).,
  Hyderabad, India, Dec. 2015</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04432</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knock-Knock: Acoustic Object Recognition by using Stacked Denoising
  Autoencoders</dc:title>
 <dc:creator>Luo, Shan</dc:creator>
 <dc:creator>Zhu, Leqi</dc:creator>
 <dc:creator>Althoefer, Kaspar</dc:creator>
 <dc:creator>Liu, Hongbin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a successful application of deep learning for object
recognition based on acoustic data. The shortcomings of previously employed
approaches where handcrafted features describing the acoustic data are being
used, include limiting the capability of the found representation to be widely
applicable and facing the risk of capturing only insignificant characteristics
for a task. In contrast, there is no need to define the feature representation
format when using multilayer/deep learning architecture methods: features can
be learned from raw sensor data without defining discriminative characteristics
a-priori. In this paper, stacked denoising autoencoders are applied to train a
deep learning model. Knocking each object in our test set 120 times with a
marker pen to obtain the auditory data, thirty different objects were
successfully classified in our experiment and each object was knocked 120 times
by a marker pen to obtain the auditory data. By employing the proposed deep
learning framework, a high accuracy of 91.50% was achieved. A traditional
method using handcrafted features with a shallow classifier was taken as a
benchmark and the attained recognition rate was only 58.22%. Interestingly, a
recognition rate of 82.00% was achieved when using a shallow classifier with
raw acoustic data as input. In addition, we could show that the time taken to
classify one object using deep learning was far less (by a factor of more than
6) than utilizing the traditional method. It was also explored how different
model parameters in our deep architecture affect the recognition performance.
</dc:description>
 <dc:description>Comment: 6 pages, 10 figures, Neurocomputing</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04432</dc:identifier>
 <dc:identifier>doi:10.1016/j.neucom.2017.03.014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04436</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Closest Labeled Point for Tactile Object Shape Recognition</dc:title>
 <dc:creator>Luo, Shan</dc:creator>
 <dc:creator>Mou, Wenxuan</dc:creator>
 <dc:creator>Althoefer, Kaspar</dc:creator>
 <dc:creator>Liu, Hongbin</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Tactile data and kinesthetic cues are two important sensing sources in robot
object recognition and are complementary to each other. In this paper, we
propose a novel algorithm named Iterative Closest Labeled Point (iCLAP) to
recognize objects using both tactile and kinesthetic information.The iCLAP
first assigns different local tactile features with distinct label numbers. The
label numbers of the tactile features together with their associated 3D
positions form a 4D point cloud of the object. In this manner, the two sensing
modalities are merged to form a synthesized perception of the touched object.
To recognize an object, the partial 4D point cloud obtained from a number of
touches iteratively matches with all the reference cloud models to identify the
best fit. An extensive evaluation study with 20 real objects shows that our
proposed iCLAP approach outperforms those using either of the separate sensing
modalities, with a substantial recognition rate improvement of up to 18%.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, IROS 2016</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04436</dc:identifier>
 <dc:identifier>doi:10.1109/IROS.2016.7759485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04439</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extractive Summarization using Deep Learning</dc:title>
 <dc:creator>Verma, Sukriti</dc:creator>
 <dc:creator>Nidhi, Vagisha</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper proposes a text summarization approach for factual reports using a
deep learning model. This approach consists of three phases: feature
extraction, feature enhancement, and summary generation, which work together to
assimilate core information and generate a coherent, understandable summary. We
are exploring various features to improve the set of sentences selected for the
summary, and are using a Restricted Boltzmann Machine to enhance and abstract
those features to improve resultant accuracy without losing any important
information. The sentences are scored based on those enhanced features and an
extractive summary is constructed. Experimentation carried out on several
articles demonstrates the effectiveness of the proposed approach.
</dc:description>
 <dc:description>Comment: Accepted to 18th International Conference on Computational
  Linguistics and Intelligent Text Processing</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04440</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An OpenGL and C++ based function library for curve and surface modeling
  in a large class of extended Chebyshev spaces</dc:title>
 <dc:creator>R&#xf3;th, &#xc1;goston</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65D17, 68U07</dc:subject>
 <dc:description>  Applying original and existing theoretical results, we propose a
platform-independent multi-threaded function library that provides data
structures to generate, differentiate and render both the ordinary basis and
the non-negative normalized B-basis of an arbitrary extended Chebyshev (EC)
space that comprises the constants and can be identified with the solution
space of a user-defined constant-coefficient homogeneous linear differential
equation. Using the obtained non-negative normalized B-bases, our library can
also generate, (partially) differentiate, modify and visualize a large family
of so-called B-curves and tensor product B-surfaces. Moreover, the library also
implements methods that can be used to perform general order elevation, to
subdivide B-curves and B-surfaces by means of general de Casteljau-like
B-algorithms, and to generate general basis transformations for the control
point based exact description of arbitrary integral curves and surfaces that
are described in traditional parametric form by means of the ordinary bases of
the underlying EC spaces. Independently of the algebraic, exponential,
trigonometric or mixed type of the applied EC space, the proposed library is
numerically stable and efficient up to a reasonable dimension number and may be
useful for academics and engineers in the fields of Approximation Theory,
Computer Aided Geometric Design, Computer Graphics, Isogeometric and Numerical
Analysis.
</dc:description>
 <dc:description>Comment: 27 pages, 17 figures, 2 tables</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04441</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localizing the Object Contact through Matching Tactile Features with
  Visual Map</dc:title>
 <dc:creator>Luo, Shan</dc:creator>
 <dc:creator>Mou, Wenxuan</dc:creator>
 <dc:creator>Althoefer, Kaspar</dc:creator>
 <dc:creator>Liu, Hongbin</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a novel framework for integration of vision and tactile
sensing by localizing tactile readings in a visual object map. Intuitively,
there are some correspondences, e.g., prominent features, between visual and
tactile object identification. To apply it in robotics, we propose to localize
tactile readings in visual images by sharing same sets of feature descriptors
through two sensing modalities. It is then treated as a probabilistic
estimation problem solved in a framework of recursive Bayesian filtering.
Feature-based measurement model and Gaussian based motion model are thus built.
In our tests, a tactile array sensor is utilized to generate tactile images
during interaction with objects and the results have proven the feasibility of
our proposed framework.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, ICRA 2015</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04441</dc:identifier>
 <dc:identifier>ICRA 2015</dc:identifier>
 <dc:identifier>doi:10.1109/ICRA.2015.7139743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04442</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reference Publication Year Spectroscopy (RPYS) of Eugene Garfield's
  publications</dc:title>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:creator>Haunschild, Robin</dc:creator>
 <dc:creator>Leydesdorff, Loet</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Which studies, theories, and ideas have influenced Eugene Garfield's
scientific work? Recently, the method reference publication year spectroscopy
(RPYS) has been introduced, which can be used to answer this and related
questions. Since then, several studies have been published dealing with the
historical roots of research fields and scientists. The program CRExplorer
(http://www.crexplorer.net) was specifically developed for RPYS. In this study,
we use this program to investigate the historical roots of Eugene Garfield's
oeuvre.
</dc:description>
 <dc:description>Comment: 16 pages, 3 tables, and 3 figures</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04442</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-017-2608-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04444</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Downlink Channel Probing and Uplink Feedback in FDD Massive
  MIMO Systems</dc:title>
 <dc:creator>Khalilsarai, Mahdi Barzegar</dc:creator>
 <dc:creator>Haghighatshoar, Saeid</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Massive Multiple-Input Multiple-Output (massive MIMO) is a variant of
multi-user MIMO in which the number of antennas at each Base Station (BS) is
very large and typically much larger than the number of users simultaneously
served. Massive MIMO can be implemented with Time Division Duplexing (TDD) or
Frequency Division Duplexing (FDD) operation. FDD massive MIMO systems are
particularly desirable due to their implementation in current wireless networks
and their efficiency in situations with symmetric traffic and delay-sensitive
applications. However, implementing FDD massive MIMO systems is known to be
challenging since it imposes a large feedback overhead in the Uplink (UL) to
obtain channel state information for the Downlink (DL). In recent years, a
considerable amount of research is dedicated to developing methods to reduce
the feedback overhead in such systems. In this paper, we use the sparse spatial
scattering properties of the environment to achieve this goal. The idea is to
estimate the support of the continuous, frequency-invariant scattering function
from UL channel observations and use this estimate to obtain the support of the
DL channel vector via appropriate interpolation. We use the resulting support
estimate to design an efficient DL probing and UL feedback scheme in which the
feedback dimension scales proportionally with the sparsity order of DL channel
vectors. Since the sparsity order is much less than the number of BS antennas
in almost all practically relevant scenarios, our method incurs much less
feedback overhead compared with the currently proposed methods in the
literature, such as those based on compressed-sensing. We use numerical
simulations to assess the performance of our probing-feedback algorithm and
compare it with these methods.
</dc:description>
 <dc:description>Comment: 24 pages, 10 figures</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04454</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convex Approximated Weighted Sum-Rate Maximization for Multicell
  Multiuser OFDM</dc:title>
 <dc:creator>Kibria, Mirza Golam</dc:creator>
 <dc:creator>Murata, Hidekazu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter considers the weighted sum-rate maximization (WSRMax) problem in
downlink multicell multiuser orthogonal frequency-division multiplexing system.
The WSRMax problem under per base station transmit power constraint is known to
be NP-hard, and the optimal solution is computationally very expensive. We
propose two less-complex suboptimal convex approximated solutions which are
based on sequential parametric convex approximation approach. We derive
provably faster convergent iterative convex approximation techniques that
locally optimize the weighted sum-rate function. Both the iterative solutions
are found to converge to the local optimal solution within a few iterations
compared to other well-known techniques. The numerical results demonstrate the
effectiveness and superiority of the proposed approaches.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04454</dc:identifier>
 <dc:identifier>IEICE Trans. Fundamentals, vol. E97-A, no. 8, pp. 1800-1805, Aug.
  2014</dc:identifier>
 <dc:identifier>doi:10.1587/transfun.E97.A.1800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04465</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Actively Learning what makes a Discrete Sequence Valid</dc:title>
 <dc:creator>Janz, David</dc:creator>
 <dc:creator>van der Westhuizen, Jos</dc:creator>
 <dc:creator>Hern&#xe1;ndez-Lobato, Jos&#xe9; Miguel</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep learning techniques have been hugely successful for traditional
supervised and unsupervised machine learning problems. In large part, these
techniques solve continuous optimization problems. Recently however, discrete
generative deep learning models have been successfully used to efficiently
search high-dimensional discrete spaces. These methods work by representing
discrete objects as sequences, for which powerful sequence-based deep models
can be employed. Unfortunately, these techniques are significantly hindered by
the fact that these generative models often produce invalid sequences. As a
step towards solving this problem, we propose to learn a deep recurrent
validator model. Given a partial sequence, our model learns the probability of
that sequence occurring as the beginning of a full valid sequence. Thus this
identifies valid versus invalid sequences and crucially it also provides
insight about how individual sequence elements influence the validity of
discrete objects. To learn this model we propose an approach inspired by
seminal work in Bayesian active learning. On a synthetic dataset, we
demonstrate the ability of our model to distinguish valid and invalid
sequences. We believe this is a key step toward learning generative models that
faithfully produce valid discrete objects.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04465</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04469</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison of Decoding Strategies for CTC Acoustic Models</dc:title>
 <dc:creator>Zenkel, Thomas</dc:creator>
 <dc:creator>Sanabria, Ramon</dc:creator>
 <dc:creator>Metze, Florian</dc:creator>
 <dc:creator>Niehues, Jan</dc:creator>
 <dc:creator>Sperber, Matthias</dc:creator>
 <dc:creator>St&#xfc;ker, Sebastian</dc:creator>
 <dc:creator>Waibel, Alex</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Connectionist Temporal Classification has recently attracted a lot of
interest as it offers an elegant approach to building acoustic models (AMs) for
speech recognition. The CTC loss function maps an input sequence of observable
feature vectors to an output sequence of symbols. Output symbols are
conditionally independent of each other under CTC loss, so a language model
(LM) can be incorporated conveniently during decoding, retaining the
traditional separation of acoustic and linguistic components in ASR. For fixed
vocabularies, Weighted Finite State Transducers provide a strong baseline for
efficient integration of CTC AMs with n-gram LMs. Character-based neural LMs
provide a straight forward solution for open vocabulary speech recognition and
all-neural models, and can be decoded with beam search. Finally,
sequence-to-sequence models can be used to translate a sequence of individual
sounds into a word string. We compare the performance of these three
approaches, and analyze their error patterns, which provides insightful
guidance for future research and development in this important area.
</dc:description>
 <dc:description>Comment: 5 pages. To appear in Interspeech 2017</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04479</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble Methods for Personalized E-Commerce Search Challenge at CIKM
  Cup 2016</dc:title>
 <dc:creator>Wu, Chen</dc:creator>
 <dc:creator>Yan, Ming</dc:creator>
 <dc:creator>Si, Luo</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Personalized search has been a hot research topic for many years and has been
widely used in e-commerce. This paper describes our solution to tackle the
challenge of personalized e-commerce search at CIKM Cup 2016. The goal of this
competition is to predict search relevance and re-rank the result items in SERP
according to the personalized search, browsing and purchasing preferences.
Based on a detailed analysis of the provided data, we extract three different
types of features, i.e., statistic features, query-item features and session
features. Different models are used on these features, including logistic
regression, gradient boosted decision trees, rank svm and a novel deep match
model. With the blending of multiple models, a stacking ensemble model is built
to integrate the output of individual models and produce a more accurate
prediction result. Based on these efforts, our solution won the champion of the
competition on all the evaluation metrics.
</dc:description>
 <dc:description>Comment: First Place Solution at CIKM Cup 2016 Track 2</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04479</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04483</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning with Rethinking: Recurrently Improving Convolutional Neural
  Networks through Feedback</dc:title>
 <dc:creator>Li, Xin</dc:creator>
 <dc:creator>Jie, Zequn</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Liu, Changsong</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent years have witnessed the great success of convolutional neural network
(CNN) based models in the field of computer vision. CNN is able to learn
hierarchically abstracted features from images in an end-to-end training
manner. However, most of the existing CNN models only learn features through a
feedforward structure and no feedback information from top to bottom layers is
exploited to enable the networks to refine themselves. In this paper, we
propose a &quot;Learning with Rethinking&quot; algorithm. By adding a feedback layer and
producing the emphasis vector, the model is able to recurrently boost the
performance based on previous prediction. Particularly, it can be employed to
boost any pre-trained models. This algorithm is tested on four object
classification benchmark datasets: CIFAR-100, CIFAR-10, MNIST-background-image
and ILSVRC-2012 dataset. These results have demonstrated the advantage of
training CNN models with the proposed feedback mechanism.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04485</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SCNN: An Accelerator for Compressed-sparse Convolutional Neural Networks</dc:title>
 <dc:creator>Parashar, Angshuman</dc:creator>
 <dc:creator>Rhu, Minsoo</dc:creator>
 <dc:creator>Mukkara, Anurag</dc:creator>
 <dc:creator>Puglielli, Antonio</dc:creator>
 <dc:creator>Venkatesan, Rangharajan</dc:creator>
 <dc:creator>Khailany, Brucek</dc:creator>
 <dc:creator>Emer, Joel</dc:creator>
 <dc:creator>Keckler, Stephen W.</dc:creator>
 <dc:creator>Dally, William J.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Convolutional Neural Networks (CNNs) have emerged as a fundamental technology
for machine learning. High performance and extreme energy efficiency are
critical for deployments of CNNs in a wide range of situations, especially
mobile platforms such as autonomous vehicles, cameras, and electronic personal
assistants. This paper introduces the Sparse CNN (SCNN) accelerator
architecture, which improves performance and energy efficiency by exploiting
the zero-valued weights that stem from network pruning during training and
zero-valued activations that arise from the common ReLU operator applied during
inference. Specifically, SCNN employs a novel dataflow that enables maintaining
the sparse weights and activations in a compressed encoding, which eliminates
unnecessary data transfers and reduces storage requirements. Furthermore, the
SCNN dataflow facilitates efficient delivery of those weights and activations
to the multiplier array, where they are extensively reused. In addition, the
accumulation of multiplication products are performed in a novel accumulator
array. Our results show that on contemporary neural networks, SCNN can improve
both performance and energy by a factor of 2.7x and 2.3x, respectively, over a
comparably provisioned dense CNN accelerator.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04495</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysing Relations involving small number of Monomials in AES S- Box</dc:title>
 <dc:creator>Ghosal, Riddhi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In the present day, AES is one the most widely used and most secure
Encryption Systems prevailing. So, naturally lots of research work is going on
to mount a significant attack on AES. Many different forms of Linear and
differential cryptanalysis have been performed on AES. Of late, an active area
of research has been Algebraic Cryptanalysis of AES, where although fast
progress is being made, there are still numerous scopes for research and
improvement. One of the major reasons behind this being that algebraic
cryptanalysis mainly depends on I/O relations of the AES S- Box (a major
component of the AES). As, already known, that the key recovery algorithm of
AES can be broken down as an MQ problem which is itself considered hard.
Solving these equations depends on our ability reduce them into linear forms
which are easily solvable under our current computational prowess. The lower
the degree of these equations, the easier it is for us to linearlize hence the
attack complexity reduces. The aim of this paper is to analyze the various
relations involving small number of monomials of the AES S- Box and to answer
the question whether it is actually possible to have such monomial equations
for the S- Box if we restrict the degree of the monomials. In other words this
paper aims to study such equations and see if they can be applicable for AES.
</dc:description>
 <dc:description>Comment: 5 pages, 1 table</dc:description>
 <dc:date>2017-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04497</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SPMC: Socially-Aware Personalized Markov Chains for Sparse Sequential
  Recommendation</dc:title>
 <dc:creator>Cai, Chenwei</dc:creator>
 <dc:creator>He, Ruining</dc:creator>
 <dc:creator>McAuley, Julian</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Dealing with sparse, long-tailed datasets, and cold-start problems is always
a challenge for recommender systems. These issues can partly be dealt with by
making predictions not in isolation, but by leveraging information from related
events; such information could include signals from social relationships or
from the sequence of recent activities. Both types of additional information
can be used to improve the performance of state-of-the-art matrix
factorization-based techniques. In this paper, we propose new methods to
combine both social and sequential information simultaneously, in order to
further improve recommendation performance. We show these techniques to be
particularly effective when dealing with sparsity and cold-start issues in
several large, real-world datasets.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, 3 tables, accepted to IJCAI 2017</dc:description>
 <dc:date>2017-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04498</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-adaptive node-based PCA encodings</dc:title>
 <dc:creator>Johard, Leonard</dc:creator>
 <dc:creator>Rivera, Victor</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:creator>Lee, JooYoung</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this paper we propose an algorithm, Simple Hebbian PCA, and prove that it
is able to calculate the principal component analysis (PCA) in a distributed
fashion across nodes. It simplifies existing network structures by removing
intralayer weights, essentially cutting the number of weights that need to be
trained in half.
</dc:description>
 <dc:date>2017-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04500</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient and Secure Routing Protocol for WSN-A Thesis</dc:title>
 <dc:creator>Ganesh, S.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Advances in Wireless Sensor Network (WSN) have provided the availability of
small and low-cost sensors with the capability of sensing various types of
physical and environmental conditions, data processing, and wireless
communication. Since WSN protocols are application specific, the focus has been
given to the routing protocols that might differ depending on the application
and network architecture. In this work, novel routing protocols have been
proposed which is a cluster-based security protocol is named as Efficient and
Secure Routing Protocol (ESRP) for WSN. The goal of ESRP is to provide an
energy efficient routing solution with dynamic security features for clustered
WSN. During the network formation, a node which is connected to a Personal
Computer (PC) has been selected as a sink node. Once the sensor nodes were
deployed, the sink node logically segregates the other nodes in a cluster
structure and subsequently creates a WSN. This centralized cluster formation
method is used to reduce the node level processing burden and avoid multiple
communications. In order to ensure reliable data delivery, various security
features have been incorporated in the proposed protocol such as Modified
Zero-Knowledge Protocol (MZKP), Promiscuous hearing method, Trapping of
adversaries and Mine detection. One of the unique features of this ESRP is that
it can dynamically decide about the selection of these security methods, based
on the residual energy of nodes.
</dc:description>
 <dc:description>Comment: 183 Pages,52 Figurs</dc:description>
 <dc:date>2017-06-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04501</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear algebraic analogues of the graph isomorphism problem and the
  Erd\H{o}s-R\'enyi model</dc:title>
 <dc:creator>Li, Yinan</dc:creator>
 <dc:creator>Qiao, Youming</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:description>  A classical difficult isomorphism testing problem is to test isomorphism of
p-groups of class 2 and exponent p in time polynomial in the group order. It is
known that this problem can be reduced to solving the alternating matrix space
isometry problem over a finite field in time polynomial in the underlying
vector space size. We propose a venue of attack for the latter problem by
viewing it as a linear algebraic analogue of the graph isomorphism problem.
This viewpoint leads us to explore the possibility of transferring techniques
for graph isomorphism to this long-believed bottleneck case of group
isomorphism.
  In 1970's, Babai, Erd\H{o}s, and Selkow presented the first average-case
efficient graph isomorphism testing algorithm (SIAM J Computing, 1980).
Inspired by that algorithm, we devise an average-case efficient algorithm for
the alternating matrix space isometry problem over a key range of parameters,
in a random model of alternating matrix spaces in vein of the Erd\H{o}s-R\'enyi
model of random graphs. For this, we develop a linear algebraic analogue of the
classical individualisation technique, a technique belonging to a set of
combinatorial techniques that has been critical for the progress on the
worst-case time complexity for graph isomorphism, but was missing in the group
isomorphism context. As a consequence of the main algorithm, we establish a
weaker linear algebraic analogue of Erd\H{o}s and R\'enyi's classical result
that most graphs have the trivial automorphism group. We finally show that
Luks' dynamic programming technique for graph isomorphism (STOC 1999) can be
adapted to slightly improve the worst-case time complexity of the alternating
matrix space isometry problem in a certain range of parameters.
</dc:description>
 <dc:description>Comment: 32 pages, 2 figures. The implication to group enumeration corrected</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-10-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04503</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pathological Pulmonary Lobe Segmentation from CT Images using
  Progressive Holistically Nested Neural Networks and Random Walker</dc:title>
 <dc:creator>George, Kevin</dc:creator>
 <dc:creator>Harrison, Adam P.</dc:creator>
 <dc:creator>Jin, Dakai</dc:creator>
 <dc:creator>Xu, Ziyue</dc:creator>
 <dc:creator>Mollura, Daniel J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic pathological pulmonary lobe segmentation(PPLS) enables regional
analyses of lung disease, a clinically important capability. Due to often
incomplete lobe boundaries, PPLS is difficult even for experts, and most prior
art requires inference from contextual information. To address this, we propose
a novel PPLS method that couples deep learning with the random walker (RW)
algorithm. We first employ the recent progressive holistically-nested network
(P-HNN) model to identify potential lobar boundaries, then generate final
segmentations using a RW that is seeded and weighted by the P-HNN output. We
are the first to apply deep learning to PPLS. The advantages are independence
from prior airway/vessel segmentations, increased robustness in diseased lungs,
and methodological simplicity that does not sacrifice accuracy. Our method
posts a high mean Jaccard score of 0.888$\pm$0.164 on a held-out set of 154 CT
scans from lung-disease patients, while also significantly (p &lt; 0.001)
outperforming a state-of-the-art method.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04512</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DesnowNet: Context-Aware Deep Network for Snow Removal</dc:title>
 <dc:creator>Liu, Yun-Fu</dc:creator>
 <dc:creator>Jaw, Da-Wei</dc:creator>
 <dc:creator>Huang, Shih-Chia</dc:creator>
 <dc:creator>Hwang, Jenq-Neng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Existing learning-based atmospheric particle-removal approaches such as those
used for rainy and hazy images are designed with strong assumptions regarding
spatial frequency, trajectory, and translucency. However, the removal of snow
particles is more complicated because it possess the additional attributes of
particle size and shape, and these attributes may vary within a single image.
Currently, hand-crafted features are still the mainstream for snow removal,
making significant generalization difficult to achieve. In response, we have
designed a multistage network codenamed DesnowNet to in turn deal with the
removal of translucent and opaque snow particles. We also differentiate snow
into attributes of translucency and chromatic aberration for accurate
estimation. Moreover, our approach individually estimates residual complements
of the snow-free images to recover details obscured by opaque snow.
Additionally, a multi-scale design is utilized throughout the entire network to
model the diversity of snow. As demonstrated in experimental results, our
approach outperforms state-of-the-art learning-based atmospheric phenomena
removal methods and one semantic segmentation baseline on the proposed Snow100K
dataset in both qualitative and quantitative comparisons. The results indicate
our network would benefit applications involving computer vision and graphics.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04513</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Switching Networks</dc:title>
 <dc:creator>Khalili, A. M.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The concept of emergence is a powerful concept to explain very complex
behaviour by simple underling rules. Existing approaches of producing emergent
collective behaviour have many limitations making them unable to account for
the complexity we see in the real world. In this paper we propose a new
dynamic, non-local, and time independent approach that uses a network like
structure to implement the laws or the rules, where the mathematical equations
representing the rules are converted to a series of switching decisions carried
out by the network on the particles moving in the network. The proposed
approach is used to generate patterns with different types of symmetry.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04517</identifier>
 <datestamp>2017-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-Preserving Mechanisms for Parametric Survival Analysis with
  Weibull Distribution</dc:title>
 <dc:creator>Nguy&#xea;n, Th&#xf4;ng T.</dc:creator>
 <dc:creator>Hui, Siu Cheung</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Survival analysis studies the statistical properties of the time until an
event of interest occurs. It has been commonly used to study the effectiveness
of medical treatments or the lifespan of a population. However, survival
analysis can potentially leak confidential information of individuals in the
dataset. The state-of-the-art techniques apply ad-hoc privacy-preserving
mechanisms on publishing results to protect the privacy. These techniques
usually publish sanitized and randomized answers which promise to protect the
privacy of individuals in the dataset but without providing any formal
mechanism on privacy protection. In this paper, we propose private mechanisms
for parametric survival analysis with Weibull distribution. We prove that our
proposed mechanisms achieve differential privacy, a robust and rigorous
definition of privacy-preservation. Our mechanisms exploit the property of
local sensitivity to carefully design a utility function which enables us to
publish parameters of Weibull distribution with high precision. Our
experimental studies show that our mechanisms can publish useful answers and
outperform other differentially private techniques on real datasets.
</dc:description>
 <dc:description>Comment: 8 pages, Trustcom17</dc:description>
 <dc:date>2017-07-01</dc:date>
 <dc:date>2017-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04523</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Room-temperature solid state quantum emitters in the telecom range</dc:title>
 <dc:creator>Zhou, Yu</dc:creator>
 <dc:creator>Wang, Ziyu</dc:creator>
 <dc:creator>Rasmita, Abdullah</dc:creator>
 <dc:creator>Kim, Sejeong</dc:creator>
 <dc:creator>Berhane, Amanuel</dc:creator>
 <dc:creator>Bodrog, Zoltan</dc:creator>
 <dc:creator>Adamo, Giorgio</dc:creator>
 <dc:creator>Gali, Adam</dc:creator>
 <dc:creator>Aharonovich, Igor</dc:creator>
 <dc:creator>Gao, Wei-bo</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Physics - Applied Physics</dc:subject>
 <dc:description>  On demand single photon emitters (SPEs) play a key role across a broad range
of quantum technologies, including quantum computation, quantum simulation,
quantum metrology and quantum communications. In quantum networks and quantum
key distribution protocols, where photons are employed as flying qubits,
telecom wavelength operation is preferred due to the reduced fibre loss.
However, despite the tremendous efforts to develop various triggered SPE
platforms, a robust source of triggered SPEs operating at room temperature and
the telecom wavelength is still missing. Here we report a triggered, optically
stable, room temperature solid state SPE operating at telecom wavelengths. The
emitters exhibit high photon purity (~ 5% multiphoton events) and a record-high
brightness of ~ 1.5 MHz. The emission is attributed to localized defects in a
gallium nitride (GaN) crystal. The high performance SPEs embedded in a
technologically mature semiconductor are promising for on-chip quantum
simulators and practical quantum communication technologies.
</dc:description>
 <dc:description>Comment: Comments welcome</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04524</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ThermalSim: A Thermal Simulator for Error Analysis</dc:title>
 <dc:creator>Jain, Milan</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Researchers have extensively explored predictive control strategies for
controlling heating, ventilation, and air conditioning (HVAC) units in
commercial buildings. Predictive control strategies, however, critically rely
on weather and occupancy forecasts. Existing state-of-the-art building
simulators are incapable of analysing the influence of prediction errors (in
weather and occupancy) on HVAC energy consumption and occupant comfort. In this
paper, we introduce ThermalSim, a building simulator that can quantify the
effect of prediction errors on the HVAC operations. ThermalSim has been
implemented in C/C++ and MATLAB. We describe its design, use, and input format.
</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04529</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning from Noisy Label Distributions</dc:title>
 <dc:creator>Yoshikawa, Yuya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we consider a novel machine learning problem, that is,
learning a classifier from noisy label distributions. In this problem, each
instance with a feature vector belongs to at least one group. Then, instead of
the true label of each instance, we observe the label distribution of the
instances associated with a group, where the label distribution is distorted by
an unknown noise. Our goals are to (1) estimate the true label of each
instance, and (2) learn a classifier that predicts the true label of a new
instance. We propose a probabilistic model that considers true label
distributions of groups and parameters that represent the noise as hidden
variables. The model can be learned based on a variational Bayesian method. In
numerical experiments, we show that the proposed model outperforms existing
methods in terms of the estimation of the true labels of instances.
</dc:description>
 <dc:description>Comment: Accepted in ICANN2017</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04529</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04531</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Non-Exhaustive Classification for Active Online Name
  Disambiguation</dc:title>
 <dc:creator>Zhang, Baichuan</dc:creator>
 <dc:creator>Dundar, Murat</dc:creator>
 <dc:creator>Hasan, Mohammad Al</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The name disambiguation task partitions a collection of records pertaining to
a given name, such that there is a one-to-one correspondence between the
partitions and a group of people, all sharing that given name. Most existing
solutions for this task are proposed for static data. However, more realistic
scenarios stipulate emergence of records in a streaming fashion where records
may belong to known as well as unknown persons all sharing the same name. This
requires a flexible name disambiguation algorithm that can not only classify
records of known persons represented in the train- ing data by their existing
records but can also identify records of new ambiguous persons with no existing
records included in the initial training dataset. Toward achieving this
objective, in this paper we propose a Bayesian non-exhaustive classification
frame- work for solving online name disambiguation. In particular, we present a
Dirichlet Process Gaussian Mixture Model (DPGMM) as a core engine for online
name disambiguation task. Meanwhile, two online inference algorithms, namely
one-pass Gibbs sampler and Sequential Importance Sampling with Resampling (also
known as particle filtering), are proposed to simultaneously perform online
classification and new class discovery. As a case study we consider
bibliographic data in a temporal stream format and disambiguate authors by
partitioning their papers into homogeneous groups.Our experimental results
demonstrate that the proposed method is significantly better than existing
methods for performing online name disambiguation task. We also propose an
interactive version of our online name disambiguation method designed to
leverage user feedback to improve prediction accuracy.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1607.05746</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04536</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polynomial-time algorithms for the Longest Induced Path and Induced
  Disjoint Paths problems on graphs of bounded mim-width</dc:title>
 <dc:creator>Jaffke, Lars</dc:creator>
 <dc:creator>Kwon, O-joung</dc:creator>
 <dc:creator>Telle, Jan Arne</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>05C85</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We give the first polynomial-time algorithms on graphs of bounded maximum
induced matching width (mim-width) for problems that are not locally checkable.
In particular, we give $n^{\mathcal{O}(w)}$-time algorithms on graphs of
mim-width at most $w$, when given a decomposition, for the following problems:
Longest Induced Path, Induced Disjoint Paths and $H$-Induced Topological Minor
for fixed $H$. Our results imply that the following graph classes have
polynomial-time algorithms for these three problems: Interval and Bi-Interval
graphs, Circular Arc, Permutation and Circular Permutation graphs, Convex
graphs, $k$-Trapezoid, Circular $k$-Trapezoid, $k$-Polygon, Dilworth-$k$ and
Co-$k$-Degenerate graphs for fixed $k$.
</dc:description>
 <dc:description>Comment: 20 pages, 4 figures; accepted at IPEC 2017</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04538</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artistic style transfer for videos and spherical images</dc:title>
 <dc:creator>Ruder, Manuel</dc:creator>
 <dc:creator>Dosovitskiy, Alexey</dc:creator>
 <dc:creator>Brox, Thomas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Manually re-drawing an image in a certain artistic style takes a professional
artist a long time. Doing this for a video sequence single-handedly is beyond
imagination. We present two computational approaches that transfer the style
from one image (for example, a painting) to a whole video sequence. In our
first approach, we adapt to videos the original image style transfer technique
by Gatys et al. based on energy minimization. We introduce new ways of
initialization and new loss functions to generate consistent and stable
stylized video sequences even in cases with large motion and strong occlusion.
Our second approach formulates video stylization as a learning problem. We
propose a deep network architecture and training procedures that allow us to
stylize arbitrary-length videos in a consistent and stable way, and nearly in
real time. We show that the proposed methods clearly outperform simpler
baselines both qualitatively and quantitatively. Finally, we propose a way to
adapt these approaches also to 360 degree images and videos as they emerge with
recent virtual reality hardware.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1604.08610</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04539</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PSelInv - A Distributed Memory Parallel Algorithm for Selected
  Inversion: the non-symmetric Case</dc:title>
 <dc:creator>Jacquelin, Mathias</dc:creator>
 <dc:creator>Lin, Lin</dc:creator>
 <dc:creator>Yang, Chao</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  This paper generalizes the parallel selected inversion algorithm called
PSelInv to sparse non- symmetric matrices. We assume a general sparse matrix A
has been decomposed as PAQ = LU on a distributed memory parallel machine, where
L, U are lower and upper triangular matrices, and P, Q are permutation
matrices, respectively. The PSelInv method computes selected elements of A-1.
The selection is confined by the sparsity pattern of the matrix AT . Our
algorithm does not assume any symmetry properties of A, and our parallel
implementation is memory efficient, in the sense that the computed elements of
A-T overwrites the sparse matrix L+U in situ. PSelInv involves a large number
of collective data communication activities within different processor groups
of various sizes. In order to minimize idle time and improve load balancing,
tree-based asynchronous communication is used to coordinate all such collective
communication. Numerical results demonstrate that PSelInv can scale efficiently
to 6,400 cores for a variety of matrices.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1404.0447</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04540</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum estimation of detection efficiency with no-knowledge quantum
  feedback</dc:title>
 <dc:creator>Xie, Dong</dc:creator>
 <dc:creator>Xu, Chunling</dc:creator>
 <dc:creator>Chen, Jianyong</dc:creator>
 <dc:creator>Wang, Anmin</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We investigate that no-knowledge measurement-based feedback control is
utilized to obtain the estimation precision of the detection efficiency. For
the feedback operators that concern us, no-knowledge measurement is the optimal
way to estimate the detection efficiency. We show that the higher precision can
be achieved for the lower or larger detection efficiency. It is found that
no-knowledge feedback can be used to cancel decoherence. No-knowledge feedback
with a high detection efficiency can perform well in estimating frequency and
detection efficiency parameters simultaneously. And simultaneous estimation is
better than independent estimation given by the same probes.
</dc:description>
 <dc:description>Comment: 7pages, 3figures</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04544</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sample Efficient Estimation and Recovery in Sparse FFT via Isolation on
  Average</dc:title>
 <dc:creator>Kapralov, Michael</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The problem of computing the Fourier Transform of a signal whose spectrum is
dominated by a small number $k$ of frequencies quickly and using a small number
of samples of the signal in time domain (the Sparse FFT problem) has received
significant attention recently. It is known how to approximately compute the
$k$-sparse Fourier transform in $\approx k\log^2 n$ time [Hassanieh et
al'STOC'12], or using the optimal number $O(k\log n)$ of samples [Indyk et
al'FOCS'14] in time domain, or come within $(\log\log n)^{O(1)}$ factors of
both these bounds simultaneously, but no algorithm achieving the optimal
$O(k\log n)$ bound in sublinear time is known.
  In this paper we propose a new technique for analysing noisy hashing schemes
that arise in Sparse FFT, which we refer to as isolation on average. We apply
this technique to two problems in Sparse FFT: estimating the values of a list
of frequencies using few samples and computing Sparse FFT itself, achieving
sample-optimal results in $k\log^{O(1)} n$ time for both. We feel that our
approach will likely be of interest in designing Fourier sampling schemes for
more general settings (e.g. model based Sparse FFT).
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04552</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Regularization of Convolutional Neural Networks with Cutout</dc:title>
 <dc:creator>DeVries, Terrance</dc:creator>
 <dc:creator>Taylor, Graham W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks are capable of learning powerful
representational spaces, which are necessary for tackling complex learning
tasks. However, due to the model capacity required to capture such
representations, they are often susceptible to overfitting and therefore
require proper regularization in order to generalize well. In this paper, we
show that the simple regularization technique of randomly masking out square
regions of input during training, which we call cutout, can be used to improve
the robustness and overall performance of convolutional neural networks. Not
only is this method extremely easy to implement, but we also demonstrate that
it can be used in conjunction with existing forms of data augmentation and
other regularizers to further improve model performance. We evaluate this
method by applying it to current state-of-the-art architectures on the
CIFAR-10, CIFAR-100, and SVHN datasets, yielding new state-of-the-art results
of 2.56%, 15.20%, and 1.30% test error respectively. Code is available at
https://github.com/uoguelph-mlrg/Cutout
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04557</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Database of Parliamentary Speeches in Ireland, 1919-2013</dc:title>
 <dc:creator>Herzog, Alexander</dc:creator>
 <dc:creator>Mikhaylov, Slava J.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a database of parliamentary debates that contains the complete
record of parliamentary speeches from D\'ail \'Eireann, the lower house and
principal chamber of the Irish parliament, from 1919 to 2013. In addition, the
database contains background information on all TDs (Teachta D\'ala, members of
parliament), such as their party affiliations, constituencies and office
positions. The current version of the database includes close to 4.5 million
speeches from 1,178 TDs. The speeches were downloaded from the official
parliament website and further processed and parsed with a Python script.
Background information on TDs was collected from the member database of the
parliament website. Data on cabinet positions (ministers and junior ministers)
was collected from the official website of the government. A record linkage
algorithm and human coders were used to match TDs and ministers.
</dc:description>
 <dc:description>Comment: The database is made available on the Harvard Dataverse at
  http://dx.doi.org/10.7910/DVN/6MZN76</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04559</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Vs Rule Based Machine Translation; A Case Study on Indian
  Language Perspective</dc:title>
 <dc:creator>S, Sreelekha</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we present our work on a case study between Statistical Machien
Transaltion (SMT) and Rule-Based Machine Translation (RBMT) systems on
English-Indian langugae and Indian to Indian langugae perspective. Main
objective of our study is to make a five way performance compariosn; such as,
a) SMT and RBMT b) SMT on English-Indian langugae c) RBMT on English-Indian
langugae d) SMT on Indian to Indian langugae perspective e) RBMT on Indian to
Indian langugae perspective. Through a detailed analysis we describe the Rule
Based and the Statistical Machine Translation system developments and its
evaluations. Through a detailed error analysis, we point out the relative
strengths and weaknesses of both systems. The observations based on our study
are: a) SMT systems outperforms RBMT b) In the case of SMT, English to Indian
language MT systmes performs better than Indian to English langugae MT systems
c) In the case of RBMT, English to Indian langugae MT systems perofrms better
than Indian to Englsih Language MT systems d) SMT systems performs better for
Indian to Indian language MT systems compared to RBMT. Effectively, we shall
see that even with a small amount of training corpus a statistical machine
translation system has many advantages for high quality domain specific machine
translation over that of a rule-based counterpart.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1703.03666,
  arXiv:1702.08217</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04560</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Review of Internet of Things Architecture, Technologies and Analysis
  Smartphone-based Attacks Against 3D printers</dc:title>
 <dc:creator>Bilal, Muhammad</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Human beings cannot be happy with any kind of tiredness based work, so they
focused on machines to work on behalf of humans. The Internet-based latest
technology provides the platforms for human beings to relax and unburden
feeling. The Internet of Things (IoT) field efficiently helps human beings with
smart decisions through Machine-to-Machine (M2M) communication all over the
world. It has been difficult to ignore the importance of the IoT field with the
new development of applications such as a smartphone in the present era. The
IoT field sensor plays a vital role in sensing the intelligent object/things
and making an intelligent decision after sensing the objects. The rapid
development of new applications using smartphones in the world caused all users
of the IoT community to be faced with one major challenge of security in the
form of side channel attacks against highly intensive 3D printing systems. The
smartphone formulated Intellectual property (IP) of side channel attacks
investigate against 3D printer in the physical domain through reconstructed
G-code file through primitive operations. The smartphone (Nexus 5) solved the
main problems such as orientation fixing, model accuracy of frame size and
validate the feasibility and effectiveness in real case studies against the 3D
printer. The 3D printing estimated value reached 20.2 billion of dollars in
2021. The thermal camera is used for exploring the side channel attacks after
reconstructing the objects against 3D printers. The researcher analyzed IoT
security relevant issues which were avoided in future by enhanced strong
security mechanism strategy, encryption, and machine learning-based algorithms,
latest technologies, schemes and protocols utilized in an efficient way.
Keywords: - Internet of Things (IoT), Machine-to-Machine (M2M), Security, 3D
printer, smartphone
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2017-06-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04567</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GARDENIA: A Domain-specific Benchmark Suite for Next-generation
  Accelerators</dc:title>
 <dc:creator>Xu, Zhen</dc:creator>
 <dc:creator>Chen, Xuhao</dc:creator>
 <dc:creator>Shen, Jie</dc:creator>
 <dc:creator>Zhang, Yang</dc:creator>
 <dc:creator>Chen, Cheng</dc:creator>
 <dc:creator>Yang, Canqun</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  This paper presents the Graph Analytics Repository for Designing
Next-generation Accelerators (GARDENIA), a benchmark suite for studying
irregular algorithms on massively parallel accelerators. Existing generic
benchmarks for accelerators have mainly focused on high performance computing
(HPC) applications with limited control and data irregularity, while available
graph analytics benchmarks do not apply state-of-the-art algorithms and/or
optimization techniques. GARDENIA includes emerging irregular applications in
big-data and machine learning domains which mimic massively multithreaded
commercial programs running on modern large-scale datacenters. Our
characterization shows that GARDENIA exhibits irregular microarchitectural
behavior which is quite different from structured workloads and
straightforward-implemented graph benchmarks.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures, journal</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04571</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Machine Learning Based Intrusion Detection System for Software Defined
  5G Network</dc:title>
 <dc:creator>Li, Jiaqi</dc:creator>
 <dc:creator>Zhao, Zhifeng</dc:creator>
 <dc:creator>Li, Rongpeng</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  As an inevitable trend of future 5G networks, Software Defined architecture
has many advantages in providing central- ized control and flexible resource
management. But it is also confronted with various security challenges and
potential threats with emerging services and technologies. As the focus of
network security, Intrusion Detection Systems (IDS) are usually deployed
separately without collaboration. They are also unable to detect novel attacks
with limited intelligent abilities, which are hard to meet the needs of
software defined 5G. In this paper, we propose an intelligent intrusion system
taking the advances of software defined technology and artificial intelligence
based on Software Defined 5G architecture. It flexibly combines security
function mod- ules which are adaptively invoked under centralized management
and control with a globle view. It can also deal with unknown intrusions by
using machine learning algorithms. Evaluation results prove that the
intelligent intrusion detection system achieves a better performance.
</dc:description>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04575</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information flow reveals prediction limits in online social activity</dc:title>
 <dc:creator>Bagrow, James P.</dc:creator>
 <dc:creator>Liu, Xipei</dc:creator>
 <dc:creator>Mitchell, Lewis</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Modern society depends on the flow of information over online social
networks, and popular social platforms now generate significant behavioral
data. Yet it remains unclear what fundamental limits may exist when using these
data to predict the activities and interests of individuals. Here we apply
tools from information theory to estimate the predictive information content of
the writings of Twitter users and to what extent that information flows between
users. Distinct temporal and social effects are visible in the information
flow, and these estimates provide a fundamental bound on the predictive
accuracy achievable with these data. Due to the social flow of information, we
estimate that approximately 95% of the potential predictive accuracy attainable
for an individual is available within the social ties of that individual only,
without requiring the individual's data.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures, supporting material included</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04576</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhanced power grid evaluation through efficient stochastic model-based
  analysis</dc:title>
 <dc:creator>Masetti, Giulio</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Electrical infrastructures provide services at the basis of a number of
application sectors, several of which are critical from the perspective of
human life, environment or financials. Following the increasing trend in
electricity generation from renewable sources, pushed by the need to meet
sustainable energy goals in many countries, more sophisticated control
strategies are being adopted to regulate the operation of the electric power
system, driving electrical infrastructures towards the so called Smart Grid
scenario. It is therefore paramount to be assisted by technologies able to
analyze the Smart Grid behavior in critical scenarios, e.g. where cyber
malfunctions or grid disruptions occur. In this context, stochastic model-based
analysis are well suited to assess dependability and quality of service related
indicators, and continuous improvements in modeling strategies and system
models design are required. Thus, my PhD work addresses this topic by
contributing to study new Smart Grid scenarios, concerning the advanced
interplay between ICT and electrical infrastructures in presence of cyber
faults/attacks, define a new modeling approach, based on modularity and
composition, and start to study how to improve the electrical grid dynamics
representation. In this article these studies are briefly presented and
discussed.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04583</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Modeling Methods for Complex System with Separable Features</dc:title>
 <dc:creator>Chen, Chen</dc:creator>
 <dc:creator>Luo, Changtong</dc:creator>
 <dc:creator>Jiang, Zonglin</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Data-driven modeling plays an increasingly important role in different areas
of engineering. For most of existing methods, such as genetic programming (GP),
the convergence speed might be too slow for large scale problems with a large
number of variables. Fortunately, in many applications, the target models are
separable in some sense. In this paper, we analyze different types of
separability of some real-world engineering equations and establish a
mathematical model of generalized separable system (GS system). In order to get
the structure of the GS system, two concepts, namely block and factor are
introduced, and a special method, block and factor detection is also proposed,
in which the target model is decomposed into a number of blocks, further into
minimal blocks and factors. Compare to the conventional GP, the new method can
make large reductions to the search space. The minimal blocks and factors are
optimized and assembled with a global optimization search engine, low
dimensional simplex evolution (LDSE). An extensive study between the proposed
method and a state-of-the-art data-driven fitting tool, Eureqa, has been
presented with several man-made problems. Test results indicate that the
proposed method is more effective and efficient under all the investigated
cases.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1706.02281</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04584</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of Decoupling and Nonlinear PD Controller for Cruise Control of a
  Quadrotor</dc:title>
 <dc:creator>Arrosida, Hanum</dc:creator>
 <dc:creator>Effendi, Rusdhianto</dc:creator>
 <dc:creator>Agustinah, Trihastuti</dc:creator>
 <dc:creator>Pramudijanto, Josaphat</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Quadrotor is often used to accomplish various missions related to
surveillance, territory mapping, search and rescue, and other purposes.
Quadrotor is a nonlinear system with multiple input multiple output and has
stability issue due to external disturbance. These characteristics lead to
difficulty in cruise control of quadrotor automatically. Decoupling method is
used to eliminate the interaction of other control on rotational motion, then
the roll, pitch, and yaw angle can be controlled independently. Nonlinear PD
controller is obtained from invers model of control signal on a quad rotor and
it is used to control the translational motion in x and y axis with nonlinear
dynamics because of the influence the rotational angle. Simulation results show
that the proposed method can eliminate the control interaction of roll, pitch
and yaw angle, hence it works like single input single output system and
translational motion on x andy axis can achieve the expected trajectory
precisely.
</dc:description>
 <dc:description>Comment: Published in: 2015 International Seminar on Intelligent Technology
  and Its Applications</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04584</dc:identifier>
 <dc:identifier>doi:10.1109/ISITIA.2015.7219953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04585</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Capacity of Wireless Networks with Fractal and Hierarchical
  Social Communications</dc:title>
 <dc:creator>Chen, Ying</dc:creator>
 <dc:creator>Li, Rongpeng</dc:creator>
 <dc:creator>Zhao, Zhifeng</dc:creator>
 <dc:creator>Zhang, Honggang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The capacity of a wireless network with fractal and hierarchical social
communications is studied in this paper. Specifically, we mathematically
formulate the self-similarity of a fractal wireless network by a power-law
degree distribution $ P(k) $, and we capture the direct social connection
feature between two nodes with degree $ k_{1} $ and $ k_{2} $ by a joint
probability distribution $ P(k_{1},k_{2}) $. Firstly, for a fractal wireless
network with direct social communications, it is proved that the maximum
capacity is $ \Theta\left(\frac{1}{\sqrt{n\log n}}\right) $ with $ n $ denotes
the total number of nodes in the network, if the source node communicates with
one of its direct contacts randomly, and it can reach up to $
\Theta\left(\frac{1}{\log n}\right) $ if the two nodes with distance $ d $
communicate according to the probability in proportion to $ d^{-\beta} $.
Secondly, since humans might get in touch with others without direct connection
but through the inter-conneced users, the fractal wireless networks with
hierarchical social communications is studied as well, and the related capacity
is derived based on the results in the case with direct social communications.
Our results show that this capacity is mainly affected by the correlation
exponent $\epsilon$ of the fractal networks. The capacity is reduced in
proportional to $ \frac{1}{{\log n}} $ if $ 2&lt;\epsilon&lt;3 $, while the reduction
coefficient is $ \frac{1}{n} $ if $ \epsilon=3 $.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1705.09751</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04586</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Google Shopping Campaigns Structures With Query-Level
  Matching</dc:title>
 <dc:creator>Raffinot, Mathieu</dc:creator>
 <dc:creator>Rivi&#xe8;re, Romain</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  How to bid on a Google shopping account (set of shopping campaigns) with
query-level matching like in Google Adwords.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04587</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Summarization of Online Debates</dc:title>
 <dc:creator>Sanchan, Nattapong</dc:creator>
 <dc:creator>Aker, Ahmet</dc:creator>
 <dc:creator>Bontcheva, Kalina</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Debate summarization is one of the novel and challenging research areas in
automatic text summarization which has been largely unexplored. In this paper,
we develop a debate summarization pipeline to summarize key topics which are
discussed or argued in the two opposing sides of online debates. We view that
the generation of debate summaries can be achieved by clustering, cluster
labeling, and visualization. In our work, we investigate two different
clustering approaches for the generation of the summaries. In the first
approach, we generate the summaries by applying purely term-based clustering
and cluster labeling. The second approach makes use of X-means for clustering
and Mutual Information for labeling the clusters. Both approaches are driven by
ontologies. We visualize the results using bar charts. We think that our
results are a smooth entry for users aiming to receive the first impression
about what is discussed within a debate topic containing waste number of
argumentations.
</dc:description>
 <dc:description>Comment: Accepted and to be published in Natural Language Processing and
  Information Retrieval workshop, Recent Advances in Natural Language
  Processing 2017 (RANLP 2017)</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04589</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Effective Changes for Software Projects</dc:title>
 <dc:creator>Krishna, Rahul</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The primary motivation of much of software analytics is decision making. How
to make these decisions? Should one make decisions based on lessons that arise
from within a particular project? Or should one generate these decisions from
across multiple projects? This work is an attempt to answer these questions.
Our work was motivated by a realization that much of the current generation
software analytics tools focus primarily on prediction. Indeed prediction is a
useful task, but it is usually followed by &quot;planning&quot; about what actions need
to be taken. This research seeks to address the planning task by seeking
methods that support actionable analytics that offer clear guidance on what to
do. Specifically, we propose XTREE and BELLTREE algorithms for generating a set
of actionable plans within and across projects. Each of these plans, if
followed will improve the quality of the software project.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures. This a submission for ASE 2017 Doctoral Symposium</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04592</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gold Standard Online Debates Summaries and First Experiments Towards
  Automatic Summarization of Online Debate Data</dc:title>
 <dc:creator>Sanchan, Nattapong</dc:creator>
 <dc:creator>Aker, Ahmet</dc:creator>
 <dc:creator>Bontcheva, Kalina</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Usage of online textual media is steadily increasing. Daily, more and more
news stories, blog posts and scientific articles are added to the online
volumes. These are all freely accessible and have been employed extensively in
multiple research areas, e.g. automatic text summarization, information
retrieval, information extraction, etc. Meanwhile, online debate forums have
recently become popular, but have remained largely unexplored. For this reason,
there are no sufficient resources of annotated debate data available for
conducting research in this genre. In this paper, we collected and annotated
debate data for an automatic summarization task. Similar to extractive gold
standard summary generation our data contains sentences worthy to include into
a summary. Five human annotators performed this task. Inter-annotator
agreement, based on semantic similarity, is 36% for Cohen's kappa and 48% for
Krippendorff's alpha. Moreover, we also implement an extractive summarization
system for online debates and discuss prominent features for the task of
summarizing online debate data automatically.
</dc:description>
 <dc:description>Comment: accepted and presented at the CICLING 2017 - 18th International
  Conference on Intelligent Text Processing and Computational Linguistics</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04597</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient NPN Boolean Matching Algorithm Based on Structural
  Signature and Shannon Expansion</dc:title>
 <dc:creator>Zhang, Juling</dc:creator>
 <dc:creator>Yang, Guowu</dc:creator>
 <dc:creator>Hung, William N. N.</dc:creator>
 <dc:creator>Zhang, Yan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  An efficient pairwise Boolean matching algorithm to solve the problem of
matching single-output specified Boolean functions under input negation and/or
input permutation and/or output negation (NPN) is proposed in this paper. We
present the Structural Signature (SS) vector, which is composed of a 1st
signature value, two symmetry marks, and a group mark. As a necessary condition
for NPN Boolean matching, the structural signature is more effective than is
the traditional signature. Two Boolean functions, f and g, may be equivalent
when they have the same SS vector. The symmetry mark can distinguish symmetric
variables and asymmetric variables and search multiple variable mappings in a
single variable-mapping search operation, which reduces the search space
significantly. Updating the SS vector using Shannon decomposition provides
benefits in distinguishing unidentified variables, and the group mark and the
phase collision check discover incorrect variable mappings quickly, which also
speeds up the NPN Boolean matching process. Using the algorithm proposed in
this paper, we tested both equivalent and non-equivalent matching peeds on the
MCNC benchmark circuit sets and the random circuit sets. In the experiment, our
algorithm is two times faster than competitors when testing equivalent circuits
and averages at least one hundred times faster when testing non-equivalent
circuits. The experimental results show that our approach is highly effective
in solving the NPN Boolean matching problem.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04607</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Segmentation-Aware Convolutional Networks Using Local Attention Masks</dc:title>
 <dc:creator>Harley, Adam W.</dc:creator>
 <dc:creator>Derpanis, Konstantinos G.</dc:creator>
 <dc:creator>Kokkinos, Iasonas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce an approach to integrate segmentation information within a
convolutional neural network (CNN). This counter-acts the tendency of CNNs to
smooth information across regions and increases their spatial precision. To
obtain segmentation information, we set up a CNN to provide an embedding space
where region co-membership can be estimated based on Euclidean distance. We use
these embeddings to compute a local attention mask relative to every neuron
position. We incorporate such masks in CNNs and replace the convolution
operation with a &quot;segmentation-aware&quot; variant that allows a neuron to
selectively attend to inputs coming from its own region. We call the resulting
network a segmentation-aware CNN because it adapts its filters at each image
point according to local segmentation cues. We demonstrate the merit of our
method on two widely different dense prediction tasks, that involve
classification (semantic segmentation) and regression (optical flow). Our
results show that in semantic segmentation we can match the performance of
DenseCRFs while being faster and simpler, and in optical flow we obtain clearly
sharper responses than networks that do not use local attention masks. In both
cases, segmentation-aware convolution yields systematic improvements over
strong baselines. Source code for this work is available online at
http://cs.cmu.edu/~aharley/segaware.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04608</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Robust Consensus Algorithm for Current Sharing and Voltage Regulation
  in DC Microgrids</dc:title>
 <dc:creator>Cucuzzella, Michele</dc:creator>
 <dc:creator>Trip, Sebastian</dc:creator>
 <dc:creator>De Persis, Claudio</dc:creator>
 <dc:creator>Ferrara, Antonella</dc:creator>
 <dc:creator>van der Schaft, Arjan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper a novel distributed control algorithm for current sharing and
voltage regulation in Direct Current (DC) microgrids is proposed. The DC
microgrid is composed of several Distributed Generation units (DGus),
interfaced with Buck converters, and current loads. The considered model
permits an arbitrary network topology and is affected by unknown load demand
and modelling uncertainties. The proposed control strategy exploits a
communication network to achieve current sharing using a consensus-like
algorithm. Voltage regulation is achieved by constraining the system to a
suitable manifold. Two robust control strategies of Sliding Mode (SM) type are
developed to reach the desired manifold in a finite time. The proposed control
scheme is formally analyzed, proving the achievement of current sharing, while
guaranteeing that the average voltage of the microgrid is identical to the
average of the voltage references. The latter objective is often desired in
practical implementations, but difficult to obtain, even with advanced control
methodologies, rendering the proposed solution relevant for the further
deployment of DC microgrids.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04613</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time Load Prediction with High Velocity Smart Home Data Stream</dc:title>
 <dc:creator>Doblander, Christoph</dc:creator>
 <dc:creator>Strohbach, Martin</dc:creator>
 <dc:creator>Ziekow, Holger</dc:creator>
 <dc:creator>Jacobsen, Hans-Arno</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper addresses the use of smart-home sensor streams for continuous
prediction of energy loads of individual households which participate as an
agent in local markets. We introduces a new device level energy consumption
dataset recorded over three years wich includes high resolution energy
measurements from electrical devices collected within a pilot program. Using
data from that pilot, we analyze the applicability of various machine learning
mechanisms for continuous load prediction. Specifically, we address short-term
load prediction that is required for load balancing in electrical micro-grids.
We report on the prediction performance and the computational requirements of a
broad range of prediction mechanisms. Furthermore we present an architecture
and experimental evaluation when this prediction is applied in the stream.
</dc:description>
 <dc:description>Comment: 11 pages, 12 figures</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04617</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attentional Factorization Machines: Learning the Weight of Feature
  Interactions via Attention Networks</dc:title>
 <dc:creator>Xiao, Jun</dc:creator>
 <dc:creator>Ye, Hao</dc:creator>
 <dc:creator>He, Xiangnan</dc:creator>
 <dc:creator>Zhang, Hanwang</dc:creator>
 <dc:creator>Wu, Fei</dc:creator>
 <dc:creator>Chua, Tat-Seng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Factorization Machines (FMs) are a supervised learning approach that enhances
the linear regression model by incorporating the second-order feature
interactions. Despite effectiveness, FM can be hindered by its modelling of all
feature interactions with the same weight, as not all feature interactions are
equally useful and predictive. For example, the interactions with useless
features may even introduce noises and adversely degrade the performance. In
this work, we improve FM by discriminating the importance of different feature
interactions. We propose a novel model named Attentional Factorization Machine
(AFM), which learns the importance of each feature interaction from data via a
neural attention network. Extensive experiments on two real-world datasets
demonstrate the effectiveness of AFM. Empirically, it is shown on regression
task AFM betters FM with a $8.6\%$ relative improvement, and consistently
outperforms the state-of-the-art deep learning methods Wide&amp;Deep and DeepCross
with a much simpler structure and fewer model parameters. Our implementation of
AFM is publicly available at:
https://github.com/hexiangnan/attentional_factorization_machine
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04622</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning the Ising Model Near Criticality</dc:title>
 <dc:creator>Morningstar, Alan</dc:creator>
 <dc:creator>Melko, Roger G.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  It is well established that neural networks with deep architectures perform
better than shallow networks for many tasks in machine learning. In statistical
physics, while there has been recent interest in representing physical data
with generative modelling, the focus has been on shallow neural networks. A
natural question to ask is whether deep neural networks hold any advantage over
shallow networks in representing such data. We investigate this question by
using unsupervised, generative graphical models to learn the probability
distribution of a two-dimensional Ising system. Deep Boltzmann machines, deep
belief networks, and deep restricted Boltzmann networks are trained on thermal
spin configurations from this system, and compared to the shallow architecture
of the restricted Boltzmann machine. We benchmark the models, focussing on the
accuracy of generating energetic observables near the phase transition, where
these quantities are most difficult to approximate. Interestingly, after
training the generative networks, we observe that the accuracy essentially
depends only on the number of neurons in the first hidden layer of the network,
and not on other model details such as network depth or model type. This is
evidence that shallow networks are more efficient than deep networks at
representing physical probability distributions associated with Ising systems
near criticality.
</dc:description>
 <dc:description>Comment: 16 pages, 8 figures, 1 table</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04632</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Almost Well-Covered Graphs Without Short Cycles</dc:title>
 <dc:creator>Ekim, T&#x131;naz</dc:creator>
 <dc:creator>G&#xf6;z&#xfc;pek, Didem</dc:creator>
 <dc:creator>Hujdurovi&#x107;, Ademir</dc:creator>
 <dc:creator>Milani&#x10d;, Martin</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We study graphs in which the maximum and the minimum sizes of a maximal
independent set differ by exactly one. We call these graphs almost
well-covered, in analogy with the class of well-covered graphs, in which all
maximal independent sets have the same size. A characterization of graphs of
girth at least $8$ having exactly two different sizes of maximal independent
sets due to Finbow, Hartnell, and Whitehead implies a polynomial-time
recognition algorithm for the class of almost well-covered graphs of girth at
least $8$. We focus on the structure of almost well-covered graphs of girth at
least $6$. We give a complete structural characterization of a subclass of the
class of almost well-covered graphs of girth at least $6$, a polynomially
testable characterization of another one, and a polynomial-time recognition
algorithm of almost well-covered $\{C_3,C_4,C_5,C_7\}$-free graphs.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04632</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04634</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Derandomization Beyond Connectivity: Undirected Laplacian Systems in
  Nearly Logarithmic Space</dc:title>
 <dc:creator>Murtagh, Jack</dc:creator>
 <dc:creator>Reingold, Omer</dc:creator>
 <dc:creator>Sidford, Aaron</dc:creator>
 <dc:creator>Vadhan, Salil</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We give a deterministic $\tilde{O}(\log n)$-space algorithm for approximately
solving linear systems given by Laplacians of undirected graphs, and
consequently also approximating hitting times, commute times, and escape
probabilities for undirected graphs. Previously, such systems were known to be
solvable by randomized algorithms using $O(\log n)$ space (Doron, Le Gall, and
Ta-Shma, 2017) and hence by deterministic algorithms using $O(\log^{3/2} n)$
space (Saks and Zhou, FOCS 1995 and JCSS 1999).
  Our algorithm combines ideas from time-efficient Laplacian solvers (Spielman
and Teng, STOC `04; Peng and Spielman, STOC `14) with ideas used to show that
Undirected S-T Connectivity is in deterministic logspace (Reingold, STOC `05
and JACM `08; Rozenman and Vadhan, RANDOM `05).
</dc:description>
 <dc:description>Comment: 25 pages</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04636</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Driver Identification Using Automobile Sensor Data from a Single Turn</dc:title>
 <dc:creator>Hallac, David</dc:creator>
 <dc:creator>Sharang, Abhijit</dc:creator>
 <dc:creator>Stahlmann, Rainer</dc:creator>
 <dc:creator>Lamprecht, Andreas</dc:creator>
 <dc:creator>Huber, Markus</dc:creator>
 <dc:creator>Roehder, Martin</dc:creator>
 <dc:creator>Sosic, Rok</dc:creator>
 <dc:creator>Leskovec, Jure</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  As automotive electronics continue to advance, cars are becoming more and
more reliant on sensors to perform everyday driving operations. These sensors
are omnipresent and help the car navigate, reduce accidents, and provide
comfortable rides. However, they can also be used to learn about the drivers
themselves. In this paper, we propose a method to predict, from sensor data
collected at a single turn, the identity of a driver out of a given set of
individuals. We cast the problem in terms of time series classification, where
our dataset contains sensor readings at one turn, repeated several times by
multiple drivers. We build a classifier to find unique patterns in each
individual's driving style, which are visible in the data even on such a short
road segment. To test our approach, we analyze a new dataset collected by AUDI
AG and Audi Electronics Venture, where a fleet of test vehicles was equipped
with automotive data loggers storing all sensor readings on real roads. We show
that turns are particularly well-suited for detecting variations across
drivers, especially when compared to straightaways. We then focus on the 12
most frequently made turns in the dataset, which include rural, urban, highway
on-ramps, and more, obtaining accurate identification results and learning
useful insights about driver behavior in a variety of settings.
</dc:description>
 <dc:date>2017-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04649</identifier>
 <datestamp>2017-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning for Survival Analysis: A Survey</dc:title>
 <dc:creator>Wang, Ping</dc:creator>
 <dc:creator>Li, Yan</dc:creator>
 <dc:creator>Reddy, Chandan K.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Accurately predicting the time of occurrence of an event of interest is a
critical problem in longitudinal data analysis. One of the main challenges in
this context is the presence of instances whose event outcomes become
unobservable after a certain time point or when some instances do not
experience any event during the monitoring period. Such a phenomenon is called
censoring which can be effectively handled using survival analysis techniques.
Traditionally, statistical approaches have been widely developed in the
literature to overcome this censoring issue. In addition, many machine learning
algorithms are adapted to effectively handle survival data and tackle other
challenging problems that arise in real-world data. In this survey, we provide
a comprehensive and structured review of the representative statistical methods
along with the machine learning techniques used in survival analysis and
provide a detailed taxonomy of the existing methods. We also discuss several
topics that are closely related to survival analysis and illustrate several
successful applications in various real-world application domains. We hope that
this paper will provide a more thorough understanding of the recent advances in
survival analysis and offer some guidelines on applying these approaches to
solve new problems that arise in applications with censored data.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04649</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04653</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Usability Evaluation of a Mobile Application in Extraordinary
  Environment for Extraordinary People</dc:title>
 <dc:creator>Bhuiyan, Monir</dc:creator>
 <dc:creator>Zaman, Ambreen</dc:creator>
 <dc:creator>Miraz, Mahdi H.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In a contemporary world, people become dependent on electronic devices.
Technologies help to clarification and structure life in many ways to meet the
need of the children oriented requirements. The children suffering from
disabilities (e.g. autism) has desperate needs for elucidation and structures
their life. MumIES is a research based system facilitates to support and manage
their living. This paper works on MumIES system to evaluate usability of the
system in extraordinary environment for extraordinary people. The paper shows
from the survey observation users need supporting tools to access the
children's potential and challenges and to give the full support to overcome
disabilities. Usability evaluation has been considered one of the key
challenges to MumIES system. The paper represents analysis, design of usability
studies for the extraordinary user in environment.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04653</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on eBusiness,
  eCommerce, eManagement, eLearning and eGovernance (IC5E 2014), held at
  University of Greenwich, London, UK, 30-31 July 2014, pp. 96-103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04654</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>P-Governance Technology: Using Big Data for Political Party Management</dc:title>
 <dc:creator>Bhuiyan, Monir</dc:creator>
 <dc:creator>Haque, Rafikul</dc:creator>
 <dc:creator>Miraz, Mahdi H.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Information and Communication Technology (ICT) has been playing a pivotal
role since the last decade in developing countries that brings citizen services
to the doorsteps and connecting people. With this aspiration ICT has introduced
several technologies of citizen services towards all categories of people. The
purpose of this study is to examine the Governance technology perspectives for
political party, emphasizing on the basic critical steps through which it could
be operationalized. We call it P-Governance. P-Governance shows technologies to
ensure governance, management, interaction communication in a political party
by improving decision making processes using big data. P-Governance challenges
the competence perspective to apply itself more assiduously to
operationalization, including the need to choose and give definition to one or
more units of analysis (of which the routine is a promising candidate). This
paper is to focus on research challenges posed by competence to which
P-Governance can and should respond include different strategy issues faced by
particular sections. Both the qualitative as well as quantitative research
approaches were conducted. The standard of citizen services, choice &amp;
consultation, courtesy &amp; consultation, entrance &amp; information, and value for
money have found the positive relation with citizen's satisfaction. This study
results how can be technology make important roles on political movements in
developing countries using big data.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04654</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on eBusiness,
  eCommerce, eManagement, eLearning and eGovernance (IC5E 2014), held at
  University of Greenwich, London, UK, 30-31 July 2014, pp. 33-40</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04655</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile Academy: A Ubiquitous Mobile Learning (mLearning) Platform</dc:title>
 <dc:creator>Miraz, Mahdi H.</dc:creator>
 <dc:creator>Khan, Sajid</dc:creator>
 <dc:creator>Bhuiyan, Monir</dc:creator>
 <dc:creator>Excell, Peter</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The paper reports on an ongoing research project into the development of
&quot;Mobile Academy&quot;, an Android-based mobile learning (mLearning) application
(app). The project comprises three major phases: requirement analysis,
application development and testing and evaluation. To satisfy the user
requirement analysis, a detailed ethnographic study was conducted to
investigate how people from different background use mobile devices for
learning purposes. The initial analysis and evaluation of the first version of
the projected app demonstrates very promising results. Making use of the app
seemed to have, in general, a positive dimension in facilitating educational
use of mobile devices.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04655</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on eBusiness,
  eCommerce, eManagement, eLearning and eGovernance (IC5E 2014), held at
  University of Greenwich, London, UK, 30-31 July 2014, pp. 89-95</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04656</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Android Based Shopping Mall Applications</dc:title>
 <dc:creator>Khan, Sajid</dc:creator>
 <dc:creator>Shayokh, Md Al</dc:creator>
 <dc:creator>Miraz, Mahdi H.</dc:creator>
 <dc:creator>Bhuiyan, Monir</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Android is Google's latest open source software platform for mobile devices
which has already attained enormous popularity. The purpose of this paper is to
describe the development of mobile application for shopping mall using Android
platform. A prototype was developed for the shoppers of Bashundhara Shopping
Mall of Bangladesh. This prototype will serve as a framework for any such
applications (apps). The paper presents a practical demonstration of how to
integrate shops' information, such as names, categories, locations,
descriptions, floor layout and so forth, with map module via an android
application. A summary of survey results of the related literature and projects
have also been included. Critical Evaluation of the prototype along with future
research and development plan has been revealed. The paper will serve as a
guideline for the researchers and developers to introduce and develop similar
apps.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04656</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on eBusiness,
  eCommerce, eManagement, eLearning and eGovernance (IC5E 2014), held at
  University of Greenwich, London, UK, 30-31 July 2014, pp. 27-32</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04657</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guiding Network Analysis using Graph Slepians: An Illustration for the
  C. Elegans Connectome</dc:title>
 <dc:creator>Van De Ville, Dimitri</dc:creator>
 <dc:creator>Demesmaeker, Robin</dc:creator>
 <dc:creator>Preti, Maria Giulia</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Spectral approaches of network analysis heavily rely upon the
eigendecomposition of the graph Laplacian. For instance, in graph signal
processing, the Laplacian eigendecomposition is used to define the graph
Fourier transform and then transpose signal processing operations to graphs by
implementing them in the spectral domain. Here, we build on recent work that
generalized Slepian functions to the graph setting. In particular, graph
Slepians are band-limited graph signals with maximal energy concentration in a
given subgraph. We show how this approach can be used to guide network
analysis; i.e., we propose a visualization that reveals network organization of
a subgraph, but while striking a balance with global network structure. These
developments are illustrated for the structural connectome of the C. Elegans.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures, Proceedings of the SPIE Wavelets &amp; Sparsity XVII
  (August 2017)</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04662</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controlled Experiments with Student Participants in Software
  Engineering: Preliminary Results from a Systematic Mapping Study</dc:title>
 <dc:creator>Daun, Marian</dc:creator>
 <dc:creator>H&#xfc;bscher, Carolin</dc:creator>
 <dc:creator>Weyer, Thorsten</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  [Context] In software engineering research, emphasis is given to sound
evaluations of new approaches. While industry surveys or industrial case
studies are preferred to evaluate industrial applicability, controlled
experiments with student participants are commonly used to determine
measurements such as effectiveness and efficiency of a proposed approach.
[Objectives] In this paper, we elaborate on the current state of the art of
controlled experiments using student participants. As student participants are
commonly only reluctantly accepted in scientific communities and threats
regarding the generalizability are quite obvious, we want to determine how
widespread controlled experiments with student participants are and in which
settings they are used. [Methods] This paper reports on a systematic mapping
study using high-quality journals and conferences from the software engineering
field as data sources. We scanned all papers published between 2010 and 2014
and investigated all papers reporting student experiments in detail. [Results]
From 2788 papers under investigation 175 report results from controlled
experiments. 109 (62.29%) of these controlled experiments have been conducted
with student participants. Most experiments used undergraduate student
participants, recruited students on a voluntary basis, and set them tasks to
measure their comprehension. However, many experiments lack information
regarding the students' recruitment and other important factors. [Conclusions]
In conclusion, student participation in software engineering experiments can be
seen as a common evaluation approach. In contrast, there seems to be little
knowledge about the threats to validity in student experiments, as major
drivers such as the recruitment are not reported at all.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04664</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel data Pre-processing method for multi-dimensional and non-uniform
  data</dc:title>
 <dc:creator>Zareen, Farhana Javed</dc:creator>
 <dc:creator>Jabin, Suraiya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We are in the era of data analytics and data science which is on full bloom.
There is abundance of all kinds of data for example biometrics based data,
satellite images data, chip-seq data, social network data, sensor based data
etc. from a variety of sources. This data abundance is the result of the fact
that storage cost is getting cheaper day by day, so people as well as almost
all business or scientific organizations are storing more and more data. Most
of the real data is multi-dimensional, non-uniform, and big in size, such that
it requires a unique pre-processing before analyzing it. In order to make data
useful for any kind of analysis, pre-processing is a very important step. This
paper presents a unique and novel pre-processing method for multi-dimensional
and non-uniform data with the aim of making it uniform and reduced in size
without losing much of its value. We have chosen biometric signature data to
demonstrate the proposed method as it qualifies for the attributes of being
multi-dimensional, non-uniform and big in size. Biometric signature data does
not only captures the structural characteristics of a signature but also its
behavioral characteristics that are captured using a dynamic signature capture
device. These features like pen pressure, pen tilt angle, time taken to sign a
document when collected in real-time turn out to be of varying dimensions. This
feature data set along with the structural data needs to be pre-processed in
order to use it to train a machine learning based model for signature
verification purposes. We demonstrate the success of the proposed method over
other methods using experimental results for biometric signature data but the
same can be implemented for any other data with similar properties from a
different domain.
</dc:description>
 <dc:description>Comment: 11 pages, 4 Figures, 7 Tables</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04668</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beating the Multiplicative Weights Update Algorithm</dc:title>
 <dc:creator>Aggarwal, Abhinav</dc:creator>
 <dc:creator>Joo, Jos&#xe9; Abel Castellanos</dc:creator>
 <dc:creator>Gupta, Diksha</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Multiplicative weights update algorithms have been used extensively in
designing iterative algorithms for many computational tasks. The core idea is
to maintain a distribution over a set of experts and update this distribution
in an online fashion based on the parameters of the underlying optimization
problem. In this report, we study the behavior of a special MWU algorithm used
for generating a global coin flip in the presence of an adversary that tampers
the experts' advice. Specifically, we focus our attention on two adversarial
strategies: (1) non-adaptive, in which the adversary chooses a fixed set of
experts a priori and corrupts their advice in each round; and (2) adaptive, in
which this set is chosen as the rounds of the algorithm progress. We formulate
these adversarial strategies as being greedy in terms of trying to maximize the
share of the corrupted experts in the final weighted advice the MWU computes
and provide the underlying optimization problem that needs to be solved to
achieve this goal. We provide empirical results to show that in the presence of
either of the above adversaries, the MWU algorithm takes $\mathcal{O}(n)$
rounds in expectation to produce the desired output. This result compares well
with the current state of the art of $\mathcal{O}(n^3)$ for the general
Byzantine consensus problem. Finally, we briefly discuss the extension of these
adversarial strategies for a general MWU algorithm and provide an outline for
the framework in that setting.
</dc:description>
 <dc:description>Comment: Word done as part of UNM CS506 term paper</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04669</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Neural Networks for Non-iterative Reconstruction of
  Compressively Sensed Images</dc:title>
 <dc:creator>Lohit, Suhas</dc:creator>
 <dc:creator>Kulkarni, Kuldeep</dc:creator>
 <dc:creator>Kerviche, Ronan</dc:creator>
 <dc:creator>Turaga, Pavan</dc:creator>
 <dc:creator>Ashok, Amit</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Traditional algorithms for compressive sensing recovery are computationally
expensive and are ineffective at low measurement rates. In this work, we
propose a data driven non-iterative algorithm to overcome the shortcomings of
earlier iterative algorithms. Our solution, ReconNet, is a deep neural network,
whose parameters are learned end-to-end to map block-wise compressive
measurements of the scene to the desired image blocks. Reconstruction of an
image becomes a simple forward pass through the network and can be done in
real-time. We show empirically that our algorithm yields reconstructions with
higher PSNRs compared to iterative algorithms at low measurement rates and in
presence of measurement noise. We also propose a variant of ReconNet which uses
adversarial loss in order to further improve reconstruction quality. We discuss
how adding a fully connected layer to the existing ReconNet architecture allows
for jointly learning the measurement matrix and the reconstruction algorithm in
a single network. Experiments on real data obtained from a block compressive
imager show that our networks are robust to unseen sensor noise. Finally,
through an experiment in object tracking, we show that even at very low
measurement rates, reconstructions using our algorithm possess rich semantic
content that can be used for high level inference.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04670</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepFaceLIFT: Interpretable Personalized Models for Automatic Estimation
  of Self-Reported Pain</dc:title>
 <dc:creator>Liu, Dianbo</dc:creator>
 <dc:creator>Peng, Fengjiao</dc:creator>
 <dc:creator>Shea, Andrew</dc:creator>
 <dc:creator>Ognjen</dc:creator>
 <dc:creator>Rudovic</dc:creator>
 <dc:creator>Picard, Rosalind</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Previous research on automatic pain estimation from facial expressions has
focused primarily on &quot;one-size-fits-all&quot; metrics (such as PSPI). In this work,
we focus on directly estimating each individual's self-reported visual-analog
scale (VAS) pain metric, as this is considered the gold standard for pain
measurement. The VAS pain score is highly subjective and context-dependent, and
its range can vary significantly among different persons. To tackle these
issues, we propose a novel two-stage personalized model, named DeepFaceLIFT,
for automatic estimation of VAS. This model is based on (1) Neural Network and
(2) Gaussian process regression models, and is used to personalize the
estimation of self-reported pain via a set of hand-crafted personal features
and multi-task learning. We show on the benchmark dataset for pain analysis
(The UNBC-McMaster Shoulder Pain Expression Archive) that the proposed
personalized model largely outperforms the traditional, unpersonalized models:
the intra-class correlation improves from a baseline performance of 19\% to a
personalized performance of 35\% while also providing confidence in the
model\textquotesingle s estimates -- in contrast to existing models for the
target task. Additionally, DeepFaceLIFT automatically discovers the
pain-relevant facial regions for each person, allowing for an easy
interpretation of the pain-related facial cues.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04671</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence-to-Label Script Identification for Multilingual OCR</dc:title>
 <dc:creator>Fujii, Yasuhisa</dc:creator>
 <dc:creator>Driesen, Karel</dc:creator>
 <dc:creator>Baccash, Jonathan</dc:creator>
 <dc:creator>Hurst, Ash</dc:creator>
 <dc:creator>Popat, Ashok C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68T45</dc:subject>
 <dc:subject>I.7.5</dc:subject>
 <dc:description>  We describe a novel line-level script identification method. Previous work
repurposed an OCR model generating per-character script codes, counted to
obtain line-level script identification. This has two shortcomings. First, as a
sequence-to-sequence model it is more complex than necessary for the
sequence-to-label problem of line script identification. This makes it harder
to train and inefficient to run. Second, the counting heuristic may be
suboptimal compared to a learned model. Therefore we reframe line script
identification as a sequence-to-label problem and solve it using two
components, trained end-toend: Encoder and Summarizer. The encoder converts a
line image into a feature sequence. The summarizer aggregates the sequence to
classify the line. We test various summarizers with identical inception-style
convolutional networks as encoders. Experiments on scanned books and photos
containing 232 languages in 30 scripts show 16% reduction of script
identification error rate compared to the baseline. This improved script
identification reduces the character error rate attributable to script
misidentification by 33%.
</dc:description>
 <dc:description>Comment: ICDAR2017, The 14th IAPR International Conference on Document
  Analysis and Recognition, Kyoto, Japan</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04671</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04672</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeformNet: Free-Form Deformation Network for 3D Shape Reconstruction
  from a Single Image</dc:title>
 <dc:creator>Kurenkov, Andrey</dc:creator>
 <dc:creator>Ji, Jingwei</dc:creator>
 <dc:creator>Garg, Animesh</dc:creator>
 <dc:creator>Mehta, Viraj</dc:creator>
 <dc:creator>Gwak, JunYoung</dc:creator>
 <dc:creator>Choy, Christopher</dc:creator>
 <dc:creator>Savarese, Silvio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  3D reconstruction from a single image is a key problem in multiple
applications ranging from robotic manipulation to augmented reality. Prior
methods have tackled this problem through generative models which predict 3D
reconstructions as voxels or point clouds. However, these methods can be
computationally expensive and miss fine details. We introduce a new
differentiable layer for 3D data deformation and use it in DeformNet to learn a
model for 3D reconstruction-through-deformation. DeformNet takes an image
input, searches the nearest shape template from a database, and deforms the
template to match the query image. We evaluate our approach on the ShapeNet
dataset and show that - (a) the Free-Form Deformation layer is a powerful new
building block for Deep Learning models that manipulate 3D data (b) DeformNet
uses this FFD layer combined with shape retrieval for smooth and
detail-preserving 3D reconstruction of qualitatively plausible point clouds
with respect to a single query image (c) compared to other state-of-the-art 3D
reconstruction methods, DeformNet quantitatively matches or outperforms their
benchmarks by significant margins. For more information, visit:
https://deformnet-site.github.io/DeformNet-website/ .
</dc:description>
 <dc:description>Comment: 11 pages, 9 figures, NIPS</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04673</identifier>
 <datestamp>2017-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Acoustic Feature Learning via Deep Variational Canonical Correlation
  Analysis</dc:title>
 <dc:creator>Tang, Qingming</dc:creator>
 <dc:creator>Wang, Weiran</dc:creator>
 <dc:creator>Livescu, Karen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the problem of acoustic feature learning in the setting where we
have access to another (non-acoustic) modality for feature learning but not at
test time. We use deep variational canonical correlation analysis (VCCA), a
recently proposed deep generative method for multi-view representation
learning. We also extend VCCA with improved latent variable priors and with
adversarial learning. Compared to other techniques for multi-view feature
learning, VCCA's advantages include an intuitive latent variable interpretation
and a variational lower bound objective that can be trained end-to-end
efficiently. We compare VCCA and its extensions with previous feature learning
methods on the University of Wisconsin X-ray Microbeam Database, and show that
VCCA-based feature learning improves over previous methods for
speaker-independent phonetic recognition.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04673</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04675</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Graph While Training: An Evolving Graph Convolutional Neural
  Network</dc:title>
 <dc:creator>Li, Ruoyu</dc:creator>
 <dc:creator>Huang, Junzhou</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolution Neural Networks on Graphs are important generalization and
extension of classical CNNs. While previous works generally assumed that the
graph structures of samples are regular with unified dimensions, in many
applications, they are highly diverse or even not well defined. Under some
circumstances, e.g. chemical molecular data, clustering or coarsening for
simplifying the graphs is hard to be justified chemically. In this paper, we
propose a more general and flexible graph convolution network (EGCN) fed by
batch of arbitrarily shaped data together with their evolving graph Laplacians
trained in supervised fashion. Extensive experiments have been conducted to
demonstrate the superior performance in terms of both the acceleration of
parameter fitting and the significantly improved prediction accuracy on
multiple graph-structured datasets.
</dc:description>
 <dc:description>Comment: 10 pages, submitted to NIPS 2017</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04677</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Directions: Wireless Robotic Materials</dc:title>
 <dc:creator>Correll, Nikolaus</dc:creator>
 <dc:creator>Dutta, Prabal</dc:creator>
 <dc:creator>Han, Richard</dc:creator>
 <dc:creator>Pister, Kristofer</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We describe opportunities and challenges with wireless robotic materials.
Robotic materials are multi-functional composites that tightly integrate
sensing, actuation, computation and communication to create smart composites
that can sense their environment and change their physical properties in an
arbitrary programmable manner. Computation and communication in such materials
are based on miniature, possibly wireless, devices that are scattered in the
material and interface with sensors and actuators inside the material. Whereas
routing and processing of information within the material build upon results
from the field of sensor networks, robotic materials are pushing the limits of
sensor networks in both size (down to the order of microns) and numbers of
devices (up to the order of millions). In order to solve the algorithmic and
systems challenges of such an approach, which will involve not only computer
scientists, but also roboticists, chemists and material scientists, the
community requires a common platform - much like the &quot;Mote&quot; that bootstrapped
the widespread adoption of the field of sensor networks - that is small,
provides ample of computation, is equipped with basic networking
functionalities, and preferably can be powered wirelessly.
</dc:description>
 <dc:description>Comment: To appear at SenSys 2017</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04680</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Augmentor: An Image Augmentation Library for Machine Learning</dc:title>
 <dc:creator>Bloice, Marcus D.</dc:creator>
 <dc:creator>Stocker, Christof</dc:creator>
 <dc:creator>Holzinger, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The generation of artificial data based on existing observations, known as
data augmentation, is a technique used in machine learning to improve model
accuracy, generalisation, and to control overfitting. Augmentor is a software
package, available in both Python and Julia versions, that provides a high
level API for the expansion of image data using a stochastic, pipeline-based
approach which effectively allows for images to be sampled from a distribution
of augmented images at runtime. Augmentor provides methods for most standard
augmentation practices as well as several advanced features such as
label-preserving, randomised elastic distortions, and provides many helper
functions for typical augmentation tasks used in machine learning.
</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04681</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying Harm Events in Clinical Care through Medical Narratives</dc:title>
 <dc:creator>Cohan, Arman</dc:creator>
 <dc:creator>Fong, Allan</dc:creator>
 <dc:creator>Ratwani, Raj</dc:creator>
 <dc:creator>Goharian, Nazli</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Preventable medical errors are estimated to be among the leading causes of
injury and death in the United States. To prevent such errors, healthcare
systems have implemented patient safety and incident reporting systems. These
systems enable clinicians to report unsafe conditions and cases where patients
have been harmed due to errors in medical care. These reports are narratives in
natural language and while they provide detailed information about the
situation, it is non-trivial to perform large scale analysis for identifying
common causes of errors and harm to the patients. In this work, we present a
method based on attentive convolutional and recurrent networks for identifying
harm events in patient care and categorize the harm based on its severity
level. We demonstrate that our methods can significantly improve the
performance over existing methods in identifying harm in clinical care.
</dc:description>
 <dc:description>Comment: ACM-BCB 2017</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04681</dc:identifier>
 <dc:identifier>doi:10.1145/3107411.3107485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04682</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for Passive Synthetic Aperture Radar</dc:title>
 <dc:creator>Yonel, Bariscan</dc:creator>
 <dc:creator>Mason, Eric</dc:creator>
 <dc:creator>Yaz&#x131;c&#x131;, Birsen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  We introduce a deep learning (DL) framework for inverse problems in imaging,
and demonstrate the advantages and applicability of this approach in passive
synthetic aperture radar (SAR) image reconstruction. We interpret image recon-
struction as a machine learning task and utilize deep networks as forward and
inverse solvers for imaging. Specifically, we design a recurrent neural network
(RNN) architecture as an inverse solver based on the iterations of proximal
gradient descent optimization methods. We further adapt the RNN architecture to
image reconstruction problems by transforming the network into a recurrent
auto-encoder, thereby allowing for unsupervised training. Our DL based inverse
solver is particularly suitable for a class of image formation problems in
which the forward model is only partially known. The ability to learn forward
models and hyper parameters combined with unsupervised training approach
establish our recurrent auto-encoder suitable for real world applications. We
demonstrate the performance of our method in passive SAR image reconstruction.
In this regime a source of opportunity, with unknown location and transmitted
waveform, is used to illuminate a scene of interest. We investigate recurrent
auto- encoder architecture based on the 1 and 0 constrained least- squares
problem. We present a projected stochastic gradient descent based training
scheme which incorporates constraints of the unknown model parameters. We
demonstrate through extensive numerical simulations that our DL based approach
out performs conventional sparse coding methods in terms of computation and
reconstructed image quality, specifically, when no information about the
transmitter is available.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Journal of Selected Topics in Signal Processing</dc:description>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04685</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Colorimetric Calibration of a Digital Camera</dc:title>
 <dc:creator>Rychtarikova, Renata</dc:creator>
 <dc:creator>Soucek, Pavel</dc:creator>
 <dc:creator>Stys, Dalibor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:description>  In this paper, we introduce a novel - physico-chemical - approach for
calibration of a digital camera chip. This approach utilizes results of
measurement of incident light spectra of calibration films of different levels
of gray for construction of calibration curve (number of incident photons vs.
image pixel intensity) for each camera pixel. We show spectral characteristics
of such corrected digital raw image files (a primary camera signal) and
demonstrate their suitability for next image processing and analysis.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04685</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04686</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VQS: Linking Segmentations to Questions and Answers for Supervised
  Attention in VQA and Question-Focused Semantic Segmentation</dc:title>
 <dc:creator>Gan, Chuang</dc:creator>
 <dc:creator>Li, Yandong</dc:creator>
 <dc:creator>Li, Haoxiang</dc:creator>
 <dc:creator>Sun, Chen</dc:creator>
 <dc:creator>Gong, Boqing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Rich and dense human labeled datasets are among the main enabling factors for
the recent advance on vision-language understanding. Many seemingly distant
annotations (e.g., semantic segmentation and visual question answering (VQA))
are inherently connected in that they reveal different levels and perspectives
of human understandings about the same visual scenes --- and even the same set
of images (e.g., of COCO). The popularity of COCO correlates those annotations
and tasks. Explicitly linking them up may significantly benefit both individual
tasks and the unified vision and language modeling. We present the preliminary
work of linking the instance segmentations provided by COCO to the questions
and answers (QAs) in the VQA dataset, and name the collected links visual
questions and segmentation answers (VQS). They transfer human supervision
between the previously separate tasks, offer more effective leverage to
existing problems, and also open the door for new research problems and models.
We study two applications of the VQS data in this paper: supervised attention
for VQA and a novel question-focused semantic segmentation task. For the
former, we obtain state-of-the-art results on the VQA real multiple-choice task
by simply augmenting the multilayer perceptrons with some attention features
that are learned using the segmentation-QA links as explicit supervision. To
put the latter in perspective, we study two plausible methods and compare them
to an oracle method assuming that the instance segmentations are given at the
test stage.
</dc:description>
 <dc:description>Comment: To appear on ICCV 2017</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04692</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GANs for Biological Image Synthesis</dc:title>
 <dc:creator>Osokin, Anton</dc:creator>
 <dc:creator>Chessel, Anatole</dc:creator>
 <dc:creator>Salas, Rafael E. Carazo</dc:creator>
 <dc:creator>Vaggi, Federico</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose a novel application of Generative Adversarial
Networks (GAN) to the synthesis of cells imaged by fluorescence microscopy.
Compared to natural images, cells tend to have a simpler and more geometric
global structure that facilitates image generation. However, the correlation
between the spatial pattern of different fluorescent proteins reflects
important biological functions, and synthesized images have to capture these
relationships to be relevant for biological applications. We adapt GANs to the
task at hand and propose new models with casual dependencies between image
channels that can generate multi-channel images, which would be impossible to
obtain experimentally. We evaluate our approach using two independent
techniques and compare it against sensible baselines. Finally, we demonstrate
that by interpolating across the latent space we can mimic the known changes in
protein localization that occur through time during the cell cycle, allowing us
to predict temporal evolution from static images.
</dc:description>
 <dc:description>Comment: The paper appearing at the International Conference on Computer
  Vision (ICCV) 2017 + its supplementary materials</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04696</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Uniformity Testing</dc:title>
 <dc:creator>Batu, Tu&#x11f;kan</dc:creator>
 <dc:creator>Canonne, Cl&#xe9;ment L.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  In this work, we revisit the problem of uniformity testing of discrete
probability distributions. A fundamental problem in distribution testing,
testing uniformity over a known domain has been addressed over a significant
line of works, and is by now fully understood.
  The complexity of deciding whether an unknown distribution is uniform over
its unknown (and arbitrary) support, however, is much less clear. Yet, this
task arises as soon as no prior knowledge on the domain is available, or
whenever the samples originate from an unknown and unstructured universe. In
this work, we introduce and study this generalized uniformity testing question,
and establish nearly tight upper and lower bound showing that -- quite
surprisingly -- its sample complexity significantly differs from the
known-domain case. Moreover, our algorithm is intrinsically adaptive, in
contrast to the overwhelming majority of known distribution testing algorithms.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04699</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mechanism Redesign</dc:title>
 <dc:creator>Chawla, Shuchi</dc:creator>
 <dc:creator>Hartline, Jason D.</dc:creator>
 <dc:creator>Nekipelov, Denis</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper develops the theory of mechanism redesign by which an auctioneer
can reoptimize an auction based on bid data collected from previous iterations
of the auction on bidders from the same market. We give a direct method for
estimation of the revenue of a counterfactual auction from the bids in the
current auction. The estimator is a simple weighted order statistic of the bids
and has the optimal error rate. Two applications of our estimator are A/B
testing (a.k.a., randomized controlled trials) and instrumented optimization
(i.e., revenue optimization subject to being able to do accurate inference of
any counterfactual auction revenue).
</dc:description>
 <dc:description>Comment: This paper combines and improves upon results from manuscripts
  &quot;Mechanism Design for Data Science&quot; (arXiv:1404.5971) and &quot;A/B Testing of
  Auctions&quot; (arXiv:1606.00908)</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04699</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04701</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Characterization of Multi-threaded Graph Processing
  Applications on Intel Many-Integrated-Core Architecture</dc:title>
 <dc:creator>Liu, Xu</dc:creator>
 <dc:creator>Chen, Langshi</dc:creator>
 <dc:creator>Firoz, Jesun S.</dc:creator>
 <dc:creator>Qiu, Judy</dc:creator>
 <dc:creator>Jiang, Lei</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Intel Xeon Phi many-integrated-core (MIC) architectures usher in a new era of
terascale integration. Among emerging killer applications, parallel graph
processing has been a critical technique to analyze connected data. In this
paper, we empirically evaluate various computing platforms including an Intel
Xeon E5 CPU, a Nvidia Geforce GTX1070 GPU and an Xeon Phi 7210 processor
codenamed Knights Landing (KNL) in the domain of parallel graph processing. We
show that the KNL gains encouraging performance when processing graphs, so that
it can become a promising solution to accelerating multi-threaded graph
applications. We further characterize the impact of KNL architectural
enhancements on the performance of a state-of-the art graph framework.We have
four key observations: 1 Different graph applications require distinctive
numbers of threads to reach the peak performance. For the same application,
various datasets need even different numbers of threads to achieve the best
performance. 2 Only a few graph applications benefit from the high bandwidth
MCDRAM, while others favor the low latency DDR4 DRAM. 3 Vector processing units
executing AVX512 SIMD instructions on KNLs are underutilized when running the
state-of-the-art graph framework. 4 The sub-NUMA cache clustering mode offering
the lowest local memory access latency hurts the performance of graph
benchmarks that are lack of NUMA awareness. At last, We suggest future works
including system auto-tuning tools and graph framework optimizations to fully
exploit the potential of KNL for parallel graph processing.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04704</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Word Embeddings for Sentence Boundary Detection in Speech
  Transcripts</dc:title>
 <dc:creator>Treviso, Marcos V.</dc:creator>
 <dc:creator>Shulby, Christopher D.</dc:creator>
 <dc:creator>Aluisio, Sandra M.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper is motivated by the automation of neuropsychological tests
involving discourse analysis in the retellings of narratives by patients with
potential cognitive impairment. In this scenario the task of sentence boundary
detection in speech transcripts is important as discourse analysis involves the
application of Natural Language Processing tools, such as taggers and parsers,
which depend on the sentence as a processing unit. Our aim in this paper is to
verify which embedding induction method works best for the sentence boundary
detection task, specifically whether it be those which were proposed to capture
semantic, syntactic or morphological similarities.
</dc:description>
 <dc:description>Comment: Accepted on STIL 2017</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04706</identifier>
 <datestamp>2017-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Error-Correction Performance and Implementation of Polar Code List
  Decoders for 5G</dc:title>
 <dc:creator>Ercan, Furkan</dc:creator>
 <dc:creator>Condo, Carlo</dc:creator>
 <dc:creator>Hashemi, Seyyed Ali</dc:creator>
 <dc:creator>Gross, Warren J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Polar codes are a class of capacity achieving error correcting codes that has
been recently selected for the next generation of wireless communication
standards (5G). Polar code decoding algorithms have evolved in various
directions, striking different balances between error-correction performance,
speed and complexity. Successive-cancellation list (SCL) and its incarnations
constitute a powerful, well-studied set of algorithms, in constant improvement.
At the same time, different implementation approaches provide a wide range of
area occupations and latency results. 5G puts a focus on improved
error-correction performance, high throughput and low power consumption: a
comprehensive study considering all these metrics is currently lacking in
literature. In this work, we evaluate SCL-based decoding algorithms in terms of
error-correction performance and compare them to low-density parity-check
(LDPC) codes. Moreover, we consider various decoder implementations, for both
polar and LDPC codes, and compare their area occupation and power and energy
consumption when targeting short code lengths and rates. Our work shows that
among SCL-based decoders, the partitioned SCL (PSCL) provides the lowest area
occupation and power consumption, whereas fast simplified SCL (Fast-SSCL)
yields the lowest energy consumption. Compared to LDPC decoder architectures,
different SCL implementations occupy up to 17.1x less area, dissipate up to
7.35x less power, and up to 26x less energy.
</dc:description>
 <dc:description>Comment: Accepted in 55th Annual Allerton Conference on Communication,
  Control, and Computing</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-10-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04713</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counting Roots of Polynomials over $\mathbb{Z}/p^2\mathbb{Z}$</dc:title>
 <dc:creator>Hammonds, Trajan</dc:creator>
 <dc:creator>Johnson, Jeremy</dc:creator>
 <dc:creator>Patini, Angela</dc:creator>
 <dc:creator>Walker, Robert M.</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:subject>11Y05, 11Y16, 13F20 (Primary). 11M38, 11S05, 11T06 (Secondary)</dc:subject>
 <dc:description>  Until recently, the only known method of finding the roots of polynomials
over prime power rings, other than fields, was brute force. One reason for this
is the lack of a division algorithm, obstructing the use of greatest common
divisors. Fix a prime $p \in \mathbb{Z}$ and $f \in ( \mathbb{Z}/p^n \mathbb{Z}
) [x]$ any nonzero polynomial of degree $d$ whose coefficients are not all
divisible by $p$. For the case $n=2$, we prove a new efficient algorithm to
count the roots of $f$ in $\mathbb{Z}/p^2\mathbb{Z}$ within time polynomial in
$(d+\operatorname{size}(f)+\log{p})$, and record a concise formula for the
number of roots, formulated by Cheng, Gao, Rojas, and Wan.
</dc:description>
 <dc:description>Comment: 6 pages, comments welcome! Rewritten to address referee feedback.
  Bibliography updated. There is a new Corollary 3.3 giving a formula for the
  number of degenerate roots modulo p that fail to lift to roots modulo p^2</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04714</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Rich Geographical Representations: Predicting Colorectal Cancer
  Survival in the State of Iowa</dc:title>
 <dc:creator>Lash, Michael T.</dc:creator>
 <dc:creator>Sun, Yuqi</dc:creator>
 <dc:creator>Zhou, Xun</dc:creator>
 <dc:creator>Lynch, Charles F.</dc:creator>
 <dc:creator>Street, W. Nick</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Neural networks are capable of learning rich, nonlinear feature
representations shown to be beneficial in many predictive tasks. In this work,
we use these models to explore the use of geographical features in predicting
colorectal cancer survival curves for patients in the state of Iowa, spanning
the years 1989 to 2012. Specifically, we compare model performance using a
newly defined metric -- area between the curves (ABC) -- to assess (a) whether
survival curves can be reasonably predicted for colorectal cancer patients in
the state of Iowa, (b) whether geographical features improve predictive
performance, and (c) whether a simple binary representation or richer, spectral
clustering-based representation perform better. Our findings suggest that
survival curves can be reasonably estimated on average, with predictive
performance deviating at the five-year survival mark. We also find that
geographical features improve predictive performance, and that the best
performance is obtained using richer, spectral analysis-elicited features.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04716</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Powered Wireless Sensor</dc:title>
 <dc:creator>Huang, Paul Ryuji Chuen-Ying</dc:creator>
 <dc:creator>Nguang, Sing Kiong</dc:creator>
 <dc:creator>Partridge, Ashton</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper develops a novel power harvesting system to harvest ambient RF
energy to power a wireless sensor. Harvesting ambient RF energy is a very
difficult task as the power levels are extremely weak. Simulation results show
zero threshold MOSFETs are essential in the RF to DC conversion process. 0.5VDC
at the output of the RF to DC conversion stage is the minimum voltage which
must be achieved for the micro-power sensor circuitry to operate. The weakest
power level the proposed system can successfully harvest is -37dBm. The
measured available power from the FM band has been measured to fluctuate
between -33 to -43dBm using a ribbon FM dipole antenna. Ambient RF energy would
best be used in conjunction with other forms of harvested ambient energy to
increase diversity and dependability. The potential economic and environmental
benefits make such endeavors truly worthwhile.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04722</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Sensor Sequential Change Detection with Unknown Change Propagation
  Dynamics</dc:title>
 <dc:creator>Kurt, Mehmet Necip</dc:creator>
 <dc:creator>Raghavan, Vasanthan</dc:creator>
 <dc:creator>Wang, Xiaodong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The problem of detecting changes with multiple sensors has received
significant attention in the literature. In many practical applications such as
critical infrastructure monitoring and modeling of disease spread, a useful
change propagation model is one where change eventually happens at all sensors,
but where not all sensors witness change at the same time-instant. While prior
work considered the case of known change propagation dynamics, this paper
studies a more general setting of unknown change propagation dynamics. A
Bayesian formulation of the problem in both centralized and decentralized
settings is studied with the goal of detecting the first time-instant at which
any sensor witnesses a change. Using the dynamic programming framework, the
optimal solution structure is derived and in the rare change regime, several
more practical change detection algorithms are proposed. Under certain
conditions, the first-order asymptotic optimality of a proposed algorithm
called multichart test is shown as the false alarm probability vanishes.
Numerical studies illustrate that the proposed detection techniques offer
near-optimal performance. Further, in the decentralized setting, it is shown
that if sensors use a novel event-triggered sampling scheme called
level-crossing sampling with hysteresis instead of the conventional
uniform-in-time sampling scheme, the detection performance can be significantly
improved using the same amount of communication resources.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04723</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polylogarithmic approximation for minimum planarization (almost)</dc:title>
 <dc:creator>Kawarabayashi, Ken-ichi</dc:creator>
 <dc:creator>Sidiropoulos, Anastasios</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the minimum planarization problem, given some $n$-vertex graph, the goal
is to find a set of vertices of minimum cardinality whose removal leaves a
planar graph. This is a fundamental problem in topological graph theory. We
present a $\log^{O(1)} n$-approximation algorithm for this problem on general
graphs with running time $n^{O(\log n/\log\log n)}$. We also obtain a
$O(n^\varepsilon)$-approximation with running time $n^{O(1/\varepsilon)}$ for
any arbitrarily small constant $\varepsilon &gt; 0$. Prior to our work, no
non-trivial algorithm was known for this problem on general graphs, and the
best known result even on graphs of bounded degree was a
$n^{\Omega(1)}$-approximation [Chekuri and Sidiropoulos 2013].
  As an immediate corollary, we also obtain improved approximation algorithms
for the crossing number problem on graphs of bounded degree. Specifically, we
obtain $O(n^{1/2+\varepsilon})$-approximation and $n^{1/2} \log^{O(1)}
n$-approximation algorithms in time $n^{O(1/\varepsilon)}$ and $n^{O(\log
n/\log\log n)}$ respectively. The previously best-known result was a
polynomial-time $n^{9/10}\log^{O(1)} n$-approximation algorithm [Chuzhoy 2011].
  Our algorithm introduces several new tools including an efficient grid-minor
construction for apex graphs, and a new method for computing irrelevant
vertices. Analogues of these tools were previously available only for exact
algorithms. Our work gives efficient implementations of these ideas in the
setting of approximation algorithms, which could be of independent interest.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04723</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04725</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hypotheses generation using link prediction in a bipartite graph</dc:title>
 <dc:creator>Kim, Jung-Hun</dc:creator>
 <dc:creator>Segev, Aviv</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The large volume of scientific publications is likely to have hidden
knowledge that can be used for suggesting new research topics. We propose an
automatic method that is helpful for generating research hypotheses in the
field of physics using the massive number of physics journal publications. We
convert the text data of titles and abstract sections in publications to a
bipartite graph, extracting words of physical matter composed of chemical
elements and extracting related keywords in the paper. The proposed method
predicts the formation of new links between matter and keyword nodes based on
collaborative filtering and matter popularity. The formation of links
represents research hypotheses, as it suggests the new possible relationships
between physical matter and keywords for physical properties or phenomena. The
suggested method has better performance than existing methods for link
prediction in the entire bipartite graph and the subgraph that contains only a
specific keyword, such as `antiferromagnetism' or `superconductivity.'
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04726</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-Enabled Biometric Search</dc:title>
 <dc:creator>Streit, Scott</dc:creator>
 <dc:creator>Streit, Brian</dc:creator>
 <dc:creator>Suffian, Stephen</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Biometrics have a long-held hope of replacing passwords by establishing a
non-repudiated identity and providing authentication with convenience.
Convenience drives consumers toward biometrics-based access management
solutions. Unlike passwords, biometrics cannot be script-injected; however,
biometric data is considered highly sensitive due to its personal nature and
unique association with users. Biometrics differ from passwords in that
compromised passwords may be reset. Compromised biometrics offer no such
relief. A compromised biometric offers unlimited risk in privacy (anyone can
view the biometric) and authentication (anyone may use the biometric).
Standards such as the Biometric Open Protocol Standard (BOPS) (IEEE 2410-2016)
provide a detailed mechanism to authenticate biometrics based on pre-enrolled
devices and a previous identity by storing the biometric in encrypted form.
This paper describes a biometric-agnostic approach that addresses the privacy
concerns of biometrics through the implementation of BOPS. Specifically, two
novel concepts are introduced. First, a biometric is applied to a neural
network to create a feature vector. This neural network alone can be used for
one-to-one matching (authentication), but would require a search in linear time
for the one-to-many case (identity lookup). The classifying algorithm described
in this paper addresses this concern by producing normalized floating-point
values for each feature vector. This allows authentication lookup to occur in
up to polynomial time, allowing for search in encrypted biometric databases
with speed, accuracy and privacy.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04727</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distances and Isomorphism between Networks and the Stability of Network
  Invariants</dc:title>
 <dc:creator>Chowdhury, Samir</dc:creator>
 <dc:creator>M&#xe9;moli, Facundo</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  We develop the theoretical foundations of a network distance that has
recently been applied to various subfields of topological data analysis, namely
persistent homology and hierarchical clustering. While this network distance
has previously appeared in the context of finite networks, we extend the
setting to that of compact networks. The main challenge in this new setting is
the lack of an easy notion of sampling from compact networks; we solve this
problem in the process of obtaining our results. The generality of our setting
means that we automatically establish results for exotic objects such as
directed metric spaces and Finsler manifolds. We identify readily computable
network invariants and establish their quantitative stability under this
network distance. We also discuss the computational complexity involved in
precisely computing this distance, and develop easily-computable lower bounds
by using the identified invariants. By constructing a wide range of explicit
examples, we show that these lower bounds are effective in distinguishing
between networks. Finally, we provide a simple algorithm that computes a lower
bound on the distance between two networks in polynomial time and illustrate
our metric and invariant constructions on a database of random networks and a
database of simulated hippocampal networks.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04728</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepRebirth: Accelerating Deep Neural Network Execution on Mobile
  Devices</dc:title>
 <dc:creator>Li, Dawei</dc:creator>
 <dc:creator>Wang, Xiaolong</dc:creator>
 <dc:creator>Kong, Deguang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deploying deep neural networks on mobile devices is a challenging task.
Current model compression methods such as matrix decomposition effectively
reduce the deployed model size, but still cannot satisfy real-time processing
requirement. This paper first discovers that the major obstacle is the
excessive execution time of non-tensor layers such as pooling and normalization
without tensor-like trainable parameters. This motivates us to design a novel
acceleration framework: DeepRebirth through &quot;slimming&quot; existing consecutive and
parallel non-tensor and tensor layers. The layer slimming is executed at
different substructures: (a) streamline slimming by merging the consecutive
non-tensor and tensor layer vertically; (b) branch slimming by merging
non-tensor and tensor branches horizontally. The proposed optimization
operations significantly accelerate the model execution and also greatly reduce
the run-time memory cost since the slimmed model architecture contains less
hidden layers. To maximally avoid accuracy loss, the parameters in new
generated layers are learned with layer-wise fine-tuning based on both
theoretical analysis and empirical verification. As observed in the experiment,
DeepRebirth achieves more than 3x speed-up and 2.5x run-time memory saving on
GoogLeNet with only 0.4% drop of top-5 accuracy on ImageNet. Furthermore, by
combining with other model compression techniques, DeepRebirth offers an
average of 65ms inference time on the CPU of Samsung Galaxy S6 with 86.5% top-5
accuracy, 14% faster than SqueezeNet which only has a top-5 accuracy of 80.5%.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04729</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deconvolutional Paragraph Representation Learning</dc:title>
 <dc:creator>Zhang, Yizhe</dc:creator>
 <dc:creator>Shen, Dinghan</dc:creator>
 <dc:creator>Wang, Guoyin</dc:creator>
 <dc:creator>Gan, Zhe</dc:creator>
 <dc:creator>Henao, Ricardo</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning latent representations from long text sequences is an important
first step in many natural language processing applications. Recurrent Neural
Networks (RNNs) have become a cornerstone for this challenging task. However,
the quality of sentences during RNN-based decoding (reconstruction) decreases
with the length of the text. We propose a sequence-to-sequence, purely
convolutional and deconvolutional autoencoding framework that is free of the
above issue, while also being computationally efficient. The proposed method is
simple, easy to implement and can be leveraged as a building block for many
applications. We show empirically that compared to RNNs, our framework is
better at reconstructing and correcting long paragraphs. Quantitative
evaluation on semi-supervised text classification and summarization tasks
demonstrate the potential for better utilization of long unlabeled text data.
</dc:description>
 <dc:description>Comment: Accepted by NIPS 2017</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04733</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric Enclosing Networks</dc:title>
 <dc:creator>Le, Trung</dc:creator>
 <dc:creator>Vu, Hung</dc:creator>
 <dc:creator>Nguyen, Tu Dinh</dc:creator>
 <dc:creator>Phung, Dinh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Training model to generate data has increasingly attracted research attention
and become important in modern world applications. We propose in this paper a
new geometry-based optimization approach to address this problem. Orthogonal to
current state-of-the-art density-based approaches, most notably VAE and GAN, we
present a fresh new idea that borrows the principle of minimal enclosing ball
to train a generator G\left(\bz\right) in such a way that both training and
generated data, after being mapped to the feature space, are enclosed in the
same sphere. We develop theory to guarantee that the mapping is bijective so
that its inverse from feature space to data space results in expressive
nonlinear contours to describe the data manifold, hence ensuring data generated
are also lying on the data manifold learned from training data. Our model
enjoys a nice geometric interpretation, hence termed Geometric Enclosing
Networks (GEN), and possesses some key advantages over its rivals, namely
simple and easy-to-control optimization formulation, avoidance of mode
collapsing and efficiently learn data manifold representation in a completely
unsupervised manner. We conducted extensive experiments on synthesis and
real-world datasets to illustrate the behaviors, strength and weakness of our
proposed GEN, in particular its ability to handle multi-modal data and quality
of generated data.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04745</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weight-based Fish School Search algorithm for Many-Objective
  Optimization</dc:title>
 <dc:creator>Albuquerque, I. M. C.</dc:creator>
 <dc:creator>Filho, J. B. Monteiro</dc:creator>
 <dc:creator>Neto, F. B. Lima</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Optimization problems with more than one objective consist in a very
attractive topic for researchers due to its applicability in real-world
situations. Over the years, the research effort in Computational Intelligence
area resulted in algorithms able to achieve good results by solving problems
with more than one conflicting objective. However, these techniques do not
exhibit the same performance as the number of objectives increases and become
greater than 3. This paper proposes an adaptation of the metaheuristic Fish
School Search to solve optimization problems with many objectives. This
adaptation is based on the division of the school in clusters that are
specialized in solving a single-objective problem generated by the
decomposition of the original problem. For this, we used concepts and ideas
often found in the literature and applied in state-of-the-art algorithms,
namely: (i) reference points and lines in the objectives space; (ii) clustering
process; and (iii) the decomposition technique Penalty-based Boundary
Intersection. The proposed algorithm was compared with two state-of-the-art
bio-inspired algorithms. Results have shown competitiveness, as well as the
necessity of improving the performance of the proposed technique on multi-modal
many-objective problems.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04747</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Improved Neural Segmentation Method Based on U-NET</dc:title>
 <dc:creator>Xu, Chenyang</dc:creator>
 <dc:creator>Li, Mengxin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Neural segmentation has a great impact on the smooth implementation of local
anesthesia surgery. At present, the network for the segmentation includes U-NET
[1] and SegNet [2]. U-NET network has short training time and less training
parameters, but the depth is not deep enough. SegNet network has deeper
structure, but it needs longer training time, and more training samples. In
this paper, we propose an improved U-NET neural network for the segmentation.
This network deepens the original structure through importing residual network.
Compared with U-NET and SegNet, the improved U-NET network has fewer training
parameters, shorter training time and get a great improvement in segmentation
effect. The improved U-NET network structure has a good application scene in
neural segmentation.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04748</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When the cookie meets the blockchain: Privacy risks of web payments via
  cryptocurrencies</dc:title>
 <dc:creator>Goldfeder, Steven</dc:creator>
 <dc:creator>Kalodner, Harry</dc:creator>
 <dc:creator>Reisman, Dillon</dc:creator>
 <dc:creator>Narayanan, Arvind</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We show how third-party web trackers can deanonymize users of
cryptocurrencies. We present two distinct but complementary attacks. On most
shopping websites, third party trackers receive information about user
purchases for purposes of advertising and analytics. We show that, if the user
pays using a cryptocurrency, trackers typically possess enough information
about the purchase to uniquely identify the transaction on the blockchain, link
it to the user's cookie, and further to the user's real identity. Our second
attack shows that if the tracker is able to link two purchases of the same user
to the blockchain in this manner, it can identify the user's entire cluster of
addresses and transactions on the blockchain, even if the user employs
blockchain anonymity techniques such as CoinJoin. The attacks are passive and
hence can be retroactively applied to past purchases. We discuss several
mitigations, but none are perfect.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04748</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04749</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining Relationship-Based Access Control Policies</dc:title>
 <dc:creator>Bui, Thang</dc:creator>
 <dc:creator>Stoller, Scott D.</dc:creator>
 <dc:creator>Li, Jiajie</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Relationship-based access control (ReBAC) provides a high level of
expressiveness and flexibility that promotes security and information sharing.
We formulate ReBAC as an object-oriented extension of attribute-based access
control (ABAC) in which relationships are expressed using fields that refer to
other objects, and path expressions are used to follow chains of relationships
between objects.
  ReBAC policy mining algorithms have potential to significantly reduce the
cost of migration from legacy access control systems to ReBAC, by partially
automating the development of a ReBAC policy from an existing access control
policy and attribute data. This paper presents an algorithm for mining ReBAC
policies from access control lists (ACLs) and attribute data represented as an
object model, and an evaluation of the algorithm on four sample policies and
two large case studies. Our algorithm can be adapted to mine ReBAC policies
from access logs and object models. It is the first algorithm for these
problems.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04750</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coordinated Linear Precoding in Downlink Multicell MU-MISO OFDMA
  Networks</dc:title>
 <dc:creator>Kibria, Mirza Golam</dc:creator>
 <dc:creator>Murata, Hidekazu</dc:creator>
 <dc:creator>Yoshida, Susumu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers coordinated linear precoding in downlink multicell
multiuser orthogonal frequency-division multiple access (OFDMA) network. A
less-complex, fast and provably convergent algorithm that maximizes the
weighted sum-rate with per base station (BS) transmit power constraint is
formulated. We approximate the nonconvex weighted sum- rate maximization (WSRM)
problem with a solvable convex form by means of sequential parametric convex
approximation (SPCA) approach. The second order cone program (SOCP)
formulations of the objective function and constraints of the optimization
problem are derived through proper change of vari- ables, first order linear
approximation and hyperbolic constraints transformation, etc. The algorithm
converges to the suboptimal solution taking fewer number of iterations in
comparison to other known iterative WSRM algorithms. Finally, numerical results
are presented to justify the effectiveness and superiority of the proposed
algorithm.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1309.4203</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04750</dc:identifier>
 <dc:identifier>Proc. IEEE Vehicular Technology Conference (IEEE VTC)., Las Vegas,
  USA, Sep. 2013</dc:identifier>
 <dc:identifier>doi:10.1109/VTCFall.2013.6692147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04754</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Specification and Implementation of Replicated List: The Jupiter
  Protocol Revisited</dc:title>
 <dc:creator>Wei, Hengfeng</dc:creator>
 <dc:creator>Huang, Yu</dc:creator>
 <dc:creator>Lu, Jian</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The replicated list object has been frequently used to model the core
functionality (e.g., insertion, deletion, and read) of replicated collaborative
text editing systems. In this paper we revisit the specification and
implementation of a replicated list object, specifically the weak list
specification proposed recently by Attiya et al. and the Jupiter protocol
designed in the 1990s. We prove that Jupiter indeed satisfies the weak list
specification, solving the conjecture of Attiya et al. To address the mismatch
between the global property of weak list specification and the local views each
replica maintains in the Jupiter protocol, we propose the CSS (Compact
State-space) Jupiter protocol, which at a high level, maintains only a single
novel $n$-ary ordered state-space for a client/server system with $n$ clients.
By contrast, the original Jupiter protocol, we call the CSCW protocol, needs to
maintain $2n$ 2D state-spaces where replica states are dispersed. We first show
that the CSS protocol and the CSCW protocol are equivalent in the sense that
their behaviors are the same under the same schedule of operations/messages.
Then, we prove that the CSS protocol satisfies the weak list specification. We
further extend the CSS protocol to a distributed setting, by orthogonally
integrating the compact $n$-ary ordered state-space with a distributed scheme
to totally order operations.
</dc:description>
 <dc:description>Comment: 17 pages, 10 figures</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04755</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Chinese Word Representations From Glyphs Of Characters</dc:title>
 <dc:creator>Su, Tzu-Ray</dc:creator>
 <dc:creator>Lee, Hung-Yi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we propose new methods to learn Chinese word representations.
Chinese characters are composed of graphical components, which carry rich
semantics. It is common for a Chinese learner to comprehend the meaning of a
word from these graphical components. As a result, we propose models that
enhance word representations by character glyphs. The character glyph features
are directly learned from the bitmaps of characters by convolutional
auto-encoder(convAE), and the glyph features improve Chinese word
representations which are already enhanced by character embeddings. Another
contribution in this paper is that we created several evaluation datasets in
traditional Chinese and made them public.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04757</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Joint Models for Reliable Uncertainty-Aware Event Prediction</dc:title>
 <dc:creator>Soleimani, Hossein</dc:creator>
 <dc:creator>Hensman, James</dc:creator>
 <dc:creator>Saria, Suchi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Missing data and noisy observations pose significant challenges for reliably
predicting events from irregularly sampled multivariate time series
(longitudinal) data. Imputation methods, which are typically used for
completing the data prior to event prediction, lack a principled mechanism to
account for the uncertainty due to missingness. Alternatively, state-of-the-art
joint modeling techniques can be used for jointly modeling the longitudinal and
event data and compute event probabilities conditioned on the longitudinal
observations. These approaches, however, make strong parametric assumptions and
do not easily scale to multivariate signals with many observations. Our
proposed approach consists of several key innovations. First, we develop a
flexible and scalable joint model based upon sparse multiple-output Gaussian
processes. Unlike state-of-the-art joint models, the proposed model can explain
highly challenging structure including non-Gaussian noise while scaling to
large data. Second, we derive an optimal policy for predicting events using the
distribution of the event occurrence estimated by the joint model. The derived
policy trades-off the cost of a delayed detection versus incorrect assessments
and abstains from making decisions when the estimated event probability does
not satisfy the derived confidence criteria. Experiments on a large dataset
show that the proposed framework significantly outperforms state-of-the-art
techniques in event prediction.
</dc:description>
 <dc:description>Comment: To appear in IEEE Transaction on Pattern Analysis and Machine
  Intelligence</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04764</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Orthogonal Matching Pursuit for Sparse Subspace Clustering</dc:title>
 <dc:creator>Chen, Yanxi</dc:creator>
 <dc:creator>Li, Gen</dc:creator>
 <dc:creator>Gu, Yuantao</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Sparse Subspace Clustering (SSC) is a state-of-the-art method for clustering
high-dimensional data points lying in a union of low-dimensional subspaces.
However, while $\ell_1$ optimization-based SSC algorithms suffer from high
computational complexity, other variants of SSC, such as Orthogonal Matching
Pursuit-based SSC (OMP-SSC), lose clustering accuracy in pursuit of improving
time efficiency. In this letter, we propose a novel Active OMP-SSC, which
improves clustering accuracy of OMP-SSC by adaptively updating data points and
randomly dropping data points in the OMP process, while still enjoying the low
computational complexity of greedy pursuit algorithms. We provide heuristic
analysis of our approach, and explain how these two active steps achieve a
better tradeoff between connectivity and separation. Numerical results on both
synthetic data and real-world data validate our analyses and show the
advantages of the proposed active algorithm.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures, 1 table</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04765</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dialogue Act Segmentation for Vietnamese Human-Human Conversational
  Texts</dc:title>
 <dc:creator>Ngo, Thi Lan</dc:creator>
 <dc:creator>Pham, Khac Linh</dc:creator>
 <dc:creator>Cao, Minh Son</dc:creator>
 <dc:creator>Pham, Son Bao</dc:creator>
 <dc:creator>Phan, Xuan Hieu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Dialog act identification plays an important role in understanding
conversations. It has been widely applied in many fields such as dialogue
systems, automatic machine translation, automatic speech recognition, and
especially useful in systems with human-computer natural language dialogue
interfaces such as virtual assistants and chatbots. The first step of
identifying dialog act is identifying the boundary of the dialog act in
utterances. In this paper, we focus on segmenting the utterance according to
the dialog act boundaries, i.e. functional segments identification, for
Vietnamese utterances. We investigate carefully functional segment
identification in two approaches: (1) machine learning approach using maximum
entropy (ME) and conditional random fields (CRFs); (2) deep learning approach
using bidirectional Long Short-Term Memory (LSTM) with a CRF layer
(Bi-LSTM-CRF) on two different conversational datasets: (1) Facebook messages
(Message data); (2) transcription from phone conversations (Phone data). To the
best of our knowledge, this is the first work that applies deep learning based
approach to dialog act segmentation. As the results show, deep learning
approach performs appreciably better as to compare with traditional machine
learning approaches. Moreover, it is also the first study that tackles dialog
act and functional segment identification for Vietnamese.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04773</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Thickness and Antithickness of Graphs</dc:title>
 <dc:creator>Dujmovi&#x107;, Vida</dc:creator>
 <dc:creator>Wood, David R.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  This paper studies questions about duality between crossings and
non-crossings in graph drawings via the notions of thickness and antithickness.
The &quot;thickness' of a graph $G$ is the minimum integer $k$ such that in some
drawing of $G$, the edges can be partitioned into $k$ noncrossing subgraphs.
The &quot;antithickness&quot; of a graph $G$ is the minimum integer $k$ such that in some
drawing of $G$, the edges can be partitioned into $k$ thrackles, where a
&quot;thrackle&quot; is a set of edges, each pair of which intersect exactly once. So
thickness is a measure of how close a graph is to being planar, whereas
antithickness is a measure of how close a graph is to being a thrackle. This
paper explores the relationship between the thickness and antithickness of a
graph, under various graph drawing models, with an emphasis on extremal
questions.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04774</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CLIMEX: A Wireless Physical Layer Security Protocol Based on Clocked
  Impulse Exchanges</dc:title>
 <dc:creator>Dwivedi, Satyam</dc:creator>
 <dc:creator>Nilsson, John Olof</dc:creator>
 <dc:creator>Papadimitratos, Panos</dc:creator>
 <dc:creator>H&#xe4;ndel, Peter</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A novel method and protocol establishing common secrecy based on physical
parameters between two users is proposed. The four physical parameters of users
are their clock frequencies, their relative clock phases and the distance
between them. The protocol proposed between two users is backed by theoretical
model for the measurements. Further, estimators are proposed to estimate secret
physical parameters. Physically exchanged parameters are shown to be secure by
virtue of their non-observability to adversaries. Under a simplified analysis
based on a testbed settings, it is shown that 38 bits of common secrecy can be
derived for one run of the proposed protocol among users. The method proposed
is also robust against various kinds of active timing attacks and active
impersonating adversaries.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04774</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04776</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modality-specific Cross-modal Similarity Measurement with Recurrent
  Attention Network</dc:title>
 <dc:creator>Peng, Yuxin</dc:creator>
 <dc:creator>Qi, Jinwei</dc:creator>
 <dc:creator>Yuan, Yuxin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Nowadays, cross-modal retrieval plays an indispensable role to flexibly find
information across different modalities of data. Effectively measuring the
similarity between different modalities of data is the key of cross-modal
retrieval. Different modalities such as image and text have imbalanced and
complementary relationships, which contain unequal amount of information when
describing the same semantics. For example, images often contain more details
that cannot be demonstrated by textual descriptions and vice versa. Existing
works based on Deep Neural Network (DNN) mostly construct one common space for
different modalities to find the latent alignments between them, which lose
their exclusive modality-specific characteristics. Different from the existing
works, we propose modality-specific cross-modal similarity measurement (MCSM)
approach by constructing independent semantic space for each modality, which
adopts end-to-end framework to directly generate modality-specific cross-modal
similarity without explicit common representation. For each semantic space,
modality-specific characteristics within one modality are fully exploited by
recurrent attention network, while the data of another modality is projected
into this space with attention based joint embedding to utilize the learned
attention weights for guiding the fine-grained cross-modal correlation
learning, which can capture the imbalanced and complementary relationships
between different modalities. Finally, the complementarity between the semantic
spaces for different modalities is explored by adaptive fusion of the
modality-specific cross-modal similarities to perform cross-modal retrieval.
Experiments on the widely-used Wikipedia and Pascal Sentence datasets as well
as our constructed large-scale XMediaNet dataset verify the effectiveness of
our proposed approach, outperforming 9 state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 13 pages, submitted to IEEE Transactions on Image Processing</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04778</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Refined Asymptotics for Rate-Distortion using Gaussian Codebooks for
  Arbitrary Sources</dc:title>
 <dc:creator>Zhou, Lin</dc:creator>
 <dc:creator>Tan, Vincent Y. F.</dc:creator>
 <dc:creator>Motani, Mehul</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The rate-distortion saddle-point problem considered by Lapidoth (1997)
consists in finding the minimum rate to compress an arbitrary ergodic source
when one is constrained to use a random Gaussian codebook and minimum
(Euclidean) distance encoding is employed. We extend Lapidoth's analysis in
several directions in this paper. Firstly, we consider refined asymptotics. In
particular, when the source is stationary and memoryless, we establish the
second-order, moderate, and large deviation asymptotics of the problem.
Secondly, by &quot;random Gaussian codebook&quot;, Lapidoth refers to a collection of
random codewords, each of which is drawn independently and uniformly from the
surface of an $n$-dimensional sphere. To be more precise, we term this as a
spherical Gaussian codebook. We also consider i.i.d.\ Gaussian codebooks in
which each random codeword is drawn independently from a product Gaussian
distribution. We derive the second-order, moderate, and large deviation
asymptotics when i.i.d.\ Gaussian codebooks are employed. Interestingly, in
contrast to the recent work on the channel coding counterpart by Scarlett, Tan
and Durisi (2017), the dispersions for spherical and i.i.d.\ Gaussian codebooks
are identical. The optimal excess-distortion exponents for both spherical and
i.i.d. Gaussian codebooks are established for all rates. Furthermore, we prove
that the i.i.d. Gaussian codebook has a strictly larger excess-distortion
exponent than the spherical counterpart for any rate larger the first order
coding rate.
</dc:description>
 <dc:description>Comment: 21 pages, under review with TIT</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04778</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04781</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Racing Thompson: an Efficient Algorithm for Thompson Sampling with
  Non-conjugate Priors</dc:title>
 <dc:creator>Zhou, Yichi</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:creator>Zhuo, Jingwei</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Thompson sampling has impressive empirical performance for many multi-armed
bandit problems. But current algorithms for Thompson sampling only work for the
case of conjugate priors since these algorithms require to infer the posterior,
which is often computationally intractable when the prior is not conjugate. In
this paper, we propose a novel algorithm for Thompson sampling which only
requires to draw samples from a tractable distribution, so our algorithm is
efficient even when the prior is non-conjugate. To do this, we reformulate
Thompson sampling as an optimization problem via the Gumbel-Max trick. After
that we construct a set of random variables and our goal is to identify the one
with highest mean. Finally, we solve it with techniques in best arm
identification.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04782</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>StarCraft II: A New Challenge for Reinforcement Learning</dc:title>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:creator>Ewalds, Timo</dc:creator>
 <dc:creator>Bartunov, Sergey</dc:creator>
 <dc:creator>Georgiev, Petko</dc:creator>
 <dc:creator>Vezhnevets, Alexander Sasha</dc:creator>
 <dc:creator>Yeo, Michelle</dc:creator>
 <dc:creator>Makhzani, Alireza</dc:creator>
 <dc:creator>K&#xfc;ttler, Heinrich</dc:creator>
 <dc:creator>Agapiou, John</dc:creator>
 <dc:creator>Schrittwieser, Julian</dc:creator>
 <dc:creator>Quan, John</dc:creator>
 <dc:creator>Gaffney, Stephen</dc:creator>
 <dc:creator>Petersen, Stig</dc:creator>
 <dc:creator>Simonyan, Karen</dc:creator>
 <dc:creator>Schaul, Tom</dc:creator>
 <dc:creator>van Hasselt, Hado</dc:creator>
 <dc:creator>Silver, David</dc:creator>
 <dc:creator>Lillicrap, Timothy</dc:creator>
 <dc:creator>Calderone, Kevin</dc:creator>
 <dc:creator>Keet, Paul</dc:creator>
 <dc:creator>Brunasso, Anthony</dc:creator>
 <dc:creator>Lawrence, David</dc:creator>
 <dc:creator>Ekermo, Anders</dc:creator>
 <dc:creator>Repp, Jacob</dc:creator>
 <dc:creator>Tsing, Rodney</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper introduces SC2LE (StarCraft II Learning Environment), a
reinforcement learning environment based on the StarCraft II game. This domain
poses a new grand challenge for reinforcement learning, representing a more
difficult class of problems than considered in most prior work. It is a
multi-agent problem with multiple players interacting; there is imperfect
information due to a partially observed map; it has a large action space
involving the selection and control of hundreds of units; it has a large state
space that must be observed solely from raw input feature planes; and it has
delayed credit assignment requiring long-term strategies over thousands of
steps. We describe the observation, action, and reward specification for the
StarCraft II domain and provide an open source Python-based interface for
communicating with the game engine. In addition to the main game maps, we
provide a suite of mini-games focusing on different elements of StarCraft II
gameplay. For the main game maps, we also provide an accompanying dataset of
game replay data from human expert players. We give initial baseline results
for neural networks trained from this data to predict game outcomes and player
actions. Finally, we present initial baseline results for canonical deep
reinforcement learning agents applied to the StarCraft II domain. On the
mini-games, these agents learn to achieve a level of play that is comparable to
a novice player. However, when trained on the main game, these agents are
unable to make significant progress. Thus, SC2LE offers a new and challenging
environment for exploring deep reinforcement learning algorithms and
architectures.
</dc:description>
 <dc:description>Comment: Collaboration between DeepMind &amp; Blizzard. 20 pages, 9 figures, 2
  tables</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04788</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BitNet: Bit-Regularized Deep Neural Networks</dc:title>
 <dc:creator>Raghavan, Aswin</dc:creator>
 <dc:creator>Amer, Mohamed</dc:creator>
 <dc:creator>Chai, Sek</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a novel regularization scheme for training deep neural networks.
The parameters of neural networks are usually unconstrained and have a dynamic
range dispersed over the real line. Our key idea is to control the expressive
power of the network by dynamically quantizing the range and set of values that
the parameters can take. We formulate this idea using a novel end-to-end
approach that regularizes the traditional classification loss function. Our
regularizer is inspired by the Minimum Description Length principle. For each
layer of the network, our approach optimizes a translation and scaling factor
along with integer-valued parameters. We empirically compare BitNet to an
equivalent unregularized model on the MNIST and CIFAR-10 datasets. We show that
BitNet converges faster to a superior quality solution. Additionally, the
resulting model is significantly smaller in size due to the use of integer
parameters instead of floats.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04789</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>revisit: a Workflow Tool for Data Science</dc:title>
 <dc:creator>Matloff, Norman</dc:creator>
 <dc:creator>Davis, Reed</dc:creator>
 <dc:creator>Beckett, Laurel</dc:creator>
 <dc:creator>Thompson, Paul</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In recent years there has been widespread concern in the scientific community
over a reproducibility crisis. Among the major causes that have been identified
is statistical: In many scientific research the statistical analysis (including
data preparation) suffers from a lack of transparency and methodological
problems, major obstructions to reproducibility. The revisit package aims
toward remedying this problem, by generating a &quot;software paper trail&quot; of the
statistical operations applied to a dataset. This record can be &quot;replayed&quot; for
verification purposes, as well as be modified to enable alternative analyses.
The software also issues warnings of certain kinds of potential errors in
statistical methodology, again related to the reproducibility issue.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04790</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Human-Robot Collaboration Models for Fluent Operations in
  Industrial Tasks</dc:title>
 <dc:creator>Sayfeld, Lior</dc:creator>
 <dc:creator>Peretz, Ygal</dc:creator>
 <dc:creator>Someshwar, Roy</dc:creator>
 <dc:creator>Edan, Yael</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this study we evaluated human-robot collaboration models in an integrated
human-robot operational system. An integrated work cell which includes a
robotic arm working collaboratively with a human worker was specially designed
for executing a real-time assembly task. Eighty industrial engineering students
aged 22-27 participated in experiments in which timing and sensor based models
were compared to an adaptive model developed within this framework. Performance
measures included total assembly time and total idle time. The results showed
conclusively that the adaptive system improved the examined parameters and
provided an improvement of 7% in total assembly time and 60% in total idle time
when compared to timing and sensory based models.
</dc:description>
 <dc:description>Comment: Robotics: Science and Systems, Human-Robot Hand-Over Workshop 2015</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04795</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Independent Low-Rank Matrix Analysis Based on Complex Student's
  $t$-Distribution for Blind Audio Source Separation</dc:title>
 <dc:creator>Mogami, Shinichi</dc:creator>
 <dc:creator>Kitamura, Daichi</dc:creator>
 <dc:creator>Mitsui, Yoshiki</dc:creator>
 <dc:creator>Takamune, Norihiro</dc:creator>
 <dc:creator>Saruwatari, Hiroshi</dc:creator>
 <dc:creator>Ono, Nobutaka</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  In this paper, we generalize a source generative model in a state-of-the-art
blind source separation (BSS), independent low-rank matrix analysis (ILRMA).
ILRMA is a unified method of frequency-domain independent component analysis
and nonnegative matrix factorization and can provide better performance for
audio BSS tasks. To further improve the performance and stability of the
separation, we introduce an isotropic complex Student's $t$-distribution as a
source generative model, which includes the isotropic complex Gaussian
distribution used in conventional ILRMA. Experiments are conducted using both
music and speech BSS tasks, and the results show the validity of the proposed
method.
</dc:description>
 <dc:description>Comment: Preprint manuscript of 2017 IEEE International Workshop on Machine
  Learning for Signal Processing</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04796</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strategies for Big Data Analytics through Lambda Architectures in
  Volatile Environments</dc:title>
 <dc:creator>Veith, Alexandre Da Silva</dc:creator>
 <dc:creator>Anjos, Julio C. S. dos</dc:creator>
 <dc:creator>de Freitas, Edison Pignaton</dc:creator>
 <dc:creator>Lampoltshammer, Thomas</dc:creator>
 <dc:creator>Geyer, Claudio</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Expectations regarding the future growth of Internet of Things (IoT)-related
technologies are high. These expectations require the realization of a
sustainable general purpose application framework that is capable to handle
these kinds of environments with their complexity in terms of heterogeneity and
volatility. The paradigm of the Lambda architecture features key
characteristics (such as robustness, fault tolerance, scalability,
generalization, extensibility, ad-hoc queries, minimal maintenance, and
low-latency reads and updates) to cope with this complexity. The paper at hand
suggest a basic set of strategies to handle the arising challenges regarding
the volatility, heterogeneity, and desired low latency execution by reducing
the overall system timing (scheduling, execution, monitoring, and faults
recovery) as well as possible faults (churn, no answers to executions). The
proposed strategies make use of services such as migration, replication,
MapReduce simulation, and combined processing methods (batch- and
streaming-based). Via these services, a distribution of tasks for the best
balance of computational resources is achieved, while monitoring and management
can be performed asynchronously in the background. %An application of batch and
stream-based methods are proposed to reduce the latency.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04796</dc:identifier>
 <dc:identifier>IFAC, Nov 2016, Porto Alegre, Brazil. pp.114-119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04797</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing control invariant sets is easy</dc:title>
 <dc:creator>Mirko, Fiacchini</dc:creator>
 <dc:creator>Mazen, Alamir</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we consider the problem of computing control invariant sets for
linear controlled systems with constraints on the input and on the states. We
focus in particular on the complexity of the computation of the N-step
operator, given by the Minkowski addition of sets, that is the basis of many of
the iterative procedures for obtaining control invariant sets. Set inclusions
conditions for control invariance are presented that involve the N-step sets
and are posed in form of linear programming problems. Such conditions are
employed in algorithms based on LP problems that allow to overcome the
complexity limitation inherent to the set addition and can be applied also to
high dimensional systems. The efficiency and scalability of the method are
illustrated by computing in less than two seconds an approximation of the
maximal control invariant set, based on the 15-step operator, for a system
whose state and input dimensions are 20 and 10 respectively.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04798</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design-Time Quantification of Integrity in Cyber-Physical-Systems</dc:title>
 <dc:creator>Morris, Eric Rothstein</dc:creator>
 <dc:creator>Murguia, Carlos G.</dc:creator>
 <dc:creator>Ochoa, Mart&#xed;n</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In a software system it is possible to quantify the amount of information
that is leaked or corrupted by analysing the flows of information present in
the source code. In a cyber-physical system, information flows are not only
present at the digital level, but also at a physical level, and to and fro the
two levels. In this work, we provide a methodology to formally analyse a
Cyber-Physical System composite model (combining physics and control) using an
information flow-theoretic approach. We use this approach to quantify the level
of vulnerability of a system with respect to attackers with different
capabilities. We illustrate our approach by means of a water distribution case
study.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04799</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Compression Technique for Sparse Sets</dc:title>
 <dc:creator>Pratap, Rameshwar</dc:creator>
 <dc:creator>Sohony, Ishan</dc:creator>
 <dc:creator>Kulkarni, Raghav</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent technological advancements have led to the generation of huge amounts
of data over the web, such as text, image, audio and video. Most of this data
is high dimensional and sparse, for e.g., the bag-of-words representation used
for representing text. Often, an efficient search for similar data points needs
to be performed in many applications like clustering, nearest neighbour search,
ranking and indexing. Even though there have been significant increases in
computational power, a simple brute-force similarity-search on such datasets is
inefficient and at times impossible. Thus, it is desirable to get a compressed
representation which preserves the similarity between data points. In this
work, we consider the data points as sets and use Jaccard similarity as the
similarity measure. Compression techniques are generally evaluated on the
following parameters --1) Randomness required for compression, 2) Time required
for compression, 3) Dimension of the data after compression, and 4) Space
required to store the compressed data. Ideally, the compressed representation
of the data should be such, that the similarity between each pair of data
points is preserved, while keeping the time and the randomness required for
compression as low as possible.
  We show that the compression technique suggested by Pratap and Kulkarni also
works well for Jaccard similarity. We present a theoretical proof of the same
and complement it with rigorous experimentations on synthetic as well as
real-world datasets. We also compare our results with the state-of-the-art
&quot;min-wise independent permutation&quot;, and show that our compression algorithm
achieves almost equal accuracy while significantly reducing the compression
time and the randomness.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04801</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weighted parallel SGD for distributed unbalanced-workload training
  system</dc:title>
 <dc:creator>Daning, Cheng</dc:creator>
 <dc:creator>Shigang, Li</dc:creator>
 <dc:creator>Yunquan, Zhang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Stochastic gradient descent (SGD) is a popular stochastic optimization method
in machine learning. Traditional parallel SGD algorithms, e.g., SimuParallel
SGD, often require all nodes to have the same performance or to consume equal
quantities of data. However, these requirements are difficult to satisfy when
the parallel SGD algorithms run in a heterogeneous computing environment;
low-performance nodes will exert a negative influence on the final result. In
this paper, we propose an algorithm called weighted parallel SGD (WP-SGD).
WP-SGD combines weighted model parameters from different nodes in the system to
produce the final output. WP-SGD makes use of the reduction in standard
deviation to compensate for the loss from the inconsistency in performance of
nodes in the cluster, which means that WP-SGD does not require that all nodes
consume equal quantities of data. We also analyze the theoretical feasibility
of running two other parallel SGD algorithms combined with WP-SGD in a
heterogeneous environment. The experimental results show that WP-SGD
significantly outperforms the traditional parallel SGD algorithms on
distributed training systems with an unbalanced workload.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04804</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficiently Tracking Homogeneous Regions in Multichannel Images</dc:title>
 <dc:creator>B&#xf6;ttger, Tobias</dc:creator>
 <dc:creator>Eisenhofer, Christina</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a method for tracking Maximally Stable Homogeneous Regions (MSHR)
in images with an arbitrary number of channels. MSHR are conceptionally very
similar to Maximally Stable Extremal Regions (MSER) and Maximally Stable Color
Regions (MSCR), but can also be applied to hyperspectral and color images while
remaining extremely efficient. The presented approach makes use of the
edge-based component-tree which can be calculated in linear time. In the
tracking step, the MSHR are localized by matching them to the nodes in the
component-tree. We use rotationally invariant region and gray-value features
that can be calculated through first and second order moments at low
computational complexity. Furthermore, we use a weighted feature vector to
improve the data association in the tracking step. The algorithm is evaluated
on a collection of different tracking scenes from the literature. Furthermore,
we present two different applications: 2D object tracking and the 3D
segmentation of organs.
</dc:description>
 <dc:description>Comment: to be published in ICPRS 2017 proceedings</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04806</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Ideas for Brain Modelling 4</dc:title>
 <dc:creator>Greer, Kieran</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper continues the research that considers a new cognitive model. In
particular, it considers the neural binding structure of an earlier paper. To
help with this, the paper describes some new methods in the areas of image
processing and high-level behaviour simulation. The work is all based on
earlier research by the author and the new additions are intended to fit in
with the overall design. For image processing, a grid-like structure is used
with 'full linking'. Each cell in the classifier grid stores a list of all
other cells it gets associated with and this is used as the learned image that
new input is compared to. For the behaviour metric, a new prediction equation
is suggested, as part of a simulation, that uses feedback and history to
dynamically determine its course of action. While the new methods are from
widely different topics, both can be compared with the binary-analog type of
interface that is the main focus of the paper. It is suggested that the
simplest of linking between a tree and ensemble can explain neural binding and
variable signal strengths.
</dc:description>
 <dc:description>Comment: Some new information and equation corrections</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04807</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Liquid Marble Interaction Gate for Collision-Based Computing</dc:title>
 <dc:creator>Draper, Thomas C.</dc:creator>
 <dc:creator>Fullarton, Claire</dc:creator>
 <dc:creator>Phillips, Neil</dc:creator>
 <dc:creator>Costello, Ben P. J. De Lacy</dc:creator>
 <dc:creator>Adamatzky, Andrew</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Liquid marbles are microlitre droplets of liquid, encapsulated by
self-organised hydrophobic particles at the liquid/air interface. They offer an
efficient approach for manipulating liquid droplets and compartmentalising
reactions in droplets. Digital fluidic devices employing liquid marbles might
benefit from having embedded computing circuits without electronics and moving
mechanical parts (apart from the marbles). We present an experimental
implementation of a collision gate with liquid marbles. Mechanics of the gate
follows principles of Margolus' soft-sphere collision gate. Boolean values of
the inputs are given by the absence (FALSE) or presence (TRUE) of a liquid
marble. There are three outputs: two outputs are trajectories of undisturbed
marbles (they only report TRUE when just one marble is present at one of the
inputs), one output is represented by trajectories of colliding marbles (when
two marbles collide they lose their horizontal momentum and fall), this output
reports TRUE only when two marbles are present at inputs. Thus the gate
implements AND and AND-NOT logical functions. We speculate that by merging
trajectories representing AND-NOT output into a single channel one can produce
a one-bit half-adder. Potential design of a one-bit full-adder is discussed,
and the synthesis of both a pure nickel metal and hybrid nickel/polymer liquid
marble is reported.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04811</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Language Identification Using Deep Convolutional Recurrent Neural
  Networks</dc:title>
 <dc:creator>Bartz, Christian</dc:creator>
 <dc:creator>Herold, Tom</dc:creator>
 <dc:creator>Yang, Haojin</dc:creator>
 <dc:creator>Meinel, Christoph</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Language Identification (LID) systems are used to classify the spoken
language from a given audio sample and are typically the first step for many
spoken language processing tasks, such as Automatic Speech Recognition (ASR)
systems. Without automatic language detection, speech utterances cannot be
parsed correctly and grammar rules cannot be applied, causing subsequent speech
recognition steps to fail. We propose a LID system that solves the problem in
the image domain, rather than the audio domain. We use a hybrid Convolutional
Recurrent Neural Network (CRNN) that operates on spectrogram images of the
provided audio snippets. In extensive experiments we show, that our model is
applicable to a range of noisy scenarios and can easily be extended to
previously unknown languages, while maintaining its classification accuracy. We
release our code and a large scale training set for LID systems to the
community.
</dc:description>
 <dc:description>Comment: to be presented at ICONIP 2017</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04813</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient Resource Allocation for Cache-Assisted Mobile Edge
  Computing</dc:title>
 <dc:creator>Cui, Ying</dc:creator>
 <dc:creator>He, Wen</dc:creator>
 <dc:creator>Ni, Chun</dc:creator>
 <dc:creator>Guo, Chengjun</dc:creator>
 <dc:creator>Liu, Zhi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we jointly consider communication, caching and computation in
a multi-user cache-assisted mobile edge computing (MEC) system, consisting of
one base station (BS) of caching and computing capabilities and multiple users
with computation-intensive and latency-sensitive applications. We propose a
joint caching and offloading mechanism which involves task uploading and
executing for tasks with uncached computation results as well as computation
result downloading for all tasks at the BS, and efficiently utilizes multi-user
diversity and multicasting opportunities. Then, we formulate the average total
energy minimization problem subject to the caching and deadline constraints to
optimally allocate the storage resource at the BS for caching computation
results as well as the uploading and downloading time durations. The problem is
a challenging mixed discrete-continuous optimization problem. We show that
strong duality holds, and obtain an optimal solution using a dual method. To
reduce the computational complexity, we further propose a low-complexity
suboptimal solution. Finally, numerical results show that the proposed
suboptimal solution outperforms existing comparison schemes.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures, to appear in IEEE LCN 2017, Oct 9-12</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04814</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GSLAM: Initialization-robust Monocular Visual SLAM via Global
  Structure-from-Motion</dc:title>
 <dc:creator>Tang, Chengzhou</dc:creator>
 <dc:creator>Wang, Oliver</dc:creator>
 <dc:creator>Tan, Ping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many monocular visual SLAM algorithms are derived from incremental
structure-from-motion (SfM) methods. This work proposes a novel monocular SLAM
method which integrates recent advances made in global SfM. In particular, we
present two main contributions to visual SLAM. First, we solve the visual
odometry problem by a novel rank-1 matrix factorization technique which is more
robust to the errors in map initialization. Second, we adopt a recent global
SfM method for the pose-graph optimization, which leads to a multi-stage linear
formulation and enables L1 optimization for better robustness to false loops.
The combination of these two approaches generates more robust reconstruction
and is significantly faster (4X) than recent state-of-the-art SLAM systems. We
also present a new dataset recorded with ground truth camera motion in a Vicon
motion capture room, and compare our method to prior systems on it and
established benchmark datasets.
</dc:description>
 <dc:description>Comment: 3DV 2017 Project Page: https://frobelbest.github.io/gslam</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04816</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generalised Directional Laplacian Distribution: Estimation, Mixture
  Models and Audio Source Separation</dc:title>
 <dc:creator>Mitianoudis, Nikolaos</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Directional or Circular statistics are pertaining to the analysis and
interpretation of directions or rotations. In this work, a novel probability
distribution is proposed to model multidimensional sparse directional data. The
Generalised Directional Laplacian Distribution (DLD) is a hybrid between the
Laplacian distribution and the von Mises-Fisher distribution. The
distribution's parameters are estimated using Maximum-Likelihood Estimation
over a set of training data points. Mixtures of Directional Laplacian
Distributions (MDLD) are also introduced in order to model multiple
concentrations of sparse directional data. The author explores the application
of the derived DLD mixture model to cluster sound sources that exist in an
underdetermined instantaneous sound mixture. The proposed model can solve the
general K x L (K&lt;L) underdetermined instantaneous source separation problem,
offering a fast and stable solution.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04816</dc:identifier>
 <dc:identifier>IEEE Transactions on Audio, Speech and Language Processing, Vol.
  20, No. 9, pp. 2397- 2408 (2012)</dc:identifier>
 <dc:identifier>doi:10.1109/TASL.2012.2203804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04820</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Light in Power: A General and Parameter-free Algorithm for Caustic
  Design</dc:title>
 <dc:creator>M&#xe9;rigot, Quentin</dc:creator>
 <dc:creator>Meyron, Jocelyn</dc:creator>
 <dc:creator>Thibert, Boris</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  We present in this paper a generic and parameter-free algorithm to
efficiently build a wide variety of optical components, such as mirrors or
lenses, that satisfy some light energy constraints. In all of our problems, one
is given a collimated or point light source and a desired illumination after
reflection or refraction and the goal is to design the geometry of a mirror or
lens which transports exactly the light emitted by the source onto the target.
We first propose a general framework and show that eight different optical
component design problems amount to solving a Light Energy Conservation
equation that involves the computation of Visibility diagrams. We show that
these diagrams all have the same structure and can be obtained by intersecting
a 3D Power Diagram with a planar or spherical domain. This allows us to propose
an efficient and fully generic algorithm capable to solve the eight optical
component design problems. Our solutions can satisfy design constraints such as
convexity or concavity and are always graphs over the plane or the sphere. We
show the effectiveness of our algorithm on numerous simulated examples.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04821</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Underdetermined source separation using a sparse STFT framework and
  weighted laplacian directional modelling</dc:title>
 <dc:creator>Sgouros, Thomas</dc:creator>
 <dc:creator>Mitianoudis, Nikolaos</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  The instantaneous underdetermined audio source separation problem of
K-sensors, L-sources mixing scenario (where K &lt; L) has been addressed by many
different approaches, provided the sources remain quite distinct in the virtual
positioning space spanned by the sensors. This problem can be tackled as a
directional clustering problem along the source position angles in the mixture.
The use of Generalised Directional Laplacian Densities (DLD) in the MDCT domain
for underdetermined source separation has been proposed before. Here, we derive
weighted mixtures of DLDs in a sparser representation of the data in the STFT
domain to perform separation. The proposed approach yields improved results
compared to our previous offering and compares favourably with the
state-of-the-art.
</dc:description>
 <dc:description>Comment: EUSIPCO 2016, Budapest, Hungary</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04821</dc:identifier>
 <dc:identifier>doi:10.1109/EUSIPCO.2016.7760549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04828</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-task Neural Network for Non-discrete Attribute Prediction in
  Knowledge Graphs</dc:title>
 <dc:creator>Tay, Yi</dc:creator>
 <dc:creator>Tuan, Luu Anh</dc:creator>
 <dc:creator>Phan, Minh C.</dc:creator>
 <dc:creator>Hui, Siu Cheung</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Many popular knowledge graphs such as Freebase, YAGO or DBPedia maintain a
list of non-discrete attributes for each entity. Intuitively, these attributes
such as height, price or population count are able to richly characterize
entities in knowledge graphs. This additional source of information may help to
alleviate the inherent sparsity and incompleteness problem that are prevalent
in knowledge graphs. Unfortunately, many state-of-the-art relational learning
models ignore this information due to the challenging nature of dealing with
non-discrete data types in the inherently binary-natured knowledge graphs. In
this paper, we propose a novel multi-task neural network approach for both
encoding and prediction of non-discrete attribute information in a relational
setting. Specifically, we train a neural network for triplet prediction along
with a separate network for attribute value regression. Via multi-task
learning, we are able to learn representations of entities, relations and
attributes that encode information about both tasks. Moreover, such attributes
are not only central to many predictive tasks as an information source but also
as a prediction target. Therefore, models that are able to encode, incorporate
and predict such information in a relational learning context are highly
attractive as well. We show that our approach outperforms many state-of-the-art
methods for the tasks of relational triplet classification and attribute value
prediction.
</dc:description>
 <dc:description>Comment: Accepted at CIKM 2017</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04838</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Template for Implementing Fast Lock-free Trees Using HTM</dc:title>
 <dc:creator>Brown, Trevor</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  Algorithms that use hardware transactional memory (HTM) must provide a
software-only fallback path to guarantee progress. The design of the fallback
path can have a profound impact on performance. If the fallback path is allowed
to run concurrently with hardware transactions, then hardware transactions must
be instrumented, adding significant overhead. Otherwise, hardware transactions
must wait for any processes on the fallback path, causing concurrency
bottlenecks, or move to the fallback path. We introduce an approach that
combines the best of both worlds. The key idea is to use three execution paths:
an HTM fast path, an HTM middle path, and a software fallback path, such that
the middle path can run concurrently with each of the other two. The fast path
and fallback path do not run concurrently, so the fast path incurs no
instrumentation overhead. Furthermore, fast path transactions can move to the
middle path instead of waiting or moving to the software path. We demonstrate
our approach by producing an accelerated version of the tree update template of
Brown et al., which can be used to implement fast lock-free data structures
based on down-trees. We used the accelerated template to implement two
lock-free trees: a binary search tree (BST), and an (a,b)-tree (a
generalization of a B-tree). Experiments show that, with 72 concurrent
processes, our accelerated (a,b)-tree performs between 4.0x and 4.2x as many
operations per second as an implementation obtained using the original tree
update template.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04845</identifier>
 <datestamp>2017-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Descriptive Complexity of Modal $\mu$ Model-checking Games</dc:title>
 <dc:creator>Lehtinen, Karoliina</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This paper revisits the well-established relationship between the modal mu
calculus and parity games to show that it is even more robust than previously
known. It addresses the question of whether the descriptive complexity of modal
mu model-checking games, previously known to depend on the syntactic complexity
of a formula, depends in fact on its semantic complexity. It shows that up to
formulas of semantic co-B\&quot;uchi complexity, the descriptive complexity of their
model-checking games coincides exactly with their semantic complexity. Beyond
co-B\&quot;uchi, the descriptive complexity of the model-checking parity games of a
formula is shown to be an upper bound on its semantic complexity; whether it is
also a lower bound remains an open question.
</dc:description>
 <dc:description>Comment: In Proceedings GandALF 2017, arXiv:1709.01761</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04845</dc:identifier>
 <dc:identifier>EPTCS 256, 2017, pp. 76-90</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.256.6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04846</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum A Posteriori Inference in Sum-Product Networks</dc:title>
 <dc:creator>Mei, Jun</dc:creator>
 <dc:creator>Jiang, Yong</dc:creator>
 <dc:creator>Tu, Kewei</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Sum-product networks (SPNs) are a class of probabilistic graphical models
that allow tractable marginal inference. However, the maximum a posteriori
(MAP) inference in SPNs is NP-hard. We investigate MAP inference in SPNs from
both theoretical and algorithmic perspectives. For the theoretical part, we
reduce general MAP inference to its special case without evidence and hidden
variables; we also show that it is NP-hard to approximate the MAP problem to
$2^{n^\epsilon}$ for fixed $0 \leq \epsilon &lt; 1$, where $n$ is the input size.
For the algorithmic part, we first present an exact MAP solver that runs
reasonably fast and could handle SPNs with up to 1k variables and 150k arcs in
our experiments. We then present a new approximate MAP solver with a good
balance between speed and accuracy, and our comprehensive experiments on
real-world datasets show that it has better overall performance than existing
approximate solvers.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04851</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Top-Down Synthesis of Multi-Agent Formation Control: An Eigenstructure
  Assignment based Approach</dc:title>
 <dc:creator>Motoyama, Takatoshi</dc:creator>
 <dc:creator>Cai, Kai</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We propose a top-down approach for formation control of heterogeneous
multi-agent systems, based on the method of eigenstructure assignment. Given
the problem of achieving scalable formations on the plane, our approach
globally computes a state feedback control that assigns desired closed-loop
eigenvalues/eigenvectors. We characterize the relation between the
eigenvalues/eigenvectors and the resulting inter-agent communication topology,
and design special (sparse) topologies such that the synthesized control may be
implemented locally by the individual agents. Moreover, we present a
hierarchical synthesis procedure that significantly improves computational
efficiency. Finally, we extend the proposed approach to achieve rigid formation
and circular motion, and illustrate these results by simulation examples.
</dc:description>
 <dc:description>Comment: 15 pages, 4 figures</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04851</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04862</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Approximations for Coalitional Manipulation in General Scoring Rules</dc:title>
 <dc:creator>Keller, Orgad</dc:creator>
 <dc:creator>Hassidim, Avinatan</dc:creator>
 <dc:creator>Hazon, Noam</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the problem of coalitional manipulation---where $k$ manipulators try
to manipulate an election on $m$ candidates---under general scoring rules, with
a focus on the Borda protocol. We do so both in the weighted and unweighted
settings. We focus on minimizing the maximum score obtainable by a
non-preferred candidate.
  In the strongest, most general setting, we provide an algorithm for any
scoring rule as described by a vector
$\vec{\alpha}=(\alpha_1,\ldots,\alpha_m)$: for some $\beta=O(\sqrt{m\log m})$,
it obtains an additive approximation equal to $W\cdot \max_i \lvert
\alpha_{i+\beta}-\alpha_i \rvert$, where $W$ is the sum of voter weights.
  For Borda, both the weighted and unweighted variants are known to be
$NP$-hard. For the unweighted case, our simpler algorithm provides a
randomized, additive $O(k \sqrt{m \log m} )$ approximation; in other words, if
there exists a strategy enabling the preferred candidate to win by an $\Omega(k
\sqrt{m \log m} )$ margin, our method, with high probability, will find a
strategy enabling her to win (albeit with a possibly smaller margin). It thus
provides a somewhat stronger guarantee compared to the previous methods, which
implicitly implied a strategy that provides an $\Omega(m)$-additive
approximation to the maximum score of a non-preferred candidate.
  For the weighted case, our generalized algorithm provides an $O(W \sqrt{m
\log m} )$-additive approximation, where $W$ is the sum of voter weights. This
is a clear advantage over previous methods: some of them do not generalize to
the weighted case, while others---which approximate the number of
manipulators---pose restrictions on the weights of extra manipulators added.
  Our methods are based on carefully rounding an exponentially-large
configuration linear program that is solved by using the ellipsoid method with
an efficient separation oracle.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04863</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Specification and Safety Proof of a Leaderless Concurrent Atomic
  Broadcast Algorithm</dc:title>
 <dc:creator>Poke, Marius</dc:creator>
 <dc:creator>Glass, Colin W.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Agreement plays a central role in distributed systems working on a common
task. The increasing size of modern distributed systems makes them more
susceptible to single component failures. Fault-tolerant distributed agreement
protocols rely for the most part on leader-based atomic broadcast algorithms,
such as Paxos. Such protocols are mostly used for data replication, which
requires only a small number of servers to reach agreement. Yet, their
centralized nature makes them ill-suited for distributed agreement at large
scales. The recently introduced atomic broadcast algorithm AllConcur enables
high throughput for distributed agreement while being completely decentralized.
In this paper, we extend the work on AllConcur in two ways. First, we provide a
formal specification of AllConcur that enables a better understanding of the
algorithm. Second, we formally prove AllConcur's safety property on the basis
of this specification. Therefore, our work not only ensures operators safe
usage of AllConcur, but also facilitates the further improvement of distributed
agreement protocols based on AllConcur.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures, 1 table</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04864</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synchronizing automata and the language of minimal reset words</dc:title>
 <dc:creator>Rodaro, Emanuele</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We study a connection between synchronizing automata and its set $M$ of
minimal reset words, i.e., such that no proper factor is a reset word. We first
show that any synchronizing automaton having the set of minimal reset words
whose set of factors does not contain a word of length at most
$\frac{1}{4}\min\{|u|: u\in I\}+\frac{1}{16}$ has a reset word of length at
most $(n-\frac{1}{2})^{2}$ In the last part of the paper we focus on the
existence of synchronizing automata with a given ideal $I$ that serves as the
set of reset words. To this end, we introduce the notion of the tail structure
of the (not necessarily regular) ideal $I=\Sigma^{*}M\Sigma^{*}$. With this
tool, we first show the existence of an infinite strongly connected
synchronizing automaton $\mathcal{A}$ having $I$ as the set of reset words and
such that every other strongly connected synchronizing automaton having $I$ as
the set of reset words is an homomorphic image of $\mathcal{A}$. Finally, we
show that for any non-unary regular ideal $I$ there is a strongly connected
synchronizing automaton having $I$ as the set of reset words with at most
$(km^{k})2^{km^{k}n}$ states, where $k=|\Sigma|$, $m$ is the length of a
shortest word in $M$, and $n$ is the dimension of the smallest automaton
recognizing $M$ (state complexity of $M$). This automaton is computable and we
show an algorithm to compute it in time $\mathcal{O}((k^{2}m^{k})2^{km^{k}n})$.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04866</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Economic Factors of Vulnerability Trade and Exploitation</dc:title>
 <dc:creator>Allodi, Luca</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Cybercrime markets support the development and diffusion of new attack
technologies, vulnerability exploits, and malware. Whereas the revenue streams
of cyber attackers have been studied multiple times in the literature, no
quantitative account currently exists on the economics of attack acquisition
and deployment. Yet, this understanding is critical to characterize the
production of (traded) exploits, the economy that drives it, and its effects on
the overall attack scenario. In this paper we provide an empirical
investigation of the economics of vulnerability exploitation, and the effects
of market factors on likelihood of exploit. Our data is collected
first-handedly from a prominent Russian cybercrime market where the trading of
the most active attack tools reported by the security industry happens. Our
findings reveal that exploits in the underground are priced similarly or above
vulnerabilities in legitimate bug-hunting programs, and that the refresh cycle
of exploits is slower than currently often assumed. On the other hand,
cybercriminals are becoming faster at introducing selected vulnerabilities, and
the market is in clear expansion both in terms of players, traded exploits, and
exploit pricing. We then evaluate the effects of these market variables on
likelihood of attack realization, and find strong evidence of the correlation
between market activity and exploit deployment. We discuss implications on
vulnerability metrics, economics, and exploit measurement.
</dc:description>
 <dc:description>Comment: 17 pages, 11 figures, 14 tables</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04866</dc:identifier>
 <dc:identifier>In Proceedings of the 2017 ACM SIGSAC Conference on Computer and
  Communications Security (CCS '17). ACM, New York, NY, USA, 1483-1499</dc:identifier>
 <dc:identifier>doi:10.1145/3133956.3133960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04871</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SMAUG: Secure Mobile Authentication Using Gestures</dc:title>
 <dc:creator>Gorke, Christian A.</dc:creator>
 <dc:creator>Armknecht, Frederik</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present SMAUG (Secure Mobile Authentication Using Gestures), a novel
biometric assisted authentication algorithm for mobile devices that is solely
based on data collected from multiple sensors that are usually installed on
modern devices -- touch screen, gyroscope and accelerometer. As opposed to
existing approaches, our system supports a fully flexible user input such as
free-form gestures, multi-touch, and arbitrary amount of strokes.
  Our experiments confirm that this approach provides a high level of
robustness and security. More precisely, in 77% of all our test cases over all
gestures considered, a user has been correctly identified during the first
authentication attempt and in 99% after the third attempt, while an attacker
has been detected in 97% of all test cases. As an example, gestures that have a
good balance between complexity and usability, e.g., drawing a two parallel
lines using two fingers at the same time, 100% success rate after three login
attempts and 97% impostor detection rate were given. We stress that we consider
the strongest possible attacker model: an attacker is not only allowed to
monitor the legitimate user during the authentication process, but also
receives additional information on the biometric properties, for example
pressure, speed, rotation, and acceleration. We see this method as a
significant step beyond existing authentication methods that can be deployed
directly to devices in use without the need of additional hardware.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04871</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04872</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ontology of Blockchain Technologies. Principles of Identification and
  Classification</dc:title>
 <dc:creator>Tasca, Paolo</dc:creator>
 <dc:creator>Thanabalasingham, Thayabaran</dc:creator>
 <dc:creator>Tessone, Claudio J.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A comparative study across the most widely known blockchain technologies is
conducted with a bottom-up approach. Blockchains are disentangled into building
blocks. Each building block is then hierarchically classified in main and
subcomponents. Then, alternative values (i.e., layouts) for the subcomponents
are identified and compared between them. Finally, an ontology matrix
summarises the study and provides a navigation tool across different blockchain
architectural configurations.
</dc:description>
 <dc:description>Comment: 58 pages, 10 figures</dc:description>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04873</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Heuristic Method for Scheduling Band Concert Tours</dc:title>
 <dc:creator>Nghiem, Linh</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Scheduling band concert tours is an important and challenging task faced by
many band management companies and producers. A band has to perform in various
cities over a period of time, and the specific route they follow is subject to
numerous constraints, such as: venue availability, travel limits, and required
rest periods. A good tour must consider several objectives regarding the
desirability of certain days of the week, as well as travel cost. We developed
and implemented a heuristic algorithm in Java, which was based on simulated
annealing, to automatically generate good tours that both satisfied the above
constraints and improved objectives significantly when compared to the best
manual tour created by the client. Our program also enabled the client to see
and explore trade-offs among objectives while choosing the best tour that meets
the requirements of the business.
</dc:description>
 <dc:date>2017-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04873</dc:identifier>
 <dc:identifier>Society for Industrial and Applied Mathematics (SIAM)
  Undergraduate Research Online (SIURO), 9</dc:identifier>
 <dc:identifier>doi:10.1137/14S013718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04875</identifier>
 <datestamp>2017-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Survey on Additive Manufacturing, Cloud 3D Printing and Services</dc:title>
 <dc:creator>Baumann, Felix W.</dc:creator>
 <dc:creator>Roller, Dieter</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Cloud Manufacturing (CM) is the concept of using manufacturing resources in a
service oriented way over the Internet. Recent developments in Additive
Manufacturing (AM) are making it possible to utilise resources ad-hoc as
replacement for traditional manufacturing resources in case of spontaneous
problems in the established manufacturing processes. In order to be of use in
these scenarios the AM resources must adhere to a strict principle of
transparency and service composition in adherence to the Cloud Computing (CC)
paradigm. With this review we provide an overview over CM, AM and relevant
domains as well as present the historical development of scientific research in
these fields, starting from 2002. Part of this work is also a meta-review on
the domain to further detail its development and structure.
</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04875</dc:identifier>
 <dc:identifier>doi:10.3390/jmmp1020015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04878</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enriching Information Technology Course Materials by Using Youtube</dc:title>
 <dc:creator>Abdillah, Leon Andretti</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  IT offers some benefits and collaborations in various sectors. This research
focuses on exploring higher education subjects via social technology, YouTube.
YouTube is the world largest video based contents application in the world.
Current learning materials are not only in text and images, but included video
contents. This research enriching students learning materials may involving
YouTube as learning sources. The study observed 118 sophomore students in
computer science faculty. The results show that, involving YouTube in enriching
students course material able to create conductive learning environment. This
strategy increases students understanding in their field of study.
</dc:description>
 <dc:description>Comment: Excellent Paper Award of AICSIT2017, 8 pages</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04878</dc:identifier>
 <dc:identifier>The 5th International Conference On Artificial Intelligence,
  Computer Science and Information Technology (AICSIT2017), Malaysia, 2017, pp.
  75-82</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04879</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interstitial Content Detection</dc:title>
 <dc:creator>Lucas, Elizabeth</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Interstitial content is online content which grays out, or otherwise obscures
the main page content. In this technical report, we discuss exploratory
research into detecting the presence of interstitial content in web pages. We
discuss the use of computer vision techniques to detect interstitials, and the
potential use of these techniques to provide a labelled dataset for machine
learning.
</dc:description>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04881</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polyhedral Clinching Auctions for Two-sided Markets</dc:title>
 <dc:creator>Hirai, Hiroshi</dc:creator>
 <dc:creator>Sato, Ryosuke</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>91B26, 91-08</dc:subject>
 <dc:description>  In this paper, we present a new model and mechanism for auctions in two-sided
markets of buyers and sellers, with budget constraints imposed on buyers. Our
mechanism is viewed as a two-sided extension of the polyhedral clinching
auction by Goel et al., and enjoys various nice properties, such as incentive
compatibility of buyers, individual rationality, pareto optimality, strong
budget balance. Our framework is built on polymatroid theory, and hence is
applicable to a wide variety of models that include multiunit auctions,
matching markets and reservation exchange markets.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04887</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fixed effects testing in high-dimensional linear mixed models</dc:title>
 <dc:creator>Bradic, Jelena</dc:creator>
 <dc:creator>Claeskens, Gerda</dc:creator>
 <dc:creator>Gueuning, Thomas</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many scientific and engineering challenges -- ranging from pharmacokinetic
drug dosage allocation and personalized medicine to marketing mix (4Ps)
recommendations -- require an understanding of the unobserved heterogeneity in
order to develop the best decision making-processes. In this paper, we develop
a hypothesis test and the corresponding p-value for testing for the
significance of the homogeneous structure in linear mixed models. A robust
matching moment construction is used for creating a test that adapts to the
size of the model sparsity. When unobserved heterogeneity at a cluster level is
constant, we show that our test is both consistent and unbiased even when the
dimension of the model is extremely high. Our theoretical results rely on a new
family of adaptive sparse estimators of the fixed effects that do not require
consistent estimation of the random effects. Moreover, our inference results do
not require consistent model selection. We showcase that moment matching can be
extended to nonlinear mixed effects models and to generalized linear mixed
effects models. In numerical and real data experiments, we find that the
developed method is extremely accurate, that it adapts to the size of the
underlying model and is decidedly powerful in the presence of irrelevant
covariates.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04890</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A deep architecture for unified aesthetic prediction</dc:title>
 <dc:creator>Murray, Naila</dc:creator>
 <dc:creator>Gordo, Albert</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image aesthetics has become an important criterion for visual content
curation on social media sites and media content repositories. Previous work on
aesthetic prediction models in the computer vision community has focused on
aesthetic score prediction or binary image labeling. However, raw aesthetic
annotations are in the form of score histograms and provide richer and more
precise information than binary labels or mean scores. Consequently, in this
work we focus on the rarely-studied problem of predicting aesthetic score
distributions and propose a novel architecture and training procedure for our
model. Our model achieves state-of-the-art results on the standard AVA
large-scale benchmark dataset for three tasks: (i) aesthetic quality
classification; (ii) aesthetic score regression; and (iii) aesthetic score
distribution prediction, all while using one model trained only for the
distribution prediction task. We also introduce a method to modify an image
such that its predicted aesthetics changes, and use this modification to gain
insight into our model.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04896</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Erasing Data Augmentation</dc:title>
 <dc:creator>Zhong, Zhun</dc:creator>
 <dc:creator>Zheng, Liang</dc:creator>
 <dc:creator>Kang, Guoliang</dc:creator>
 <dc:creator>Li, Shaozi</dc:creator>
 <dc:creator>Yang, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we introduce Random Erasing, a new data augmentation method
for training the convolutional neural network (CNN). In training, Random
Erasing randomly selects a rectangle region in an image and erases its pixels
with random values. In this process, training images with various levels of
occlusion are generated, which reduces the risk of over-fitting and makes the
model robust to occlusion. Random Erasing is parameter learning free, easy to
implement, and can be integrated with most of the CNN-based recognition models.
Albeit simple, Random Erasing is complementary to commonly used data
augmentation techniques such as random cropping and flipping, and yields
consistent improvement over strong baselines in image classification, object
detection and person re-identification. Code is available at:
https://github.com/zhunzhong07/Random-Erasing.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04903</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Primal-Dual Algorithms with Configuration Linear Programs</dc:title>
 <dc:creator>Thang, Nguyen Kim</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Non-linear, especially convex, objective functions have been extensively
studied in recent years in which approaches relies crucially on the convexity
property of cost functions. In this paper, we present primal-dual approaches
based on configuration linear programs to design competitive online algorithms
for problems with arbitrarily-grown objective. This approach is particularly
appropriate for non-linear (non-convex) objectives in online setting.
  We first present a simple greedy algorithm for a general cost-minimization
problem. The competitive ratio of the algorithm is characterized by the mean of
a notion, called smoothness, which is inspired by a similar concept in the
context of algorithmic game theory. The algorithm gives optimal (up to a
constant factor) competitive ratios while applying to different contexts such
as network routing, vector scheduling, energy-efficient scheduling and
non-convex facility location.
  Next, we consider the online $0-1$ covering problems with non-convex
objective. Building upon the resilient ideas from the primal-dual framework
with configuration LPs, we derive a competitive algorithm for these problems.
Our result generalizes the online primal-dual algorithm developed recently by
Azar et al. for convex objectives with monotone gradients to non-convex
objectives. The competitive ratio is now characterized by a new concept, called
local smoothness --- a notion inspired by the smoothness. Our algorithm yields
tight competitive ratio for the objectives such as the sum of $\ell_{k}$-norms
and gives competitive solutions for online problems of submodular minimization
and some natural non-convex minimization under covering constraints.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04907</identifier>
 <datestamp>2017-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-View Stereo with Single-View Semantic Mesh Refinement</dc:title>
 <dc:creator>Romanoni, Andrea</dc:creator>
 <dc:creator>Ciccone, Marco</dc:creator>
 <dc:creator>Visin, Francesco</dc:creator>
 <dc:creator>Matteucci, Matteo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While 3D reconstruction is a well-established and widely explored research
topic, semantic 3D reconstruction has only recently witnessed an increasing
share of attention from the Computer Vision community. Semantic annotations
allow in fact to enforce strong class-dependent priors, as planarity for ground
and walls, which can be exploited to refine the reconstruction often resulting
in non-trivial performance improvements. State-of-the art methods propose
volumetric approaches to fuse RGB image data with semantic labels; even if
successful, they do not scale well and fail to output high resolution meshes.
In this paper we propose a novel method to refine both the geometry and the
semantic labeling of a given mesh. We refine the mesh geometry by applying a
variational method that optimizes a composite energy made of a state-of-the-art
pairwise photo-metric term and a single-view term that models the semantic
consistency between the labels of the 3D mesh and those of the segmented
images. We also update the semantic labeling through a novel Markov Random
Field (MRF) formulation that, together with the classical data and smoothness
terms, takes into account class-specific priors estimated directly from the
annotated mesh. This is in contrast to state-of-the-art methods that are
typically based on handcrafted or learned priors. We are the first, jointly
with the very recent and seminal work of [M. Blaha et al arXiv:1706.08336,
2017], to propose the use of semantics inside a mesh refinement framework.
Differently from [M. Blaha et al arXiv:1706.08336, 2017], which adopts a more
classical pairwise comparison to estimate the flow of the mesh, we apply a
single-view comparison between the semantically annotated image and the current
3D mesh labels; this improves the robustness in case of noisy segmentations.
</dc:description>
 <dc:description>Comment: {\pounds}D Reconstruction Meets Semantic, ICCV workshop</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04908</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The covertime of a biased random walk on $G_{n,p}$</dc:title>
 <dc:creator>Cooper, Colin</dc:creator>
 <dc:creator>Frieze, Alan</dc:creator>
 <dc:creator>Petti, Samantha</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We analyze the covertime of a biased random walk on the random graph
$G_{n,p}$. The walk is biased towards visiting vertices of low degree and this
makes the covertime less than in the unbiased case
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04911</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Multi-Application Concurrency Support Within the GPU Memory
  System</dc:title>
 <dc:creator>Ausavarungnirun, Rachata</dc:creator>
 <dc:creator>Rossbach, Christopher J.</dc:creator>
 <dc:creator>Miller, Vance</dc:creator>
 <dc:creator>Landgraf, Joshua</dc:creator>
 <dc:creator>Ghose, Saugata</dc:creator>
 <dc:creator>Gnadhi, Jayneel</dc:creator>
 <dc:creator>Jog, Adwait</dc:creator>
 <dc:creator>Mutlu, Onur</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  GPUs exploit a high degree of thread-level parallelism to hide long-latency
stalls. Due to the heterogeneous compute requirements of different
applications, there is a growing need to share the GPU across multiple
applications in large-scale computing environments. However, while CPUs offer
relatively seamless multi-application concurrency, and are an excellent fit for
multitasking and for virtualized environments, GPUs currently offer only
primitive support for multi-application concurrency. Much of the problem in a
contemporary GPU lies within the memory system, where multi-application
execution requires virtual memory support to manage the address spaces of each
application and to provide memory protection. In this work, we perform a
detailed analysis of the major problems in state-of-the-art GPU virtual memory
management that hinders multi-application execution. Existing GPUs are designed
to share memory between the CPU and GPU, but do not handle multi-application
support within the GPU well. We find that when multiple applications spatially
share the GPU, there is a significant amount of inter-core thrashing on the
shared TLB within the GPU. The TLB contention is high enough to prevent the GPU
from successfully hiding stall latencies, thus becoming a first-order
performance concern. We introduce MASK, a memory hierarchy design that provides
low-overhead virtual memory support for the concurrent execution of multiple
applications. MASK extends the GPU memory hierarchy to efficiently support
address translation through the use of multi-level TLBs, and uses
translation-aware memory and cache management to maximize throughput in the
presence of inter-application contention.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04915</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DARVIZ: Deep Abstract Representation, Visualization, and Verification of
  Deep Learning Models</dc:title>
 <dc:creator>Sankaran, Anush</dc:creator>
 <dc:creator>Aralikatte, Rahul</dc:creator>
 <dc:creator>Mani, Senthil</dc:creator>
 <dc:creator>Khare, Shreya</dc:creator>
 <dc:creator>Panwar, Naveen</dc:creator>
 <dc:creator>Gantayat, Neelamadhav</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Traditional software engineering programming paradigms are mostly object or
procedure oriented, driven by deterministic algorithms. With the advent of deep
learning and cognitive sciences there is an emerging trend for data-driven
programming, creating a shift in the programming paradigm among the software
engineering communities. Visualizing and interpreting the execution of a
current large scale data-driven software development is challenging. Further,
for deep learning development there are many libraries in multiple programming
languages such as TensorFlow (Python), CAFFE (C++), Theano (Python), Torch
(Lua), and Deeplearning4j (Java), driving a huge need for interoperability
across libraries.
</dc:description>
 <dc:description>Comment: Accepted in ICSE NIER 2017. Preprint</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04915</dc:identifier>
 <dc:identifier>doi:10.1109/ICSE-NIER.2017.13</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04922</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Alarms for Vehicular Collision Detection</dc:title>
 <dc:creator>Motro, Michael</dc:creator>
 <dc:creator>Ghosh, Joydeep</dc:creator>
 <dc:creator>Bhat, Chandra</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  An important application of intelligent vehicles is advance detection of
dangerous events such as collisions. This problem is framed as a problem of
optimal alarm choice given predictive models for vehicle location and motion.
Techniques for real-time collision detection are surveyed and grouped into
three classes: random Monte Carlo sampling, faster deterministic
approximations, and machine learning models trained by simulation. Theoretical
guarantees on the performance of these collision detection techniques are
provided where possible, and empirical analysis is provided for two example
scenarios. Results validate Monte Carlo sampling as a robust solution despite
its simplicity.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04922</dc:identifier>
 <dc:identifier>doi:10.1109/IVS.2017.7995732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04923</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>mAnI: Movie Amalgamation using Neural Imitation</dc:title>
 <dc:creator>Panwar, Naveen</dc:creator>
 <dc:creator>Khare, Shreya</dc:creator>
 <dc:creator>Gantayat, Neelamadhav</dc:creator>
 <dc:creator>Aralikatte, Rahul</dc:creator>
 <dc:creator>Mani, Senthil</dc:creator>
 <dc:creator>Sankaran, Anush</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Cross-modal data retrieval has been the basis of various creative tasks
performed by Artificial Intelligence (AI). One such highly challenging task for
AI is to convert a book into its corresponding movie, which most of the
creative film makers do as of today. In this research, we take the first step
towards it by visualizing the content of a book using its corresponding movie
visuals. Given a set of sentences from a book or even a fan-fiction written in
the same universe, we employ deep learning models to visualize the input by
stitching together relevant frames from the movie. We studied and compared
three different types of setting to match the book with the movie content: (i)
Dialog model: using only the dialog from the movie, (ii) Visual model: using
only the visual content from the movie, and (iii) Hybrid model: using the
dialog and the visual content from the movie. Experiments on the publicly
available MovieBook dataset shows the effectiveness of the proposed models.
</dc:description>
 <dc:description>Comment: Accepted in ML4Creativity workshop in KDD 2017. Preprint</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04927</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TheoSea: Marching Theory to Light</dc:title>
 <dc:creator>Stalzer, Mark A.</dc:creator>
 <dc:creator>Ju, Chao</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  There is sufficient information in the far-field of a radiating dipole
antenna to rediscover the Maxwell Equations and the wave equations of light,
including the speed of light $c.$ TheoSea is a Julia program that does this in
about a second, and the key insight is that the compactness of theories drives
the search. The program is a computational embodiment of the scientific method:
observation, consideration of candidate theories, and validation.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:1706.06975</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04928</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eigenvalue Solvers for Modeling Nuclear Reactors on Leadership Class
  Machines</dc:title>
 <dc:creator>Slaybaugh, R. N.</dc:creator>
 <dc:creator>Ramirez-Zweiger, M.</dc:creator>
 <dc:creator>Pandya, Tara</dc:creator>
 <dc:creator>Hamilton, Steven</dc:creator>
 <dc:creator>Evans, T. M.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Three complementary methods have been implemented in the code Denovo that
accelerate neutral particle transport calculations with methods that use
leadership-class computers fully and effectively: a multigroup block (MG)
Krylov solver, a Rayleigh Quotient Iteration (RQI) eigenvalue solver, and a
multigrid in energy (MGE) preconditioner. The MG Krylov solver converges more
quickly than Gauss Seidel and enables energy decomposition such that Denovo can
scale to hundreds of thousands of cores. RQI should converge in fewer
iterations than power iteration (PI) for large and challenging problems. RQI
creates shifted systems that would not be tractable without the MG Krylov
solver. It also creates ill-conditioned matrices. The MGE preconditioner
reduces iteration count significantly when used with RQI and takes advantage of
the new energy decomposition such that it can scale efficiently. Each
individual method has been described before, but this is the first time they
have been demonstrated to work together effectively.
  The combination of solvers enables the RQI eigenvalue solver to work better
than the other available solvers for large reactors problems on leadership
class machines. Using these methods together, RQI converged in fewer iterations
and in less time than PI for a full pressurized water reactor core. These
solvers also performed better than an Arnoldi eigenvalue solver for a reactor
benchmark problem when energy decomposition is needed. The MG Krylov, MGE
preconditioner, and RQI solver combination also scales well in energy. This
solver set is a strong choice for very large and challenging problems.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1702.02111,
  arXiv:1612.00907</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04928</dc:identifier>
 <dc:identifier>doi:10.1080/00295639.2017.1413875</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04943</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stacked Deconvolutional Network for Semantic Segmentation</dc:title>
 <dc:creator>Fu, Jun</dc:creator>
 <dc:creator>Liu, Jing</dc:creator>
 <dc:creator>Wang, Yuhang</dc:creator>
 <dc:creator>Lu, Hanqing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent progress in semantic segmentation has been driven by improving the
spatial resolution under Fully Convolutional Networks (FCNs). To address this
problem, we propose a Stacked Deconvolutional Network (SDN) for semantic
segmentation. In SDN, multiple shallow deconvolutional networks, which are
called as SDN units, are stacked one by one to integrate contextual information
and guarantee the fine recovery of localization information. Meanwhile,
inter-unit and intra-unit connections are designed to assist network training
and enhance feature fusion since the connections improve the flow of
information and gradient propagation throughout the network. Besides,
hierarchical supervision is applied during the upsampling process of each SDN
unit, which guarantees the discrimination of feature representations and
benefits the network optimization. We carry out comprehensive experiments and
achieve the new state-of-the-art results on three datasets, including PASCAL
VOC 2012, CamVid, GATECH. In particular, our best model without CRF
post-processing achieves an intersection-over-union score of 86.6% in the test
set.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04945</identifier>
 <datestamp>2017-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Balanced Allocation Through Random Walk</dc:title>
 <dc:creator>Frieze, Alan</dc:creator>
 <dc:creator>Petti, Samantha</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We consider the allocation problem in which $m \leq (1-\epsilon) dn $ items
are to be allocated to $n$ bins with capacity $d$. The items
$x_1,x_2,\ldots,x_m$ arrive sequentially and when item $x_i$ arrives it is
given two possible bin locations $p_i=h_1(x_i),q_i=h_2(x_i)$ via hash functions
$h_1,h_2$. We consider a random walk procedure for inserting items and show
that the expected time insertion time is constant provided $\epsilon =
\Omega\left(\sqrt{ \frac{ \log d}{d}} \right).$
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04955</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>qBitcoin: A Peer-to-Peer Quantum Cash System</dc:title>
 <dc:creator>Ikeda, Kazuki</dc:creator>
 <dc:subject>Quantitative Finance - General Finance</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  A decentralized online quantum cash system, called qBitcoin, is given. We
design the system which has great benefits of quantization in the following
sense. Firstly, quantum teleportation technology is used for coin transaction,
which prevents from the owner of the coin keeping the original coin data even
after sending the coin to another. This was a main problem in a classical
circuit and a blockchain was introduced to solve this issue. In qBitcoin, the
double-spending problem never happens and its security is guaranteed
theoretically by virtue of quantum information theory. Making a block is time
consuming and the system of qBitcoin is based on a quantum chain, instead of
blocks. Therefore a payment can be completed much faster than Bitcoin. Moreover
we employ quantum digital signature so that it naturally inherits properties of
peer-to-peer (P2P) cash system as originally proposed in Bitcoin.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04956</identifier>
 <datestamp>2017-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strategic Communication Between Prospect Theoretic Agents over a
  Gaussian Test Channel</dc:title>
 <dc:creator>Nadendla, Venkata Sriram Siddhardh</dc:creator>
 <dc:creator>Akyol, Emrah</dc:creator>
 <dc:creator>Langbort, Cedric</dc:creator>
 <dc:creator>Ba&#x15f;ar, Tamer</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we model a Stackelberg game in a simple Gaussian test channel
where a human transmitter (leader) communicates a source message to a human
receiver (follower). We model human decision making using prospect theory
models proposed for continuous decision spaces. Assuming that the value
function is the squared distortion at both the transmitter and the receiver, we
analyze the effects of the weight functions at both the transmitter and the
receiver on optimal communication strategies, namely encoding at the
transmitter and decoding at the receiver, in the Stackelberg sense. We show
that the optimal strategies for the behavioral agents in the Stackelberg sense
are identical to those designed for unbiased agents. At the same time, we also
show that the prospect-theoretic distortions at both the transmitter and the
receiver are both larger than the expected distortion, thus making behavioral
agents less contended than unbiased agents. Consequently, the presence of
cognitive biases increases the need for transmission power in order to achieve
a given distortion at both transmitter and receiver.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, Accepted to MILCOM-2017, Corrections made in the
  new version</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2017-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04963</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introducing the truly chaotic finite state machines and their
  applications in security field</dc:title>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Wang, Qianxue</dc:creator>
 <dc:creator>Fang, Xiole</dc:creator>
 <dc:creator>Bahi, Jacques</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The truly chaotic finite machines introduced by authors in previous research
papers are presented here. A state of the art in this discipline, encompassing
all previous mathematical investigations, is provided, explaining how finite
state machines can behave chaotically regarding the slight alteration of their
inputs. This behavior is explained using Turing machines and formalized thanks
to a special family of discrete dynamical systems called chaotic iterations. An
illustrative example is finally given in the field of hash functions.
</dc:description>
 <dc:date>2017-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04968</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fault in your stars: An Analysis of Android App Reviews</dc:title>
 <dc:creator>Aralikatte, Rahul</dc:creator>
 <dc:creator>Sridhara, Giriprasad</dc:creator>
 <dc:creator>Gantayat, Neelamadhav</dc:creator>
 <dc:creator>Mani, Senthil</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Mobile app distribution platforms such as Google Play Store allow users to
share their feedback about downloaded apps in the form of a review comment and
a corresponding star rating. Typically, the star rating ranges from one to five
stars, with one star denoting a high sense of dissatisfaction with the app and
five stars denoting a high sense of satisfaction.
  Unfortunately, due to a variety of reasons, often the star rating provided by
a user is inconsistent with the opinion expressed in the review. For example,
consider the following review for the Facebook App on Android; &quot;Awesome App&quot;.
One would reasonably expect the rating for this review to be five stars, but
the actual rating is one star!
  Such inconsistent ratings can lead to a deflated (or inflated) overall
average rating of an app which can affect user downloads, as typically users
look at the average star ratings while making a decision on downloading an app.
Also, the app developers receive a biased feedback about the application that
does not represent ground reality. This is especially significant for small
apps with a few thousand downloads as even a small number of mismatched reviews
can bring down the average rating drastically.
  In this paper, we conducted a study on this review-rating mismatch problem.
We manually examined 8600 reviews from 10 popular Android apps and found that
20% of the ratings in our dataset were inconsistent with the review. Further,
we developed three systems; two of which were based on traditional machine
learning and one on deep learning to automatically identify reviews whose
rating did not match with the opinion expressed in the review. Our deep
learning system performed the best and had an accuracy of 92% in identifying
the correct star rating to be associated with a given review.
</dc:description>
 <dc:description>Comment: Under review in CoDS-COMAD 2018. Preprint</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04968</dc:identifier>
 <dc:identifier>doi:10.1145/3152494.3152500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04970</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Threshold Sampling and Estimation</dc:title>
 <dc:creator>Ting, Daniel</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Sampling is a fundamental problem in both computer science and statistics. A
number of issues arise when designing a method based on sampling. These include
statistical considerations such as constructing a good sampling design and
ensuring there are good, tractable estimators for the quantities of interest as
well as computational considerations such as designing fast algorithms for
streaming data and ensuring the sample fits within memory constraints.
Unfortunately, existing sampling methods are only able to address all of these
issues in limited scenarios.
  We develop a framework that can be used to address these issues in a broad
range of scenarios. In particular, it addresses the problem of drawing and
using samples under some memory budget constraint. This problem can be
challenging since the memory budget forces samples to be drawn
non-independently and consequently, makes computation of resulting estimators
difficult.
  At the core of the framework is the notion of a data adaptive thresholding
scheme where the threshold effectively allows one to treat the non-independent
sample as if it were drawn independently. We provide sufficient conditions for
a thresholding scheme to allow this and provide ways to build and compose such
schemes.
  Furthermore, we provide fast algorithms to efficiently sample under these
thresholding schemes.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04972</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Side Information in the Binary Stochastic Block Model: Exact Recovery</dc:title>
 <dc:creator>Saad, Hussein</dc:creator>
 <dc:creator>Abotabl, Ahmed</dc:creator>
 <dc:creator>Nosratinia, Aria</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the community detection problem, one may have access to additional
observations (side information) about the label of each node. This paper
studies the effect of the quality and quantity of side information on the phase
transition of exact recovery in the binary symmetric stochastic block model
(SBM) with $n$ nodes. When the side information consists of the label observed
through a binary symmetric channel with crossover probability $\alpha$, and
when $\log(\frac{1-\alpha}{\alpha}) =O(\log(n))$, it is shown that side
information has a positive effect on phase transition; the new phase transition
under this condition is characterized. When $\alpha$ is constant or approaches
zero sufficiently slowly, i.e., $\log(\frac{1-\alpha}{\alpha}) = o(\log(n))$,
it is shown that side information does not help exact recovery. When the side
information consists of the label observed through a binary erasure channel
with parameter $\epsilon$, and when $\log(\epsilon)=O(\log(n))$, it is shown
that side information improves exact recovery and the new phase transition is
characterized. If $\log(\epsilon)=o(\log(n))$, then it is shown that side
information is not helpful. The results are then generalized to an arbitrary
side information of finite cardinality. Necessary and sufficient conditions are
derived for exact recovery that are tight, except for one special case under
$M$-ary side information. An efficient algorithm that incorporates the effect
of side information is proposed that uses a partial recovery algorithm combined
with a local improvement procedure. Sufficient conditions are derived for exact
recovery under this efficient algorithm.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04974</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A fast coset-translation algorithm for computing the cycle structure of
  Comer relation algebras over $\mathbb{Z}/p\mathbb{Z}$</dc:title>
 <dc:creator>Alm, Jeremy F.</dc:creator>
 <dc:creator>Ylvisaker, Andrew</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>03G15, 11Y16</dc:subject>
 <dc:description>  Proper relation algebras can be constructed using $\mathbb{Z}/p\mathbb{Z}$ as
a base set using a method due to Comer. The cycle structure of such an algebra
must, in general, be determined \emph{a posteriori}, normally with the aid of a
computer. In this paper, we give an improved algorithm for checking the cycle
structure that reduces the time complexity from $\mathcal{O}(p^2)$ to
$\mathcal{O}(p)$.
</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:date>2018-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04975</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient training-image based geostatistical simulation and inversion
  using a spatial generative adversarial neural network</dc:title>
 <dc:creator>Laloy, Eric</dc:creator>
 <dc:creator>H&#xe9;rault, Romain</dc:creator>
 <dc:creator>Jacques, Diederik</dc:creator>
 <dc:creator>Linde, Niklas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Geophysics</dc:subject>
 <dc:description>  Probabilistic inversion within a multiple-point statistics framework is still
computationally prohibitive for large-scale problems. To partly address this,
we introduce and evaluate a new training-image based simulation and inversion
approach for complex geologic media. Our approach relies on a deep neural
network of the spatial generative adversarial network (SGAN) type. After
training using a training image (TI), our proposed SGAN can quickly generate 2D
and 3D unconditional realizations. A key feature of our SGAN is that it defines
a (very) low-dimensional parameterization, thereby allowing for efficient
probabilistic (or deterministic) inversion using state-of-the-art Markov chain
Monte Carlo (MCMC) methods. A series of 2D and 3D categorical TIs is first used
to analyze the performance of our SGAN for unconditional simulation. The speed
at which realizations are generated makes it especially useful for simulating
over large grids and/or from a complex multi-categorical TI. Subsequently,
synthetic inversion case studies involving 2D steady-state flow and 3D
transient hydraulic tomography are used to illustrate the effectiveness of our
proposed SGAN-based probabilistic inversion. For the 2D case, the inversion
rapidly explores the posterior model distribution. For the 3D case, the
inversion recovers model realizations that fit the data close to the target
level and visually resemble the true model well. Future work will focus on the
inclusion of direct conditioning data and application to continuous TIs.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04975</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04976</identifier>
 <datestamp>2017-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A fix-point characterization of Herbrand equivalence of expressions in
  data flow frameworks</dc:title>
 <dc:creator>Babu, Jasine</dc:creator>
 <dc:creator>Krishnan, K. Murali</dc:creator>
 <dc:creator>Paleri, Vineeth</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  The problem of determining Herbrand equivalence of terms at each program
point in a data flow framework is a central and well studied question in
program analysis. Most of the well-known algorithms for the computation of
Herbrand equivalence in data flow frameworks proceed via iterative fix-point
computation on some abstract lattice of short expressions relevant to the given
flow graph. However the mathematical definition of Herbrand equivalence is
based on a meet over all path characterization over the (infinite) set of all
possible expressions. The aim of this paper is to develop a lattice theoretic
fix-point formulation of Herbrand equivalence on the (infinite) concrete
lattice defined over the set of all terms constructible from variables,
constants and operators of a program. The present characterization uses an
axiomatic formulation of the notion of Herbrand congruence and defines the
(infinite) concrete lattice of Herbrand congruences. Transfer functions and
non-deterministic assignments are formulated as monotone functions over this
concrete lattice. Herbrand equivalence is defined as the maximum fix point of a
composite transfer function defined over an appropriate product lattice of the
above concrete lattice. A re-formulation of the classical meet-over-all-paths
definition of Herbrand equivalence in the above lattice theoretic framework is
also presented and is proven to be equivalent to the new lattice theoretic
fix-point characterization.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-10-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04983</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualizing and Exploring Dynamic High-Dimensional Datasets with
  LION-tSNE</dc:title>
 <dc:creator>Boytsov, Andrey</dc:creator>
 <dc:creator>Fouquet, Francois</dc:creator>
 <dc:creator>Hartmann, Thomas</dc:creator>
 <dc:creator>LeTraon, Yves</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.m</dc:subject>
 <dc:description>  T-distributed stochastic neighbor embedding (tSNE) is a popular and
prize-winning approach for dimensionality reduction and visualizing
high-dimensional data. However, tSNE is non-parametric: once visualization is
built, tSNE is not designed to incorporate additional data into existing
representation. It highly limits the applicability of tSNE to the scenarios
where data are added or updated over time (like dashboards or series of data
snapshots).
  In this paper we propose, analyze and evaluate LION-tSNE (Local Interpolation
with Outlier coNtrol) - a novel approach for incorporating new data into tSNE
representation. LION-tSNE is based on local interpolation in the vicinity of
training data, outlier detection and a special outlier mapping algorithm. We
show that LION-tSNE method is robust both to outliers and to new samples from
existing clusters. We also discuss multiple possible improvements for special
cases.
  We compare LION-tSNE to a comprehensive list of possible benchmark approaches
that include multiple interpolation techniques, gradient descent for new data,
and neural network approximation.
</dc:description>
 <dc:description>Comment: 44 pages, 24 figures, 7 tables, planned for submission</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04986</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MaxMinSum Steiner Systems for Access-Balancing in Distributed Storage</dc:title>
 <dc:creator>Dau, Hoang</dc:creator>
 <dc:creator>Milenkovic, Olgica</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Many code families such as low-density parity-check codes, fractional
repetition codes, batch codes and private information retrieval codes with low
storage overhead rely on the use of combinatorial block designs or derivatives
thereof. In the context of distributed storage applications, one is often faced
with system design issues that impose additional constraints on the coding
schemes, and therefore on the underlying block designs. Here, we address one
such problem, pertaining to server access frequency balancing, by introducing a
new form of Steiner systems, termed MaxMinSum Steiner systems. MinMaxSum
Steiner systems are characterized by the property that the minimum value of the
sum of points (elements) within a block is maximized, or that the minimum sum
of block indices containing some fixed point is maximized. We show that proper
relabelings of points in the Bose and Skolem constructions for Steiner triple
systems lead to optimal MaxMin values for the sums of interest; for the duals
of the designs, we exhibit block labelings that are within a $3/4$
multiplicative factor from the optimum. We conjecture the existence of
MaxMinSum Steiner triple systems for all sets of parameters for which the
unconstrained systems exist, independent of the particular construction used.
</dc:description>
 <dc:description>Comment: 28 pages</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04987</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ANI-1: A data set of 20M off-equilibrium DFT calculations for organic
  molecules</dc:title>
 <dc:creator>Smith, Justin S.</dc:creator>
 <dc:creator>Isayev, Olexandr</dc:creator>
 <dc:creator>Roitberg, Adrian E.</dc:creator>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  One of the grand challenges in modern theoretical chemistry is designing and
implementing approximations that expedite ab initio methods without loss of
accuracy. Machine learning (ML), in particular neural networks, are emerging as
a powerful approach to constructing various forms of transferable atomistic
potentials. They have been successfully applied in a variety of applications in
chemistry, biology, catalysis, and solid-state physics. However, these models
are heavily dependent on the quality and quantity of data used in their
fitting. Fitting highly flexible ML potentials comes at a cost: a vast amount
of reference data is required to properly train these models. We address this
need by providing access to a large computational DFT database, which consists
of 20M conformations for 57,454 small organic molecules. We believe it will
become a new standard benchmark for comparison of current and future methods in
the ML potential community.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04987</dc:identifier>
 <dc:identifier>Scientific Data 4, Article number: 170193 (2017)</dc:identifier>
 <dc:identifier>doi:10.1038/sdata.2017.193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04988</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Warp: a method for neural network interpretability applied to gene
  expression profiles</dc:title>
 <dc:creator>Assya, Trofimov</dc:creator>
 <dc:creator>Sebastien, Lemieux</dc:creator>
 <dc:creator>Claude, Perreault</dc:creator>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We show a proof of principle for warping, a method to interpret the inner
working of neural networks in the context of gene expression analysis. Warping
is an efficient way to gain insight to the inner workings of neural nets and
make them more interpretable. We demonstrate the ability of warping to recover
meaningful information for a given class on a samplespecific individual basis.
We found warping works well in both linearly and nonlinearly separable
datasets. These encouraging results show that warping has a potential to be the
answer to neural networks interpretability in computational biology.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, NIPS2016, Machine Learning in Computational
  Biology workshop</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04989</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Free Space Estimation using Occupancy Grids and Dynamic Object Detection</dc:title>
 <dc:creator>Sahdev, Raghavender</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we present an approach to estimate Free Space from a Stereo
image pair using stochastic occupancy grids. We do this in the domain of
autonomous driving on the famous benchmark dataset KITTI. Later based on the
generated occupancy grid we match 2 image sequences to compute the top view
representation of the map. We do this to map the environment. We compute a
transformation between the occupancy grids of two successive images and use it
to compute the top view map. Two issues need to be addressed for mapping are
discussed - computing a map and dealing with dynamic objects for computing the
map. Dynamic Objects are detected in successive images based on an idea similar
to tracking of foreground objects from the background objects based on motion
flow. A novel RANSAC based segmentation approach has been proposed here to
address this issue.
</dc:description>
 <dc:description>Comment: 10 pages, 10 figures</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.04999</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized least squares can overcome the critical threshold in
  respondent-driven sampling</dc:title>
 <dc:creator>Roch, Sebastien</dc:creator>
 <dc:creator>Rohe, Karl</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  In order to sample marginalized and/or hard-to-reach populations,
respondent-driven sampling (RDS) and similar techniques reach their
participants via peer referral. Under a Markov model for RDS, previous research
has shown that if the typical participant refers too many contacts, then the
variance of common estimators does not decay like $O(n^{-1})$, where $n$ is the
sample size. This implies that confidence intervals will be far wider than
under a typical sampling design. Here we show that generalized least squares
(GLS) can effectively reduce the variance of RDS estimates. In particular, a
theoretical analysis indicates that the variance of the GLS estimator is
$O(n^{-1})$. We then derive two classes of feasible GLS estimators. The first
class is based upon a Degree Corrected Stochastic Blockmodel for the underlying
social network. The second class is based upon a rank-two model. It might be of
independent interest that in both model classes, the theoretical results show
that it is possible to estimate the spectral properties of the population
network from the sampled observations. Simulations on empirical social networks
show that the feasible GLS (fGLS) estimators can have drastically smaller error
and rarely increase the error. A diagnostic plot helps to identify where fGLS
will aid estimation. The fGLS estimators continue to outperform standard
estimators even when they are built from a misspecified model and when there is
preferential recruitment.
</dc:description>
 <dc:description>Comment: Submitted</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.04999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05004</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RodFIter: Attitude Reconstruction from Inertial Measurement by
  Functional Iteration</dc:title>
 <dc:creator>Wu, Yuanxin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Rigid motion computation or estimation is a cornerstone in numerous fields.
Attitude computation can be achieved by integrating the angular velocity
measured by gyroscopes, the accuracy of which is crucially important for the
dead-reckoning inertial navigation. The state-of-the-art attitude algorithms
have unexceptionally relied on the simplified differential equation of the
rotation vector to obtain the attitude. This paper proposes a Functional
Iteration technique with the Rodrigues vector (named the RodFIter method) to
analytically reconstruct the attitude from gyroscope measurements. The RodFIter
method is provably exact in reconstructing the incremental attitude as long as
the angular velocity is exact. Notably, the Rodrigues vector is analytically
obtained and can be used to update the attitude over the considered time
interval. The proposed method gives birth to an ultimate attitude algorithm
scheme that can be naturally extended to the general rigid motion computation.
It is extensively evaluated under the attitude coning motion and compares
favorably in accuracy with the mainstream attitude algorithms. This work is
believed having eliminated the long-standing theoretical barrier in exact
motion integration from inertial measurements.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-10-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05006</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Augmented Reality Navigation</dc:title>
 <dc:creator>Bhorkar, Gaurav</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Navigation has been a popular area of research in both academia and industry.
Combined with maps, and different localization technologies, navigation systems
have become robust and more usable. By combining navigation with augmented
reality, it can be improved further to become realistic and user friendly. This
paper surveys existing researches carried out in this area, describes existing
techniques for building augmented reality navigation systems, and the problems
faced.
</dc:description>
 <dc:description>Comment: Seminar on Software Systems, Technologies and Security, Spring 2016,
  Aalto University</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05019</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Salt-n-pepper noise filtering using Cellular Automata</dc:title>
 <dc:creator>Tourtounis, Dimitrios</dc:creator>
 <dc:creator>Mitianoudis, Nikolaos</dc:creator>
 <dc:creator>Sirakoulis, Georgios Ch.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Cellular Automata (CA) have been considered one of the most pronounced
parallel computational tools in the recent era of nature and bio-inspired
computing. Taking advantage of their local connectivity, the simplicity of
their design and their inherent parallelism, CA can be effectively applied to
many image processing tasks. In this paper, a CA approach for efficient
salt-n-pepper noise filtering in grayscale images is presented. Using a 2D
Moore neighborhood, the classified &quot;noisy&quot; cells are corrected by averaging the
non-noisy neighboring cells. While keeping the computational burden really low,
the proposed approach succeeds in removing high-noise levels from various
images and yields promising qualitative and quantitative results, compared to
state-of-the-art techniques.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05019</dc:identifier>
 <dc:identifier>Journal of Cellular Automata, Vol. 13, No. 1-2, pp. 81-101, 2018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05024</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Matrix Factorization for Online Recommendation with Implicit
  Feedback</dc:title>
 <dc:creator>He, Xiangnan</dc:creator>
 <dc:creator>Zhang, Hanwang</dc:creator>
 <dc:creator>Kan, Min-Yen</dc:creator>
 <dc:creator>Chua, Tat-Seng</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This paper contributes improvements on both the effectiveness and efficiency
of Matrix Factorization (MF) methods for implicit feedback. We highlight two
critical issues of existing works. First, due to the large space of unobserved
feedback, most existing works resort to assign a uniform weight to the missing
data to reduce computational complexity. However, such a uniform assumption is
invalid in real-world settings. Second, most methods are also designed in an
offline setting and fail to keep up with the dynamic nature of online data. We
address the above two issues in learning MF models from implicit feedback. We
first propose to weight the missing data based on item popularity, which is
more effective and flexible than the uniform-weight assumption. However, such a
non-uniform weighting poses efficiency challenge in learning the model. To
address this, we specifically design a new learning algorithm based on the
element-wise Alternating Least Squares (eALS) technique, for efficiently
optimizing a MF model with variably-weighted missing data. We exploit this
efficiency to then seamlessly devise an incremental update strategy that
instantly refreshes a MF model given new feedback. Through comprehensive
experiments on two public datasets in both offline and online protocols, we
show that our eALS method consistently outperforms state-of-the-art implicit MF
methods. Our implementation is available at
https://github.com/hexiangnan/sigir16-eals.
</dc:description>
 <dc:description>Comment: 10 pages, 8 figures</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05027</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Factorization Machines for Sparse Predictive Analytics</dc:title>
 <dc:creator>He, Xiangnan</dc:creator>
 <dc:creator>Chua, Tat-Seng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many predictive tasks of web applications need to model categorical
variables, such as user IDs and demographics like genders and occupations. To
apply standard machine learning techniques, these categorical predictors are
always converted to a set of binary features via one-hot encoding, making the
resultant feature vector highly sparse. To learn from such sparse data
effectively, it is crucial to account for the interactions between features.
  Factorization Machines (FMs) are a popular solution for efficiently using the
second-order feature interactions. However, FM models feature interactions in a
linear way, which can be insufficient for capturing the non-linear and complex
inherent structure of real-world data. While deep neural networks have recently
been applied to learn non-linear feature interactions in industry, such as the
Wide&amp;Deep by Google and DeepCross by Microsoft, the deep structure meanwhile
makes them difficult to train.
  In this paper, we propose a novel model Neural Factorization Machine (NFM)
for prediction under sparse settings. NFM seamlessly combines the linearity of
FM in modelling second-order feature interactions and the non-linearity of
neural network in modelling higher-order feature interactions. Conceptually,
NFM is more expressive than FM since FM can be seen as a special case of NFM
without hidden layers. Empirical results on two regression tasks show that with
one hidden layer only, NFM significantly outperforms FM with a 7.3% relative
improvement. Compared to the recent deep learning methods Wide&amp;Deep and
DeepCross, our NFM uses a shallower structure but offers better performance,
being much easier to train and tune in practice.
</dc:description>
 <dc:description>Comment: 10 pages, 8 figures</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05029</identifier>
 <datestamp>2017-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Neural Network Capacity</dc:title>
 <dc:creator>Wang, Aosen</dc:creator>
 <dc:creator>Zhou, Hua</dc:creator>
 <dc:creator>Xu, Wenyao</dc:creator>
 <dc:creator>Chen, Xin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In recent years, deep neural network exhibits its powerful superiority on
information discrimination in many computer vision applications. However, the
capacity of deep neural network architecture is still a mystery to the
researchers. Intuitively, larger capacity of neural network can always deposit
more information to improve the discrimination ability of the model. But, the
learnable parameter scale is not feasible to estimate the capacity of deep
neural network. Due to the overfitting, directly increasing hidden nodes number
and hidden layer number are already demonstrated not necessary to effectively
increase the network discrimination ability.
  In this paper, we propose a novel measurement, named &quot;total valid bits&quot;, to
evaluate the capacity of deep neural networks for exploring how to
quantitatively understand the deep learning and the insights behind its super
performance. Specifically, our scheme to retrieve the total valid bits
incorporates the skilled techniques in both training phase and inference phase.
In the network training, we design decimal weight regularization and 8-bit
forward quantization to obtain the integer-oriented network representations.
Moreover, we develop adaptive-bitwidth and non-uniform quantization strategy in
the inference phase to find the neural network capacity, total valid bits. By
allowing zero bitwidth, our adaptive-bitwidth quantization can execute the
model reduction and valid bits finding simultaneously. In our extensive
experiments, we first demonstrate that our total valid bits is a good indicator
of neural network capacity. We also analyze the impact on network capacity from
the network architecture and advanced training skills, such as dropout and
batch normalization.
</dc:description>
 <dc:description>Comment: There an error in Average Valid Bits computation in figure 1 in page
  2</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05031</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Collaborative Filtering</dc:title>
 <dc:creator>He, Xiangnan</dc:creator>
 <dc:creator>Liao, Lizi</dc:creator>
 <dc:creator>Zhang, Hanwang</dc:creator>
 <dc:creator>Nie, Liqiang</dc:creator>
 <dc:creator>Hu, Xia</dc:creator>
 <dc:creator>Chua, Tat-Seng</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In recent years, deep neural networks have yielded immense success on speech
recognition, computer vision and natural language processing. However, the
exploration of deep neural networks on recommender systems has received
relatively less scrutiny. In this work, we strive to develop techniques based
on neural networks to tackle the key problem in recommendation -- collaborative
filtering -- on the basis of implicit feedback. Although some recent work has
employed deep learning for recommendation, they primarily used it to model
auxiliary information, such as textual descriptions of items and acoustic
features of musics. When it comes to model the key factor in collaborative
filtering -- the interaction between user and item features, they still
resorted to matrix factorization and applied an inner product on the latent
features of users and items. By replacing the inner product with a neural
architecture that can learn an arbitrary function from data, we present a
general framework named NCF, short for Neural network-based Collaborative
Filtering. NCF is generic and can express and generalize matrix factorization
under its framework. To supercharge NCF modelling with non-linearities, we
propose to leverage a multi-layer perceptron to learn the user-item interaction
function. Extensive experiments on two real-world datasets show significant
improvements of our proposed NCF framework over the state-of-the-art methods.
Empirical evidence shows that using deeper layers of neural networks offers
better recommendation performance.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05033</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Corrupt Bandits for Preserving Local Privacy</dc:title>
 <dc:creator>Gajane, Pratik</dc:creator>
 <dc:creator>Urvoy, Tanguy</dc:creator>
 <dc:creator>Kaufmann, Emilie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study a variant of the stochastic multi-armed bandit (MAB) problem in
which the rewards are corrupted. In this framework, motivated by privacy
preservation in online recommender systems, the goal is to maximize the sum of
the (unobserved) rewards, based on the observation of transformation of these
rewards through a stochastic corruption process with known parameters. We
provide a lower bound on the expected regret of any bandit algorithm in this
corrupted setting. We devise a frequentist algorithm, KLUCB-CF, and a Bayesian
algorithm, TS-CF and give upper bounds on their regret. We also provide the
appropriate corruption parameters to guarantee a desired level of local privacy
and analyze how this impacts the regret. Finally, we present some experimental
results that confirm our analysis.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05038</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ConvNet Architecture Search for Spatiotemporal Feature Learning</dc:title>
 <dc:creator>Tran, Du</dc:creator>
 <dc:creator>Ray, Jamie</dc:creator>
 <dc:creator>Shou, Zheng</dc:creator>
 <dc:creator>Chang, Shih-Fu</dc:creator>
 <dc:creator>Paluri, Manohar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning image representations with ConvNets by pre-training on ImageNet has
proven useful across many visual understanding tasks including object
detection, semantic segmentation, and image captioning. Although any image
representation can be applied to video frames, a dedicated spatiotemporal
representation is still vital in order to incorporate motion patterns that
cannot be captured by appearance based models alone. This paper presents an
empirical ConvNet architecture search for spatiotemporal feature learning,
culminating in a deep 3-dimensional (3D) Residual ConvNet. Our proposed
architecture outperforms C3D by a good margin on Sports-1M, UCF101, HMDB51,
THUMOS14, and ASLAN while being 2 times faster at inference time, 2 times
smaller in model size, and having a more compact representation.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05044</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spying on the Smart Home: Privacy Attacks and Defenses on Encrypted IoT
  Traffic</dc:title>
 <dc:creator>Apthorpe, Noah</dc:creator>
 <dc:creator>Reisman, Dillon</dc:creator>
 <dc:creator>Sundaresan, Srikanth</dc:creator>
 <dc:creator>Narayanan, Arvind</dc:creator>
 <dc:creator>Feamster, Nick</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The growing market for smart home IoT devices promises new conveniences for
consumers while presenting new challenges for preserving privacy within the
home. Many smart home devices have always-on sensors that capture users'
offline activities in their living spaces and transmit information about these
activities on the Internet. In this paper, we demonstrate that an ISP or other
network observer can infer privacy sensitive in-home activities by analyzing
Internet traffic from smart homes containing commercially-available IoT devices
even when the devices use encryption. We evaluate several strategies for
mitigating the privacy risks associated with smart home device traffic,
including blocking, tunneling, and rate-shaping. Our experiments show that
traffic shaping can effectively and practically mitigate many privacy risks
associated with smart home IoT devices. We find that 40KB/s extra bandwidth
usage is enough to protect user activities from a passive network adversary.
This bandwidth cost is well within the Internet speed limits and data caps for
many smart homes.
</dc:description>
 <dc:description>Comment: 16 pages, 9 figures. This article draws heavily from arXiv:1705.06805
  and arXiv:1705.06809</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05045</identifier>
 <datestamp>2017-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-lingual Entity Alignment via Joint Attribute-Preserving Embedding</dc:title>
 <dc:creator>Sun, Zequn</dc:creator>
 <dc:creator>Hu, Wei</dc:creator>
 <dc:creator>Li, Chengkai</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Entity alignment is the task of finding entities in two knowledge bases (KBs)
that represent the same real-world object. When facing KBs in different natural
languages, conventional cross-lingual entity alignment methods rely on machine
translation to eliminate the language barriers. These approaches often suffer
from the uneven quality of translations between languages. While recent
embedding-based techniques encode entities and relationships in KBs and do not
need machine translation for cross-lingual entity alignment, a significant
number of attributes remain largely unexplored. In this paper, we propose a
joint attribute-preserving embedding model for cross-lingual entity alignment.
It jointly embeds the structures of two KBs into a unified vector space and
further refines it by leveraging attribute correlations in the KBs. Our
experimental results on real-world datasets show that this approach
significantly outperforms the state-of-the-art embedding approaches for
cross-lingual entity alignment and could be complemented with methods based on
machine translation.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-09-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05050</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AntibIoTic: Protecting IoT Devices Against DDoS Attacks</dc:title>
 <dc:creator>De Donno, Michele</dc:creator>
 <dc:creator>Dragoni, Nicola</dc:creator>
 <dc:creator>Giaretta, Alberto</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The 2016 is remembered as the year that showed to the world how dangerous
Distributed Denial of Service attacks can be. Gauge of the disruptiveness of
DDoS attacks is the number of bots involved: the bigger the botnet, the more
powerful the attack. This character, along with the increasing availability of
connected and insecure IoT devices, makes DDoS and IoT the perfect pair for the
malware industry. In this paper we present the main idea behind AntibIoTic, a
palliative solution to prevent DDoS attacks perpetrated through IoT devices.
</dc:description>
 <dc:date>2017-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05050</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-70578-1_7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05063</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What is Decidable about Perfect Timed Channels?</dc:title>
 <dc:creator>Abdulla, Parosh Aziz</dc:creator>
 <dc:creator>Atig, Mohamed Faouzi</dc:creator>
 <dc:creator>Krishna, S.</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  In this paper, we introduce the model of communicating timed automata (CTA)
that extends the classical models of finite-state processes communicating
through FIFO perfect channels and timed automata, in the sense that the
finite-state processes are replaced by timed automata, and messages inside the
perfect channels are equipped with clocks representing their ages. In addition
to the standard operations of timed automaton, each automaton can either (1)
append a message to the tail of a channel with an initial age or (2) receive
the message at the head of a channel if it is age satisfies a set of given
constraints. In this paper, we show that the reachability problem is
undecidable even in the case of two timed automata connected by one
unidirectional timed channel if one allows global clocks (that the two automata
can check and manipulate). We prove that this undecidability still holds even
for an CTA consisting of three timed automata and two unidirectional timed
channels (and without any global clock). However, the reachability problem
becomes decidable in the case of two automata linked with one unidirectional
timed channel and with no global clock. Finally, we consider the
bounded-context case, where in each context only one timed automaton is allowed
to receive messages from one channel while being able to send messages to all
the other timed channels. In this case we show that the reachability problem is
decidable.
</dc:description>
 <dc:date>2017-08-10</dc:date>
 <dc:date>2017-10-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05068</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of QoS of VoIP Traffic through WiFi-UMTS Networks</dc:title>
 <dc:creator>Miraz, Mahdi H.</dc:creator>
 <dc:creator>Molvi, Suhail A.</dc:creator>
 <dc:creator>Ali, Maaruf</dc:creator>
 <dc:creator>Ganie, Muzafar A.</dc:creator>
 <dc:creator>Hussein, AbdelRahman H.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Simulation of VoIP (Voice over Internet Protocol) traffic through UMTS
(Universal Mobile Telecommunication System) and WiFi (IEEE 802.11x) alone and
together are analysed for Quality of Service (QoS) performance. The average
jitter of VoIP transiting the WiFi-UMTS network has been found to be lower than
that of either solely through the WiFi and the UMTS networks. It is normally
expected to be higher than traversing through the WiFi network only. Both the
MOS (Mean Opinion Score) and the packet end-to-end delay were also found to be
much lower than expected through the heterogeneous WiFi-UMTS network.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05068</dc:identifier>
 <dc:identifier>World Congress on Engineering (WCE 2014) held at Imperial College,
  London, UK, 2-4 July 2014, ISBN-13: 978-988-19252-7-5, Print ISSN: 2078-0958,
  Online ISSN: 2078-0966, Vol. 1, pp. 684-689</dc:identifier>
 <dc:identifier>doi:10.13140/2.1.1307.1681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05069</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A causation coefficient and taxonomy of correlation/causation
  relationships</dc:title>
 <dc:creator>Brul&#xe9;, Joshua</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Other Statistics</dc:subject>
 <dc:description>  This paper introduces a causation coefficient which is defined in terms of
probabilistic causal models. This coefficient is suggested as the natural
causal analogue of the Pearson correlation coefficient and permits comparing
causation and correlation to each other in a simple, yet rigorous manner.
Together, these coefficients provide a natural way to classify the possible
correlation/causation relationships that can occur in practice and examples of
each relationship are provided. In addition, the typical relationship between
correlation and causation is analyzed to provide insight into why correlation
and causation are often conflated. Finally, example calculations of the
causation coefficient are shown on a real data set.
</dc:description>
 <dc:description>Comment: 31 pages, 6 figures</dc:description>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05070</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-driven Advice for Applying Machine Learning to Bioinformatics
  Problems</dc:title>
 <dc:creator>Olson, Randal S.</dc:creator>
 <dc:creator>La Cava, William</dc:creator>
 <dc:creator>Mustahsan, Zairah</dc:creator>
 <dc:creator>Varik, Akshay</dc:creator>
 <dc:creator>Moore, Jason H.</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  As the bioinformatics field grows, it must keep pace not only with new data
but with new algorithms. Here we contribute a thorough analysis of 13
state-of-the-art, commonly used machine learning algorithms on a set of 165
publicly available classification problems in order to provide data-driven
algorithm recommendations to current researchers. We present a number of
statistical and visual comparisons of algorithm performance and quantify the
effect of model selection and algorithm tuning for each algorithm and dataset.
The analysis culminates in the recommendation of five algorithms with
hyperparameters that maximize classifier performance across the tested
problems, as well as general guidelines for applying machine learning to
supervised classification problems.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures, 4 tables. To be published in the proceedings of
  PSB 2018. Randal S. Olson and William La Cava contributed equally as co-first
  authors</dc:description>
 <dc:date>2017-08-08</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05071</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning spectro-temporal features with 3D CNNs for speech emotion
  recognition</dc:title>
 <dc:creator>Kim, Jaebok</dc:creator>
 <dc:creator>Truong, Khiet P.</dc:creator>
 <dc:creator>Englebienne, Gwenn</dc:creator>
 <dc:creator>Evers, Vanessa</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose to use deep 3-dimensional convolutional networks
(3D CNNs) in order to address the challenge of modelling spectro-temporal
dynamics for speech emotion recognition (SER). Compared to a hybrid of
Convolutional Neural Network and Long-Short-Term-Memory (CNN-LSTM), our
proposed 3D CNNs simultaneously extract short-term and long-term spectral
features with a moderate number of parameters. We evaluated our proposed and
other state-of-the-art methods in a speaker-independent manner using aggregated
corpora that give a large and diverse set of speakers. We found that 1) shallow
temporal and moderately deep spectral kernels of a homogeneous architecture are
optimal for the task; and 2) our 3D CNNs are more effective for
spectro-temporal feature learning compared to other methods. Finally, we
visualised the feature space obtained with our proposed method using
t-distributed stochastic neighbour embedding (T-SNE) and could observe distinct
clusters of emotions.
</dc:description>
 <dc:description>Comment: ACII, 2017, San Antonio</dc:description>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05072</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Mining Attribute Selection Approach for Drought Modeling: A Case
  Study for Greater Horn of Africa</dc:title>
 <dc:creator>Demisse, Getachew B.</dc:creator>
 <dc:creator>Tadesse, Tsegaye</dc:creator>
 <dc:creator>Bayissa, Yared</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The objectives of this paper were to 1) develop an empirical method for
selecting relevant attributes for modelling drought, and 2) select the most
relevant attribute for drought modelling and predictions in the Greater Horn of
Africa (GHA). Twenty four attributes from different domain areas were used for
this experimental analysis. Two attribute selection algorithms were used for
the current study: Principal Component Analysis (PCA) and correlation-based
attribute selection (CAS). Using the PCA and CAS algorithms, the 24 attributes
were ranked by their merit value. Accordingly, 15 attributes were selected for
modelling drought in GHA. The average merit values for the selected attributes
ranged from 0.5 to 0.9. Future research may evaluate the developed methodology
using relevant classification techniques and quantify the actual information
gain from the developed approach.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05072</dc:identifier>
 <dc:identifier>doi:10.5121/ijdkp.2017.7401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05073</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finger Based Technique (FBT): An Innovative System for Improved
  Usability for the Blind Users' Dynamic Interaction with Mobile Touch Screen
  Devices</dc:title>
 <dc:creator>Fakrudeen, Mohammed</dc:creator>
 <dc:creator>Yousef, Sufian</dc:creator>
 <dc:creator>Miraz, Mahdi H</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  This paper presents Finger Based Technique (FBT) prototypes, a novel
interaction system for blind users, which is especially designed and developed
for non-visual touch screen devices and their applications. The FBT prototypes
were developed with virtual keys to be identified based on finger holding
positions. Two different models namely the single digit FBT and double digit
FBT were propounded. FBT technique were applied using two different phone
dialer applications: a single digit virtual key for the single digit FBT model
and a double digit virtual key with audio feedback enabling touch as input
gesture for the later one. An evaluation with 7 blind participants showed that
single digit FBT was significantly faster and more accurate than double digit
FBT. In addition to that, single digit FBT was found to be much faster than
iPhone VoiceOver entry speeds in performing similar tasks. Furthermore, our
research also suggests 11 accessible regions for quick access or navigation in
flat touch screen based smart phones for blind users. These accessible regions
will serve as a usability design framework and facilitate the developers to
place the widget for the blind user for dynamic interaction with the touch
screen devices. As far as is known to the authors, this is a novel suggestion.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05073</dc:identifier>
 <dc:identifier>World Congress on Engineering (WCE 2014) held at Imperial College,
  London, UK, 2-4 July 2014, ISBN-13: 978-988-19252-7-5, Print ISSN: 2078-0958,
  Online ISSN: 2078-0966, Vol. 1, pp. 128-133</dc:identifier>
 <dc:identifier>doi:10.13140/2.1.4190.7529</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05076</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SOCRATES: A System For Scalable Graph Analytics</dc:title>
 <dc:creator>Savkli, Cetin</dc:creator>
 <dc:creator>Carr, Ryan</dc:creator>
 <dc:creator>Chapman, Matthew</dc:creator>
 <dc:creator>Chee, Brant</dc:creator>
 <dc:creator>Minch, David</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A distributed semantic graph processing system that provides locality
control, indexing, graph query, and parallel processing capabilities is
presented.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05076</dc:identifier>
 <dc:identifier>doi:10.1109/HPEC.2014.7040993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05078</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rapid Mixing of $k$-Class Biased Permutations</dc:title>
 <dc:creator>Miracle, Sarah</dc:creator>
 <dc:creator>Streib, Amanda Pascoe</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In this paper, we study a biased version of the nearest-neighbor
transposition Markov chain on the set of permutations where neighboring
elements $i$ and $j$ are placed in order $(i,j)$ with probability $p_{i,j}$.
Our goal is to identify the class of parameter sets ${\bf P} = \{p_{i,j}\}$ for
which this Markov chain is rapidly mixing. Specifically, we consider the open
conjecture of Jim Fill that all monotone, positively biased distributions are
rapidly mixing.
  We resolve Fill's conjecture in the affirmative for distributions arising
from $k$-class particle processes, where the elements are divided into $k$
classes and the probability of exchanging neighboring elements depends on the
particular classes the elements are in. We further require that $k$ is a
constant, and all probabilities between elements in different classes are
bounded away from $1/2$. These particle processes arise in the context of
self-organizing lists and our result also applies beyond permutations to the
setting where all particles in a class are indistinguishable. Additionally we
show that a broader class of distributions based on trees is also rapidly
mixing, which generalizes a class analyzed by Bhakta et. al. (SODA '13). Our
work generalizes recent work by Haddadan and Winkler (STACS '17) studying
3-class particle processes.
  Our proof involves analyzing a generalized biased exclusion process, which is
a nearest-neighbor transposition chain applied to a 2-particle system. Biased
exclusion processes are of independent interest, with applications in
self-assembly. We generalize the results of Greenberg et al. (SODA '09) and
Benjamini et. al (Trans. AMS '05) on biased exclusion processes to allow the
probability of swapping neighboring elements to depend on the entire system, as
long as the minimum bias is bounded away from $1$.
</dc:description>
 <dc:description>Comment: 20 pages, 4 figures</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05081</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Importance of Image Enhancement Techniques in Color Image Segmentation:
  A Comprehensive and Comparative Study</dc:title>
 <dc:creator>Bora, Dibya Jyoti</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Color image segmentation is a very emerging research topic in the area of
color image analysis and pattern recognition. Many state-of-the-art algorithms
have been developed for this purpose. But, often the segmentation results of
these algorithms seem to be suffering from miss-classifications and
over-segmentation. The reasons behind these are the degradation of image
quality during the acquisition, transmission and color space conversion. So,
here arises the need of an efficient image enhancement technique which can
remove the redundant pixels or noises from the color image before proceeding
for final segmentation. In this paper, an effort has been made to study and
analyze different image enhancement techniques and thereby finding out the
better one for color image segmentation. Also, this comparative study is done
on two well-known color spaces HSV and LAB separately to find out which color
space supports segmentation task more efficiently with respect to those
enhancement techniques.
</dc:description>
 <dc:description>Comment: 27 pages, 17 figures, 2 Tables, 1 flowchart</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05081</dc:identifier>
 <dc:identifier>Indian J.Sci.Res. 15 (1): 115-131, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05083</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Amplify-and-Forward Two-Way Relaying System over Free-Space Optics
  Channels</dc:title>
 <dc:creator>Park, Jaedon</dc:creator>
 <dc:creator>Chae, Chan-Byoung</dc:creator>
 <dc:creator>Yoon, Giwan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we analyze the performance of a two- way subcarrier
intensity-modulated (SIM) amplify-and-forward (AF) relaying system over
free-space optics (FSO) communication channels. The analysis takes into
consideration attenuations due to atmospheric turbulence, geometric spread and
pointing errors at the same time. We derive, in generalized infinite power
series expressions, the tight upper and lower bounds of the overall outage
probability and average probability of errors of the system. The study finds
that this two-way subcarrier intensity- modulated AF relaying system using a
binary phase shift keying (BPSK) modulation could be used for practical
applications in case of a weak turbulence regime in which the required SNR is
about 30 dB to obtain the average bit error probability of 10-6. It is also
noted that the pointing errors clearly degrade the performance of the two-way
subcarrier intensity-modulated AF relaying system.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05085</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilingual Website Usability Analysis Based on an International User
  Survey</dc:title>
 <dc:creator>Miraz, Mahdi H.</dc:creator>
 <dc:creator>Ali, Maaruf</dc:creator>
 <dc:creator>Excell, Peter</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  A study was undertaken to determine the important usability factors (UF) used
in the English and the non-English version of a website. The important
usability factors were determined, based on a detailed questionnaire used in an
international survey. Analysis of the questionnaire found inequalities in the
user satisfaction and a general dissatisfaction with the non-English version of
the website. The study concluded that more care should be taken in creating the
text, taking into account the cultural and linguistic background of the users
and the use of graphics in multilingual websites.
</dc:description>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05085</dc:identifier>
 <dc:identifier>the proceedings of the fifth international conference on Internet
  Technologies and Applications (ITA 13) held at Glyndwr University in Wrexham,
  UK, 10-13 September 2013, ISBN-10: 0-946881-81-2, ISBN-13: 978-0-946881-81-9,
  pp. 236-244</dc:identifier>
 <dc:identifier>doi:10.13140/2.1.1208.8648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05091</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Millimeter Wave Channel Measurements in a Railway Depot</dc:title>
 <dc:creator>Bulut, Berna</dc:creator>
 <dc:creator>Barratt, Thomas</dc:creator>
 <dc:creator>Kong, Di</dc:creator>
 <dc:creator>Cao, Jue</dc:creator>
 <dc:creator>Freire, Alberto Loaiza</dc:creator>
 <dc:creator>Tila, Fai</dc:creator>
 <dc:creator>Armour, Simon</dc:creator>
 <dc:creator>Beach, Mark</dc:creator>
 <dc:creator>Nix, Andrew</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Millimeter wave (mmWave) communication is a key enabling technology with the
potential to deliver high capacity, high peak data rate communications for
future railway services. Knowledge of the radio characteristics is of paramount
importance for the successful deployment of such systems. In this paper mmWave
channel measurements are reported for a railway environment using a wideband
channel sounder operating at 60GHz. Highly directional antennas are deployed at
both ends of the link. Data is reported for path loss, root mean square (RMS)
delay spread and K-factor. Static and mobile measurements are considered.
Analysis shows that the signal strength is strongly dependent (up to 25dB) on
the azimuth orientation of the directional transmit and receive antennas. A
path loss exponent of n=2.04 was extracted from the Line-of-Sight measurements
with optimally aligned antennas. RMS delay spreads ranged from 1ns to 22ns
depending on antenna alignment. 50% of the measured K-factors were found to be
less than 6dB. We conclude this is the result of ground reflections in the
vertical Tx-Rx plane.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05095</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Navigator-free EPI Ghost Correction with Structured Low-Rank Matrix
  Models: New Theory and Methods</dc:title>
 <dc:creator>Lobos, Rodrigo A.</dc:creator>
 <dc:creator>Kim, Tae Hyung</dc:creator>
 <dc:creator>Hoge, W. Scott</dc:creator>
 <dc:creator>Haldar, Justin P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:description>  Structured low-rank matrix models have previously been introduced to enable
calibrationless MR image reconstruction from sub-Nyquist data, and such ideas
have recently been extended to enable navigator-free echo-planar imaging (EPI)
ghost correction. This paper presents novel theoretical analysis which shows
that, because of uniform subsampling, the structured low-rank matrix
optimization problems for EPI data will always have either undesirable or
non-unique solutions in the absence of additional constraints. This theory
leads us to recommend and investigate problem formulations for navigator-free
EPI that incorporate side information from either image-domain or k-space
domain parallel imaging methods. The importance of using nonconvex low-rank
matrix regularization is also identified. We demonstrate using phantom and
\emph{in vivo} data that the proposed methods are able to eliminate ghost
artifacts for several navigator-free EPI acquisition schemes, obtaining better
performance in comparison to state-of-the-art methods across a range of
different scenarios. Results are shown for both single-channel acquisition and
highly accelerated multi-channel acquisition.
</dc:description>
 <dc:description>Comment: 13 pages, 9 figures, Submitted to IEEE Transactions on Medical
  Imaging</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05096</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Will SDN be part of 5G?</dc:title>
 <dc:creator>Zaidi, Zainab</dc:creator>
 <dc:creator>Friderikos, Vasilis</dc:creator>
 <dc:creator>Yousaf, Zarrar</dc:creator>
 <dc:creator>Fletcher, Simon</dc:creator>
 <dc:creator>Dohler, Mischa</dc:creator>
 <dc:creator>Aghvami, Hamid</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  For many, this is no longer a valid question and the case is considered
settled with SDN/NFV (Software Defined Networking/Network Function
Virtualization) providing the inevitable innovation enablers solving many
outstanding management issues regarding 5G. However, given the monumental task
of softwarization of radio access network (RAN) while 5G is just around the
corner and some companies have started unveiling their 5G equipment already,
the concern is very realistic that we may only see some point solutions
involving SDN technology instead of a fully SDN-enabled RAN. This survey paper
identifies all important obstacles in the way and looks at the state of the art
of the relevant solutions. This survey is different from the previous surveys
on SDN-based RAN as it focuses on the salient problems and discusses solutions
proposed within and outside SDN literature. Our main focus is on fronthaul,
backward compatibility, supposedly disruptive nature of SDN deployment,
business cases and monetization of SDN related upgrades, latency of general
purpose processors (GPP), and additional security vulnerabilities,
softwarization brings along to the RAN. We have also provided a summary of the
architectural developments in SDN-based RAN landscape as not all work can be
covered under the focused issues. This paper provides a comprehensive survey on
the state of the art of SDN-based RAN and clearly points out the gaps in the
technology.
</dc:description>
 <dc:description>Comment: 33 pages, 10 figures</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05102</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation Schemes for Minimizing the Maximum Lateness on a Single
  Machine with Release Times under Non-Availability or Deadline Constraints</dc:title>
 <dc:creator>Kacem, Imed</dc:creator>
 <dc:creator>Kellerer, Hans</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we consider four single-machine scheduling problems with
release times, with the aim of minimizing the maximum lateness. In the first
problem we have a common deadline for all the jobs. The second problem looks
for the Pareto frontier with respect to the two objective functions maximum
lateness and makespan. The third problem is associated with a non-availability
constraint. In the fourth one, the non-availibility interval is related to the
operator who is organizing the execution of jobs on the machine (no job can
start, and neither can complete during the operator non-availability period).
For each of the four problems, we establish the existence of a polynomial time
approximation scheme (PTAS).
</dc:description>
 <dc:description>Comment: The extended version has been submitted to an international journal.
  It has been received by Springer on 12 April 2017</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05106</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Mean and Median Criterion for Automatic Kernel Bandwidth Selection
  for Support Vector Data Description</dc:title>
 <dc:creator>Chaudhuri, Arin</dc:creator>
 <dc:creator>Kakde, Deovrat</dc:creator>
 <dc:creator>Sadek, Carol</dc:creator>
 <dc:creator>Gonzalez, Laura</dc:creator>
 <dc:creator>Kong, Seunghyun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Support vector data description (SVDD) is a popular technique for detecting
anomalies. The SVDD classifier partitions the whole space into an inlier
region, which consists of the region near the training data, and an outlier
region, which consists of points away from the training data. The computation
of the SVDD classifier requires a kernel function, and the Gaussian kernel is a
common choice for the kernel function. The Gaussian kernel has a bandwidth
parameter, whose value is important for good results. A small bandwidth leads
to overfitting, and the resulting SVDD classifier overestimates the number of
anomalies. A large bandwidth leads to underfitting, and the classifier fails to
detect many anomalies. In this paper we present a new automatic, unsupervised
method for selecting the Gaussian kernel bandwidth. The selected value can be
computed quickly, and it is competitive with existing bandwidth selection
methods.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05115</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Residual Learning and PDEs on Manifold</dc:title>
 <dc:creator>Li, Zhen</dc:creator>
 <dc:creator>Shi, Zuoqiang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we formulate the deep residual network (ResNet) as a control
problem of transport equation. In ResNet, the transport equation is solved
along the characteristics. Based on this observation, deep neural network is
closely related to the control problem of PDEs on manifold. We propose several
models based on transport equation and Hamilton-Jacobi equation. The
discretization of these PDEs on point cloud is also discussed.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05117</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aadhaar Card: Challenges and Impact on Digital Transformation</dc:title>
 <dc:creator>Raju, Raja Siddharth</dc:creator>
 <dc:creator>Singh, Sukhdev</dc:creator>
 <dc:creator>Khatter, Kiran</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Objectives: This paper presents a brief review on Aadhaar card, and discusses
the scope and advantages of linking Aadhaar card to various systems. Further we
present various cases in which Aadhaar card may pose security threats. The
observations of Supreme Court of India are also presented in this paper
followed by a discussion on the loopholes in the existing system. Methods: We
conducted literature survey based on the various research articles, leading
newspapers, case studies and the observations of Supreme Court of India, and
categorized the various cases into three categories. Findings: Aadhaar project
is one of the significant projects in India to bring the universal trend of
digital innovation. The launch of this project was focused on the
inter-operability of various e-governance functionalities to ensure the optimal
utilization of Information, Communication and Technology Infrastructure.
Towards this Government of India has recently made Aadhaar card mandatory for
many government applications, and also has promoted Aadhaar enabled
transactions.
  Improvements: There are many issues related to security and privacy of the
Aadhaar data need to be addressed. This paper highlights such cases.
</dc:description>
 <dc:description>Comment: 20 Pages</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05118</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure Learning of $H$-colorings</dc:title>
 <dc:creator>Blanca, Antonio</dc:creator>
 <dc:creator>Chen, Zongchen</dc:creator>
 <dc:creator>&#x160;tefankovi&#x10d;, Daniel</dc:creator>
 <dc:creator>Vigoda, Eric</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We study the structure learning problem for graph homomorphisms, commonly
referred to as $H$-colorings, including the weighted case which corresponds to
spin systems with hard constraints. The learning problem is as follows: for a
fixed (and known) constraint graph $H$ with $q$ colors and an unknown graph
$G=(V,E)$ with $n$ vertices, given uniformly random $H$-colorings of $G$, how
many samples are required to learn the edges of the unknown graph $G$? We give
a characterization of $H$ for which the problem is identifiable for every $G$,
i.e., we can learn $G$ with an infinite number of samples.
  We focus particular attention on the case of proper vertex $q$-colorings of
graphs of maximum degree $d$ where intriguing connections to statistical
physics phase transitions appear. We prove that when $q&gt;d$ the problem is
identifiable and we can learn $G$ in $\mathrm{poly}(d,q)\times O(n^2\log{n})$
time. In contrast for soft-constraint systems, such as the Ising model, the
best possible running time is exponential in $d$. When $q\leq d$ we prove that
the problem is not identifiable, and we cannot hope to learn $G$. When
$q&lt;d-\sqrt{d} + \Theta(1)$ we prove that even learning an equivalent graph (any
graph with the same set of $H$-colorings) is computationally hard---sample
complexity is exponential in $n$ in the worst-case. For the $q$-colorings
problem, the threshold for efficient learning seems to be connected to the
uniqueness/non-uniqueness phase transition at $q=d$. We explore this connection
for general $H$-colorings and prove that under a well-known condition in
statistical physics, known as Dobrushin uniqueness condition, we can learn $G$
in $\mathrm{poly}(d,q)\times O(n^2\log{n})$ time.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05119</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bufferless transmission in complex networks</dc:title>
 <dc:creator>Pu, Cunlai</dc:creator>
 <dc:creator>Cui, Wei</dc:creator>
 <dc:creator>Wu, Jiexin</dc:creator>
 <dc:creator>Yang, Jian</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Complex bufferless networks such as on-chip networks and optical burst
switching networks haven't been paid enough attention in network science. In
complex bufferless networks, the store and forward mechanism is not applicable,
since the network nodes are not allowed to buffer data packets. In this paper,
we study the data transmission process in complex bufferless networks from the
perspective of network science. Specifically, we use the Price model to
generate the underlying network topological structures. We propose a delivery
queue based deflection mechanism, which accompanies the efficient routing
protocol, to transmit data packets in bufferless networks. We investigate the
average deflection times, packets loss rate, average arrival time, and how the
network topological structure and some other factors affect these transmission
performances. Our work provides some clues for the architecture and routing
design of bufferless networks.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05122</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Visual Conversational Agents via Cooperative Human-AI Games</dc:title>
 <dc:creator>Chattopadhyay, Prithvijit</dc:creator>
 <dc:creator>Yadav, Deshraj</dc:creator>
 <dc:creator>Prabhu, Viraj</dc:creator>
 <dc:creator>Chandrasekaran, Arjun</dc:creator>
 <dc:creator>Das, Abhishek</dc:creator>
 <dc:creator>Lee, Stefan</dc:creator>
 <dc:creator>Batra, Dhruv</dc:creator>
 <dc:creator>Parikh, Devi</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As AI continues to advance, human-AI teams are inevitable. However, progress
in AI is routinely measured in isolation, without a human in the loop. It is
crucial to benchmark progress in AI, not just in isolation, but also in terms
of how it translates to helping humans perform certain tasks, i.e., the
performance of human-AI teams.
  In this work, we design a cooperative game - GuessWhich - to measure human-AI
team performance in the specific context of the AI being a visual
conversational agent. GuessWhich involves live interaction between the human
and the AI. The AI, which we call ALICE, is provided an image which is unseen
by the human. Following a brief description of the image, the human questions
ALICE about this secret image to identify it from a fixed pool of images.
  We measure performance of the human-ALICE team by the number of guesses it
takes the human to correctly identify the secret image after a fixed number of
dialog rounds with ALICE. We compare performance of the human-ALICE teams for
two versions of ALICE. Our human studies suggest a counterintuitive trend -
that while AI literature shows that one version outperforms the other when
paired with an AI questioner bot, we find that this improvement in AI-AI
performance does not translate to improved human-AI performance. This suggests
a mismatch between benchmarking of AI in isolation and in the context of
human-AI teams.
</dc:description>
 <dc:description>Comment: HCOMP 2017</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05123</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep &amp; Cross Network for Ad Click Predictions</dc:title>
 <dc:creator>Wang, Ruoxi</dc:creator>
 <dc:creator>Fu, Bin</dc:creator>
 <dc:creator>Fu, Gang</dc:creator>
 <dc:creator>Wang, Mingliang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Feature engineering has been the key to the success of many prediction
models. However, the process is non-trivial and often requires manual feature
engineering or exhaustive searching. DNNs are able to automatically learn
feature interactions; however, they generate all the interactions implicitly,
and are not necessarily efficient in learning all types of cross features. In
this paper, we propose the Deep &amp; Cross Network (DCN) which keeps the benefits
of a DNN model, and beyond that, it introduces a novel cross network that is
more efficient in learning certain bounded-degree feature interactions. In
particular, DCN explicitly applies feature crossing at each layer, requires no
manual feature engineering, and adds negligible extra complexity to the DNN
model. Our experimental results have demonstrated its superiority over the
state-of-art algorithms on the CTR prediction dataset and dense classification
dataset, in terms of both model accuracy and memory usage.
</dc:description>
 <dc:description>Comment: In Proceedings of AdKDD and TargetAd, Halifax, NS, Canada, August,
  14, 2017, 7 pages</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05124</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Securing Wireless Communications of the Internet of Things from the
  Physical Layer, An Overview</dc:title>
 <dc:creator>Zhang, Junqing</dc:creator>
 <dc:creator>Duong, Trung Q.</dc:creator>
 <dc:creator>Woods, Roger</dc:creator>
 <dc:creator>Marshall, Alan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The security of the Internet of Things (IoT) is receiving considerable
interest as the low power constraints and complexity features of many IoT
devices are limiting the use of conventional cryptographic techniques. This
article provides an overview of recent research efforts on alternative
approaches for securing IoT wireless communications at the physical layer,
specifically the key topics of key generation and physical layer encryption.
These schemes can be implemented and are lightweight, and thus offer practical
solutions for providing effective IoT wireless security. Future research to
make IoT-based physical layer security more robust and pervasive is also
covered.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05124</dc:identifier>
 <dc:identifier>doi:10.3390/e19080420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05125</identifier>
 <datestamp>2017-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hyperspectral Unmixing: Ground Truth Labeling, Datasets, Benchmark
  Performances and Survey</dc:title>
 <dc:creator>Zhu, Feiyun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Hyperspectral unmixing (HU) is a very useful and increasingly popular
preprocessing step for a wide range of hyperspectral applications. However, the
HU research has been constrained a lot by three factors: (a) the number of
hyperspectral images (especially the ones with ground truths) are very limited;
(b) the ground truths of most hyperspectral images are not shared on the web,
which may cause lots of unnecessary troubles for researchers to evaluate their
algorithms; (c) the codes of most state-of-the-art methods are not shared,
which may also delay the testing of new methods.
  Accordingly, this paper deals with the above issues from the following three
perspectives: (1) as a profound contribution, we provide a general labeling
method for the HU. With it, we labeled up to 15 hyperspectral images, providing
18 versions of ground truths. To the best of our knowledge, this is the first
paper to summarize and share up to 15 hyperspectral images and their 18
versions of ground truths for the HU. Observing that the hyperspectral
classification (HyC) has much more standard datasets (whose ground truths are
generally publicly shared) than the HU, we propose an interesting method to
transform the HyC datasets for the HU research. (2) To further facilitate the
evaluation of HU methods under different conditions, we reviewed and
implemented the algorithm to generate a complex synthetic hyperspectral image.
By tuning the hyper-parameters in the code, we may verify the HU methods from
four perspectives. The code would also be shared on the web. (3) To provide a
standard comparison, we reviewed up to 10 state-of-the-art HU algorithms, then
selected the 5 most benchmark HU algorithms, and compared them on the 15 real
hyperspectral datasets. The experiment results are surely reproducible; the
implemented codes would be shared on the web.
</dc:description>
 <dc:date>2017-08-16</dc:date>
 <dc:date>2017-10-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05127</identifier>
 <datestamp>2017-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Binary Reconstruction for Cross-modal Hashing</dc:title>
 <dc:creator>Li, Xuelong</dc:creator>
 <dc:creator>Hu, Di</dc:creator>
 <dc:creator>Nie, Feiping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  With the increasing demand of massive multimodal data storage and
organization, cross-modal retrieval based on hashing technique has drawn much
attention nowadays. It takes the binary codes of one modality as the query to
retrieve the relevant hashing codes of another modality. However, the existing
binary constraint makes it difficult to find the optimal cross-modal hashing
function. Most approaches choose to relax the constraint and perform
thresholding strategy on the real-value representation instead of directly
solving the original objective. In this paper, we first provide a concrete
analysis about the effectiveness of multimodal networks in preserving the
inter- and intra-modal consistency. Based on the analysis, we provide a
so-called Deep Binary Reconstruction (DBRC) network that can directly learn the
binary hashing codes in an unsupervised fashion. The superiority comes from a
proposed simple but efficient activation function, named as Adaptive Tanh
(ATanh). The ATanh function can adaptively learn the binary codes and be
trained via back-propagation. Extensive experiments on three benchmark datasets
demonstrate that DBRC outperforms several state-of-the-art methods in both
image2text and text2image retrieval task.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, accepted by ACM Multimedia 2017</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05127</dc:identifier>
 <dc:identifier>doi:10.1145/3123266.3123355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05132</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An instrumental intelligibility metric based on information theory</dc:title>
 <dc:creator>Van Kuyk, Steven</dc:creator>
 <dc:creator>Kleijn, W. Bastiaan</dc:creator>
 <dc:creator>Hendriks, Richard C.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  We propose a monaural intrusive instrumental intelligibility metric called
speech intelligibility in bits (SIIB). SIIB is an estimate of the amount of
information shared between a talker and a listener in bits per second. Unlike
existing information theoretic intelligibility metrics, SIIB accounts for
talker variability and statistical dependencies between time-frequency units.
Our evaluation shows that relative to state-of-the-art intelligibility metrics,
SIIB is highly correlated with the intelligibility of speech that has been
degraded by noise and processed by speech enhancement algorithms.
</dc:description>
 <dc:description>Comment: Published in IEEE Signal Processing Letters</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05132</dc:identifier>
 <dc:identifier>IEEE Signal Processing Letters, vol. 25, no. 1, pp. 115-119, Jan.
  2018</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2017.2774250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05133</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Scene Text Detection with Connected Component Proposals</dc:title>
 <dc:creator>Jiang, Fan</dc:creator>
 <dc:creator>Hao, Zhihui</dc:creator>
 <dc:creator>Liu, Xinran</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A growing demand for natural-scene text detection has been witnessed by the
computer vision community since text information plays a significant role in
scene understanding and image indexing. Deep neural networks are being used due
to their strong capabilities of pixel-wise classification or word localization,
similar to being used in common vision problems. In this paper, we present a
novel two-task network with integrating bottom and top cues. The first task
aims to predict a pixel-by-pixel labeling and based on which, word proposals
are generated with a canonical connected component analysis. The second task
aims to output a bundle of character candidates used later to verify the word
proposals. The two sub-networks share base convolutional features and moreover,
we present a new loss to strengthen the interaction between them. We evaluate
the proposed network on public benchmark datasets and show it can detect
arbitrary-orientation scene text with a finer output boundary. In ICDAR 2013
text localization task, we achieve the state-of-the-art performance with an
F-score of 0.919 and a much better recall of 0.915.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05136</identifier>
 <datestamp>2017-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>More Iterations per Second, Same Quality -- Why Asynchronous Algorithms
  may Drastically Outperform Traditional Ones</dc:title>
 <dc:creator>Hannah, Robert</dc:creator>
 <dc:creator>Yin, Wotao</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  In this paper, we consider the convergence of a very general
asynchronous-parallel algorithm called ARock, that takes many well-known
asynchronous algorithms as special cases (gradient descent, proximal gradient,
Douglas Rachford, ADMM, etc.). In asynchronous-parallel algorithms, the
computing nodes simply use the most recent information that they have access
to, instead of waiting for a full update from all nodes in the system. This
means that nodes do not have to waste time waiting for information, which can
be a major bottleneck, especially in distributed systems. When the system has
$p$ nodes, asynchronous algorithms may complete $\Theta(\ln(p))$ more
iterations than synchronous algorithms in a given time period (&quot;more iterations
per second&quot;).
  Although asynchronous algorithms may compute more iterations per second,
there is error associated with using outdated information. How many more
iterations in total are needed to compensate for this error is still an open
question. The main results of this paper aim to answer this question. We prove,
loosely, that as the size of the problem becomes large, the number of
additional iterations that asynchronous algorithms need becomes negligible
compared to the total number (&quot;same quality&quot; of the iterations). Taking these
facts together, our results provide solid evidence of the potential of
asynchronous algorithms to vastly speed up certain distributed computations.
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05137</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pixel-Level Matching for Video Object Segmentation using Convolutional
  Neural Networks</dc:title>
 <dc:creator>Yoon, Jae Shin</dc:creator>
 <dc:creator>Rameau, Francois</dc:creator>
 <dc:creator>Kim, Junsik</dc:creator>
 <dc:creator>Lee, Seokju</dc:creator>
 <dc:creator>Shin, Seunghak</dc:creator>
 <dc:creator>Kweon, In So</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel video object segmentation algorithm based on pixel-level
matching using Convolutional Neural Networks (CNN). Our network aims to
distinguish the target area from the background on the basis of the pixel-level
similarity between two object units. The proposed network represents a target
object using features from different depth layers in order to take advantage of
both the spatial details and the category-level semantic information.
Furthermore, we propose a feature compression technique that drastically
reduces the memory requirements while maintaining the capability of feature
representation. Two-stage training (pre-training and fine-tuning) allows our
network to handle any target object regardless of its category (even if the
object's type does not belong to the pre-training data) or of variations in its
appearance through a video sequence. Experiments on large datasets demonstrate
the effectiveness of our model - against related methods - in terms of
accuracy, speed, and stability. Finally, we introduce the transferability of
our network to different domains, such as the infrared data domain.
</dc:description>
 <dc:description>Comment: To appear on ICCV 2017</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05144</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable trust-region method for deep reinforcement learning using
  Kronecker-factored approximation</dc:title>
 <dc:creator>Wu, Yuhuai</dc:creator>
 <dc:creator>Mansimov, Elman</dc:creator>
 <dc:creator>Liao, Shun</dc:creator>
 <dc:creator>Grosse, Roger</dc:creator>
 <dc:creator>Ba, Jimmy</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work, we propose to apply trust region optimization to deep
reinforcement learning using a recently proposed Kronecker-factored
approximation to the curvature. We extend the framework of natural policy
gradient and propose to optimize both the actor and the critic using
Kronecker-factored approximate curvature (K-FAC) with trust region; hence we
call our method Actor Critic using Kronecker-Factored Trust Region (ACKTR). To
the best of our knowledge, this is the first scalable trust region natural
gradient method for actor-critic methods. It is also a method that learns
non-trivial tasks in continuous control as well as discrete control policies
directly from raw pixel inputs. We tested our approach across discrete domains
in Atari games as well as continuous domains in the MuJoCo environment. With
the proposed methods, we are able to achieve higher rewards and a 2- to 3-fold
improvement in sample efficiency on average, compared to previous
state-of-the-art on-policy actor-critic methods. Code is available at
https://github.com/openai/baselines
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures; update github repo link</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05148</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Natural Language Processing: State of The Art, Current Trends and
  Challenges</dc:title>
 <dc:creator>Khurana, Diksha</dc:creator>
 <dc:creator>Koli, Aditya</dc:creator>
 <dc:creator>Khatter, Kiran</dc:creator>
 <dc:creator>Singh, Sukhdev</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Natural language processing (NLP) has recently gained much attention for
representing and analysing human language computationally. It has spread its
applications in various fields such as machine translation, email spam
detection, information extraction, summarization, medical, and question
answering etc. The paper distinguishes four phases by discussing different
levels of NLP and components of Natural Language Generation (NLG) followed by
presenting the history and evolution of NLP, state of the art presenting the
various applications of NLP and current trends and challenges.
</dc:description>
 <dc:description>Comment: 25 pages</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05152</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Triangle-Free Penny Graphs: Degeneracy, Choosability, and Edge Count</dc:title>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We show that triangle-free penny graphs have degeneracy at most two, list
coloring number (choosability) at most three, diameter $D=\Omega(\sqrt n)$, and
at most $\min\bigl(2n-\Omega(\sqrt n),2n-D-2\bigr)$ edges.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures. To appear at the 25th International Symposium on
  Graph Drawing and Network Visualization (GD 2017)</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05155</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Effect of Planarization on Width</dc:title>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We study the effects of planarization (the construction of a planar diagram
$D$ from a non-planar graph $G$ by replacing each crossing by a new vertex) on
graph width parameters. We show that for treewidth, pathwidth, branchwidth,
clique-width, and tree-depth there exists a family of $n$-vertex graphs with
bounded parameter value, all of whose planarizations have parameter value
$\Omega(n)$. However, for bandwidth, cutwidth, and carving width, every graph
with bounded parameter value has a planarization of linear size whose parameter
value remains bounded. The same is true for the treewidth, pathwidth, and
branchwidth of graphs of bounded degree.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures. To appear at the 25th International Symposium on
  Graph Drawing and Network Visualization (GD 2017)</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05156</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matrix output extension of the tensor network Kalman filter with an
  application in MIMO Volterra system identification</dc:title>
 <dc:creator>Batselier, Kim</dc:creator>
 <dc:creator>Wong, Ngai</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This article extends the tensor network Kalman filter to matrix outputs with
an application in recursive identification of discrete-time nonlinear
multiple-input-multiple-output (MIMO) Volterra systems. This extension
completely supersedes previous work, where only $l$ scalar outputs were
considered. The Kalman tensor equations are modified to accommodate for matrix
outputs and their implementation using tensor networks is discussed. The MIMO
Volterra system identification application requires the conversion of the
output model matrix with a row-wise Kronecker product structure into its
corresponding tensor network, for which we propose an efficient algorithm.
Numerical experiments demonstrate both the efficacy of the proposed matrix
conversion algorithm and the improved convergence of the Volterra kernel
estimates when using matrix outputs.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05156</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05159</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Subcube Heavy Hitters in Data Streams</dc:title>
 <dc:creator>Kveton, Branislav</dc:creator>
 <dc:creator>Muthukrishnan, S.</dc:creator>
 <dc:creator>Vu, Hoa T.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Data streams typically have items of large number of dimensions. We study the
fundamental heavy-hitters problem in this setting. Formally, the data stream
consists of $d$-dimensional items $x_1,\ldots,x_m \in [n]^d$. A $k$-dimensional
subcube $T$ is a subset of distinct coordinates $\{ T_1,\cdots,T_k \} \subseteq
[d]$. A subcube heavy hitter query ${\rm Query}(T,v)$, $v \in [n]^k$, outputs
YES if $f_T(v) \geq \gamma$ and NO if $f_T(v) &lt; \gamma/4$, where $f_T$ is the
ratio of number of stream items whose coordinates $T$ have joint values $v$.
The all subcube heavy hitters query ${\rm AllQuery}(T)$ outputs all joint
values $v$ that return YES to ${\rm Query}(T,v)$. The one dimensional version
of this problem where $d=1$ was heavily studied in data stream theory,
databases, networking and signal processing. The subcube heavy hitters problem
is applicable in all these cases.
  We present a simple reservoir sampling based one-pass streaming algorithm to
solve the subcube heavy hitters problem in $\tilde{O}(kd/\gamma)$ space. This
is optimal up to poly-logarithmic factors given the established lower bound. In
the worst case, this is $\Theta(d^2/\gamma)$ which is prohibitive for large
$d$, and our goal is to circumvent this quadratic bottleneck.
  Our main contribution is a model-based approach to the subcube heavy hitters
problem. In particular, we assume that the dimensions are related to each other
via the Naive Bayes model, with or without a latent dimension. Under this
assumption, we present a new two-pass, $\tilde{O}(d/\gamma)$-space algorithm
for our problem, and a fast algorithm for answering ${\rm AllQuery}(T)$ in
$O(k/\gamma^2)$ time. Our work develops the direction of model-based data
stream analysis, with much that remains to be explored.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05163</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RAPToR: A Resampling Algorithm for Pseudo-Polar based Tomographic
  Reconstruction</dc:title>
 <dc:creator>Tsiper, Shahar</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  We propose a stable and fast reconstruction technique for parallel-beam (PB)
tomographic X-ray imaging, relying on the discrete pseudo-polar (PP) Radon
transform. Our main contribution is a resampling method, based on modern
sampling theory, that transforms the acquired PB measurements to a PP grid. The
resampling process is both fast and accurate, and in addition, simultaneously
denoises the measurements, by exploiting geometrical properties of the
tomographic scan. The transformed measurements are then reconstructed using an
iterative solver with total variation (TV) regularization. We show that
reconstructing from measurements on the PP grid, leads to improved recovery,
due to the inherent stability and accuracy of the PP Radon transform, compared
with the PB Radon transform. We also demonstrate recovery from a reduced number
of PB acquisition angles, and high noise levels. Our approach is shown to
achieve superior results over other state-of-the-art solutions, that operate
directly on the given PB measurements.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05165</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting revisits in trajectory recommendation</dc:title>
 <dc:creator>Menon, Aditya Krishna</dc:creator>
 <dc:creator>Chen, Dawei</dc:creator>
 <dc:creator>Xie, Lexing</dc:creator>
 <dc:creator>Ong, Cheng Soon</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>68T05</dc:subject>
 <dc:description>  Trajectory recommendation is the problem of recommending a sequence of places
in a city for a tourist to visit. It is strongly desirable for the recommended
sequence to avoid loops, as tourists typically would not wish to revisit the
same location. Given some learned model that scores sequences, how can we then
find the highest-scoring sequence that is loop-free? This paper studies this
problem, with three contributions. First, we detail three distinct approaches
to the problem -- graph-based heuristics, integer linear programming, and list
extensions of the Viterbi algorithm -- and qualitatively summarise their
strengths and weaknesses. Second, we explicate how two ostensibly different
approaches to the list Viterbi algorithm are in fact fundamentally identical.
Third, we conduct experiments on real-world trajectory recommendation datasets
to identify the tradeoffs imposed by each of the three approaches. Overall, our
results indicate that a greedy graph-based heuristic offer excellent
performance and runtime, leading us to recommend its use for removing loops at
prediction time.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05170</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High Efficient Reconstruction of Single-shot T2 Mapping from
  OverLapping-Echo Detachment Planar Imaging Based on Deep Residual Network</dc:title>
 <dc:creator>Cai, Congbo</dc:creator>
 <dc:creator>Zeng, Yiqing</dc:creator>
 <dc:creator>Wang, Chao</dc:creator>
 <dc:creator>Cai, Shuhui</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Chen, Zhong</dc:creator>
 <dc:creator>Ding, Xinghao</dc:creator>
 <dc:creator>Zhong, Jianhui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Purpose: An end-to-end deep convolutional neural network (CNN) based on deep
residual network (ResNet) was proposed to efficiently reconstruct reliable T2
mapping from single-shot OverLapping-Echo Detachment (OLED) planar imaging.
Methods: The training dataset was obtained from simulations carried out on
SPROM software developed by our group. The relationship between the original
OLED image containing two echo signals and the corresponded T2 mapping was
learned by ResNet training. After the ResNet was trained, it was applied to
reconstruct the T2 mapping from simulation and in vivo human brain data.
Results: Though the ResNet was trained entirely on simulated data, the trained
network was generalized well to real human brain data. The results from
simulation and in vivo human brain experiments show that the proposed method
significantly outperformed the echo-detachment-based method. Reliable T2
mapping was achieved within tens of milliseconds after the network had been
trained while the echo-detachment-based OLED reconstruction method took
minutes. Conclusion: The proposed method will greatly facilitate real-time
dynamic and quantitative MR imaging via OLED sequence, and ResNet has the
potential to reconstruct images from complex MRI sequence efficiently.
</dc:description>
 <dc:description>Comment: 18 pages, 7 figures</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05170</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05172</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Open storm: a complete framework for sensing and control of urban
  watersheds</dc:title>
 <dc:creator>Bartos, Matthew</dc:creator>
 <dc:creator>Wong, Brandon</dc:creator>
 <dc:creator>Kerkez, Branko</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Leveraging recent advances in technologies surrounding the Internet of
Things, &quot;smart&quot; water systems are poised to transform water resources
management by enabling ubiquitous real-time sensing and control. Recent
applications have demonstrated the potential to improve flood forecasting,
enhance rainwater harvesting, and prevent combined sewer overflows. However,
adoption of smart water systems has been hindered by a limited number of proven
case studies, along with a lack of guidance on how smart water systems should
be built. To this end, we review existing solutions, and introduce open
storm---an open-source, end-to-end platform for real-time monitoring and
control of watersheds. Open storm includes (i) a robust hardware stack for
distributed sensing and control in harsh environments (ii) a cloud services
platform that enables system-level supervision and coordination of water
assets, and (iii) a comprehensive, web-based &quot;how-to&quot; guide, available on
open-storm.org, that empowers newcomers to develop and deploy their own smart
water networks. We illustrate the capabilities of the open storm platform
through two ongoing deployments: (i) a high-resolution flash-flood monitoring
network that detects and communicates flood hazards at the level of individual
roadways and (ii) a real-time stormwater control network that actively
modulates discharges from stormwater facilities to improve water quality and
reduce stream erosion. Through these case studies, we demonstrate the
real-world potential for smart water systems to enable sustainable management
of water resources.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05174</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Self-aware Smart Buildings by Augmented Reality</dc:title>
 <dc:creator>Aftab, Muhammad</dc:creator>
 <dc:creator>Chau, Chi-Kin</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Conventional HVAC control systems are usually incognizant of the physical
structures and materials of buildings. These systems merely follow pre-set HVAC
control logic based on abstract building thermal response models, which are
rough approximations to true physical models, ignoring dynamic spatial
variations in built environments. To enable more accurate and responsive HVAC
control, this paper introduces the notion of self-aware smart buildings, such
that buildings are able to explicitly construct physical models of themselves
(e.g., incorporating building structures and materials, and thermal flow
dynamics). The question is how to enable self-aware buildings that
automatically acquire dynamic knowledge of themselves. This paper presents a
novel approach using augmented reality. The extensive user-environment
interactions in augmented reality not only can provide intuitive user
interfaces for building systems, but also can capture the physical structures
and possibly materials of buildings accurately to enable real-time building
simulation and control. This paper presents a building system prototype
incorporating augmented reality, and discusses its applications.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05185</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Block Halving Party Times</dc:title>
 <dc:creator>Rosenfeld, Meni</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Bitcoin is the world's first decentralized digital currency. The rate at
which bitcoins enter circulation is cut in half every 4 years, approximately.
These events are considered landmarks in Bitcoin's history, and as such are
widely celebrated. However, this requires placing confidence intervals on the
precise timing of the halving well in advance, and the particular mechanism by
which the halving time is determined makes this challenging. In this paper, we
intend to help party planners by describing the problem, and highlighting
several techniques to estimate the mean and variance of the halving.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05192</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiform Adaptive Robot Skill Learning from Humans</dc:title>
 <dc:creator>Zhao, Leidi</dc:creator>
 <dc:creator>Lawhorn, Raheem</dc:creator>
 <dc:creator>Patil, Siddharth</dc:creator>
 <dc:creator>Susanibar, Steve</dc:creator>
 <dc:creator>Lu, Lu</dc:creator>
 <dc:creator>Wang, Cong</dc:creator>
 <dc:creator>Ouyang, Bo</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Object manipulation is a basic element in everyday human lives. Robotic
manipulation has progressed from maneuvering single-rigid-body objects with
firm grasping to maneuvering soft objects and handling contact-rich actions.
Meanwhile, technologies such as robot learning from demonstration have enabled
humans to intuitively train robots. This paper discusses a new level of robotic
learning-based manipulation. In contrast to the single form of learning from
demonstration, we propose a multiform learning approach that integrates
additional forms of skill acquisition, including adaptive learning from
definition and evaluation. Moreover, going beyond state-of-the-art technologies
of handling purely rigid or soft objects in a pseudo-static manner, our work
allows robots to learn to handle partly rigid partly soft objects with
time-critical skills and sophisticated contact control. Such capability of
robotic manipulation offers a variety of new possibilities in human-robot
interaction.
</dc:description>
 <dc:description>Comment: Accepted to 2017 Dynamic Systems and Control Conference (DSCC),
  Tysons Corner, VA, October 11-13</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05193</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proof-Relevant Logical Relations for Name Generation</dc:title>
 <dc:creator>Benton, Nick</dc:creator>
 <dc:creator>Hofmann, Martin</dc:creator>
 <dc:creator>Nigam, Vivek</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Pitts and Stark's nu-calculus is a paradigmatic total language for studying
the problem of contextual equivalence in higher-order languages with name
generation. Models for the nu-calculus that validate basic equivalences
concerning names may be constructed using functor categories or nominal sets,
with a dynamic allocation monad used to model computations that may allocate
fresh names. If recursion is added to the language and one attempts to adapt
the models from (nominal) sets to (nominal) domains, however, the direct-style
construction of the allocation monad no longer works. This issue has previously
been addressed by using a monad that combines dynamic allocation with
continuations, at some cost to abstraction.
  This paper presents a direct-style model of a nu-calculus-like language with
recursion using the novel framework of proof-relevant logical relations, in
which logical relations also contain objects (or proofs) demonstrating the
equivalence of (the semantic counterparts of) programs. Apart from providing a
fresh solution to an old problem, this work provides an accessible setting in
which to introduce the use of proof-relevant logical relations, free of the
additional complexities associated with their use for more sophisticated
languages.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05194</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extracting Formal Specifications to Strenghten Type Behaviour Testing</dc:title>
 <dc:creator>Racordon, Dimitri</dc:creator>
 <dc:creator>Buchs, Didier</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Testing has become an indispensable activity of software development, yet
writing good and relevant tests remains a quite challenging task. One
well-known problem is that it often is impossible or unrealistic to test for
every outcome, as the input and/or output of a program component can represent
incredbly large, unless infinite domains. A common approach to tackle this
issue it to only test classes of cases, and to assume that those classes cover
all (or at least most) of the cases a component is susceptible to be exposed
to. Unfortunately, those kind of assumptions can prove wrong in many
situations, causing a yet well-tested program to fail upon a particular input.
In this short paper, we propose to leverage formal verification, in particular
model checking techniques, as a way to better identify cases for which the
aforementioned assumptions do not hold, and ultimately strenghten the
confidence one can have in a test suite. The idea is to extract a formal
specification of the data types of a program, in the form of a term rewriting
system, and to check that specification against a set of properties specified
by the programmer. Cases for which tose properties do not hold can then be
identified using model checking, and selected as test cases.
</dc:description>
 <dc:description>Comment: 2 pages</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05198</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hypothesis Testing In Multi-Hop Networks</dc:title>
 <dc:creator>Salehkalaibar, Sadaf</dc:creator>
 <dc:creator>Wigger, Michele</dc:creator>
 <dc:creator>Wang, Ligong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Coding and testing schemes for binary hypothesis testing over three kinds of
multi-hop networks are presented and their achievable type-II error exponents
as functions of the available communication rates are characterized. The
schemes are based on cascade source coding techniques and
\emph{unanimous-decision forwarding}, where terminals decide only on the null
hypothesis if all previous terminals have decided on this hypothesis, and where
they forward their decision to the next hop. The achieved exponent-rate region
is analyzed by extending Han's approach to account for the unanimous-decision
forwarding strategy and for the more complicated code constructions. The
proposed coding and testing schemes are shown to attain the optimal type-II
error exponent region for various instances of testing against independence on
the single-relay multi-hop network, one instance of the $K$-relay multi-hop
network, and one instance of a network with two parallel multi-hop networks
that share a common receiver.
  For the basic single-relay multi-hop network, the proposed scheme is further
improved by means of binning. This improved scheme is again analyzed by
extending Han's approach, and is shown to be optimal when testing against
conditional independence under some Markov condition. For completeness, the
paper also presents the previously missing analysis of the Shimokawa, Han and
Amari binning scheme for the point-to-point hypothesis testing setup.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05201</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analog to Digital Cognitive Radio: Sampling, Detection and Hardware</dc:title>
 <dc:creator>Cohen, Deborah</dc:creator>
 <dc:creator>Tsiper, Shahar</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The proliferation of wireless communications has recently created a
bottleneck in terms of spectrum availability. Motivated by the observation that
the root of the spectrum scarcity is not a lack of resources but an inefficient
managing that can be solved, dynamic opportunistic exploitation of spectral
bands has been considered, under the name of Cognitive Radio (CR). This
technology allows secondary users to access currently idle spectral bands by
detecting and tracking the spectrum occupancy. The CR application revisits this
traditional task with specific and severe requirements in terms of spectrum
sensing and detection performance, real-time processing, robustness to noise
and more. Unfortunately, conventional methods do not satisfy these demands for
typical signals, that often have very high Nyquist rates.
  Recently, several sampling methods have been proposed that exploit signals' a
priori known structure to sample them below the Nyquist rate. Here, we review
some of these techniques and tie them to the task of spectrum sensing in the
context of CR. We then show how issues related to spectrum sensing can be
tackled in the sub-Nyquist regime. First, to cope with low signal to noise
ratios, we propose to recover second-order statistics from the low rate
samples, rather than the signal itself. In particular, we consider
cyclostationary based detection, and investigate CR networks that perform
collaborative spectrum sensing to overcome channel effects. To enhance the
efficiency of the available spectral bands detection, we present joint spectrum
sensing and direction of arrival estimation methods. Throughout this work, we
highlight the relation between theoretical algorithms and their practical
implementation. We show hardware simulations performed on a prototype we built,
demonstrating the feasibility of sub-Nyquist spectrum sensing in the context of
CR.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Signal Processing Magazine</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05206</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Brain Abnormality Detection by Deep Convolutional Neural Network</dc:title>
 <dc:creator>Rezaei, Mina</dc:creator>
 <dc:creator>Yang, Haojin</dc:creator>
 <dc:creator>Meinel, Christoph</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  In this paper, we describe our method for classification of brain magnetic
resonance (MR) images into different abnormalities and healthy classes based on
the deep neural network. We propose our method to detect high and low-grade
glioma, multiple sclerosis, and Alzheimer diseases as well as healthy cases.
Our network architecture has ten learning layers that include seven
convolutional layers and three fully connected layers. We have achieved a
promising result in five categories of brain images (classification task) with
95.7% accuracy.
</dc:description>
 <dc:description>Comment: Accepted for presenting in ACM-womENcourage_2016</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05207</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Universal Adversarial Perturbations with Generative Models</dc:title>
 <dc:creator>Hayes, Jamie</dc:creator>
 <dc:creator>Danezis, George</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neural networks are known to be vulnerable to adversarial examples, inputs
that have been intentionally perturbed to remain visually similar to the source
input, but cause a misclassification. It was recently shown that given a
dataset and classifier, there exists so called universal adversarial
perturbations, a single perturbation that causes a misclassification when
applied to any input. In this work, we introduce universal adversarial
networks, a generative network that is capable of fooling a target classifier
when it's generated output is added to a clean sample from a dataset. We show
that this technique improves on known universal adversarial attacks.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2018-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05208</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic HVAC Control with Real-time Occupancy Recognition and
  Simulation-guided Model Predictive Control in Low-cost Embedded System</dc:title>
 <dc:creator>Aftab, Muhammad</dc:creator>
 <dc:creator>Chen, Chien</dc:creator>
 <dc:creator>Chau, Chi-Kin</dc:creator>
 <dc:creator>Rahwan, Talal</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Intelligent building automation systems can reduce the energy consumption of
heating, ventilation and air-conditioning (HVAC) units by sensing the comfort
requirements automatically and scheduling the HVAC operations dynamically.
Traditional building automation systems rely on fairly inaccurate occupancy
sensors and basic predictive control using oversimplified building thermal
response models, all of which prevent such systems from reaching their full
potential. Such limitations can now be avoided due to the recent developments
in embedded system technologies, which provide viable low-cost computing
platforms with powerful processors and sizeable memory storage in a small
footprint. As a result, building automation systems can now efficiently execute
highly-sophisticated computational tasks, such as real-time video processing
and accurate thermal-response simulations. With this in mind, we designed and
implemented an occupancy-predictive HVAC control system in a low-cost yet
powerful embedded system (using Raspberry Pi 3) to demonstrate the following
key features for building automation: (1) real-time occupancy recognition using
video-processing and machine-learning techniques, (2) dynamic analysis and
prediction of occupancy patterns, and (3) model predictive control for HVAC
operations guided by real-time building thermal response simulations (using an
on-board EnergyPlus simulator). We deployed and evaluated our system for
providing automatic HVAC control in the large public indoor space of a mosque,
thereby achieving significant energy savings.
</dc:description>
 <dc:description>Comment: To appear in Energy and Buildings</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05208</dc:identifier>
 <dc:identifier>Volume 154, 1 November 2017, Pages 141-156, Energy and Buildings</dc:identifier>
 <dc:identifier>doi:10.1016/j.enbuild.2017.07.077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05209</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LSCHC: Layered Static Context Header Compression for LPWANs</dc:title>
 <dc:creator>Abdelfadeel, Khaled Q.</dc:creator>
 <dc:creator>Cionca, Victor</dc:creator>
 <dc:creator>Pesch, Dirk</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Supporting IPv6/UDP/CoAP protocols over Low Power Wide Area Networks (LPWANs)
can bring open networking, interconnection, and cooperation to this new type of
Internet of Things networks. However, accommodating these protocols over these
very low bandwidth networks requires efficient header compression schemes to
meet the limited frame size of these networks, where only one or two octets are
available to transmit all headers. Recently, the Internet Engineering Task
Force (IETF) LPWAN working group drafted the Static Context Header Compression
(SCHC), a new header compression scheme for LPWANs, which can provide a good
compression factor without complex synchronization. In this paper, we present
an implementation and evaluation of SCHC. We compare SCHC with IPHC, which also
targets constrained networks. Additionally, we propose an enhancement of SCHC,
Layered SCHC (LSCHC). LSCHC is a layered context that reduces memory
consumption and processing complexity, and adds flexibility when compressing
packets. Finally, we perform calculations to show the impact of SCHC/LSCHC on
an example LPWAN technology, e.g. LoRaWAN, from the point of view of
transmission time and reliability.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, accepted fir publication in CHANTS workshop in
  ACM MobiCom</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05211</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-based Models for Video Anomaly Detection</dc:title>
 <dc:creator>Vu, Hung</dc:creator>
 <dc:creator>Phung, Dinh</dc:creator>
 <dc:creator>Nguyen, Tu Dinh</dc:creator>
 <dc:creator>Trevors, Anthony</dc:creator>
 <dc:creator>Venkatesh, Svetha</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automated detection of abnormalities in data has been studied in research
area in recent years because of its diverse applications in practice including
video surveillance, industrial damage detection and network intrusion
detection. However, building an effective anomaly detection system is a
non-trivial task since it requires to tackle challenging issues of the shortage
of annotated data, inability of defining anomaly objects explicitly and the
expensive cost of feature engineering procedure. Unlike existing appoaches
which only partially solve these problems, we develop a unique framework to
cope the problems above simultaneously. Instead of hanlding with ambiguous
definition of anomaly objects, we propose to work with regular patterns whose
unlabeled data is abundant and usually easy to collect in practice. This allows
our system to be trained completely in an unsupervised procedure and liberate
us from the need for costly data annotation. By learning generative model that
capture the normality distribution in data, we can isolate abnormal data points
that result in low normality scores (high abnormality scores). Moreover, by
leverage on the power of generative networks, i.e. energy-based models, we are
also able to learn the feature representation automatically rather than
replying on hand-crafted features that have been dominating anomaly detection
research over many decades. We demonstrate our proposal on the specific
application of video anomaly detection and the experimental results indicate
that our method performs better than baselines and are comparable with
state-of-the-art methods in many benchmark video anomaly detection datasets.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05214</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When data mining meets optimization: A case study on the quadratic
  assignment problem</dc:title>
 <dc:creator>Zhou, Yangming</dc:creator>
 <dc:creator>Hao, Jin-Kao</dc:creator>
 <dc:creator>Duval, B&#xe9;atrice</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This paper presents a hybrid approach called frequent pattern based search
that combines data mining and optimization. The proposed method uses a data
mining procedure to mine frequent patterns from a set of high-quality solutions
collected from previous search, and the mined frequent patterns are then
employed to build starting solutions that are improved by an optimization
procedure. After presenting the general approach and its composing ingredients,
we illustrate its application to solve the well-known and challenging quadratic
assignment problem. Computational results on the 21 hardest benchmark instances
show that the proposed approach competes favorably with state-of-the-art
algorithms both in terms of solution quality and computing time.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-10-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05221</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Neural Network with l2-norm Unit for Brain Lesions Detection</dc:title>
 <dc:creator>Rezaei, Mina</dc:creator>
 <dc:creator>Yang, Haojin</dc:creator>
 <dc:creator>Meinel, Christoph</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automated brain lesions detection is an important and very challenging
clinical diagnostic task because the lesions have different sizes, shapes,
contrasts, and locations. Deep Learning recently has shown promising progress
in many application fields, which motivates us to apply this technology for
such important problem. In this paper, we propose a novel and end-to-end
trainable approach for brain lesions classification and detection by using deep
Convolutional Neural Network (CNN). In order to investigate the applicability,
we applied our approach on several brain diseases including high and low-grade
glioma tumor, ischemic stroke, Alzheimer diseases, by which the brain Magnetic
Resonance Images (MRI) have been applied as an input for the analysis. We
proposed a new operating unit which receives features from several projections
of a subset units of the bottom layer and computes a normalized l2-norm for
next layer. We evaluated the proposed approach on two different CNN
architectures and number of popular benchmark datasets. The experimental
results demonstrate the superior ability of the proposed approach.
</dc:description>
 <dc:description>Comment: Accepted for presentation in ICONIP-2017</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05221</dc:identifier>
 <dc:identifier>Springer2017</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-70093-9_85</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05223</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The streaming $k$-mismatch problem</dc:title>
 <dc:creator>Clifford, Rapha&#xeb;l</dc:creator>
 <dc:creator>Kociumaka, Tomasz</dc:creator>
 <dc:creator>Porat, Ely</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W32 (Primary) 68W27, 68P30 (Secondary)</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:description>  We consider the problem of approximate pattern matching in a stream. In the
streaming $k$-mismatch problem, we must compute all Hamming distances between a
pattern of length $n$ and successive $n$-length substrings of a longer text, as
long as the Hamming distance is at most $k$. The twin challenges of streaming
pattern matching derive from the need both to achieve small and typically
sublinear working space and also to have fast guaranteed running time for every
arriving symbol of the text.
  As a preliminary step we first give a deterministic $O(k(\log \frac{n}{k} +
\log |\Sigma|) )$-bit encoding of all the alignments with Hamming distance at
most $k$ between a pattern and a text of length $O(n)$. (We denote the input
alphabet by the symbol $\Sigma$.) This result, which provides a solution for a
seemingly difficult combinatorial problem, may be of independent interest. We
then go on to give an $O(k\log^3 n\log\frac{n}{k})$-time streaming algorithm
for the $k$-mismatch streaming problem which uses only
$O(k\log{n}\log\frac{n}{k})$ bits of space. The space usage is within
logarithmic factors of optimal and approximately a factor of $k$ improvement
over the previous record [Clifford et al., SODA 2016]
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05227</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional Adversarial Network for Semantic Segmentation of Brain Tumor</dc:title>
 <dc:creator>Rezaei, Mina</dc:creator>
 <dc:creator>Harmuth, Konstantin</dc:creator>
 <dc:creator>Gierke, Willi</dc:creator>
 <dc:creator>Kellermeier, Thomas</dc:creator>
 <dc:creator>Fischer, Martin</dc:creator>
 <dc:creator>Yang, Haojin</dc:creator>
 <dc:creator>Meinel, Christoph</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automated medical image analysis has a significant value in diagnosis and
treatment of lesions. Brain tumors segmentation has a special importance and
difficulty due to the difference in appearances and shapes of the different
tumor regions in magnetic resonance images. Additionally, the data sets are
heterogeneous and usually limited in size in comparison with the computer
vision problems. The recently proposed adversarial training has shown promising
results in generative image modeling. In this paper, we propose a novel
end-to-end trainable architecture for brain tumor semantic segmentation through
conditional adversarial training. We exploit conditional Generative Adversarial
Network (cGAN) and train a semantic segmentation Convolution Neural Network
(CNN) along with an adversarial network that discriminates segmentation maps
coming from the ground truth or from the segmentation network for BraTS 2017
segmentation task[15, 4, 2, 3]. We also propose an end-to-end trainable CNN for
survival day prediction based on deep learning techniques for BraTS 2017
prediction task [15, 4, 2, 3]. The experimental results demonstrate the
superior ability of the proposed approach for both tasks. The proposed model
achieves on validation data a DICE score, Sensitivity and Specificity
respectively 0.68, 0.99 and 0.98 for the whole tumor, regarding online judgment
system.
</dc:description>
 <dc:description>Comment: Submitted to BraTS challenges which is part of MICCAI-2017</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05233</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Semiotics-inspired Domain-Specific Modeling Language for Complex Event
  Processing Rules</dc:title>
 <dc:creator>Diniz, Herbertt</dc:creator>
 <dc:creator>Gama, Kiev</dc:creator>
 <dc:creator>Fidalgo, Robson</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Complex Event Processing (CEP) is one technique used to the handling data
flows. It allows pre-establishing conditions through rules and firing events
when certain patterns are found in the data flows. Because the rules for
defining such patterns are expressed with specific languages, users of these
technologies must understand the underlying expression syntax. To reduce the
complexity of writing CEP rules, some researchers are employing Domain Specific
Modeling Language (DSML) to provide modelling through visual tools. However,
existing approaches are ignoring some user design techniques that facilitate
usability. Thus, resulting tools eventually has become more complexes for
handling CEP than the conventional usage. Also, research on DSML tools
targeting CEP does not present any evaluation around usability. This article
proposes a DSML combined with visual notations techniques to create CEP rules
with a more intuitive development model adapted for the non-expert user needs.
The resulting tool was evaluated by non-expert users that were capable of
easily creating CEP rules without prior knowledge of the underlying expression
language.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05234</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FaceBoxes: A CPU Real-time Face Detector with High Accuracy</dc:title>
 <dc:creator>Zhang, Shifeng</dc:creator>
 <dc:creator>Zhu, Xiangyu</dc:creator>
 <dc:creator>Lei, Zhen</dc:creator>
 <dc:creator>Shi, Hailin</dc:creator>
 <dc:creator>Wang, Xiaobo</dc:creator>
 <dc:creator>Li, Stan Z.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Although tremendous strides have been made in face detection, one of the
remaining open challenges is to achieve real-time speed on the CPU as well as
maintain high performance, since effective models for face detection tend to be
computationally prohibitive. To address this challenge, we propose a novel face
detector, named FaceBoxes, with superior performance on both speed and
accuracy. Specifically, our method has a lightweight yet powerful network
structure that consists of the Rapidly Digested Convolutional Layers (RDCL) and
the Multiple Scale Convolutional Layers (MSCL). The RDCL is designed to enable
FaceBoxes to achieve real-time speed on the CPU. The MSCL aims at enriching the
receptive fields and discretizing anchors over different layers to handle faces
of various scales. Besides, we propose a new anchor densification strategy to
make different types of anchors have the same density on the image, which
significantly improves the recall rate of small faces. As a consequence, the
proposed detector runs at 20 FPS on a single CPU core and 125 FPS using a GPU
for VGA-resolution images. Moreover, the speed of FaceBoxes is invariant to the
number of faces. We comprehensively evaluate this method and present
state-of-the-art detection performance on several face detection benchmark
datasets, including the AFW, PASCAL face, and FDDB.
</dc:description>
 <dc:description>Comment: Accepted by IJCB 2017; Added references</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05237</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>S$^3$FD: Single Shot Scale-invariant Face Detector</dc:title>
 <dc:creator>Zhang, Shifeng</dc:creator>
 <dc:creator>Zhu, Xiangyu</dc:creator>
 <dc:creator>Lei, Zhen</dc:creator>
 <dc:creator>Shi, Hailin</dc:creator>
 <dc:creator>Wang, Xiaobo</dc:creator>
 <dc:creator>Li, Stan Z.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a real-time face detector, named Single Shot
Scale-invariant Face Detector (S$^3$FD), which performs superiorly on various
scales of faces with a single deep neural network, especially for small faces.
Specifically, we try to solve the common problem that anchor-based detectors
deteriorate dramatically as the objects become smaller. We make contributions
in the following three aspects: 1) proposing a scale-equitable face detection
framework to handle different scales of faces well. We tile anchors on a wide
range of layers to ensure that all scales of faces have enough features for
detection. Besides, we design anchor scales based on the effective receptive
field and a proposed equal proportion interval principle; 2) improving the
recall rate of small faces by a scale compensation anchor matching strategy; 3)
reducing the false positive rate of small faces via a max-out background label.
As a consequence, our method achieves state-of-the-art detection performance on
all the common face detection benchmarks, including the AFW, PASCAL face, FDDB
and WIDER FACE datasets, and can run at 36 FPS on a Nvidia Titan X (Pascal) for
VGA-resolution images.
</dc:description>
 <dc:description>Comment: Accepted by ICCV 2017 + its supplementary materials; Updated the
  latest results on WIDER FACE</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05240</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Answer Substitutions in Logic Programming</dc:title>
 <dc:creator>Kwon, Keehang</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Answer substitutions play a central role in logic programming. To support
{\it selective} answer substitutions, we refine $\exists x$ in goals into two
different versions: the noisy version $\exists^o x$ and the silent version
$\exists x$. The main difference is that only the instantiation in $\exists^o
x$ will be recorded in the answer substitutions. Similarly for $\forall x$.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05256</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning at 15PF: Supervised and Semi-Supervised Classification for
  Scientific Data</dc:title>
 <dc:creator>Kurth, Thorsten</dc:creator>
 <dc:creator>Zhang, Jian</dc:creator>
 <dc:creator>Satish, Nadathur</dc:creator>
 <dc:creator>Mitliagkas, Ioannis</dc:creator>
 <dc:creator>Racah, Evan</dc:creator>
 <dc:creator>Patwary, Mostofa Ali</dc:creator>
 <dc:creator>Malas, Tareq</dc:creator>
 <dc:creator>Sundaram, Narayanan</dc:creator>
 <dc:creator>Bhimji, Wahid</dc:creator>
 <dc:creator>Smorkalov, Mikhail</dc:creator>
 <dc:creator>Deslippe, Jack</dc:creator>
 <dc:creator>Shiryaev, Mikhail</dc:creator>
 <dc:creator>Sridharan, Srinivas</dc:creator>
 <dc:creator>Prabhat</dc:creator>
 <dc:creator>Dubey, Pradeep</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents the first, 15-PetaFLOP Deep Learning system for solving
scientific pattern classification problems on contemporary HPC architectures.
We develop supervised convolutional architectures for discriminating signals in
high-energy physics data as well as semi-supervised architectures for
localizing and classifying extreme weather in climate data. Our
Intelcaffe-based implementation obtains $\sim$2TFLOP/s on a single Cori
Phase-II Xeon-Phi node. We use a hybrid strategy employing synchronous
node-groups, while using asynchronous communication across groups. We use this
strategy to scale training of a single model to $\sim$9600 Xeon-Phi nodes;
obtaining peak performance of 11.73-15.07 PFLOP/s and sustained performance of
11.41-13.27 PFLOP/s. At scale, our HEP architecture produces state-of-the-art
classification accuracy on a dataset with 10M images, exceeding that achieved
by selections on high-level physics-motivated features. Our semi-supervised
architecture successfully extracts weather patterns in a 15TB climate dataset.
Our results demonstrate that Deep Learning can be optimized and scaled
effectively on many-core, HPC systems.
</dc:description>
 <dc:description>Comment: 12 pages, 9 figures</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05261</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy Guidelines for Internet of Things: A Cheat Sheet</dc:title>
 <dc:creator>Perera, Charith</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This document presents 30 different privacy guidelines that can be used to
both design and assess IoT applications and IoT middleware platforms. These
guidelines can be broadly categorised into eight categories, namely, MINIMIZE (
), HIDE ( ), SEPARATE ( ), AGGREGATE ( ), INFORM ( ), CONTROL ( ), ENFORCE ( ),
DEMONSTRATE ( ). This document uses the following structure to introduce the
each privacy guidelines. First, we describe the philosophy behind each
guideline in general. Then, we present the questions that software architects
need to think about when designing or assessing an IoT platform or application.
The questions slightly vary depending on whether the architect is assessing a
platform or an application.
</dc:description>
 <dc:description>Comment: Charith Perera (2017), Privacy Guidelines for Internet of Things: A
  Cheat Sheet, Technical Report, Newcastle University, UK. arXiv admin note:
  substantial text overlap with arXiv:1609.04060</dc:description>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05263</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Size of a Hyperball in a Conceptual Space</dc:title>
 <dc:creator>Bechberger, Lucas</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The cognitive framework of conceptual spaces [3] provides geometric means for
representing knowledge. A conceptual space is a high-dimensional space whose
dimensions are partitioned into so-called domains. Within each domain, the
Euclidean metric is used to compute distances. Distances in the overall space
are computed by applying the Manhattan metric to the intra-domain distances.
Instances are represented as points in this space and concepts are represented
by regions. In this paper, we derive a formula for the size of a hyperball
under the combined metric of a conceptual space. One can think of such a
hyperball as the set of all points having a certain minimal similarity to the
hyperball's center.
</dc:description>
 <dc:date>2017-07-04</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05264</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design, Configuration, Implementation, and Performance of a Simple 32
  Core Raspberry Pi Cluster</dc:title>
 <dc:creator>Cicirello, Vincent A.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this report, I describe the design and implementation of an inexpensive,
eight node, 32 core, cluster of raspberry pi single board computers, as well as
the performance of this cluster on two computational tasks, one that requires
significant data transfer relative to computational time requirements, and one
that does not. We have two use-cases for the cluster: (a) as an educational
tool for classroom usage, such as covering parallel algorithms in an algorithms
course; and (b) as a test system for use during the development of parallel
metaheuristics, essentially serving as a personal desktop parallel computing
cluster. Our preliminary results show that the slow 100 Mbps networking of the
raspberry pi significantly limits such clusters to parallel computational tasks
that are either long running relative to data communications requirements, or
that which requires very little internode communications. Additionally,
although the raspberry pi 3 has a quad-core processor, parallel speedup
degrades during attempts to utilize all four cores of all cluster nodes for a
parallel computation, likely due to resource contention with operating system
level processes. However, distributing a task across three cores of each
cluster node does enable linear (or near linear) speedup.
</dc:description>
 <dc:description>Comment: Stockton University</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05269</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Syntactic Iberian Polarity Classification</dc:title>
 <dc:creator>Vilares, David</dc:creator>
 <dc:creator>Garcia, Marcos</dc:creator>
 <dc:creator>Alonso, Miguel A.</dc:creator>
 <dc:creator>G&#xf3;mez-Rodr&#xed;guez, Carlos</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Lexicon-based methods using syntactic rules for polarity classification rely
on parsers that are dependent on the language and on treebank guidelines. Thus,
rules are also dependent and require adaptation, especially in multilingual
scenarios. We tackle this challenge in the context of the Iberian Peninsula,
releasing the first symbolic syntax-based Iberian system with rules shared
across five official languages: Basque, Catalan, Galician, Portuguese and
Spanish. The model is made available.
</dc:description>
 <dc:description>Comment: 7 pages, 5 tables. Contribution to the 8th Workshop on Computational
  Approaches to Subjectivity, Sentiment and Social Media Analysis (WASSA-2017)
  at EMNLP 2017</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05271</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incorporating Copying Mechanism in Image Captioning for Learning Novel
  Objects</dc:title>
 <dc:creator>Yao, Ting</dc:creator>
 <dc:creator>Pan, Yingwei</dc:creator>
 <dc:creator>Li, Yehao</dc:creator>
 <dc:creator>Mei, Tao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Image captioning often requires a large set of training image-sentence pairs.
In practice, however, acquiring sufficient training pairs is always expensive,
making the recent captioning models limited in their ability to describe
objects outside of training corpora (i.e., novel objects). In this paper, we
present Long Short-Term Memory with Copying Mechanism (LSTM-C) --- a new
architecture that incorporates copying into the Convolutional Neural Networks
(CNN) plus Recurrent Neural Networks (RNN) image captioning framework, for
describing novel objects in captions. Specifically, freely available object
recognition datasets are leveraged to develop classifiers for novel objects.
Our LSTM-C then nicely integrates the standard word-by-word sentence generation
by a decoder RNN with copying mechanism which may instead select words from
novel objects at proper places in the output sentence. Extensive experiments
are conducted on both MSCOCO image captioning and ImageNet datasets,
demonstrating the ability of our proposed LSTM-C architecture to describe novel
objects. Furthermore, superior results are reported when compared to
state-of-the-art deep models.
</dc:description>
 <dc:description>Comment: CVPR17</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05279</identifier>
 <datestamp>2017-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing and building the mlpack open-source machine learning library</dc:title>
 <dc:creator>Curtin, Ryan R.</dc:creator>
 <dc:creator>Edel, Marcus</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  mlpack is an open-source C++ machine learning library with an emphasis on
speed and flexibility. Since its original inception in 2007, it has grown to be
a large project implementing a wide variety of machine learning algorithms,
from standard techniques such as decision trees and logistic regression to
modern techniques such as deep neural networks as well as other
recently-published cutting-edge techniques not found in any other library.
mlpack is quite fast, with benchmarks showing mlpack outperforming other
libraries' implementations of the same methods. mlpack has an active community,
with contributors from around the world---including some from PUST. This short
paper describes the goals and design of mlpack, discusses how the open-source
community functions, and shows an example usage of mlpack for a simple data
science problem.
</dc:description>
 <dc:description>Comment: submitted to ICOPUST 2017</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05281</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource Optimization with Load Coupling in Multi-cell NOMA</dc:title>
 <dc:creator>You, Lei</dc:creator>
 <dc:creator>Yuan, Di</dc:creator>
 <dc:creator>Lei, Lei</dc:creator>
 <dc:creator>Sun, Sumei</dc:creator>
 <dc:creator>Chatzinotas, Symeon</dc:creator>
 <dc:creator>Ottersten, Bj&#xf6;rn</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Optimizing non-orthogonal multiple access (NOMA) in multi-cell scenarios is
much more challenging than the single-cell case because inter-cell interference
must be considered. Most papers addressing NOMA consider a single cell. We take
a significant step of analyzing NOMA in multi-cell scenarios. We explore the
potential of NOMA networks in achieving optimal resource utilization with
arbitrary topologies. Towards this goal, we investigate a broad class of
problems consisting in optimizing power allocation and user pairing for any
cost function that is monotonically increasing in time-frequency resource
consump- tion. We propose an algorithm that achieves global optimality for this
problem class. The basic idea is to prove that solving the joint optimization
problem of power allocation, user pair selection, and time-frequency resource
allocation amounts to solving a so-called iterated function without a closed
form. We prove that the algorithm approaches optimality with fast convergence.
Numerically, we evaluate and demonstrate the performance of NOMA for multi-cell
scenarios in terms of resource efficiency and load balancing.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05286</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple Open Stance Classification for Rumour Analysis</dc:title>
 <dc:creator>Aker, Ahmet</dc:creator>
 <dc:creator>Derczynski, Leon</dc:creator>
 <dc:creator>Bontcheva, Kalina</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Stance classification determines the attitude, or stance, in a (typically
short) text. The task has powerful applications, such as the detection of fake
news or the automatic extraction of attitudes toward entities or events in the
media. This paper describes a surprisingly simple and efficient classification
approach to open stance classification in Twitter, for rumour and veracity
classification. The approach profits from a novel set of automatically
identifiable problem-specific features, which significantly boost classifier
accuracy and achieve above state-of-the-art results on recent benchmark
datasets. This calls into question the value of using complex sophisticated
models for stance classification without first doing informed feature
extraction.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05286</dc:identifier>
 <dc:identifier>In RANLP 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05291</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Organisation and Quality Analysis of User-Generated Content
  with Audio Fingerprinting</dc:title>
 <dc:creator>Mordido, Gon&#xe7;alo</dc:creator>
 <dc:creator>Magalh&#xe3;es, Jo&#xe3;o</dc:creator>
 <dc:creator>Cavaco, Sofia</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The increase of the quantity of user-generated content experienced in social
media has boosted the importance of analysing and organising the content by its
quality. Here, we propose a method that uses audio fingerprinting to organise
and infer the quality of user-generated audio content. The proposed method
detects the overlapping segments between different audio clips to organise and
cluster the data according to events, and to infer the audio quality of the
samples. A test setup with concert recordings manually crawled from YouTube is
used to validate the presented method. The results show that the proposed
method achieves better results than previous methods.
</dc:description>
 <dc:description>Comment: EUSIPCO 2017 - 25th European Signal Processing Conference</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05294</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorial Optimization on Gate Model Quantum Computers: A Survey</dc:title>
 <dc:creator>Zahedinejad, Ehsan</dc:creator>
 <dc:creator>Zaribafiyan, Arman</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The advent of quantum computing processors with possibility to scale beyond
experimental capacities magnifies the importance of studying their
applications. Combinatorial optimization problems can be one of the promising
applications of these new devices. These problems are recurrent in industrial
applications and they are in general difficult for classical computing
hardware. In this work, we provide a survey of the approaches to solving
different types of combinatorial optimization problems, in particular quadratic
unconstrained binary optimization (QUBO) problems on a gate model quantum
computer. We focus mainly on four different approaches including digitizing the
adiabatic quantum computing, global quantum optimization algorithms, the
quantum algorithms that approximate the ground state of a general QUBO problem,
and quantum sampling. We also discuss the quantum algorithms that are custom
designed to solve certain types of QUBO problems.
</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05296</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Parallel A*</dc:title>
 <dc:creator>Fukunaga, Alex</dc:creator>
 <dc:creator>Botea, Adi</dc:creator>
 <dc:creator>Jinnai, Yuu</dc:creator>
 <dc:creator>Kishimoto, Akihiro</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A* is a best-first search algorithm for finding optimal-cost paths in graphs.
A* benefits significantly from parallelism because in many applications, A* is
limited by memory usage, so distributed memory implementations of A* that use
all of the aggregate memory on the cluster enable problems that can not be
solved by serial, single-machine implementations to be solved. We survey
approaches to parallel A*, focusing on decentralized approaches to A* which
partition the state space among processors. We also survey approaches to
parallel, limited-memory variants of A* such as parallel IDA*.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1201.3204</dc:description>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05302</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Organisation, Segmentation, and Filtering of User-Generated
  Audio Content</dc:title>
 <dc:creator>Mordido, Gon&#xe7;alo</dc:creator>
 <dc:creator>Magalh&#xe3;es, Jo&#xe3;o</dc:creator>
 <dc:creator>Cavaco, Sofia</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Using solely the information retrieved by audio fingerprinting techniques, we
propose methods to treat a possibly large dataset of user-generated audio
content, that (1) enable the grouping of several audio files that contain a
common audio excerpt (i.e., are relative to the same event), and (2) give
information about how those files are correlated in terms of time and quality
inside each event. Furthermore, we use supervised learning to detect incorrect
matches that may arise from the audio fingerprinting algorithm itself, whilst
ensuring our model learns with previous predictions. All the presented methods
were further validated by user-generated recordings of several different
concerts manually crawled from YouTube.
</dc:description>
 <dc:description>Comment: MMSP 2017 - IEEE 19th International Workshop on Multimedia Signal
  Processing</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05311</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User-centric Performance Optimization with Remote Radio Head Cooperation
  in C-RAN</dc:title>
 <dc:creator>You, Lei</dc:creator>
 <dc:creator>Yuan, Di</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In a cloud radio access network (C-RAN), distributed remote radio heads
(RRHs) are coordinated by baseband units (BBUs) in the cloud. The
centralization of signal processing provides flexibility for coordinated
multi-point transmission (CoMP) of RRHs to cooperatively serve user equipments
(UEs). We target enhancing UEs' capacity performance, by jointly optimizing the
selection of RRHs for serving UEs, i.e., resource allocation (and CoMP
selection). We analyze the computational complexity of the problem. Next, we
prove that under fixed CoMP selection, the optimal resource allocation amounts
to solving a so-called iterated function. Towards user-centric network
optimization, we propose an algorithm for the joint optimization problem,
aiming at maximumly scaling up the capacity for any target UE group of
interest. The proposed algorithm enables network-level performance evaluation
for quality of experience.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05325</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Musical Relations using Gated Autoencoders</dc:title>
 <dc:creator>Lattner, Stefan</dc:creator>
 <dc:creator>Grachten, Maarten</dc:creator>
 <dc:creator>Widmer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Music is usually highly structured and it is still an open question how to
design models which can successfully learn to recognize and represent musical
structure. A fundamental problem is that structurally related patterns can have
very distinct appearances, because the structural relationships are often based
on transformations of musical material, like chromatic or diatonic
transposition, inversion, retrograde, or rhythm change. In this preliminary
work, we study the potential of two unsupervised learning techniques -
Restricted Boltzmann Machines (RBMs) and Gated Autoencoders (GAEs) - to capture
pre-defined transformations from constructed data pairs. We evaluate the models
by using the learned representations as inputs in a discriminative task where
for a given type of transformation (e.g. diatonic transposition), the specific
relation between two musical patterns must be recognized (e.g. an upward
transposition of diatonic steps). Furthermore, we measure the reconstruction
error of models when reconstructing musical transformed patterns. Lastly, we
test the models in an analogy-making task. We find that it is difficult to
learn musical transformations with the RBM and that the GAE is much more
adequate for this task, since it is able to learn representations of specific
transformations that are largely content-invariant. We believe these results
show that models such as GAEs may provide the basis for more encompassing music
analysis systems, by endowing them with a better understanding of the
structures underlying music.
</dc:description>
 <dc:description>Comment: In Proceedings of the 2nd Conference on Computer Simulation of
  Musical Creativity (CSMC 2017)</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05327</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Static and Dynamic Configurability of Existing Group
  Communication Systems</dc:title>
 <dc:creator>K&#xf6;stler, Johannes</dc:creator>
 <dc:creator>Reiser, Hans P.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Active replication following the state machine replication (SMR) approach is
a way to make existing systems and services more reliable and fault-tolerant.
The additional communication overhead has a negative impact on the system's
throughput and overall request latency. Today's systems should be highly
optimized to their execution environment and usage scenario in order to remedy
the performance loss introduced by such group communication systems (GCS). In
addition to that, systems should be able to adapt to changing environmental
conditions. This report analyzes the available configuration options of three
existing GCSs. Therefore, it explains the available configuration parameters
and describes the given reconfiguration mechanisms. The found parameters are
then classified in a parameter scheme.
</dc:description>
 <dc:description>Comment: Technical Report (38 pages)</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05329</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Inference from Consensus Dynamics</dc:title>
 <dc:creator>Segarra, Santiago</dc:creator>
 <dc:creator>Schaub, Michael T.</dc:creator>
 <dc:creator>Jadbabaie, Ali</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We consider the problem of identifying the topology of a weighted, undirected
network $\mathcal G$ from observing snapshots of multiple independent consensus
dynamics. Specifically, we observe the opinion profiles of a group of agents
for a set of $M$ independent topics and our goal is to recover the precise
relationships between the agents, as specified by the unknown network $\mathcal
G$. In order to overcome the under-determinacy of the problem at hand, we
leverage concepts from spectral graph theory and convex optimization to unveil
the underlying network structure. More precisely, we formulate the network
inference problem as a convex optimization that seeks to endow the network with
certain desired properties -- such as sparsity -- while being consistent with
the spectral information extracted from the observed opinions. This is
complemented with theoretical results proving consistency as the number $M$ of
topics grows large. We further illustrate our method by numerical experiments,
which showcase the effectiveness of the technique in recovering synthetic and
real-world networks.
</dc:description>
 <dc:description>Comment: Will be presented at the 2017 IEEE Conference on Decision and Control
  (CDC)</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05333</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Isometries and Binary Images of Linear Block Codes over $Z_4+uZ_4$ and
  $Z_8+uZ_8$</dc:title>
 <dc:creator>Sison, Virgilio P.</dc:creator>
 <dc:creator>Remillion, Monica N.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:subject>94B05, 94B65, 94B99</dc:subject>
 <dc:description>  Let $F_2$ be the binary field and $Z_{2^r}$ the residue class ring of
integers modulo $2^r$, where $r$ is a positive integer. For the finite
$16$-element commutative local Frobenius non-chain ring $Z_4+uZ_4$, where $u$
is nilpotent of index $2$, two weight functions are considered, namely the Lee
weight and the homogeneous weight. With the appropriate application of these
weights, isometric maps from $Z_4+uZ_4$ to the binary spaces $F_2^4$ and
$F_2^8$, respectively, are established via the composition of other
weight-based isometries. The classical Hamming weight is used on the binary
space. The resulting isometries are then applied to linear block codes over
$Z_4+uZ_4$ whose images are binary codes of predicted length, which may or may
not be linear. Certain lower and upper bounds on the minimum distances of the
binary images are also derived in terms of the parameters of the $Z_4+uZ_4$
codes. Several new codes and their images are constructed as illustrative
examples. An analogous procedure is performed successfully on the ring
$Z_8+uZ_8$, where $u^2=0$, which is a commutative local Frobenius non-chain
ring of order $64$. It turns out that the method is possible in general for the
class of rings $Z_{2^r}+uZ_{2^r}$, where $u^2=0$, for any positive integer $r$,
using the generalized Gray map from $Z_{2^r}$ to $F_2^{2^{r-1}}$.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, Presented in the 2016 Asian Mathematical
  Conference</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05333</dc:identifier>
 <dc:identifier>doi:10.1088/1742-6596/893/1/012049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05339</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Determining the Efficiency of Quantum Search Algorithms with the
  Renormalization Group</dc:title>
 <dc:creator>Boettcher, Stefan</dc:creator>
 <dc:creator>Li, Shanshan</dc:creator>
 <dc:creator>Fernandes, Tharso D.</dc:creator>
 <dc:creator>Portugal, Renato</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Quantum walks provide a powerful demonstration of the effectiveness of the
renormalization group (RG), here applied to find a lower bound on the
computational complexity of Grover's quantum search algorithms in
low-dimensional networks. For these, the RG reveals a competition between
Grover's abstract algorithm, i.e., a rotation in Hilbert space, and quantum
transport in an actual geometry. It can be characterized in terms of the
quantum walk dimension $d^Q_w$ and the spatial (fractal) dimension $d_f$, even
when translational invariance is broken. The analysis simultaneously determines
the optimal time for a quantum measurement and the probability for successfully
pin-pointing the sought-after element in the network. The RG further
encompasses an optimization scheme, devised by Tulsi, that allows to tune that
probability to certainty. Our RG considers entire families of problems to be
studied, thereby establishing a large universality class for quantum search,
here verified with extensive simulations.
</dc:description>
 <dc:description>Comment: 12 pages, revtex-4.1, enclosed is also a Mathematica Notebook to
  reproduce and experiment with the calculations; related information can be
  found at http://www.physics.emory.edu/faculty/boettcher/</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05340</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Registration and Geometry Estimation from Unstructured Facial
  Scans</dc:title>
 <dc:creator>Bazik, Maxim</dc:creator>
 <dc:creator>Crispell, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Commercial off the shelf (COTS) 3D scanners are capable of generating point
clouds covering visible portions of a face with sub-millimeter accuracy at
close range, but lack the coverage and specialized anatomic registration
provided by more expensive 3D facial scanners. We demonstrate an effective
pipeline for joint alignment of multiple unstructured 3D point clouds and
registration to a parameterized 3D model which represents shape variation of
the human head. Most algorithms separate the problems of pose estimation and
mesh warping, however we propose a new iterative method where these steps are
interwoven. Error decreases with each iteration, showing the proposed approach
is effective in improving geometry and alignment. The approach described is
used to align the NDOff-2007 dataset, which contains 7,358 individual scans at
various poses of 396 subjects. The dataset has a number of full profile scans
which are correctly aligned and contribute directly to the associated mesh
geometry. The dataset in its raw form contains a significant number of
mislabeled scans, which are identified and corrected based on alignment error
using the proposed algorithm. The average point to surface distance between the
aligned scans and the produced geometries is one half millimeter.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05344</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SMASH: One-Shot Model Architecture Search through HyperNetworks</dc:title>
 <dc:creator>Brock, Andrew</dc:creator>
 <dc:creator>Lim, Theodore</dc:creator>
 <dc:creator>Ritchie, J. M.</dc:creator>
 <dc:creator>Weston, Nick</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Designing architectures for deep neural networks requires expert knowledge
and substantial computation time. We propose a technique to accelerate
architecture selection by learning an auxiliary HyperNet that generates the
weights of a main model conditioned on that model's architecture. By comparing
the relative validation performance of networks with HyperNet-generated
weights, we can effectively search over a wide range of architectures at the
cost of a single training run. To facilitate this search, we develop a flexible
mechanism based on memory read-writes that allows us to define a wide range of
network connectivity patterns, with ResNet, DenseNet, and FractalNet blocks as
special cases. We validate our method (SMASH) on CIFAR-10 and CIFAR-100,
STL-10, ModelNet10, and Imagenet32x32, achieving competitive performance with
similarly-sized hand-designed networks. Our code is available at
https://github.com/ajbrock/SMASH
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05346</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>General AI Challenge - Round One: Gradual Learning</dc:title>
 <dc:creator>Feyereisl, Jan</dc:creator>
 <dc:creator>Nikl, Matej</dc:creator>
 <dc:creator>Poliak, Martin</dc:creator>
 <dc:creator>Stransky, Martin</dc:creator>
 <dc:creator>Vlasak, Michal</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The General AI Challenge is an initiative to encourage the wider artificial
intelligence community to focus on important problems in building intelligent
machines with more general scope than is currently possible. The challenge
comprises of multiple rounds, with the first round focusing on gradual
learning, i.e. the ability to re-use already learned knowledge for efficiently
learning to solve subsequent problems. In this article, we will present details
of the first round of the challenge, its inspiration and aims. We also outline
a more formal description of the challenge and present a preliminary analysis
of its curriculum, based on ideas from computational mechanics. We believe,
that such formalism will allow for a more principled approach towards
investigating tasks in the challenge, building new curricula and for
potentially improving consequent challenge rounds.
</dc:description>
 <dc:description>Comment: Presented as keynote talk at IJCAI Workshop on Evaluating
  General-Purpose AI (EGPAI 2017)</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05347</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two weight $\mathbb{Z}_{p^k}$-codes, $p$ odd prime</dc:title>
 <dc:creator>Shi, MinJia</dc:creator>
 <dc:creator>Sepasdar, Zahra</dc:creator>
 <dc:creator>Wu, Rongsheng</dc:creator>
 <dc:creator>Sol&#xe9;, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B05</dc:subject>
 <dc:description>  We show that regular homogeneous two-weight $\mathbb{Z}_{p^k}$-codes where
$p$ is odd and $k\geqslant 2$ with dual Hamming distance at least four do not
exist. The proof relies on existence conditions for the strongly regular graph
built on the cosets of the dual code.
</dc:description>
 <dc:description>Comment: This paper has been submitted in early 2016</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05349</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PixelNN: Example-based Image Synthesis</dc:title>
 <dc:creator>Bansal, Aayush</dc:creator>
 <dc:creator>Sheikh, Yaser</dc:creator>
 <dc:creator>Ramanan, Deva</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a simple nearest-neighbor (NN) approach that synthesizes
high-frequency photorealistic images from an &quot;incomplete&quot; signal such as a
low-resolution image, a surface normal map, or edges. Current state-of-the-art
deep generative models designed for such conditional image synthesis lack two
important things: (1) they are unable to generate a large set of diverse
outputs, due to the mode collapse problem. (2) they are not interpretable,
making it difficult to control the synthesized output. We demonstrate that NN
approaches potentially address such limitations, but suffer in accuracy on
small datasets. We design a simple pipeline that combines the best of both
worlds: the first stage uses a convolutional neural network (CNN) to maps the
input to a (overly-smoothed) image, and the second stage uses a pixel-wise
nearest neighbor method to map the smoothed output to multiple high-quality,
high-frequency outputs in a controllable manner. We demonstrate our approach
for various input modalities, and for various domains ranging from human faces
to cats-and-dogs to shoes and handbags.
</dc:description>
 <dc:description>Comment: Project Page: http://www.cs.cmu.edu/~aayushb/pixelNN/</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05350</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of Hilbert-Huang decomposition to reduce noise and
  characterize for NMR FID signal of proton precession magnetometer</dc:title>
 <dc:creator>Liu, Huan</dc:creator>
 <dc:creator>Dong, Haobin</dc:creator>
 <dc:creator>Liu, Zheng</dc:creator>
 <dc:creator>Ge, Jian</dc:creator>
 <dc:creator>Bai, Bingjie</dc:creator>
 <dc:creator>Zhang, Cheng</dc:creator>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  The parameters in a nuclear magnetic resonance (NMR) free induction decay
(FID) signal contain information that is useful in magnetic field measurement,
magnetic resonance sounding (MRS) and other related applications. A real time
sampled FID signal is well modeled as a finite mixture of exponential sequences
plus noise. We propose to use the Hilbert-Huang Transform (HHT) for noise
reduction and characterization, where the generalized Hilbert-Huang represents
a way to decompose a signal into so-called intrinsic mode function (IMF) along
with a trend, and obtain instantaneous frequency data. Moreover, the HHT for an
FID signal's feature analysis is applied for the first time. First, acquiring
the actual untuned FID signal by a developed prototype of proton magnetometer,
and then the empirical mode decomposition (EMD) is performed to decompose the
noise and original FID. Finally, the HHT is applied to the obtained IMFs to
extract the Hilbert energy spectrum, to indicate the energy distribution of the
signal on the frequency axis. By theory analysis and the testing of an actual
FID signal, the results show that, compared with general noise reduction
methods such as auto correlation and singular value decomposition (SVD),
combined with the proposed method can further suppress the interfered signals
effectively, and can obtain different components of FID signal, which can use
to identify the magnetic anomaly, the existence of groundwater etc. This is a
very important property since it can be exploited to separate the FID signal
from noise and to estimate exponential sequence parameters of FID signal.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures, 3 tables</dc:description>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05355</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MirrorFlow: Exploiting Symmetries in Joint Optical Flow and Occlusion
  Estimation</dc:title>
 <dc:creator>Hur, Junhwa</dc:creator>
 <dc:creator>Roth, Stefan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Optical flow estimation is one of the most studied problems in computer
vision, yet recent benchmark datasets continue to reveal problem areas of
today's approaches. Occlusions have remained one of the key challenges. In this
paper, we propose a symmetric optical flow method to address the well-known
chicken-and-egg relation between optical flow and occlusions. In contrast to
many state-of-the-art methods that consider occlusions as outliers, possibly
filtered out during post-processing, we highlight the importance of joint
occlusion reasoning in the optimization and show how to utilize occlusion as an
important cue for estimating optical flow. The key feature of our model is to
fully exploit the symmetry properties that characterize optical flow and
occlusions in the two consecutive images. Specifically through utilizing
forward-backward consistency and occlusion-disocclusion symmetry in the energy,
our model jointly estimates optical flow in both forward and backward
direction, as well as consistent occlusion maps in both views. We demonstrate
significant performance benefits on standard benchmarks, especially from the
occlusion-disocclusion symmetry. On the challenging KITTI dataset we report the
most accurate two-frame results to date.
</dc:description>
 <dc:description>Comment: 14 pages, To appear in ICCV 2017</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05356</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Heart-rate Estimation in Wearables With Liquid States and A
  Probabilistic Readout</dc:title>
 <dc:creator>Das, Anup</dc:creator>
 <dc:creator>Pradhapan, Paruthi</dc:creator>
 <dc:creator>Groenendaal, Willemijn</dc:creator>
 <dc:creator>Adiraju, Prathyusha</dc:creator>
 <dc:creator>Rajan, Raj Thilak</dc:creator>
 <dc:creator>Catthoor, Francky</dc:creator>
 <dc:creator>Schaafsma, Siebren</dc:creator>
 <dc:creator>Krichmar, Jeffrey L.</dc:creator>
 <dc:creator>Dutt, Nikil</dc:creator>
 <dc:creator>Van Hoof, Chris</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Heart-rate estimation is a fundamental feature of modern wearable devices. In
this paper we propose a machine intelligent approach for heart-rate estimation
from electrocardiogram (ECG) data collected using wearable devices. The novelty
of our approach lies in (1) encoding spatio-temporal properties of ECG signals
directly into spike train and using this to excite recurrently connected
spiking neurons in a Liquid State Machine computation model; (2) a novel
learning algorithm; and (3) an intelligently designed unsupervised readout
based on Fuzzy c-Means clustering of spike responses from a subset of neurons
(Liquid states), selected using particle swarm optimization. Our approach
differs from existing works by learning directly from ECG signals (allowing
personalization), without requiring costly data annotations. Additionally, our
approach can be easily implemented on state-of-the-art spiking-based
neuromorphic systems, offering high accuracy, yet significantly low energy
footprint, leading to an extended battery life of wearable devices. We
validated our approach with CARLsim, a GPU accelerated spiking neural network
simulator modeling Izhikevich spiking neurons with Spike Timing Dependent
Plasticity (STDP) and homeostatic scaling. A range of subjects are considered
from in-house clinical trials and public ECG databases. Results show high
accuracy and low energy footprint in heart-rate estimation across subjects with
and without cardiac irregularities, signifying the strong potential of this
approach to be integrated in future wearable devices.
</dc:description>
 <dc:description>Comment: 51 pages, 12 figures, 6 tables, 95 references. Under submission at
  Elsevier Neural Networks</dc:description>
 <dc:date>2017-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05357</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Use of Limited-Memory Accelerators for Linear Learning on
  Heterogeneous Systems</dc:title>
 <dc:creator>D&#xfc;nner, Celestine</dc:creator>
 <dc:creator>Parnell, Thomas</dc:creator>
 <dc:creator>Jaggi, Martin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>90C25, 68W15, 68W10</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>C.1.4</dc:subject>
 <dc:description>  We propose a generic algorithmic building block to accelerate training of
machine learning models on heterogeneous compute systems. Our scheme allows to
efficiently employ compute accelerators such as GPUs and FPGAs for the training
of large-scale machine learning models, when the training data exceeds their
memory capacity. Also, it provides adaptivity to any system's memory hierarchy
in terms of size and processing speed. Our technique is built upon novel
theoretical insights regarding primal-dual coordinate methods, and uses duality
gap information to dynamically decide which part of the data should be made
available for fast processing. To illustrate the power of our approach we
demonstrate its performance for training of generalized linear models on a
large-scale dataset exceeding the memory size of a modern GPU, showing an
order-of-magnitude speedup over existing approaches.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05368</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structures of Knowledge from Wikipedia Networks</dc:title>
 <dc:creator>Gabella, Maxime</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Knowledge is useless without structure. While the classification of knowledge
has been an enduring philosophical enterprise, it recently found applications
in computer science, notably for artificial intelligence. The availability of
large databases allowed for complex ontologies to be built automatically, for
example by extracting structured content from Wikipedia. However, this approach
is subject to manual categorization decisions made by online editors. Here we
show that an implicit classification system emerges spontaneously on Wikipedia.
We study the network of first links between articles, and find that it centers
on a core cycle involving concepts of fundamental classifying importance. We
argue that this structure is rooted in cultural history. For European
languages, articles like Philosophy and Science are central, whereas Human and
Earth dominate for East Asian languages. This reflects the differences between
ancient Greek thought and Chinese tradition. Our results reveal the powerful
influence of culture on the intrinsic architecture of complex data sets.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures, 6 tables</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05374</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Medical Cyber-Physical Systems Development: A Forensics-Driven Approach</dc:title>
 <dc:creator>Grispos, George</dc:creator>
 <dc:creator>Glisson, William Bradley</dc:creator>
 <dc:creator>Choo, Kim-Kwang Raymond</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The synthesis of technology and the medical industry has partly contributed
to the increasing interest in Medical Cyber-Physical Systems (MCPS). While
these systems provide benefits to patients and professionals, they also
introduce new attack vectors for malicious actors (e.g. financially-and/or
criminally-motivated actors). A successful breach involving a MCPS can impact
patient data and system availability. The complexity and operating requirements
of a MCPS complicates digital investigations. Coupling this information with
the potentially vast amounts of information that a MCPS produces and/or has
access to is generating discussions on, not only, how to compromise these
systems but, more importantly, how to investigate these systems. The paper
proposes the integration of forensics principles and concepts into the design
and development of a MCPS to strengthen an organization's investigative
posture. The framework sets the foundation for future research in the
refinement of specific solutions for MCPS investigations.
</dc:description>
 <dc:description>Comment: This is the pre-print version of a paper presented at the 2nd
  International Workshop on Security, Privacy, and Trustworthiness in Medical
  Cyber-Physical Systems (MedSPT 2017)</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05374</dc:identifier>
 <dc:identifier>doi:10.1109/CHASE.2017.48</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05375</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a Multi-View Stereo Machine</dc:title>
 <dc:creator>Kar, Abhishek</dc:creator>
 <dc:creator>H&#xe4;ne, Christian</dc:creator>
 <dc:creator>Malik, Jitendra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a learnt system for multi-view stereopsis. In contrast to recent
learning based methods for 3D reconstruction, we leverage the underlying 3D
geometry of the problem through feature projection and unprojection along
viewing rays. By formulating these operations in a differentiable manner, we
are able to learn the system end-to-end for the task of metric 3D
reconstruction. End-to-end learning allows us to jointly reason about shape
priors while conforming geometric constraints, enabling reconstruction from
much fewer images (even a single image) than required by classical approaches
as well as completion of unseen surfaces. We thoroughly evaluate our approach
on the ShapeNet dataset and demonstrate the benefits over classical approaches
as well as recent learning based methods.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05376</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Restricted Boltzmann machine to determine the input weights for extreme
  learning machines</dc:title>
 <dc:creator>Pacheco, Andre</dc:creator>
 <dc:creator>Krohling, Renato</dc:creator>
 <dc:creator>da Silva, Carlos</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The Extreme Learning Machine (ELM) is a single-hidden layer feedforward
neural network (SLFN) learning algorithm that can learn effectively and
quickly. The ELM training phase assigns the input weights and bias randomly and
does not change them in the whole process. Although the network works well, the
random weights in the input layer can make the algorithm less effective and
impact on its performance. Therefore, we propose a new approach to determine
the input weights and bias for the ELM using the restricted Boltzmann machine
(RBM), which we call RBM-ELM. We compare our new approach with a well-known
approach to improve the ELM and a state of the art algorithm to select the
weights for the ELM. The results show that the RBM-ELM outperforms both
methodologies and achieve a better performance than the ELM.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures and 5 tables</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05377</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complete algorithms for algebraic strongest postconditions and weakest
  preconditions in polynomial ode's</dc:title>
 <dc:creator>Boreale, Michele</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  A system of polynomial ordinary differential equations (ode's) is specified
via a vector of multivariate polynomials, or vector field, F. A safety
assertion psi-&gt;[F]phi means that the system's trajectory will lie in a subset
phi (the postcondition) of the state-space, whenever the initial state belongs
to a subset psi (the precondition). We consider the case when phi and psi are
algebraic varieties, that is, zero sets of polynomials. In particular,
polynomials specifying the postcondition can be seen as conservation laws
implied by psi. Checking the validity of algebraic safety assertions is a
fundamental problem in, for instance, hybrid systems. We consider generalized
versions of this problem, and offer algorithms to: (1) given a user specified
polynomial set P and a precondition psi, find the smallest algebraic
postcondition phi including the variety determined by the valid conservation
laws in P (relativized strongest postcondition); (2) given a user specified
postcondition phi, find the largest algebraic precondition psi (weakest
precondition). The first algorithm can also be used to find the weakest
algebraic invariant of the system implying all conservation laws in P valid
under psi. The effectiveness of these algorithms is demonstrated on a few case
studies from the literature.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05401</identifier>
 <datestamp>2017-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deformable Modeling for Human Body Acquired from Depth Sensors</dc:title>
 <dc:creator>Vegeshna, Vamshhi Pavan Kumar Varma</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a novel approach to reconstruct complete 3D deformable
models over time by a single depth camera. These are the steps employed for
deforming objects from single depth camera. The partial surfaces reconstructed
from various times of capture are assembled together to form a complete 3D
surface. A mesh warping algorithm is used to align different partial surfaces
based on linear mesh deformation. A volumetric method is then applied to
combine partial surfaces, fix missing holes and smooth alignment errors.
</dc:description>
 <dc:description>Comment: arXiv admin note: submission has been withdrawn by arXiv
  administrators due to inappropriate text reuse from external sources</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05402</identifier>
 <datestamp>2017-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secrecy Energy Efficiency of MIMOME Wiretap Channels with Full-Duplex
  Jamming</dc:title>
 <dc:creator>Taghizadeh, Omid</dc:creator>
 <dc:creator>Neuhaus, Peter</dc:creator>
 <dc:creator>Mathar, Rudolf</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work we study the secrecy energy efficiency (SEE) of a
multiple-input-multiple-output multiple-antenna eavesdropper (MIMOME) wiretap
channel, in terms of the securely communicated bits-per-Joule, where the
legitimate receiver is enabled with full-duplex (FD) capability. Hence, the
transmitter and the legitimate receiver are capable of transmitting artificial
noise (AN) to the eavesdropper, while exchanging information. In particular, we
seek answer to the question: if and how the application of an FD jammer can
enhance the system SEE, considering the additional power consumption used for
jamming and self-interference cancellation, as well as the degrading effect of
residual self-interference. In this regard, an SEE maximization problem is
formulated assuming the availability of the exact, or statistical channel state
information (CSI). Due to the intractable problem structure, an iterative
solution is provided in each case with a guaranteed convergence to a local
optimum. Numerical simulations indicate a marginal SEE gain, via the
utilization of FD jamming, for a wide range of system conditions. However, a
significant gain is observed for the scenarios with a small distance between
the FD node and the eavesdropper, a high signal-to-noise (SNR) condition or for
a bidirectional FD communication setup, under the condition that the
self-interference can be effectively and efficiently mitigated.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05405</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massive BLAST: An Architecture for Realizing Ultra-High Data Rates for
  Large-Scale MIMO</dc:title>
 <dc:creator>Shental, Ori</dc:creator>
 <dc:creator>Venkatesan, Sivarama</dc:creator>
 <dc:creator>Ashikhmin, Alexei</dc:creator>
 <dc:creator>Valenzuela, Reinaldo A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A detection scheme for uplink massive MIMO, dubbed massive-BLAST or M-BLAST,
is proposed. The derived algorithm is an enhancement of the well-known soft
parallel interference cancellation. Using computer simulations in massive MIMO
application scenarios, M-BLAST is shown to yield a substantially better error
performance with reduced complexity, compared to the benchmark alternative of a
one-shot linear detector, as well as the original sequential V-BLAST. Hence,
M-BLAST may serve as a computationally efficient means to exploit the large
number of antennas in massive MIMO.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Wireless Communications Letters</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05410</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wearable Communications in 5G: Challenges and Enabling Technologies</dc:title>
 <dc:creator>Sun, Haijian</dc:creator>
 <dc:creator>Zhang, Zekun</dc:creator>
 <dc:creator>Hu, Rose Qingyang</dc:creator>
 <dc:creator>Qian, Yi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  As wearable devices become more ingrained in our daily lives, traditional
communication networks primarily designed for human being-oriented applications
are facing tremendous challenges. The upcoming 5G wireless system aims to
support unprecedented high capacity, low latency, and massive connectivity. In
this article, we evaluate key challenges in wearable communications. A
cloud/edge communication architecture that integrates the cloud radio access
network, software defined network, device to device communications, and
cloud/edge technologies is presented. Computation offloading enabled by this
multi-layer communications architecture can offload computation-excessive and
latency-stringent applications to nearby devices through device to device
communications or to nearby edge nodes through cellular or other wireless
technologies. Critical issues faced by wearable communications such as short
battery life, limited computing capability, and stringent latency can be
greatly alleviated by this cloud/edge architecture. Together with the presented
architecture, current transmission and networking technologies, including
non-orthogonal multiple access, mobile edge computing, and energy harvesting,
can greatly enhance the performance of wearable communication in terms of
spectral efficiency, energy efficiency, latency, and connectivity.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication,
  this is a revision</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05417</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Serverless Protocols for Inventory and Tracking with a UAV</dc:title>
 <dc:creator>Mtita, Collins</dc:creator>
 <dc:creator>Laurent, Maryline</dc:creator>
 <dc:creator>Sauveron, Damien</dc:creator>
 <dc:creator>Akram, Raja Naeem</dc:creator>
 <dc:creator>Markantonakis, Konstantinos</dc:creator>
 <dc:creator>Chaumette, Serge</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  It is widely acknowledged that the proliferation of Unmanned Aerial Vehicles
(UAVs) may lead to serious concerns regarding avionics safety, particularly
when end-users are not adhering to air safety regulations. There are, however,
domains in which UAVs may help to increase the safety of airplanes and the
management of flights and airport resources that often require substantial
human resources. For instance, Paris Charles de Gaulle airport (CDG) has more
than 7,000 staff and supports 30,000 direct jobs for more than 60 million
passengers per year (as of 2016). Indeed, these new systems can be used
beneficially for several purposes, even in sensitive areas like airports. Among
the considered applications are those that suggest using UAVs to enhance safety
of on-ground airplanes; for instance, by collecting (once the aircraft has
landed) data recorded by different systems during the flight (like the sensors
of the Aircraft Data Networks - ADN) or by examining the state of airplane
structure. In this paper, our proposal is to use UAVs, under the control of the
airport authorities, to inventory and track various tagged assets, such as
luggage, supplies required for the flights, and maintenance tools. The aim of
our proposal is to make airport management systems more efficient for
operations requiring inventory and tracking, along with increasing safety
(sensitive assets such as refueling tanks, or sensitive pieces of luggage can
be tracked), thus raising financial profit.
</dc:description>
 <dc:description>Comment: 11 pages, Conference, The 36th IEEE/AIAA Digital Avionics Systems
  Conference (DASC'17)</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05424</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nowhere Dense Graph Classes and Dimension</dc:title>
 <dc:creator>Joret, Gwena&#xeb;l</dc:creator>
 <dc:creator>Micek, Piotr</dc:creator>
 <dc:creator>de Mendez, Patrice Ossona</dc:creator>
 <dc:creator>Wiechert, Veit</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Nowhere dense graph classes provide one of the least restrictive notions of
sparsity for graphs. Several equivalent characterizations of nowhere dense
classes have been obtained over the years, using a wide range of combinatorial
objects. In this paper we establish a new characterization of nowhere dense
classes, in terms of poset dimension: A monotone graph class is nowhere dense
if and only if for every $h \geq 1$ and every $\epsilon &gt; 0$, posets of height
at most $h$ with $n$ elements and whose cover graphs are in the class have
dimension $\mathcal{O}(n^{\epsilon})$.
</dc:description>
 <dc:description>Comment: v2: Minor changes</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05425</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Heuristic Approach to Protocol Tuning for High Performance Data
  Transfers</dc:title>
 <dc:creator>Arslan, Engin</dc:creator>
 <dc:creator>Kosar, Tevfik</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Obtaining optimal data transfer performance is of utmost importance to
today's data-intensive distributed applications and wide-area data replication
services. Doing so necessitates effectively utilizing available network
bandwidth and resources, yet in practice transfers seldom reach the levels of
utilization they potentially could. Tuning protocol parameters such as
pipelining, parallelism, and concurrency can significantly increase utilization
and performance, however determining the best settings for these parameters is
a difficult problem, as network conditions can vary greatly between sites and
over time. Nevertheless, it is an important problem, since poor tuning can
cause either under- or over-utilization of network resources and thus degrade
transfer performance. In this paper, we present three algorithms for
application-level tuning of different protocol parameters for maximizing
transfer throughput in wide-area networks. Our algorithms dynamically tune the
number of parallel data streams per file (for large file optimization), the
level of control channel pipelining (for small file optimization), and the
number of concurrent file transfers to increase I/O throughput (a technique
useful for all types of files). The proposed heuristic algorithms improve the
transfer throughput up to 10x compared to the baseline and 7x compared to the
state of the art solutions.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05435</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faculty citation measures are highly correlated with peer assessment of
  computer science doctoral programs</dc:title>
 <dc:creator>Vucetic, Slobodan</dc:creator>
 <dc:creator>Chanda, Ashis Kumar</dc:creator>
 <dc:creator>Zhang, Shanshan</dc:creator>
 <dc:creator>Bai, Tian</dc:creator>
 <dc:creator>Maiti, Aniruddha</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  We study relationship between peer assessment of quality of U.S. Computer
Science (CS) doctoral programs and objective measures of research strength of
those programs. In Fall 2016 we collected Google Scholar citation data for
4,352 tenure-track CS faculty from 173 U.S. universities. The citations are
measured by the t10 index, which represents the number of citations received by
the 10th highest cited paper of a faculty. To measure the research strength of
a CS doctoral program we use 2 groups of citation measures. The first group of
measures averages t10 of faculty in a program. Pearson correlation of those
measures with the peer assessment of U.S. CS doctoral programs published by the
U.S. News in 2014 is as high as 0.890. The second group of measures counts the
number of well cited faculty in a program. Pearson correlation of those
measures with the peer assessment is as high as 0.909. By combining those two
groups of measures using linear regression, we create the Scholar score whose
Pearson correlation with the peer assessment is 0.933 and which explains 87.2%
of the variance in the peer assessment. Our evaluation shows that the highest
62 ranked CS doctoral programs by the U.S. News peer assessment are much higher
correlated with the Scholar score than the next 57 ranked programs, indicating
the deficiencies of peer assessment of less-known CS programs. Our results also
indicate that university reputation might have a sizeable impact on peer
assessment of CS doctoral programs. To promote transparency, the raw data and
the codes used in this study are made available to research community at
http://www.dabi.temple.edu/~vucetic/CSranking/.
</dc:description>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.05435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="131000" completeListSize="155308">2369777|132001</resumptionToken>
</ListRecords>
</OAI-PMH>
