<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:44:34Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|147001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9803001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automating Coreference: The Role of Annotated Training Data</dc:title>
 <dc:creator>Hirschman, Lynette</dc:creator>
 <dc:creator>Robinson, Patricia</dc:creator>
 <dc:creator>Burger, John</dc:creator>
 <dc:creator>Vilain, Marc</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We report here on a study of interannotator agreement in the coreference task
as defined by the Message Understanding Conference (MUC-6 and MUC-7). Based on
feedback from annotators, we clarified and simplified the annotation
specification. We then performed an analysis of disagreement among several
annotators, concluding that only 16% of the disagreements represented genuine
disagreement about coreference; the remainder of the cases were mostly
typographical errors or omissions, easily reconciled. Initially, we measured
interannotator agreement in the low 80s for precision and recall. To try to
improve upon this, we ran several experiments. In our final experiment, we
separated the tagging of candidate noun phrases from the linking of actual
coreferring expressions. This method shows promise - interannotator agreement
climbed to the low 90s - but it needs more extensive validation. These results
position the research community to broaden the coreference task to multiple
languages, and possibly to different kinds of coreference.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures. To appear in the AAAI Spring Symposium on
  Applying Machine Learning to Discourse Processing. The Alembic Workbench
  annotation tool described in this paper is available at
  http://www.mitre.org/resources/centers/advanced_info/g04h/workbench.html</dc:description>
 <dc:date>1998-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9803001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9803002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time, Tense and Aspect in Natural Language Database Interfaces</dc:title>
 <dc:creator>Androutsopoulos, I.</dc:creator>
 <dc:creator>Ritchie, G. D.</dc:creator>
 <dc:creator>Thanisch, P.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Most existing natural language database interfaces (NLDBs) were designed to
be used with database systems that provide very limited facilities for
manipulating time-dependent data, and they do not support adequately temporal
linguistic mechanisms (verb tenses, temporal adverbials, temporal subordinate
clauses, etc.). The database community is becoming increasingly interested in
temporal database systems, that are intended to store and manipulate in a
principled manner information not only about the present, but also about the
past and future. When interfacing to temporal databases, supporting temporal
linguistic mechanisms becomes crucial.
  We present a framework for constructing natural language interfaces for
temporal databases (NLTDBs), that draws on research in tense and aspect
theories, temporal logics, and temporal databases. The framework consists of a
temporal intermediate representation language, called TOP, an HPSG grammar that
maps a wide range of questions involving temporal mechanisms to appropriate TOP
expressions, and a provably correct method for translating from TOP to TSQL2,
TSQL2 being a recently proposed temporal extension of the SQL database
language. This framework was employed to implement a prototype NLTDB using ALE
and Prolog.
</dc:description>
 <dc:description>Comment: 50 pages. LaTeX2e. Uses: amstex, a4, a4wide, xspace, avm, examples.
  EPS figures included. To appear in the Journal of Natural Language
  Engineering</dc:description>
 <dc:date>1998-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9803002</dc:identifier>
 <dc:identifier>Natural Language Engineering, 4(3), pp. 229-276, Sept. 1998,
  Cambridge Univ. Press.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9803003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nymble: a High-Performance Learning Name-finder</dc:title>
 <dc:creator>Bikel, Daniel M.</dc:creator>
 <dc:creator>Miller, Scott</dc:creator>
 <dc:creator>Schwartz, Richard</dc:creator>
 <dc:creator>Weischedel, Ralph</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents a statistical, learned approach to finding names and
other non-recursive entities in text (as per the MUC-6 definition of the NE
task), using a variant of the standard hidden Markov model. We present our
justification for the problem and our approach, a detailed discussion of the
model itself and finally the successful results of this new approach.
</dc:description>
 <dc:description>Comment: Postscript only, 8 pages</dc:description>
 <dc:date>1998-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9803003</dc:identifier>
 <dc:identifier>Proceedings of the Fifth Conference on Applied Natural Language
  Processing, 1997, pp. 194-201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9804001</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Interpolation Grammars: a Rule-based Approach to the Incremental
  Parsing of Natural Languages</dc:title>
 <dc:creator>Larcheveque, John</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Graph Interpolation Grammars are a declarative formalism with an operational
semantics. Their goal is to emulate salient features of the human parser, and
notably incrementality. The parsing process defined by GIGs incrementally
builds a syntactic representation of a sentence as each successive lexeme is
read. A GIG rule specifies a set of parse configurations that trigger its
application and an operation to perform on a matching configuration. Rules are
partly context-sensitive; furthermore, they are reversible, meaning that their
operations can be undone, which allows the parsing process to be
nondeterministic. These two factors confer enough expressive power to the
formalism for parsing natural languages.
</dc:description>
 <dc:description>Comment: 41 pages, Postscript only</dc:description>
 <dc:date>1998-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9804001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9804002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Proper Treatment of Optimality in Computational Phonology</dc:title>
 <dc:creator>Karttunen, Lauri</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents a novel formalization of optimality theory. Unlike
previous treatments of optimality in computational linguistics, starting with
Ellison (1994), the new approach does not require any explicit marking and
counting of constraint violations. It is based on the notion of &quot;lenient
composition,&quot; defined as the combination of ordinary composition and priority
union. If an underlying form has outputs that can meet a given constraint,
lenient composition enforces the constraint; if none of the output candidates
meet the constraint, lenient composition allows all of them. For the sake of
greater efficiency, we may &quot;leniently compose&quot; the GEN relation and all the
constraints into a single finite-state transducer that maps each underlying
form directly into its optimal surface realizations, and vice versa, without
ever producing any failing candidates. Seen from this perspective, optimality
theory is surprisingly similar to the two older strains of finite-state
phonology: classical rewrite systems and two-level models. In particular, the
ranking of optimality constraints corresponds to the ordering of rewrite rules.
</dc:description>
 <dc:description>Comment: 12 pages. Postscript</dc:description>
 <dc:date>1998-04-26</dc:date>
 <dc:date>1998-05-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9804002</dc:identifier>
 <dc:identifier>Proceedings of FSMNLP'98. International Workshop on Finite-State
  Methods in Natural Language Processing, pages 1-12, June 29 - July 1, 1998.
  Bilkent University. Ankara, Turkey</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9804003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Treatment of Epsilon-Moves in Subset Construction</dc:title>
 <dc:creator>van Noord, Gertjan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The paper discusses the problem of determinising finite-state automata
containing large numbers of epsilon-moves. Experiments with finite-state
approximations of natural language grammars often give rise to very large
automata with a very large number of epsilon-moves. The paper identifies three
subset construction algorithms which treat epsilon-moves. A number of
experiments has been performed which indicate that the algorithms differ
considerably in practice. Furthermore, the experiments suggest that the average
number of epsilon-moves per state can be used to predict which algorithm is
likely to perform best for a given input automaton.
</dc:description>
 <dc:date>1998-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9804003</dc:identifier>
 <dc:identifier>Proceedings of FSMNLP'98. International Workshop on Finite-State
  Methods in Natural Language Processing, pages 1-12, June 29 - July 1, 1998.
  Bilkent University. Ankara, Turkey.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9804004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Corpus-Based Word Sense Disambiguation</dc:title>
 <dc:creator>Fujii, Atsushi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Resolution of lexical ambiguity, commonly termed ``word sense
disambiguation'', is expected to improve the analytical accuracy for tasks
which are sensitive to lexical semantics. Such tasks include machine
translation, information retrieval, parsing, natural language understanding and
lexicography. Reflecting the growth in utilization of machine readable texts,
word sense disambiguation techniques have been explored variously in the
context of corpus-based approaches. Within one corpus-based framework, that is
the similarity-based method, systems use a database, in which example sentences
are manually annotated with correct word senses. Given an input, systems search
the database for the most similar example to the input. The lexical ambiguity
of a word contained in the input is resolved by selecting the sense annotation
of the retrieved example. In this research, we apply this method of resolution
of verbal polysemy, in which the similarity between two examples is computed as
the weighted average of the similarity between complements governed by a target
polysemous verb. We explore similarity-based verb sense disambiguation focusing
on the following three methods. First, we propose a weighting schema for each
verb complement in the similarity computation. Second, in similarity-based
techniques, the overhead for manual supervision and searching the large-sized
database can be prohibitive. To resolve this problem, we propose a method to
select a small number of effective examples, for system usage. Finally, the
efficiency of our system is highly dependent on the similarity computation
used. To maximize efficiency, we propose a method which integrates the
advantages of previous methods for similarity computation.
</dc:description>
 <dc:description>Comment: PhD Thesis, 108 pages</dc:description>
 <dc:date>1998-04-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9804004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9804005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the existence of certain total recursive functions in nontrivial
  axiom systems, I</dc:title>
 <dc:creator>da Costa, N. C. A.</dc:creator>
 <dc:creator>Doria, F. A.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We investigate the existence of a class of ZFC-provably total recursive unary
functions, given certain constraints, and apply some of those results to show
that, for $\Sigma_1$-sound set theory, ZFC$\not\vdash P&lt;NP$.
</dc:description>
 <dc:description>Comment: LaTeX, 16 pages, no figures. This paper was submitted to a major
  journal in the field and rejected. The referee somehow misundesrtood
  Corollary 3.8 and wrongly concluded that the proof had either a gap or an
  error. Can you find whether that error exists?</dc:description>
 <dc:date>1998-04-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9804005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9805001</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Valence Induction with a Head-Lexicalized PCFG</dc:title>
 <dc:creator>Carroll, Glenn</dc:creator>
 <dc:creator>Rooth, Mats</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents an experiment in learning valences (subcategorization
frames) from a 50 million word text corpus, based on a lexicalized
probabilistic context free grammar. Distributions are estimated using a
modified EM algorithm. We evaluate the acquired lexicon both by comparison with
a dictionary and by entropy measures. Results show that our model produces
highly accurate frame distributions.
</dc:description>
 <dc:description>Comment: 10 pages, 5 postscript figures</dc:description>
 <dc:date>1998-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9805001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9805002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group Theory and Grammatical Description</dc:title>
 <dc:creator>Dymetman, Marc</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents a model for linguistic description based on group theory.
A grammar in this model, or &quot;G-grammar&quot;, is a collection of lexical expressions
which are products of logical forms, phonological forms, and their inverses.
Phrasal descriptions are obtained by forming products of lexical expressions
and by cancelling contiguous elements which are inverses of each other. We show
applications of this model to parsing and generation, long-distance movement,
and quantifier scoping. We believe that by moving from the free monoid over a
vocabulary V --- standard in formal language studies --- to the free group over
V, deep affinities between linguistic phenomena and classical algebra come to
the surface, and that the consequences of tapping the mathematical connections
thus established could be considerable.
</dc:description>
 <dc:description>Comment: 17 pages (Latex, Postscript). A shorter version of this paper will
  appear in the Coling/ACL 98 Proceedings. See
  http://www.xrce.xerox.com/people/dymetman/dymetman.html</dc:description>
 <dc:date>1998-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9805002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9805003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Models of Co-occurrence</dc:title>
 <dc:creator>Melamed, I. Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A model of co-occurrence in bitext is a boolean predicate that indicates
whether a given pair of word tokens co-occur in corresponding regions of the
bitext space. Co-occurrence is a precondition for the possibility that two
tokens might be mutual translations. Models of co-occurrence are the glue that
binds methods for mapping bitext correspondence with methods for estimating
translation models into an integrated system for exploiting parallel texts.
Different models of co-occurrence are possible, depending on the kind of bitext
map that is available, the language-specific information that is available, and
the assumptions made about the nature of translational equivalence. Although
most statistical translation models are based on models of co-occurrence,
modeling co-occurrence correctly is more difficult than it may at first appear.
</dc:description>
 <dc:date>1998-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9805003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9805004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Annotation Style Guide for the Blinker Project</dc:title>
 <dc:creator>Melamed, I. Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This annotation style guide was created by and for the Blinker project at the
University of Pennsylvania. The Blinker project was so named after the
``bilingual linker'' GUI, which was created to enable bilingual annotators to
``link'' word tokens that are mutual translations in parallel texts. The
parallel text chosen for this project was the Bible, because it is probably the
easiest text to obtain in electronic form in multiple languages. The languages
involved were English and French, because, of the languages with which the
project co-ordinator was familiar, these were the two for which a sufficient
number of annotators was likely to be found.
</dc:description>
 <dc:date>1998-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9805004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9805005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Manual Annotation of Translational Equivalence: The Blinker Project</dc:title>
 <dc:creator>Melamed, I. Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Bilingual annotators were paid to link roughly sixteen thousand corresponding
words between on-line versions of the Bible in modern French and modern
English. These annotations are freely available to the research community from
http://www.cis.upenn.edu/~melamed . The annotations can be used for several
purposes. First, they can be used as a standard data set for developing and
testing translation lexicons and statistical translation models. Second,
researchers in lexical semantics will be able to mine the annotations for
insights about cross-linguistic lexicalization patterns. Third, the annotations
can be used in research into certain recently proposed methods for monolingual
word-sense disambiguation. This paper describes the annotated texts, the
specially-designed annotation tool, and the strategies employed to increase the
consistency of the annotations. The annotation process was repeated five times
by different annotators. Inter-annotator agreement rates indicate that the
annotations are reasonably reliable and that the method is easy to replicate.
</dc:description>
 <dc:date>1998-05-08</dc:date>
 <dc:date>1998-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9805005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9805006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Word-to-Word Models of Translational Equivalence</dc:title>
 <dc:creator>Melamed, I. Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Parallel texts (bitexts) have properties that distinguish them from other
kinds of parallel data. First, most words translate to only one other word.
Second, bitext correspondence is noisy. This article presents methods for
biasing statistical translation models to reflect these properties. Analysis of
the expected behavior of these biases in the presence of sparse data predicts
that they will result in more accurate models. The prediction is confirmed by
evaluation with respect to a gold standard -- translation models that are
biased in this fashion are significantly more accurate than a baseline
knowledge-poor model. This article also shows how a statistical translation
model can take advantage of various kinds of pre-existing knowledge that might
be available about particular language pairs. Even the simplest kinds of
language-specific knowledge, such as the distinction between content words and
function words, is shown to reliably boost translation model performance on
some tasks. Statistical models that are informed by pre-existing knowledge
about the model domain combine the best of both the rationalist and empiricist
traditions.
</dc:description>
 <dc:date>1998-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9805006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9805007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parsing Inside-Out</dc:title>
 <dc:creator>Goodman, Joshua</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The inside-outside probabilities are typically used for reestimating
Probabilistic Context Free Grammars (PCFGs), just as the forward-backward
probabilities are typically used for reestimating HMMs. I show several novel
uses, including improving parser accuracy by matching parsing algorithms to
evaluation criteria; speeding up DOP parsing by 500 times; and 30 times faster
PCFG thresholding at a given accuracy level. I also give an elegant,
state-of-the-art grammar formalism, which can be used to compute inside-outside
probabilities; and a parser description formalism, which makes it easy to
derive inside-outside formulas and many others.
</dc:description>
 <dc:description>Comment: Ph.D. Thesis, 257 pages, 40 postscript figures</dc:description>
 <dc:date>1998-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9805007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9805008</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Descriptive Characterization of Tree-Adjoining Languages (Full
  Version)</dc:title>
 <dc:creator>Rogers, James</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Since the early Sixties and Seventies it has been known that the regular and
context-free languages are characterized by definability in the monadic
second-order theory of certain structures. More recently, these descriptive
characterizations have been used to obtain complexity results for constraint-
and principle-based theories of syntax and to provide a uniform model-theoretic
framework for exploring the relationship between theories expressed in
disparate formal terms. These results have been limited, to an extent, by the
lack of descriptive characterizations of language classes beyond the
context-free. Recently, we have shown that tree-adjoining languages (in a
mildly generalized form) can be characterized by recognition by automata
operating on three-dimensional tree manifolds, a three-dimensional analog of
trees. In this paper, we exploit these automata-theoretic results to obtain a
characterization of the tree-adjoining languages by definability in the monadic
second-order theory of these three-dimensional tree manifolds. This not only
opens the way to extending the tools of model-theoretic syntax to the level of
TALs, but provides a highly flexible mechanism for defining TAGs in terms of
logical constraints.
  This is the full version of a paper to appear in the proceedings of
COLING-ACL'98 as a project note.
</dc:description>
 <dc:description>Comment: 7 pages, uses colacl.sty</dc:description>
 <dc:date>1998-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9805008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9805009</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovery of Linguistic Relations Using Lexical Attraction</dc:title>
 <dc:creator>Yuret, Deniz</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This work has been motivated by two long term goals: to understand how humans
learn language and to build programs that can understand language. Using a
representation that makes the relevant features explicit is a prerequisite for
successful learning and understanding. Therefore, I chose to represent
relations between individual words explicitly in my model. Lexical attraction
is defined as the likelihood of such relations. I introduce a new class of
probabilistic language models named lexical attraction models which can
represent long distance relations between words and I formalize this new class
of models using information theory.
  Within the framework of lexical attraction, I developed an unsupervised
language acquisition program that learns to identify linguistic relations in a
given sentence. The only explicitly represented linguistic knowledge in the
program is lexical attraction. There is no initial grammar or lexicon built in
and the only input is raw text. Learning and processing are interdigitated. The
processor uses the regularities detected by the learner to impose structure on
the input. This structure enables the learner to detect higher level
regularities. Using this bootstrapping procedure, the program was trained on
100 million words of Associated Press material and was able to achieve 60%
precision and 50% recall in finding relations between content-words. Using
knowledge of lexical attraction, the program can identify the correct relations
in syntactically ambiguous sentences such as ``I saw the Statue of Liberty
flying over New York.''
</dc:description>
 <dc:description>Comment: dissertation, 56 pages</dc:description>
 <dc:date>1998-05-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9805009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9805010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating Text Plans for Conciseness and Coherence</dc:title>
 <dc:creator>Harvey, Terrence</dc:creator>
 <dc:creator>Carberry, Sandra</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Our experience with a critiquing system shows that when the system detects
problems with the user's performance, multiple critiques are often produced.
Analysis of a corpus of actual critiques revealed that even though each
individual critique is concise and coherent, the set of critiques as a whole
may exhibit several problems that detract from conciseness and coherence, and
consequently assimilation. Thus a text planner was needed that could integrate
the text plans for individual communicative goals to produce an overall text
plan representing a concise, coherent message.
  This paper presents our general rule-based system for accomplishing this
task. The system takes as input a \emph{set} of individual text plans
represented as RST-style trees, and produces a smaller set of more complex
trees representing integrated messages that still achieve the multiple
communicative goals of the individual text plans. Domain-independent rules are
used to capture strategies across domains, while the facility for addition of
domain-dependent rules enables the system to be tuned to the requirements of a
particular domain. The system has been tested on a corpus of critiques in the
domain of trauma care.
</dc:description>
 <dc:description>Comment: 7 pages, 7 Postscript figures, uses colacl.sty</dc:description>
 <dc:date>1998-05-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9805010</dc:identifier>
 <dc:identifier>Proceedings of the 17th International Conference on Computational
  Linguistics (COLING-ACL '98)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9805011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic summarising: factors and directions</dc:title>
 <dc:creator>Jones, Karen Sparck</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This position paper suggests that progress with automatic summarising demands
a better research methodology and a carefully focussed research strategy. In
order to develop effective procedures it is necessary to identify and respond
to the context factors, i.e. input, purpose, and output factors, that bear on
summarising and its evaluation. The paper analyses and illustrates these
factors and their implications for evaluation. It then argues that this
analysis, together with the state of the art and the intrinsic difficulty of
summarising, imply a nearer-term strategy concentrating on shallow, but not
surface, text analysis and on indicative summarising. This is illustrated with
current work, from which a potentially productive research programme can be
developed.
</dc:description>
 <dc:date>1998-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9805011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9805012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recognizing Syntactic Errors in the Writing of Second Language Learners</dc:title>
 <dc:creator>Schneider, David A.</dc:creator>
 <dc:creator>McCoy, Kathleen F.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper reports on the recognition component of an intelligent tutoring
system that is designed to help foreign language speakers learn standard
English. The system models the grammar of the learner, with this instantiation
of the system tailored to signers of American Sign Language (ASL). We discuss
the theoretical motivations for the system, various difficulties that have been
encountered in the implementation, as well as the methods we have used to
overcome these problems. Our method of capturing ungrammaticalities involves
using mal-rules (also called 'error productions'). However, the straightforward
addition of some mal-rules causes significant performance problems with the
parser. For instance, the ASL population has a strong tendency to drop pronouns
and the auxiliary verb `to be'. Being able to account for these as sentences
results in an explosion in the number of possible parses for each sentence.
This explosion, left unchecked, greatly hampers the performance of the system.
We discuss how this is handled by taking into account expectations from the
specific population (some of which are captured in our unique user model). The
different representations of lexical items at various points in the acquisition
process are modeled by using mal-rules, which obviates the need for multiple
lexicons. The grammar is evaluated on its ability to correctly diagnose
agreement problems in actual sentences produced by ASL native speakers.
</dc:description>
 <dc:description>Comment: 7 pages, uses colacl.sty</dc:description>
 <dc:date>1998-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9805012</dc:identifier>
 <dc:identifier>Proceedings of the 17th International Conference on Computational
  Linguistics (COLING-ACL '98)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Correlations between Linguistic Indicators and Semantic
  Constraints: Reuse of Context-Dependent Descriptions of Entities</dc:title>
 <dc:creator>Radev, Dragomir R.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents the results of a study on the semantic constraints
imposed on lexical choice by certain contextual indicators. We show how such
indicators are computed and how correlations between them and the choice of a
noun phrase description of a named entity can be automatically established
using supervised learning. Based on this correlation, we have developed a
technique for automatic lexical choice of descriptions of entities in text
generation. We discuss the underlying relationship between the pragmatics of
choosing an appropriate description that serves a specific purpose in the
automatically generated text and the semantics of the description itself. We
present our work in the framework of the more general concept of reuse of
linguistic structures that are automatically extracted from large corpora. We
present a formal evaluation of our approach and we conclude with some thoughts
on potential applications of our method.
</dc:description>
 <dc:description>Comment: 7 pages, uses colacl.sty and acl.bst, uses epsfig. To appear in the
  Proceedings of the Joint 17th International Conference on Computational
  Linguistics 36th Annual Meeting of the Association for Computational
  Linguistics (COLING-ACL'98)</dc:description>
 <dc:date>1998-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Dialogue Acts from Features with Transformation-Based Learning</dc:title>
 <dc:creator>Samuel, Ken</dc:creator>
 <dc:creator>Carberry, Sandra</dc:creator>
 <dc:creator>Vijay-Shanker, K.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  To interpret natural language at the discourse level, it is very useful to
accurately recognize dialogue acts, such as SUGGEST, in identifying speaker
intentions. Our research explores the utility of a machine learning method
called Transformation-Based Learning (TBL) in computing dialogue acts, because
TBL has a number of advantages over alternative approaches for this
application. We have identified some extensions to TBL that are necessary in
order to address the limitations of the original algorithm and the particular
demands of discourse processing. We use a Monte Carlo strategy to increase the
applicability of the TBL method, and we select features of utterances that can
be used as input to improve the performance of TBL. Our system is currently
being tested on the VerbMobil corpora of spoken dialogues, producing promising
preliminary results.
</dc:description>
 <dc:description>Comment: 8 pages, 1 Postscript figure, uses aaai.sty and aaai.bst</dc:description>
 <dc:date>1998-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806002</dc:identifier>
 <dc:identifier>Applying Machine Learning to Discourse Processing: Papers from the
  1998 AAAI Spring Symposium</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lazy Transformation-Based Learning</dc:title>
 <dc:creator>Samuel, Ken</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce a significant improvement for a relatively new machine learning
method called Transformation-Based Learning. By applying a Monte Carlo strategy
to randomly sample from the space of rules, rather than exhaustively analyzing
all possible rules, we drastically reduce the memory and time costs of the
algorithm, without compromising accuracy on unseen data. This enables
Transformation- Based Learning to apply to a wider range of domains, as it can
effectively consider a larger number of different features and feature
interactions in the data. In addition, the Monte Carlo improvement decreases
the labor demands on the human developer, who no longer needs to develop a
minimal set of rule templates to maintain tractability.
</dc:description>
 <dc:description>Comment: 5 pages, 4 Postscript figures, uses aaai.sty and aaai.bst</dc:description>
 <dc:date>1998-06-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806003</dc:identifier>
 <dc:identifier>Proceedings of the 11th International Florida Artificial
  Intelligence Research Symposium Conference</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rationality, Cooperation and Conversational Implicature</dc:title>
 <dc:creator>Lee, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Conversational implicatures are usually described as being licensed by the
disobeying or flouting of a Principle of Cooperation. However, the
specification of this principle has proved computationally elusive. In this
paper we suggest that a more useful concept is rationality. Such a concept can
be specified explicitely in planning terms and we argue that speakers perform
utterances as part of the optimal plan for their particular communicative
goals. Such an assumption can be used by the hearer to infer conversational
implicatures implicit in the speaker's utterance.
</dc:description>
 <dc:description>Comment: Presented at the Ninth Irish Conference on Artificial Intelligence
  (1997)</dc:description>
 <dc:date>1998-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eliminating deceptions and mistaken belief to infer conversational
  implicature</dc:title>
 <dc:creator>Lee, Mark</dc:creator>
 <dc:creator>Wilks, Yorick</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Conversational implicatures are usually described as being licensed by the
disobeying or flouting of some principle by the speaker in cooperative
dialogue. However, such work has failed to distinguish cases of the speaker
flouting such a principle from cases where the speaker is either deceptive or
holds a mistaken belief. In this paper, we demonstrate how the three different
cases can be distinguished in terms of the beliefs ascribed to the speaker of
the utterance. We argue that in the act of distinguishing the speaker's
intention and ascribing such beliefs, the intended inference can be made by the
hearer. This theory is implemented in ViewGen, a pre-existing belief modelling
system used in a medical counselling domain.
</dc:description>
 <dc:description>Comment: IJCAI-97 workshop on Collaboration, Cooperation, and Conflict in
  Dialogue Systems</dc:description>
 <dc:date>1998-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dialogue Act Tagging with Transformation-Based Learning</dc:title>
 <dc:creator>Samuel, Ken</dc:creator>
 <dc:creator>Carberry, Sandra</dc:creator>
 <dc:creator>Vijay-Shanker, K.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  For the task of recognizing dialogue acts, we are applying the
Transformation-Based Learning (TBL) machine learning algorithm. To circumvent a
sparse data problem, we extract values of well-motivated features of
utterances, such as speaker direction, punctuation marks, and a new feature,
called dialogue act cues, which we find to be more effective than cue phrases
and word n-grams in practice. We present strategies for constructing a set of
dialogue act cues automatically by minimizing the entropy of the distribution
of dialogue acts in a training corpus, filtering out irrelevant dialogue act
cues, and clustering semantically-related words. In addition, to address
limitations of TBL, we introduce a Monte Carlo strategy for training
efficiently and a committee method for computing confidence measures. These
ideas are combined in our working implementation, which labels held-out data as
accurately as any other reported system for the dialogue act tagging task.
</dc:description>
 <dc:description>Comment: 7 pages, no Postscript figures, uses colacl.sty and acl.bst</dc:description>
 <dc:date>1998-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806006</dc:identifier>
 <dc:identifier>Proceedings of the 17th International Conference on Computational
  Linguistics (COLING-ACL '98)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Investigation of Transformation-Based Learning in Discourse</dc:title>
 <dc:creator>Samuel, Ken</dc:creator>
 <dc:creator>Carberry, Sandra</dc:creator>
 <dc:creator>Vijay-Shanker, K.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents results from the first attempt to apply
Transformation-Based Learning to a discourse-level Natural Language Processing
task. To address two limitations of the standard algorithm, we developed a
Monte Carlo version of Transformation-Based Learning to make the method
tractable for a wider range of problems without degradation in accuracy, and we
devised a committee method for assigning confidence measures to tags produced
by Transformation-Based Learning. The paper describes these advances, presents
experimental evidence that Transformation-Based Learning is as effective as
alternative approaches (such as Decision Trees and N-Grams) for a discourse
task called Dialogue Act Tagging, and argues that Transformation-Based Learning
has desirable features that make it particularly appealing for the Dialogue Act
Tagging task.
</dc:description>
 <dc:description>Comment: 9 pages, 3 Postscript figure, uses ml98.sty</dc:description>
 <dc:date>1998-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806007</dc:identifier>
 <dc:identifier>Machine Learning: Proceedings of the 15th International Conference</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unlimited Vocabulary Grapheme to Phoneme Conversion for Korean TTS</dc:title>
 <dc:creator>Kim, Byeongchang</dc:creator>
 <dc:creator>Lee, WonIl</dc:creator>
 <dc:creator>Lee, Geunbae</dc:creator>
 <dc:creator>Lee, Jong-Hyeok</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper describes a grapheme-to-phoneme conversion method using phoneme
connectivity and CCV conversion rules. The method consists of mainly four
modules including morpheme normalization, phrase-break detection, morpheme to
phoneme conversion and phoneme connectivity check.
  The morpheme normalization is to replace non-Korean symbols into standard
Korean graphemes. The phrase-break detector assigns phrase breaks using
part-of-speech (POS) information. In the morpheme-to-phoneme conversion module,
each morpheme in the phrase is converted into phonetic patterns by looking up
the morpheme phonetic pattern dictionary which contains candidate phonological
changes in boundaries of the morphemes. Graphemes within a morpheme are grouped
into CCV patterns and converted into phonemes by the CCV conversion rules. The
phoneme connectivity table supports grammaticality checking of the adjacent two
phonetic morphemes.
  In the experiments with a corpus of 4,973 sentences, we achieved 99.9% of the
grapheme-to-phoneme conversion performance and 97.5% of the sentence conversion
performance. The full Korean TTS system is now being implemented using this
conversion method.
</dc:description>
 <dc:description>Comment: 5 pages, uses colacl.sty and acl.bst, uses epsfig. To appear in the
  Proceedings of the Joint 17th International Conference on Computational
  Linguistics 36th Annual Meeting of the Association for Computational
  Linguistics (COLING-ACL'98)</dc:description>
 <dc:date>1998-06-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Methods and Tools for Building the Catalan WordNet</dc:title>
 <dc:creator>Benitez, Laura</dc:creator>
 <dc:creator>Cervell, Sergi</dc:creator>
 <dc:creator>Escudero, Gerard</dc:creator>
 <dc:creator>Lopez, Monica</dc:creator>
 <dc:creator>Rigau, German</dc:creator>
 <dc:creator>Taule, Mariona</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we introduce the methodology used and the basic phases we
followed to develop the Catalan WordNet, and shich lexical resources have been
employed in its building. This methodology, as well as the tools we made use
of, have been thought in a general way so that they could be applied to any
other language.
</dc:description>
 <dc:description>Comment: 5 pages, postscript file. In workshop Language Resources for European
  Minority Languages at LREC'98</dc:description>
 <dc:date>1998-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a single proposal is spelling correction</dc:title>
 <dc:creator>Agirre, E.</dc:creator>
 <dc:creator>Gojenola, K.</dc:creator>
 <dc:creator>Sarasola, K.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The study presented here relies on the integrated use of different kinds of
knowledge in order to improve first-guess accuracy in non-word
context-sensitive correction for general unrestricted texts. State of the art
spelling correction systems, e.g. ispell, apart from detecting spelling errors,
also assist the user by offering a set of candidate corrections that are close
to the misspelled word. Based on the correction proposals of ispell, we built
several guessers, which were combined in different ways. Firstly, we evaluated
all possibilities and selected the best ones in a corpus with artificially
generated typing errors. Secondly, the best combinations were tested on texts
with genuine spelling errors. The results for the latter suggest that we can
expect automatic non-word correction for all the errors in a free running text
with 80% precision and a single proposal 98% of the times (1.02 proposals on
average).
</dc:description>
 <dc:date>1998-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Memory-Based Approach to Learning Shallow Natural Language Patterns</dc:title>
 <dc:creator>Argamon, Shlomo</dc:creator>
 <dc:creator>Dagan, Ido</dc:creator>
 <dc:creator>Krymolowski, Yuval</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Recognizing shallow linguistic patterns, such as basic syntactic
relationships between words, is a common task in applied natural language and
text processing. The common practice for approaching this task is by tedious
manual definition of possible pattern structures, often in the form of regular
expressions or finite automata. This paper presents a novel memory-based
learning method that recognizes shallow patterns in new text based on a
bracketed training corpus. The training data are stored as-is, in efficient
suffix-tree data structures. Generalization is performed on-line at recognition
time by comparing subsequences of the new text to positive and negative
evidence in the corpus. This way, no information in the training is lost, as
can happen in other learning systems that construct a single generalized model
at the time of training. The paper presents experimental results for
recognizing noun phrase, subject-verb and verb-object patterns in English.
Since the learning approach enables easy porting to new domains, we plan to
apply it to syntactic patterns in other languages and to sub-language patterns
for information extraction.
</dc:description>
 <dc:description>Comment: 27 pages. This is a revised and extended version of the paper
  presented in COLING-ACL '98. To appear in Journal of Experimental and
  Theoretical AI (JETAI) special issue on memory-based learning</dc:description>
 <dc:date>1998-06-16</dc:date>
 <dc:date>1999-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Stratified Sampling to Assess Corpus Utility</dc:title>
 <dc:creator>Hochberg, Judith</dc:creator>
 <dc:creator>Scovel, Clint</dc:creator>
 <dc:creator>Thomas, Timothy</dc:creator>
 <dc:creator>Hall, Sam</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper describes a method for asking statistical questions about a large
text corpus. We exemplify the method by addressing the question, &quot;What
percentage of Federal Register documents are real documents, of possible
interest to a text researcher or analyst?&quot; We estimate an answer to this
question by evaluating 200 documents selected from a corpus of 45,820 Federal
Register documents. Stratified sampling is used to reduce the sampling
uncertainty of the estimate from over 3100 documents to fewer than 1000. The
stratification is based on observed characteristics of real documents, while
the sampling procedure incorporates a Bayesian version of Neyman allocation. A
possible application of the method is to establish baseline statistics used to
estimate recall rates for information retrieval systems.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures. To appear in Proceedings of WVLC-6</dc:description>
 <dc:date>1998-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Subcategorisation Probabilities Help a Statistical Parser?</dc:title>
 <dc:creator>Carroll, John</dc:creator>
 <dc:creator>Minnen, Guido</dc:creator>
 <dc:creator>Briscoe, Ted</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Research into the automatic acquisition of lexical information from corpora
is starting to produce large-scale computational lexicons containing data on
the relative frequencies of subcategorisation alternatives for individual
verbal predicates. However, the empirical question of whether this type of
frequency information can in practice improve the accuracy of a statistical
parser has not yet been answered. In this paper we describe an experiment with
a wide-coverage statistical grammar and parser for English and
subcategorisation frequencies acquired from ten million words of text which
shows that this information can significantly improve parse accuracy.
</dc:description>
 <dc:description>Comment: 9 pages, uses colacl.sty</dc:description>
 <dc:date>1998-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806013</dc:identifier>
 <dc:identifier>6th Workshop on Very Large Corpora, Montreal, Canada, 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Word Sense Disambiguation using Optimised Combinations of Knowledge
  Sources</dc:title>
 <dc:creator>Wilks, Yorick</dc:creator>
 <dc:creator>Stevenson, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Word sense disambiguation algorithms, with few exceptions, have made use of
only one lexical knowledge source. We describe a system which performs
unrestricted word sense disambiguation (on all content words in free text) by
combining different knowledge sources: semantic preferences, dictionary
definitions and subject/domain codes along with part-of-speech tags. The
usefulness of these sources is optimised by means of a learning algorithm. We
also describe the creation of a new sense tagged corpus by combining existing
resources. Tested accuracy of our approach on this corpus exceeds 92%,
demonstrating the viability of all-word disambiguation rather than restricting
oneself to a small sample.
</dc:description>
 <dc:description>Comment: 7 pages, uses colacl.sty. To appear in the Proceedings of COLING-ACL
  '98</dc:description>
 <dc:date>1998-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Accurate Semantic Taxonomies from Monolingual MRDs</dc:title>
 <dc:creator>Rigau, German</dc:creator>
 <dc:creator>Rodriguez, Horacio</dc:creator>
 <dc:creator>Agirre, Eneko</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents a method that combines a set of unsupervised algorithms
in order to accurately build large taxonomies from any machine-readable
dictionary (MRD). Our aim is to profit from conventional MRDs, with no explicit
semantic coding. We propose a system that 1) performs fully automatic exraction
of taxonomic links from MRD entries and 2) ranks the extracted relations in a
way that selective manual refinement is allowed. Tested accuracy can reach
around 100% depending on the degree of coverage selected, showing that taxonomy
building is not limited to structured dictionaries such as LDOCE.
</dc:description>
 <dc:description>Comment: 7 pages, postscript file. In COLIN-ACL'98</dc:description>
 <dc:date>1998-06-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using WordNet for Building WordNets</dc:title>
 <dc:creator>Farreres, Xavier</dc:creator>
 <dc:creator>Rigau, German</dc:creator>
 <dc:creator>Rodriguez, Horacio</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper summarises a set of methodologies and techniques for the fast
construction of multilingual WordNets. The English WordNet is used in this
approach as a backbone for Catalan and Spanish WordNets and as a lexical
knowledge resource for several subtasks.
</dc:description>
 <dc:description>Comment: 8 pages, postscript file. In workshop on Usage of WordNet in NLP</dc:description>
 <dc:date>1998-06-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anchoring a Lexicalized Tree-Adjoining Grammar for Discourse</dc:title>
 <dc:creator>Webber, Bonnie Lynn</dc:creator>
 <dc:creator>Joshi, Aravind K.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We here explore a ``fully'' lexicalized Tree-Adjoining Grammar for discourse
that takes the basic elements of a (monologic) discourse to be not simply
clauses, but larger structures that are anchored on variously realized
discourse cues. This link with intra-sentential grammar suggests an account for
different patterns of discourse cues, while the different structures and
operations suggest three separate sources for elements of discourse meaning:
(1) a compositional semantics tied to the basic trees and operations; (2) a
presuppositional semantics carried by cue phrases that freely adjoin to trees;
and (3) general inference, that draws additional, defeasible conclusions that
flesh out what is conveyed compositionally.
</dc:description>
 <dc:description>Comment: 7 pages, uses aclcol.sty</dc:description>
 <dc:date>1998-06-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806017</dc:identifier>
 <dc:identifier>Proceedings of COLING-ACL'98 Workshop on Discourse Relations and
  Discourse Markers. (Reproduced with permission of the Universite de Montreal</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Never Look Back: An Alternative to Centering</dc:title>
 <dc:creator>Strube, Michael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  I propose a model for determining the hearer's attentional state which
depends solely on a list of salient discourse entities (S-list). The ordering
among the elements of the S-list covers also the function of the
backward-looking center in the centering model. The ranking criteria for the
S-list are based on the distinction between hearer-old and hearer-new discourse
entities and incorporate preferences for inter- and intra-sentential anaphora.
The model is the basis for an algorithm which operates incrementally, word by
word.
</dc:description>
 <dc:description>Comment: 7 pages, uses colacl.sty, epsfig.sty, times.sty, lingmacros.sty</dc:description>
 <dc:date>1998-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806018</dc:identifier>
 <dc:identifier>Proceedings of COLING-ACL '98</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Investigation of Proposals in Collaborative Dialogues</dc:title>
 <dc:creator>Di Eugenio, Barbara</dc:creator>
 <dc:creator>Jordan, Pamela W.</dc:creator>
 <dc:creator>Moore, Johanna D.</dc:creator>
 <dc:creator>Thomason, Richmond H.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We describe a corpus-based investigation of proposals in dialogue. First, we
describe our DRI compliant coding scheme and report our inter-coder reliability
results. Next, we test several hypotheses about what constitutes a well-formed
proposal.
</dc:description>
 <dc:description>Comment: 5 pages, colacl.sty, formulas.sty</dc:description>
 <dc:date>1998-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806019</dc:identifier>
 <dc:identifier>Proceedings of COLING-ACL 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9806020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Textual Economy through Close Coupling of Syntax and Semantics</dc:title>
 <dc:creator>Stone, Matthew</dc:creator>
 <dc:creator>Webber, Bonnie</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We focus on the production of efficient descriptions of objects, actions and
events. We define a type of efficiency, textual economy, that exploits the
hearer's recognition of inferential links to material elsewhere within a
sentence. Textual economy leads to efficient descriptions because the material
that supports such inferences has been included to satisfy independent
communicative goals, and is therefore overloaded in Pollack's sense. We argue
that achieving textual economy imposes strong requirements on the
representation and reasoning used in generating sentences. The representation
must support the generator's simultaneous consideration of syntax and
semantics. Reasoning must enable the generator to assess quickly and reliably
at any stage how the hearer will interpret the current sentence, with its
(incomplete) syntax and semantics. We show that these representational and
reasoning requirements are met in the SPUD system for sentence planning and
realization.
</dc:description>
 <dc:description>Comment: 10 pages, uses QobiTree.tex</dc:description>
 <dc:date>1998-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9806020</dc:identifier>
 <dc:identifier>Proceedings 1998 Int'l Workshop on Natural Language Generation,
  Niagara-on-the-Lake, Canada, August 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9807001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating a Focus-Based Approach to Anaphora Resolution</dc:title>
 <dc:creator>Azzam, Saliha</dc:creator>
 <dc:creator>Humphreys, Kevin</dc:creator>
 <dc:creator>Gaizauskas, Robert</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present an approach to anaphora resolution based on a focusing algorithm,
and implemented within an existing MUC (Message Understanding Conference)
Information Extraction system, allowing quantitative evaluation against a
substantial corpus of annotated real-world texts. Extensions to the basic
focusing mechanism can be easily tested, resulting in refinements to the
mechanism and resolution rules. Results are compared with the results of a
simpler heuristic-based approach.
</dc:description>
 <dc:description>Comment: 5 pages, uses colacl.sty</dc:description>
 <dc:date>1998-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9807001</dc:identifier>
 <dc:identifier>Proceedings of COLING-ACL '98</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9807002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Role of Verbs in Document Analysis</dc:title>
 <dc:creator>Klavans, Judith L.</dc:creator>
 <dc:creator>Kan, Min-Yen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present results of two methods for assessing the event profile of news
articles as a function of verb type. The unique contribution of this research
is the focus on the role of verbs, rather than nouns. Two algorithms are
presented and evaluated, one of which is shown to accurately discriminate
documents by type and semantic properties, i.e. the event profile. The initial
method, using WordNet (Miller et al. 1990), produced multiple
cross-classification of articles, primarily due to the bushy nature of the verb
tree coupled with the sense disambiguation problem. Our second approach using
English Verb Classes and Alternations (EVCA) Levin (1993) showed that
monosemous categorization of the frequent verbs in WSJ made it possible to
usefully discriminate documents. For example, our results show that articles in
which communication verbs predominate tend to be opinion pieces, whereas
articles with a high percentage of agreement verbs tend to be about mergers or
legal cases. An evaluation is performed on the results using Kendall's Tau. We
present convincing evidence for using verb semantic classes as a discriminant
in document classification.
</dc:description>
 <dc:description>Comment: 7 + 1 pages, US Letter, LaTeX (+2 eps figures). To appear in
  Proceedings of the 17th International Conference on Computational Linguistics
  (COLING-ACL '98). Tool license available at
  http://www.cs.columbia.edu/nlp/licenses/verberLicenseDownload.html</dc:description>
 <dc:date>1998-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9807002</dc:identifier>
 <dc:identifier>Proceedings of the 17th International Conference on Computational
  Linguistics (COLING-ACL '98), Montreal, Canada: Aug. 1998. pp. 680-686.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9807003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Centering in Dynamic Semantics</dc:title>
 <dc:creator>Hardt, Daniel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Centering theory posits a discourse center, a distinguished discourse entity
that is the topic of a discourse. A simplified version of this theory is
developed in a Dynamic Semantics framework. In the resulting system, the
mechanism of center shift allows a simple, elegant analysis of a variety of
phenomena involving sloppy identity in ellipsis and ``paycheck pronouns''.
</dc:description>
 <dc:date>1998-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9807003</dc:identifier>
 <dc:identifier>Proceedings of COLING 96, Copenhagen, Denmark</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9807004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Word Clustering and Disambiguation Based on Co-occurrence Data</dc:title>
 <dc:creator>Li, Hang</dc:creator>
 <dc:creator>Abe, Naoki</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We address the problem of clustering words (or constructing a thesaurus)
based on co-occurrence data, and using the acquired word classes to improve the
accuracy of syntactic disambiguation. We view this problem as that of
estimating a joint probability distribution specifying the joint probabilities
of word pairs, such as noun verb pairs. We propose an efficient algorithm based
on the Minimum Description Length (MDL) principle for estimating such a
probability distribution. Our method is a natural extension of those proposed
in (Brown et al 92) and (Li &amp; Abe 96), and overcomes their drawbacks while
retaining their advantages. We then combined this clustering method with the
disambiguation method of (Li &amp; Abe 95) to derive a disambiguation method that
makes use of both automatically constructed thesauruses and a hand-made
thesaurus. The overall disambiguation accuracy achieved by our method is 85.2%,
which compares favorably against the accuracy (82.4%) obtained by the
state-of-the-art disambiguation method of (Brill &amp; Resnik 94).
</dc:description>
 <dc:description>Comment: latex file, uses colacl.sty file and 4 eps files, to appear in Proc.
  of COLING-ACL'98, 8 pages</dc:description>
 <dc:date>1998-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9807004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9807005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Interpolation Grammars as Context-Free Automata</dc:title>
 <dc:creator>Larcheveque, John</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A derivation step in a Graph Interpolation Grammar has the effect of scanning
an input token. This feature, which aims at emulating the incrementality of the
natural parser, restricts the formal power of GIGs. This contrasts with the
fact that the derivation mechanism involves a context-sensitive device similar
to tree adjunction in TAGs. The combined effect of input-driven derivation and
restricted context-sensitiveness would be conceivably unfortunate if it turned
out that Graph Interpolation Languages did not subsume Context Free Languages
while being partially context-sensitive. This report sets about examining
relations between CFGs and GIGs, and shows that GILs are a proper superclass of
CFLs. It also brings out a strong equivalence between CFGs and GIGs for the
class of CFLs. Thus, it lays the basis for meaningfully investigating the
amount of context-sensitiveness supported by GIGs, but leaves this
investigation for further research.
</dc:description>
 <dc:date>1998-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9807005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9807006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Maximum-Entropy Partial Parser for Unrestricted Text</dc:title>
 <dc:creator>Skut, Wojciech</dc:creator>
 <dc:creator>Brants, Thorsten</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper describes a partial parser that assigns syntactic structures to
sequences of part-of-speech tags. The program uses the maximum entropy
parameter estimation method, which allows a flexible combination of different
knowledge sources: the hierarchical structure, parts of speech and phrasal
categories. In effect, the parser goes beyond simple bracketing and recognises
even fairly complex structures. We give accuracy figures for different
applications of the parser.
</dc:description>
 <dc:description>Comment: 9 pages, LaTeX</dc:description>
 <dc:date>1998-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9807006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9807007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chunk Tagger - Statistical Recognition of Noun Phrases</dc:title>
 <dc:creator>Skut, Wojciech</dc:creator>
 <dc:creator>Brants, Thorsten</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We describe a stochastic approach to partial parsing, i.e., the recognition
of syntactic structures of limited depth. The technique utilises Markov Models,
but goes beyond usual bracketing approaches, since it is capable of recognising
not only the boundaries, but also the internal structure and syntactic category
of simple as well as complex NP's, PP's, AP's and adverbials. We compare
tagging accuracy for different applications and encoding schemes.
</dc:description>
 <dc:description>Comment: 7 pages, LaTeX</dc:description>
 <dc:date>1998-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9807007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9807008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Linguistically Interpreted Corpus of German Newspaper Text</dc:title>
 <dc:creator>Skut, Wojciech</dc:creator>
 <dc:creator>Brants, Thorsten</dc:creator>
 <dc:creator>Krenn, Brigitte</dc:creator>
 <dc:creator>Uszkoreit, Hans</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we report on the development of an annotation scheme and
annotation tools for unrestricted German text. Our representation format is
based on argument structure, but also permits the extraction of other kinds of
representations. We discuss several methodological issues and the analysis of
some phenomena. Additional focus is on the tools developed in our project and
their applications.
</dc:description>
 <dc:description>Comment: 7 pages, LaTeX</dc:description>
 <dc:date>1998-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9807008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9807009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Projection Architecture for Dependency Grammar and How it Compares to
  LFG</dc:title>
 <dc:creator>Broeker, Norbert</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper explores commonalities and differences between \dachs, a variant
of Dependency Grammar, and Lexical-Functional Grammar. \dachs\ is based on
traditional linguistic insights, but on modern mathematical tools, aiming to
integrate different knowledge systems (from syntax and semantics) via their
coupling to an abstract syntactic primitive, the dependency relation. These
knowledge systems correspond rather closely to projections in LFG. We will
investigate commonalities arising from the usage of the projection approach in
both theories, and point out differences due to the incompatible linguistic
premises. The main difference to LFG lies in the motivation and status of the
dimensions, and the information coded there. We will argue that LFG confounds
different information in one projection, preventing it to achieve a good
separation of alternatives and calling the motivation of the projection into
question.
</dc:description>
 <dc:description>Comment: Proc. LFG'98 (Brisbane/AUS); LaTeX2e with html package</dc:description>
 <dc:date>1998-07-20</dc:date>
 <dc:date>1998-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9807009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9807010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatically Creating Bilingual Lexicons for Machine Translation from
  Bilingual Text</dc:title>
 <dc:creator>Turcato, Davide</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A method is presented for automatically augmenting the bilingual lexicon of
an existing Machine Translation system, by extracting bilingual entries from
aligned bilingual text. The proposed method only relies on the resources
already available in the MT system itself. It is based on the use of bilingual
lexical templates to match the terminal symbols in the parses of the aligned
sentences.
</dc:description>
 <dc:description>Comment: Latex file, uses colacl.sty file, 7 pages</dc:description>
 <dc:date>1998-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9807010</dc:identifier>
 <dc:identifier>Proceedings of COLING-ACL'98</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9807011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Models for Unsupervised Prepositional Phrase Attachment</dc:title>
 <dc:creator>Ratnaparkhi, Adwait</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present several unsupervised statistical models for the prepositional
phrase attachment task that approach the accuracy of the best supervised
methods for this task. Our unsupervised approach uses a heuristic based on
attachment proximity and trains from raw text that is annotated with only
part-of-speech tags and morphological base forms, as opposed to attachment
information. It is therefore less resource-intensive and more portable than
previous corpus-based algorithms proposed for this task. We present results for
prepositional phrase attachment in both English and Spanish.
</dc:description>
 <dc:description>Comment: uses colacl.sty</dc:description>
 <dc:date>1998-07-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9807011</dc:identifier>
 <dc:identifier>Proceedings of the 17th International Conference on Computational
  Linguistics (COLING-ACL '98)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9807012</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Character design for soccer commmentary</dc:title>
 <dc:creator>Binsted, Kim</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we present early work on an animated talking head commentary
system called {\bf Byrne}\footnote{David Byrne is the lead singer of the
Talking Heads.}. The goal of this project is to develop a system which can take
the output from the RoboCup soccer simulator, and generate appropriate
affective speech and facial expressions, based on the character's personality,
emotional state, and the state of play. Here we describe a system which takes
pre-analysed simulator output as input, and which generates text marked-up for
use by a speech generator and a face animation system. We make heavy use of
inter-system standards, so that future versions of Byrne will be able to take
advantage of advances in the technologies that it incorporates.
</dc:description>
 <dc:description>Comment: uuencoded gzipped tar file. Latex. Uses psfig, times, llncs</dc:description>
 <dc:date>1998-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9807012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9807013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Data Driven Wordclass Tagging by System Combination</dc:title>
 <dc:creator>van Halteren, Hans</dc:creator>
 <dc:creator>Zavrel, Jakub</dc:creator>
 <dc:creator>Daelemans, Walter</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we examine how the differences in modelling between different
data driven systems performing the same NLP task can be exploited to yield a
higher accuracy than the best individual system. We do this by means of an
experiment involving the task of morpho-syntactic wordclass tagging. Four
well-known tagger generators (Hidden Markov Model, Memory-Based, Transformation
Rules and Maximum Entropy) are trained on the same corpus data. After
comparison, their outputs are combined using several voting strategies and
second stage classifiers. All combination taggers outperform their best
component, with the best combination showing a 19.1% lower error rate than the
best individual tagger.
</dc:description>
 <dc:description>Comment: 7 pages, LaTeX, uses acl.bst, colacl.sty</dc:description>
 <dc:date>1998-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9807013</dc:identifier>
 <dc:identifier>Proceedings of the 17th International Conference on Computational
  Linguistics (COLING-ACL'98)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Evaluation of Probabilistic Lexicalized Tree Insertion
  Grammars</dc:title>
 <dc:creator>Hwa, Rebecca</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present an empirical study of the applicability of Probabilistic
Lexicalized Tree Insertion Grammars (PLTIG), a lexicalized counterpart to
Probabilistic Context-Free Grammars (PCFG), to problems in stochastic
natural-language processing. Comparing the performance of PLTIGs with
non-hierarchical N-gram models and PCFGs, we show that PLTIG combines the best
aspects of both, with language modeling capability comparable to N-grams, and
improved parsing performance over its non-lexicalized counterpart. Furthermore,
training of PLTIGs displays faster convergence than PCFGs.
</dc:description>
 <dc:description>Comment: 10 pages, 6 encapsulated postscript figures and 2 latex figures, uses
  colacl.sty</dc:description>
 <dc:date>1998-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808001</dc:identifier>
 <dc:identifier>Proceedings of COLING-ACL'98</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Indexing with WordNet synsets can improve Text Retrieval</dc:title>
 <dc:creator>Gonzalo, Julio</dc:creator>
 <dc:creator>Verdejo, Felisa</dc:creator>
 <dc:creator>Chugur, Irina</dc:creator>
 <dc:creator>Cigarran, Juan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The classical, vector space model for text retrieval is shown to give better
results (up to 29% better in our experiments) if WordNet synsets are chosen as
the indexing space, instead of word forms. This result is obtained for a
manually disambiguated test collection (of queries and documents) derived from
the Semcor semantic concordance. The sensitivity of retrieval performance to
(automatic) disambiguation errors when indexing documents is also measured.
Finally, it is observed that if queries are not disambiguated, indexing by
synsets performs (at best) only as good as standard word indexing.
</dc:description>
 <dc:description>Comment: 7 pages, LaTeX2e, 3 eps figures, uses epsfig, colacl.sty</dc:description>
 <dc:date>1998-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808002</dc:identifier>
 <dc:identifier>Proceedings of the COLING/ACL'98 Workshop on Usage of WordNet for
  NLP, Montreal, 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Strands: A Preliminary Investigation into Mining the Web for
  Bilingual Text</dc:title>
 <dc:creator>Resnik, Philip</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Parallel corpora are a valuable resource for machine translation, but at
present their availability and utility is limited by genre- and
domain-specificity, licensing restrictions, and the basic difficulty of
locating parallel texts in all but the most dominant of the world's languages.
A parallel corpus resource not yet explored is the World Wide Web, which hosts
an abundance of pages in parallel translation, offering a potential solution to
some of these problems and unique opportunities of its own. This paper presents
the necessary first step in that exploration: a method for automatically
finding parallel translated documents on the Web. The technique is conceptually
simple, fully language independent, and scalable, and preliminary evaluation
results indicate that the method may be accurate enough to apply without human
intervention.
</dc:description>
 <dc:description>Comment: LaTeX2e, 11 pages, 7 eps figures; uses psfig, llncs.cls, theapa.sty.
  An Appendix at http://umiacs.umd.edu/~resnik/amta98/amta98_appendix.html
  contains test data</dc:description>
 <dc:date>1998-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808003</dc:identifier>
 <dc:identifier>Proceedings of AMTA-98</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Word Length Frequency and Distribution in English: Observations, Theory,
  and Implications for the Construction of Verse Lines</dc:title>
 <dc:creator>Aoyama, Hideaki</dc:creator>
 <dc:creator>Constable, John</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent observations in the theory of verse and empirical metrics have
suggested that constructing a verse line involves a pattern-matching search
through a source text, and that the number of found elements (complete words
totaling a specified number of syllables) is given by dividing the total number
of words by the mean number of syllables per word in the source text. This
paper makes this latter point explicit mathematically, and in the course of
this demonstration shows that the word length frequency totals in English
output are distributed geometrically (previous researchers reported an adjusted
Poisson distribution), and that the sequential distribution is random at the
global level, with significant non-randomness in the fine structure. Data from
a corpus of just under two million words, and a syllable-count lexicon of
71,000 word-forms is reported. The pattern-matching theory is shown to be
internally coherent, and it is observed that some of the analytic techniques
described here form a satisfactory test for regular (isometric) lineation in a
text.
</dc:description>
 <dc:description>Comment: 32 pages, 11 figures, uses epsf.tex</dc:description>
 <dc:date>1998-08-12</dc:date>
 <dc:date>1998-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Expression and Content in Domains for Dialog Managers</dc:title>
 <dc:creator>Ludwig, Bernd</dc:creator>
 <dc:creator>Goerz, Guenther</dc:creator>
 <dc:creator>Niemann, Heinrich</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present work in progress on abstracting dialog managers from their domain
in order to implement a dialog manager development tool which takes (among
other data) a domain description as input and delivers a new dialog manager for
the described domain as output. Thereby we will focus on two topics; firstly,
the construction of domain descriptions with description logics and secondly,
the interpretation of utterances in a given domain.
</dc:description>
 <dc:description>Comment: 5 pages, uses conference.sty</dc:description>
 <dc:date>1998-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808005</dc:identifier>
 <dc:identifier>Proceedings of DL '98, pp. 126-130, Trento, Italy</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Isometric Lineation in English Texts: An Empirical and Mathematical
  Examination of its Character and Consequences</dc:title>
 <dc:creator>Aoyama, Hideaki</dc:creator>
 <dc:creator>Constable, John</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we build on earlier observations and theory regarding word
length frequency and sequential distribution to develop a mathematical
characterization of some of the language features distinguishing isometrically
lineated text from unlineated text, in other words the features distinguishing
isometrical verse from prose. It is shown that the frequency of syllables
making complete words produces a flat distribution for prose, while that for
verse exhibits peaks at the line length position and subsequent multiples of
that position. Data from several verse authors is presented, including a
detailed mathematical analysis of the dynamics underlying peak creation, and
comments are offered on the processes by which authors construct lines. We note
that the word-length sequence of prose is random, whereas lineation
necessitates non-random word-length sequencing, and that this has the probable
consequence of introducing a degree of randomness into the otherwise highly
ordered grammatical sequence. In addition we observe that this effect can be
ameliorated by a reduction in the mean word length of the text (confirming
earlier observations that verse tends to use shorter words) and the use of
lines varying from the core isometrical set. The frequency of variant lines is
shown to be coincident with the frequency of polysyllables, suggesting that the
use of variant lines is motivated by polysyllabic word placement. The
restrictive effects of different line lengths, the relationship between
metrical restriction and poetic effect, and the general character of metrical
rules are also discussed.
</dc:description>
 <dc:description>Comment: PDF file only</dc:description>
 <dc:date>1998-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some Properties of Preposition and Subordinate Conjunction Attachments</dc:title>
 <dc:creator>Yeh, Alexander S.</dc:creator>
 <dc:creator>Vilain, Marc B.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Determining the attachments of prepositions and subordinate conjunctions is a
key problem in parsing natural language. This paper presents a trainable
approach to making these attachments through transformation sequences and
error-driven learning. Our approach is broad coverage, and accounts for roughly
three times the attachment cases that have previously been handled by
corpus-based techniques. In addition, our approach is based on a simplified
model of syntax that is more consistent with the practice in current
state-of-the-art language processing systems. This paper sketches syntactic and
algorithmic details, and presents experimental results on data sets derived
from the Penn Treebank. We obtain an attachment accuracy of 75.4% for the
general case, the first such corpus-based result to be reported. For the
restricted cases previously studied with corpus-based methods, our approach
yields an accuracy comparable to current work (83.1%).
</dc:description>
 <dc:description>Comment: 7 pages, uses colacl.sty</dc:description>
 <dc:date>1998-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808007</dc:identifier>
 <dc:identifier>Proceedings of COLING-ACL '98: 36th Annual Meeting of the
  Association for Computational Linguistics and 17th International Conference
  on Computational Linguistics, Montreal, Canada, 1998. Pages 1436-1442.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deriving the Predicate-Argument Structure for a Free Word Order Language</dc:title>
 <dc:creator>Bozsahin, Cem</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In relatively free word order languages, grammatical functions are
intricately related to case marking. Assuming an ordered representation of the
predicate-argument structure, this work proposes a Combinatory Categorial
Grammar formulation of relating surface case cues to categories and types for
correctly placing the arguments in the predicate-argument structure. This is
achieved by assigning case markers GF-encoding categories. Unlike other CG
formulations, type shifting does not proliferate or cause spurious ambiguity.
Categories of all argument-encoding grammatical functions follow from the same
principle of category assignment. Normal order evaluation of the combinatory
form reveals the predicate-argument structure. Application of the method to
Turkish is shown.
</dc:description>
 <dc:description>Comment: 7 pages LaTeX; uses {times,avm,lingmacros,tree-dvips}.sty; minor
  corrections in the abstract</dc:description>
 <dc:date>1998-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808008</dc:identifier>
 <dc:identifier>Proceedings of COLING-ACL '98, 167-173</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808009</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to define a context-free backbone for DGs: Implementing a DG in the
  LFG formalism</dc:title>
 <dc:creator>Broeker, Norbert</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents a multidimensional Dependency Grammar (DG), which
decouples the dependency tree from word order, such that surface ordering is
not determined by traversing the dependency tree. We develop the notion of a
\emph{word order domain structure}, which is linked but structurally dissimilar
to the syntactic dependency tree. We then discuss the implementation of such a
DG using constructs from a unification-based phrase-structure approach, namely
Lexical-Functional Grammar (LFG). Particular attention is given to the analysis
of discontinuities in DG in terms of LFG's functional uncertainty.
</dc:description>
 <dc:description>Comment: 10 pages, LaTeX2e</dc:description>
 <dc:date>1998-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808009</dc:identifier>
 <dc:identifier>Proc. COLING-ACL'98 Workshop ``Processing of Dependency-Based
  Grammars'', pp 29-38</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Letter to Sound Rules for Accented Lexicon Compression</dc:title>
 <dc:creator>Pagel, V.</dc:creator>
 <dc:creator>Lenzo, K.</dc:creator>
 <dc:creator>Black, A.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents trainable methods for generating letter to sound rules
from a given lexicon for use in pronouncing out-of-vocabulary words and as a
method for lexicon compression.
  As the relationship between a string of letters and a string of phonemes
representing its pronunciation for many languages is not trivial, we discuss
two alignment procedures, one fully automatic and one hand-seeded which produce
reasonable alignments of letters to phones.
  Top Down Induction Tree models are trained on the aligned entries. We show
how combined phoneme/stress prediction is better than separate prediction
processes, and still better when including in the model the last phonemes
transcribed and part of speech information. For the lexicons we have tested,
our models have a word accuracy (including stress) of 78% for OALD, 62% for CMU
and 94% for BRULEX. The extremely high scores on the training sets allow
substantial size reductions (more than 1/20).
  WWW site: http://tcts.fpms.ac.be/synthesis/mbrdico
</dc:description>
 <dc:description>Comment: 4 pages 1 figure</dc:description>
 <dc:date>1998-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Primitive Part-of-Speech Tagging using Word Length and Sentential
  Structure</dc:title>
 <dc:creator>Cozens, Simon</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  It has been argued that, when learning a first language, babies use a series
of small clues to aid recognition and comprehension, and that one of these
clues is word length. In this paper we present a statistical part of speech
tagger which trains itself solely on the number of letters in each word in a
sentence.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>1998-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separating Surface Order and Syntactic Relations in a Dependency Grammar</dc:title>
 <dc:creator>Broeker, Norbert</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper proposes decoupling the dependency tree from word order, such that
surface ordering is not determined by traversing the dependency tree. We
develop the notion of a \emph{word order domain structure}, which is linked but
structurally dissimilar to the syntactic dependency tree. The proposal results
in a lexicalized, declarative, and formally precise description of word order;
features which lack previous proposals for dependency grammars. Contrary to
other lexicalized approaches to word order, our proposal does not require
lexical ambiguities for ordering alternatives.
</dc:description>
 <dc:description>Comment: 7 pages, LaTeX2e</dc:description>
 <dc:date>1998-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808012</dc:identifier>
 <dc:identifier>Proc. COLING-ACL'98, pp 174-180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partial Evaluation for Efficient Access to Inheritance Lexicons</dc:title>
 <dc:creator>Hartrumpf, Sven</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Multiple default inheritance formalisms for lexicons have attracted much
interest in recent years. I propose a new efficient method to access such
lexicons. After showing two basic strategies for lookup in inheritance
lexicons, a compromise is developed which combines to a large degree (from a
practical point of view) the advantages of both strategies and avoids their
disadvantages. The method is a kind of (off-line) partial evaluation that makes
a subset of inherited information explicit before using the lexicon. I identify
the parts of a lexicon which should be evaluated, and show how partial
evaluation works for inheritance lexicons. Finally, the theoretical results are
confirmed by a complete implementation. Speedups by a factor of 10-100 are
reached.
</dc:description>
 <dc:description>Comment: 8 pages; uses amsfonts.sty, avm.sty, booktabs.sty, caption.sty,
  ranlp97.sty, and xy.sty</dc:description>
 <dc:date>1998-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808013</dc:identifier>
 <dc:identifier>Proceedings of the 2nd International Conference on Recent Advances
  in Natural Language Processing (RANLP-97), pp. 43-50, Tzigov Chark, Bulgaria,
  September 1997.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spotting Prosodic Boundaries in Continuous Speech in French</dc:title>
 <dc:creator>Pagel, V.</dc:creator>
 <dc:creator>Carbonell, N.</dc:creator>
 <dc:creator>Laprie, Y.</dc:creator>
 <dc:creator>Vaissiere, J.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A radio speech corpus of 9mn has been prosodically marked by a phonetician
expert, and non expert listeners. this corpus is large enough to train and test
an automatic boundary spotting system, namely a time delay neural network fed
with F0 values, vowels and pseudo-syllable durations. Results validate both
prosodic marking and automatic spotting of prosodic events.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>1998-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error-Driven Pruning of Treebank Grammars for Base Noun Phrase
  Identification</dc:title>
 <dc:creator>Cardie, Claire</dc:creator>
 <dc:creator>Pierce, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Finding simple, non-recursive, base noun phrases is an important subtask for
many natural language processing applications. While previous empirical methods
for base NP identification have been rather complex, this paper instead
proposes a very simple algorithm that is tailored to the relative simplicity of
the task. In particular, we present a corpus-based approach for finding base
NPs by matching part-of-speech tag sequences. The training phase of the
algorithm is based on two successful techniques: first the base NP grammar is
read from a ``treebank'' corpus; then the grammar is improved by selecting
rules with high ``benefit'' scores. Using this simple algorithm with a naive
heuristic for matching rules, we achieve surprising accuracy in an evaluation
on the Penn Treebank Wall Street Journal.
</dc:description>
 <dc:description>Comment: 7 pages; 2 eps figures; uses epsf, colacl</dc:description>
 <dc:date>1998-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808015</dc:identifier>
 <dc:identifier>Proceedings of COLING-ACL'98, pages 218-224.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Segregatory Coordination and Ellipsis in Text Generation</dc:title>
 <dc:creator>Shaw, James</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we provide an account of how to generate sentences with
coordination constructions from clause-sized semantic representations. An
algorithm is developed to generate sentences with ellipsis, gapping,
right-node-raising, and non-constituent coordination constructions. Various
examples from linguistic literature will be used to demonstrate that the
algorithm does its job well.
</dc:description>
 <dc:description>Comment: 7 pages, uses colacl.sty</dc:description>
 <dc:date>1998-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808016</dc:identifier>
 <dc:identifier>COLING-ACL'98, pp. 1220-1226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9808017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Variant of Earley Parsing</dc:title>
 <dc:creator>Nederhof, Mark-Jan</dc:creator>
 <dc:creator>Satta, Giorgio</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The Earley algorithm is a widely used parsing method in natural language
processing applications. We introduce a variant of Earley parsing that is based
on a ``delayed'' recognition of constituents. This allows us to start the
recognition of a constituent only in cases in which all of its subconstituents
have been found within the input string. This is particularly advantageous in
several cases in which partial analysis of a constituent cannot be completed
and in general in all cases of productions sharing some suffix of their
right-hand sides (even for different left-hand side nonterminals). Although the
two algorithms result in the same asymptotic time and space complexity, from a
practical perspective our algorithm improves the time and space requirements of
the original method, as shown by reported experimental results.
</dc:description>
 <dc:description>Comment: 12 pages, 1 Postscript figure, uses psfig.tex and llncs.sty</dc:description>
 <dc:date>1998-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9808017</dc:identifier>
 <dc:identifier>AI*IA 97: Advances in Artificial Intelligence, 5th Congress of the
  Italian Association for Artificial Intelligence, LNAI 1321, Springer Verlag,
  pages 84-95, 1997.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9809001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards an implementable dependency grammar</dc:title>
 <dc:creator>Jarvinen, Timo</dc:creator>
 <dc:creator>Tapanainen, Pasi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The aim of this paper is to define a dependency grammar framework which is
both linguistically motivated and computationally parsable. See the demo at
http://www.conexor.fi/analysers.html#testing
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>1998-09-01</dc:date>
 <dc:date>1998-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9809001</dc:identifier>
 <dc:identifier>in CoLing-ACL'98 workshop 'Processing of Dependency-Based
  Grammars', Kahane and Polguere (eds), p. 1-10, Montreal, Canada, 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9809002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some Ontological Principles for Designing Upper Level Lexical Resources</dc:title>
 <dc:creator>Guarino, Nicola</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The purpose of this paper is to explore some semantic problems related to the
use of linguistic ontologies in information systems, and to suggest some
organizing principles aimed to solve such problems. The taxonomic structure of
current ontologies is unfortunately quite complicated and hard to understand,
especially for what concerns the upper levels. I will focus here on the problem
of ISA overloading, which I believe is the main responsible of these
difficulties. To this purpose, I will carefully analyze the ontological nature
of the categories used in current upper-level structures, considering the
necessity of splitting them according to more subtle distinctions or the
opportunity of excluding them because of their limited organizational role.
</dc:description>
 <dc:description>Comment: 8 pages - gzipped postscript file - A4 format</dc:description>
 <dc:date>1998-09-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9809002</dc:identifier>
 <dc:identifier>in Proc. of First International Conference on Language Resources
  and Evaluation, Rubio, Gallardo, Castro, and Tejada (eds.), p. 527-534,
  Granada, Spain, 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cmp-lg/9809003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparison of WordNet and Roget's Taxonomy for Measuring Semantic
  Similarity</dc:title>
 <dc:creator>Hale, Michael Mc</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents the results of using Roget's International Thesaurus as
the taxonomy in a semantic similarity measurement task. Four similarity metrics
were taken from the literature and applied to Roget's The experimental
evaluation suggests that the traditional edge counting approach does
surprisingly well (a correlation of r=0.88 with a benchmark set of human
similarity judgements, with an upper bound of r=0.90 for human subjects
performing the same task.)
</dc:description>
 <dc:description>Comment: 6 pages, postscript</dc:description>
 <dc:date>1998-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cmp-lg/9809003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0001137</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The number of guards needed by a museum: A phase transition in vertex
  covering of random graphs</dc:title>
 <dc:creator>Weigt, Martin</dc:creator>
 <dc:creator>Hartmann, Alexander K.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this letter we study the NP-complete vertex cover problem on finite
connectivity random graphs. When the allowed size of the cover set is
decreased, a discontinuous transition in solvability and typical-case
complexity occurs. This transition is characterized by means of exact numerical
simulations as well as by analytical replica calculations. The replica
symmetric phase diagram is in excellent agreement with numerical findings up to
average connectivity $e$, where replica symmetry becomes locally unstable.
</dc:description>
 <dc:description>Comment: 4 pages, 3 eps-figures, new version to be published in Phys. Rev. Let</dc:description>
 <dc:date>2000-01-11</dc:date>
 <dc:date>2000-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0001137</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 84, 6118 (2000)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.84.6118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0002331</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From naive to sophisticated behavior in multiagents based financial
  market models</dc:title>
 <dc:creator>Mansilla, Ricardo</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Quantitative Finance - Trading and Market Microstructure</dc:subject>
 <dc:description>  We discuss the behavior of two magnitudes, physical complexity and mutual
information function of the outcome of a model of heterogeneous, inductive
rational agents inspired in the El Farol Bar problem and the Minority Game. The
first is a measure rooted in Kolmogorov-Chaitin theory and the second one a
measure related with information entropy of Shannon.
  We make extensive computer simulations, as result of which, we propose an
ansatz for physical complexity and establish the dependence of exponent of that
ansatz from the parameters of the model. We discuss the accuracy of our results
and the relationship with the behavior of mutual information function as a
measure of time correlations of agents choice.
</dc:description>
 <dc:description>Comment: 16 pages, 4 figures, submitted to Physica A</dc:description>
 <dc:date>2000-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0002331</dc:identifier>
 <dc:identifier>doi:10.1016/S0378-4371(00)00227-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0002469</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-equilibrium Surface Growth and Scalability of Parallel Algorithms
  for Large Asynchronous Systems</dc:title>
 <dc:creator>Korniss, G.</dc:creator>
 <dc:creator>Novotny, M. A.</dc:creator>
 <dc:creator>Toroczkai, Z.</dc:creator>
 <dc:creator>Rikvold, P. A.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  The scalability of massively parallel algorithms is a fundamental question in
computer science. We study the scalability and the efficiency of a conservative
massively parallel algorithm for discrete-event simulations where the discrete
events are Poisson arrivals. The parallel algorithm is applicable to a wide
range of problems, including dynamic Monte Carlo simulations for large
asynchronous systems with short-range interactions. The evolution of the
simulated time horizon is analogous to a growing and fluctuating surface, and
the efficiency of the algorithm corresponds to the density of local minima of
this surface. In one dimension we find that the steady state of the macroscopic
landscape is governed by the Edwards-Wilkinson Hamiltonian, which implies that
the algorithm is scalable. Preliminary results for higher-dimensional logical
topologies are discussed.
</dc:description>
 <dc:description>Comment: to appear in Computer Simulation Studies in Condensed Matter Physics
  XIII, edited by D.P. Landau, S.P. Lewis, and H.-B. Schuttler</dc:description>
 <dc:date>2000-02-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0002469</dc:identifier>
 <dc:identifier>Springer Proceedings in Physics, Vol. 86, Computer Simulation
  Studies in Condensed-Matter Physics XIII, edited by D.P. Landau, S.P. Lewis,
  and H.-B. Schuttler (Springer, Berlin, 2001) p. 183.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0006316</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical mechanics perspective on the phase transition in vertex
  covering finite-connectivity random graphs</dc:title>
 <dc:creator>Hartmann, Alexander K.</dc:creator>
 <dc:creator>Weigt, Martin</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The vertex-cover problem is studied for random graphs $G_{N,cN}$ having $N$
vertices and $cN$ edges. Exact numerical results are obtained by a
branch-and-bound algorithm. It is found that a transition in the coverability
at a $c$-dependent threshold $x=x_c(c)$ appears, where $xN$ is the cardinality
of the vertex cover. This transition coincides with a sharp peak of the typical
numerical effort, which is needed to decide whether there exists a cover with
$xN$ vertices or not. For small edge concentrations $c\ll 0.5$, a cluster
expansion is performed, giving very accurate results in this regime. These
results are extended using methods developed in statistical physics. The so
called annealed approximation reproduces a rigorous bound on $x_c(c)$ which was
known previously. The main part of the paper contains an application of the
replica method. Within the replica symmetric ansatz the threshold $x_c(c)$ and
the critical backbone size $b_c(c)$ can be calculated. For $c&lt;e/2$ the results
show an excellent agreement with the numerical findings. At average vertex
degree $2c=e$, an instability of the simple replica symmetric solution occurs.
</dc:description>
 <dc:description>Comment: 24 pages, 9 figures</dc:description>
 <dc:date>2000-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0006316</dc:identifier>
 <dc:identifier>Theoretical Computer Science 265, 199 (2001)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0009165</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Occam factors and model-independent Bayesian learning of continuous
  distributions</dc:title>
 <dc:creator>Nemenman, Ilya</dc:creator>
 <dc:creator>Bialek, William</dc:creator>
 <dc:subject>Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Learning of a smooth but nonparametric probability density can be regularized
using methods of Quantum Field Theory. We implement a field theoretic prior
numerically, test its efficacy, and show that the data and the phase space
factors arising from the integration over the model space determine the free
parameter of the theory (&quot;smoothness scale&quot;) self-consistently. This persists
even for distributions that are atypical in the prior and is a step towards a
model-independent theory for learning continuous distributions. Finally, we
point out that a wrong parameterization of a model family may sometimes be
advantageous for small data sets.
</dc:description>
 <dc:description>Comment: publication revisions: extended introduction, new references, other
  minor corrections; 6 pages, 6 figures, revtex</dc:description>
 <dc:date>2000-09-11</dc:date>
 <dc:date>2002-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0009165</dc:identifier>
 <dc:identifier>Phys. Rev. E, 65 (2), 2002</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.65.026137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0009417</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Typical solution time for a vertex-covering algorithm on
  finite-connectivity random graphs</dc:title>
 <dc:creator>Weigt, Martin</dc:creator>
 <dc:creator>Hartmann, Alexander K.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this letter, we analytically describe the typical solution time needed by
a backtracking algorithm to solve the vertex-cover problem on
finite-connectivity random graphs. We find two different transitions: The first
one is algorithm-dependent and marks the dynamical transition from linear to
exponential solution times. The second one gives the maximum computational
complexity, and is found exactly at the threshold where the system undergoes an
algorithm-independent phase transition in its solvability. Analytical results
are corroborated by numerical simulations.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, to appear in Phys. Rev. Lett</dc:description>
 <dc:date>2000-09-27</dc:date>
 <dc:date>2000-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0009417</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 86, 1658 (2001)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.86.1658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0010337</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization with Extremal Dynamics</dc:title>
 <dc:creator>Boettcher, S.</dc:creator>
 <dc:creator>Percus, A. G.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We explore a new general-purpose heuristic for finding high-quality solutions
to hard optimization problems. The method, called extremal optimization, is
inspired by self-organized criticality, a concept introduced to describe
emergent complexity in physical systems. Extremal optimization successively
replaces extremely undesirable variables of a single sub-optimal solution with
new, random ones. Large fluctuations ensue, that efficiently explore many local
optima. With only one adjustable parameter, the heuristic's performance has
proven competitive with more elaborate methods, especially near phase
transitions which are believed to coincide with the hardest instances. We use
extremal optimization to elucidate the phase transition in the 3-coloring
problem, and we provide independent confirmation of previously reported
extrapolations for the ground-state energy of +-J spin glasses in d=3 and 4.
</dc:description>
 <dc:description>Comment: 4 pages, RevTex4, 1 table and 3 ps-figures included, as to appear in
  PRL, related papers available at
  http://www.physics.emory.edu/faculty/boettcher/</dc:description>
 <dc:date>2000-10-23</dc:date>
 <dc:date>2001-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0010337</dc:identifier>
 <dc:identifier>Phys. Rev. Lett, 86 (2001) 5211</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.86.5211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0011181</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simplest random K-satisfiability problem</dc:title>
 <dc:creator>Ricci-Tersenghi, F.</dc:creator>
 <dc:creator>Weigt, M.</dc:creator>
 <dc:creator>Zecchina, R.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study a simple and exactly solvable model for the generation of random
satisfiability problems. These consist of $\gamma N$ random boolean constraints
which are to be satisfied simultaneously by $N$ logical variables. In
statistical-mechanics language, the considered model can be seen as a diluted
p-spin model at zero temperature. While such problems become extraordinarily
hard to solve by local search methods in a large region of the parameter space,
still at least one solution may be superimposed by construction. The
statistical properties of the model can be studied exactly by the replica
method and each single instance can be analyzed in polynomial time by a simple
global solution method. The geometrical/topological structures responsible for
dynamic and static phase transitions as well as for the onset of computational
complexity in local search method are thoroughly analyzed. Numerical analysis
on very large samples allows for a precise characterization of the critical
scaling behaviour.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures, to appear in Phys. Rev. E (Feb 2001). v2: minor
  errors and references corrected</dc:description>
 <dc:date>2000-11-10</dc:date>
 <dc:date>2000-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0011181</dc:identifier>
 <dc:identifier>Phys. Rev. E 63, 026702 (2001)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.63.026702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0103328</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact solutions for diluted spin glasses and optimization problems</dc:title>
 <dc:creator>Franz, S.</dc:creator>
 <dc:creator>Leone, M.</dc:creator>
 <dc:creator>Ricci-Tersenghi, F.</dc:creator>
 <dc:creator>Zecchina, R.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study the low temperature properties of p-spin glass models with finite
connectivity and of some optimization problems. Using a one-step functional
replica symmetry breaking Ansatz we can solve exactly the saddle-point
equations for graphs with uniform connectivity. The resulting ground state
energy is in perfect agreement with numerical simulations. For fluctuating
connectivity graphs, the same Ansatz can be used in a variational way: For
p-spin models (known as p-XOR-SAT in computer science) it provides the exact
configurational entropy together with the dynamical and static critical
connectivities (for p=3, \gamma_d=0.818 and \gamma_s=0.918 resp.), whereas for
hard optimization problems like 3-SAT or Bicoloring it provides new upper
bounds for their critical thresholds (\gamma_c^{var}=4.396 and
\gamma_c^{var}=2.149 resp.).
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure, accepted for publication in PRL</dc:description>
 <dc:date>2001-03-15</dc:date>
 <dc:date>2001-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0103328</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 87 (2001) 127209</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.87.127209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0104066</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond the Zipf-Mandelbrot law in quantitative linguistics</dc:title>
 <dc:creator>Montemurro, Marcelo A.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  In this paper the Zipf-Mandelbrot law is revisited in the context of
linguistics. Despite its widespread popularity the Zipf--Mandelbrot law can
only describe the statistical behaviour of a rather restricted fraction of the
total number of words contained in some given corpus. In particular, we focus
our attention on the important deviations that become statistically relevant as
larger corpora are considered and that ultimately could be understood as
salient features of the underlying complex process of language generation.
Finally, it is shown that all the different observed regimes can be accurately
encompassed within a single mathematical framework recently introduced by C.
Tsallis.
</dc:description>
 <dc:description>Comment: 6 pages and 7 figures; minor changes in text, added refereces</dc:description>
 <dc:date>2001-04-03</dc:date>
 <dc:date>2001-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0104066</dc:identifier>
 <dc:identifier>doi:10.1016/S0378-4371(01)00355-7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0104214</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extremal Optimization for Graph Partitioning</dc:title>
 <dc:creator>Boettcher, S.</dc:creator>
 <dc:creator>Percus, A. G.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Extremal optimization is a new general-purpose method for approximating
solutions to hard optimization problems. We study the method in detail by way
of the NP-hard graph partitioning problem. We discuss the scaling behavior of
extremal optimization, focusing on the convergence of the average run as a
function of runtime and system size. The method has a single free parameter,
which we determine numerically and justify using a simple argument. Our
numerical results demonstrate that on random graphs, extremal optimization
maintains consistent accuracy for increasing system sizes, with an
approximation error decreasing over runtime roughly as a power law t^(-0.4). On
geometrically structured graphs, the scaling of results from the average run
suggests that these are far from optimal, with large fluctuations between
individual trials. But when only the best runs are considered, results
consistent with theoretical arguments are recovered.
</dc:description>
 <dc:description>Comment: 34 pages, RevTex4, 1 table and 20 ps-figures included, related papers
  available at http://www.physics.emory.edu/faculty/boettcher/</dc:description>
 <dc:date>2001-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0104214</dc:identifier>
 <dc:identifier>Phys. Rev. E, 64 (2001) 026114</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.64.026114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0106096</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical mechanics of complex networks</dc:title>
 <dc:creator>Albert, Reka</dc:creator>
 <dc:creator>Barabasi, Albert-Laszlo</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Complex networks describe a wide range of systems in nature and society, much
quoted examples including the cell, a network of chemicals linked by chemical
reactions, or the Internet, a network of routers and computers connected by
physical links. While traditionally these systems were modeled as random
graphs, it is increasingly recognized that the topology and evolution of real
networks is governed by robust organizing principles. Here we review the recent
advances in the field of complex networks, focusing on the statistical
mechanics of network topology and dynamics. After reviewing the empirical data
that motivated the recent interest in networks, we discuss the main models and
analytical tools, covering random graphs, small-world and scale-free networks,
as well as the interplay between topology and the network's robustness against
failures and attacks.
</dc:description>
 <dc:description>Comment: 54 pages, submitted to Reviews of Modern Physics</dc:description>
 <dc:date>2001-06-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0106096</dc:identifier>
 <dc:identifier>Reviews of Modern Physics 74, 47 (2002)</dc:identifier>
 <dc:identifier>doi:10.1103/RevModPhys.74.47</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0107212</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intentional Walks on Scale Free Small Worlds</dc:title>
 <dc:creator>Puniyani, Amit R</dc:creator>
 <dc:creator>Lukose, Rajan M</dc:creator>
 <dc:creator>Huberman, Bernardo A</dc:creator>
 <dc:subject>Condensed Matter - Soft Condensed Matter</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  We present a novel algorithm that generates scale free small world graphs
such as those found in the World Wide Web,social and metabolic networks. We use
the generated graphs to study the dynamics of a realistic search strategy on
the graphs, and find that they can be navigated in a very short number of
steps.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures (10 eps files)</dc:description>
 <dc:date>2001-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0107212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0109121</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coordination of Decisions in a Spatial Agent Model</dc:title>
 <dc:creator>Schweitzer, Frank</dc:creator>
 <dc:creator>Zimmermann, Joerg</dc:creator>
 <dc:creator>Muehlenbein, Heinz</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  For a binary choice problem, the spatial coordination of decisions in an
agent community is investigated both analytically and by means of stochastic
computer simulations. The individual decisions are based on different local
information generated by the agents with a finite lifetime and disseminated in
the system with a finite velocity. We derive critical parameters for the
emergence of minorities and majorities of agents making opposite decisions and
investigate their spatial organization. We find that dependent on two essential
parameters describing the local impact and the spatial dissemination of
information, either a definite stable minority/majority relation
(single-attractor regime) or a broad range of possible values (multi-attractor
regime) occurs. In the latter case, the outcome of the decision process becomes
rather diverse and hard to predict, both with respect to the share of the
majority and their spatial distribution. We further investigate how a
dissemination of information on different time scales affects the outcome of
the decision process. We find that a more ``efficient'' information exchange
within a subpopulation provides a suitable way to stabilize their majority
status and to reduce ``diversity'' and uncertainty in the decision process.
</dc:description>
 <dc:description>Comment: submitted for publication in Physica A (31 pages incl. 17 multi-part
  figures)</dc:description>
 <dc:date>2001-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0109121</dc:identifier>
 <dc:identifier>Physica A, vol. 303, no. 1-2 (2002) pp. 189-216</dc:identifier>
 <dc:identifier>doi:10.1016/S0378-4371(01)00486-1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0109218</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropic analysis of the role of words in literary texts</dc:title>
 <dc:creator>Montemurro, Marcelo A.</dc:creator>
 <dc:creator>Zanette, Damian H.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Beyond the local constraints imposed by grammar, words concatenated in long
sequences carrying a complex message show statistical regularities that may
reflect their linguistic role in the message. In this paper, we perform a
systematic statistical analysis of the use of words in literary English
corpora. We show that there is a quantitative relation between the role of
content words in literary English and the Shannon information entropy defined
over an appropriate probability distribution. Without assuming any previous
knowledge about the syntactic structure of language, we are able to cluster
certain groups of words according to their specific role in the text.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures</dc:description>
 <dc:date>2001-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0109218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0109313</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extreme Value Statistics and Traveling Fronts: An Application to
  Computer Science</dc:title>
 <dc:creator>Majumdar, Satya N.</dc:creator>
 <dc:creator>Krapivsky, P. L.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the statistics of height and balanced height in the binary search
tree problem in computer science. The search tree problem is first mapped to a
fragmentation problem which is then further mapped to a modified directed
polymer problem on a Cayley tree. We employ the techniques of traveling fronts
to solve the polymer problem and translate back to derive exact asymptotic
properties in the original search tree problem. The second mapping allows us
not only to re-derive the already known results for random binary trees but to
obtain new exact results for search trees where the entries arrive according to
an arbitrary distribution, not necessarily randomly. Besides it allows us to
derive the asymptotic shape of the full probability distribution of height and
not just its moments. Our results are then generalized to $m$-ary search trees
with arbitrary distribution. An attempt has been made to make the article
accessible to both physicists and computer scientists.
</dc:description>
 <dc:description>Comment: 16 pages, two-column revtex</dc:description>
 <dc:date>2001-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0109313</dc:identifier>
 <dc:identifier>Phys. Rev. E 65, 036127 (2002)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.65.036127</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0110165</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Jamming Model for the Extremal Optimization Heuristic</dc:title>
 <dc:creator>Boettcher, S.</dc:creator>
 <dc:creator>Grigni, M.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Extremal Optimization, a recently introduced meta-heuristic for hard
optimization problems, is analyzed on a simple model of jamming. The model is
motivated first by the problem of finding lowest energy configurations for a
disordered spin system on a fixed-valence graph. The numerical results for the
spin system exhibit the same phenomena found in all earlier studies of extremal
optimization, and our analytical results for the model reproduce many of these
features.
</dc:description>
 <dc:description>Comment: 9 pages, RevTex4, 7 ps-figures included, as to appear in J. Phys. A,
  related papers available at http://www.physics.emory.edu/faculty/boettcher/</dc:description>
 <dc:date>2001-10-09</dc:date>
 <dc:date>2001-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0110165</dc:identifier>
 <dc:identifier>Journal of Physics A: Math. Gen., 35 (2002) 1109</dc:identifier>
 <dc:identifier>doi:10.1088/0305-4470/35/5/301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0111153</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hiding solutions in random satisfiability problems: A statistical
  mechanics approach</dc:title>
 <dc:creator>Barthel, W.</dc:creator>
 <dc:creator>Hartmann, A. K.</dc:creator>
 <dc:creator>Leone, M.</dc:creator>
 <dc:creator>Ricci-Tersenghi, F.</dc:creator>
 <dc:creator>Weigt, M.</dc:creator>
 <dc:creator>Zecchina, R.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  A major problem in evaluating stochastic local search algorithms for
NP-complete problems is the need for a systematic generation of hard test
instances having previously known properties of the optimal solutions. On the
basis of statistical mechanics results, we propose random generators of hard
and satisfiable instances for the 3-satisfiability problem (3SAT). The design
of the hardest problem instances is based on the existence of a first order
ferromagnetic phase transition and the glassy nature of excited states. The
analytical predictions are corroborated by numerical results obtained from
complete as well as stochastic local algorithms.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, revised version to app. in PRL</dc:description>
 <dc:date>2001-11-09</dc:date>
 <dc:date>2002-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0111153</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 88, 188701 (2002)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.88.188701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0112103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Going through Rough Times: from Non-Equilibrium Surface Growth to
  Algorithmic Scalability</dc:title>
 <dc:creator>Korniss, G.</dc:creator>
 <dc:creator>Novotny, M. A.</dc:creator>
 <dc:creator>Rikvold, P. A.</dc:creator>
 <dc:creator>Guclu, H.</dc:creator>
 <dc:creator>Toroczkai, Z.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Efficient and faithful parallel simulation of large asynchronous systems is a
challenging computational problem. It requires using the concept of local
simulated times and a synchronization scheme. We study the scalability of
massively parallel algorithms for discrete-event simulations which employ
conservative synchronization to enforce causality. We do this by looking at the
simulated time horizon as a complex evolving system, and we identify its
universal characteristics. We find that the time horizon for the conservative
parallel discrete-event simulation scheme exhibits Kardar-Parisi-Zhang-like
kinetic roughening. This implies that the algorithm is asymptotically scalable
in the sense that the average progress rate of the simulation approaches a
non-zero constant. It also implies, however, that there are diverging memory
requirements associated with such schemes.
</dc:description>
 <dc:description>Comment: to appear in the Proceedings of the MRS, Fall 2001</dc:description>
 <dc:date>2001-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0112103</dc:identifier>
 <dc:identifier>Materials Research Society Symposium Proceedings Series Vol. 700,
  pp. 297-308, 2002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0112142</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting search by rare events</dc:title>
 <dc:creator>Montanari, Andrea</dc:creator>
 <dc:creator>Zecchina, Riccardo</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Randomized search algorithms for hard combinatorial problems exhibit a large
variability of performances. We study the different types of rare events which
occur in such out-of-equilibrium stochastic processes and we show how they
cooperate in determining the final distribution of running times. As a
byproduct of our analysis we show how search algorithms are optimized by random
restarts.
</dc:description>
 <dc:description>Comment: 4 pages, 3 eps figures. References updated</dc:description>
 <dc:date>2001-12-08</dc:date>
 <dc:date>2001-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0112142</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 88, 178701 (2002)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.88.178701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0201139</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Long-range fractal correlations in literary corpora</dc:title>
 <dc:creator>Montemurro, Marcelo A.</dc:creator>
 <dc:creator>Pury, Pedro A.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  In this paper we analyse the fractal structure of long human-language records
by mapping large samples of texts onto time series. The particular mapping set
up in this work is inspired on linguistic basis in the sense that is retains
{\em the word} as the fundamental unit of communication. The results confirm
that beyond the short-range correlations resulting from syntactic rules acting
at sentence level, long-range structures emerge in large written language
samples that give rise to long-range correlations in the use of words.
</dc:description>
 <dc:description>Comment: to appear in Fractals</dc:description>
 <dc:date>2002-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0201139</dc:identifier>
 <dc:identifier>Fractals 10(4), 451-461 (2002)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0202190</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Threshold Disorder as a Source of Diverse and Complex Behavior in Random
  Nets</dc:title>
 <dc:creator>McGuire, Patrick C.</dc:creator>
 <dc:creator>Bohr, Henrik</dc:creator>
 <dc:creator>Clark, John W.</dc:creator>
 <dc:creator>Haschke, Robert</dc:creator>
 <dc:creator>Pershing, Chris</dc:creator>
 <dc:creator>Rafelski, Johann</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  We study the diversity of complex spatio-temporal patterns in the behavior of
random synchronous asymmetric neural networks (RSANNs). Special attention is
given to the impact of disordered threshold values on limit-cycle diversity and
limit-cycle complexity in RSANNs which have `normal' thresholds by default.
Surprisingly, RSANNs exhibit only a small repertoire of rather complex
limit-cycle patterns when all parameters are fixed. This repertoire of complex
patterns is also rather stable with respect to small parameter changes. These
two unexpected results may generalize to the study of other complex systems. In
order to reach beyond this seemingly-disabling `stable and small' aspect of the
limit-cycle repertoire of RSANNs, we have found that if an RSANN has threshold
disorder above a critical level, then there is a rapid increase of the size of
the repertoire of patterns. The repertoire size initially follows a power-law
function of the magnitude of the threshold disorder. As the disorder increases
further, the limit-cycle patterns themselves become simpler until at a second
critical level most of the limit cycles become simple fixed points.
Nonetheless, for moderate changes in the threshold parameters, RSANNs are found
to display specific features of behavior desired for rapidly-responding
processing systems: accessibility to a large set of complex patterns.
</dc:description>
 <dc:description>Comment: 20 pages, 14 figures, submitted to Neural Networks</dc:description>
 <dc:date>2002-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0202190</dc:identifier>
 <dc:identifier>Neural Networks,15(10), pp. 1243-1258 (2002)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0202383</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extended Comment on Language Trees and Zipping</dc:title>
 <dc:creator>Goodman, Joshua</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This is the extended version of a Comment submitted to Physical Review
Letters. I first point out the inappropriateness of publishing a Letter
unrelated to physics. Next, I give experimental results showing that the
technique used in the Letter is 3 times worse and 17 times slower than a simple
baseline. And finally, I review the literature, showing that the ideas of the
Letter are not novel. I conclude by suggesting that Physical Review Letters
should not publish Letters unrelated to physics.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2002-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0202383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0203227</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ising Model on Networks with an Arbitrary Distribution of Connections</dc:title>
 <dc:creator>Dorogovtsev, S. N.</dc:creator>
 <dc:creator>Goltsev, A. V.</dc:creator>
 <dc:creator>Mendes, J. F. F.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>High Energy Physics - Lattice</dc:subject>
 <dc:subject>High Energy Physics - Theory</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Nonlinear Sciences - Exactly Solvable and Integrable Systems</dc:subject>
 <dc:subject>Physics - Classical Physics</dc:subject>
 <dc:description>  We find the exact critical temperature $T_c$ of the nearest-neighbor
ferromagnetic Ising model on an `equilibrium' random graph with an arbitrary
degree distribution $P(k)$. We observe an anomalous behavior of the
magnetization, magnetic susceptibility and specific heat, when $P(k)$ is
fat-tailed, or, loosely speaking, when the fourth moment of the distribution
diverges in infinite networks. When the second moment becomes divergent, $T_c$
approaches infinity, the phase transition is of infinite order, and size effect
is anomalously strong.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2002-03-11</dc:date>
 <dc:date>2002-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0203227</dc:identifier>
 <dc:identifier>Phys.Rev.E66:016104,2002</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.66.016104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0203436</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropy estimation of symbol sequences</dc:title>
 <dc:creator>Sch&#xfc;rmann, Thomas</dc:creator>
 <dc:creator>Grassberger, Peter</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We discuss algorithms for estimating the Shannon entropy h of finite symbol
sequences with long range correlations. In particular, we consider algorithms
which estimate h from the code lengths produced by some compression algorithm.
Our interest is in describing their convergence with sequence length, assuming
no limits for the space and time complexities of the compression algorithms. A
scaling law is proposed for extrapolation from finite sample lengths. This is
applied to sequences of dynamical systems in non-trivial chaotic regimes, a 1-D
cellular automaton, and to written English texts.
</dc:description>
 <dc:description>Comment: 14 pages, 13 figures, 2 tables</dc:description>
 <dc:date>2002-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0203436</dc:identifier>
 <dc:identifier>CHAOS Vol. 6, No. 3 (1996) 414-427</dc:identifier>
 <dc:identifier>doi:10.1063/1.166191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0203591</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anticorrelations and subdiffusion in financial systems</dc:title>
 <dc:creator>Staliunas, Kestutis</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:description>  Statistical dynamics of financial systems is investigated, based on a model
of a randomly coupled equation system driven by a stochastic Langevin force.
Anticorrelations of price returns, and subdiffusion of prices is found from the
model, and and compared with those calculated from historical $/EURO exchange
rates.
</dc:description>
 <dc:date>2002-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0203591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0204102</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerated growth of networks</dc:title>
 <dc:creator>Dorogovtsev, S. N.</dc:creator>
 <dc:creator>Mendes, J. F. F.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In many real growing networks the mean number of connections per vertex
increases with time. The Internet, the Word Wide Web, collaboration networks,
and many others display this behavior. Such a growth can be called {\em
accelerated}. We show that this acceleration influences distribution of
connections and may determine the structure of a network. We discuss general
consequences of the acceleration and demonstrate its features applying simple
illustrating examples. In particular, we show that the accelerated growth
fairly well explains the structure of the Word Web (the network of interacting
words of human language). Also, we use the models of the accelerated growth of
networks to describe a wealth condensation transition in evolving societies.
</dc:description>
 <dc:description>Comment: 29 pages, 11 figures, a brief review of the accelerated growth
  including applications to econophysics, Contribution to `Handbook of Graphs
  and Networks: From the Genome to the Internet', eds. S. Bornholdt and H.G.
  Schuster (Wiley-VCH, Berlin, 2002), to be published</dc:description>
 <dc:date>2002-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0204102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0204111</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Principles of statistical mechanics of random networks</dc:title>
 <dc:creator>Dorogovtsev, S. N.</dc:creator>
 <dc:creator>Mendes, J. F. F.</dc:creator>
 <dc:creator>Samukhin, A. N.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>High Energy Physics - Lattice</dc:subject>
 <dc:subject>High Energy Physics - Theory</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  We develop a statistical mechanics approach for random networks with
uncorrelated vertices. We construct equilibrium statistical ensembles of such
networks and obtain their partition functions and main characteristics. We find
simple dynamical construction procedures that produce equilibrium uncorrelated
random graphs with an arbitrary degree distribution. In particular, we show
that in equilibrium uncorrelated networks, fat-tailed degree distributions may
exist only starting from some critical average number of connections of a
vertex, in a phase with a condensate of edges.
</dc:description>
 <dc:description>Comment: 14 pages, an extended version</dc:description>
 <dc:date>2002-04-04</dc:date>
 <dc:date>2002-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0204111</dc:identifier>
 <dc:identifier>Nucl.Phys. B666 (2003) 396-416</dc:identifier>
 <dc:identifier>doi:10.1016/S0550-3213(03)00504-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0204181</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Search in Unstructured Networks</dc:title>
 <dc:creator>Adamic, Lada A.</dc:creator>
 <dc:creator>Lukose, Rajan M.</dc:creator>
 <dc:creator>Huberman, Bernardo A.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We review a number of message-passing algorithms that can be used to search
through power-law networks. Most of these algorithms are meant to be
improvements for peer-to-peer file sharing systems, and some may also shed some
light on how unstructured social networks with certain topologies might
function relatively efficiently with local information. Like the networks that
they are designed for, these algorithms are completely decentralized, and they
exploit the power-law link distribution in the node degree. We demonstrate that
some of these search algorithms can work well on real Gnutella networks, scale
sub-linearly with the number of nodes, and may help reduce the network search
traffic that tends to cripple such networks.
</dc:description>
 <dc:description>Comment: v2 includes minor revisions: corrections to Fig. 8's caption and
  references. 23 pages, 10 figures, a review of local search strategies in
  unstructured networks, a contribution to `Handbook of Graphs and Networks:
  From the Genome to the Internet', eds. S. Bornholdt and H.G. Schuster
  (Wiley-VCH, Berlin, 2002), to be published</dc:description>
 <dc:date>2002-04-08</dc:date>
 <dc:date>2002-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0204181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0205034</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Transition in a Random Fragmentation Problem with Applications to
  Computer Science</dc:title>
 <dc:creator>Dean, David S.</dc:creator>
 <dc:creator>Majumdar, Satya N.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We study a fragmentation problem where an initial object of size x is broken
into m random pieces provided x&gt;x_0 where x_0 is an atomic cut-off.
Subsequently the fragmentation process continues for each of those daughter
pieces whose sizes are bigger than x_0. The process stops when all the
fragments have sizes smaller than x_0. We show that the fluctuation of the
total number of splitting events, characterized by the variance, generically
undergoes a nontrivial phase transition as one tunes the branching number m
through a critical value m=m_c. For m&lt;m_c, the fluctuations are Gaussian where
as for m&gt;m_c they are anomalously large and non-Gaussian. We apply this general
result to analyze two different search algorithms in computer science.
</dc:description>
 <dc:description>Comment: 5 pages RevTeX, 3 figures (.eps)</dc:description>
 <dc:date>2002-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0205034</dc:identifier>
 <dc:identifier>J. Phys. A. 35, L501 (2002)</dc:identifier>
 <dc:identifier>doi:10.1088/0305-4470/35/32/101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0205336</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Solution of a Drop-push Model for Percolation</dc:title>
 <dc:creator>Majumdar, Satya N.</dc:creator>
 <dc:creator>Dean, David S.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Motivated by a computer science algorithm known as `linear probing with
hashing' we study a new type of percolation model whose basic features include
a sequential `dropping' of particles on a substrate followed by their transport
via a `pushing' mechanism. Our exact solution in one dimension shows that,
unlike the ordinary random percolation model, the drop-push model has
nontrivial spatial correlations generated by the dynamics itself. The critical
exponents in the drop-push model are also different from that of the ordinary
percolation. The relevance of our results to computer science is pointed out.
</dc:description>
 <dc:description>Comment: 4 pages revtex, 2 eps figures</dc:description>
 <dc:date>2002-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0205336</dc:identifier>
 <dc:identifier>Phys. Rev. Lett., 89, 115701 (2002)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.89.115701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0206084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Internet topology at the router and autonomous system level</dc:title>
 <dc:creator>Vazquez, A.</dc:creator>
 <dc:creator>Pastor-Satorras, R.</dc:creator>
 <dc:creator>Vespignani, A.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We present a statistical analysis of different metrics characterizing the
topological properties of Internet maps, collected at two different resolution
scales: the router and the autonomous system level. The metrics we consider
allow us to confirm the presence of scale-free signatures in several
statistical distributions, as well as to show in a quantitative way the
hierarchical nature of the Internet. Our findings are relevant for the
development of more accurate Internet topology generators, which should
include, along with the scale-free properties of the connectivity distribution,
the hierarchical signatures unveiled in the present work.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, ACM style package</dc:description>
 <dc:date>2002-06-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0206084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0206410</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal network topologies for local search with congestion</dc:title>
 <dc:creator>Guimera, R.</dc:creator>
 <dc:creator>Arenas, A.</dc:creator>
 <dc:creator>Diaz-Guilera, A.</dc:creator>
 <dc:creator>Vega-Redondo, F.</dc:creator>
 <dc:creator>Cabrales, A.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The problem of searchability in decentralized complex networks is of great
importance in computer science, economy and sociology. We present a formalism
that is able to cope simultaneously with the problem of search and the
congestion effects that arise when parallel searches are performed, and obtain
expressions for the average search cost--written in terms of the search
algorithm and the topological properties of the network--both in presence and
abscence of congestion. This formalism is used to obtain optimal network
structures for a system using a local search algorithm. It is found that only
two classes of networks can be optimal: star-like configurations, when the
number of parallel searches is small, and homogeneous-isotropic configurations,
when the number of parallel searches is large.
</dc:description>
 <dc:description>Comment: 4 pages. Final version accepted in PRL</dc:description>
 <dc:date>2002-06-21</dc:date>
 <dc:date>2002-10-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0206410</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 89, 248701 (2002)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.89.248701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0207035</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational complexity arising from degree correlations in networks</dc:title>
 <dc:creator>Vazquez, Alexei</dc:creator>
 <dc:creator>Weigt, Martin</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We apply a Bethe-Peierls approach to statistical-mechanics models defined on
random networks of arbitrary degree distribution and arbitrary correlations
between the degrees of neighboring vertices. Using the NP-hard optimization
problem of finding minimal vertex covers on these graphs, we show that such
correlations may lead to a qualitatively different solution structure as
compared to uncorrelated networks. This results in a higher complexity of the
network in a computational sense: Simple heuristic algorithms fail to find a
minimal vertex cover in the highly correlated case, whereas uncorrelated
networks seem to be simple from the point of view of combinatorial
optimization.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure, accepted in Phys. Rev. E</dc:description>
 <dc:date>2002-07-01</dc:date>
 <dc:date>2002-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0207035</dc:identifier>
 <dc:identifier>Phys. Rev. E 67, 027101 (2003)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.67.027101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0207140</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alternative solutions to diluted p-spin models and XORSAT problems</dc:title>
 <dc:creator>Mezard, M.</dc:creator>
 <dc:creator>Ricci-Tersenghi, F.</dc:creator>
 <dc:creator>Zecchina, R.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We derive analytical solutions for p-spin models with finite connectivity at
zero temperature. These models are the statistical mechanics equivalent of
p-XORSAT problems in theoretical computer science. We give a full
characterization of the phase diagram: location of the phase transitions
(static and dynamic), together with a description of the clustering phenomenon
taking place in configurational space. We use two alternative methods: the
cavity approach and a rigorous derivation.
</dc:description>
 <dc:description>Comment: 14 pages, 14 figures. v3: small errors corrected, simpler notation
  used</dc:description>
 <dc:date>2002-07-04</dc:date>
 <dc:date>2002-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0207140</dc:identifier>
 <dc:identifier>J. Stat. Phys. 111, 505 (2003)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0208414</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Winner-Relaxing Self-Organizing Maps</dc:title>
 <dc:creator>Claussen, Jens Christian</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  A new family of self-organizing maps, the Winner-Relaxing Kohonen Algorithm,
is introduced as a generalization of a variant given by Kohonen in 1991. The
magnification behaviour is calculated analytically. For the original variant a
magnification exponent of 4/7 is derived; the generalized version allows to
steer the magnification in the wide range from exponent 1/2 to 1 in the
one-dimensional case, thus provides optimal mapping in the sense of information
theory. The Winner Relaxing Algorithm requires minimal extra computations per
learning step and is conveniently easy to implement.
</dc:description>
 <dc:description>Comment: 14 pages (6 figs included). To appear in Neural Computation</dc:description>
 <dc:date>2002-08-21</dc:date>
 <dc:date>2004-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0208414</dc:identifier>
 <dc:identifier>Neural Computation 17 (5), 996-1009 (2005)</dc:identifier>
 <dc:identifier>doi:10.1162/0899766053491922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0208460</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coloring random graphs</dc:title>
 <dc:creator>Mulet, R.</dc:creator>
 <dc:creator>Pagnani, A.</dc:creator>
 <dc:creator>Weigt, M.</dc:creator>
 <dc:creator>Zecchina, R.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study the graph coloring problem over random graphs of finite average
connectivity $c$. Given a number $q$ of available colors, we find that graphs
with low connectivity admit almost always a proper coloring whereas graphs with
high connectivity are uncolorable. Depending on $q$, we find the precise value
of the critical average connectivity $c_q$. Moreover, we show that below $c_q$
there exist a clustering phase $c\in [c_d,c_q]$ in which ground states
spontaneously divide into an exponential number of clusters and where the
proliferation of metastable states is responsible for the onset of complexity
in local search algorithms.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure, version to app. in PRL</dc:description>
 <dc:date>2002-08-23</dc:date>
 <dc:date>2002-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0208460</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 89, 268701 (2002)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.89.268701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0208488</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Prospects of Chaos Aware Traffic Modeling</dc:title>
 <dc:creator>Fekete, A.</dc:creator>
 <dc:creator>Marodi, M.</dc:creator>
 <dc:creator>Vattay, G.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  In this paper the chaotic properties of the TCP congestion avoidance
mechanism are investigated. The analysis focuses on the origin of the complex
behavior appearing in deterministic TCP/IP networks. From the traffic modeling
point of view the understanding of the mechanism generating chaos is essential,
since present models are unable to cope with this phenomena. Using the basic
tools of chaos theory in our study, the main characteristics of chaotic
dynamics are revealed. The dynamics of packet loss events is studied by a
simple symbolic description. The cellular structure of the phase space of
congestion windows is shown. This implies periodic behavior for large time
scales. Chaotic behavior in short time scales and periodicity for larger times
makes it necessary to develop models that account for both. Thus a simple model
that describes the congestion window dynamics according to fluid equations, but
handles the packet loss events separately is introduced. This model can
reproduce the basic features observed in realistic packet level simulations.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2002-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0208488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0209111</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approaches to Network Classification</dc:title>
 <dc:creator>Gudkov, Vladimir</dc:creator>
 <dc:creator>Johnson, Joseph E.</dc:creator>
 <dc:creator>Nussinov, Shmuel</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  We introduce a novel approach to description of networks/graphs. It is based
on an analogue physical model which is dynamically evolved. This evolution
depends on the connectivity matrix and readily brings out many qualitative
features of the graph.
</dc:description>
 <dc:description>Comment: RevTeX4</dc:description>
 <dc:date>2002-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0209111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0209112</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph equivalence and characterization via a continuous evolution of a
  physical analog</dc:title>
 <dc:creator>Gudkov, Vladimir</dc:creator>
 <dc:creator>Nussinov, Shmuel</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  A general novel approach mapping discrete, combinatorial, graph-theoretic
problems onto ``physical'' models - namely $n$ simplexes in $n-1$ dimensions -
is applied to the graph equivalence problem. It is shown to solve this long
standing problem in polynomial, short, time.
</dc:description>
 <dc:description>Comment: RevTeX4</dc:description>
 <dc:date>2002-09-04</dc:date>
 <dc:date>2002-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0209112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0209419</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Approach Applied to the Largest Clique Problem</dc:title>
 <dc:creator>Gudkov, Vladimir</dc:creator>
 <dc:creator>Nussinov, Shmuel</dc:creator>
 <dc:creator>Nussinov, Zohar</dc:creator>
 <dc:subject>Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  A novel approach to complex problems has been previously applied to graph
classification and the graph equivalence problem. Here we apply it to the NP
complete problem of finding the largest perfect clique within a graph $G$.
</dc:description>
 <dc:description>Comment: 20 pages, 15 figures</dc:description>
 <dc:date>2002-09-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0209419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0211605</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolution of Cooperation in a Spatial Prisoner's Dilemma</dc:title>
 <dc:creator>Schweitzer, Frank</dc:creator>
 <dc:creator>Behera, Laxmidhar</dc:creator>
 <dc:creator>Muehlenbein, Heinz</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:description>  We investigate the spatial distribution and the global frequency of agents
who can either cooperate or defect. The agent interaction is described by a
deterministic, non-iterated prisoner's dilemma game, further each agent only
locally interacts with his neighbors. Based on a detailed analysis of the local
payoff structures we derive critical conditions for the invasion or the spatial
coexistence of cooperators and defectors. These results are concluded in a
phase diagram that allows to identify five regimes, each characterized by a
distinct spatiotemporal dynamics and a corresponding final spatial structure.
In addition to the complete invasion of defectors, we find coexistence regimes
with either a majority of cooperators in large spatial domains, or a minority
of cooperators organized in small non-stationary domains or in small clusters.
The analysis further allowed a verification of computer simulation results by
Nowak and May (1993). Eventually, we present simulation results of a true
5-person game on a lattice. This modification leads to non-uniform spatial
interactions that may even enhance the effect of cooperation. Keywords:
Prisoner's dilemma; cooperation; spatial 5-person game
</dc:description>
 <dc:description>Comment: 33 pages, 22 multipart figures, for related papers see
  http://www.ais.fraunhofer.de/~frank/papers.html</dc:description>
 <dc:date>2002-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0211605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0212451</identifier>
 <datestamp>2010-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constraint Satisfaction by Survey Propagation</dc:title>
 <dc:creator>Braunstein, A.</dc:creator>
 <dc:creator>Mezard, M.</dc:creator>
 <dc:creator>Weigt, M.</dc:creator>
 <dc:creator>Zecchina, R.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Survey Propagation is an algorithm designed for solving typical instances of
random constraint satisfiability problems. It has been successfully tested on
random 3-SAT and random $G(n,\frac{c}{n})$ graph 3-coloring, in the hard region
of the parameter space. Here we provide a generic formalism which applies to a
wide class of discrete Constraint Satisfaction Problems.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2002-12-18</dc:date>
 <dc:date>2003-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0212451</dc:identifier>
 <dc:identifier>Advances in Neural Information Processing Systems. Vol 9. Oxford
  University Press; 2005. 424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0301035</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scaling and Universality in Continuous Length Combinatorial Optimization</dc:title>
 <dc:creator>Aldous, David</dc:creator>
 <dc:creator>Percus, Allon G.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We consider combinatorial optimization problems defined over random
ensembles, and study how solution cost increases when the optimal solution
undergoes a small perturbation delta. For the minimum spanning tree, the
increase in cost scales as delta^2; for the mean-field and Euclidean minimum
matching and traveling salesman problems in dimension d&gt;=2, the increase scales
as delta^3; this is observed in Monte Carlo simulations in d=2,3,4 and in
theoretical analysis of a mean-field model. We speculate that the scaling
exponent could serve to classify combinatorial optimization problems into a
small number of distinct categories, similar to universality classes in
statistical physics.
</dc:description>
 <dc:description>Comment: 5 pages; 3 figures</dc:description>
 <dc:date>2003-01-03</dc:date>
 <dc:date>2003-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0301035</dc:identifier>
 <dc:identifier>doi:10.1073/pnas.1635191100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0301271</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving satisfiability problems by fluctuations: The dynamics of
  stochastic local search algorithms</dc:title>
 <dc:creator>Barthel, Wolfgang</dc:creator>
 <dc:creator>Hartmann, Alexander K.</dc:creator>
 <dc:creator>Weigt, Martin</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Stochastic local search algorithms are frequently used to numerically solve
hard combinatorial optimization or decision problems. We give numerical and
approximate analytical descriptions of the dynamics of such algorithms applied
to random satisfiability problems. We find two different dynamical regimes,
depending on the number of constraints per variable: For low constraintness,
the problems are solved efficiently, i.e. in linear time. For higher
constraintness, the solution times become exponential. We observe that the
dynamical behavior is characterized by a fast equilibration and fluctuations
around this equilibrium. If the algorithm runs long enough, an exponentially
rare fluctuation towards a solution appears.
</dc:description>
 <dc:description>Comment: 21 pages, 18 figures, revised version, to app. in PRE (2003)</dc:description>
 <dc:date>2003-01-15</dc:date>
 <dc:date>2003-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0301271</dc:identifier>
 <dc:identifier>Phys. Rev. E 67, 066104 (2003)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.67.066104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0301272</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relaxation and Metastability in the RandomWalkSAT search procedure</dc:title>
 <dc:creator>Semerjian, Guilhem</dc:creator>
 <dc:creator>Monasson, Remi</dc:creator>
 <dc:subject>Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  An analysis of the average properties of a local search resolution procedure
for the satisfaction of random Boolean constraints is presented. Depending on
the ratio alpha of constraints per variable, resolution takes a time T_res
growing linearly (T_res \sim tau(alpha) N, alpha &lt; alpha_d) or exponentially
(T_res \sim exp(N zeta(alpha)), alpha &gt; alpha_d) with the size N of the
instance. The relaxation time tau(alpha) in the linear phase is calculated
through a systematic expansion scheme based on a quantum formulation of the
evolution operator. For alpha &gt; alpha_d, the system is trapped in some
metastable state, and resolution occurs from escape from this state through
crossing of a large barrier. An annealed calculation of the height zeta(alpha)
of this barrier is proposed. The polynomial/exponentiel cross-over alpha_d is
not related to the onset of clustering among solutions.
</dc:description>
 <dc:description>Comment: 23 pages, 11 figures. A mistake in sec. IV.B has been corrected</dc:description>
 <dc:date>2003-01-15</dc:date>
 <dc:date>2003-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0301272</dc:identifier>
 <dc:identifier>Phys. Rev. E 67, 066103 (2003)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.67.066103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0301307</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonextensive statistical mechanics and economics</dc:title>
 <dc:creator>Tsallis, Constantino</dc:creator>
 <dc:creator>Anteneodo, Celia</dc:creator>
 <dc:creator>Borland, Lisa</dc:creator>
 <dc:creator>Osorio, Roberto</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:description>  Ergodicity, this is to say, dynamics whose time averages coincide with
ensemble averages, naturally leads to Boltzmann-Gibbs (BG) statistical
mechanics, hence to standard thermodynamics. This formalism has been at the
basis of an enormous success in describing, among others, the particular
stationary state corresponding to thermal equilibrium. There are, however, vast
classes of complex systems which accomodate quite badly, or even not at all,
within the BG formalism. Such dynamical systems exhibit, in one way or another,
nonergodic aspects. In order to be able to theoretically study at least some of
these systems, a formalism was proposed 14 years ago, which is sometimes
referred to as nonextensive statistical mechanics. We briefly introduce this
formalism, its foundations and applications. Furthermore, we provide some
bridging to important economical phenomena, such as option pricing, return and
volume distributions observed in the financial markets, and the fascinating and
ubiquitous concept of risk aversion. One may summarize the whole approach by
saying that BG statistical mechanics is based on the entropy $S_{BG}=-k \sum_i
p_i \ln p_i$, and typically provides {\it exponential laws} for describing
stationary states and basic time-dependent phenomena, while nonextensive
statistical mechanics is instead based on the entropic form
$S_q=k(1-\sum_ip_i^q)/(q-1)$ (with $S_1=S_{BG}$), and typically provides, for
the same type of description, (asymptotic) {\it power laws}.
</dc:description>
 <dc:description>Comment: 6 pages and 6 figures. Contribution to the International Econophysics
  Conference, held in Bali, Indonesia (29-31 August 2002). To appear in Physica
  A. It includes a partial reply to a recent criticism by D.H. Zanette and M.A.
  Montemurro, cond-mat/0212327</dc:description>
 <dc:date>2003-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0301307</dc:identifier>
 <dc:identifier>Physica A 324, 89 (2003).</dc:identifier>
 <dc:identifier>doi:10.1016/S0378-4371(03)00042-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0301459</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collectives for the Optimal Combination of Imperfect Objects</dc:title>
 <dc:creator>Tumer, Kagan</dc:creator>
 <dc:creator>Wolpert, David</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  In this letter we summarize some recent theoretical work on the design of
collectives, i.e., of systems containing many agents, each of which can be
viewed as trying to maximize an associated private utility, where there is also
a world utility rating the behavior of that overall system that the designer of
the collective wishes to optimize. We then apply algorithms based on that work
on a recently suggested testbed for such optimization problems (Challet &amp;
Johnson, PRL, vol 89, 028701 2002). This is the problem of finding the
combination of imperfect nano-scale objects that results in the best aggregate
object. We present experimental results showing that these algorithms
outperform conventional methods by more than an order of magnitude in this
domain.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2003-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0301459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0302050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Suppressing Roughness of Virtual Times in Parallel Discrete-Event
  Simulations</dc:title>
 <dc:creator>Korniss, G.</dc:creator>
 <dc:creator>Novotny, M. A.</dc:creator>
 <dc:creator>Guclu, H.</dc:creator>
 <dc:creator>Toroczkai, Z.</dc:creator>
 <dc:creator>Rikvold, P. A.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  In a parallel discrete-event simulation (PDES) scheme, tasks are distributed
among processing elements (PEs), whose progress is controlled by a
synchronization scheme. For lattice systems with short-range interactions, the
progress of the conservative PDES scheme is governed by the Kardar-Parisi-Zhang
equation from the theory of non-equilibrium surface growth. Although the
simulated (virtual) times of the PEs progress at a nonzero rate, their standard
deviation (spread) diverges with the number of PEs, hindering efficient data
collection. We show that weak random interactions among the PEs can make this
spread nondivergent. The PEs then progress at a nonzero, near-uniform rate
without requiring global synchronizations.
</dc:description>
 <dc:date>2003-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0302050</dc:identifier>
 <dc:identifier>Science 299, 677 (2003)</dc:identifier>
 <dc:identifier>doi:10.1126/science.1079382</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0302536</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Diagram for the Constrained Integer Partitioning Problem</dc:title>
 <dc:creator>Borgs, C.</dc:creator>
 <dc:creator>Chayes, J. T.</dc:creator>
 <dc:creator>Mertens, S.</dc:creator>
 <dc:creator>Pittel, B.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We consider the problem of partitioning $n$ integers into two subsets of
given cardinalities such that the discrepancy, the absolute value of the
difference of their sums, is minimized. The integers are i.i.d. random
variables chosen uniformly from the set $\{1,...,M\}$. We study how the typical
behavior of the optimal partition depends on $n,M$ and the bias $s$, the
difference between the cardinalities of the two subsets in the partition. In
particular, we rigorously establish this typical behavior as a function of the
two parameters $\kappa:=n^{-1}\log_2M$ and $b:=|s|/n$ by proving the existence
of three distinct ``phases'' in the $\kappa b$-plane, characterized by the
value of the discrepancy and the number of optimal solutions: a ``perfect
phase'' with exponentially many optimal solutions with discrepancy 0 or 1; a
``hard phase'' with minimal discrepancy of order $Me^{-\Theta(n)}$; and a
``sorted phase'' with an unique optimal partition of order $Mn$, obtained by
putting the $(s+n)/2$ smallest integers in one subset. Our phase diagram covers
all but a relatively small region in the $\kappa b$-plane. We also show that
the three phases can be alternatively characterized by the number of basis
solutions of the associated linear programming problem, and by the fraction of
these basis solutions whose $\pm 1$-valued components form optimal integer
partitions of the subproblem with the corresponding weights. We show in
particular that this fraction is one in the sorted phase, and exponentially
small in both the perfect and hard phases, and strictly exponentially smaller
in the hard phase than in the perfect phase. Open problems are discussed, and
numerical experiments are presented.
</dc:description>
 <dc:description>Comment: 62 pages, 8 figures</dc:description>
 <dc:date>2003-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0302536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0303089</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiplicative point process as a model of trading activity</dc:title>
 <dc:creator>Gontis, Vygintas</dc:creator>
 <dc:creator>Kaulakys, Bronislovas</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Spectral Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>Quantitative Finance - Trading and Market Microstructure</dc:subject>
 <dc:description>  Signals consisting of a sequence of pulses show that inherent origin of the
1/f noise is a Brownian fluctuation of the average interevent time between
subsequent pulses of the pulse sequence. In this paper we generalize the model
of interevent time to reproduce a variety of self-affine time series exhibiting
power spectral density S(f) scaling as a power of the frequency f. Furthermore,
we analyze the relation between the power-law correlations and the origin of
the power-law probability distribution of the signal intensity. We introduce a
stochastic multiplicative model for the time intervals between point events and
analyze the statistical properties of the signal analytically and numerically.
Such model system exhibits power-law spectral density S(f)~1/f**beta for
various values of beta, including beta=1/2, 1 and 3/2. Explicit expressions for
the power spectra in the low frequency limit and for the distribution density
of the interevent time are obtained. The counting statistics of the events is
analyzed analytically and numerically, as well. The specific interest of our
analysis is related with the financial markets, where long-range correlations
of price fluctuations largely depend on the number of transactions. We analyze
the spectral density and counting statistics of the number of transactions. The
model reproduces spectral properties of the real markets and explains the
mechanism of power-law distribution of trading activity. The study provides
evidence that the statistical properties of the financial markets are enclosed
in the statistics of the time interval between trades. A multiplicative point
process serves as a consistent model generating this statistics.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures</dc:description>
 <dc:date>2003-03-05</dc:date>
 <dc:date>2004-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0303089</dc:identifier>
 <dc:identifier>Gontis V., Kaulakys B., Physica A 343 (2004) 505-514</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2004.05.080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0304132</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Causalities of the Taiwan Stock Market</dc:title>
 <dc:creator>Ting, Juhi-Lian Julian</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:description>  Volatility, fitting with first order Landau expansion, stationarity, and
causality of the Taiwan stock market (TAIEX) are investigated based on daily
records. Instead of consensuses that consider stock market index change as a
random time series we propose the market change as a dual time series consists
of the index and the corresponding volume. Therefore, causalities between these
two time series are investigated.
</dc:description>
 <dc:description>Comment: 8 pages, 15 figures</dc:description>
 <dc:date>2003-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0304132</dc:identifier>
 <dc:identifier>Physica A 324, 285-295 (2003)</dc:identifier>
 <dc:identifier>doi:10.1016/S0378-4371(02)01842-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0305097</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Traveling Front Solutions to Directed Diffusion Limited Aggregation,
  Digital Search Trees and the Lempel-Ziv Data Compression Algorithm</dc:title>
 <dc:creator>Majumdar, Satya N.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We use the traveling front approach to derive exact asymptotic results for
the statistics of the number of particles in a class of directed diffusion
limited aggregation models on a Cayley tree. We point out that some aspects of
these models are closely connected to two different problems in computer
science, namely the digital search tree problem in data structures and the
Lempel-Ziv algorithm for data compression. The statistics of the number of
particles studied here is related to the statistics of height in digital search
trees which, in turn, is related to the statistics of the length of the longest
word formed by the Lempel-Ziv algorithm. Implications of our results to these
computer science problems are pointed out.
</dc:description>
 <dc:description>Comment: Revtex, 11 pages, 3 .eps figures included</dc:description>
 <dc:date>2003-05-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0305097</dc:identifier>
 <dc:identifier>Phys. Rev. E 68, 026103 (2003)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.68.026103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0305508</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural network modeling of data with gaps: method of principal curves,
  Carleman's formula, and other</dc:title>
 <dc:creator>Gorban, A. N.</dc:creator>
 <dc:creator>Rossiev, A. A.</dc:creator>
 <dc:creator>Wunsch II, D. C.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  A method of modeling data with gaps by a sequence of curves has been
developed. The new method is a generalization of iterative construction of
singular expansion of matrices with gaps. Under discussion are three versions
of the method featuring clear physical interpretation: linear - modeling the
data by a sequence of linear manifolds of small dimension; quasilinear -
constructing &quot;principal curves: (or &quot;principal surfaces&quot;), univalently
projected on the linear principal components; essentially non-linear - based on
constructing &quot;principal curves&quot;: (principal strings and beams) employing the
variation principle; the iteration implementation of this method is close to
Kohonen self-organizing maps. The derived dependencies are extrapolated by
Carleman's formulas. The method is interpreted as a construction of neural
network conveyor designed to solve the following problems: to fill gaps in
data; to repair data - to correct initial data values in such a way as to make
the constructed models work best; to construct a calculator to fill gaps in the
data line fed to the input.
</dc:description>
 <dc:description>Comment: 28 pages, 7 figures,The talk was given at the USA-NIS Neurocomputing
  opportunities workshop, Washington DC, July 1999 (Associated with IJCNN'99)</dc:description>
 <dc:date>2003-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0305508</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0305527</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Back-propagation of accuracy</dc:title>
 <dc:creator>Senashova, M. Yu.</dc:creator>
 <dc:creator>Gorban, A. N.</dc:creator>
 <dc:creator>Wunsch II, D. C.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper we solve the problem: how to determine maximal allowable
errors, possible for signals and parameters of each element of a network
proceeding from the condition that the vector of output signals of the network
should be calculated with given accuracy? &quot;Back-propagation of accuracy&quot; is
developed to solve this problem. The calculation of allowable errors for each
element of network by back-propagation of accuracy is surprisingly similar to a
back-propagation of error, because it is the backward signals motion, but at
the same time it is very different because the new rules of signals
transformation in the passing back through the elements are different. The
method allows us to formulate the requirements to the accuracy of calculations
and to the realization of technical devices, if the requirements to the
accuracy of output signals of the network are known.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures, The talk given on ICNN97 (The 1997 IEEE
  International Conference on Neural Networks, Houston, USA)</dc:description>
 <dc:date>2003-05-22</dc:date>
 <dc:date>2004-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0305527</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0305575</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software systems as complex networks: structure, function, and
  evolvability of software collaboration graphs</dc:title>
 <dc:creator>Myers, C. R.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Software systems emerge from mere keystrokes to form intricate functional
networks connecting many collaborating modules, objects, classes, methods, and
subroutines. Building on recent advances in the study of complex networks, I
have examined software collaboration graphs contained within several
open-source software systems, and have found them to reveal scale-free,
small-world networks similar to those identified in other technological,
sociological, and biological systems. I present several measures of these
network topologies, and discuss their relationship to software engineering
practices. I also present a simple model of software system evolution based on
refactoring processes which captures some of the salient features of the
observed systems. Some implications of object-oriented design for questions
about network robustness, evolvability, degeneracy, and organization are
discussed in the wake of these findings.
</dc:description>
 <dc:description>Comment: 16 pages, 8 figures; changed content, corrected typos</dc:description>
 <dc:date>2003-05-23</dc:date>
 <dc:date>2003-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0305575</dc:identifier>
 <dc:identifier>Phys. Rev. E 68, 046116 (2003)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.68.046116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0305582</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Tomography of Networks and Multicast Trees</dc:title>
 <dc:creator>Cohen, R.</dc:creator>
 <dc:creator>Dolev, D.</dc:creator>
 <dc:creator>Havlin, S.</dc:creator>
 <dc:creator>Kalisky, T.</dc:creator>
 <dc:creator>Mokryn, O.</dc:creator>
 <dc:creator>Shavitt, Y.</dc:creator>
 <dc:subject>Condensed Matter</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper we model the tomography of scale free networks by studying the
structure of layers around an arbitrary network node. We find, both
analytically and empirically, that the distance distribution of all nodes from
a specific network node consists of two regimes. The first is characterized by
rapid growth, and the second decays exponentially. We also show that the nodes
degree distribution at each layer is a power law with an exponential cut-off.
We obtain similar results for the layers surrounding the root of multicast
trees cut from such networks, as well as the Internet. All of our results were
obtained both analytically and on empirical Interenet data.
</dc:description>
 <dc:date>2003-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0305582</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.74.066108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0305681</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Seven clusters in genomic triplet distributions</dc:title>
 <dc:creator>Gorban, A. N.</dc:creator>
 <dc:creator>Zinovyev, A. Yu.</dc:creator>
 <dc:creator>Popova, T. G.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:description>  In several recent papers new gene-detection algorithms were proposed for
detecting protein-coding regions without requiring learning dataset of already
known genes. The fact that unsupervised gene-detection is possible closely
connected to existence of a cluster structure in oligomer frequency
distributions. In this paper we study cluster structure of several genomes in
the space of their triplet frequencies, using pure data exploration strategy.
Several complete genomic sequences were analyzed, using visualization of tables
of triplet frequencies in a sliding window. The distribution of 64-dimensional
vectors of triplet frequencies displays a well-detectable cluster structure.
The structure was found to consist of seven clusters, corresponding to
protein-coding information in three possible phases in one of the two
complementary strands and in the non-coding regions with high accuracy (higher
than 90% on the nucleotide level). Visualizing and understanding the structure
allows to analyze effectively performance of different gene-prediction tools.
Since the method does not require extraction of ORFs, it can be applied even
for unassembled genomes. The information content of the triplet distributions
and the validity of the mean-field models are analysed.
</dc:description>
 <dc:description>Comment: Correction of URL. 16 pages, 5 figures. The software and datasets are
  available at http://www.ihes.fr/~zinovyev/bullet and
  http://www.ihes.fr/~zinovyev/7clusters Paper also available at
  http://www.bioinfo.de/isb/2003/03/0039</dc:description>
 <dc:date>2003-05-29</dc:date>
 <dc:date>2004-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0305681</dc:identifier>
 <dc:identifier>In Silico Biology, 3 (2003), 0039, 471-482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0306222</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Update statistics in conservative parallel discrete event simulations of
  asynchronous systems</dc:title>
 <dc:creator>Kolakowska, A.</dc:creator>
 <dc:creator>Novotny, M. A.</dc:creator>
 <dc:creator>Rikvold, Per Arne</dc:creator>
 <dc:subject>Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.6</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:subject>B.4.4</dc:subject>
 <dc:description>  We model the performance of an ideal closed chain of L processing elements
that work in parallel in an asynchronous manner. Their state updates follow a
generic conservative algorithm. The conservative update rule determines the
growth of a virtual time surface. The physics of this growth is reflected in
the utilization (the fraction of working processors) and in the interface
width. We show that it is possible to nake an explicit connection between the
utilization and the macroscopic structure of the virtual time interface. We
exploit this connection to derive the theoretical probability distribution of
updates in the system within an approximate model. It follows that the
theoretical lower bound for the computational speed-up is s=(L+1)/4 for L&gt;3.
Our approach uses simple statistics to count distinct surface configuration
classes consistent with the model growth rule. It enables one to compute
analytically microscopic properties of an interface, which are unavailable by
continuum methods.
</dc:description>
 <dc:description>Comment: 15 pages, 12 figures</dc:description>
 <dc:date>2003-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0306222</dc:identifier>
 <dc:identifier>Phys. Rev. E 68, 046705 (2003)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.68.046705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0306509</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bug propagation and debugging in asymmetric software structures</dc:title>
 <dc:creator>Challet, Damien</dc:creator>
 <dc:creator>Lombardoni, Andrea</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Software dependence networks are shown to be scale-free and asymmetric. We
then study how software components are affected by the failure of one of them,
and the inverse problem of locating the faulty component. Software at all
levels is fragile with respect to the failure of a random single component.
Locating a faulty component is easy if the failures only affect their nearest
neighbors, while it is hard if the failures propagate further.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures</dc:description>
 <dc:date>2003-06-19</dc:date>
 <dc:date>2003-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0306509</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.70.046109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0306511</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Closed source versus open source in a model of software bug dynamics</dc:title>
 <dc:creator>Challet, Damien</dc:creator>
 <dc:creator>Du, Yann Le</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  We introduce a simple microscopic description of software bug dynamics where
users, programmers and a maintainer interact through a given program, with a
particular emphasis on bug creation, detection and fixing. When the program is
written from scratch, the first phase of development is characterized by a fast
decline of the number of bugs, followed by a slow phase where most bugs have
been fixed, hence, are hard to find. Releasing immediately bug fixes speeds up
the debugging process, which substantiates bazaar open-source methodology. We
provide a mathematical analysis that supports our numerical simulations.
Finally, we apply our model to Linux history and determine the existence of a
lower bound to the quality of its programmers.
</dc:description>
 <dc:description>Comment: 13 pages, 8 figures. Better introduction of the model. New section of
  analytical results. Added a discussion on how to fit the model to real data.
  To appear in International Journal of Reliability, Quality and Safety
  Engineering</dc:description>
 <dc:date>2003-06-19</dc:date>
 <dc:date>2005-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0306511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0306609</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Signatures of small-world and scale-free properties in large computer
  programs</dc:title>
 <dc:creator>de Moura, Alessandro P. S.</dc:creator>
 <dc:creator>Lai, Ying-Cheng</dc:creator>
 <dc:creator>Motter, Adilson E.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - General Literature</dc:subject>
 <dc:description>  A large computer program is typically divided into many hundreds or even
thousands of smaller units, whose logical connections define a network in a
natural way. This network reflects the internal structure of the program, and
defines the ``information flow'' within the program. We show that, (1) due to
its growth in time this network displays a scale-free feature in that the
probability of the number of links at a node obeys a power-law distribution,
and (2) as a result of performance optimization of the program the network has
a small-world structure. We believe that these features are generic for large
computer programs. Our work extends the previous studies on growing networks,
which have mostly been for physical networks, to the domain of computer
software.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure, to appear in Phys. Rev. E</dc:description>
 <dc:date>2003-06-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0306609</dc:identifier>
 <dc:identifier>Phys. Rev. E 68, 017102 (2003)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.68.017102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0307058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite size scaling approach to dynamic storage allocation problem</dc:title>
 <dc:creator>Seyed-allaei, Hamed</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  It is demonstrated how dynamic storage allocation algorithms can be analyzed
in terms of finite size scaling. The method is illustrated in the three simple
cases of the it first-fit, next-fit and it best-fit algorithms, and the system
works at full capacity. The analysis is done from two different points of view
- running speed and employed memory. In both cases, and for all algorithms, it
is shown that a simple scaling function exists and the relevant exponents are
calculated. The method can be applied on similar problems as well.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures, will apear in Physica A</dc:description>
 <dc:date>2003-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0307058</dc:identifier>
 <dc:identifier>Physica A: Statistical Mechanics and its Applications, Volume 327,
  Issues 3-4, 15 September 2003, Pages 563-569</dc:identifier>
 <dc:identifier>doi:10.1016/S0378-4371(03)00509-0</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0307083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generation of Explicit Knowledge from Empirical Data through Pruning of
  Trainable Neural Networks</dc:title>
 <dc:creator>Gorban, A. N.</dc:creator>
 <dc:creator>Mirkes, Eu. M.</dc:creator>
 <dc:creator>Tsaregorodtsev, V. G.</dc:creator>
 <dc:subject>Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  This paper presents a generalized technology of extraction of explicit
knowledge from data. The main ideas are 1) maximal reduction of network
complexity (not only removal of neurons or synapses, but removal all the
unnecessary elements and signals and reduction of the complexity of elements),
2) using of adjustable and flexible pruning process (the pruning sequence
shouldn't be predetermined - the user should have a possibility to prune
network on his own way in order to achieve a desired network structure for the
purpose of extraction of rules of desired type and form), and 3) extraction of
rules not in predetermined but any desired form. Some considerations and notes
about network architecture and training process and applicability of currently
developed pruning techniques and rule extraction algorithms are discussed. This
technology, being developed by us for more than 10 years, allowed us to create
dozens of knowledge-based expert systems. In this paper we present a
generalized three-step technology of extraction of explicit knowledge from
empirical data.
</dc:description>
 <dc:description>Comment: 9 pages, The talk was given at the IJCNN '99 (Washington DC, July
  1999)</dc:description>
 <dc:date>2003-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0307083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0307201</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Punctuated Equilibrium in Software Evolution</dc:title>
 <dc:creator>Gorshenev, A. A.</dc:creator>
 <dc:creator>Pis'mak, Yu. M.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The approach based on paradigm of self-organized criticality proposed for
experimental investigation and theoretical modelling of software evolution. The
dynamics of modifications studied for three free, open source programs Mozilla,
Free-BSD and Emacs using the data from version control systems. Scaling laws
typical for the self-organization criticality found. The model of software
evolution presenting the natural selection principle is proposed. The results
of numerical and analytical investigation of the model are presented. They are
in a good agreement with the data collected for the real-world software.
</dc:description>
 <dc:description>Comment: 4 pages, LaTeX, 2 Postscript figures</dc:description>
 <dc:date>2003-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0307201</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.70.067103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0307630</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Product Distribution Field Theory</dc:title>
 <dc:creator>Wolpert, David H.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  This paper presents a novel way to approximate a distribution governing a
system of coupled particles with a product of independent distributions. The
approach is an extension of mean field theory that allows the independent
distributions to live in a different space from the system, and thereby capture
statistical dependencies in that system. It also allows different Hamiltonians
for each independent distribution, to facilitate Monte Carlo estimation of
those distributions. The approach leads to a novel energy-minimization
algorithm in which each coordinate Monte Carlo estimates an associated
spectrum, and then independently sets its state by sampling a Boltzmann
distribution across that spectrum. It can also be used for high-dimensional
numerical integration, (constrained) combinatorial optimization, and adaptive
distributed control. This approach also provides a simple, physics-based
derivation of the powerful approximate energy-minimization algorithms
semi-formally derived in \cite{wowh00, wotu02c, wolp03a}. In addition it
suggests many improvements to those algorithms, and motivates a new (bounded
rationality) game theory equilibrium concept.
</dc:description>
 <dc:description>Comment: 4 pages, submitted</dc:description>
 <dc:date>2003-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0307630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0308147</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Instability of one-step replica-symmetry-broken phase in satisfiability
  problems</dc:title>
 <dc:creator>Montanari, Andrea</dc:creator>
 <dc:creator>Parisi, Giorgio</dc:creator>
 <dc:creator>Ricci-Tersenghi, Federico</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We reconsider the one-step replica-symmetry-breaking (1RSB) solutions of two
random combinatorial problems: k-XORSAT and k-SAT. We present a general method
for establishing the stability of these solutions with respect to further steps
of replica-symmetry breaking. Our approach extends the ideas of [A.Montanari
and F. Ricci-Tersenghi, Eur.Phys.J. B 33, 339 (2003)] to more general
combinatorial problems.
  It turns out that 1RSB is always unstable at sufficiently small clauses
density alpha or high energy. In particular, the recent 1RSB solution to 3-SAT
is unstable at zero energy for alpha&lt; alpha_m, with alpha_m\approx 4.153. On
the other hand, the SAT-UNSAT phase transition seems to be correctly described
within 1RSB.
</dc:description>
 <dc:description>Comment: 26 pages, 7 eps figures</dc:description>
 <dc:date>2003-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0308147</dc:identifier>
 <dc:identifier>J. Phys. A 37, 2073 (2004)</dc:identifier>
 <dc:identifier>doi:10.1088/0305-4470/37/6/008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0308288</identifier>
 <datestamp>2008-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compact Routing on Internet-Like Graphs</dc:title>
 <dc:creator>Krioukov, Dmitri</dc:creator>
 <dc:creator>Fall, Kevin</dc:creator>
 <dc:creator>Yang, Xiaowei</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The Thorup-Zwick (TZ) routing scheme is the first generic stretch-3 routing
scheme delivering a nearly optimal local memory upper bound. Using both direct
analysis and simulation, we calculate the stretch distribution of this routing
scheme on random graphs with power-law node degree distributions, $P_k \sim
k^{-\gamma}$. We find that the average stretch is very low and virtually
independent of $\gamma$. In particular, for the Internet interdomain graph,
$\gamma \sim 2.1$, the average stretch is around 1.1, with up to 70% of paths
being shortest. As the network grows, the average stretch slowly decreases. The
routing table is very small, too. It is well below its upper bounds, and its
size is around 50 records for $10^4$-node networks. Furthermore, we find that
both the average shortest path length (i.e. distance) $\bar{d}$ and width of
the distance distribution $\sigma$ observed in the real Internet inter-AS graph
have values that are very close to the minimums of the average stretch in the
$\bar{d}$- and $\sigma$-directions. This leads us to the discovery of a unique
critical quasi-stationary point of the average TZ stretch as a function of
$\bar{d}$ and $\sigma$. The Internet distance distribution is located in a
close neighborhood of this point. This observation suggests the analytical
structure of the average stretch function may be an indirect indicator of some
hidden optimization criteria influencing the Internet's interdomain topology
evolution.
</dc:description>
 <dc:description>Comment: 29 pages, 16 figures</dc:description>
 <dc:date>2003-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0308288</dc:identifier>
 <dc:identifier>INFOCOM 2004</dc:identifier>
 <dc:identifier>doi:10.1109/INFCOM.2004.1354495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0310227</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random k-SAT: Two Moments Suffice to Cross a Sharp Threshold</dc:title>
 <dc:creator>Achlioptas, Dimitris</dc:creator>
 <dc:creator>Moore, Cristopher</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Many NP-complete constraint satisfaction problems appear to undergo a &quot;phase
transition'' from solubility to insolubility when the constraint density passes
through a critical threshold. In all such cases it is easy to derive upper
bounds on the location of the threshold by showing that above a certain density
the first moment (expectation) of the number of solutions tends to zero. We
show that in the case of certain symmetric constraints, considering the second
moment of the number of solutions yields nearly matching lower bounds for the
location of the threshold. Specifically, we prove that the threshold for both
random hypergraph 2-colorability (Property B) and random Not-All-Equal k-SAT is
2^{k-1} ln 2 -O(1). As a corollary, we establish that the threshold for random
k-SAT is of order Theta(2^k), resolving a long-standing open problem.
</dc:description>
 <dc:date>2003-10-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0310227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0310600</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Communities in Linear Time: A Physics Approach</dc:title>
 <dc:creator>Wu, Fang</dc:creator>
 <dc:creator>Huberman, Bernardo A.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a method that allows for the discovery of communities within
graphs of arbitrary size in times that scale linearly with their size. This
method avoids edge cutting and is based on notions of voltage drops across
networks that are both intuitive and easy to solve regardless of the complexity
of the graph involved. We additionally show how this algorithm allows for the
swift discovery of the community surrounding a given node without having to
extract all the communities out of a graph.
</dc:description>
 <dc:date>2003-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0310600</dc:identifier>
 <dc:identifier>doi:10.1140/epjb/e2004-00125-x</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0311552</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extremal Properties of Random Structures</dc:title>
 <dc:creator>Ben-Naim, E.</dc:creator>
 <dc:creator>Krapivsky, P. L.</dc:creator>
 <dc:creator>Redner, S.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  The extremal characteristics of random structures, including trees, graphs,
and networks, are discussed. A statistical physics approach is employed in
which extremal properties are obtained through suitably defined rate equations.
A variety of unusual time dependences and system-size dependences for basic
extremal properties are obtained.
</dc:description>
 <dc:description>Comment: 24 pages, 8 figures, review</dc:description>
 <dc:date>2003-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0311552</dc:identifier>
 <dc:identifier>Lecture Notes in Physics 650, 211 (2004)</dc:identifier>
 <dc:identifier>doi:10.1007/b98716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0312019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A theoretical investigation of ferromagnetic tunnel junctions with
  4-valued conductances</dc:title>
 <dc:creator>Kokado, Satoshi</dc:creator>
 <dc:creator>Harigaya, Kikuo</dc:creator>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  In considering a novel function in ferromagnetic tunnel junctions consisting
of ferromagnet(FM)/barrier/FM junctions, we theoretically investigate multiple
valued (or multi-level) cell property, which is in principle realized by
sensing conductances of four states recorded with magnetization configurations
of two FMs; that is, (up,up), (up,down), (down,up), (down,down). To obtain such
4-valued conductances, we propose FM1/spin-polarized barrier/FM2 junctions,
where the FM1 and FM2 are different ferromagnets, and the barrier has spin
dependence. The proposed idea is applied to the case of the barrier having
localized spins. Assuming that all the localized spins are pinned parallel to
magnetization axes of the FM1 and FM2, 4-valued conductances are explicitly
obtained for the case of many localized spins. Furthermore, objectives for an
ideal spin-polarized barrier are discussed.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures, accepted for publication in J. Phys.: Condens.
  Matter</dc:description>
 <dc:date>2003-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0312019</dc:identifier>
 <dc:identifier>J. Phys.: Condens. Matter 15 (2003) 8797-8804</dc:identifier>
 <dc:identifier>doi:10.1088/0953-8984/15/50/012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0312483</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Survey Propagation as local equilibrium equations</dc:title>
 <dc:creator>Braunstein, A.</dc:creator>
 <dc:creator>Zecchina, R.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  It has been shown experimentally that a decimation algorithm based on Survey
Propagation (SP) equations allows to solve efficiently some combinatorial
problems over random graphs. We show that these equations can be derived as
sum-product equations for the computation of marginals in an extended space
where the variables are allowed to take an additional value -- $*$ -- when they
are not forced by the combinatorial constraints. An appropriate ``local
equilibrium condition'' cost/energy function is introduced and its entropy is
shown to coincide with the expected logarithm of the number of clusters of
solutions as computed by SP. These results may help to clarify the geometrical
notion of clusters assumed by SP for the random K-SAT or random graph coloring
(where it is conjectured to be exact) and helps to explain which kind of
clustering operation or approximation is enforced in general/small sized models
in which it is known to be inexact.
</dc:description>
 <dc:description>Comment: 13 pages, 3 figures</dc:description>
 <dc:date>2003-12-18</dc:date>
 <dc:date>2004-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0312483</dc:identifier>
 <dc:identifier>J. Stat. Mech., P06007 (2004)</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/2004/06/P06007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0312603</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complex Grid Computing</dc:title>
 <dc:creator>Costa, Luciano da Fontoura</dc:creator>
 <dc:creator>Travieso, Gonzalo</dc:creator>
 <dc:creator>Ruggiero, Carlos Antonio</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This article investigates the performance of grid computing systems whose
interconnections are given by random and scale-free complex network models.
Regular networks, which are common in parallel computing architectures, are
also used as a standard for comparison. The processing load is assigned to the
processing nodes on demand, and the efficiency of the overall computing is
quantified in terms of the respective speed-ups. It is found that random
networks allow higher computing efficiency than their scale-free counterparts
as a consequence of the smaller number of isolated clusters implied by the
former model. At the same time, for fixed cluster sizes, the scale free model
tend to provide slightly better efficiency. Two modifications of the random and
scale free paradigms, where new connections tend to favor more recently added
nodes, are proposed and shown to be more effective for grid computing than the
standard models. A well-defined correlation is observed between the topological
properties of the network and their respective computing efficiency.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2003-12-23</dc:date>
 <dc:date>2005-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0312603</dc:identifier>
 <dc:identifier>Eur. Phys. J. B, 44 (2005) p.119</dc:identifier>
 <dc:identifier>doi:10.1140/epjb/e2005-00107-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0401065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploration of scale-free networks</dc:title>
 <dc:creator>Petermann, Thomas</dc:creator>
 <dc:creator>Rios, Paolo De Los</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The increased availability of data on real networks has favoured an explosion
of activity in the elaboration of models able to reproduce both qualitatively
and quantitatively the measured properties. What has been less explored is the
reliability of the data, and whether the measurement technique biases them.
Here we show that tree-like explorations (similar in principle to traceroute)
can indeed change the measured exponents of a scale-free network.
</dc:description>
 <dc:description>Comment: To appear in Eur. Phys. J. B; 5 pages, 4 figures</dc:description>
 <dc:date>2004-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0401065</dc:identifier>
 <dc:identifier>Eur. Phys. J. B 38, 201 (2004)</dc:identifier>
 <dc:identifier>doi:10.1140/epjb/e2004-00021-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0401191</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chaos and Annealing in Social networks</dc:title>
 <dc:creator>Shafee, Fariel</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  In this work we compare social clusters with spin clusters and compare
different properties. We also try to compare phase changes in market and labor
stratification with phase changes of spin clusters. Then we compare the
requisites for redrawing the boundaries of social clusters with respect to
energy minimization and efficiency. We finally do a simulation experiment and
show that by choosing suitable link matrices for agents and attributes of the
same and of different agents it is possible to have at the same time behavior
similar to chaos or punctuated equilibrium in some attributes or fairly regular
oscillations of preferences for other attributes, using greatest utility or
efficiency as a criterion for change in conflicting social networks with
different agents having different preferences with respect to the attributes in
the agent himself or with similar attributes in other agents.
</dc:description>
 <dc:description>Comment: New simulations added. Accepted for Verhulst 200, 2004</dc:description>
 <dc:date>2004-01-12</dc:date>
 <dc:date>2004-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0401191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0401229</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Evolution of Time Horizons in Parallel and Grid Simulations</dc:title>
 <dc:creator>Shchur, L. N.</dc:creator>
 <dc:creator>Novotny, M. A.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We analyze the evolution of the local simulation times (LST) in Parallel
Discrete Event Simulations. The new ingredients introduced are i) we associate
the LST with the nodes and not with the processing elements, and 2) we propose
to minimize the exchange of information between different processing elements
by freezing the LST on the boundaries between processing elements for some time
of processing and then releasing them by a wide-stream memory exchange between
processing elements. Highlights of our approach are i) it keeps the highest
level of processor time utilization during the algorithm evolution, ii) it
takes a reasonable time for the memory exchange excluding the time-consuming
and complicated process of message exchange between processors, and iii) the
communication between processors is decoupled from the calculations performed
on a processor. The effectiveness of our algorithm grows with the number of
nodes (or threads). This algorithm should be applicable for any parallel
simulation with short-range interactions, including parallel or grid
simulations of partial differential equations.
</dc:description>
 <dc:description>Comment: 24 pages with 11 figures</dc:description>
 <dc:date>2004-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0401229</dc:identifier>
 <dc:identifier>Phys. Rev. E 70 (2004) 026703</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.70.026703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0402143</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Personal Email Networks: An Effective Anti-Spam Tool</dc:title>
 <dc:creator>Boykin, P. Oscar</dc:creator>
 <dc:creator>Roychowdhury, Vwani</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We provide an automated graph theoretic method for identifying individual
users' trusted networks of friends in cyberspace. We routinely use our social
networks to judge the trustworthiness of outsiders, i.e., to decide where to
buy our next car, or to find a good mechanic for it. In this work, we show that
an email user may similarly use his email network, constructed solely from
sender and recipient information available in the email headers, to distinguish
between unsolicited commercial emails, commonly called &quot;spam&quot;, and emails
associated with his circles of friends. We exploit the properties of social
networks to construct an automated anti-spam tool which processes an individual
user's personal email network to simultaneously identify the user's core
trusted networks of friends, as well as subnetworks generated by spams. In our
empirical studies of individual mail boxes, our algorithm classified
approximately 53% of all emails as spam or non-spam, with 100% accuracy. Some
of the emails are left unclassified by this network analysis tool. However, one
can exploit two of the following useful features. First, it requires no user
intervention or supervised training; second, it results in no false negatives
i.e., spam being misclassified as non-spam, or vice versa. We demonstrate that
these two features suggest that our algorithm may be used as a platform for a
comprehensive solution to the spam problem when used in concert with more
sophisticated, but more cumbersome, content-based filters.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2004-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0402143</dc:identifier>
 <dc:identifier>IEEE Computer, Vol. 38, No. 4, pages 61-68, April 2005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0402268</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competition-Induced Preferential Attachment</dc:title>
 <dc:creator>Berger, N.</dc:creator>
 <dc:creator>Borgs, C.</dc:creator>
 <dc:creator>Chayes, J. T.</dc:creator>
 <dc:creator>D'Souza, R. M.</dc:creator>
 <dc:creator>Kleinberg, R. D.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Models based on preferential attachment have had much success in reproducing
the power law degree distributions which seem ubiquitous in both natural and
engineered systems. Here, rather than assuming preferential attachment, we give
an explanation of how it can arise from a more basic underlying mechanism of
competition between opposing forces.
  We introduce a family of one-dimensional geometric growth models, constructed
iteratively by locally optimizing the tradeoffs between two competing metrics.
This family admits an equivalent description as a graph process with no
reference to the underlying geometry. Moreover, the resulting graph process is
shown to be preferential attachment with an upper cutoff. We rigorously
determine the degree distribution for the family of random graph models,
showing that it obeys a power law up to a finite threshold and decays
exponentially above this threshold.
  We also introduce and rigorously analyze a generalized version of our graph
process, with two natural parameters, one corresponding to the cutoff and the
other a ``fertility'' parameter. Limiting cases of this process include the
standard Barabasi-Albert preferential attachment model and the uniform
attachment model. In the general case, we prove that the process has a power
law degree distribution up to a cutoff, and establish monotonicity of the power
as a function of the two parameters.
</dc:description>
 <dc:description>Comment: Submitted to Intnl. Colloq. on Automata, Languages and Programming
  (ICALP 2004)</dc:description>
 <dc:date>2004-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0402268</dc:identifier>
 <dc:identifier>Proceedings of the 31st International Colloquium on Automata,
  Languages and Programming, 208-221 (2004).</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0402508</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Theory - The Bridge Connecting Bounded Rational Game Theory
  and Statistical Physics</dc:title>
 <dc:creator>Wolpert, David H.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  A long-running difficulty with conventional game theory has been how to
modify it to accommodate the bounded rationality of all real-world players. A
recurring issue in statistical physics is how best to approximate joint
probability distributions with decoupled (and therefore far more tractable)
distributions. This paper shows that the same information theoretic
mathematical structure, known as Product Distribution (PD) theory, addresses
both issues. In this, PD theory not only provides a principled formulation of
bounded rationality and a set of new types of mean field theory in statistical
physics. It also shows that those topics are fundamentally one and the same.
</dc:description>
 <dc:description>Comment: 17 pages, no figures, accepted for publication</dc:description>
 <dc:date>2004-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0402508</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0402581</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dictionary based methods for information extraction</dc:title>
 <dc:creator>Baronchelli, A.</dc:creator>
 <dc:creator>Caglioti, E.</dc:creator>
 <dc:creator>Loreto, V.</dc:creator>
 <dc:creator>Pizzi, E.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Other Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Quantitative Biology - Other Quantitative Biology</dc:subject>
 <dc:description>  In this paper we present a general method for information extraction that
exploits the features of data compression techniques. We first define and focus
our attention on the so-called &quot;dictionary&quot; of a sequence. Dictionaries are
intrinsically interesting and a study of their features can be of great
usefulness to investigate the properties of the sequences they have been
extracted from (e.g. DNA strings). We then describe a procedure of string
comparison between dictionary-created sequences (or &quot;artificial texts&quot;) that
gives very good results in several contexts. We finally present some results on
self-consistent classification problems.
</dc:description>
 <dc:description>Comment: 7 pages, Latex, elsart style</dc:description>
 <dc:date>2004-02-24</dc:date>
 <dc:date>2004-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0402581</dc:identifier>
 <dc:identifier>Physica A - Vol 342/1-2 pp 294-300 (2004)</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2004.01.072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0403233</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial Sequences and Complexity Measures</dc:title>
 <dc:creator>Baronchelli, Andrea</dc:creator>
 <dc:creator>Caglioti, Emanuele</dc:creator>
 <dc:creator>Loreto, Vittorio</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we exploit concepts of information theory to address the
fundamental problem of identifying and defining the most suitable tools to
extract, in a automatic and agnostic way, information from a generic string of
characters. We introduce in particular a class of methods which use in a
crucial way data compression techniques in order to define a measure of
remoteness and distance between pairs of sequences of characters (e.g. texts)
based on their relative information content. We also discuss in detail how
specific features of data compression techniques could be used to introduce the
notion of dictionary of a given sequence and of Artificial Text and we show how
these new tools can be used for information extraction purposes. We point out
the versatility and generality of our method that applies to any kind of
corpora of character strings independently of the type of coding behind them.
We consider as a case study linguistic motivated problems and we present
results for automatic language recognition, authorship attribution and self
consistent-classification.
</dc:description>
 <dc:description>Comment: Revised version, with major changes, of previous &quot;Data Compression
  approach to Information Extraction and Classification&quot; by A. Baronchelli and
  V. Loreto. 15 pages; 5 figures</dc:description>
 <dc:date>2004-03-09</dc:date>
 <dc:date>2006-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0403233</dc:identifier>
 <dc:identifier>J. Stat. Mech., P04002 (2005)</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/2005/04/P04002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0403341</identifier>
 <datestamp>2009-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Roughening of the (1+1) interfaces in two-component surface growth with
  an admixture of random deposition</dc:title>
 <dc:creator>Kolakowska, A.</dc:creator>
 <dc:creator>Novotny, M. A.</dc:creator>
 <dc:creator>Verma, P. S.</dc:creator>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  We simulate competitive two-component growth on a one dimensional substrate
of $L$ sites. One component is a Poisson-type deposition that generates
Kardar-Parisi-Zhang (KPZ) correlations. The other is random deposition (RD). We
derive the universal scaling function of the interface width for this model and
show that the RD admixture acts as a dilatation mechanism to the fundamental
time and height scales, but leaves the KPZ correlations intact. This
observation is generalized to other growth models. It is shown that the
flat-substrate initial condition is responsible for the existence of an early
non-scaling phase in the interface evolution. The length of this initial phase
is a non-universal parameter, but its presence is universal. In application to
parallel and distributed computations, the important consequence of the derived
scaling is the existence of the upper bound for the desynchronization in a
conservative update algorithm for parallel discrete-event simulations. It is
shown that such algorithms are generally scalable in a ring communication
topology.
</dc:description>
 <dc:description>Comment: 16 pages, 16 figures, 77 references</dc:description>
 <dc:date>2004-03-13</dc:date>
 <dc:date>2004-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0403341</dc:identifier>
 <dc:identifier>Phys. Rev. E, Vol.70, 051602 (2004)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.70.051602</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0403453</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unicyclic Components in Random Graphs</dc:title>
 <dc:creator>Ben-Naim, E.</dc:creator>
 <dc:creator>Krapivsky, P. L.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  The distribution of unicyclic components in a random graph is obtained
analytically. The number of unicyclic components of a given size approaches a
self-similar form in the vicinity of the gelation transition. At the gelation
point, this distribution decays algebraically, U_k ~ 1/(4k) for k&gt;&gt;1. As a
result, the total number of unicyclic components grows logarithmically with the
system size.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures</dc:description>
 <dc:date>2004-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0403453</dc:identifier>
 <dc:identifier>J. Phys. A 37, L189 (2004)</dc:identifier>
 <dc:identifier>doi:10.1088/0305-4470/37/18/L01</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0403725</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Threshold values, stability analysis and high-q asymptotics for the
  coloring problem on random graphs</dc:title>
 <dc:creator>Krzakala, Florent</dc:creator>
 <dc:creator>Pagnani, Andrea</dc:creator>
 <dc:creator>Weigt, Martin</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We consider the problem of coloring Erdos-Renyi and regular random graphs of
finite connectivity using q colors. It has been studied so far using the cavity
approach within the so-called one-step replica symmetry breaking (1RSB) ansatz.
We derive a general criterion for the validity of this ansatz and, applying it
to the ground state, we provide evidence that the 1RSB solution gives exact
threshold values c_q for the q-COL/UNCOL phase transition. We also study the
asymptotic thresholds for q &gt;&gt; 1 finding c_q = 2qlog(q)-log(q)-1+o(1) in
perfect agreement with rigorous mathematical bounds, as well as the nature of
excited states, and give a global phase diagram of the problem.
</dc:description>
 <dc:description>Comment: 23 pages, 10 figures. Replaced with accepted version</dc:description>
 <dc:date>2004-03-30</dc:date>
 <dc:date>2004-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0403725</dc:identifier>
 <dc:identifier>Phys. Rev. E 70, 046705 (2004)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.70.046705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0404424</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Travelling Salesman Problem with a Center</dc:title>
 <dc:creator>Lipowski, Adam</dc:creator>
 <dc:creator>Lipowska, Dorota</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study a travelling salesman problem where the path is optimized with a
cost function that includes its length $L$ as well as a certain measure $C$ of
its distance from the geometrical center of the graph. Using simulated
annealing (SA) we show that such a problem has a transition point that
separates two phases differing in the scaling behaviour of $L$ and $C$, in
efficiency of SA, and in the shape of minimal paths.
</dc:description>
 <dc:description>Comment: 4 pages, minor changes, accepted in Phys.Rev.E</dc:description>
 <dc:date>2004-04-18</dc:date>
 <dc:date>2005-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0404424</dc:identifier>
 <dc:identifier>Phys. Rev. E 71, 067701 (2005)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.71.067701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0404593</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The shortest path to complex networks</dc:title>
 <dc:creator>Dorogovtsev, S. N.</dc:creator>
 <dc:creator>Mendes, J. F. F.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:description>  1. The birth of network science. 2. What are random networks? 3. Adjacency
matrix. 4. Degree distribution. 5. What are simple networks? Classical random
graphs. 6. Birth of the giant component. 7. Topology of the Web. 8.Uncorrelated
networks. 9. What are small worlds? 10. Real networks are mesoscopic objects.
11. What are complex networks? 12. The configuration model. 13. The absence of
degree--degree correlations. 14.Networks with correlated degrees.15.Clustering.
16. What are small-world networks? 17. `Small worlds' is not the same as
`small-world networks'. 18. Fat-tailed degree distributions. 19.Reasons for the
fat-tailed degree distributions. 20. Preferential linking. 21. Condensation of
edges. 22. Cut-offs of degree distributions. 23. Reasons for correlations in
networks. 24. Classical random graphs cannot be used for comparison with real
networks. 25. How to measure degree--degree correlations. 26. Assortative and
disassortative mixing. 27. Disassortative mixing does not mean that vertices of
high degrees rarely connect to each other. 28. Reciprocal links in directed
nets. 29. Ultra-small-world effect. 30. Tree ansatz. 31.Ultraresilience against
random failures. 32. When correlated nets are ultraresilient. 33. Vulnerability
of complex networks. 34. The absence of an epidemic threshold. 35. Search based
on local information. 36.Ultraresilience disappears in finite nets. 37.Critical
behavior of cooperative models on networks. 38. Berezinskii-Kosterlitz-Thouless
phase transitions in networks. 39.Cascading failures. 40.Cliques &amp; communities.
41. Betweenness. 42.Extracting communities. 43. Optimal paths. 44.Distributions
of the shortest-path length &amp; of the loop's length are narrow. 45. Diffusion on
networks. 46. What is modularity? 47.Hierarchical organization of networks. 48.
Convincing modelling of real-world networks:Is it possible? 49. The small Web..
</dc:description>
 <dc:description>Comment: 25 pages, a contribution to `Complex Systems and Inter-disciplinary
  Science', v.1, eds. N. Johnson, J. Efstathiou, and F. Reed-Tsochas (World
  Scientific, 2004), to be published</dc:description>
 <dc:date>2004-04-24</dc:date>
 <dc:date>2004-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0404593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0405319</identifier>
 <datestamp>2016-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Critical behaviour of combinatorial search algorithms, and the
  unitary-propagation universality class</dc:title>
 <dc:creator>Deroulers, Christophe</dc:creator>
 <dc:creator>Monasson, R&#xe9;mi</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The probability P(alpha, N) that search algorithms for random Satisfiability
problems successfully find a solution is studied as a function of the ratio
alpha of constraints per variable and the number N of variables. P is shown to
be finite if alpha lies below an algorithm--dependent threshold alpha\_A, and
exponentially small in N above. The critical behaviour is universal for all
algorithms based on the widely-used unitary propagation rule: P[ (1 + epsilon)
alpha\_A, N] ~ exp[-N^(1/6) Phi(epsilon N^(1/3)) ]. Exponents are related to
the critical behaviour of random graphs, and the scaling function Phi is
exactly calculated through a mapping onto a diffusion-and-death problem.
</dc:description>
 <dc:description>Comment: 7 pages; 3 figures</dc:description>
 <dc:date>2004-05-14</dc:date>
 <dc:date>2006-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0405319</dc:identifier>
 <dc:identifier>Europhysics Letters 68 (2004) 153-159</dc:identifier>
 <dc:identifier>doi:10.1209/epl/i2004-10177-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0406152</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Percolation Search in Power Law Networks</dc:title>
 <dc:creator>Sarshar, Nima</dc:creator>
 <dc:creator>Boykin, P. Oscar</dc:creator>
 <dc:creator>Roychowdhury, Vwani P.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We introduce a scalable searching algorithm for finding nodes and contents in
random networks with Power-Law (PL) and heavy-tailed degree distributions. The
network is searched using a probabilistic broadcast algorithm, where a query
message is relayed on each edge with probability just above the bond
percolation threshold of the network. We show that if each node caches its
directory via a short random walk, then the total number of {\em accessible
contents exhibits a first-order phase transition}, ensuring very high hit rates
just above the percolation threshold. In any random PL network of size, $N$,
and exponent, $2 \leq \tau &lt; 3$, the total traffic per query scales
sub-linearly, while the search time scales as $O(\log N)$. In a PL network with
exponent, $\tau \approx 2$, {\em any content or node} can be located in the
network with {\em probability approaching one} in time $O(\log N)$, while
generating traffic that scales as $O(\log^2 N)$, if the maximum degree,
$k_{max}$, is unconstrained, and as $O(N^{{1/2}+\epsilon})$ (for any
$\epsilon&gt;0$) if $ k_{max}=O(\sqrt{N})$. Extensive large-scale simulations show
these scaling laws to be precise. We discuss how this percolation search
algorithm can be directly adapted to solve the well-known scaling problem in
unstructured Peer-to-Peer (P2P) networks. Simulations of the protocol on sample
large-scale subnetworks of existing P2P services show that overall traffic can
be reduced by almost two-orders of magnitude, without any significant loss in
search performance.
</dc:description>
 <dc:date>2004-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0406152</dc:identifier>
 <dc:identifier>Best paper award Fourth International Conference on Peer-to-Peer
  Computing, pp. 2-9, 2004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0406404</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A statistical approach to the traceroute-like exploration of networks:
  theory and simulations</dc:title>
 <dc:creator>Dall'Asta, Luca</dc:creator>
 <dc:creator>Alvarez-Hamelin, Ignacio</dc:creator>
 <dc:creator>Barrat, Alain</dc:creator>
 <dc:creator>Vazquez, Alexei</dc:creator>
 <dc:creator>Vespignani, Alessandro</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Mapping the Internet generally consists in sampling the network from a
limited set of sources by using &quot;traceroute&quot;-like probes. This methodology,
akin to the merging of different spanning trees to a set of destinations, has
been argued to introduce uncontrolled sampling biases that might produce
statistical properties of the sampled graph which sharply differ from the
original ones. Here we explore these biases and provide a statistical analysis
of their origin. We derive a mean-field analytical approximation for the
probability of edge and vertex detection that exploits the role of the number
of sources and targets and allows us to relate the global topological
properties of the underlying network with the statistical accuracy of the
sampled graph. In particular we find that the edge and vertex detection
probability is depending on the betweenness centrality of each element. This
allows us to show that shortest path routed sampling provides a better
characterization of underlying graphs with scale-free topology. We complement
the analytical discussion with a throughout numerical investigation of
simulated mapping strategies in different network models. We show that sampled
graphs provide a fair qualitative characterization of the statistical
properties of the original networks in a fair range of different strategies and
exploration parameters. The numerical study also allows the identification of
intervals of the exploration parameters that optimize the fraction of nodes and
edges discovered in the sampled graph. This finding might hint the steps toward
more efficient mapping strategies.
</dc:description>
 <dc:date>2004-06-17</dc:date>
 <dc:date>2004-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0406404</dc:identifier>
 <dc:identifier>CAAN 2004, LNCS 3405, p. 140 (2005) .</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0406765</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competition and adaptation in an Internet evolution model</dc:title>
 <dc:creator>Serrano, M. Angeles</dc:creator>
 <dc:creator>Boguna, Marian</dc:creator>
 <dc:creator>Diaz-Guilera, Albert</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We model the evolution of the Internet at the Autonomous System level as a
process of competition for users and adaptation of bandwidth capability. We
find the exponent of the degree distribution as a simple function of the growth
rates of the number of autonomous systems and the total number of connections
in the Internet, both empirically measurable quantities. This fact place our
model apart from others in which this exponent depends on parameters that need
to be adjusted in a model dependent way. Our approach also accounts for a high
level of clustering as well as degree-degree correlations, both with the same
hierarchical structure present in the real Internet. Further, it also
highlights the interplay between bandwidth, connectivity and traffic of the
network.
</dc:description>
 <dc:description>Comment: Minor content changes and inset of fig.2</dc:description>
 <dc:date>2004-06-30</dc:date>
 <dc:date>2004-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0406765</dc:identifier>
 <dc:identifier>Physical Review Letters 94, 038701 (2005)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.94.038701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0407439</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Theoretical Study on Spin-Dependent Transport of &quot;Ferromagnet/Carbon
  Nanotube Encapsulating Magnetic Atoms/Ferromagnet&quot; Junctions with 4-Valued
  Conductances</dc:title>
 <dc:creator>Kokado, Satoshi</dc:creator>
 <dc:creator>Harigaya, Kikuo</dc:creator>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:description>  As a novel function of ferromagnet (FM)/spacer/FM junctions, we theoretically
investigate multiple-valued (or multi-level) cell property, which is in
principle realized by sensing conductances of four states recorded with
magnetization configurations of two FMs; (up,up), (up,down), (down,up),
(down,down). In order to sense all the states, 4-valued conductances
corresponding to the respective states are necessary. We previously proposed
that 4-valued conductances are obtained in FM1/spin-polarized spacer (SPS)/FM2
junctions, where FM1 and FM2 have different spin polarizations, and the spacer
depends on spin [J. Phys.: Condens. Matter 15, 8797 (2003)]. In this paper, an
ideal SPS is considered as a single-wall armchair carbon nanotube encapsulating
magnetic atoms, where the nanotube shows on-resonance or off-resonance at the
Fermi level according to its length. The magnitude of the obtained 4-valued
conductances has an opposite order between the on-resonant nanotube and the
off-resonant one, and this property can be understood by considering electronic
states of the nanotube. Also, the magnetoresistance ratio between (up,up) and
(down,down) can be larger than the conventional one between parallel and
anti-parallel configurations.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures, accepted for publication in J. Phys.: Condens.
  Matter</dc:description>
 <dc:date>2004-07-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0407439</dc:identifier>
 <dc:identifier>J. Phys.: Condens. Matter 16, 5605 (2004)</dc:identifier>
 <dc:identifier>doi:10.1088/0953-8984/16/30/020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0408190</identifier>
 <datestamp>2012-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From spin glasses to hard satisfiable formulas</dc:title>
 <dc:creator>Jia, Haixia</dc:creator>
 <dc:creator>Moore, Cristopher</dc:creator>
 <dc:creator>Selman, Bart</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce a highly structured family of hard satisfiable 3-SAT formulas
corresponding to an ordered spin-glass model from statistical physics. This
model has provably &quot;glassy&quot; behavior; that is, it has many local optima with
large energy barriers between them, so that local search algorithms get stuck
and have difficulty finding the true ground state, i.e., the unique satisfying
assignment. We test the hardness of our formulas with two Davis-Putnam solvers,
Satz and zChaff, the recently introduced Survey Propagation (SP), and two local
search algorithms, Walksat and Record-to-Record Travel (RRT). We compare our
formulas to random 3-XOR-SAT formulas and to two other generators of hard
satisfiable instances, the minimum disagreement parity formulas of Crawford et
al., and Hirsch's hgen. For the complete solvers the running time of our
formulas grows exponentially in sqrt(n), and exceeds that of random 3-XOR-SAT
formulas for small problem sizes. SP is unable to solve our formulas with as
few as 25 variables. For Walksat, our formulas appear to be harder than any
other known generator of satisfiable instances. Finally, our formulas can be
solved efficiently by RRT but only if the parameter d is tuned to the height of
the barriers between local minima, and we use this parameter to measure the
barrier heights in random 3-XOR-SAT formulas as well.
</dc:description>
 <dc:description>Comment: This is now somewhat out of date, but we thought it would make sense
  to cross-list to cs.AI as an example of hard SAT problems. The preliminary
  version (without results on RRT) appeared in SAT 2004</dc:description>
 <dc:date>2004-08-09</dc:date>
 <dc:date>2012-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0408190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0408370</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational complexity and fundamental limitations to fermionic
  quantum Monte Carlo simulations</dc:title>
 <dc:creator>Troyer, Matthias</dc:creator>
 <dc:creator>Wiese, Uwe-Jens</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Strongly Correlated Electrons</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>High Energy Physics - Lattice</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Quantum Monte Carlo simulations, while being efficient for bosons, suffer
from the &quot;negative sign problem'' when applied to fermions - causing an
exponential increase of the computing time with the number of particles. A
polynomial time solution to the sign problem is highly desired since it would
provide an unbiased and numerically exact method to simulate correlated quantum
systems. Here we show, that such a solution is almost certainly unattainable by
proving that the sign problem is NP-hard, implying that a generic solution of
the sign problem would also solve all problems in the complexity class NP
(nondeterministic polynomial) in polynomial time.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2004-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0408370</dc:identifier>
 <dc:identifier>Phys.Rev.Lett. 94 (2005) 170201</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.94.170201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0409532</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Poisson convergence in the restricted $k$-partioning problem</dc:title>
 <dc:creator>Bovier, Anton</dc:creator>
 <dc:creator>Kurkova, Irina</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  The randomized $k$-number partitioning problem is the task to distribute $N$
i.i.d. random variables into $k$ groups in such a way that the sums of the
variables in each group are as similar as possible. The restricted
$k$-partitioning problem refers to the case where the number of elements in
each group is fixed to $N/k$. In the case $k=2$ it has been shown that the
properly rescaled differences of the two sums in the close to optimal
partitions converge to a Poisson point process, as if they were independent
random variables. We generalize this result to the case $k&gt;2$ in the restricted
problem and show that the vector of differences between the $k$ sums converges
to a $k-1$-dimensional Poisson point process.
</dc:description>
 <dc:description>Comment: 31pp, AMSTeX</dc:description>
 <dc:date>2004-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0409532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0410059</identifier>
 <datestamp>2008-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accuracy and Scaling Phenomena in Internet Mapping</dc:title>
 <dc:creator>Clauset, Aaron</dc:creator>
 <dc:creator>Moore, Cristopher</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  A great deal of effort has been spent measuring topological features of the
Internet. However, it was recently argued that sampling based on taking paths
or traceroutes through the network from a small number of sources introduces a
fundamental bias in the observed degree distribution. We examine this bias
analytically and experimentally. For Erdos-Renyi random graphs with mean degree
c, we show analytically that traceroute sampling gives an observed degree
distribution P(k) ~ 1/k for k &lt; c, even though the underlying degree
distribution is Poisson. For graphs whose degree distributions have power-law
tails P(k) ~ k^-alpha, traceroute sampling from a small number of sources can
significantly underestimate the value of \alpha when the graph has a large
excess (i.e., many more edges than vertices). We find that in order to obtain a
good estimate of alpha it is necessary to use a number of sources which grows
linearly in the average degree of the underlying graph. Based on these
observations we comment on the accuracy of the published values of alpha for
the Internet.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures; supercedes cond-mat/0407339 and contains scaling
  results on the accuracy of multi-source traceroute studies</dc:description>
 <dc:date>2004-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0410059</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 94, 018701 (2005)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.94.018701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0410270</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On uniqueness theorems for Tsallis entropy and Tsallis relative entropy</dc:title>
 <dc:creator>Furuichi, Shigeru</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The uniqueness theorem for Tsallis entropy was presented in {\it H.Suyari,
IEEE Trans. Inform. Theory, Vol.50, pp.1783-1787 (2004)} by introducing the
generalized Shannon-Khinchin's axiom. In the present paper, this result is
generalized and simplified as follows: {\it Generalization}: The uniqueness
theorem for Tsallis relative entropy is shown by means of the generalized
Hobson's axiom. {\it Simplification}: The uniqueness theorem for Tsallis
entropy is shown by means of the generalized Faddeev's axiom.
</dc:description>
 <dc:description>Comment: this was merged by two manuscripts (arXiv:cond-mat/0410270 and
  arXiv:cond-mat/0410271), and will be published from IEEE TIT</dc:description>
 <dc:date>2004-10-12</dc:date>
 <dc:date>2005-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0410270</dc:identifier>
 <dc:identifier>IEEE Trans. on Information Theory, Vol.51(2005),pp.3638-3645</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2005.855606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0410271</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A generalized Faddeev's axiom and the uniqueness theorem for Tsallis
  entropy</dc:title>
 <dc:creator>Furuichi, Shigeru</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The uniequness theorem for the Tsallis entropy by introducing the generalized
Faddeev's axiom is proven. Our result improves the recent result, the
uniqueness theorem for Tsallis entropy by the generalized Shannon-Khinchin's
axiom in \cite{Suy}, in the sence that our axiom is simpler than his one, as
similar that Faddeev's axiom is simpler than Shannon-Khinchin's one.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author. The contents were
  unified in cond-mat/0410270</dc:description>
 <dc:date>2004-10-12</dc:date>
 <dc:date>2010-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0410271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0410460</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Computational Study of Rotating Spiral Waves and Spatio-Temporal
  Transient Chaos in a Deterministic Three-Level Active System</dc:title>
 <dc:creator>Makovetskiy, S. D.</dc:creator>
 <dc:creator>Makovetskii, D. N.</dc:creator>
 <dc:subject>Condensed Matter - Other Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:description>  Spatio-temporal dynamics of a deterministic three-level cellular automaton
(TLCA) of Zykov-Mikhailov type (Sov. Phys. - Dokl., 1986, Vol.31, No.1, P.51)
is studied numerically. Evolution of spatial structures is investigated both
for the original Zykov-Mikhailov model (which is applicable to, for example,
Belousov-Zhabotinskii chemical reactions) and for proposed by us TLCA, which is
a generalization of Zykov-Mikhailov model for the case of two-channel
diffusion. Such the TLCA is a minimal model for an excitable medium of
microwave phonon laser, called phaser (D. N. Makovetskii, Tech. Phys., 2004,
Vol.49, No.2, P.224; cond-mat/0402640). The most interesting observed forms of
TLCA dynamics are as follows: (a) spatio-temporal transient chaos in form of
highly bottlenecked collective evolution of excitations by rotating spiral
waves (RSW) with variable topological charges; (b) competition of left-handed
and right-handed RSW with unexpected features, including self-induced
alteration of integral effective topological charge; (c) transient chimera
states, i.e. coexistence of regular and chaotic domains in TLCA patterns; (d)
branching of TLCA states with different symmetry which may lead to full
restoring of symmetry of imperfect starting pattern. Phenomena (a) and (c) are
directly related to phaser dynamics features observed earlier in real
experiments at liquid helium temperatures on corundum crystals doped by
iron-group ions. ACM: F.1.1, I.6, J.2; PACS:05.65.+b, 07.05.Tp, 82.20.Wt
</dc:description>
 <dc:description>Comment: 24 pages (LaTeX2e file) and 14 figures (separate PNG-files); Version
  2 - minor changes and corrections, new references</dc:description>
 <dc:date>2004-10-19</dc:date>
 <dc:date>2005-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0410460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0410498</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Search Trees via Statistical Physics</dc:title>
 <dc:creator>Majumdar, Satya N.</dc:creator>
 <dc:creator>Dean, David S.</dc:creator>
 <dc:creator>Krapivsky, P. L.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the random m-ary search tree model (where m stands for the number of
branches of a search tree), an important problem for data storage in computer
science, using a variety of statistical physics techniques that allow us to
obtain exact asymptotic results. In particular, we show that the probability
distributions of extreme observables associated with a random search tree such
as the height and the balanced height of a tree have a traveling front
structure. In addition, the variance of the number of nodes needed to store a
data string of a given size N is shown to undergo a striking phase transition
at a critical value of the branching ratio m_c=26. We identify the mechanism of
this phase transition, show that it is generic and occurs in various other
problems as well. New results are obtained when each element of the data string
is a D-dimensional vector. We show that this problem also has a phase
transition at a critical dimension, D_c= \pi/\sin^{-1}(1/\sqrt{8})=8.69363...
</dc:description>
 <dc:description>Comment: 11 pages, 8 .eps figures included. Invited contribution to
  STATPHYS-22 held at Bangalore (India) in July 2004. To appear in the
  proceedings of STATPHYS-22</dc:description>
 <dc:date>2004-10-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0410498</dc:identifier>
 <dc:identifier>doi:10.1007/BF02704178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0410594</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A model of student's dilemma</dc:title>
 <dc:creator>Lipowski, Adam</dc:creator>
 <dc:creator>Ferreira, Antonio L.</dc:creator>
 <dc:subject>Condensed Matter - Other Condensed Matter</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Each year perhaps millions of young people face the following dilemma: should
I continue my education or rather start working with already acquired skills.
Right decision must take into account somebody's own abilities, accessibility
to education institutions, competition, and potential benefits. A multi-agent,
evolutionary model of this dilemma predicts a transition between stratified and
homogeneous phases, evolution that diminishes fitness, fewer applicants per
seat for decreased capacity of the university, and presence of poor students at
\'elite universities.
</dc:description>
 <dc:description>Comment: 4 pages, minor changes, accepted in Physica A</dc:description>
 <dc:date>2004-10-22</dc:date>
 <dc:date>2005-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0410594</dc:identifier>
 <dc:identifier>Physica A 354-C, pp.539-546 (2005)</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2005.03.009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0411077</identifier>
 <datestamp>2012-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Long Range Frustrations in a Spin Glass Model of the Vertex Cover
  Problem</dc:title>
 <dc:creator>Zhou, Haijun</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In a spin glass system on a random graph, some vertices have their spins
changing among different configurations of a ground--state domain. Long range
frustrations may exist among these unfrozen vertices in the sense that certain
combinations of spin values for these vertices may never appear in any
configuration of this domain. We present a mean field theory to tackle such
long range frustrations and apply it to the NP-hard minimum vertex cover
(hard-core gas condensation) problem. Our analytical results on the
ground-state energy density and on the fraction of frozen vertices are in good
agreement with known numerical and mathematical results.
</dc:description>
 <dc:description>Comment: An erratum is added to the main text. 5 pages, 5 figures</dc:description>
 <dc:date>2004-11-03</dc:date>
 <dc:date>2012-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0411077</dc:identifier>
 <dc:identifier>Physical Review Letters 94, 217203 (2005)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.94.217203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0411079</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Long range frustration in finite connectivity spin glasses: A mean field
  theory and its application to the random $K$-satisfiability problem</dc:title>
 <dc:creator>Zhou, Haijun</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Shortened abstract: A mean field theory of long range frustration is
constructed for spin glass systems with quenched randomness of vertex--vertex
connections and of spin--spin coupling strengths. This theory is applied to a
spin glass model of the random $K$-satisfiability problem (K=2 or K=3).
  The zero--temperature phase diagram of the $\pm J$ Viana--Bray model is also
determined, which is identical to that of the random 2-SAT problem. The
predicted phase transition between a non-frustrated and a long--rangely
frustrated spin glass phase might also be observable in real materials at a
finite temperature.
</dc:description>
 <dc:description>Comment: Final version. Published in New Journal of Physics, freely available
  at http://www.njp.org/</dc:description>
 <dc:date>2004-11-03</dc:date>
 <dc:date>2005-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0411079</dc:identifier>
 <dc:identifier>New Journal of Physics 7: 123 (2005)</dc:identifier>
 <dc:identifier>doi:10.1088/1367-2630/7/1/123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0412460</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Maxwell-Boltzmann, Bose-Einstein and Fermi-Dirac Statistics</dc:title>
 <dc:creator>Niven, Robert K.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  The exact Maxwell-Boltzmann (MB), Bose-Einstein (BE) and Fermi-Dirac (FD)
entropies and probabilistic distributions are derived by the combinatorial
method of Boltzmann, without Stirling's approximation. The new entropy measures
are explicit functions of the probability and degeneracy of each state, and the
total number of entities, N. By analysis of the cost of a &quot;binary decision&quot;,
exact BE and FD statistics are shown to have profound consequences for the
behaviour of quantum mechanical systems.
</dc:description>
 <dc:description>Comment: 18 pages; 6 figures; accepted for publication by Physics Letters A,
  13/5/05</dc:description>
 <dc:date>2004-12-17</dc:date>
 <dc:date>2005-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0412460</dc:identifier>
 <dc:identifier>doi:10.1016/j.physleta.2005.05.063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0412587</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spin dependent transport of ``nonmagnetic metal/zigzag nanotube
  encapsulating magnetic atoms/nonmagnetic metal'' junctions</dc:title>
 <dc:creator>Kokado, Satoshi</dc:creator>
 <dc:creator>Harigaya, Kikuo</dc:creator>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Towards a novel magnetoresistance (MR) device with a carbon nanotube, we
propose ``nonmagnetic metal/zigzag nanotube encapsulating magnetic
atoms/nonmagnetic metal'' junctions. We theoretically investigate how
spin-polarized edges of the nanotube and the encapsulated magnetic atoms
influence on transport. When the on-site Coulomb energy divided by the
magnitude of transfer integral, $U/|t|$, is larger than 0.8, large MR effect
due to the direction of spins of magnetic atoms, which has the magnitude of the
MR ratio of about 100%, appears reflecting such spin-polarized edges.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures, accepted for publication in Synth. Metals</dc:description>
 <dc:date>2004-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0412587</dc:identifier>
 <dc:identifier>Synthetic Metals, Volume 152, Issues 1-3, 20 September 2005, Pages
  465-468</dc:identifier>
 <dc:identifier>doi:10.1016/j.synthmet.2005.07.187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0412723</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling financial markets by the multiplicative sequence of trades</dc:title>
 <dc:creator>Gontis, Vygintas</dc:creator>
 <dc:creator>Kaulakys, Bronislovas</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Spectral Theory</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:description>  We introduce the stochastic multiplicative point process modelling trading
activity of financial markets. Such a model system exhibits power-law spectral
density S(f) ~ 1/f**beta, scaled as power of frequency for various values of
beta between 0.5 and 2. Furthermore, we analyze the relation between the
power-law autocorrelations and the origin of the power-law probability
distribution of the trading activity. The model reproduces the spectral
properties of trading activity and explains the mechanism of power-law
distribution in real markets.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures</dc:description>
 <dc:date>2004-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0412723</dc:identifier>
 <dc:identifier>Gontis V., Kaulakys B., Physica A 344 (2004) 128-133</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2004.06.153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0501169</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Theory of Scale-Free Graphs: Definition, Properties, and
  Implications (Extended Version)</dc:title>
 <dc:creator>Li, Lun</dc:creator>
 <dc:creator>Alderson, David</dc:creator>
 <dc:creator>Tanaka, Reiko</dc:creator>
 <dc:creator>Doyle, John C.</dc:creator>
 <dc:creator>Willinger, Walter</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:description>  Although the ``scale-free'' literature is large and growing, it gives neither
a precise definition of scale-free graphs nor rigorous proofs of many of their
claimed properties. In fact, it is easily shown that the existing theory has
many inherent contradictions and verifiably false claims. In this paper, we
propose a new, mathematically precise, and structural definition of the extent
to which a graph is scale-free, and prove a series of results that recover many
of the claimed properties while suggesting the potential for a rich and
interesting theory. With this definition, scale-free (or its opposite,
scale-rich) is closely related to other structural graph properties such as
various notions of self-similarity (or respectively, self-dissimilarity).
Scale-free graphs are also shown to be the likely outcome of random
construction processes, consistent with the heuristic definitions implicit in
existing random graph approaches. Our approach clarifies much of the confusion
surrounding the sensational qualitative claims in the scale-free literature,
and offers rigorous and quantitative alternatives.
</dc:description>
 <dc:description>Comment: 44 pages, 16 figures. The primary version is to appear in Internet
  Mathematics (2005)</dc:description>
 <dc:date>2005-01-08</dc:date>
 <dc:date>2005-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0501169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0501707</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Focused Local Search for Random 3-Satisfiability</dc:title>
 <dc:creator>Seitz, Sakari</dc:creator>
 <dc:creator>Alava, Mikko</dc:creator>
 <dc:creator>Orponen, Pekka</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  A local search algorithm solving an NP-complete optimisation problem can be
viewed as a stochastic process moving in an 'energy landscape' towards
eventually finding an optimal solution. For the random 3-satisfiability
problem, the heuristic of focusing the local moves on the presently
unsatisfiedclauses is known to be very effective: the time to solution has been
observed to grow only linearly in the number of variables, for a given
clauses-to-variables ratio $\alpha$ sufficiently far below the critical
satisfiability threshold $\alpha_c \approx 4.27$. We present numerical results
on the behaviour of three focused local search algorithms for this problem,
considering in particular the characteristics of a focused variant of the
simple Metropolis dynamics. We estimate the optimal value for the
``temperature'' parameter $\eta$ for this algorithm, such that its linear-time
regime extends as close to $\alpha_c$ as possible. Similar parameter
optimisation is performed also for the well-known WalkSAT algorithm and for the
less studied, but very well performing Focused Record-to-Record Travel method.
We observe that with an appropriate choice of parameters, the linear time
regime for each of these algorithms seems to extend well into ratios $\alpha &gt;
4.2$ -- much further than has so far been generally assumed. We discuss the
statistics of solution times for the algorithms, relate their performance to
the process of ``whitening'', and present some conjectures on the shape of
their computational phase diagrams.
</dc:description>
 <dc:description>Comment: 20 pages, lots of figures</dc:description>
 <dc:date>2005-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0501707</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/2005/06/P06006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0502205</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Degree Distribution of Competition-Induced Preferential Attachment
  Graphs</dc:title>
 <dc:creator>Berger, N.</dc:creator>
 <dc:creator>Borgs, C.</dc:creator>
 <dc:creator>Chayes, J. T.</dc:creator>
 <dc:creator>D'Souza, R. M.</dc:creator>
 <dc:creator>Kleinberg, R. D.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We introduce a family of one-dimensional geometric growth models, constructed
iteratively by locally optimizing the tradeoffs between two competing metrics,
and show that this family is equivalent to a family of preferential attachment
random graph models with upper cutoffs. This is the first explanation of how
preferential attachment can arise from a more basic underlying mechanism of
local competition. We rigorously determine the degree distribution for the
family of random graph models, showing that it obeys a power law up to a finite
threshold and decays exponentially above this threshold.
  We also rigorously analyze a generalized version of our graph process, with
two natural parameters, one corresponding to the cutoff and the other a
``fertility'' parameter. We prove that the general model has a power-law degree
distribution up to a cutoff, and establish monotonicity of the power as a
function of the two parameters. Limiting cases of the general model include the
standard preferential attachment model without cutoff and the uniform
attachment model.
</dc:description>
 <dc:description>Comment: 24 pages, one figure. To appear in the journal: Combinatorics,
  Probability and Computing. Note, this is a long version, with complete
  proofs, of the paper &quot;Competition-Induced Preferential Attachment&quot;
  (cond-mat/0402268)</dc:description>
 <dc:date>2005-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0502205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0503087</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Bias of Traceroute Sampling; or, Power-law Degree Distributions
  in Regular Graphs</dc:title>
 <dc:creator>Achlioptas, Dimitris</dc:creator>
 <dc:creator>Clauset, Aaron</dc:creator>
 <dc:creator>Kempe, David</dc:creator>
 <dc:creator>Moore, Cristopher</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Understanding the structure of the Internet graph is a crucial step for
building accurate network models and designing efficient algorithms for
Internet applications. Yet, obtaining its graph structure is a surprisingly
difficult task, as edges cannot be explicitly queried. Instead, empirical
studies rely on traceroutes to build what are essentially single-source,
all-destinations, shortest-path trees. These trees only sample a fraction of
the network's edges, and a recent paper by Lakhina et al. found empirically
that the resuting sample is intrinsically biased. For instance, the observed
degree distribution under traceroute sampling exhibits a power law even when
the underlying degree distribution is Poisson.
  In this paper, we study the bias of traceroute sampling systematically, and,
for a very general class of underlying degree distributions, calculate the
likely observed distributions explicitly. To do this, we use a continuous-time
realization of the process of exposing the BFS tree of a random graph with a
given degree distribution, calculate the expected degree distribution of the
tree, and show that it is sharply concentrated. As example applications of our
machinery, we show how traceroute sampling finds power-law degree distributions
in both delta-regular and Poisson-distributed random graphs. Thus, our work
puts the observations of Lakhina et al. on a rigorous footing, and extends them
to nearly arbitrary degree distributions.
</dc:description>
 <dc:description>Comment: Long-format version (19 pages); includes small correction to section
  6.1</dc:description>
 <dc:date>2005-03-03</dc:date>
 <dc:date>2006-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0503087</dc:identifier>
 <dc:identifier>Proc. 37th ACM Symposium on Theory of Computing (STOC) 2005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0503627</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to Simulate Billiards and Similar Systems</dc:title>
 <dc:creator>Lubachevsky, Boris D.</dc:creator>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  An N-component continuous-time dynamic system is considered whose components
evolve autonomously all the time except for in discrete asynchronous instances
of pairwise interactions. Examples include chaotically colliding billiard balls
and combat models. A new efficient serial event-driven algorithm is described
for simulating such systems. Rather than maintaining and updating the global
state of the system, the algorithm tries to examine only essential events,
i.e., component interactions. The events are processed in a non-decreasing
order of time; new interactions are scheduled on the basis of the examined
interactions using preintegrated equations of the evolutions of the components.
If the components are distributed uniformly enough in the evolution space, so
that this space can be subdivided into small sectors such that only O(1)
sectors and O(1)$components are in the neighborhood of a sector, then the
algorithm spends time O (log N) for processing an event which is the
asymptotical minimum. The algorithm uses a simple strategy for handling data:
only two states are maintained for each simulated component. Fast data access
in this strategy assures the practical efficiency of the algorithm. It works
noticeably faster than other algorithms proposed for this model.
  Key phrases: collision detection, dense packing, molecular dynamics, hard
spheres, granular flow
</dc:description>
 <dc:description>Comment: 29 pages. 10 figures</dc:description>
 <dc:date>2005-03-26</dc:date>
 <dc:date>2006-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0503627</dc:identifier>
 <dc:identifier>Journal of Computational Physics, v.94 n.2, p.255-283, June 1991</dc:identifier>
 <dc:identifier>doi:10.1016/0021-9991(91)90222-7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0504025</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Point process model of 1/f noise versus a sum of Lorentzians</dc:title>
 <dc:creator>Kaulakys, B.</dc:creator>
 <dc:creator>Gontis, V.</dc:creator>
 <dc:creator>Alaburda, M.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Astrophysics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  We present a simple point process model of $1/f^{\beta}$ noise, covering
different values of the exponent $\beta$. The signal of the model consists of
pulses or events. The interpulse, interevent, interarrival, recurrence or
waiting times of the signal are described by the general Langevin equation with
the multiplicative noise and stochastically diffuse in some interval resulting
in the power-law distribution. Our model is free from the requirement of a wide
distribution of relaxation times and from the power-law forms of the pulses. It
contains only one relaxation rate and yields $1/f^ {\beta}$ spectra in a wide
range of frequency. We obtain explicit expressions for the power spectra and
present numerical illustrations of the model. Further we analyze the relation
of the point process model of $1/f$ noise with the Bernamont-Surdin-McWhorter
model, representing the signals as a sum of the uncorrelated components. We
show that the point process model is complementary to the model based on the
sum of signals with a wide-range distribution of the relaxation times. In
contrast to the Gaussian distribution of the signal intensity of the sum of the
uncorrelated components, the point process exhibits asymptotically a power-law
distribution of the signal intensity. The developed multiplicative point
process model of $1/f^{\beta}$ noise may be used for modeling and analysis of
stochastic processes in different systems with the power-law distribution of
the intensity of pulsing signals.
</dc:description>
 <dc:description>Comment: 23 pages, 10 figures, to be published in Phys. Rev. E</dc:description>
 <dc:date>2005-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0504025</dc:identifier>
 <dc:identifier>Phys.Rev. E71 (2005) 051105</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.71.051105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0504070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clustering of solutions in the random satisfiability problem</dc:title>
 <dc:creator>Mezard, M.</dc:creator>
 <dc:creator>Mora, T.</dc:creator>
 <dc:creator>Zecchina, R.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Using elementary rigorous methods we prove the existence of a clustered phase
in the random $K$-SAT problem, for $K\geq 8$. In this phase the solutions are
grouped into clusters which are far away from each other. The results are in
agreement with previous predictions of the cavity method and give a rigorous
confirmation to one of its main building blocks. It can be generalized to other
systems of both physical and computational interest.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure</dc:description>
 <dc:date>2005-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0504070</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 94, 197205 (2005)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.94.197205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0504185</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disaster Management in Scale-Free Networks: Recovery from and Protection
  Against Intentional Attacks</dc:title>
 <dc:creator>Rezaei, Behnam A.</dc:creator>
 <dc:creator>Sarshar, Nima</dc:creator>
 <dc:creator>Boykin, P. Oscar</dc:creator>
 <dc:creator>Roychowdhury, Vwani P.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Susceptibility of scale free Power Law (PL) networks to attacks has been
traditionally studied in the context of what may be termed as {\em
instantaneous attacks}, where a randomly selected set of nodes and edges are
deleted while the network is kept {\em static}. In this paper, we shift the
focus to the study of {\em progressive} and instantaneous attacks on {\em
reactive} grown and random PL networks, which can respond to attacks and take
remedial steps. In the process, we present several techniques that managed
networks can adopt to minimize the damages during attacks, and also to
efficiently recover from the aftermath of successful attacks. For example, we
present (i) compensatory dynamics that minimize the damages inflicted by
targeted progressive attacks, such as linear-preferential deletions of nodes in
grown PL networks; the resulting dynamic naturally leads to the emergence of
networks with PL degree distributions with exponential cutoffs; (ii)
distributed healing algorithms that can scale the maximum degree of nodes in a
PL network using only local decisions, and (iii) efficient means of creating
giant connected components in a PL network that has been fragmented by attacks
on a large number of high-degree nodes. Such targeted attacks are considered to
be a major vulnerability of PL networks; however, our results show that the
introduction of only a small number of random edges, through a {\em reverse
percolation} process, can restore connectivity, which in turn allows
restoration of other topological properties of the original network. Thus, the
scale-free nature of the networks can itself be effectively utilized for
protection and recovery purposes.
</dc:description>
 <dc:description>Comment: 12 pages, to be submitted to PRE</dc:description>
 <dc:date>2005-04-07</dc:date>
 <dc:date>2005-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0504185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0505193</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Organization of complex networks without multiple connections</dc:title>
 <dc:creator>Dorogovtsev, S. N.</dc:creator>
 <dc:creator>Mendes, J. F. F.</dc:creator>
 <dc:creator>Povolotsky, A. M.</dc:creator>
 <dc:creator>Samukhin, A. N.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>High Energy Physics - Lattice</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We find a new structural feature of equilibrium complex random networks
without multiple and self-connections. We show that if the number of
connections is sufficiently high, these networks contain a core of highly
interconnected vertices. The number of vertices in this core varies in the
range between $const N^{1/2}$ and $const N^{2/3}$, where $N$ is the number of
vertices in a network. At the birth point of the core, we obtain the
size-dependent cut-off of the distribution of the number of connections and
find that its position differs from earlier estimates.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2005-05-08</dc:date>
 <dc:date>2005-09-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0505193</dc:identifier>
 <dc:identifier>Phys.Rev.Lett. 95 (2005) 195701</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.95.195701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0506002</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correlations in interacting systems with a network topology</dc:title>
 <dc:creator>Dorogovtsev, S. N.</dc:creator>
 <dc:creator>Goltsev, A. V.</dc:creator>
 <dc:creator>Mendes, J. F. F.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We study pair correlations in cooperative systems placed on complex networks.
We show that usually in these systems, the correlations between two interacting
objects (e.g., spins), separated by a distance $\ell$, decay, on average,
faster than $1/(\ell z_\ell)$. Here $z_\ell$ is the mean number of the
$\ell$-th nearest neighbors of a vertex in a network. This behavior, in
particular, leads to a dramatic weakening of correlations between second and
more distant neighbors on networks with fat-tailed degree distributions, which
have a divergent number $z_2$ in the infinite network limit. In this case, only
the pair correlations between the nearest neighbors are observable. We obtain
the pair correlation function of the Ising model on a complex network and also
derive our results in the framework of a phenomenological approach.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2005-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0506002</dc:identifier>
 <dc:identifier>Phys. Rev. E 72, 066130 (2005)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.72.066130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0506037</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diagnosis of weaknesses in modern error correction codes: a physics
  approach</dc:title>
 <dc:creator>Stepanov, M. G.</dc:creator>
 <dc:creator>Chernyak, V.</dc:creator>
 <dc:creator>Chertkov, M.</dc:creator>
 <dc:creator>Vasic, B.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  One of the main obstacles to the wider use of the modern error-correction
codes is that, due to the complex behavior of their decoding algorithms, no
systematic method which would allow characterization of the Bit-Error-Rate
(BER) is known. This is especially true at the weak noise where many systems
operate and where coding performance is difficult to estimate because of the
diminishingly small number of errors. We show how the instanton method of
physics allows one to solve the problem of BER analysis in the weak noise range
by recasting it as a computationally tractable minimization problem.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures</dc:description>
 <dc:date>2005-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0506037</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.95.228701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0506053</identifier>
 <datestamp>2008-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pairs of SAT Assignment in Random Boolean Formulae</dc:title>
 <dc:creator>Daud&#xe9;, Herv&#xe9;</dc:creator>
 <dc:creator>Mezard, Marc</dc:creator>
 <dc:creator>Mora, Thierry</dc:creator>
 <dc:creator>Zecchina, Riccardo</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We investigate geometrical properties of the random K-satisfiability problem
using the notion of x-satisfiability: a formula is x-satisfiable if there exist
two SAT assignments differing in Nx variables. We show the existence of a sharp
threshold for this property as a function of the clause density. For large
enough K, we prove that there exists a region of clause density, below the
satisfiability threshold, where the landscape of Hamming distances between SAT
assignments experiences a gap: pairs of SAT-assignments exist at small x, and
around x=1/2, but they donot exist at intermediate values of x. This result is
consistent with the clustering scenario which is at the heart of the recent
heuristic analysis of satisfiability using statistical physics analysis (the
cavity method), and its algorithmic counterpart (the survey propagation
algorithm). The method uses elementary probabilistic arguments (first and
second moment methods), and might be useful in other problems of computational
and physical interest where similar phenomena appear.
</dc:description>
 <dc:date>2005-06-02</dc:date>
 <dc:date>2007-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0506053</dc:identifier>
 <dc:identifier>Theoretical Computer Science 393 (2008) 260-279</dc:identifier>
 <dc:identifier>doi:10.1016/j.tcs.2008.01.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0506330</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A program generating homogeneous random graphs with given weights</dc:title>
 <dc:creator>Bogacz, L.</dc:creator>
 <dc:creator>Burda, Z.</dc:creator>
 <dc:creator>Janke, W.</dc:creator>
 <dc:creator>Waclaw, B.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  We present a program package which generates homogeneous random graphs with
probabilities prescribed by the user. The statistical weight of a labeled graph
$\alpha$ is given in the form $W(\alpha)=\prod_{i=1}^N p(q_i)$, where $p(q)$ is
an arbitrary user function and $q_i$ are the degrees of the graph nodes. The
program can be used to generate two types of graphs (simple graphs and
pseudo-graphs) from three types of ensembles (micro-canonical, canonical and
grand-canonical).
</dc:description>
 <dc:description>Comment: 19 pages, 3 figures</dc:description>
 <dc:date>2005-06-14</dc:date>
 <dc:date>2005-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0506330</dc:identifier>
 <dc:identifier>Comp. Phys. Comm. 173 (2005) 162-174</dc:identifier>
 <dc:identifier>doi:10.1016/j.cpc.2005.07.010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0506652</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The theoretical capacity of the Parity Source Coder</dc:title>
 <dc:creator>Ciliberti, Stefano</dc:creator>
 <dc:creator>Mezard, Marc</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The Parity Source Coder is a protocol for data compression which is based on
a set of parity checks organized in a sparse random network. We consider here
the case of memoryless unbiased binary sources. We show that the theoretical
capacity saturate the Shannon limit at large K. We also find that the first
corrections to the leading behavior are exponentially small, so that the
behavior at finite K is very close to the optimal one.
</dc:description>
 <dc:description>Comment: Added references, minor changes</dc:description>
 <dc:date>2005-06-24</dc:date>
 <dc:date>2005-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0506652</dc:identifier>
 <dc:identifier>J. Stat Mech P10003 (2005)</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/2005/10/P10003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0507451</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Landscape of solutions in constraint satisfaction problems</dc:title>
 <dc:creator>Mezard, Marc</dc:creator>
 <dc:creator>Palassini, Matteo</dc:creator>
 <dc:creator>Rivoire, Olivier</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We present a theoretical framework for characterizing the geometrical
properties of the space of solutions in constraint satisfaction problems,
together with practical algorithms for studying this structure on particular
instances. We apply our method to the coloring problem, for which we obtain the
total number of solutions and analyze in detail the distribution of distances
between solutions.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures. Replaced with published version</dc:description>
 <dc:date>2005-07-19</dc:date>
 <dc:date>2005-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0507451</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 95, 200202 (2005)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.95.200202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0508125</identifier>
 <datestamp>2016-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Criticality and Universality in the Unit-Propagation Search Rule</dc:title>
 <dc:creator>Deroulers, Christophe</dc:creator>
 <dc:creator>Monasson, R&#xe9;mi</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The probability Psuccess(alpha, N) that stochastic greedy algorithms
successfully solve the random SATisfiability problem is studied as a function
of the ratio alpha of constraints per variable and the number N of variables.
These algorithms assign variables according to the unit-propagation (UP) rule
in presence of constraints involving a unique variable (1-clauses), to some
heuristic (H) prescription otherwise. In the infinite N limit, Psuccess
vanishes at some critical ratio alpha\_H which depends on the heuristic H. We
show that the critical behaviour is determined by the UP rule only. In the case
where only constraints with 2 and 3 variables are present, we give the phase
diagram and identify two universality classes: the power law class, where
Psuccess[alpha\_H (1+epsilon N^{-1/3}), N] ~ A(epsilon)/N^gamma; the stretched
exponential class, where Psuccess[alpha\_H (1+epsilon N^{-1/3}), N] ~
exp[-N^{1/6} Phi(epsilon)]. Which class is selected depends on the
characteristic parameters of input data. The critical exponent gamma is
universal and calculated; the scaling functions A and Phi weakly depend on the
heuristic H and are obtained from the solutions of reaction-diffusion equations
for 1-clauses. Computation of some non-universal corrections allows us to match
numerical results with good precision. The critical behaviour for constraints
with &gt;3 variables is given. Our results are interpreted in terms of dynamical
graph percolation and we argue that they should apply to more general
situations where UP is used.
</dc:description>
 <dc:description>Comment: 30 pages, 13 figures</dc:description>
 <dc:date>2005-08-04</dc:date>
 <dc:date>2006-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0508125</dc:identifier>
 <dc:identifier>European Physical Journal B 49 (2006) 339-369</dc:identifier>
 <dc:identifier>doi:10.1140/epjb/e2006-00072-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0508152</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Universal Scaling Theory for Complexity of Analog Computation</dc:title>
 <dc:creator>Avizrats, Yaniv S.</dc:creator>
 <dc:creator>Feinberg, Joshua</dc:creator>
 <dc:creator>Fishman, Shmuel</dc:creator>
 <dc:subject>Condensed Matter - Other Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We discuss the computational complexity of solving linear programming
problems by means of an analog computer. The latter is modeled by a dynamical
system which converges to the optimal vertex solution. We analyze various
probability ensembles of linear programming problems. For each one of these we
obtain numerically the probability distribution functions of certain quantities
which measure the complexity. Remarkably, in the asymptotic limit of very large
problems, each of these probability distribution functions reduces to a
universal scaling function, depending on a single scaling variable and
independent of the details of its parent probability ensemble. These functions
are reminiscent of the scaling functions familiar in the theory of phase
transitions. The results reported here extend analytical and numerical results
obtained recently for the Gaussian ensemble.
</dc:description>
 <dc:description>Comment: 4 pages, 2 eps figures</dc:description>
 <dc:date>2005-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0508152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0508216</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cluster Variation Method in Statistical Physics and Probabilistic
  Graphical Models</dc:title>
 <dc:creator>Pelizzola, Alessandro</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The cluster variation method (CVM) is a hierarchy of approximate variational
techniques for discrete (Ising--like) models in equilibrium statistical
mechanics, improving on the mean--field approximation and the Bethe--Peierls
approximation, which can be regarded as the lowest level of the CVM. In recent
years it has been applied both in statistical physics and to inference and
optimization problems formulated in terms of probabilistic graphical models.
  The foundations of the CVM are briefly reviewed, and the relations with
similar techniques are discussed. The main properties of the method are
considered, with emphasis on its exactness for particular models and on its
asymptotic properties.
  The problem of the minimization of the variational free energy, which arises
in the CVM, is also addressed, and recent results about both provably
convergent and message-passing algorithms are discussed.
</dc:description>
 <dc:description>Comment: 36 pages, 17 figures</dc:description>
 <dc:date>2005-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0508216</dc:identifier>
 <dc:identifier>J. Phys. A 38, R309 (2005)</dc:identifier>
 <dc:identifier>doi:10.1088/0305-4470/38/33/R01</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0509102</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>k-core organization of complex networks</dc:title>
 <dc:creator>Dorogovtsev, S. N.</dc:creator>
 <dc:creator>Goltsev, A. V.</dc:creator>
 <dc:creator>Mendes, J. F. F.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We analytically describe the architecture of randomly damaged uncorrelated
networks as a set of successively enclosed substructures -- k-cores. The k-core
is the largest subgraph where vertices have at least k interconnections. We
find the structure of k-cores, their sizes, and their birth points -- the
bootstrap percolation thresholds. We show that in networks with a finite mean
number z_2 of the second-nearest neighbors, the emergence of a k-core is a
hybrid phase transition. In contrast, if z_2 diverges, the networks contain an
infinite sequence of k-cores which are ultra-robust against random damage.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures</dc:description>
 <dc:date>2005-09-05</dc:date>
 <dc:date>2006-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0509102</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 96, 040601 (2006)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.96.040601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0510064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Brownian Functionals in Physics and Computer Science</dc:title>
 <dc:creator>Majumdar, Satya N.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This is a brief review on Brownian functionals in one dimension and their
various applications, a contribution to the special issue ``The Legacy of
Albert Einstein&quot; of Current Science. After a brief description of Einstein's
original derivation of the diffusion equation, this article provides a
pedagogical introduction to the path integral methods leading to the derivation
of the celebrated Feynman-Kac formula. The usefulness of this technique in
calculating the statistical properties of Brownian functionals is illustrated
with several examples in physics and probability theory, with particular
emphasis on applications in computer science. The statistical properties of
&quot;first-passage Brownian functionals&quot; and their applications are also discussed.
</dc:description>
 <dc:description>Comment: 21 pages, 5 .eps figures included</dc:description>
 <dc:date>2005-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0510064</dc:identifier>
 <dc:identifier>Current Science, vol-89, 2076 (2005).</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0510429</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Transition in the Aldous-Shields Model of Growing Trees</dc:title>
 <dc:creator>Dean, David S.</dc:creator>
 <dc:creator>Majumdar, Satya N.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We study analytically the late time statistics of the number of particles in
a growing tree model introduced by Aldous and Shields. In this model, a cluster
grows in continuous time on a binary Cayley tree, starting from the root, by
absorbing new particles at the empty perimeter sites at a rate proportional to
c^{-l} where c is a positive parameter and l is the distance of the perimeter
site from the root. For c=1, this model corresponds to random binary search
trees and for c=2 it corresponds to digital search trees in computer science.
By introducing a backward Fokker-Planck approach, we calculate the mean and the
variance of the number of particles at large times and show that the variance
undergoes a `phase transition' at a critical value c=sqrt{2}. While for
c&gt;sqrt{2} the variance is proportional to the mean and the distribution is
normal, for c&lt;sqrt{2} the variance is anomalously large and the distribution is
non-Gaussian due to the appearance of extreme fluctuations. The model is
generalized to one where growth occurs on a tree with $m$ branches and, in this
more general case, we show that the critical point occurs at c=sqrt{m}.
</dc:description>
 <dc:description>Comment: Latex 17 pages, 6 figures</dc:description>
 <dc:date>2005-10-17</dc:date>
 <dc:date>2005-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0510429</dc:identifier>
 <dc:identifier>J. Stat. Phys 124, 1351 (2006).</dc:identifier>
 <dc:identifier>doi:10.1007/s10955-006-9193-9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0511159</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning by message-passing in networks of discrete synapses</dc:title>
 <dc:creator>Braunstein, Alfredo</dc:creator>
 <dc:creator>Zecchina, Riccardo</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  We show that a message-passing process allows to store in binary &quot;material&quot;
synapses a number of random patterns which almost saturates the information
theoretic bounds. We apply the learning algorithm to networks characterized by
a wide range of different connection topologies and of size comparable with
that of biological systems (e.g. $n\simeq10^{5}-10^{6}$). The algorithm can be
turned into an on-line --fault tolerant-- learning protocol of potential
interest in modeling aspects of synaptic plasticity and in building
neuromorphic devices.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures; references updated and minor corrections;
  accepted in PRL</dc:description>
 <dc:date>2005-11-07</dc:date>
 <dc:date>2005-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0511159</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 96, 030201 (2006)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.96.030201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0512017</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorial Information Theory: I. Philosophical Basis of
  Cross-Entropy and Entropy</dc:title>
 <dc:creator>Niven, Robert K.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  This study critically analyses the information-theoretic, axiomatic and
combinatorial philosophical bases of the entropy and cross-entropy concepts.
The combinatorial basis is shown to be the most fundamental (most primitive) of
these three bases, since it gives (i) a derivation for the Kullback-Leibler
cross-entropy and Shannon entropy functions, as simplified forms of the
multinomial distribution subject to the Stirling approximation; (ii) an
explanation for the need to maximize entropy (or minimize cross-entropy) to
find the most probable realization; and (iii) new, generalized definitions of
entropy and cross-entropy - supersets of the Boltzmann principle - applicable
to non-multinomial systems. The combinatorial basis is therefore of much
broader scope, with far greater power of application, than the
information-theoretic and axiomatic bases. The generalized definitions underpin
a new discipline of ``{\it combinatorial information theory}'', for the
analysis of probabilistic systems of any type.
  Jaynes' generic formulation of statistical mechanics for multinomial systems
is re-examined in light of the combinatorial approach. (abbreviated abstract)
</dc:description>
 <dc:description>Comment: 45 pp; 1 figure; REVTex; updated version 5 (incremental changes)</dc:description>
 <dc:date>2005-12-01</dc:date>
 <dc:date>2007-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0512017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0601021</identifier>
 <datestamp>2014-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing correlations of flow oscillations at bottlenecks</dc:title>
 <dc:creator>Kretz, Tobias</dc:creator>
 <dc:creator>Woelki, Marko</dc:creator>
 <dc:creator>Schreckenberg, Michael</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  &quot;Oscillations&quot; occur in quite different kinds of many-particle-systems when
two groups of particles with different directions of motion meet or intersect
at a certain spot. We present a model of pedestrian motion that is able to
reproduce oscillations with different characteristics. The Wald-Wolfowitz test
and Gillis' correlated random walk are shown to hold observables that can be
used to characterize different kinds of oscillations.
</dc:description>
 <dc:date>2006-01-02</dc:date>
 <dc:date>2006-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0601021</dc:identifier>
 <dc:identifier>J. Stat. Mech. (2006) P02005</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/2006/02/P02005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0601487</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Loop Calculus in Statistical Physics and Information Science</dc:title>
 <dc:creator>Chertkov, Michael</dc:creator>
 <dc:creator>Chernyak, Vladimir Y.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Considering a discrete and finite statistical model of a general position we
introduce an exact expression for the partition function in terms of a finite
series. The leading term in the series is the Bethe-Peierls (Belief
Propagation)-BP contribution, the rest are expressed as loop-contributions on
the factor graph and calculated directly using the BP solution. The series
unveils a small parameter that often makes the BP approximation so successful.
Applications of the loop calculus in statistical physics and information
science are discussed.
</dc:description>
 <dc:description>Comment: 4 pages, submitted to Phys.Rev.Lett. Changes: More general model,
  Simpler derivation</dc:description>
 <dc:date>2006-01-20</dc:date>
 <dc:date>2006-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0601487</dc:identifier>
 <dc:identifier>Phys. Rev. E 73, 065102(R) (2006)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.73.065102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0601573</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Amorphous packings of hard spheres in large space dimension</dc:title>
 <dc:creator>Parisi, G.</dc:creator>
 <dc:creator>Zamponi, F.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - General Mathematics</dc:subject>
 <dc:description>  In a recent paper (cond-mat/0506445) we derived an expression for the
replicated free energy of a liquid of hard spheres based on the HNC free energy
functional. An approximate equation of state for the glass and an estimate of
the random close packing density were obtained in d=3. Here we show that the
HNC approximation is not needed: the same expression can be obtained from the
full diagrammatic expansion of the replicated free energy. Then, we consider
the asymptotics of this expression when the space dimension d is very large. In
this limit, the entropy of the hard sphere liquid has been computed exactly.
Using this solution, we derive asymptotic expressions for the glass transition
density and for the random close packing density for hard spheres in large
space dimension.
</dc:description>
 <dc:description>Comment: 11 pages, 1 figure, includes feynmf diagrams</dc:description>
 <dc:date>2006-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0601573</dc:identifier>
 <dc:identifier>J.Stat.Mech. (2006) P03017</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/2006/03/P03017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0602183</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonlinear parametric model for Granger causality of time series</dc:title>
 <dc:creator>Marinazzo, Daniele</dc:creator>
 <dc:creator>Pellicoro, Mario</dc:creator>
 <dc:creator>Stramaglia, Sebastiano</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  We generalize a previously proposed approach for nonlinear Granger causality
of time series, based on radial basis function. The proposed model is not
constrained to be additive in variables from the two time series and can
approximate any function of these variables, still being suitable to evaluate
causality. Usefulness of this measure of causality is shown in a physiological
example and in the study of the feed-back loop in a model of excitatory and
inhibitory neurons.
</dc:description>
 <dc:description>Comment: 4 pages 5 figures</dc:description>
 <dc:date>2006-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0602183</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.73.066216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0602345</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical Modeling of Coexistence, Competition and Collapse of Rotating
  Spiral Waves in Three-Level Excitable Media with Discrete Active Centers and
  Absorbing Boundaries</dc:title>
 <dc:creator>Makovetskiy, S. D.</dc:creator>
 <dc:subject>Condensed Matter - Other Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:description>  Spatio-temporal dynamics of excitable media with discrete three-level active
centers (ACs) and absorbing boundaries is studied numerically by means of a
deterministic three-level model (see S. D. Makovetskiy and D. N. Makovetskii,
on-line preprint cond-mat/0410460 ), which is a generalization of Zykov-
Mikhailov model (see Sov. Phys. -- Doklady, 1986, Vol.31, No.1, P.51) for the
case of two-channel diffusion of excitations. In particular, we revealed some
qualitatively new features of coexistence, competition and collapse of rotating
spiral waves (RSWs) in three-level excitable media under conditions of strong
influence of the second channel of diffusion. Part of these features are caused
by unusual mechanism of RSWs evolution when RSW's cores get into the surface
layer of an active medium (i.~e. the layer of ACs resided at the absorbing
boundary). Instead of well known scenario of RSW collapse, which takes place
after collision of RSW's core with absorbing boundary, we observed complicated
transformations of the core leading to nonlinear ''reflection'' of the RSW from
the boundary or even to birth of several new RSWs in the surface layer. To our
knowledge, such nonlinear ''reflections'' of RSWs and resulting die hard
vorticity in excitable media with absorbing boundaries were unknown earlier.
ACM classes: F.1.1, I.6, J.2; PACS numbers: 05.65.+b, 07.05.Tp, 82.20.Wt
</dc:description>
 <dc:description>Comment: 12 pages (LaTeX2e file) and 3 figures (separate PNG-files)</dc:description>
 <dc:date>2006-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0602345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0602351</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synchronization in Network Structures: Entangled Topology as Optimal
  Architecture for Network Design</dc:title>
 <dc:creator>Donetti, Luca</dc:creator>
 <dc:creator>Hurtado, Pablo I.</dc:creator>
 <dc:creator>Munoz, Miguel A.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In these notes we study synchronizability of dynamical processes defined on
complex networks as well as its interplay with network topology. Building from
a recent work by Barahona and Pecora [Phys. Rev. Lett. 89, 054101 (2002)], we
use a simulated annealing algorithm to construct optimally-synchronizable
networks. The resulting structures, known as entangled networks, are
characterized by an extremely homogeneous and interwoven topology: degree,
distance, and betweenness distributions are all very narrow, with short average
distances, large loops, and small modularity. Entangled networks exhibit an
excellent (almost optimal) performance with respect to other flow or
connectivity properties such as robustness, random walk minimal first-passage
times, and good searchability. All this converts entangled networks in a
powerful concept with optimal properties in many respects.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figs., to appear in Lecture Notes in Computer Science</dc:description>
 <dc:date>2006-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0602351</dc:identifier>
 <dc:identifier>Lecture Notes in Computer Science 3993, 1075 (2006)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0602611</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>k-core (bootstrap) percolation on complex networks: Critical phenomena
  and nonlocal effects</dc:title>
 <dc:creator>Goltsev, A. V.</dc:creator>
 <dc:creator>Dorogovtsev, S. N.</dc:creator>
 <dc:creator>Mendes, J. F. F.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We develop the theory of the k-core (bootstrap) percolation on uncorrelated
random networks with arbitrary degree distributions. We show that the k-core
percolation is an unusual, hybrid phase transition with a jump emergence of the
k-core as at a first order phase transition but also with a critical
singularity as at a continuous transition. We describe the properties of the
k-core, explain the meaning of the order parameter for the k-core percolation,
and reveal the origin of the specific critical phenomena. We demonstrate that a
so-called ``corona'' of the k-core plays a crucial role (corona is a subset of
vertices in the k-core which have exactly k neighbors in the k-core). It turns
out that the k-core percolation threshold is at the same time the percolation
threshold of finite corona clusters. The mean separation of vertices in corona
clusters plays the role of the correlation length and diverges at the critical
point. We show that a random removal of even one vertex from the k-core may
result in the collapse of a vast region of the k-core around the removed
vertex. The mean size of this region diverges at the critical point. We find an
exact mapping of the k-core percolation to a model of cooperative relaxation.
This model undergoes critical relaxation with a divergent rate at some critical
moment.
</dc:description>
 <dc:description>Comment: 11 pages, 8 figures</dc:description>
 <dc:date>2006-02-26</dc:date>
 <dc:date>2006-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0602611</dc:identifier>
 <dc:identifier>Phys. Rev. E 73, 056101 (2006)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.73.056101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0602661</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the high density behavior of Hamming codes with fixed minimum
  distance</dc:title>
 <dc:creator>Parisi, G.</dc:creator>
 <dc:creator>Zamponi, F.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We discuss the high density behavior of a system of hard spheres of diameter
d on the hypercubic lattice of dimension n, in the limit n -&gt; oo, d -&gt; oo,
d/n=delta. The problem is relevant for coding theory. We find a solution to the
equations describing the liquid up to very large values of the density, but we
show that this solution gives a negative entropy for the liquid phase when the
density is large enough. We then conjecture that a phase transition towards a
different phase might take place, and we discuss possible scenarios for this
transition. Finally we discuss the relation between our results and known
rigorous bounds on the maximal density of the system.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures</dc:description>
 <dc:date>2006-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0602661</dc:identifier>
 <dc:identifier>J.Stat.Phys. 123, 1145 (2006)</dc:identifier>
 <dc:identifier>doi:10.1007/s10955-006-9142-7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0603189</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Loop series for discrete statistical models on graphs</dc:title>
 <dc:creator>Chertkov, Michael</dc:creator>
 <dc:creator>Chernyak, Vladimir Y.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we present derivation details, logic, and motivation for the
loop calculus introduced in \cite{06CCa}. Generating functions for three
inter-related discrete statistical models are each expressed in terms of a
finite series. The first term in the series corresponds to the Bethe-Peierls
(Belief Propagation)-BP contribution, the other terms are labeled by loops on
the factor graph. All loop contributions are simple rational functions of spin
correlation functions calculated within the BP approach. We discuss two
alternative derivations of the loop series. One approach implements a set of
local auxiliary integrations over continuous fields with the BP contribution
corresponding to an integrand saddle-point value. The integrals are replaced by
sums in the complimentary approach, briefly explained in \cite{06CCa}. A local
gauge symmetry transformation that clarifies an important invariant feature of
the BP solution, is revealed in both approaches. The partition function remains
invariant while individual terms change under the gauge transformation. The
requirement for all individual terms to be non-zero only for closed loops in
the factor graph (as opposed to paths with loose ends) is equivalent to fixing
the first term in the series to be exactly equal to the BP contribution.
Further applications of the loop calculus to problems in statistical physics,
computer and information sciences are discussed.
</dc:description>
 <dc:description>Comment: 20 pages, 3 figures</dc:description>
 <dc:date>2006-03-07</dc:date>
 <dc:date>2007-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0603189</dc:identifier>
 <dc:identifier>J. Stat. Mech. (2006) P06009</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/2006/06/P06009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0603350</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The number of matchings in random graphs</dc:title>
 <dc:creator>Zdeborov&#xe1;, Lenka</dc:creator>
 <dc:creator>M&#xe9;zard, Marc</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We study matchings on sparse random graphs by means of the cavity method. We
first show how the method reproduces several known results about maximum and
perfect matchings in regular and Erdos-Renyi random graphs. Our main new result
is the computation of the entropy, i.e. the leading order of the logarithm of
the number of solutions, of matchings with a given size. We derive both an
algorithm to compute this entropy for an arbitrary graph with a girth that
diverges in the large size limit, and an analytic result for the entropy in
regular and Erdos-Renyi random graph ensembles.
</dc:description>
 <dc:description>Comment: 17 pages, 6 figures, to be published in Journal of Statistical
  Mechanics</dc:description>
 <dc:date>2006-03-13</dc:date>
 <dc:date>2006-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0603350</dc:identifier>
 <dc:identifier>J. Stat. Mech. (2006) P05003</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/2006/05/P05003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0603861</identifier>
 <datestamp>2007-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Congestion-gradient driven transport on complex networks</dc:title>
 <dc:creator>Danila, Bogdan</dc:creator>
 <dc:creator>Yu, Yong</dc:creator>
 <dc:creator>Earl, Samuel</dc:creator>
 <dc:creator>Marsh, John A.</dc:creator>
 <dc:creator>Toroczkai, Zoltan</dc:creator>
 <dc:creator>Bassler, Kevin E.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We present a study of transport on complex networks with routing based on
local information. Particles hop from one node of the network to another
according to a set of routing rules with different degrees of congestion
awareness, ranging from random diffusion to rigid congestion-gradient driven
flow. Each node can be either source or destination for particles and all nodes
have the same routing capacity, which are features of ad-hoc wireless networks.
It is shown that the transport capacity increases when a small amount of
congestion awareness is present in the routing rules, and that it then
decreases as the routing rules become too rigid when the flow becomes strictly
congestion-gradient driven. Therefore, an optimum value of the congestion
awareness exists in the routing rules. It is also shown that, in the limit of a
large number of nodes, networks using routing based on local information jam at
any nonzero load. Finally, we study the correlation between congestion at node
level and a betweenness centrality measure.
</dc:description>
 <dc:description>Comment: 11 pages, 8 figures</dc:description>
 <dc:date>2006-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0603861</dc:identifier>
 <dc:identifier>Phys Rev E 74, 046114 (2006)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.74.046114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0604267</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Survey propagation for the cascading Sourlas code</dc:title>
 <dc:creator>Hatchett, Jonathan PL</dc:creator>
 <dc:creator>Kabashima, Yoshiyuki</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We investigate how insights from statistical physics, namely survey
propagation, can improve decoding of a particular class of sparse error
correcting codes. We show that a recently proposed algorithm, time averaged
belief propagation, is in fact intimately linked to a specific survey
propagation for which Parisi's replica symmetry breaking parameter is set to
zero, and that the latter is always superior to belief propagation in the high
connectivity limit. We briefly look at further improvements available by going
to the second level of replica symmetry breaking.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures</dc:description>
 <dc:date>2006-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0604267</dc:identifier>
 <dc:identifier>doi:10.1088/0305-4470/39/34/005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0604569</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Public-channel cryptography based on mutual chaos pass filters</dc:title>
 <dc:creator>Klein, Einat</dc:creator>
 <dc:creator>Gross, Noam</dc:creator>
 <dc:creator>Kopelowitz, Evi</dc:creator>
 <dc:creator>Rosenbluh, Michael</dc:creator>
 <dc:creator>Khaykovich, Lev</dc:creator>
 <dc:creator>Kinzel, Wolfgang</dc:creator>
 <dc:creator>Kanter, Ido</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We study the mutual coupling of chaotic lasers and observe both
experimentally and in numeric simulations, that there exists a regime of
parameters for which two mutually coupled chaotic lasers establish isochronal
synchronization, while a third laser coupled unidirectionally to one of the
pair, does not synchronize. We then propose a cryptographic scheme, based on
the advantage of mutual-coupling over unidirectional coupling, where all the
parameters of the system are public knowledge. We numerically demonstrate that
in such a scheme the two communicating lasers can add a message signal
(compressed binary message) to the transmitted coupling signal, and recover the
message in both directions with high fidelity by using a mutual chaos pass
filter procedure. An attacker however, fails to recover an errorless message
even if he amplifies the coupling signal.
</dc:description>
 <dc:date>2006-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0604569</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.74.046201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0605190</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Message passing for vertex covers</dc:title>
 <dc:creator>Weigt, Martin</dc:creator>
 <dc:creator>Zhou, Haijun</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Constructing a minimal vertex cover of a graph can be seen as a prototype for
a combinatorial optimization problem under hard constraints. In this paper, we
develop and analyze message passing techniques, namely warning and survey
propagation, which serve as efficient heuristic algorithms for solving these
computational hard problems. We show also, how previously obtained results on
the typical-case behavior of vertex covers of random graphs can be recovered
starting from the message passing equations, and how they can be extended.
</dc:description>
 <dc:description>Comment: 25 pages, 9 figures - version accepted for publication in PRE</dc:description>
 <dc:date>2006-05-08</dc:date>
 <dc:date>2006-09-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0605190</dc:identifier>
 <dc:identifier>Phys. Rev. E 74, 046110 (2006)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.74.046110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0605570</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Box-Muller method for generating q-Gaussian random deviates</dc:title>
 <dc:creator>Thistleton, William</dc:creator>
 <dc:creator>Marsh, John A.</dc:creator>
 <dc:creator>Nelson, Kenric</dc:creator>
 <dc:creator>Tsallis, Constantino</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  The q-Gaussian distribution is known to be an attractor of certain correlated
systems, and is the distribution which, under appropriate constraints,
maximizes the entropy Sq, basis of nonextensive statistical mechanics. This
theory is postulated as a natural extension of the standard (Boltzmann-Gibbs)
statistical mechanics, and may explain the ubiquitous appearance of
heavy-tailed distributions in both natural and man-made systems. The q-Gaussian
distribution is also used as a numerical tool, for example as a visiting
distribution in Generalized Simulated Annealing. We develop and present a
simple, easy to implement numerical method for generating random deviates from
a q-Gaussian distribution based upon a generalization of the well known
Box-Muller method. Our method is suitable for a larger range of q values, q&lt;3,
than has previously appeared in the literature, and can generate deviates from
q-Gaussian distributions of arbitrary width and center. MATLAB code showing a
straightforward implementation is also included.
</dc:description>
 <dc:description>Comment: 14 pages including 8 figures and a code</dc:description>
 <dc:date>2006-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0605570</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0606125</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Microscopic activity patterns in the Naming Game</dc:title>
 <dc:creator>Dall'Asta, Luca</dc:creator>
 <dc:creator>Baronchelli, Andrea</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The models of statistical physics used to study collective phenomena in some
interdisciplinary contexts, such as social dynamics and opinion spreading, do
not consider the effects of the memory on individual decision processes. On the
contrary, in the Naming Game, a recently proposed model of Language formation,
each agent chooses a particular state, or opinion, by means of a memory-based
negotiation process, during which a variable number of states is collected and
kept in memory. In this perspective, the statistical features of the number of
states collected by the agents becomes a relevant quantity to understand the
dynamics of the model, and the influence of topological properties on
memory-based models. By means of a master equation approach, we analyze the
internal agent dynamics of Naming Game in populations embedded on networks,
finding that it strongly depends on very general topological properties of the
system (e.g. average and fluctuations of the degree). However, the influence of
topological properties on the microscopic individual dynamics is a general
phenomenon that should characterize all those social interactions that can be
modeled by memory-based negotiation processes.
</dc:description>
 <dc:description>Comment: submitted to J. Phys. A</dc:description>
 <dc:date>2006-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0606125</dc:identifier>
 <dc:identifier>J. Phys. A: Math. Gen. 39 14851-14867 (2006)</dc:identifier>
 <dc:identifier>doi:10.1088/0305-4470/39/48/002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0606128</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simplifying Random Satisfiability Problem by Removing Frustrating
  Interactions</dc:title>
 <dc:creator>Ramezanpour, A.</dc:creator>
 <dc:creator>Moghimi-Araghi, S.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  How can we remove some interactions in a constraint satisfaction problem
(CSP) such that it still remains satisfiable? In this paper we study a modified
survey propagation algorithm that enables us to address this question for a
prototypical CSP, i.e. random K-satisfiability problem. The average number of
removed interactions is controlled by a tuning parameter in the algorithm. If
the original problem is satisfiable then we are able to construct satisfiable
subproblems ranging from the original one to a minimal one with minimum
possible number of interactions. The minimal satisfiable subproblems will
provide directly the solutions of the original problem.
</dc:description>
 <dc:description>Comment: 21 pages, 16 figures</dc:description>
 <dc:date>2006-06-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0606128</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.74.041105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0606696</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical mechanics of error exponents for error-correcting codes</dc:title>
 <dc:creator>Mora, Thierry</dc:creator>
 <dc:creator>Rivoire, Olivier</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Error exponents characterize the exponential decay, when increasing message
length, of the probability of error of many error-correcting codes. To tackle
the long standing problem of computing them exactly, we introduce a general,
thermodynamic, formalism that we illustrate with maximum-likelihood decoding of
low-density parity-check (LDPC) codes on the binary erasure channel (BEC) and
the binary symmetric channel (BSC). In this formalism, we apply the cavity
method for large deviations to derive expressions for both the average and
typical error exponents, which differ by the procedure used to select the codes
from specified ensembles. When decreasing the noise intensity, we find that two
phase transitions take place, at two different levels: a glass to ferromagnetic
transition in the space of codewords, and a paramagnetic to glass transition in
the space of codes.
</dc:description>
 <dc:description>Comment: 32 pages, 13 figures</dc:description>
 <dc:date>2006-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0606696</dc:identifier>
 <dc:identifier>Phys. Rev. E 74, 056110 (2006)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.74.056110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0607017</identifier>
 <datestamp>2007-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal routing on complex networks</dc:title>
 <dc:creator>Danila, Bogdan</dc:creator>
 <dc:creator>Yu, Yong</dc:creator>
 <dc:creator>Marsh, John A.</dc:creator>
 <dc:creator>Bassler, Kevin E.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We present a novel heuristic algorithm for routing optimization on complex
networks. Previously proposed routing optimization algorithms aim at avoiding
or reducing link overload. Our algorithm balances traffic on a network by
minimizing the maximum node betweenness with as little path lengthening as
possible, thus being useful in cases when networks are jamming due to queuing
overload. By using the resulting routing table, a network can sustain
significantly higher traffic without jamming than in the case of traditional
shortest path routing.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures</dc:description>
 <dc:date>2006-07-01</dc:date>
 <dc:date>2006-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0607017</dc:identifier>
 <dc:identifier>Phys Rev E 74, 046106 (2006)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.74.046106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0607290</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A rigorous proof of the cavity method for counting matchings</dc:title>
 <dc:creator>Bayati, Mohsen</dc:creator>
 <dc:creator>Nair, Chandra</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this paper we rigorously prove the validity of the cavity method for the
problem of counting the number of matchings in graphs with large girth. Cavity
method is an important heuristic developed by statistical physicists that has
lead to the development of faster distributed algorithms for problems in
various combinatorial optimization problems. The validity of the approach has
been supported mostly by numerical simulations. In this paper we prove the
validity of cavity method for the problem of counting matchings using rigorous
techniques. We hope that these rigorous approaches will finally help us
establish the validity of the cavity method in general.
</dc:description>
 <dc:description>Comment: 11 pages, 1 figure</dc:description>
 <dc:date>2006-07-11</dc:date>
 <dc:date>2006-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0607290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0607454</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encryption of Covert Information into Multiple Statistical Distributions</dc:title>
 <dc:creator>Venkatesan, R. C.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A novel strategy to encrypt covert information (code) via unitary projections
into the null spaces of ill-conditioned eigenstructures of multiple host
statistical distributions, inferred from incomplete constraints, is presented.
The host pdf's are inferred using the maximum entropy principle. The projection
of the covert information is dependent upon the pdf's of the host statistical
distributions. The security of the encryption/decryption strategy is based on
the extreme instability of the encoding process. A self-consistent procedure to
derive keys for both symmetric and asymmetric cryptography is presented. The
advantages of using a multiple pdf model to achieve encryption of covert
information are briefly highlighted. Numerical simulations exemplify the
efficacy of the model.
</dc:description>
 <dc:description>Comment: 18 pages, 4 figures. Three sentences expanded to emphasize detail.
  Typos corrected</dc:description>
 <dc:date>2006-07-18</dc:date>
 <dc:date>2006-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0607454</dc:identifier>
 <dc:identifier>doi:10.1016/j.physleta.2007.05.117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0608312</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Cavity Approximations for Graphical Models</dc:title>
 <dc:creator>Rizzo, T.</dc:creator>
 <dc:creator>Wemmenhove, B.</dc:creator>
 <dc:creator>Kappen, H. J.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We reformulate the Cavity Approximation (CA), a class of algorithms recently
introduced for improving the Bethe approximation estimates of marginals in
graphical models. In our new formulation, which allows for the treatment of
multivalued variables, a further generalization to factor graphs with arbitrary
order of interaction factors is explicitly carried out, and a message passing
algorithm that implements the first order correction to the Bethe approximation
is described. Furthermore we investigate an implementation of the CA for
pairwise interactions. In all cases considered we could confirm that CA[k] with
increasing $k$ provides a sequence of approximations of markedly increasing
precision. Furthermore in some cases we could also confirm the general
expectation that the approximation of order $k$, whose computational complexity
is $O(N^{k+1})$ has an error that scales as $1/N^{k+1}$ with the size of the
system. We discuss the relation between this approach and some recent
developments in the field.
</dc:description>
 <dc:description>Comment: Extension to factor graphs and comments on related work added</dc:description>
 <dc:date>2006-08-14</dc:date>
 <dc:date>2007-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0608312</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.76.011102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0609098</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synchronization in Weighted Uncorrelated Complex Networks in a Noisy
  Environment: Optimization and Connections with Transport Efficiency</dc:title>
 <dc:creator>Korniss, G.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Motivated by synchronization problems in noisy environments, we study the
Edwards-Wilkinson process on weighted uncorrelated scale-free networks. We
consider a specific form of the weights, where the strength (and the associated
cost) of a link is proportional to $(k_{i}k_{j})^{\beta}$ with $k_{i}$ and
$k_{j}$ being the degrees of the nodes connected by the link. Subject to the
constraint that the total network cost is fixed, we find that in the mean-field
approximation on uncorrelated scale-free graphs, synchronization is optimal at
$\beta^{*}$$=$-1. Numerical results, based on exact numerical diagonalization
of the corresponding network Laplacian, confirm the mean-field results, with
small corrections to the optimal value of $\beta^{*}$. Employing our recent
connections between the Edwards-Wilkinson process and resistor networks, and
some well-known connections between random walks and resistor networks, we also
pursue a naturally related problem of optimizing performance in queue-limited
communication networks utilizing local weighted routing schemes.
</dc:description>
 <dc:description>Comment: Papers on related research can be found at
  http://www.rpi.edu/~korniss/Research/</dc:description>
 <dc:date>2006-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0609098</dc:identifier>
 <dc:identifier>Phys. Rev. E 75, 051121 (2007)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.75.051121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0609099</identifier>
 <datestamp>2016-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometrical organization of solutions to random linear Boolean equations</dc:title>
 <dc:creator>Mora, Thierry</dc:creator>
 <dc:creator>M&#xe9;zard, Marc</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The random XORSAT problem deals with large random linear systems of Boolean
variables. The difficulty of such problems is controlled by the ratio of number
of equations to number of variables. It is known that in some range of values
of this parameter, the space of solutions breaks into many disconnected
clusters. Here we study precisely the corresponding geometrical organization.
In particular, the distribution of distances between these clusters is computed
by the cavity method. This allows to study the `x-satisfiability' threshold,
the critical density of equations where there exist two solutions at a given
distance.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2006-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0609099</dc:identifier>
 <dc:identifier>Journal of Statistical Mechanics: Theory and Experiment (2006)
  P10007</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/2006/10/P10007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0609584</identifier>
 <datestamp>2007-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random numbers for large scale distributed Monte Carlo simulations</dc:title>
 <dc:creator>Bauke, Heiko</dc:creator>
 <dc:creator>Mertens, Stephan</dc:creator>
 <dc:subject>Condensed Matter - Other Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Monte Carlo simulations are one of the major tools in statistical physics,
complex system science, and other fields, and an increasing number of these
simulations is run on distributed systems like clusters or grids. This raises
the issue of generating random numbers in a parallel, distributed environment.
In this contribution we demonstrate that multiple linear recurrences in finite
fields are an ideal method to produce high quality pseudorandom numbers in
sequential and parallel algorithms. Their known weakness (failure of sampling
points in high dimensions) can be overcome by an appropriate delinearization
that preserves all desirable properties of the underlying linear sequence.
</dc:description>
 <dc:date>2006-09-22</dc:date>
 <dc:date>2007-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0609584</dc:identifier>
 <dc:identifier>Physical Review E, vol. 75, nr. 6 (2007), article 066701</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.75.066701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0611567</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Statistics Framework for Rate Distortion Theory</dc:title>
 <dc:creator>Venkatesan, R. C.</dc:creator>
 <dc:creator>Plastino, A.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Variational principles for the rate distortion (RD) theory in lossy
compression are formulated within the ambit of the generalized nonextensive
statistics of Tsallis, for values of the nonextensivity parameter satisfying $
0 &lt; q &lt; 1 $ and $ q &gt; 1 $. Alternating minimization numerical schemes to
evaluate the nonextensive RD function, are derived. Numerical simulations
demonstrate the efficacy of generalized statistics RD models.
</dc:description>
 <dc:description>Comment: 31 pages, 2 figures. Minor formatting and typographical changes</dc:description>
 <dc:date>2006-11-21</dc:date>
 <dc:date>2009-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0611567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0611717</identifier>
 <datestamp>2007-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-equilibrium phase transition in negotiation dynamics</dc:title>
 <dc:creator>Baronchelli, A.</dc:creator>
 <dc:creator>Dall'Asta, L.</dc:creator>
 <dc:creator>Barrat, A.</dc:creator>
 <dc:creator>Loreto, V.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  We introduce a model of negotiation dynamics whose aim is that of mimicking
the mechanisms leading to opinion and convention formation in a population of
individuals. The negotiation process, as opposed to ``herding-like'' or
``bounded confidence'' driven processes, is based on a microscopic dynamics
where memory and feedback play a central role. Our model displays a
non-equilibrium phase transition from an absorbing state in which all agents
reach a consensus to an active stationary state characterized either by
polarization or fragmentation in clusters of agents with different opinions. We
show the exystence of at least two different universality classes, one for the
case with two possible opinions and one for the case with an unlimited number
of opinions. The phase transition is studied analytically and numerically for
various topologies of the agents' interaction network. In both cases the
universality classes do not seem to depend on the specific interaction
topology, the only relevant feature being the total number of different
opinions ever present in the system.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures</dc:description>
 <dc:date>2006-11-28</dc:date>
 <dc:date>2007-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0611717</dc:identifier>
 <dc:identifier>Phys. Rev. E 76, 051102 (2007)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.76.051102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0612365</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gibbs States and the Set of Solutions of Random Constraint Satisfaction
  Problems</dc:title>
 <dc:creator>Krzakala, Florent</dc:creator>
 <dc:creator>Montanari, Andrea</dc:creator>
 <dc:creator>Ricci-Tersenghi, Federico</dc:creator>
 <dc:creator>Semerjian, Guilhem</dc:creator>
 <dc:creator>Zdeborova, Lenka</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  An instance of a random constraint satisfaction problem defines a random
subset S (the set of solutions) of a large product space (the set of
assignments). We consider two prototypical problem ensembles (random
k-satisfiability and q-coloring of random regular graphs), and study the
uniform measure with support on S. As the number of constraints per variable
increases, this measure first decomposes into an exponential number of pure
states (&quot;clusters&quot;), and subsequently condensates over the largest such states.
Above the condensation point, the mass carried by the n largest states follows
a Poisson-Dirichlet process.
  For typical large instances, the two transitions are sharp. We determine for
the first time their precise location. Further, we provide a formal definition
of each phase transition in terms of different notions of correlation between
distinct variables in the problem.
  The degree of correlation naturally affects the performances of many
search/sampling algorithms. Empirical evidence suggests that local Monte Carlo
Markov Chain strategies are effective up to the clustering phase transition,
and belief propagation up to the condensation point. Finally, refined message
passing techniques (such as survey propagation) may beat also this threshold.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, slightly revised version</dc:description>
 <dc:date>2006-12-14</dc:date>
 <dc:date>2007-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0612365</dc:identifier>
 <dc:identifier>Proc. Natl. Acad. Sci. 104, 10318 (2007)</dc:identifier>
 <dc:identifier>doi:10.1073/pnas.0703685104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0701184</identifier>
 <datestamp>2007-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transport optimization on complex networks</dc:title>
 <dc:creator>Danila, Bogdan</dc:creator>
 <dc:creator>Yu, Yong</dc:creator>
 <dc:creator>Marsh, John A.</dc:creator>
 <dc:creator>Bassler, Kevin E.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We present a comparative study of the application of a recently introduced
heuristic algorithm to the optimization of transport on three major types of
complex networks. The algorithm balances network traffic iteratively by
minimizing the maximum node betweenness with as little path lengthening as
possible. We show that by using this optimal routing, a network can sustain
significantly higher traffic without jamming than in the case of shortest path
routing. A formula is proved that allows quick computation of the average
number of hops along the path and of the average travel times once the
betweennesses of the nodes are computed. Using this formula, we show that
routing optimization preserves the small-world character exhibited by networks
under shortest path routing, and that it significantly reduces the average
travel time on congested networks with only a negligible increase in the
average travel time at low loads. Finally, we study the correlation between the
weights of the links in the case of optimal routing and the betweennesses of
the nodes connected by them.
</dc:description>
 <dc:description>Comment: 19 pages, 7 figures</dc:description>
 <dc:date>2007-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0701184</dc:identifier>
 <dc:identifier>Chaos 17 (2), 026102 (2007)</dc:identifier>
 <dc:identifier>doi:10.1063/1.2731718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0701218</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Statistics Framework for Rate Distortion Theory with Bregman
  Divergences</dc:title>
 <dc:creator>Venkatesan, R. C.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A variational principle for the rate distortion (RD) theory with Bregman
divergences is formulated within the ambit of the generalized (nonextensive)
statistics of Tsallis. The Tsallis-Bregman RD lower bound is established.
Alternate minimization schemes for the generalized Bregman RD (GBRD) theory are
derived. A computational strategy to implement the GBRD model is presented. The
efficacy of the GBRD model is exemplified with the aid of numerical
simulations.
</dc:description>
 <dc:description>Comment: 5 pages + 2 figures. Typos corrected</dc:description>
 <dc:date>2007-01-10</dc:date>
 <dc:date>2007-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0701218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0701319</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Cryptography using a Fisher-Schr\&quot;{o}dinger Model</dc:title>
 <dc:creator>Venkatesan, R. C.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A principled procedure to infer a hierarchy of statistical distributions
possessing ill-conditioned eigenstructures, from incomplete constraints, is
presented. The inference process of the \textit{pdf}'s employs the Fisher
information as the measure of uncertainty, and, utilizes a semi-supervised
learning paradigm based on a measurement-response model. The principle
underlying the learning paradigm involves providing a quantum mechanical
connotation to statistical processes. The inferred \textit{pdf}'s constitute a
statistical host that facilitates the encryption/decryption of covert
information (code). A systematic strategy to encrypt/decrypt code via unitary
projections into the \textit{null spaces} of the ill-conditioned
eigenstructures, is presented. Numerical simulations exemplify the efficacy of
the model.
</dc:description>
 <dc:description>Comment: 8 pages + 2 figures</dc:description>
 <dc:date>2007-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0701319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0702421</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hike in the Phases of the 1-in-3 Satisfiability</dc:title>
 <dc:creator>Maneva, Elitza</dc:creator>
 <dc:creator>Meltzer, Talya</dc:creator>
 <dc:creator>Raymond, Jack</dc:creator>
 <dc:creator>Sportiello, Andrea</dc:creator>
 <dc:creator>Zdeborov&#xe1;, Lenka</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We summarise our results for the random $\epsilon$--1-in-3 satisfiability
problem, where $\epsilon$ is a probability of negation of the variable. We
employ both rigorous and heuristic methods to describe the SAT/UNSAT and
Hard/Easy transitions.
</dc:description>
 <dc:description>Comment: 2 pages, introductory level, proceed. for the Les Houches Session
  LXXXV 2006 on Complex Systems</dc:description>
 <dc:date>2007-02-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0702421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0702546</identifier>
 <datestamp>2007-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Landscape Analysis of Constraint Satisfaction Problems</dc:title>
 <dc:creator>Krzakala, Florent</dc:creator>
 <dc:creator>Kurchan, Jorge</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  We discuss an analysis of Constraint Satisfaction problems, such as Sphere
Packing, K-SAT and Graph Coloring, in terms of an effective energy landscape.
Several intriguing geometrical properties of the solution space become in this
light familiar in terms of the well-studied ones of rugged (glassy) energy
landscapes. A `benchmark' algorithm naturally suggested by this construction
finds solutions in polynomial time up to a point beyond the `clustering' and in
some cases even the `thermodynamic' transitions. This point has a simple
geometric meaning and can be in principle determined with standard Statistical
Mechanical methods, thus pushing the analytic bound up to which problems are
guaranteed to be easy. We illustrate this for the graph three and four-coloring
problem. For Packing problems the present discussion allows to better
characterize the `J-point', proposed as a systematic definition of Random Close
Packing, and to place it in the context of other theories of glasses.
</dc:description>
 <dc:description>Comment: 17 pages, 69 citations, 12 figures</dc:description>
 <dc:date>2007-02-23</dc:date>
 <dc:date>2007-06-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0702546</dc:identifier>
 <dc:identifier>Phys. Rev. E 76, 021122 (2007)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.76.021122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0702613</identifier>
 <datestamp>2007-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding long cycles in graphs</dc:title>
 <dc:creator>Marinari, Enzo</dc:creator>
 <dc:creator>Semerjian, Guilhem</dc:creator>
 <dc:creator>Van Kerrebroeck, Valery</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We analyze the problem of discovering long cycles inside a graph. We propose
and test two algorithms for this task. The first one is based on recent
advances in statistical mechanics and relies on a message passing procedure.
The second follows a more standard Monte Carlo Markov Chain strategy. Special
attention is devoted to Hamiltonian cycles of (non-regular) random graphs of
minimal connectivity equal to three.
</dc:description>
 <dc:date>2007-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0702613</dc:identifier>
 <dc:identifier>Phys. Rev. E 75, 066708 (2007)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.75.066708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/0703351</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error Correction and Digitalization Concepts in Biochemical Computing</dc:title>
 <dc:creator>Fedichkin, L.</dc:creator>
 <dc:creator>Katz, E.</dc:creator>
 <dc:creator>Privman, V.</dc:creator>
 <dc:subject>Condensed Matter - Soft Condensed Matter</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We offer a theoretical design of new systems that show promise for digital
biochemical computing, including realizations of error correction by utilizing
redundancy, as well as signal rectification. The approach includes information
processing using encoded DNA sequences, DNAzyme biocatalyzed reactions and the
use of DNA-functionalized magnetic nanoparticles. Digital XOR and NAND logic
gates and copying (fanout) are designed using the same components.
</dc:description>
 <dc:description>Comment: 14 pages in PDF</dc:description>
 <dc:date>2007-03-13</dc:date>
 <dc:date>2007-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/0703351</dc:identifier>
 <dc:identifier>Journal of Computational and Theoretical Nanoscience 5, 36-43
  (2008)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/9703191</identifier>
 <datestamp>2016-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Potts Neuron Approach to Communication Routing</dc:title>
 <dc:creator>H&#xe4;kkinen, J.</dc:creator>
 <dc:creator>Lagerholm, M.</dc:creator>
 <dc:creator>Peterson, C.</dc:creator>
 <dc:creator>S&#xf6;derberg, B.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>High Energy Physics - Lattice</dc:subject>
 <dc:description>  A feedback neural network approach to communication routing problems is
developed with emphasis on Multiple Shortest Path problems, with several
requests for transmissions between distinct start- and endnodes. The basic
ingredients are a set of Potts neurons for each request, with interactions
designed to minimize path lengths and to prevent overloading of network arcs.
The topological nature of the problem is conveniently handled using a
propagator matrix approach. Although the constraints are global, the
algorithmic steps are based entirely on local information, facilitating
distributed implementations. In the polynomially solvable single-request case
the approach reduces to a fuzzy version of the Bellman-Ford algorithm. The
approach is evaluated for synthetic problems of varying sizes and load levels,
by comparing with exact solutions from a branch-and-bound method. With very few
exceptions, the Potts approach gives legal solutions of very high quality. The
computational demand scales merely as the product of the numbers of requests,
nodes, and arcs.
</dc:description>
 <dc:description>Comment: 10 pages LaTeX</dc:description>
 <dc:date>1997-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/9703191</dc:identifier>
 <dc:identifier>Neural Computation 10, 1587-1599 (1998)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/9808130</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite-difference methods for simulation models incorporating
  non-conservative forces</dc:title>
 <dc:creator>Novik, Keir E.</dc:creator>
 <dc:creator>Coveney, Peter V.</dc:creator>
 <dc:subject>Condensed Matter - Soft Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  We discuss algorithms applicable to the numerical solution of second-order
ordinary differential equations by finite-differences. We make particular
reference to the solution of the dissipative particle dynamics fluid model, and
present extensive results comparing one of the algorithms discussed with the
standard method of solution. These results show the successful modeling of
phase separation and surface tension in a binary immiscible fluid mixture.
</dc:description>
 <dc:description>Comment: 27 pages RevTeX, 9 figures, J. Chem. Phys. (in press)</dc:description>
 <dc:date>1998-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/9808130</dc:identifier>
 <dc:identifier>doi:10.1063/1.477413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/9810144</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relaxation in graph coloring and satisfiability problems</dc:title>
 <dc:creator>Svenson, Pontus</dc:creator>
 <dc:creator>Nordahl, Mats G.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Using T=0 Monte Carlo simulation, we study the relaxation of graph coloring
(K-COL) and satisfiability (K-SAT), two hard problems that have recently been
shown to possess a phase transition in solvability as a parameter is varied. A
change from exponentially fast to power law relaxation, and a transition to
freezing behavior are found. These changes take place for smaller values of the
parameter than the solvability transition. Results for the coloring problem for
colorable and clustered graphs and for the fraction of persistent spins for
satisfiability are also presented.
</dc:description>
 <dc:description>Comment: 13 pages, 22 figures. Several changes to text, figures added, section
  on feromagnetic model moved to a separate publication. Accepted for
  publication in Phys Rev. E</dc:description>
 <dc:date>1998-10-13</dc:date>
 <dc:date>1999-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/9810144</dc:identifier>
 <dc:identifier>Phys. Rev. E 59(4) 3983-3999 (1999)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.59.3983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/9810347</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An exact representation of the fermion dynamics in terms of Poisson
  processes and its connection with Monte Carlo algorithms</dc:title>
 <dc:creator>Beccaria, Matteo</dc:creator>
 <dc:creator>Presilla, Carlo</dc:creator>
 <dc:creator>De Angelis, Gian Fabrizio</dc:creator>
 <dc:creator>Jona-Lasinio, Giovanni</dc:creator>
 <dc:subject>Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>High Energy Physics - Lattice</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We present a simple derivation of a Feynman-Kac type formula to study
fermionic systems. In this approach the real time or the imaginary time
dynamics is expressed in terms of the evolution of a collection of Poisson
processes. A computer implementation of this formula leads to a family of
algorithms parametrized by the values of the jump rates of the Poisson
processes. From these an optimal algorithm can be chosen which coincides with
the Green Function Monte Carlo method in the limit when the latter becomes
exact.
</dc:description>
 <dc:description>Comment: 4 pages, 1 PostScript figure, REVTeX</dc:description>
 <dc:date>1998-10-26</dc:date>
 <dc:date>1999-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/9810347</dc:identifier>
 <dc:identifier>Europhys.Lett. 48 (1999) 243-249</dc:identifier>
 <dc:identifier>doi:10.1209/epl/i1999-00472-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/9812344</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallelization of a Dynamic Monte Carlo Algorithm: a Partially
  Rejection-Free Conservative Approach</dc:title>
 <dc:creator>Korniss, G.</dc:creator>
 <dc:creator>Novotny, M. A.</dc:creator>
 <dc:creator>Rikvold, P. A.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  We experiment with a massively parallel implementation of an algorithm for
simulating the dynamics of metastable decay in kinetic Ising models. The
parallel scheme is directly applicable to a wide range of stochastic cellular
automata where the discrete events (updates) are Poisson arrivals. For high
performance, we utilize a continuous-time, asynchronous parallel version of the
n-fold way rejection-free algorithm. Each processing element carries an lxl
block of spins, and we employ the fast SHMEM-library routines on the Cray T3E
distributed-memory parallel architecture. Different processing elements have
different local simulated times. To ensure causality, the algorithm handles the
asynchrony in a conservative fashion. Despite relatively low utilization and an
intricate relationship between the average time increment and the size of the
spin blocks, we find that for sufficiently large l the algorithm outperforms
its corresponding parallel Metropolis (non-rejection-free) counterpart. As an
example application, we present results for metastable decay in a model
ferromagnetic or ferroelectric film, observed with a probe of area smaller than
the total system.
</dc:description>
 <dc:description>Comment: 17 pages, 7 figures, RevTex; submitted to the Journal of
  Computational Physics</dc:description>
 <dc:date>1998-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/9812344</dc:identifier>
 <dc:identifier>J. Comput. Phys. 153, 488 (1999)</dc:identifier>
 <dc:identifier>doi:10.1006/jcph.1999.6291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/9902011</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cortical Potential Distributions and Cognitive Information Processing</dc:title>
 <dc:creator>Tuckwell, Henry C.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:subject>Quantitative Biology</dc:subject>
 <dc:description>  The use of cortical field potentials rather than the details of spike trains
as the basis for cognitive information processing is proposed. This results in
a space of cognitive elements with natural metrics. Sets of spike trains may
also be considered to be points in a multidimensional metric space. The
closeness of sets of spike trains in such a space implies the closeness of
points in the resulting function space of potential distributions.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>1999-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/9902011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/9906017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithmic Complexity in Minority Game</dc:title>
 <dc:creator>Corona, Ricardo Mansilla</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  In this paper we introduce a new approach for the study of the complex
behavior of Minority Game using the tools of algorithmic complexity, physical
entropy and information theory. We show that physical complexity and mutual
information function strongly depend on memory size of the agents and yields
more information about the complex features of the stream of binary outcomes of
the game than volatility itself.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures included</dc:description>
 <dc:date>1999-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/9906017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/9906206</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ocular dominance patterns in mammalian visual cortex: A wire length
  minimization approach</dc:title>
 <dc:creator>Chklovskii, Dmitri B.</dc:creator>
 <dc:creator>Koulakov, Alexei A.</dc:creator>
 <dc:subject>Condensed Matter - Soft Condensed Matter</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:subject>Quantitative Biology</dc:subject>
 <dc:description>  We propose a theory for ocular dominance (OD) patterns in mammalian primary
visual cortex. This theory is based on the premise that OD pattern is an
adaptation to minimize the length of intra-cortical wiring. Thus we can
understand the existing OD patterns by solving a wire length minimization
problem. We divide all the neurons into two classes: left-eye dominated and
right-eye dominated. We find that segregation of neurons into monocular regions
reduces wire length if the number of connections with the neurons of the same
class differs from that with the other class. The shape of the regions depends
on the relative fraction of neurons in the two classes. If the numbers are
close we find that the optimal OD pattern consists of interdigitating stripes.
If one class is less numerous than the other, the optimal OD pattern consists
of patches of the first class neurons in the sea of the other class neurons. We
predict the transition from stripes to patches when the fraction of neurons
dominated by the ipsilateral eye is about 40%. This prediction agrees with the
data in macaque and Cebus monkeys. This theory can be applied to other binary
cortical systems.
</dc:description>
 <dc:description>Comment: 9 pages, submitted to Journal of Neuroscience</dc:description>
 <dc:date>1999-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/9906206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/9907038</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The diameter of the world wide web</dc:title>
 <dc:creator>Albert, Reka</dc:creator>
 <dc:creator>Jeong, Hawoong</dc:creator>
 <dc:creator>Barabasi, Albert-Laszlo</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Despite its increasing role in communication, the world wide web remains the
least controlled medium: any individual or institution can create websites with
unrestricted number of documents and links. While great efforts are made to map
and characterize the Internet's infrastructure, little is known about the
topology of the web. Here we take a first step to fill this gap: we use local
connectivity measurements to construct a topological model of the world wide
web, allowing us to explore and characterize its large scale properties.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, updated with most recent results on the size of
  the www</dc:description>
 <dc:date>1999-07-02</dc:date>
 <dc:date>1999-09-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/9907038</dc:identifier>
 <dc:identifier>Nature 401, 130-131 (1999)</dc:identifier>
 <dc:identifier>doi:10.1038/43601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/9907343</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A variational description of the ground state structure in random
  satisfiability problems</dc:title>
 <dc:creator>Biroli, Giulio</dc:creator>
 <dc:creator>Monasson, Remi</dc:creator>
 <dc:creator>Weigt, Martin</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  A variational approach to finite connectivity spin-glass-like models is
developed and applied to describe the structure of optimal solutions in random
satisfiability problems. Our variational scheme accurately reproduces the known
replica symmetric results and also allows for the inclusion of replica symmetry
breaking effects. For the 3-SAT problem, we find two transitions as the ratio
$\alpha$ of logical clauses per Boolean variables increases. At the first one
$\alpha_s \simeq 3.96$, a non-trivial organization of the solution space in
geometrically separated clusters emerges. The multiplicity of these clusters as
well as the typical distances between different solutions are calculated. At
the second threshold $\alpha_c \simeq 4.48$, satisfying assignments disappear
and a finite fraction $B_0 \simeq 0.13$ of variables are overconstrained and
take the same values in all optimal (though unsatisfying) assignments. These
values have to be compared to $\alpha_c \simeq 4.27, B_0 \simeq 0.4$ obtained
from numerical experiments on small instances. Within the present variational
approach, the SAT-UNSAT transition naturally appears as a mixture of a first
and a second order transition. For the mixed $2+p$-SAT with $p&lt;2/5$, the
behavior is as expected much simpler: a unique smooth transition from SAT to
UNSAT takes place at $\alpha_c=1/(1-p)$.
</dc:description>
 <dc:description>Comment: 24 pages, 6 eps figures, to be published in Europ. Phys. J. B</dc:description>
 <dc:date>1999-07-22</dc:date>
 <dc:date>1999-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/9907343</dc:identifier>
 <dc:identifier>Eur. Phys. J. B 14, 551 (2000)</dc:identifier>
 <dc:identifier>doi:10.1007/s100510051065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cond-mat/9909114</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Massively Parallel Algorithms and Fluctuating Time Horizons to
  Non-equilibrium Surface Growth</dc:title>
 <dc:creator>Korniss, G.</dc:creator>
 <dc:creator>Toroczkai, Z.</dc:creator>
 <dc:creator>Novotny, M. A.</dc:creator>
 <dc:creator>Rikvold, P. A.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  We study the asymptotic scaling properties of a massively parallel algorithm
for discrete-event simulations where the discrete events are Poisson arrivals.
The evolution of the simulated time horizon is analogous to a non-equilibrium
surface. Monte Carlo simulations and a coarse-grained approximation indicate
that the macroscopic landscape in the steady state is governed by the
Edwards-Wilkinson Hamiltonian. Since the efficiency of the algorithm
corresponds to the density of local minima in the associated surface, our
results imply that the algorithm is asymptotically scalable.
</dc:description>
 <dc:description>Comment: RevTex, 4 pages, 3 figures</dc:description>
 <dc:date>1999-09-07</dc:date>
 <dc:date>2000-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cond-mat/9909114</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 84, 1351 (2000).</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.84.1351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Von Neumann Quantum Logic vs. Classical von Neumann Architecture?</dc:title>
 <dc:creator>Vlasov, Alexander Yu.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>F.4</dc:subject>
 <dc:description>  The name of John von Neumann is common both in quantum mechanics and computer
science. Are they really two absolutely unconnected areas? Many works devoted
to quantum computations and communications are serious argument to suggest
about existence of such a relation, but it is impossible to touch the new and
active theme in a short review. In the paper are described the structures and
models of linear algebra and just due to their generality it is possible to use
universal description of very different areas as quantum mechanics and theory
of Bayesian image analysis, associative memory, neural networks, fuzzy logic.
</dc:description>
 <dc:description>Comment: 4 pages LaTeXe, two columns, 1 inline logo, submitted to III
  International Conference on Soft Computing and Measurements SCM'2000</dc:description>
 <dc:date>2000-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum Description Length and Compositionality</dc:title>
 <dc:creator>Zadrozny, Wlodek</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We present a non-vacuous definition of compositionality. It is based on the
idea of combining the minimum description length principle with the original
definition of compositionality (that is, that the meaning of the whole is a
function of the meaning of the parts).
  The new definition is intuitive and allows us to distinguish between
compositional and non-compositional semantics, and between idiomatic and
non-idiomatic expressions. It is not ad hoc, since it does not make any
references to non-intrinsic properties of meaning functions (like being a
polynomial). Moreover, it allows us to compare different meaning functions with
respect to how compositional they are. It bridges linguistic and corpus-based,
statistical approaches to natural language understanding.
</dc:description>
 <dc:date>2000-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001002</dc:identifier>
 <dc:identifier>H.Bunt and R.Muskens(Eds.) &quot;Computing Meaning&quot; Vol.1. Kluwer 1999.
  pp.113-128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why C++ is not very fit for GUI programming</dc:title>
 <dc:creator>Kiselyov, Oleg</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>D.1.5</dc:subject>
 <dc:description>  With no intent of starting a holy war, this paper lists several annoying C++
birthmarks that the author has come across developing GUI class libraries.
C++'s view of classes, instances and hierarchies appears tantalizingly close to
GUI concepts of controls, widgets, window classes and subwindows. OO models of
C++ and of a window system are however different. C++ was designed to be a
&quot;static&quot; language with a lexical name scoping, static type checking and
hierarchies defined at compile time. Screen objects on the other hand are
inherently dynamic; they usually live well beyond the procedure/block that
created them; the hierarchy of widgets is defined to a large extent by layout,
visibility and event flow. Many GUI fundamentals such as dynamic and geometric
hierarchies of windows and controls, broadcasting and percolation of events are
not supported directly by C++ syntax or execution semantics (or supported as
&quot;exceptions&quot; -- pun intended). Therefore these features have to be emulated in
C++ GUI code. This leads to duplication of a graphical toolkit or a window
manager functionality, code bloat, engaging in unsafe practices and forgoing of
many strong C++ features (like scoping rules and compile-time type checking).
This paper enumerates a few major C++/GUI sores and illustrates them on simple
examples.
</dc:description>
 <dc:description>Comment: Previous version of this paper appeared in Proc. MacHack'95</dc:description>
 <dc:date>2000-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiplicative Algorithm for Orthgonal Groups and Independent Component
  Analysis</dc:title>
 <dc:creator>Akuzawa, Toshinao</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  The multiplicative Newton-like method developed by the author et al. is
extended to the situation where the dynamics is restricted to the orthogonal
group. A general framework is constructed without specifying the cost function.
Though the restriction to the orthogonal groups makes the problem somewhat
complicated, an explicit expression for the amount of individual jumps is
obtained. This algorithm is exactly second-order-convergent. The global
instability inherent in the Newton method is remedied by a
Levenberg-Marquardt-type variation. The method thus constructed can readily be
applied to the independent component analysis. Its remarkable performance is
illustrated by a numerical simulation.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures</dc:description>
 <dc:date>2000-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001005</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effect of different packet sizes on RED performance</dc:title>
 <dc:creator>De Cnodder, Stefaan</dc:creator>
 <dc:creator>Elloumi, Omar</dc:creator>
 <dc:creator>Pauwels, Kenny</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  We consider the adaptation of random early detection (RED) as an active queue
management algorithm for TCP traffic in Internet gateways where different
maximum transfer units (MTUs) are used. We studied the two existing RED
variants and point out a weakness in both. The first variant where the drop
probability is independent from the packet size discriminates connections with
smaller MTUs. The second variant results in a very high Packet Loss Ratio
(PLR), and as a consequence low goodput, for connections with higher MTUs. We
show that fairness in terms of loss and goodput can be supplied through an
appropriate setting of the RED algorithm.
</dc:description>
 <dc:description>Comment: Effect of different packet size on RED performance number of pages: 9
  Submitted to IEEE Communication Letters</dc:description>
 <dc:date>2000-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compositionality, Synonymy, and the Systematic Representation of Meaning</dc:title>
 <dc:creator>Lappin, Shalom</dc:creator>
 <dc:creator>Zadrozny, Wlodek</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  In a recent issue of Linguistics and Philosophy Kasmi and Pelletier (1998)
(K&amp;P), and Westerstahl (1998) criticize Zadrozny's (1994) argument that any
semantics can be represented compositionally. The argument is based upon
Zadrozny's theorem that every meaning function m can be encoded by a function
\mu such that (i) for any expression E of a specified language L, m(E) can be
recovered from \mu(E), and (ii) \mu is a homomorphism from the syntactic
structures of L to interpretations of L.
  In both cases, the primary motivation for the objections brought against
Zadrozny's argument is the view that his encoding of the original meaning
function does not properly reflect the synonymy relations posited for the
language.
  In this paper, we argue that these technical criticisms do not go through. In
particular, we prove that \mu properly encodes synonymy relations, i.e. if two
expressions are synonymous, then their compositional meanings are identical.
This corrects some misconceptions about the function \mu, e.g. Janssen (1997).
  We suggest that the reason that semanticists have been anxious to preserve
compositionality as a significant constraint on semantic theory is that it has
been mistakenly regarded as a condition that must be satisfied by any theory
that sustains a systematic connection between the meaning of an expression and
the meanings of its parts. Recent developments in formal and computational
semantics show that systematic theories of meanings need not be compositional.
</dc:description>
 <dc:description>Comment: Submitted to &quot;Linguistics and Philosophy&quot;</dc:description>
 <dc:date>2000-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001007</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RED behavior with different packet sizes</dc:title>
 <dc:creator>De Cnodder, Stefaan</dc:creator>
 <dc:creator>Elloumi, Omar</dc:creator>
 <dc:creator>Pauwels, Kenny</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  We consider the adaptation of random early detection (RED) as a buffer
management algorithm for TCP traffic in Internet gateways where different
maximum transfer units (MTUs) are used. We studied the two RED variants
described in [4] and point out a weakness in both. The first variant where drop
probability is independent from the packet size discriminates connections with
smaller MTUs. The second variant results in a very high packet loss ratio
(PLR), and as a consequence low goodput, for connections with higher MTUs. We
show that fairness in terms of loss and goodput can be supplied through an
appropriate setting of the RED algorithm.
</dc:description>
 <dc:description>Comment: 13 pages, submitted to IEEE symposium on computer communications
  (ISCC2000)</dc:description>
 <dc:date>2000-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001007</dc:identifier>
 <dc:identifier>doi:10.1109/ISCC.2000.860741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting the expected behavior of agents that learn about agents: the
  CLRI framework</dc:title>
 <dc:creator>Vidal, Jose M.</dc:creator>
 <dc:creator>Durfee, Edmund H.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  We describe a framework and equations used to model and predict the behavior
of multi-agent systems (MASs) with learning agents. A difference equation is
used for calculating the progression of an agent's error in its decision
function, thereby telling us how the agent is expected to fare in the MAS. The
equation relies on parameters which capture the agent's learning abilities,
such as its change rate, learning rate and retention rate, as well as relevant
aspects of the MAS such as the impact that agents have on each other. We
validate the framework with experimental results using reinforcement learning
agents in a market system, as well as with other experimental results gathered
from the AI literature. Finally, we use PAC-theory to show how to calculate
bounds on the values of the learning parameters.
</dc:description>
 <dc:date>2000-01-12</dc:date>
 <dc:date>2003-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001008</dc:identifier>
 <dc:identifier>Autonomous Agents and Multi-Agent Systems Journal, January 2003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fractal Symbolic Analysis</dc:title>
 <dc:creator>Mateev, Nikolay</dc:creator>
 <dc:creator>Menon, Vijay</dc:creator>
 <dc:creator>Pingali, Keshav</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:description>  Restructuring compilers use dependence analysis to prove that the meaning of
a program is not changed by a transformation. A well-known limitation of
dependence analysis is that it examines only the memory locations read and
written by a statement, and does not assume any particular interpretation for
the operations in that statement. Exploiting the semantics of these operations
enables a wider set of transformations to be used, and is critical for
optimizing important codes such as LU factorization with pivoting.
  Symbolic execution of programs enables the exploitation of such semantic
properties, but it is intractable for all but the simplest programs. In this
paper, we propose a new form of symbolic analysis for use in restructuring
compilers. Fractal symbolic analysis compares a program and its transformed
version by repeatedly simplifying these programs until symbolic analysis
becomes tractable, ensuring that equality of simplified programs is sufficient
to guarantee equality of the original programs. We present a prototype
implementation of fractal symbolic analysis, and show how it can be used to
optimize the cache performance of LU factorization with pivoting.
</dc:description>
 <dc:description>Comment: 13 pages, 19 figures</dc:description>
 <dc:date>2000-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Real World Implementation of Answer Extraction</dc:title>
 <dc:creator>Molla, D.</dc:creator>
 <dc:creator>Berri, J.</dc:creator>
 <dc:creator>Hess, M.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  In this paper we describe ExtrAns, an answer extraction system. Answer
extraction (AE) aims at retrieving those exact passages of a document that
directly answer a given user question. AE is more ambitious than information
retrieval and information extraction in that the retrieval results are phrases,
not entire documents, and in that the queries may be arbitrarily specific. It
is less ambitious than full-fledged question answering in that the answers are
not generated from a knowledge base but looked up in the text of documents. The
current version of ExtrAns is able to parse unedited Unix &quot;man pages&quot;, and
derive the logical form of their sentences. User queries are also translated
into logical forms. A theorem prover then retrieves the relevant phrases, which
are presented through selective highlighting in their context.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2000-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001010</dc:identifier>
 <dc:identifier>Proc. of 9th International Conference and Workshop on Database and
  Expert Systems. Workshop &quot;Natural Language and Information Systems&quot;
  (NLIS'98). Vienna: 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Agents of Choice: Tools that Facilitate Notice and Choice about Web Site
  Data Practices</dc:title>
 <dc:creator>Cranor, Lorrie Faith</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.1</dc:subject>
 <dc:description>  A variety of tools have been introduced recently that are designed to help
people protect their privacy on the Internet. These tools perform many
different functions in-cluding encrypting and/or anonymizing communications,
preventing the use of persistent identifiers such as cookies, automatically
fetching and analyzing web site privacy policies, and displaying
privacy-related information to users. This paper discusses the set of privacy
tools that aim specifically at facilitating notice and choice about Web site
data practices. While these tools may also have components that perform other
functions such as encryption, or they may be able to work in conjunction with
other privacy tools, the primary pur-pose of these tools is to help make users
aware of web site privacy practices and to make it easier for users to make
informed choices about when to provide data to web sites. Examples of such
tools include the Platform for Privacy Preferences (P3P) and various
infomediary services.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2000-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001011</dc:identifier>
 <dc:identifier>Proceedings of the 21st International Conference on Privacy and
  Personal Data Protection, 13-15 September 1999, Hong Kong SAR, China, p.
  19-25</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measures of Distributional Similarity</dc:title>
 <dc:creator>Lee, Lillian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We study distributional similarity measures for the purpose of improving
probability estimation for unseen cooccurrences. Our contributions are
three-fold: an empirical comparison of a broad range of measures; a
classification of similarity functions based on the information that they
incorporate; and the introduction of a novel function that is superior at
evaluating potential proxy distributions.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures</dc:description>
 <dc:date>2000-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001012</dc:identifier>
 <dc:identifier>37th Annual Meeting of the ACL, 1999, pp. 25-32</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001013</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query Complexity: Worst-Case Quantum Versus Average-Case Classical</dc:title>
 <dc:creator>Aaronson, Scott</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:description>  In this note we investigate the relationship between worst-case quantum query
complexity and average-case classical query complexity. Specifically, we show
that if a quantum computer can evaluate a total Boolean function f with bounded
error using T queries in the worst case, then a deterministic classical
computer can evaluate f using O(T^5) queries in the average case, under a
uniform distribution of inputs. If f is monotone, we show furthermore that only
O(T^3) queries are needed. Previously, Beals et al. (1998) showed that if a
quantum computer can evaluate f with bounded error using T queries in the worst
case, then a deterministic classical computer can evaluate f using O(T^6)
queries in the worst case, or O(T^4) if f is monotone. The optimal bound is
conjectured to be O(T^2), but improving on O(T^6) remains an open problem.
Relating worst-case quantum complexity to average-case classical complexity may
suggest new ways to reduce the polynomial gap in the ordinary worst-case versus
worst-case setting.
</dc:description>
 <dc:description>Comment: Withdrawn. The results in the paper only work for a certain subclass
  of Boolean functions, in which block sensitivity has properties similar to
  those of ordinary sensitivity. They don't work in general</dc:description>
 <dc:date>2000-01-19</dc:date>
 <dc:date>2000-06-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nondeterministic Quantum Query and Quantum Communication Complexities</dc:title>
 <dc:creator>de Wolf, Ronald</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2.0</dc:subject>
 <dc:description>  We study nondeterministic quantum algorithms for Boolean functions f. Such
algorithms have positive acceptance probability on input x iff f(x)=1. In the
setting of query complexity, we show that the nondeterministic quantum
complexity of a Boolean function is equal to its ``nondeterministic
polynomial'' degree. We also prove a quantum-vs-classical gap of 1 vs n for
nondeterministic query complexity for a total function. In the setting of
communication complexity, we show that the nondeterministic quantum complexity
of a two-party function is equal to the logarithm of the rank of a
nondeterministic version of the communication matrix. This implies that the
quantum communication complexities of the equality and disjointness functions
are n+1 if we do not allow any error probability. We also exhibit a total
function in which the nondeterministic quantum communication complexity is
exponentially smaller than its classical counterpart.
</dc:description>
 <dc:description>Comment: 19 pages, Latex</dc:description>
 <dc:date>2000-01-19</dc:date>
 <dc:date>2004-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001014</dc:identifier>
 <dc:identifier>SIAM Journal on Computing, 32(3):681-699, 2003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Agent Only Knowing</dc:title>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:creator>Lakemeyer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.4, F.4.1</dc:subject>
 <dc:description>  Levesque introduced a notion of ``only knowing'', with the goal of capturing
certain types of nonmonotonic reasoning. Levesque's logic dealt with only the
case of a single agent. Recently, both Halpern and Lakemeyer independently
attempted to extend Levesque's logic to the multi-agent case. Although there
are a number of similarities in their approaches, there are some significant
differences. In this paper, we reexamine the notion of only knowing, going back
to first principles. In the process, we simplify Levesque's completeness proof,
and point out some problems with the earlier definitions. This leads us to
reconsider what the properties of only knowing ought to be. We provide an axiom
system that captures our desiderata, and show that it has a semantics that
corresponds to it. The axiom system has an added feature of interest: it
includes a modal operator for satisfiability, and thus provides a complete
axiomatization for satisfiability in the logic K45.
</dc:description>
 <dc:description>Comment: To appear, Journal of Logic and Computation</dc:description>
 <dc:date>2000-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Take-home Complexity</dc:title>
 <dc:creator>Hemaspaandra, Lane A.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - General Literature</dc:subject>
 <dc:subject>K.3.2</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  We discuss the use of projects in first-year graduate complexity theory
courses.
</dc:description>
 <dc:description>Comment: Updated version of Complexity Theory Column 20, Sigact News
  29(2):9-13, 1998</dc:description>
 <dc:date>2000-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bezier Curves Intersection Using Relief Perspective</dc:title>
 <dc:creator>Hlusek, Radoslav</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:subject>J.6</dc:subject>
 <dc:description>  Presented paper describes the method for finding the intersection of class
space rational Bezier curves. The problem curve/curve intersection belongs
among basic geometric problems and the aim of this article is to describe the
new technique to solve the problem using relief perspective and Bezier
clipping.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, to appear in Proceedings of WSCG'2000 in Plzen,
  Czech Republic</dc:description>
 <dc:date>2000-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive simulated annealing (ASA): Lessons learned</dc:title>
 <dc:creator>Ingber, Lester</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  Adaptive simulated annealing (ASA) is a global optimization algorithm based
on an associated proof that the parameter space can be sampled much more
efficiently than by using other previous simulated annealing algorithms. The
author's ASA code has been publicly available for over two years. During this
time the author has volunteered to help people via e-mail, and the feedback
obtained has been used to further develop the code. Some lessons learned, in
particular some which are relevant to other simulated annealing algorithms, are
described.
</dc:description>
 <dc:description>Comment: 26 PostScript pages</dc:description>
 <dc:date>2000-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001018</dc:identifier>
 <dc:identifier>Control and Cybernetics 25 (1996) 33-54</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PushPush is NP-hard in 2D</dc:title>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Demaine, Martin L.</dc:creator>
 <dc:creator>O'Rourke, Joseph</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.m</dc:subject>
 <dc:description>  We prove that a particular pushing-blocks puzzle is intractable in 2D,
improving an earlier result that established intractability in 3D [OS99]. The
puzzle, inspired by the game *PushPush*, consists of unit square blocks on an
integer lattice. An agent may push blocks (but never pull them) in attempting
to move between given start and goal positions. In the PushPush version, the
agent can only push one block at a time, and moreover, each block, when pushed,
slides the maximal extent of its free range. We prove this version is NP-hard
in 2D by reduction from SAT.
</dc:description>
 <dc:description>Comment: 18 pages, 13 figures, 1 table. Improves cs.CG/9911013</dc:description>
 <dc:date>2000-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Syntactic Structure for Natural Language Modeling</dc:title>
 <dc:creator>Chelba, Ciprian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>G.3, I.2.7, I.5.1, I.5.4</dc:subject>
 <dc:description>  The thesis presents an attempt at using the syntactic structure in natural
language for improved language models for speech recognition. The structured
language model merges techniques in automatic parsing and language modeling
using an original probabilistic parameterization of a shift-reduce parser. A
maximum likelihood reestimation procedure belonging to the class of
expectation-maximization algorithms is employed for training the model.
Experiments on the Wall Street Journal, Switchboard and Broadcast News corpora
show improvement in both perplexity and word error rate - word lattice
rescoring - over the standard 3-gram language model. The significance of the
thesis lies in presenting an original approach to language modeling that uses
the hierarchical - syntactic - structure in natural language to improve on
current 3-gram modeling techniques for large vocabulary speech recognition.
</dc:description>
 <dc:description>Comment: Advisor: Frederick Jelinek, Ph.D. Thesis, 122 pages; removed unused
  .eps file</dc:description>
 <dc:date>2000-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Refinement of a Structured Language Model</dc:title>
 <dc:creator>Chelba, Ciprian</dc:creator>
 <dc:creator>Jelinek, Frederick</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>G.3, I.2.7, I.5.1, I.5.4</dc:subject>
 <dc:description>  A new language model for speech recognition inspired by linguistic analysis
is presented. The model develops hidden hierarchical structure incrementally
and uses it to extract meaningful information from the word history - thus
enabling the use of extended distance dependencies - in an attempt to
complement the locality of currently used n-gram Markov models. The model, its
probabilistic parametrization, a reestimation algorithm for the model
parameters and a set of experiments meant to evaluate its potential for speech
recognition are presented.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2000-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001021</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on Advances in Pattern
  Recognition, 1998, pp. 275-284, Plymouth, UK</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recognition Performance of a Structured Language Model</dc:title>
 <dc:creator>Chelba, Ciprian</dc:creator>
 <dc:creator>Jelinek, Frederick</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>G.3, I.2.7, I.5.1, I.5.4</dc:subject>
 <dc:description>  A new language model for speech recognition inspired by linguistic analysis
is presented. The model develops hidden hierarchical structure incrementally
and uses it to extract meaningful information from the word history - thus
enabling the use of extended distance dependencies - in an attempt to
complement the locality of currently used trigram models. The structured
language model, its probabilistic parameterization and performance in a
two-pass speech recognizer are presented. Experiments on the SWITCHBOARD corpus
show an improvement in both perplexity and word error rate over conventional
trigram models.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2000-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001022</dc:identifier>
 <dc:identifier>Proceedings of Eurospeech, 1999, pp. 1567-1570, Budapest, Hungary</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured Language Modeling for Speech Recognition</dc:title>
 <dc:creator>Chelba, Ciprian</dc:creator>
 <dc:creator>Jelinek, Frederick</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>G.3, I.2.7, I.5.1, I.5.4</dc:subject>
 <dc:description>  A new language model for speech recognition is presented. The model develops
hidden hierarchical syntactic-like structure incrementally and uses it to
extract meaningful information from the word history, thus complementing the
locality of currently used trigram models. The structured language model (SLM)
and its performance in a two-pass speech recognizer --- lattice decoding ---
are presented. Experiments on the WSJ corpus show an improvement in both
perplexity (PPL) and word error rate (WER) over conventional trigram models.
</dc:description>
 <dc:description>Comment: 4 pages + 2 pages of ERRATA</dc:description>
 <dc:date>2000-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001023</dc:identifier>
 <dc:identifier>Proceedings of NLDB'99, Klagenfurt, Austria</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Parallel Algorithm for Dilated Contour Extraction from Bilevel Images</dc:title>
 <dc:creator>Schlei, B. R.</dc:creator>
 <dc:creator>Prasad, L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.10, D.1.3, G.1.2</dc:subject>
 <dc:description>  We describe a simple, but efficient algorithm for the generation of dilated
contours from bilevel images. The initial part of the contour extraction is
explained to be a good candidate for parallel computer code generation. The
remainder of the algorithm is of linear nature.
</dc:description>
 <dc:description>Comment: 5 pages, including 3 figures. For additional detail check
  http://www.nis.lanl.gov/~bschlei/labvis/index.html</dc:description>
 <dc:date>2000-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Geometry Column 38</dc:title>
 <dc:creator>O'Rourke, Joseph</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:description>  Recent results on curve reconstruction are described.
</dc:description>
 <dc:description>Comment: 3 pages, 1 figure, 18 refs</dc:description>
 <dc:date>2000-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Logic for SDSI's Linked Local Name Spaces</dc:title>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:creator>van der Meyden, Ron</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.4.6, K.6.5, C.2.0, F,4,1</dc:subject>
 <dc:description>  Abadi has introduced a logic to explicate the meaning of local names in SDSI,
the Simple Distributed Security Infrastructure proposed by Rivest and Lampson.
Abadi's logic does not correspond precisely to SDSI, however; it draws
conclusions about local names that do not follow from SDSI's name resolution
algorithm. Moreover, its semantics is somewhat unintuitive. This paper presents
the Logic of Local Name Containment, which does not suffer from these
deficiencies. It has a clear semantics and provides a tight characterization of
SDSI name resolution. The semantics is shown to be closely related to that of
logic programs, leading to an approach to the efficient implementation of
queries concerning local names. A complete axiomatization of the logic is also
provided.
</dc:description>
 <dc:description>Comment: To appear, Journal of Computer Security</dc:description>
 <dc:date>2000-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0001027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pattern Discovery and Computational Mechanics</dc:title>
 <dc:creator>Shalizi, Cosma Rohilla</dc:creator>
 <dc:creator>Crutchfield, James P.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:description>  Computational mechanics is a method for discovering, describing and
quantifying patterns, using tools from statistical physics. It constructs
optimal, minimal models of stochastic processes and their underlying causal
structures. These models tell us about the intrinsic computation embedded
within a process---how it stores and transforms information. Here we summarize
the mathematics of computational mechanics, especially recent optimality and
uniqueness results. We also expound the principles and motivations underlying
computational mechanics, emphasizing its connections to the minimum description
length principle, PAC theory, and other aspects of machine learning.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figures; submitted to the Proceedings of the 17th
  International Conference on Machine Learning (differs slightly in pagination
  and citation format from that version)</dc:description>
 <dc:date>2000-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0001027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing large and small stable models</dc:title>
 <dc:creator>Truszczynski, Miroslaw</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  In this paper, we focus on the problem of existence and computing of small
and large stable models. We show that for every fixed integer k, there is a
linear-time algorithm to decide the problem LSM (large stable models problem):
does a logic program P have a stable model of size at least |P|-k. In contrast,
we show that the problem SSM (small stable models problem) to decide whether a
logic program P has a stable model of size at most k is much harder. We present
two algorithms for this problem but their running time is given by polynomials
of order depending on k. We show that the problem SSM is fixed-parameter
intractable by demonstrating that it is W[2]-hard. This result implies that it
is unlikely, an algorithm exists to compute stable models of size at most k
that would run in time O(n^c), where c is a constant independent of k. We also
provide an upper bound on the fixed-parameter complexity of the problem SSM by
showing that it belongs to the class W[3].
</dc:description>
 <dc:description>Comment: This paper is a full version of the conference paper of the same
  title that was published in the Proceedings of the 1999 International
  Conference on Logic Programming, Las Cruces, New Mexico, MIT Press, pp.
  169-183. The proofs of the results in Section 4 were replaced by more elegant
  and general ones</dc:description>
 <dc:date>2000-02-03</dc:date>
 <dc:date>2000-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002001</dc:identifier>
 <dc:identifier>Theory and Practice of Logic Programming, 2(1), pp. 2002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uniform semantic treatment of default and autoepistemic logics</dc:title>
 <dc:creator>Denecker, Marc</dc:creator>
 <dc:creator>Marek, Victor W.</dc:creator>
 <dc:creator>Truszczynski, Miroslaw</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  We revisit the issue of connections between two leading formalisms in
nonmonotonic reasoning: autoepistemic logic and default logic. For each logic
we develop a comprehensive semantic framework based on the notion of a belief
pair. The set of all belief pairs together with the so called knowledge
ordering forms a complete lattice. For each logic, we introduce several
semantics by means of fixpoints of operators on the lattice of belief pairs.
Our results elucidate an underlying isomorphism of the respective semantic
constructions. In particular, we show that the interpretation of defaults as
modal formulas proposed by Konolige allows us to represent all semantics for
default logic in terms of the corresponding semantics for autoepistemic logic.
Thus, our results conclusively establish that default logic can indeed be
viewed as a fragment of autoepistemic logic. However, as we also demonstrate,
the semantics of Moore and Reiter are given by different operators and occupy
different locations in their corresponding families of semantics. This result
explains the source of the longstanding difficulty to formally relate these two
semantics. In the paper, we also discuss approximating skeptical reasoning with
autoepistemic and default logics and establish constructive principles behind
such approximations.
</dc:description>
 <dc:description>Comment: Proceedings of the Seventh International Conference on Principles of
  Knowledge Representation and Reasoning (KR2000); 11 pages</dc:description>
 <dc:date>2000-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002002</dc:identifier>
 <dc:identifier>Artificial Intelligence Journal, 143 (2003), pp. 79--122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the accuracy and running time of GSAT</dc:title>
 <dc:creator>East, Deborah</dc:creator>
 <dc:creator>Truszczynski, Miroslaw</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  Randomized algorithms for deciding satisfiability were shown to be effective
in solving problems with thousands of variables. However, these algorithms are
not complete. That is, they provide no guarantee that a satisfying assignment,
if one exists, will be found. Thus, when studying randomized algorithms, there
are two important characteristics that need to be considered: the running time
and, even more importantly, the accuracy --- a measure of likelihood that a
satisfying assignment will be found, provided one exists. In fact, we argue
that without a reference to the accuracy, the notion of the running time for
randomized algorithms is not well-defined. In this paper, we introduce a formal
notion of accuracy. We use it to define a concept of the running time. We use
both notions to study the random walk strategy GSAT algorithm. We investigate
the dependence of accuracy on properties of input formulas such as
clause-to-variable ratio and the number of satisfying assignments. We
demonstrate that the running time of GSAT grows exponentially in the number of
variables of the input formula for randomly generated 3-CNF formulas and for
the formulas encoding 3- and 4-colorability of graphs.
</dc:description>
 <dc:description>Comment: Proceedings of the 9th Portuguese Conference on Artificial
  Intelligence (EPIA'99), Lecture Notes in Artificial Intelligence, vol. 1695,
  Springer-Verlag, 1999</dc:description>
 <dc:date>2000-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Model Checking for Multimedia</dc:title>
 <dc:creator>Bryans, Jeremy</dc:creator>
 <dc:creator>Bowman, Howard</dc:creator>
 <dc:creator>Derrick, John</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  Modern distributed systems include a class of applications in which
non-functional requirements are important. In particular, these applications
include multimedia facilities where real time constraints are crucial to their
correct functioning. In order to specify such systems it is necessary to
describe that events occur at times given by probability distributions and
stochastic automata have emerged as a useful technique by which such systems
can be specified and verified.
  However, stochastic descriptions are very general, in particular they allow
the use of general probability distribution functions, and therefore their
verification can be complex. In the last few years, model checking has emerged
as a useful verification tool for large systems.
  In this paper we describe two model checking algorithms for stochastic
automata. These algorithms consider how properties written in a simple
probabilistic real-time logic can be checked against a given stochastic
automaton.
</dc:description>
 <dc:description>Comment: 35 pages; 6 figures</dc:description>
 <dc:date>2000-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully Sequential and Distributed Dynamic Algorithms for Minimum Spanning
  Trees</dc:title>
 <dc:creator>Mohapatra, Pradosh Kumar</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  In this paper, we present a fully-dynamic distributed algorithm for
maintaining a minimum spanning tree on general graphs with positive real edge
weights. The goal of a dynamic MST algorithm is to update efficiently the
minimum spanning tree after dynamic changes like edge weight changes, rather
than having to recompute it from scatch each time. The first part of the paper
surveys various algorithms available today both in sequential and distributed
environments to solve static MST problem. We also present some of the efficient
sequential algorithms for computing dynamic MST like the Frederickson's
algorithm and Eppstein's sparsification technique. Lastly we present our new
sequential and distributed algorithms for dynamic MST problem. To our
knowledge, this is the first of the distributed algorithms for computing
dynamic MSTs.
</dc:description>
 <dc:description>Comment: 32 pages, 4 figures</dc:description>
 <dc:date>2000-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002006</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiplicative Nonholonomic/Newton -like Algorithm</dc:title>
 <dc:creator>Akuzawa, Toshinao</dc:creator>
 <dc:creator>Murata, Noboru</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  We construct new algorithms from scratch, which use the fourth order cumulant
of stochastic variables for the cost function. The multiplicative updating rule
here constructed is natural from the homogeneous nature of the Lie group and
has numerous merits for the rigorous treatment of the dynamics. As one
consequence, the second order convergence is shown. For the cost function,
functions invariant under the componentwise scaling are choosen. By identifying
points which can be transformed to each other by the scaling, we assume that
the dynamics is in a coset space. In our method, a point can move toward any
direction in this coset. Thus, no prewhitening is required.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2000-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002006</dc:identifier>
 <dc:identifier>doi:10.1016/S0960-0779(00)00077-1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Requirements of Text Processing Lexicons</dc:title>
 <dc:creator>Litkowski, K.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  As text processing systems expand in scope, they will require ever larger
lexicons along with a parsing capability for discriminating among many senses
of a word. Existing systems do not incorporate such subtleties in meaning for
their lexicons. Ordinary dictionaries contain such information, but are largely
untapped. When the contents of dictionaries are scrutinized, they reveal many
requirements that must be satisfied in representing meaning and in developing
semantic parsers. These requirements were identified in research designed to
find primitive verb concepts. The requirements are outlined and general
procedures for satisfying them through the use of ordinary dictionaries are
described, illustrated by building frames for and examining the definitions of
&quot;change&quot; and its uses as a hypernym in other definitions.
</dc:description>
 <dc:description>Comment: HTML File (72k, about 20 pages). Paper for which extended abstract
  appears in ACL proceedings of 1980</dc:description>
 <dc:date>2000-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002007</dc:identifier>
 <dc:identifier>Proceedings of the 18th Annual Meeting of the Association for
  Computational Linguistics, Philadelphia, PA (1980), pp. 153-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Automata with Boundary</dc:title>
 <dc:creator>Gates, R.</dc:creator>
 <dc:creator>Katis, P.</dc:creator>
 <dc:creator>Sabadini, N.</dc:creator>
 <dc:creator>Walters, R. F. C.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  We present a theory of automata with boundary for designing, modelling and
analysing distributed systems. Notions of behaviour, design and simulation
appropriate to the theory are defined. The problem of model checking for
deadlock detection is discussed, and an algorithm for state space reduction in
exhaustive search, based on the theory presented here, is described. Three
examples of the application of the theory are given, one in the course of the
development of the ideas and two as illustrative examples of the use of the
theory.
</dc:description>
 <dc:description>Comment: 41 pages, 22 figures. Uses Paul Taylor's diagrams macros, see
  http://www.ctan.org/tex-archive/macros/generic/diagrams/taylor/</dc:description>
 <dc:date>2000-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Syntactic Autonomy: Why There is no Autonomy without Symbols and How
  Self-Organization Might Evolve Them</dc:title>
 <dc:creator>Rocha, Luis M.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>A.m</dc:subject>
 <dc:description>  Two different types of agency are discussed based on dynamically coherent and
incoherent couplings with an environment respectively. I propose that until a
private syntax (syntactic autonomy) is discovered by dynamically coherent
agents, there are no significant or interesting types of closure or autonomy.
When syntactic autonomy is established, then, because of a process of
description-based selected self-organization, open-ended evolution is enabled.
At this stage, agents depend, in addition to dynamics, on localized, symbolic
memory, thus adding a level of dynamical incoherence to their interaction with
the environment. Furthermore, it is the appearance of syntactic autonomy which
enables much more interesting types of closures amongst agents which share the
same syntax. To investigate how we can study the emergence of syntax from
dynamical systems, experiments with cellular automata leading to emergent
computation to solve non-trivial tasks are discussed. RNA editing is also
mentioned as a process that may have been used to obtain a primordial
biological code necessary open-ended evolution.
</dc:description>
 <dc:date>2000-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Biologically Motivated Distributed Designs for Adaptive Knowledge
  Management</dc:title>
 <dc:creator>Rocha, Luis M.</dc:creator>
 <dc:creator>Bollen, Johan</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3, H.1, H.2, I.2</dc:subject>
 <dc:description>  We discuss how distributed designs that draw from biological network
metaphors can largely improve the current state of information retrieval and
knowledge management of distributed information systems. In particular, two
adaptive recommendation systems named TalkMine and @ApWeb are discussed in more
detail. TalkMine operates at the semantic level of keywords. It leads different
databases to learn new and adapt existing keywords to the categories recognized
by its communities of users using distributed algorithms. @ApWeb operates at
the structural level of information resources, namely citation or hyperlink
structure. It relies on collective behavior to adapt such structure to the
expectations of users. TalkMine and @ApWeb are currently being implemented for
the research library of the Los Alamos National Laboratory under the Active
Recommendation Project. Together they define a biologically motivated
information retrieval system, recommending simultaneously at the level of user
knowledge categories expressed in keywords, and at the level of individual
documents and their associations to other documents. Rather than passive
information retrieval, with this system, users obtain an active, evolving
interaction with information resources.
</dc:description>
 <dc:description>Comment: To appear in Design Principles for the Immune System and Other
  Distributed Autonomous Systems. i. Cohen and L. Segel (Eds.). Oxford
  University Press</dc:description>
 <dc:date>2000-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Internet Multicast System for the Stock Market</dc:title>
 <dc:creator>Maxemchuk, N. F.</dc:creator>
 <dc:creator>Shur, D. H.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2</dc:subject>
 <dc:description>  We are moving toward a distributed, international, twenty-four hour,
electronic stock exchange. The exchange will use the global Internet, or
internet technology. This system is a natural application of multicast because
there are a large number of receivers that should receive the same information
simultaneously.
  The data requirements for the stock exchange are discussed. The current
multicast protocols lack the reliability, fairness, and scalability needed in
this application. We describe a distributed architecture together with a
reliable multicast protocol, a modification of the RMP protocol, that has
characteristics appropriate for this application.
  The architecture is used in three applications: In the first, we construct a
unified stock ticker of the transactions that are being conducted on the
various physical and electronic exchanges. Our objective is to deliver the the
same combined ticker reliably and simultaneously to all receivers, anywhere in
the world. In the second, we construct a unified sequence of buy and sell
offers that are delivered to a single exchange or a collection of exchanges.
Our objective is to give all traders the same fair access to an exchange
independent of their relative distances to the exchange or the loss
characteristics of the international network. In the third, we construct a
distributed, electronic trading floor that can replace the current exchanges.
This application uses the innovations from the first two applications to
combine their fairness attributes.
</dc:description>
 <dc:description>Comment: 19 pages, postscript</dc:description>
 <dc:date>2000-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On The Closest String and Substring Problems</dc:title>
 <dc:creator>Li, Ming</dc:creator>
 <dc:creator>Ma, Bin</dc:creator>
 <dc:creator>Wang, Lusheng</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  The problem of finding a center string that is `close' to every given string
arises and has many applications in computational biology and coding theory.
This problem has two versions: the Closest String problem and the Closest
Substring problem. Assume that we are given a set of strings ${\cal S}=\{s_1,
s_2, ..., s_n\}$ of strings, say, each of length $m$. The Closest String
problem asks for the smallest $d$ and a string $s$ of length $m$ which is
within Hamming distance $d$ to each $s_i\in {\cal S}$. This problem comes from
coding theory when we are looking for a code not too far away from a given set
of codes. The problem is NP-hard. Berman et al give a polynomial time algorithm
for constant $d$. For super-logarithmic $d$, Ben-Dor et al give an efficient
approximation algorithm using linear program relaxation technique. The best
polynomial time approximation has ratio 4/3 for all $d$ given by Lanctot et al
and Gasieniec et al. The Closest Substring problem looks for a string $t$ which
is within Hamming distance $d$ away from a substring of each $s_i$. This
problem only has a $2- \frac{2}{2|\Sigma|+1}$ approximation algorithm
previously Lanctot et al and is much more elusive than the Closest String
problem, but it has many applications in finding conserved regions, genetic
drug target identification, and genetic probes in molecular biology. Whether
there are efficient approximation algorithms for both problems are major open
questions in this area. We present two polynomial time approxmation algorithms
with approximation ratio $1+ \epsilon$ for any small $\epsilon$ to settle both
questions.
</dc:description>
 <dc:date>2000-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing and Comparing Semantics of Programs in Multi-valued Logics</dc:title>
 <dc:creator>Loyer, Y.</dc:creator>
 <dc:creator>Spyratos, N.</dc:creator>
 <dc:creator>Stamate, D.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.0</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  The different semantics that can be assigned to a logic program correspond to
different assumptions made concerning the atoms whose logical values cannot be
inferred from the rules. Thus, the well founded semantics corresponds to the
assumption that every such atom is false, while the Kripke-Kleene semantics
corresponds to the assumption that every such atom is unknown. In this paper,
we propose to unify and extend this assumption-based approach by introducing
parameterized semantics for logic programs. The parameter holds the value that
one assumes for all atoms whose logical values cannot be inferred from the
rules. We work within multi-valued logic with bilattice structure, and we
consider the class of logic programs defined by Fitting.
  Following Fitting's approach, we define a simple operator that allows us to
compute the parameterized semantics, and to compare and combine semantics
obtained for different values of the parameter. The semantics proposed by
Fitting corresponds to the value false. We also show that our approach captures
and extends the usual semantics of conventional logic programs thereby unifying
their computation.
</dc:description>
 <dc:description>Comment: 10 pages, 1 figure, A preliminary version of this paper appeared in
  the form of an extended abstract in the conference Mathematical Foundations
  of Computer Science (MFCS'99)</dc:description>
 <dc:date>2000-02-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safe cooperative robot dynamics on graphs</dc:title>
 <dc:creator>Ghrist, Robert</dc:creator>
 <dc:creator>Koditschek, Daniel</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:description>  This paper initiates the use of vector fields to design, optimize, and
implement reactive schedules for safe cooperative robot patterns on planar
graphs. We consider Automated Guided Vehicles (AGV's) operating upon a
predefined network of pathways. In contrast to the case of locally Euclidean
configuration spaces, regularization of collisions is no longer a local
procedure, and issues concerning the global topology of configuration spaces
must be addressed. The focus of the present inquiry is the achievement of safe,
efficient, cooperative patterns in the simplest nontrivial example (a pair of
robots on a Y-network) by means of a state-event heirarchical controller.
</dc:description>
 <dc:description>Comment: 18 pages, 5 figures</dc:description>
 <dc:date>2000-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Genetic Algorithms for Extension Search in Default Logic</dc:title>
 <dc:creator>Nicolas, P.</dc:creator>
 <dc:creator>Saubion, F.</dc:creator>
 <dc:creator>Stephan, I.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  A default theory can be characterized by its sets of plausible conclusions,
called its extensions. But, due to the theoretical complexity of Default Logic
(Sigma_2p-complete), the problem of finding such an extension is very difficult
if one wants to deal with non trivial knowledge bases. Based on the principle
of natural selection, Genetic Algorithms have been quite successfully applied
to combinatorial problems and seem useful for problems with huge search spaces
and when no tractable algorithm is available. The purpose of this paper is to
show that techniques issued from Genetic Algorithms can be used in order to
build an efficient default reasoning system. After providing a formal
description of the components required for an extension search based on Genetic
Algorithms principles, we exhibit some experimental results.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures, 2 tables</dc:description>
 <dc:date>2000-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SLT-Resolution for the Well-Founded Semantics</dc:title>
 <dc:creator>Shen, Yi-Dong</dc:creator>
 <dc:creator>Yuan, Li-Yan</dc:creator>
 <dc:creator>You, Jia-Huai</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  Global SLS-resolution and SLG-resolution are two representative mechanisms
for top-down evaluation of the well-founded semantics of general logic
programs. Global SLS-resolution is linear for query evaluation but suffers from
infinite loops and redundant computations. In contrast, SLG-resolution resolves
infinite loops and redundant computations by means of tabling, but it is not
linear. The principal disadvantage of a non-linear approach is that it cannot
be implemented using a simple, efficient stack-based memory structure nor can
it be easily extended to handle some strictly sequential operators such as cuts
in Prolog.
  In this paper, we present a linear tabling method, called SLT-resolution, for
top-down evaluation of the well-founded semantics. SLT-resolution is a
substantial extension of SLDNF-resolution with tabling. Its main features
include: (1) It resolves infinite loops and redundant computations while
preserving the linearity. (2) It is terminating, and sound and complete w.r.t.
the well-founded semantics for programs with the bounded-term-size property
with non-floundering queries. Its time complexity is comparable with
SLG-resolution and polynomial for function-free logic programs. (3) Because of
its linearity for query evaluation, SLT-resolution bridges the gap between the
well-founded semantics and standard Prolog implementation techniques. It can be
implemented by an extension to any existing Prolog abstract machines such as
WAM or ATOAM.
</dc:description>
 <dc:description>Comment: Slight modification</dc:description>
 <dc:date>2000-02-27</dc:date>
 <dc:date>2001-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002016</dc:identifier>
 <dc:identifier>Journal of Automated Reasoning 28(1):53-97, 2002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Usage Measure Based on Psychophysical Relations</dc:title>
 <dc:creator>Kromer, V.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  A new word usage measure is proposed. It is based on psychophysical relations
and allows to reveal words by its degree of &quot;importance&quot; for making basic
dictionaries of sublanguages.
</dc:description>
 <dc:description>Comment: 9 pages, 1 figure, 1 table</dc:description>
 <dc:date>2000-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0002018</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient generation of rotating workforce schedules</dc:title>
 <dc:creator>Musliu, Nysret</dc:creator>
 <dc:creator>Gaertner, Johannes</dc:creator>
 <dc:creator>Slany, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>B.2.4</dc:subject>
 <dc:description>  Generating high-quality schedules for a rotating workforce is a critical task
in all settings where a certain staffing level must be guaranteed beyond the
capacity of single employees, such as for instance in industrial plants,
hospitals, or airline companies. Results from ergonomics \cite{BEST91} indicate
that rotating workforce schedules have a profound impact on the health and
social life of employees as well as on their performance at work. Moreover,
rotating workforce schedules must satisfy legal requirements and should also
meet the objectives of the employing organization. We describe our solution to
this problem. A basic design decision was to aim at quickly obtaining
high-quality schedules for realistically sized problems while maintaining human
control. The interaction between the decision maker and the algorithm therefore
consists in four steps: (1) choosing a set of lengths of work blocks (a work
block is a sequence of consecutive days of work shifts), (2) choosing a
particular sequence of work and days-off blocks among those that have optimal
weekend characteristics, (3) enumerating possible shift sequences for the
chosen work blocks subject to shift change constraints and bounds on sequences
of shifts, and (4) assignment of shift sequences to work blocks while
fulfilling the staffing requirements. The combination of constraint
satisfaction and problem-oriented intelligent backtracking algorithms in each
of the four steps allows to find good solutions for real-world problems in
acceptable time. Computational results from real-world problems and from
benchmark examples found in the literature confirm the viability of our
approach. The algorithms are now part of a commercial shift scheduling software
package.
</dc:description>
 <dc:description>Comment: 24 pages, uses dbairep.sty</dc:description>
 <dc:date>2000-02-29</dc:date>
 <dc:date>2006-04-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0002018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making news understandable to computers</dc:title>
 <dc:creator>Mueller, Erik T.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>I.7.2</dc:subject>
 <dc:description>  Computers and devices are largely unaware of events taking place in the
world. This could be changed if news were made available in a
computer-understandable form. In this paper we present XML documents called
NewsForms that represent the key points of 17 types of news events. We discuss
the benefits of computer-understandable news and present the NewsExtract
program for converting text news stories into NewsForms.
</dc:description>
 <dc:date>2000-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Random Number Generators using Quasicrystals</dc:title>
 <dc:creator>Guimond, Louis-Sebastien</dc:creator>
 <dc:creator>Masakova, Zuzana</dc:creator>
 <dc:creator>Patera, Jiri</dc:creator>
 <dc:creator>Pelantova, Edita</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  This paper has been withdrawn by the author(s),
</dc:description>
 <dc:date>2000-03-01</dc:date>
 <dc:date>2000-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prospects for in-depth story understanding by computer</dc:title>
 <dc:creator>Mueller, Erik T.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  While much research on the hard problem of in-depth story understanding by
computer was performed starting in the 1970s, interest shifted in the 1990s to
information extraction and word sense disambiguation. Now that a degree of
success has been achieved on these easier problems, I propose it is time to
return to in-depth story understanding. In this paper I examine the shift away
from story understanding, discuss some of the major problems in building a
story understanding system, present some possible solutions involving a set of
interacting understanding agents, and provide pointers to useful tools and
resources for building story understanding systems.
</dc:description>
 <dc:date>2000-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A database and lexicon of scripts for ThoughtTreasure</dc:title>
 <dc:creator>Mueller, Erik T.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  Since scripts were proposed in the 1970's as an inferencing mechanism for AI
and natural language processing programs, there have been few attempts to build
a database of scripts. This paper describes a database and lexicon of scripts
that has been added to the ThoughtTreasure commonsense platform. The database
provides the following information about scripts: sequence of events, roles,
props, entry conditions, results, goals, emotions, places, duration, frequency,
and cost. English and French words and phrases are linked to script concepts.
</dc:description>
 <dc:date>2000-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Don't Trash your Intermediate Results, Cache 'em</dc:title>
 <dc:creator>Roy, Prasan</dc:creator>
 <dc:creator>Ramamritham, Krithi</dc:creator>
 <dc:creator>Seshadri, S.</dc:creator>
 <dc:creator>Shenoy, Pradeep</dc:creator>
 <dc:creator>Sudarshan, S.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:subject>H.2.7</dc:subject>
 <dc:description>  In data warehouse and data mart systems, queries often take a long time to
execute due to their complex nature. Query response times can be greatly
improved by caching final/intermediate results of previous queries, and using
them to answer later queries. In this paper we describe a caching system called
Exchequer which incorporates several novel features including optimization
aware cache maintenance and the use of a cache aware optimizer. In contrast, in
existing work, the module that makes cost-benefit decisions is part of the
cache manager and works independent of the optimizer which essentially
reconsiders these decisions while finding the best plan for a query. In our
work, the optimizer takes the decisions for the cache manager. Furthermore,
existing approaches are either restricted to cube (slice/point) queries, or
cache just the query results. On the other hand, our work is extens ible and in
fact presents a data-model independent framework and algorithm. Our
experimental results attest to the efficacy of our cache management techniques
and show that over a wide range of parameters (a) Exchequer's query response
times are lower by more than 30% compared to the best performing competitor,
and (b) Exchequer can deliver the same response time as its competitor with
just one tenth of the cache size.
</dc:description>
 <dc:description>Comment: 22 pages, 4 figures</dc:description>
 <dc:date>2000-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Materialized View Selection and Maintenance Using Multi-Query
  Optimization</dc:title>
 <dc:creator>Mistry, Hoshi</dc:creator>
 <dc:creator>Roy, Prasan</dc:creator>
 <dc:creator>Ramamritham, Krithi</dc:creator>
 <dc:creator>Sudarshan, S.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:subject>H.2.7</dc:subject>
 <dc:description>  Because the presence of views enhances query performance, materialized views
are increasingly being supported by commercial database/data warehouse systems.
Whenever the data warehouse is updated, the materialized views must also be
updated. However, whereas the amount of data entering a warehouse, the query
loads, and the need to obtain up-to-date responses are all increasing, the time
window available for making the warehouse up-to-date is shrinking. These trends
necessitate efficient techniques for the maintenance of materialized views.
  In this paper, we show how to find an efficient plan for maintenance of a
{\em set} of views, by exploiting common subexpressions between different view
maintenance expressions. These common subexpressions may be materialized
temporarily during view maintenance. Our algorithms also choose
subexpressions/indices to be materialized permanently (and maintained along
with other materialized views), to speed up view maintenance. While there has
been much work on view maintenance in the past, our novel contributions lie in
exploiting a recently developed framework for multiquery optimization to
efficiently find good view maintenance plans as above. In addition to faster
view maintenance, our algorithms can also be used to efficiently select
materialized views to speed up workloads containing queries.
</dc:description>
 <dc:description>Comment: 22 pages, 7 figures</dc:description>
 <dc:date>2000-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Circumscriptive Databases by Integer Programming: Revisited
  (Extended Abstract)</dc:title>
 <dc:creator>Satoh, Ken</dc:creator>
 <dc:creator>Okamoto, Hidenori</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  In this paper, we consider a method of computing minimal models in
circumscription using integer programming in propositional logic and
first-order logic with domain closure axioms and unique name axioms. This kind
of treatment is very important since this enable to apply various technique
developed in operations research to nonmonotonic reasoning.
  Nerode et al. (1995) are the first to propose a method of computing
circumscription using integer programming. They claimed their method was
correct for circumscription with fixed predicate, but we show that their method
does not correctly reflect their claim. We show a correct method of computing
all the minimal models not only with fixed predicates but also with varied
predicates and we extend our method to compute prioritized circumscription as
well.
</dc:description>
 <dc:date>2000-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistency Management of Normal Logic Program by Top-down Abductive
  Proof Procedure</dc:title>
 <dc:creator>Satoh, Ken</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  This paper presents a method of computing a revision of a function-free
normal logic program. If an added rule is inconsistent with a program, that is,
if it leads to a situation such that no stable model exists for a new program,
then deletion and addition of rules are performed to avoid inconsistency. We
specify a revision by translating a normal logic program into an abductive
logic program with abducibles to represent deletion and addition of rules. To
compute such deletion and addition, we propose an adaptation of our top-down
abductive proof procedure to compute a relevant abducibles to an added rule. We
compute a minimally revised program, by choosing a minimal set of abducibles
among all the sets of abducibles computed by a top-down proof procedure.
</dc:description>
 <dc:date>2000-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional indifference and conditional preservation</dc:title>
 <dc:creator>Kern-Isberner, Gabriele</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.0</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  The idea of preserving conditional beliefs emerged recently as a new paradigm
apt to guide the revision of epistemic states. Conditionals are substantially
different from propositional beliefs and need specific treatment. In this
paper, we present a new approach to conditionals, capturing particularly well
their dynamic part as revision policies. We thoroughly axiomatize a principle
of conditional preservation as an indifference property with respect to
conditional structures of worlds. This principle is developed in a
semi-quantitative setting, so as to reveal its fundamental meaning for belief
revision in quantitative as well as in qualitative frameworks. In fact, it is
shown to cover other proposed approaches to conditional preservation.
</dc:description>
 <dc:description>Comment: Workshop Nonmonotonic Reasoning 2000, Belief Revision, at KR 2000, 10
  pages</dc:description>
 <dc:date>2000-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003010</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TSIA: A Dataflow Model</dc:title>
 <dc:creator>Steinmacher-Burow, Burkhard D.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  The Task System and Item Architecture (TSIA) is a model for transparent
application execution. In many real-world projects, a TSIA provides a simple
application with a transparent reliable, distributed, heterogeneous, adaptive,
dynamic, real-time, parallel, secure or other execution. TSIA is suitable for
many applications, not just for the simple applications served to date. This
presentation shows that TSIA is a dataflow model - a long-standing model for
transparent parallel execution. The advances to the dataflow model include a
simple semantics, as well as support for input/output, for modifiable items and
for other such effects.
</dc:description>
 <dc:date>2000-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Belief Revision in SNePS</dc:title>
 <dc:creator>Shapiro, Stuart C.</dc:creator>
 <dc:creator>Johnson, Frances L.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  SNePS is a logic- and network- based knowledge representation, reasoning, and
acting system, based on a monotonic, paraconsistent, first-order term logic,
with compositional intensional semantics. It has an ATMS-style facility for
belief contraction, and an acting component, including a well-defined syntax
and semantics for primitive and composite acts, as well as for ``rules'' that
allow for acting in support of reasoning and reasoning in support of acting.
SNePS has been designed to support natural language competent cognitive agents.
  When the current version of SNePS detects an explicit contradiction, it
interacts with the user, providing information that helps the user decide what
to remove from the knowledge base in order to remove the contradiction. The
forthcoming SNePS 2.6 will also do automatic belief contraction if the
information in the knowledge base warrents it.
</dc:description>
 <dc:description>Comment: Slightly revised page 3, right column, 3rd complete paragraph to fix
  formatting problem</dc:description>
 <dc:date>2000-03-06</dc:date>
 <dc:date>2000-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Defeasible Reasoning in OSCAR</dc:title>
 <dc:creator>Pollock, John L.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  This is a system description for the OSCAR defeasible reasoner.
</dc:description>
 <dc:description>Comment: Nonmonotonic Reasoning Workshop, 2000</dc:description>
 <dc:date>2000-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A flexible framework for defeasible logics</dc:title>
 <dc:creator>Antoniou, G.</dc:creator>
 <dc:creator>Billigton, D.</dc:creator>
 <dc:creator>Governatori, G.</dc:creator>
 <dc:creator>Maher, M. J.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:description>  Logics for knowledge representation suffer from over-specialization: while
each logic may provide an ideal representation formalism for some problems, it
is less than optimal for others. A solution to this problem is to choose from
several logics and, when necessary, combine the representations. In general,
such an approach results in a very difficult problem of combination. However,
if we can choose the logics from a uniform framework then the problem of
combining them is greatly simplified. In this paper, we develop such a
framework for defeasible logics. It supports all defeasible logics that satisfy
a strong negation principle. We use logic meta-programs as the basis for the
framework.
</dc:description>
 <dc:description>Comment: Proceedings of 8th International Workshop on Non-Monotonic Reasoning,
  April 9-11, 2000, Breckenridge, Colorado</dc:description>
 <dc:date>2000-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Maxi-adjustment to Adaptive Information Filtering Agents</dc:title>
 <dc:creator>Lau, Raymond</dc:creator>
 <dc:creator>ter Hofstede, Arthur H. M.</dc:creator>
 <dc:creator>Bruza, Peter D.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Learning and adaptation is a fundamental property of intelligent agents. In
the context of adaptive information filtering, a filtering agent's beliefs
about a user's information needs have to be revised regularly with reference to
the user's most current information preferences. This learning and adaptation
process is essential for maintaining the agent's filtering performance. The AGM
belief revision paradigm provides a rigorous foundation for modelling rational
and minimal changes to an agent's beliefs. In particular, the maxi-adjustment
method, which follows the AGM rationale of belief change, offers a sound and
robust computational mechanism to develop adaptive agents so that learning
autonomy of these agents can be enhanced. This paper describes how the
maxi-adjustment method is applied to develop the learning components of
adaptive information filtering agents, and discusses possible difficulties of
applying such a framework to these agents.
</dc:description>
 <dc:description>Comment: The 8th Intl. Workshop on Non-Monotonic Reasoning NMR'2000, Belief
  Change, 9 pages</dc:description>
 <dc:date>2000-03-06</dc:date>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the semantics of merging</dc:title>
 <dc:creator>Meyer, Thomas</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  Intelligent agents are often faced with the problem of trying to merge
possibly conflicting pieces of information obtained from different sources into
a consistent view of the world. We propose a framework for the modelling of
such merging operations with roots in the work of Spohn (1988, 1991). Unlike
most approaches we focus on the merging of epistemic states, not knowledge
bases. We construct a number of plausible merging operations and measure them
against various properties that merging operations ought to satisfy. Finally,
we discuss the connection between merging and the use of infobases Meyer (1999)
and Meyer et al. (2000).
</dc:description>
 <dc:description>Comment: 7 pages, 9 figures, paper to be presented at NMR'2000</dc:description>
 <dc:date>2000-03-07</dc:date>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Abductive and Consistency-Based Diagnosis Revisited: a Modeling
  Perspective</dc:title>
 <dc:creator>Dupre', Daniele Theseider</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  Diagnostic reasoning has been characterized logically as consistency-based
reasoning or abductive reasoning. Previous analyses in the literature have
shown, on the one hand, that choosing the (in general more restrictive)
abductive definition may be appropriate or not, depending on the content of the
knowledge base [Console&amp;Torasso91], and, on the other hand, that, depending on
the choice of the definition the same knowledge should be expressed in
different form [Poole94].
  Since in Model-Based Diagnosis a major problem is finding the right way of
abstracting the behavior of the system to be modeled, this paper discusses the
relation between modeling, and in particular abstraction in the model, and the
notion of diagnosis.
</dc:description>
 <dc:description>Comment: 5 pages, 8th Int. Workshop on Nonmonotonic Reasoning, 2000</dc:description>
 <dc:date>2000-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The lexicographic closure as a revision process</dc:title>
 <dc:creator>Booth, Richard</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  The connections between nonmonotonic reasoning and belief revision are
well-known. A central problem in the area of nonmonotonic reasoning is the
problem of default entailment, i.e., when should an item of default information
representing &quot;if A is true then, normally, B is true&quot; be said to follow from a
given set of items of such information. Many answers to this question have been
proposed but, surprisingly, virtually none have attempted any explicit
connection to belief revision. The aim of this paper is to give an example of
how such a connection can be made by showing how the lexicographic closure of a
set of defaults may be conceptualised as a process of iterated revision by sets
of sentences. Specifically we use the revision process of Nayak.
</dc:description>
 <dc:description>Comment: 7 pages, Nonmonotonic Reasoning Workshop 2000 (special session on
  belief change), at KR2000</dc:description>
 <dc:date>2000-03-07</dc:date>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Description of GADEL</dc:title>
 <dc:creator>Stephan, I.</dc:creator>
 <dc:creator>Saubion, F.</dc:creator>
 <dc:creator>Nicolas, P.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  This article describes the first implementation of the GADEL system : a
Genetic Algorithm for Default Logic. The goal of GADEL is to compute extensions
in Reiter's default logic. It accepts every kind of finite propositional
default theories and is based on evolutionary principles of Genetic Algorithms.
Its first experimental results on certain instances of the problem show that
this new approach of the problem can be successful.
</dc:description>
 <dc:description>Comment: System Descriptions and Demonstrations at Nonmonotonic Reasoning
  Workshop, 2000 6 pages, 2 figures, 5 tables</dc:description>
 <dc:date>2000-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003019</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extending Classical Logic with Inductive Definitions</dc:title>
 <dc:creator>Denecker, Marc</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  The goal of this paper is to extend classical logic with a generalized notion
of inductive definition supporting positive and negative induction, to
investigate the properties of this logic, its relationships to other logics in
the area of non-monotonic reasoning, logic programming and deductive databases,
and to show its application for knowledge representation by giving a typology
of definitional knowledge.
</dc:description>
 <dc:description>Comment: 9 pages to be presented at NMR2000, Breckenridge, April 2000</dc:description>
 <dc:date>2000-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ACLP: Integrating Abduction and Constraint Solving</dc:title>
 <dc:creator>Kakas, Antonis</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  ACLP is a system which combines abductive reasoning and constraint solving by
integrating the frameworks of Abductive Logic Programming (ALP) and Constraint
Logic Programming (CLP). It forms a general high-level knowledge representation
environment for abductive problems in Artificial Intelligence and other areas.
In ACLP, the task of abduction is supported and enhanced by its non-trivial
integration with constraint solving facilitating its application to complex
problems. The ACLP system is currently implemented on top of the CLP language
of ECLiPSe as a meta-interpreter exploiting its underlying constraint solver
for finite domains. It has been applied to the problems of planning and
scheduling in order to test its computational effectiveness compared with the
direct use of the (lower level) constraint solving framework of CLP on which it
is built. These experiments provide evidence that the abductive framework of
ACLP does not compromise significantly the computational efficiency of the
solutions. Other experiments show the natural ability of ACLP to accommodate
easily and in a robust way new or changing requirements of the original
problem.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2000-03-07</dc:date>
 <dc:date>2000-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003021</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relevance Sensitive Non-Monotonic Inference on Belief Sequences</dc:title>
 <dc:creator>Chopra, Samir</dc:creator>
 <dc:creator>Georgatos, Konstantinos</dc:creator>
 <dc:creator>Parikh, Rohit</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  We present a method for relevance sensitive non-monotonic inference from
belief sequences which incorporates insights pertaining to prioritized
inference and relevance sensitive, inconsistency tolerant belief revision.
  Our model uses a finite, logically open sequence of propositional formulas as
a representation for beliefs and defines a notion of inference from
maxiconsistent subsets of formulas guided by two orderings: a temporal
sequencing and an ordering based on relevance relations between the conclusion
and formulas in the sequence. The relevance relations are ternary (using
context as a parameter) as opposed to standard binary axiomatizations. The
inference operation thus defined easily handles iterated revision by
maintaining a revision history, blocks the derivation of inconsistent answers
from a possibly inconsistent sequence and maintains the distinction between
explicit and implicit beliefs. In doing so, it provides a finitely presented
formalism and a plausible model of reasoning for automated agents.
</dc:description>
 <dc:date>2000-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hypothetical revision and matter-of-fact supposition</dc:title>
 <dc:creator>Arlo-Costa, Horacio</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  The paper studies the notion of supposition encoded in non-Archimedean
conditional probability (and revealed in the acceptance of the so-called
indicative conditionals). The notion of qualitative change of view that thus
arises is axiomatized and compared with standard notions like AGM and UPDATE.
Applications in the following fields are discussed: (1) theory of games and
decisions, (2) causal models, (3) non-monotonic logic.
</dc:description>
 <dc:description>Comment: 9 pages. Presented at the Special Session on Belief change: theory
  and practice of the 8th Intl. Workshop on Non-Monotonic Reasoning NMR'2000</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Default Reasoning with Conditional Constraints</dc:title>
 <dc:creator>Lukasiewicz, Thomas</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  We propose a combination of probabilistic reasoning from conditional
constraints with approaches to default reasoning from conditional knowledge
bases. In detail, we generalize the notions of Pearl's entailment in system Z,
Lehmann's lexicographic entailment, and Geffner's conditional entailment to
conditional constraints. We give some examples that show that the new notions
of z-, lexicographic, and conditional entailment have similar properties like
their classical counterparts. Moreover, we show that the new notions of z-,
lexicographic, and conditional entailment are proper generalizations of both
their classical counterparts and the classical notion of logical entailment for
conditional constraints.
</dc:description>
 <dc:description>Comment: 8 pages; to appear in Proceedings of the Eighth International
  Workshop on Nonmonotonic Reasoning, Special Session on Uncertainty Frameworks
  in Nonmonotonic Reasoning, Breckenridge, Colorado, USA, 9-11 April 2000</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Compiler for Ordered Logic Programs</dc:title>
 <dc:creator>Delgrande, James P.</dc:creator>
 <dc:creator>Schaub, Torsten</dc:creator>
 <dc:creator>Tompits, Hans</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  This paper describes a system, called PLP, for compiling ordered logic
programs into standard logic programs under the answer set semantics. In an
ordered logic program, rules are named by unique terms, and preferences among
rules are given by a set of dedicated atoms. An ordered logic program is
transformed into a second, regular, extended logic program wherein the
preferences are respected, in that the answer sets obtained in the transformed
theory correspond with the preferred answer sets of the original theory. Since
the result of the translation is an extended logic program, existing logic
programming systems can be used as underlying reasoning engine. In particular,
PLP is conceived as a front-end to the logic programming systems dlv and
smodels.
</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Logic Programming for Describing and Solving Planning Problems</dc:title>
 <dc:creator>Bruynooghe, Maurice</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  A logic programming paradigm which expresses solutions to problems as stable
models has recently been promoted as a declarative approach to solving various
combinatorial and search problems, including planning problems. In this
paradigm, all program rules are considered as constraints and solutions are
stable models of the rule set. This is a rather radical departure from the
standard paradigm of logic programming. In this paper we revisit abductive
logic programming and argue that it allows a programming style which is as
declarative as programming based on stable models. However, within abductive
logic programming, one has two kinds of rules. On the one hand predicate
definitions (which may depend on the abducibles) which are nothing else than
standard logic programs (with their non-monotonic semantics when containing
with negation); on the other hand rules which constrain the models for the
abducibles. In this sense abductive logic programming is a smooth extension of
the standard paradigm of logic programming, not a radical departure.
</dc:description>
 <dc:description>Comment: 8 pages, no figures, Eighth International Workshop on Nonmonotonic
  Reasoning, special track on Representing Actions and Planning</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparison of Logic Programming Approaches for Representation and
  Solving of Constraint Satisfaction Problems</dc:title>
 <dc:creator>Pelov, Nikolay</dc:creator>
 <dc:creator>De Mot, Emmanuel</dc:creator>
 <dc:creator>Bruynooghe, Maurice</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.3: Logic programming, Nonmonotonic reasoning</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>F.4.1:
  Logic and constraint programming</dc:subject>
 <dc:subject>Experiments</dc:subject>
 <dc:description>  Many logic programming based approaches can be used to describe and solve
combinatorial search problems. On the one hand there are definite programs and
constraint logic programs that compute a solution as an answer substitution to
a query containing the variables of the constraint satisfaction problem. On the
other hand there are approaches based on stable model semantics, abduction, and
first-order logic model generation that compute solutions as models of some
theory. This paper compares these different approaches from point of view of
knowledge representation (how declarative are the programs) and from point of
view of performance (how good are they at solving typical problems).
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures submitted to NMR 2000, April 9-11, Breckenridge,
  Colorado</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SLDNFA-system</dc:title>
 <dc:creator>Van Nuffelen, Bert</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  The SLDNFA-system results from the LP+ project at the K.U.Leuven, which
investigates logics and proof procedures for these logics for declarative
knowledge representation. Within this project inductive definition logic
(ID-logic) is used as representation logic. Different solvers are being
developed for this logic and one of these is SLDNFA. A prototype of the system
is available and used for investigating how to solve efficiently problems
represented in ID-logic.
</dc:description>
 <dc:description>Comment: 6 pages conference:NMR2000, special track on System descriptions and
  demonstration</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Logic Programs with Compiled Preferences</dc:title>
 <dc:creator>Delgrande, James P.</dc:creator>
 <dc:creator>Schaub, Torsten</dc:creator>
 <dc:creator>Tompits, Hans</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  We describe an approach for compiling preferences into logic programs under
the answer set semantics. An ordered logic program is an extended logic program
in which rules are named by unique terms, and in which preferences among rules
are given by a set of dedicated atoms. An ordered logic program is transformed
into a second, regular, extended logic program wherein the preferences are
respected, in that the answer sets obtained in the transformed theory
correspond with the preferred answer sets of the original theory. Our approach
allows both the specification of static orderings (as found in most previous
work), in which preferences are external to a logic program, as well as
orderings on sets of rules. In large part then, we are interested in describing
a general methodology for uniformly incorporating preference information in a
logic program. Since the result of our translation is an extended logic
program, we can make use of existing implementations, such as dlv and smodels.
To this end, we have developed a compiler, available on the web, as a front-end
for these programming systems.
</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fuzzy Approaches to Abductive Inference</dc:title>
 <dc:creator>Mellouli, Nedra</dc:creator>
 <dc:creator>Bouchon-Meunier, Bernadette</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Artificial intelligence and nonmonotonic reasoning and belief
  revision</dc:subject>
 <dc:description>  This paper proposes two kinds of fuzzy abductive inference in the framework
of fuzzy rule base. The abductive inference processes described here depend on
the semantic of the rule. We distinguish two classes of interpretation of a
fuzzy rule, certainty generation rules and possible generation rules. In this
paper we present the architecture of abductive inference in the first class of
interpretation. We give two kinds of problem that we can resolve by using the
proposed models of inference.
</dc:description>
 <dc:description>Comment: 7 pages and 8 files</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Problem solving in ID-logic with aggregates: some experiments</dc:title>
 <dc:creator>Van Nuffelen, Bert</dc:creator>
 <dc:creator>Denecker, Marc</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  The goal of the LP+ project at the K.U.Leuven is to design an expressive
logic, suitable for declarative knowledge representation, and to develop
intelligent systems based on Logic Programming technology for solving
computational problems using the declarative specifications. The ID-logic is an
integration of typed classical logic and a definition logic. Different
abductive solvers for this language are being developed. This paper is a report
of the integration of high order aggregates into ID-logic and the consequences
on the solver SLDNFA.
</dc:description>
 <dc:description>Comment: 9 pages conference: NMR2000, special track on abductive reasoning</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Belief Revision</dc:title>
 <dc:creator>Vodislav, Carmen</dc:creator>
 <dc:creator>Mercer, Robert E.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  We propose a new approach to belief revision that provides a way to change
knowledge bases with a minimum of effort. We call this way of revising belief
states optimal belief revision. Our revision method gives special attention to
the fact that most belief revision processes are directed to a specific
informational objective. This approach to belief change is founded on notions
such as optimal context and accessibility. For the sentential model of belief
states we provide both a formal description of contexts as sub-theories
determined by three parameters and a method to construct contexts. Next, we
introduce an accessibility ordering for belief sets, which we then use for
selecting the best (optimal) contexts with respect to the processing effort
involved in the revision. Then, for finitely axiomatizable knowledge bases, we
characterize a finite accessibility ranking from which the accessibility
ordering for the entire base is generated and show how to determine the ranking
of an arbitrary sentence in the language. Finally, we define the adjustment of
the accessibility ranking of a revised base of a belief set.
</dc:description>
 <dc:description>Comment: NMR'2000 Workshop 6 pages</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>cc-Golog: Towards More Realistic Logic-Based Robot Controllers</dc:title>
 <dc:creator>Grosskreutz, Henrik</dc:creator>
 <dc:creator>Lakemeyer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  High-level robot controllers in realistic domains typically deal with
processes which operate concurrently, change the world continuously, and where
the execution of actions is event-driven as in ``charge the batteries as soon
as the voltage level is low''. While non-logic-based robot control languages
are well suited to express such scenarios, they fare poorly when it comes to
projecting, in a conspicuous way, how the world evolves when actions are
executed. On the other hand, a logic-based control language like \congolog,
based on the situation calculus, is well-suited for the latter. However, it has
problems expressing event-driven behavior. In this paper, we show how these
problems can be overcome by first extending the situation calculus to support
continuous change and event-driven behavior and then presenting \ccgolog, a
variant of \congolog which is based on the extended situation calculus. One
benefit of \ccgolog is that it narrows the gap in expressiveness compared to
non-logic-based control languages while preserving a semantically well-founded
projection mechanism.
</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smodels: A System for Answer Set Programming</dc:title>
 <dc:creator>Niemela, Ilkka</dc:creator>
 <dc:creator>Simons, Patrik</dc:creator>
 <dc:creator>Syrjanen, Tommi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  The Smodels system implements the stable model semantics for normal logic
programs. It handles a subclass of programs which contain no function symbols
and are domain-restricted but supports extensions including built-in functions
as well as cardinality and weight constraints. On top of this core engine more
involved systems can be built. As an example, we have implemented total and
partial stable model computation for disjunctive logic programs. An interesting
application method is based on answer set programming, i.e., encoding an
application problem as a set of rules so that its solutions are captured by the
stable models of the rules. Smodels has been applied to a number of areas
including planning, model checking, reachability analysis, product
configuration, dynamic constraint satisfaction, and feature interaction.
</dc:description>
 <dc:description>Comment: Proceedings of the 8th International Workshop on Non-Monotonic
  Reasoning, April 9-11, 2000, Breckenridge, Colorado 4 pages, uses aaai.sty</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>E-RES: A System for Reasoning about Actions, Events and Observations</dc:title>
 <dc:creator>Kakas, Antonis</dc:creator>
 <dc:creator>Miller, Rob</dc:creator>
 <dc:creator>Toni, Francesca</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  E-RES is a system that implements the Language E, a logic for reasoning about
narratives of action occurrences and observations. E's semantics is
model-theoretic, but this implementation is based on a sound and complete
reformulation of E in terms of argumentation, and uses general computational
techniques of argumentation frameworks. The system derives sceptical
non-monotonic consequences of a given reformulated theory which exactly
correspond to consequences entailed by E's model-theory. The computation relies
on a complimentary ability of the system to derive credulous non-monotonic
consequences together with a set of supporting assumptions which is sufficient
for the (credulous) conclusion to hold. E-RES allows theories to contain
general action laws, statements about action occurrences, observations and
statements of ramifications (or universal laws). It is able to derive
consequences both forward and backward in time. This paper gives a short
overview of the theoretical basis of E-RES and illustrates its use on a variety
of examples. Currently, E-RES is being extended so that the system can be used
for planning.
</dc:description>
 <dc:description>Comment: Proceedings of the 8th International Workshop on Non-Monotonic
  Reasoning, April 9-11, 2000, Breckenridge, Colorado. 6 pages</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:date>2000-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Declarative Representation of Revision Strategies</dc:title>
 <dc:creator>Brewka, Gerhard</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  In this paper we introduce a nonmonotonic framework for belief revision in
which reasoning about the reliability of different pieces of information based
on meta-knowledge about the information is possible, and where revision
strategies can be described declaratively. The approach is based on a
Poole-style system for default reasoning in which entrenchment information is
represented in the logical language. A notion of inference based on the least
fixed point of a monotone operator is used to make sure that all theories
possess a consistent set of conclusions.
</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DLV - A System for Declarative Problem Solving</dc:title>
 <dc:creator>Eiter, Thomas</dc:creator>
 <dc:creator>Faber, Wolfgang</dc:creator>
 <dc:creator>Koch, Christoph</dc:creator>
 <dc:creator>Leone, Nicola</dc:creator>
 <dc:creator>Pfeifer, Gerald</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  DLV is an efficient logic programming and non-monotonic reasoning (LPNMR)
system with advanced knowledge representation mechanisms and interfaces to
classic relational database systems.
  Its core language is disjunctive datalog (function-free disjunctive logic
programming) under the Answer Set Semantics with integrity constraints, both
default and strong (or explicit) negation, and queries. Integer arithmetics and
various built-in predicates are also supported.
  In addition DLV has several frontends, namely brave and cautious reasoning,
abductive diagnosis, consistency-based diagnosis, a subset of SQL3, planning
with action languages, and logic programming with inheritance.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, 1 table</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QUIP - A Tool for Computing Nonmonotonic Reasoning Tasks</dc:title>
 <dc:creator>Egly, Uwe</dc:creator>
 <dc:creator>Eiter, Thomas</dc:creator>
 <dc:creator>Tompits, Hans</dc:creator>
 <dc:creator>Woltran, Stefan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  In this paper, we outline the prototype of an automated inference tool,
called QUIP, which provides a uniform implementation for several nonmonotonic
reasoning formalisms. The theoretical basis of QUIP is derived from well-known
results about the computational complexity of nonmonotonic logics and exploits
a representation of the different reasoning tasks in terms of quantified
boolean formulae.
</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Splitting Set Theorem for Epistemic Specifications</dc:title>
 <dc:creator>Watson, Richard</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  Over the past decade a considerable amount of research has been done to
expand logic programming languages to handle incomplete information. One such
language is the language of epistemic specifications. As is usual with logic
programming languages, the problem of answering queries is intractable in the
general case. For extended disjunctive logic programs, an idea that has proven
useful in simplifying the investigation of answer sets is the use of splitting
sets. In this paper we will present an extended definition of splitting sets
that will be applicable to epistemic specifications. Furthermore, an extension
of the splitting set theorem will be presented. Also, a characterization of
stratified epistemic specifications will be given in terms of splitting sets.
This characterization leads us to an algorithmic method of computing world
views of a subclass of epistemic logic programs.
</dc:description>
 <dc:description>Comment: To be published in Proceedings of NMR 2000 Workshop. 6 pages</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DES: a Challenge Problem for Nonmonotonic Reasoning Systems</dc:title>
 <dc:creator>Hietalahti, Maarit</dc:creator>
 <dc:creator>Massacci, Fabio</dc:creator>
 <dc:creator>Niemela, Ilkka</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  The US Data Encryption Standard, DES for short, is put forward as an
interesting benchmark problem for nonmonotonic reasoning systems because (i) it
provides a set of test cases of industrial relevance which shares features of
randomly generated problems and real-world problems, (ii) the representation of
DES using normal logic programs with the stable model semantics is simple and
easy to understand, and (iii) this subclass of logic programs can be seen as an
interesting special case for many other formalizations of nonmonotonic
reasoning. In this paper we present two encodings of DES as logic programs: a
direct one out of the standard specifications and an optimized one extending
the work of Massacci and Marraro. The computational properties of the encodings
are studied by using them for DES key search with the Smodels system as the
implementation of the stable model semantics. Results indicate that the
encodings and Smodels are quite competitive: they outperform state-of-the-art
SAT-checkers working with an optimized encoding of DES into SAT and are
comparable with a SAT-checker that is customized and tuned for the optimized
SAT encoding.
</dc:description>
 <dc:description>Comment: 10 pages, 1 Postscript figure, uses aaai.sty and graphicx.sty</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementing Integrity Constraints in an Existing Belief Revision System</dc:title>
 <dc:creator>Johnson, Frances L.</dc:creator>
 <dc:creator>Shapiro, Stuart C.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  SNePS is a mature knowledge representation, reasoning, and acting system that
has long contained a belief revision subsystem, called SNeBR. SNeBR is
triggered when an explicit contradiction is introduced into the SNePS belief
space, either because of a user's new assertion, or because of a user's query.
SNeBR then makes the user decide what belief to remove from the belief space in
order to restore consistency, although it provides information to help the user
in making that decision. We have recently added automatic belief revision to
SNeBR, by which, under certain circumstances, SNeBR decides by itself which
belief to remove, and then informs the user of the decision and its
consequences. We have used the well-known belief revision integrity constraints
as a guide in designing automatic belief revision, taking into account,
however, that SNePS's belief space is not deductively closed, and that it would
be infeasible to form the deductive closure in order to decide what belief to
remove. This paper briefly describes SNeBR both before and after this revision,
discusses how we adapted the integrity constraints for this purpose, and gives
an example of the new SNeBR in action.
</dc:description>
 <dc:description>Comment: 8 pages, for the Belief Change Workshop at NMR2000 colocated with
  KR2000</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coherence, Belief Expansion and Bayesian Networks</dc:title>
 <dc:creator>Bovens, Luc</dc:creator>
 <dc:creator>Hartmann, Stephan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.0</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  We construct a probabilistic coherence measure for information sets which
determines a partial coherence ordering. This measure is applied in
constructing a criterion for expanding our beliefs in the face of new
information. A number of idealizations are being made which can be relaxed by
an appeal to Bayesian Networks.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures, paper presented at the 8th Intl. Workshop on
  Non-Monotonic Reasoning NMR'2000 (April 9-11), Breckenridge, Colorado</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fages' Theorem and Answer Set Programming</dc:title>
 <dc:creator>Babovich, Yuliya</dc:creator>
 <dc:creator>Erdem, Esra</dc:creator>
 <dc:creator>Lifschitz, Vladimir</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  We generalize a theorem by Francois Fages that describes the relationship
between the completion semantics and the answer set semantics for logic
programs with negation as failure. The study of this relationship is important
in connection with the emergence of answer set programming. Whenever the two
semantics are equivalent, answer sets can be computed by a satisfiability
solver, and the use of answer set solvers such as smodels and dlv is
unnecessary. A logic programming representation of the blocks world due to
Ilkka Niemelae is discussed as an example.
</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Classification of Text Databases through Query Probing</dc:title>
 <dc:creator>Ipeirotis, Panagiotis</dc:creator>
 <dc:creator>Gravano, Luis</dc:creator>
 <dc:creator>Sahami, Mehran</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:description>  Many text databases on the web are &quot;hidden&quot; behind search interfaces, and
their documents are only accessible through querying. Search engines typically
ignore the contents of such search-only databases. Recently, Yahoo-like
directories have started to manually organize these databases into categories
that users can browse to find these valuable resources. We propose a novel
strategy to automate the classification of search-only text databases. Our
technique starts by training a rule-based document classifier, and then uses
the classifier's rules to generate probing queries. The queries are sent to the
text databases, which are then classified based on the number of matches that
they produce for each query. We report some initial exploratory experiments
that show that our approach is promising to automatically characterize the
contents of text databases accessible on the web.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure</dc:description>
 <dc:date>2000-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the tractable counting of theory models and its application to belief
  revision and truth maintenance</dc:title>
 <dc:creator>Darwiche, Adnan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  We introduced decomposable negation normal form (DNNF) recently as a
tractable form of propositional theories, and provided a number of powerful
logical operations that can be performed on it in polynomial time. We also
presented an algorithm for compiling any conjunctive normal form (CNF) into
DNNF and provided a structure-based guarantee on its space and time complexity.
We present in this paper a linear-time algorithm for converting an ordered
binary decision diagram (OBDD) representation of a propositional theory into an
equivalent DNNF, showing that DNNFs scale as well as OBDDs. We also identify a
subclass of DNNF which we call deterministic DNNF, d-DNNF, and show that the
previous complexity guarantees on compiling DNNF continue to hold for this
stricter subclass, which has stronger properties. In particular, we present a
new operation on d-DNNF which allows us to count its models under the
assertion, retraction and flipping of every literal by traversing the d-DNNF
twice. That is, after such traversal, we can test in constant-time: the
entailment of any literal by the d-DNNF, and the consistency of the d-DNNF
under the retraction or flipping of any literal. We demonstrate the
significance of these new operations by showing how they allow us to implement
linear-time, complete truth maintenance systems and linear-time, complete
belief revision systems for two important classes of propositional theories.
</dc:description>
 <dc:date>2000-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Termination Proofs for Logic Programs with Tabling</dc:title>
 <dc:creator>Verbaeten, Sofie</dc:creator>
 <dc:creator>De Schreye, Danny</dc:creator>
 <dc:creator>Sagonas, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:description>  Tabled logic programming is receiving increasing attention in the Logic
Programming community. It avoids many of the shortcomings of SLD execution and
provides a more flexible and often extremely efficient execution mechanism for
logic programs. In particular, tabled execution of logic programs terminates
more often than execution based on SLD-resolution. In this article, we
introduce two notions of universal termination of logic programming with
Tabling: quasi-termination and (the stronger notion of) LG-termination. We
present sufficient conditions for these two notions of termination, namely
quasi-acceptability and LG-acceptability, and we show that these conditions are
also necessary in case the tabling is well-chosen. Starting from these
conditions, we give modular termination proofs, i.e., proofs capable of
combining termination proofs of separate programs to obtain termination proofs
of combined programs. Finally, in the presence of mode information, we state
sufficient conditions which form the basis for automatically proving
termination in a constraint-based way.
</dc:description>
 <dc:description>Comment: 48 pages, 6 figures, submitted to ACM Transactions on Computational
  Logic (TOCL)</dc:description>
 <dc:date>2000-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Tabulated Resolution Based on Prolog Control Strategy</dc:title>
 <dc:creator>Shen, Yi-Dong</dc:creator>
 <dc:creator>Yuan, Li-Yan</dc:creator>
 <dc:creator>You, Jia-Huai</dc:creator>
 <dc:creator>Zhou, Neng-Fa</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  Infinite loops and redundant computations are long recognized open problems
in Prolog. Two ways have been explored to resolve these problems: loop checking
and tabling. Loop checking can cut infinite loops, but it cannot be both sound
and complete even for function-free logic programs. Tabling seems to be an
effective way to resolve infinite loops and redundant computations. However,
existing tabulated resolutions, such as OLDT-resolution, SLG- resolution, and
Tabulated SLS-resolution, are non-linear because they rely on the
solution-lookup mode in formulating tabling. The principal disadvantage of
non-linear resolutions is that they cannot be implemented using a simple
stack-based memory structure like that in Prolog. Moreover, some strictly
sequential operators such as cuts may not be handled as easily as in Prolog.
  In this paper, we propose a hybrid method to resolve infinite loops and
redundant computations. We combine the ideas of loop checking and tabling to
establish a linear tabulated resolution called TP-resolution. TP-resolution has
two distinctive features: (1) It makes linear tabulated derivations in the same
way as Prolog except that infinite loops are broken and redundant computations
are reduced. It handles cuts as effectively as Prolog. (2) It is sound and
complete for positive logic programs with the bounded-term-size property. The
underlying algorithm can be implemented by an extension to any existing Prolog
abstract machines such as WAM or ATOAM.
</dc:description>
 <dc:description>Comment: To appear as the first accepted paper in Theory and Practice of Logic
  Programming (http://www.cwi.nl/projects/alp/TPLP)</dc:description>
 <dc:date>2000-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003046</dc:identifier>
 <dc:identifier>Theory and Practice of Logic Programming 1(1):71-103, 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BDD-based reasoning in the fluent calculus - first results</dc:title>
 <dc:creator>Hoelldobler, Steffen</dc:creator>
 <dc:creator>Stoerr, Hans-Peter</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  The paper reports on first preliminary results and insights gained in a
project aiming at implementing the fluent calculus using methods and techniques
based on binary decision diagrams. After reporting on an initial experiment
showing promising results we discuss our findings concerning various techniques
and heuristics used to speed up the reasoning process.
</dc:description>
 <dc:description>Comment: 9 pages; Workshop on Nonmonotonic Reasoning 2000 (NMR 2000)</dc:description>
 <dc:date>2000-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003048</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PAL: Pertinence Action Language</dc:title>
 <dc:creator>Cabalar, Pedro</dc:creator>
 <dc:creator>Cabarcos, Manuel</dc:creator>
 <dc:creator>Otero, Ramon P.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  The current document contains a brief description of a system for Reasoning
about Actions and Change called PAL (Pertinence Action Language) which makes
use of several reasoning properties extracted from a Temporal Expert Systems
tool called Medtool.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2000-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Planning with Incomplete Information</dc:title>
 <dc:creator>Kakas, Antonis</dc:creator>
 <dc:creator>Miller, Rob</dc:creator>
 <dc:creator>Toni, Francesca</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  Planning is a natural domain of application for frameworks of reasoning about
actions and change. In this paper we study how one such framework, the Language
E, can form the basis for planning under (possibly) incomplete information. We
define two types of plans: weak and safe plans, and propose a planner, called
the E-Planner, which is often able to extend an initial weak plan into a safe
plan even though the (explicit) information available is incomplete, e.g. for
cases where the initial state is not completely known. The E-Planner is based
upon a reformulation of the Language E in argumentation terms and a natural
proof theory resulting from the reformulation. It uses an extension of this
proof theory by means of abduction for the generation of plans and adopts
argumentation-based techniques for extending weak plans into safe plans. We
provide representative examples illustrating the behaviour of the E-Planner, in
particular for cases where the status of fluents is incompletely known.
</dc:description>
 <dc:description>Comment: Proceedings of the 8th International Workshop on Non-Monotonic
  Reasoning, April 9-11, 2000, Breckenridge, Colorado</dc:description>
 <dc:date>2000-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A tableau methodology for deontic conditional logics</dc:title>
 <dc:creator>Artosi, Alberto</dc:creator>
 <dc:creator>Governatori, Guido</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  In this paper we present a theorem proving methodology for a restricted but
significant fragment of the conditional language made up of (boolean
combinations of) conditional statements with unnested antecedents. The method
is based on the possible world semantics for conditional logics. The KEM label
formalism, designed to account for the semantics of normal modal logics, is
easily adapted to the semantics of conditional logics by simply indexing labels
with formulas. The inference rules are provided by the propositional system KE+
- a tableau-like analytic proof system devised to be used both as a refutation
and a direct method of proof - enlarged with suitable elimination rules for the
conditional connective. The theorem proving methodology we are going to present
can be viewed as a first step towards developing an appropriate algorithmic
framework for several conditional logics for (defeasible) conditional
obligation.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2000-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003050</dc:identifier>
 <dc:identifier>Deon'98. 4th International Workshop on Deontic Logic in Computer
  Science. CIRFID, Bologna, 1998, 75-91</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Diagnosis</dc:title>
 <dc:creator>Wassermann, Renata</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  In an earlier work, we have presented operations of belief change which only
affect the relevant part of a belief base. In this paper, we propose the
application of the same strategy to the problem of model-based diangosis. We
first isolate the subset of the system description which is relevant for a
given observation and then solve the diagnosis problem for this subset.
</dc:description>
 <dc:date>2000-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Consistency-Based Model for Belief Change: Preliminary Report</dc:title>
 <dc:creator>Delgrande, James</dc:creator>
 <dc:creator>Schaub, Torsten</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  We present a general, consistency-based framework for belief change.
Informally, in revising K by A, we begin with A and incorporate as much of K as
consistently possible. Formally, a knowledge base K and sentence A are
expressed, via renaming propositions in K, in separate languages. Using a
maximization process, we assume the languages are the same insofar as
consistently possible. Lastly, we express the resultant knowledge base in a
single language. There may be more than one way in which A can be so extended
by K: in choice revision, one such ``extension'' represents the revised state;
alternately revision consists of the intersection of all such extensions.
  The most general formulation of our approach is flexible enough to express
other approaches to revision and update, the merging of knowledge bases, and
the incorporation of static and dynamic integrity constraints. Our framework
differs from work based on ordinal conditional functions, notably with respect
to iterated revision. We argue that the approach is well-suited for
implementation: the choice revision operator gives better complexity results
than general revision; the approach can be expressed in terms of a finite
knowledge base; and the scope of a revision can be restricted to just those
propositions mentioned in the sentence for revision A.
</dc:description>
 <dc:date>2000-03-11</dc:date>
 <dc:date>2000-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security of the Cao-Li Public Key Cryptosystem</dc:title>
 <dc:creator>Lim, Lek-Heng</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>E.3</dc:subject>
 <dc:description>  We show that the Cao-Li cryptosystem proposed in \cite{CL1} is not secure.
Its private key can be reconstructed from its public key using elementary means
such as LU-decomposition and Euclidean algorithm.
</dc:description>
 <dc:description>Comment: 4 pages, article in its published form available from
  http://iel.ihs.com:80</dc:description>
 <dc:date>2000-03-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003053</dc:identifier>
 <dc:identifier>Electronics Letters, Volume 34 Number 2, pp. 170-172, January 22
  1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Problem-Specific Fault-Tolerance Mechanism for Asynchronous,
  Distributed Systems</dc:title>
 <dc:creator>Iamnitchi, Adriana</dc:creator>
 <dc:creator>Foster, Ian</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  The idle computers on a local area, campus area, or even wide area network
represent a significant computational resource---one that is, however, also
unreliable, heterogeneous, and opportunistic. This type of resource has been
used effectively for embarrassingly parallel problems but not for more tightly
coupled problems. We describe an algorithm that allows branch-and-bound
problems to be solved in such environments. In designing this algorithm, we
faced two challenges: (1) scalability, to effectively exploit the variably
sized pools of resources available, and (2) fault tolerance, to ensure the
reliability of services. We achieve scalability through a fully decentralized
algorithm, by using a membership protocol for managing dynamically available
resources. However, this fully decentralized design makes achieving reliability
even more challenging. We guarantee fault tolerance in the sense that the loss
of up to all but one resource will not affect the quality of the solution. For
propagating information efficiently, we use epidemic communication for both the
membership protocol and the fault-tolerance mechanism. We have developed a
simulation framework that allows us to evaluate design alternatives. Results
obtained in this framework suggest that our techniques can execute scalably and
reliably.
</dc:description>
 <dc:description>Comment: 17 pages, 6 figures</dc:description>
 <dc:date>2000-03-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003054</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TnT - A Statistical Part-of-Speech Tagger</dc:title>
 <dc:creator>Brants, Thorsten</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Trigrams'n'Tags (TnT) is an efficient statistical part-of-speech tagger.
Contrary to claims found elsewhere in the literature, we argue that a tagger
based on Markov models performs at least as well as other current approaches,
including the Maximum Entropy framework. A recent comparison has even shown
that TnT performs significantly better for the tested corpora. We describe the
basic model of TnT, the techniques used for smoothing and for handling unknown
words. Furthermore, we present evaluations on two corpora.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2000-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003055</dc:identifier>
 <dc:identifier>Proceedings of ANLP-2000, Seattle, WA</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on the Declarative reading(s) of Logic Programming</dc:title>
 <dc:creator>Denecker, Marc</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  This paper analyses the declarative readings of logic programming. Logic
programming - and negation as failure - has no unique declarative reading. One
common view is that logic programming is a logic for default reasoning, a
sub-formalism of default logic or autoepistemic logic. In this view, negation
as failure is a modal operator. In an alternative view, a logic program is
interpreted as a definition. In this view, negation as failure is classical
objective negation. From a commonsense point of view, there is definitely a
difference between these views. Surprisingly though, both types of declarative
readings lead to grosso modo the same model semantics. This note investigates
the causes for this.
</dc:description>
 <dc:description>Comment: 6 pages; poster at NMR2000, Breckenridge, April 2000</dc:description>
 <dc:date>2000-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>XNMR: A tool for knowledge bases exploration</dc:title>
 <dc:creator>Castro, L.</dc:creator>
 <dc:creator>Warren, D.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:description>  XNMR is a system designed to explore the results of combining the
well-founded semantics system XSB with the stable-models evaluator SMODELS. Its
main goal is to work as a tool for fast and interactive exploration of
knowledge bases.
</dc:description>
 <dc:description>Comment: 2 pages; no figures; NMR2000 Systems Description</dc:description>
 <dc:date>2000-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on knowledge-based programs and specifications</dc:title>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>D.2.1</dc:subject>
 <dc:description>  Knowledge-based program are programs with explicit tests for knowledge. They
have been used successfully in a number of applications. Sanders has pointed
out what seem to be a counterintuitive property of knowledge-based programs.
Roughly speaking, they do not satisfy a certain monotonicity property, while
standard programs (ones without tests for knowledge) do. It is shown that there
are two ways of defining the monotonicity property, which agree for standard
programs. Knowledge-based programs satisfy the first, but do not satisfy the
second. It is further argued by example that the fact that they do not satisfy
the second is actually a feature, not a problem. Moreover, once we allow the
more general class of knowledge-based specifications, standard programs do not
satisfy the monotonicity property either.
</dc:description>
 <dc:description>Comment: To appear, Distributed Computing</dc:description>
 <dc:date>2000-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SATEN: An Object-Oriented Web-Based Revision and Extraction Engine</dc:title>
 <dc:creator>Williams, Mary-Anne</dc:creator>
 <dc:creator>Sims, Aidan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  SATEN is an object-oriented web-based extraction and belief revision engine.
It runs on any computer via a Java 1.1 enabled browser such as Netscape 4.
SATEN performs belief revision based on the AGM approach. The extraction and
belief revision reasoning engines operate on a user specified ranking of
information. One of the features of SATEN is that it can be used to integrate
mutually inconsistent commensuate rankings into a consistent ranking.
</dc:description>
 <dc:description>Comment: The implementation of SATEN can be found at
  http://cafe.newcastle.edu.au/saten</dc:description>
 <dc:date>2000-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Message Classification in the Call Center</dc:title>
 <dc:creator>Busemann, Stephan</dc:creator>
 <dc:creator>Schmeier, Sven</dc:creator>
 <dc:creator>Arens, Roman G.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.7.5</dc:subject>
 <dc:description>  Customer care in technical domains is increasingly based on e-mail
communication, allowing for the reproduction of approved solutions. Identifying
the customer's problem is often time-consuming, as the problem space changes if
new products are launched. This paper describes a new approach to the
classification of e-mail requests based on shallow text processing and machine
learning techniques. It is implemented within an assistance system for call
center agents that is used in a commercial setting.
</dc:description>
 <dc:description>Comment: 8 pages with 2 figures</dc:description>
 <dc:date>2000-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003060</dc:identifier>
 <dc:identifier>Proceedings of ANLP-2000, Seattle, WA</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>dcs: An Implementation of DATALOG with Constraints</dc:title>
 <dc:creator>East, Deborah</dc:creator>
 <dc:creator>Truszczynski, Miroslaw</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Answer-set programming (ASP) has emerged recently as a viable programming
paradigm. We describe here an ASP system, DATALOG with constraints or DC, based
on non-monotonic logic. Informally, DC theories consist of propositional
clauses (constraints) and of Horn rules. The semantics is a simple and natural
extension of the semantics of the propositional logic. However, thanks to the
presence of Horn rules in the system, modeling of transitive closure becomes
straightforward. We describe the syntax, use and implementation of DC and
provide experimental results.
</dc:description>
 <dc:description>Comment: 6 pages (AAAI format), 4 ps figures; System descriptions and
  demonstration Session, 8th Intl. Workshop on Non-Monotonic Reasoning</dc:description>
 <dc:date>2000-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reasoning with Higher-Order Abstract Syntax in a Logical Framework</dc:title>
 <dc:creator>McDowell, Raymond C.</dc:creator>
 <dc:creator>Miller, Dale A.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Logical frameworks based on intuitionistic or linear logics with higher-type
quantification have been successfully used to give high-level, modular, and
formal specifications of many important judgments in the area of programming
languages and inference systems. Given such specifications, it is natural to
consider proving properties about the specified systems in the framework: for
example, given the specification of evaluation for a functional programming
language, prove that the language is deterministic or that evaluation preserves
types. One challenge in developing a framework for such reasoning is that
higher-order abstract syntax (HOAS), an elegant and declarative treatment of
object-level abstraction and substitution, is difficult to treat in proofs
involving induction. In this paper, we present a meta-logic that can be used to
reason about judgments coded using HOAS; this meta-logic is an extension of a
simple intuitionistic logic that admits higher-order quantification over simply
typed lambda-terms (key ingredients for HOAS) as well as induction and a notion
of definition. We explore the difficulties of formal meta-theoretic analysis of
HOAS encodings by considering encodings of intuitionistic and linear logics,
and formally derive the admissibility of cut for important subsets of these
logics. We then propose an approach to avoid the apparent tradeoff between the
benefits of higher-order abstract syntax and the ability to analyze the
resulting encodings. We illustrate this approach through examples involving the
simple functional and imperative programming languages PCF and PCF:=. We
formally derive such properties as unicity of typing, subject reduction,
determinacy of evaluation, and the equivalence of transition semantics and
natural semantics presentations of evaluation.
</dc:description>
 <dc:description>Comment: 56 pages, 21 tables; revised in light of reviewer comments; to appear
  in ACM Transactions on Computational Logic</dc:description>
 <dc:date>2000-03-14</dc:date>
 <dc:date>2001-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistics and implementation of APRNGs</dc:title>
 <dc:creator>Guimond, Louis-Sebastien</dc:creator>
 <dc:creator>Patera, Jan</dc:creator>
 <dc:creator>Patera, Jiri</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>G3</dc:subject>
 <dc:description>  This paper has been temporarily withdrawn by the author(s),
</dc:description>
 <dc:description>Comment: This paper has been temporarily withdrawn by the author(s)</dc:description>
 <dc:date>2000-03-14</dc:date>
 <dc:date>2000-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A network file system over HTTP: remote access and modification of files
  and &quot;files&quot;</dc:title>
 <dc:creator>Kiselyov, Oleg</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>D.4.3</dc:subject>
 <dc:subject>D.4.4</dc:subject>
 <dc:subject>E.5</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  The goal of the present HTTPFS project is to enable access to remote files,
directories, and other containers through an HTTP pipe. HTTPFS system permits
retrieval, creation and modification of these resources as if they were regular
files and directories on a local filesystem. The remote host can be any UNIX or
Win9x/WinNT box that is capable of running a Perl CGI script and accessible
either directly or via a web proxy or a gateway. HTTPFS runs entirely in user
space.
  The current implementation fully supports reading as well as creating,
writing, appending, and truncating of files on a remote HTTP host. HTTPFS
provides an isolation level for concurrent file access stronger than the one
mandated by POSIX file system semantics, closer to that of AFS. Both an API
with familiar open(), read(), write(), close(), etc. calls, and an interactive
interface, via the popular Midnight Commander file browser, are provided.
</dc:description>
 <dc:description>Comment: This present document combines a paper and a Freenix Track talk
  presented at a 1999 USENIX Annual Technical Conference, June 6-11, 1999;
  Monterey, CA, USA; 6 HTML files. The paper alone appeared in Proc. FREENIX
  Track: 1999 USENIX Annual Technical Conference, June 6-11,1999; Monterey, CA,
  USA, pp. 75-80</dc:description>
 <dc:date>2000-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003065</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Compression with Iterated Function Systems, Finite Automata and
  Zerotrees: Grand Unification</dc:title>
 <dc:creator>Kiselyov, Oleg</dc:creator>
 <dc:creator>Fisher, Paul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.2</dc:subject>
 <dc:subject>I.4.10</dc:subject>
 <dc:subject>G.1.2</dc:subject>
 <dc:description>  Fractal image compression, Culik's image compression and zerotree prediction
coding of wavelet image decomposition coefficients succeed only because typical
images being compressed possess a significant degree of self-similarity.
Besides the common concept, these methods turn out to be even more tightly
related, to the point of algorithmical reducibility of one technique to
another. The goal of the present paper is to demonstrate these relations.
  The paper offers a plain-term interpretation of Culik's image compression, in
regular image processing terms, without resorting to finite state machines and
similar lofty language. The interpretation is shown to be algorithmically
related to an IFS fractal image compression method: an IFS can be exactly
transformed into Culik's image code. Using this transformation, we will prove
that in a self-similar (part of an) image any zero wavelet coefficient is the
root of a zerotree, or its branch.
  The paper discusses the zerotree coding of (wavelet/projection) coefficients
as a common predictor/corrector, applied vertically through different layers of
a multiresolutional decomposition, rather than within the same view. This
interpretation leads to an insight into the evolution of image compression
techniques: from a causal single-layer prediction, to non-causal same-view
predictions (wavelet decomposition among others) and to a causal cross-layer
prediction (zero-trees, Culik's method).
</dc:description>
 <dc:description>Comment: This is a full paper submitted to Data Compression Conference '96; 10
  pages; The abstract of this paper was published in Proc. DCC'96: Data
  Compression Conference, March 31 - April 3, 1996, Snowbird, Utah, IEEE
  Computer Society Press, Los Alamitos, California, 1996, p.443</dc:description>
 <dc:date>2000-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003065</dc:identifier>
 <dc:identifier>doi:10.1109/DCC.1996.488375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Specifying and Implementing Security Policies Using LaSCO, the Language
  for Security Constraints on Objects</dc:title>
 <dc:creator>Hoagland, James A.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:description>  In this dissertation, we present LaSCO, the Language for Security Constraints
on Objects, a new approach to expressing security policies using policy graphs
and present a method for enforcing policies so expressed. Other approaches for
stating security policies fall short of what is desirable with respect to
either policy clarity, executability, or the precision with which a policy may
be expressed. However, LaSCO is designed to have those three desirable
properties of a security policy language as well as: relevance for many
different systems, statement of policies at an appropriate level of detail,
user friendliness for both casual and expert users, and amenability to formal
reasoning. In LaSCO, the constraints of a policy are stated as directed graphs
annotated with expressions describing the situation under which the policy
applies and what the requirement is. LaSCO may be used for such diverse
applications as executing programs, file systems, operating systems,
distributed systems, and networks.
  Formal operational semantics have been defined for LaSCO. An architecture for
implementing LaSCO on any system, is presented along with an implementation of
the system-independent portion in Perl. Using this, we have implemented LaSCO
for Java programs, preventing Java programs from violating policy. A GUI to
facilitate writing policies is provided. We have studied applying LaSCO to a
network as viewed by GrIDS, a distributed intrusion detection system for large
networks, and propose a design. We conclude that LaSCO has characteristics that
enable its use on different types of systems throughout the process of
precisely expressing a policy, understanding the implications of a policy, and
implementing it on a system.
</dc:description>
 <dc:description>Comment: Ph.D. disseration, UC Davis, Computer Science, March 2000. In color
  but looks okay in black and white</dc:description>
 <dc:date>2000-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Unsolvable Queries for Definite Logic Programs</dc:title>
 <dc:creator>Bruynooghe, Maurice</dc:creator>
 <dc:creator>Vandecasteele, Henk</dc:creator>
 <dc:creator>de Waal, D. Andre</dc:creator>
 <dc:creator>Denecker, Marc</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  In solving a query, the SLD proof procedure for definite programs sometimes
searches an infinite space for a non existing solution. For example, querying a
planner for an unreachable goal state. Such programs motivate the development
of methods to prove the absence of a solution. Considering the definite program
and the query ``&lt;- Q'' as clauses of a first order theory, one can apply model
generators which search for a finite interpretation in which the program
clauses as well as the clause ``false &lt;- Q'' are true. This paper develops a
new approach which exploits the fact that all clauses are definite. It is based
on a goal directed abductive search in the space of finite pre-interpretations
for a pre-interpretation such that ``Q'' is false in the least model of the
program based on it. Several methods for efficiently searching the space of
pre-interpretations are presented. Experimental results confirm that our
approach find solutions with less search than with the use of a first order
model generator.
</dc:description>
 <dc:description>Comment: 32 pages including appendix. A preliminary version appeared in
  proceedings PLILP/ALP98 (Springer LNCS 1490) This version, without appendix
  appeared in Journal Functional and Logic Programming 1999</dc:description>
 <dc:date>2000-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003067</dc:identifier>
 <dc:identifier>Journal of Functional and Logic Programming, Vol. 1999, 1-35, 1999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Polyvariant Binding-Time Analysis for Off-line Partial Deduction</dc:title>
 <dc:creator>Bruynooghe, Maurice</dc:creator>
 <dc:creator>Leuschel, Michael</dc:creator>
 <dc:creator>Sagonas, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.3.0</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  We study the notion of binding-time analysis for logic programs. We formalise
the unfolding aspect of an on-line partial deduction system as a Prolog
program. Using abstract interpretation, we collect information about the
run-time behaviour of the program. We use this information to make the control
decisions about the unfolding at analysis time and to turn the on-line system
into an off-line system. We report on some initial experiments.
</dc:description>
 <dc:description>Comment: 19 pages (including appendix) Paper (without appendix) appeared in
  Programming Languages and Systems, Proceedings of the European Symposium on
  Programming (ESOP'98), Part of ETAPS'98 (Chris Hankin, eds.), LNCS, vol.
  1381, 1998, pp. 27-41</dc:description>
 <dc:date>2000-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003069</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proving Failure of Queries for Definite Logic Programs Using XSB-Prolog</dc:title>
 <dc:creator>Pelov, Nikolay</dc:creator>
 <dc:creator>Bruynooghe, Maurice</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  Proving failure of queries for definite logic programs can be done by
constructing a finite model of the program in which the query is false. A
general purpose model generator for first order logic can be used for this. A
recent paper presented at PLILP98 shows how the peculiarities of definite
programs can be exploited to obtain a better solution. There a procedure is
described which combines abduction with tabulation and uses a meta-interpreter
for heuristic control of the search. The current paper shows how similar
results can be obtained by direct execution under the standard tabulation of
the XSB-Prolog system. The loss of control is compensated for by better
intelligent backtracking and more accurate failure analysis.
</dc:description>
 <dc:description>Comment: 18 pages, 1 figure, 3 tables presented at LPAR'99, Tbilisi, Georgia</dc:description>
 <dc:date>2000-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The (Lazy) Functional Side of Logic Programming</dc:title>
 <dc:creator>Etalle, S.</dc:creator>
 <dc:creator>Mountjoy, J.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.1.1</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>F.3.3</dc:subject>
 <dc:description>  The possibility of translating logic programs into functional ones has long
been a subject of investigation. Common to the many approaches is that the
original logic program, in order to be translated, needs to be well-moded and
this has led to the common understanding that these programs can be considered
to be the ``functional part'' of logic programs. As a consequence of this it
has become widely accepted that ``complex'' logical variables, the possibility
of a dynamic selection rule, and general properties of non-well-moded programs
are exclusive features of logic programs. This is not quite true, as some of
these features are naturally found in lazy functional languages. We readdress
the old question of what features are exclusive to the logic programming
paradigm by defining a simple translation applicable to a wider range of logic
programs, and demonstrate that the current circumscription is unreasonably
restrictive.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2000-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Axiomatic Synthesis of Computer Programs and Computability Theorems</dc:title>
 <dc:creator>Volkstorf, Charlie</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.1.2</dc:subject>
 <dc:subject>D.2.1</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>H.2.3</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:description>  We introduce a set of eight universal Rules of Inference by which computer
programs with known properties (axioms) are transformed into new programs with
known properties (theorems). Axioms are presented to formalize a segment of
Number Theory, DataBase retrieval and Computability Theory. The resulting
Program Calculus is used to generate programs to (1) Determine if one number is
a factor of another. (2) List all employees who earn more than their manager.
(3) List the set of programs that halt no on themselves, thus proving that it
is recursively enumerable. The well-known fact that the set of programs that do
not halt yes on themselves is not recursively enumerable is formalized as a
program requirement that has no solution, an Incompleteness Axiom. Thus, any
axioms (programs) which could be used to generate this program are themselves
unattainable. Such proofs are presented to formally generate several additional
theorems, including (4) The halting problem is unsolvable.
  Open problems and future research is discussed, including the use of
temporary sort files, programs that calculate statistics (such as counts and
sums), the synthesis of programs to solve other well-known problems from Number
Theory, Logic, DataBase retrieval and Computability Theory, application to
Programming Language Semantics, and the formalization of incompleteness results
from Logic and the semantic paradoxes.
</dc:description>
 <dc:description>Comment: for submission to Journal of the ACM</dc:description>
 <dc:date>2000-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003072</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MOO: A Methodology for Online Optimization through Mining the Offline
  Optimum</dc:title>
 <dc:creator>Lee, Jason W. H.</dc:creator>
 <dc:creator>Tay, Y. C.</dc:creator>
 <dc:creator>Tung, Anthony K. H.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:description>  Ports, warehouses and courier services have to decide online how an arriving
task is to be served in order that cost is minimized (or profit maximized).
These operators have a wealth of historical data on task assignments; can these
data be mined for knowledge or rules that can help the decision-making?
  MOO is a novel application of data mining to online optimization. The idea is
to mine (logged) expert decisions or the offline optimum for rules that can be
used for online decisions. It requires little knowledge about the task
distribution and cost structure, and is applicable to a wide range of problems.
  This paper presents a feasibility study of the methodology for the well-known
k-server problem. Experiments with synthetic data show that optimization can be
recast as classification of the optimum decisions; the resulting heuristic can
achieve the optimum for strong request patterns, consistently outperforms other
heuristics for weak patterns, and is robust despite changes in cost model.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures</dc:description>
 <dc:date>2000-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the 8th International Workshop on Non-Monotonic
  Reasoning, NMR'2000</dc:title>
 <dc:creator>Baral, Chitta</dc:creator>
 <dc:creator>Truszczynski, Miroslaw</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I2.2</dc:subject>
 <dc:subject>I2.3</dc:subject>
 <dc:subject>I2.4</dc:subject>
 <dc:subject>I2.8</dc:subject>
 <dc:subject>F4.1</dc:subject>
 <dc:description>  The papers gathered in this collection were presented at the 8th
International Workshop on Nonmonotonic Reasoning, NMR2000. The series was
started by John McCarthy in 1978. The first international NMR workshop was held
at Mohonk Mountain House, New Paltz, New York in June, 1984, and was organized
by Ray Reiter and Bonnie Webber.
  In the last 10 years the area of nonmonotonic reasoning has seen a number of
important developments. Significant theoretical advances were made in the
understanding of general abstract principles underlying nonmonotonicity. Key
results on the expressibility and computational complexity of nonmonotonic
logics were established. The role of nonmonotonic reasoning in belief revision,
abduction, reasoning about action, planing and uncertainty was further
clarified. Several successful NMR systems were built and used in applications
such as planning, scheduling, logic programming and constraint satisfaction.
  The papers in the proceedings reflect these recent advances in the field.
They are grouped into sections corresponding to special sessions as they were
held at the workshop:
  1. General NMR track
  2. Abductive reasonig
  3. Belief revision: theory and practice
  4. Representing action and planning
  5. Systems descriptions and demonstrations
  6. Uncertainty frameworks in NMR
</dc:description>
 <dc:description>Comment: Contributing editors: Marc Denecker, Antonis Kakas, Francesca Toni -
  Abductive Reasoning; Samir Chopra, Mary-Anne Williams - Belief change: theory
  and practice; Vladimir Lifschitz, Alessandro Provetti - Representing actions
  and planning; Juergen Dix - System demonstrations and presentations; Salem
  Benferhat, Henri Prade - Uncertainty frameworks in NMR</dc:description>
 <dc:date>2000-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003074</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Finite State and Data-Oriented Method for Grapheme to Phoneme
  Conversion</dc:title>
 <dc:creator>Bouma, Gosse</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  A finite-state method, based on leftmost longest-match replacement, is
presented for segmenting words into graphemes, and for converting graphemes
into phonemes. A small set of hand-crafted conversion rules for Dutch achieves
a phoneme accuracy of over 93%. The accuracy of the system is further improved
by using transformation-based learning. The phoneme accuracy of the best system
(using a large set of rule templates and a `lazy' variant of Brill's algoritm),
trained on only 40K words, reaches 99% accuracy.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2000-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003074</dc:identifier>
 <dc:identifier>Proceedings of NAACL-2000, Seattle, WA</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the theory of system administration</dc:title>
 <dc:creator>Burgess, Mark</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>H.1.m</dc:subject>
 <dc:description>  This paper describes necessary elements for constructing theoretical models
of network and system administration. Armed with a theoretical model it becomes
possible to determine best practices and optimal strategies in a way which
objectively relates policies and assumptions to results obtained. It is
concluded that a mixture of automation and human, or other intelligent
incursion is required to fully implement system policy with current technology.
Some aspects of the author's immunity model for automated system administration
are explained, as an example. A theoretical framework makes the prediction that
the optimal balance between resource availability and garbage collection
strategies is encompassed by the immunity model.
</dc:description>
 <dc:description>Comment: About 38 pages american size, 4 figures</dc:description>
 <dc:date>2000-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constraint Programming viewed as Rule-based Programming</dc:title>
 <dc:creator>Apt, Krzysztof R.</dc:creator>
 <dc:creator>Monfroy, Eric</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  We study here a natural situation when constraint programming can be entirely
reduced to rule-based programming. To this end we explain first how one can
compute on constraint satisfaction problems using rules represented by simple
first-order formulas. Then we consider constraint satisfaction problems that
are based on predefined, explicitly given constraints. To solve them we first
derive rules from these explicitly given constraints and limit the computation
process to a repeated application of these rules, combined with labeling.We
consider here two types of rules. The first type, that we call equality rules,
leads to a new notion of local consistency, called {\em rule consistency} that
turns out to be weaker than arc consistency for constraints of arbitrary arity
(called hyper-arc consistency in \cite{MS98b}). For Boolean constraints rule
consistency coincides with the closure under the well-known propagation rules
for Boolean constraints. The second type of rules, that we call membership
rules, yields a rule-based characterization of arc consistency. To show
feasibility of this rule-based approach to constraint programming we show how
both types of rules can be automatically generated, as {\tt CHR} rules of
\cite{fruhwirth-constraint-95}. This yields an implementation of this approach
to programming by means of constraint logic programming. We illustrate the
usefulness of this approach to constraint programming by discussing various
examples, including Boolean constraints, two typical examples of many valued
logics, constraints dealing with Waltz's language for describing polyhedral
scenes, and Allen's qualitative approach to temporal logic.
</dc:description>
 <dc:description>Comment: 39 pages. To appear in Theory and Practice of Logic Programming
  Journal</dc:description>
 <dc:date>2000-03-24</dc:date>
 <dc:date>2001-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003077</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DATALOG with constraints - an answer-set programming system</dc:title>
 <dc:creator>East, Deborah</dc:creator>
 <dc:creator>Truszczynski, Miroslaw</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>F.4.2</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>I.6.5</dc:subject>
 <dc:description>  Answer-set programming (ASP) has emerged recently as a viable programming
paradigm well attuned to search problems in AI, constraint satisfaction and
combinatorics. Propositional logic is, arguably, the simplest ASP system with
an intuitive semantics supporting direct modeling of problem constraints.
However, for some applications, especially those requiring that transitive
closure be computed, it requires additional variables and results in large
theories. Consequently, it may not be a practical computational tool for such
problems. On the other hand, ASP systems based on nonmonotonic logics, such as
stable logic programming, can handle transitive closure computation efficiently
and, in general, yield very concise theories as problem representations. Their
semantics is, however, more complex. Searching for the middle ground, in this
paper we introduce a new nonmonotonic logic, DATALOG with constraints or DC.
Informally, DC theories consist of propositional clauses (constraints) and of
Horn rules. The semantics is a simple and natural extension of the semantics of
the propositional logic. However, thanks to the presence of Horn rules in the
system, modeling of transitive closure becomes straightforward. We describe the
syntax and semantics of DC, and study its properties. We discuss an
implementation of DC and present results of experimental study of the
effectiveness of DC, comparing it with CSAT, a satisfiability checker and
SMODELS implementation of stable logic programming. Our results show that DC is
competitive with the other two approaches, in case of many search problems,
often yielding much more efficient solutions.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, will appear in Proceedings of AAAI-2000</dc:description>
 <dc:date>2000-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003078</identifier>
 <datestamp>2016-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>About the finding of independent vertices of a graph</dc:title>
 <dc:creator>Plotnikov, Anatoly D.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We examine the Maximum Independent Set Problem in an undirected graph. The
main result is that this problem can be considered as the solving the same
problem in a subclass of the weighted normal twin-orthogonal graphs. The
problem is formulated which is dual to the problem above. It is shown that, for
trivial twin-orthogonal graphs, any of its maximal independent set is also
maximum one.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures</dc:description>
 <dc:date>2000-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003078</dc:identifier>
 <dc:identifier>About the finding of independent vertices of a graph, Journal
  &quot;Kibernetika&quot;, No. 1, 1989, p. 119 - 121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003079</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differential Invariants under Gamma Correction</dc:title>
 <dc:creator>Siebert, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.7</dc:subject>
 <dc:description>  This paper presents invariants under gamma correction and similarity
transformations. The invariants are local features based on differentials which
are implemented using derivatives of the Gaussian. The use of the proposed
invariant representation is shown to yield improved correlation results in a
template matching scenario.
</dc:description>
 <dc:description>Comment: 8 pages, 12 figures</dc:description>
 <dc:date>2000-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003079</dc:identifier>
 <dc:identifier>Vision Interface 2000, Montreal, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003080</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some Remarks on Boolean Constraint Propagation</dc:title>
 <dc:creator>Apt, Krzysztof R.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  We study here the well-known propagation rules for Boolean constraints. First
we propose a simple notion of completeness for sets of such rules and establish
a completeness result. Then we show an equivalence in an appropriate sense
between Boolean constraint propagation and unit propagation, a form of
resolution for propositional logic.
  Subsequently we characterize one set of such rules by means of the notion of
hyper-arc consistency introduced in (Mohr and Masini 1988). Also, we clarify
the status of a similar, though different, set of rules introduced in (Simonis
1989a) and more fully in (Codognet and Diaz 1996).
</dc:description>
 <dc:description>Comment: 14 pages. To appear in: New Trends in Constraints, Papers from the
  Joint ERCIM/Compulog-Net Workshop Cyprus, October 25-27, 1999.
  Springer-Verlag Lecture Notes in Artificial Intelligence</dc:description>
 <dc:date>2000-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variable Word Rate N-grams</dc:title>
 <dc:creator>Gotoh, Yoshihiko</dc:creator>
 <dc:creator>Renals, Steve</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The rate of occurrence of words is not uniform but varies from document to
document. Despite this observation, parameters for conventional n-gram language
models are usually derived using the assumption of a constant word rate. In
this paper we investigate the use of variable word rate assumption, modelled by
a Poisson distribution or a continuous mixture of Poissons. We present an
approach to estimating the relative frequencies of words or n-grams taking
prior information of their occurrences into account. Discounting and smoothing
schemes are also considered. Using the Broadcast News task, the approach
demonstrates a reduction of perplexity up to 10%.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, ICASSP-2000</dc:description>
 <dc:date>2000-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representation results for defeasible logic</dc:title>
 <dc:creator>Antoniou, G.</dc:creator>
 <dc:creator>Billington, D.</dc:creator>
 <dc:creator>Governatori, G.</dc:creator>
 <dc:creator>Maher, M. J.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  The importance of transformations and normal forms in logic programming, and
generally in computer science, is well documented. This paper investigates
transformations and normal forms in the context of Defeasible Logic, a simple
but efficient formalism for nonmonotonic reasoning based on rules and
priorities. The transformations described in this paper have two main benefits:
on one hand they can be used as a theoretical tool that leads to a deeper
understanding of the formalism, and on the other hand they have been used in
the development of an efficient implementation of defeasible logic.
</dc:description>
 <dc:description>Comment: 30 pages, 1 figure</dc:description>
 <dc:date>2000-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003082</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Advances in domain independent linear text segmentation</dc:title>
 <dc:creator>Choi, Freddy Y. Y.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper describes a method for linear text segmentation which is twice as
accurate and over seven times as fast as the state-of-the-art (Reynar, 1998).
Inter-sentence similarity is replaced by rank in the local context. Boundary
locations are discovered by divisive clustering.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures. To appear in Proceedings of NAACL00, Seattle.
  Software and experiment packages available from author's homepage:
  http://www.cs.man.ac.uk/~choif</dc:description>
 <dc:date>2000-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0003084</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Extraction from Broadcast News</dc:title>
 <dc:creator>Gotoh, Yoshihiko</dc:creator>
 <dc:creator>Renals, Steve</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper discusses the development of trainable statistical models for
extracting content from television and radio news broadcasts. In particular we
concentrate on statistical finite state models for identifying proper names and
other named entities in broadcast speech. Two models are presented: the first
represents name class information as a word attribute; the second represents
both word-word and class-class transitions explicitly. A common n-gram based
formulation is used for both models. The task of named entity identification is
characterized by relatively sparse training data and issues related to
smoothing are discussed. Experiments are reported using the DARPA/NIST Hub-4E
evaluation for North American Broadcast News.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figures, Philosophical Transactions of the Royal Society
  of London, series A: Mathematical, Physical and Engineering Sciences, vol.
  358, 2000</dc:description>
 <dc:date>2000-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0003084</dc:identifier>
 <dc:identifier>doi:10.1098/rsta.2000.0587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004001</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Theory of Universal Artificial Intelligence based on Algorithmic
  Complexity</dc:title>
 <dc:creator>Hutter, Marcus</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:description>  Decision theory formally solves the problem of rational agents in uncertain
worlds if the true environmental prior probability distribution is known.
Solomonoff's theory of universal induction formally solves the problem of
sequence prediction for unknown prior distribution. We combine both ideas and
get a parameterless theory of universal Artificial Intelligence. We give strong
arguments that the resulting AIXI model is the most intelligent unbiased agent
possible. We outline for a number of problem classes, including sequence
prediction, strategic games, function minimization, reinforcement and
supervised learning, how the AIXI model can formally solve them. The major
drawback of the AIXI model is that it is uncomputable. To overcome this
problem, we construct a modified algorithm AIXI-tl, which is still effectively
more intelligent than any other time t and space l bounded agent. The
computation time of AIXI-tl is of the order tx2^l. Other discussed topics are
formal definitions of intelligence order relations, the horizon problem and
relations of the AIXI theory to other AI approaches.
</dc:description>
 <dc:description>Comment: 62 pages, LaTeX</dc:description>
 <dc:date>2000-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Programming in Alma-0, or Imperative and Declarative Programming
  Reconciled</dc:title>
 <dc:creator>Apt, Krzysztof R.</dc:creator>
 <dc:creator>Schaerf, Andrea</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>F.3.3</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>I.5.5</dc:subject>
 <dc:description>  In (Apt et al, TOPLAS 1998) we introduced the imperative programming language
Alma-0 that supports declarative programming. In this paper we illustrate the
hybrid programming style of Alma-0 by means of various examples that complement
those presented in (Apt et al, TOPLAS 1998). The presented Alma-0 programs
illustrate the versatility of the language and show that ``don't know''
nondeterminism can be naturally combined with assignment.
</dc:description>
 <dc:description>Comment: With updated references with respect to the published version</dc:description>
 <dc:date>2000-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004002</dc:identifier>
 <dc:identifier>Frontiers of Combining Systems 2, Research Studies Press Ltd, D.
  M. Gabbay and M. de Rijke (editors), pages 1-16, 1999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Searching for Spaceships</dc:title>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  We describe software that searches for spaceships in Conway's Game of Life
and related two-dimensional cellular automata. Our program searches through a
state space related to the de Bruijn graph of the automaton, using a method
that combines features of breadth first and iterative deepening search, and
includes fast bit-parallel graph reachability and path enumeration algorithms
for finding the successors of each state. Successful results include a new 2c/7
spaceship in Life, found by searching a space with 2^126 states.
</dc:description>
 <dc:description>Comment: 17 pages, 13 figures. This revision adds Paul Tooke's new c/6
  &quot;dragon&quot;, and corrects one URL. For more information about the software and
  patterns described here, see http://www.ics.uci.edu/~eppstein/ca/</dc:description>
 <dc:date>2000-04-10</dc:date>
 <dc:date>2000-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004003</dc:identifier>
 <dc:identifier>More Games of No Chance, MSRI Publications 42, 2002, pp. 433-453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mathematical Software: Past, Present, and Future</dc:title>
 <dc:creator>Boisvert, Ronald F.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  This paper provides some reflections on the field of mathematical software on
the occasion of John Rice's 65th birthday. I describe some of the common themes
of research in this field and recall some significant events in its evolution.
Finally, I raise a number of issues that are of concern to future developments.
</dc:description>
 <dc:description>Comment: To appear in the Proceedings of the International Symposium on
  Computational Sciences, Purdue University, May 21-22, 1999. 20 pages</dc:description>
 <dc:date>2000-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Phase Transitions in Random Constraint Satisfaction Problems</dc:title>
 <dc:creator>Xu, Ke</dc:creator>
 <dc:creator>Li, Wei</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  In this paper we propose a new type of random CSP model, called Model RB,
which is a revision to the standard Model B. It is proved that phase
transitions from a region where almost all problems are satisfiable to a region
where almost all problems are unsatisfiable do exist for Model RB as the number
of variables approaches infinity. Moreover, the critical values at which the
phase transitions occur are also known exactly. By relating the hardness of
Model RB to Model B, it is shown that there exist a lot of hard instances in
Model RB.
</dc:description>
 <dc:description>Comment: See http://www.jair.org/ for any accompanying files</dc:description>
 <dc:date>2000-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004005</dc:identifier>
 <dc:identifier>Journal of Artificial Intelligence Research, Vol 12, (2000),
  93-103.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Redundancy Elimination Tolerant Scheduling Rules</dc:title>
 <dc:creator>Ferrucci, F.</dc:creator>
 <dc:creator>Pacini, G.</dc:creator>
 <dc:creator>Sessa, M. I.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:description>  In (Ferrucci, Pacini and Sessa, 1995) an extended form of resolution, called
Reduced SLD resolution (RSLD), is introduced. In essence, an RSLD derivation is
an SLD derivation such that redundancy elimination from resolvents is performed
after each rewriting step. It is intuitive that redundancy elimination may have
positive effects on derivation process. However, undesiderable effects are also
possible. In particular, as shown in this paper, program termination as well as
completeness of loop checking mechanisms via a given selection rule may be
lost. The study of such effects has led us to an analysis of selection rule
basic concepts, so that we have found convenient to move the attention from
rules of atom selection to rules of atom scheduling. A priority mechanism for
atom scheduling is built, where a priority is assigned to each atom in a
resolvent, and primary importance is given to the event of arrival of new atoms
from the body of the applied clause at rewriting time. This new computational
model proves able to address the study of redundancy elimination effects,
giving at the same time interesting insights into general properties of
selection rules. As a matter of fact, a class of scheduling rules, namely the
specialisation independent ones, is defined in the paper by using not trivial
semantic arguments. As a quite surprising result, specialisation independent
scheduling rules turn out to coincide with a class of rules which have an
immediate structural characterisation (named stack-queue rules). Then we prove
that such scheduling rules are tolerant to redundancy elimination, in the sense
that neither program termination nor completeness of equality loop check is
lost passing from SLD to RSLD.
</dc:description>
 <dc:description>Comment: 53 pages, to appear on TPLP</dc:description>
 <dc:date>2000-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deciding first-order properties of locally tree-decomposable structures</dc:title>
 <dc:creator>Frick, Markus</dc:creator>
 <dc:creator>Grohe, Martin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  We introduce the concept of a class of graphs, or more generally, relational
structures, being locally tree-decomposable. There are numerous examples of
locally tree-decomposable classes, among them the class of planar graphs and
all classes of bounded valence or of bounded tree-width. We also consider a
slightly more general concept of a class of structures having bounded local
tree-width.
  We show that for each property P of structures that is definable in
first-order logic and for each locally tree-decomposable class C of graphs,
there is a linear time algorithm deciding whether a given structure A in C has
property P. For classes C of bounded local tree-width, we show that for every
k\ge 1 there is an algorithm that solves the same problem in time
O(n^{1+(1/k)}) (where n is the cardinality of the input structure).
</dc:description>
 <dc:date>2000-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to Evaluate your Question Answering System Every Day and Still Get
  Real Work Done</dc:title>
 <dc:creator>Breck, Eric</dc:creator>
 <dc:creator>Burger, John D.</dc:creator>
 <dc:creator>Ferro, Lisa</dc:creator>
 <dc:creator>Hirschman, Lynette</dc:creator>
 <dc:creator>House, David</dc:creator>
 <dc:creator>Light, Marc</dc:creator>
 <dc:creator>Mani, Inderjeet</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:description>  In this paper, we report on Qaviar, an experimental automated evaluation
system for question answering applications. The goal of our research was to
find an automatically calculated measure that correlates well with human
judges' assessment of answer correctness in the context of question answering
tasks. Qaviar judges the response by computing recall against the stemmed
content words in the human-generated answer key. It counts the answer correct
if it exceeds agiven recall threshold. We determined that the answer
correctness predicted by Qaviar agreed with the human 93% to 95% of the time.
41 question-answering systems were ranked by both Qaviar and human assessors,
and these rankings correlated with a Kendall's Tau measure of 0.920, compared
to a correlation of 0.956 between human assessors on the same data.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, to appear in Proceedings of the Second
  International Conference on Language Resources and Evaluation (LREC 2000)</dc:description>
 <dc:date>2000-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separating the complexity classes NL and NP</dc:title>
 <dc:creator>Benson, David B.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Withdrawn since -order- was overlooked. First order reductions without order
are much too weak to separate.
</dc:description>
 <dc:description>Comment: Withdrawn</dc:description>
 <dc:date>2000-04-17</dc:date>
 <dc:date>2000-05-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004010</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Evaluation of Mechanisms for a Multicomputer Object Store</dc:title>
 <dc:creator>Weaver, Lex</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:description>  Multicomputers have traditionally been viewed as powerful compute engines. It
is from this perspective that they have been applied to various problems in
order to achieve significant performance gains. There are many applications for
which this compute intensive approach is only a partial solution. CAD, virtual
reality, simulation, document management and analysis all require timely access
to large amounts of data. This thesis investigates the use of the object store
paradigm to harness the large distributed memories found on multicomputers. The
design, implementation, and evaluation of a distributed object server on the
Fujitsu AP1000 is described. The performance of the distributed object server
under example applications, mainly physical simulation problems, is used to
evaluate solutions to the problems of client space recovery, object migration,
and coherence maintenance.
  The distributed object server follows the client-server model, allows object
replication, and uses binary semaphores as a concurrency control measure.
Instrumentation of the server under these applications supports several
conclusions: client space recovery should be dynamically controlled by the
application, predictively prefetching object replicas yields benefits in
restricted circumstances, object migration by storage unit (segment) is not
generally suitable where there are many objects per storage unit, and binary
semaphores are an expensive concurrency control measure in this environment.
</dc:description>
 <dc:description>Comment: 1994 Honours thesis, 134 pages</dc:description>
 <dc:date>2000-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Task Frames</dc:title>
 <dc:creator>Steinmacher-Burow, Burkhard D.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:description>  Forty years ago Dijkstra introduced the current conventional execution of
routines. It places activation frames onto a stack. Each frame is the internal
state of an executing routine. The resulting application execution is not
easily helped by an external system. This presentation proposes an alternative
execution of routines. It places task frames onto the stack. A task frame is
the call of a routine to be executed. The feasibility of the alternative
execution is demonstrated by a crude implementation. As described elsewhere, an
application which executes in terms of tasks can be provided by an external
system with a transparent reliable, distributed, heterogeneous, adaptive,
dynamic, real-time, parallel, secure or other execution. By extending the crude
implementation, this presentation outlines a simple transparent parallel
execution.
</dc:description>
 <dc:date>2000-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assisted Video Sequences Indexing : Motion Analysis Based on Interest
  Points</dc:title>
 <dc:creator>Etievent, Emmanuel</dc:creator>
 <dc:creator>Lebourgeois, Frank</dc:creator>
 <dc:creator>Jolion, Jean-Michel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:subject>I.4.9</dc:subject>
 <dc:description>  This work deals with content-based video indexing. Our viewpoint is
semi-automatic analysis of compressed video. We consider the possible
applications of motion analysis and moving object detection : assisting moving
object indexing, summarising videos, and allowing image and motion queries. We
propose an approach based on interest points. As first results, we test and
compare the stability of different types of interest point detectors in
compressed sequences.
</dc:description>
 <dc:description>Comment: HTML, 8 pages, 6 figures, http://rfv.insa-lyon.fr/~etievent/</dc:description>
 <dc:date>2000-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004012</dc:identifier>
 <dc:identifier>Iciap 99, Venezia, 27-29 sept., 1059-1062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sorting Integers on the AP1000</dc:title>
 <dc:creator>Weaver, Lex</dc:creator>
 <dc:creator>Lynes, Andrew</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.1.4</dc:subject>
 <dc:description>  Sorting is one of the classic problems of computer science. Whilst well
understood on sequential machines, the diversity of architectures amongst
parallel systems means that algorithms do not perform uniformly on all
platforms. This document describes the implementation of a radix based
algorithm for sorting positive integers on a Fujitsu AP1000 Supercomputer,
which was constructed as an entry in the Joint Symposium on Parallel Processing
(JSPP) 1994 Parallel Software Contest (PSC94). Brief consideration is also
given to a full radix sort conducted in parallel across the machine.
</dc:description>
 <dc:description>Comment: 1994 Project Report, 23 pages</dc:description>
 <dc:date>2000-04-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cluster Computing White Paper</dc:title>
 <dc:creator>Baker, Mark</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>B.4.1 B.4.3 C.0 C.1.2 C.1.4 C.2 C.4 D.1.3 D.1.5 D.2.11 D.3.1 D.4.1
  D.4.6</dc:subject>
 <dc:description>  Cluster computing is not a new area of computing. It is, however, evident
that there is a growing interest in its usage in all areas where applications
have traditionally used parallel or distributed computing platforms. The
growing interest has been fuelled in part by the availability of powerful
microprocessors and high-speed networks as off-the-shelf commodity components
as well as in part by the rapidly maturing software components available to
support high performance and high availability applications.
  This White Paper has been broken down into eleven sections, each of which has
been put together by academics and industrial researchers who are both experts
in their fields and where willing to volunteer their time and effort to put
together this White Paper. The status of this paper is draft and we are at the
stage of publicizing its presence and making a Request For Comments (RFC).
</dc:description>
 <dc:description>Comment: 119 page white paper - Edited by Mark Baker (University of
  Portsmouth), version 2.0</dc:description>
 <dc:date>2000-04-25</dc:date>
 <dc:date>2001-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introduction to the GiNaC Framework for Symbolic Computation within the
  C++ Programming Language</dc:title>
 <dc:creator>Bauer, Christian</dc:creator>
 <dc:creator>Frink, Alexander</dc:creator>
 <dc:creator>Kreckel, Richard</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>I.1.1</dc:subject>
 <dc:subject>I.1.3</dc:subject>
 <dc:description>  The traditional split-up into a low level language and a high level language
in the design of computer algebra systems may become obsolete with the advent
of more versatile computer languages. We describe GiNaC, a special-purpose
system that deliberately denies the need for such a distinction. It is entirely
written in C++ and the user can interact with it directly in that language. It
was designed to provide efficient handling of multivariate polynomials,
algebras and special functions that are needed for loop calculations in
theoretical quantum field theory. It also bears some potential to become a more
general purpose symbolic package.
</dc:description>
 <dc:date>2000-04-27</dc:date>
 <dc:date>2001-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004015</dc:identifier>
 <dc:identifier>J. Symbolic Computation (2002) 33, 1-12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0004016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Looking at discourse in a corpus: The role of lexical cohesion</dc:title>
 <dc:creator>Sardinha, Tony Berber</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper is aimed at reporting on the development and application of a
computer model for discourse analysis through segmentation. Segmentation refers
to the principled division of texts into contiguous constituents. Other studies
have looked at the application of a number of models to the analysis of
discourse by computer. The segmentation procedure developed for the present
investigation is called LSM ('Link Set Median'). It was applied to three corpus
of 300 texts from three different genres. The results obtained by application
of the LSM procedure on the corpus were then compared to segmentation carried
out at random. Statistical analyses suggested that LSM significantly
outperformed random segmentation, thus indicating that the segmentation was
meaningful.
</dc:description>
 <dc:description>Comment: 5 pages, Paper presented at AILA 99, Tokyo, Japan</dc:description>
 <dc:date>2000-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0004016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robustness of Regional Matching Scheme over Global Matching Scheme</dc:title>
 <dc:creator>Chen, Liang</dc:creator>
 <dc:creator>Tokuda, Naoyuki</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.5.2</dc:subject>
 <dc:subject>H.1</dc:subject>
 <dc:description>  The paper has established and verified the theory prevailing widely among
image and pattern recognition specialists that the bottom-up indirect regional
matching process is the more stable and the more robust than the global
matching process against concentrated types of noise represented by clutter,
outlier or occlusion in the imagery. We have demonstrated this by analyzing the
effect of concentrated noise on a typical decision making process of a
simplified two candidate voting model where our theorem establishes the lower
bounds to a critical breakdown point of election (or decision) result by the
bottom-up matching process are greater than the exact bound of the global
matching process implying that the former regional process is capable of
accommodating a higher level of noise than the latter global process before the
result of decision overturns. We present a convincing experimental verification
supporting not only the theory by a white-black flag recognition problem in the
presence of localized noise but also the validity of the conjecture by a facial
recognition problem that the theorem remains valid for other decision making
processes involving an important dimension-reducing transform such as principal
component analysis or a Gabor transform.
</dc:description>
 <dc:description>Comment: 16 pages, Latex, 7 EPS figures, using esub2acm.cls and epsf.tex</dc:description>
 <dc:date>2000-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application Software, Domain-Specific Languages, and Language Design
  Assistants</dc:title>
 <dc:creator>Heering, Jan</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3</dc:subject>
 <dc:description>  While application software does the real work, domain-specific languages
(DSLs) are tools to help produce it efficiently, and language design assistants
in turn are meta-tools to help produce DSLs quickly. DSLs are already in wide
use (HTML for web pages, Excel macros for spreadsheet applications, VHDL for
hardware design, ...), but many more will be needed for both new as well as
existing application domains. Language design assistants to help develop them
currently exist only in the basic form of language development systems. After a
quick look at domain-specific languages, and especially their relationship to
application libraries, we survey existing language development systems and give
an outline of future language design assistants.
</dc:description>
 <dc:description>Comment: To be presented at SSGRR 2000, L'Aquila, Italy</dc:description>
 <dc:date>2000-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005002</dc:identifier>
 <dc:identifier>in Proceedings SSGRR 2000 International Conference on Advances in
  Infrastructure for Electronic Business, Science, and Education on the
  Internet</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CoRR: A Computing Research Repository</dc:title>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:subject>K.4.0</dc:subject>
 <dc:description>  Discusses how CoRR was set up and some policy issues involved with setting up
such a repository.
</dc:description>
 <dc:description>Comment: This article is based on ``The Computing Research Repository:
  Promoting the Rapid Dissemination of Computer Science Research'', Joseph Y.
  Halpern and Carl Lagoze (http://xxx.lanl.gov/abs/cs.DL/9812020), but focuses
  on somewhat different issues, more geared to the Computer Documentation
  community. It will appear in the ACM Journal of Computer Documentation</dc:description>
 <dc:date>2000-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A response to the commentaries on CoRR</dc:title>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:subject>K.4.0</dc:subject>
 <dc:description>  This is a response to the commentaries on &quot;CoRR: A Computing Research
Repository&quot;.
</dc:description>
 <dc:description>Comment: This is a response to the commentaries on &quot;CoRR: A Computing Research
  Repository&quot; (http://xxx.lanl.gov/abs/cs.DL/0005003). The original article,
  the Commentaries,and my response, will appear in the ACM Journal of Computer
  Documentation</dc:description>
 <dc:date>2000-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Connectivity Compression for Irregular Quadrilateral Meshes</dc:title>
 <dc:creator>King, Davis</dc:creator>
 <dc:creator>Rossignac, Jarek</dc:creator>
 <dc:creator>Szymczak, Andrzej</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:subject>G2.2</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:subject>J.6</dc:subject>
 <dc:description>  Applications that require Internet access to remote 3D datasets are often
limited by the storage costs of 3D models. Several compression methods are
available to address these limits for objects represented by triangle meshes.
Many CAD and VRML models, however, are represented as quadrilateral meshes or
mixed triangle/quadrilateral meshes, and these models may also require
compression. We present an algorithm for encoding the connectivity of such
quadrilateral meshes, and we demonstrate that by preserving and exploiting the
original quad structure, our approach achieves encodings 30 - 80% smaller than
an approach based on randomly splitting quads into triangles. We present both a
code with a proven worst-case cost of 3 bits per vertex (or 2.75 bits per
vertex for meshes without valence-two vertices) and entropy-coding results for
typical meshes ranging from 0.3 to 0.9 bits per vertex, depending on the
regularity of the mesh. Our method may be implemented by a rule for a
particular splitting of quads into triangles and by using the compression and
decompression algorithms introduced in [Rossignac99] and
[Rossignac&amp;Szymczak99]. We also present extensions to the algorithm to compress
meshes with holes and handles and meshes containing triangles and other
polygons as well as quads.
</dc:description>
 <dc:date>2000-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Approach to Building Ensembles of Naive Bayesian Classifiers
  for Word Sense Disambiguation</dc:title>
 <dc:creator>Pedersen, Ted</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper presents a corpus-based approach to word sense disambiguation that
builds an ensemble of Naive Bayesian classifiers, each of which is based on
lexical features that represent co--occurring words in varying sized windows of
context. Despite the simplicity of this approach, empirical results
disambiguating the widely studied nouns line and interest show that such an
ensemble achieves accuracy rivaling the best previously published results.
</dc:description>
 <dc:description>Comment: 7 pages, Latex, uses colnaacl.sty. Appears in Proceedings of NAACL,
  pages 63-69, May 2000, Seattle, WA</dc:description>
 <dc:date>2000-05-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scientific Collaboratories as Socio-Technical Interaction Networks: A
  Theoretical Approach</dc:title>
 <dc:creator>Kling, Rob</dc:creator>
 <dc:creator>McKim, Geoffrey</dc:creator>
 <dc:creator>Fortuna, Joanna</dc:creator>
 <dc:creator>King, Adam</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>H.5.3</dc:subject>
 <dc:description>  Collaboratories refer to laboratories where scientists can work together
while they are in distant locations from each other and from key equipment.
They have captured the interest both of CSCW researchers and of science funders
who wish to optimize the use of rare scientific equipment and expertise. We
examine the kind of CSCW conceptions that help us best understand the character
of working relationships in these scientific collaboratories. Our model,
inspired by actor-network theory, considers technologies as Socio-technical
Interaction Networks (STINs). This model provides a rich understanding of the
scientific collaboratories, and also a more complete understanding of the
conditions and activities that support collaborative work in them. We
illustrate the significance of STIN models with several cases drawn from the
fields of high energy physics and materials science.
</dc:description>
 <dc:date>2000-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Denotational Semantics for First-Order Logic</dc:title>
 <dc:creator>Apt, Krzysztof R.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:description>  In Apt and Bezem [AB99] (see cs.LO/9811017) we provided a computational
interpretation of first-order formulas over arbitrary interpretations. Here we
complement this work by introducing a denotational semantics for first-order
logic. Additionally, by allowing an assignment of a non-ground term to a
variable we introduce in this framework logical variables.
  The semantics combines a number of well-known ideas from the areas of
semantics of imperative programming languages and logic programming. In the
resulting computational view conjunction corresponds to sequential composition,
disjunction to ``don't know'' nondeterminism, existential quantification to
declaration of a local variable, and negation to the ``negation as finite
failure'' rule. The soundness result shows correctness of the semantics with
respect to the notion of truth. The proof resembles in some aspects the proof
of the soundness of the SLDNF-resolution.
</dc:description>
 <dc:description>Comment: 17 pages. Invited talk at the Computational Logic Conference (CL
  2000). To appear in Springer-Verlag Lecture Notes in Computer Science</dc:description>
 <dc:date>2000-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PSPACE Reasoning for Graded Modal Logics</dc:title>
 <dc:creator>Tobies, Stephan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We present a PSPACE algorithm that decides satisfiability of the graded modal
logic Gr(K_R)---a natural extension of propositional modal logic K_R by
counting expressions---which plays an important role in the area of knowledge
representation. The algorithm employs a tableaux approach and is the first
known algorithm which meets the lower bound for the complexity of the problem.
Thus, we exactly fix the complexity of the problem and refute an
ExpTime-hardness conjecture. We extend the results to the logic Gr(K_(R \cap
I)), which augments Gr(K_R) with inverse relations and intersection of
accessibility relations. This establishes a kind of ``theoretical benchmark''
that all algorithmic approaches can be measured against.
</dc:description>
 <dc:date>2000-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005009</dc:identifier>
 <dc:identifier>Journal of Logic and Computation, Vol. 11 No. 1, pp 85-106 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extending and Implementing the Stable Model Semantics</dc:title>
 <dc:creator>Simons, Patrik</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  An algorithm for computing the stable model semantics of logic programs is
developed. It is shown that one can extend the semantics and the algorithm to
handle new and more expressive types of rules. Emphasis is placed on the use of
efficient implementation techniques. In particular, an implementation of
lookahead that safely avoids testing every literal for failure and that makes
the use of lookahead feasible is presented. In addition, a good heuristic is
derived from the principle that the search space should be minimized.
  Due to the lack of competitive algorithms and implementations for the
computation of stable models, the system is compared with three satisfiability
solvers. This shows that the heuristic can be improved by breaking ties, but
leaves open the question of how to break them. It also demonstrates that the
more expressive rules of the stable model semantics make the semantics clearly
preferable over propositional logic when a problem has a more compact logic
program representation. Conjunctive normal form representations are never more
compact than logic program ones.
</dc:description>
 <dc:description>Comment: 109 pages, 30 figures, dissertation for the degree of Doctor of
  Technology</dc:description>
 <dc:date>2000-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Average Analysis of Backtracking on Random Constraint Satisfaction
  Problems</dc:title>
 <dc:creator>Xu, Ke</dc:creator>
 <dc:creator>Li, Wei</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  In this paper we propose a random CSP model, called Model GB, which is a
natural generalization of standard Model B. It is proved that Model GB in which
each constraint is easy to satisfy exhibits non-trivial behaviour (not
trivially satisfiable or unsatisfiable) as the number of variables approaches
infinity. A detailed analysis to obtain an asymptotic estimate (good to 1+o(1))
of the average number of nodes in a search tree used by the backtracking
algorithm on Model GB is also presented. It is shown that the average number of
nodes required for finding all solutions or proving that no solution exists
grows exponentially with the number of variables. So this model might be an
interesting distribution for studying the nature of hard instances and
evaluating the performance of CSP algorithms. In addition, we further
investigate the behaviour of the average number of nodes as r (the ratio of
constraints to variables) varies. The results indicate that as r increases,
random CSP instances get easier and easier to solve, and the base for the
average number of nodes that is exponential in r tends to 1 as r approaches
infinity. Therefore, although the average number of nodes used by the
backtracking algorithm on random CSP is exponential, many CSP instances will be
very easy to solve when r is sufficiently large.
</dc:description>
 <dc:description>Comment: 20 pages, submitted to Annals of Mathematics and Artificial
  Intelligence</dc:description>
 <dc:date>2000-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005011</dc:identifier>
 <dc:identifier>Annals of Mathematics and Artificial Intelligence, 33:21-37, 2001.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reasoning with Axioms: Theory and Pratice</dc:title>
 <dc:creator>Horrocks, Ian</dc:creator>
 <dc:creator>Tobies, Stephan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1, I.2.3, I.2.4</dc:subject>
 <dc:description>  When reasoning in description, modal or temporal logics it is often useful to
consider axioms representing universal truths in the domain of discourse.
Reasoning with respect to an arbitrary set of axioms is hard, even for
relatively inexpressive logics, and it is essential to deal with such axioms in
an efficient manner if implemented systems are to be effective in real
applications. This is particularly relevant to Description Logics, where
subsumption reasoning with respect to a terminology is a fundamental problem.
Two optimisation techniques that have proved to be particularly effective in
dealing with terminologies are lazy unfolding and absorption. In this paper we
seek to improve our theoretical understanding of these important techniques. We
define a formal framework that allows the techniques to be precisely described,
establish conditions under which they can be safely applied, and prove that,
provided these conditions are respected, subsumption testing algorithms will
still function correctly. These results are used to show that the procedures
used in the FaCT system are correct and, moreover, to show how efficiency can
be significantly improved, while still retaining the guarantee of correctness,
by relaxing the safety conditions for absorption.
</dc:description>
 <dc:description>Comment: This paper appeard in the Proceedings of KR'2000</dc:description>
 <dc:date>2000-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Reasoning for Very Expressive Description Logics</dc:title>
 <dc:creator>Horrocks, Ian</dc:creator>
 <dc:creator>Sattler, Ulrike</dc:creator>
 <dc:creator>Tobies, Stephan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1, I.2.3, I.2.4</dc:subject>
 <dc:description>  Description Logics (DLs) are a family of knowledge representation formalisms
mainly characterised by constructors to build complex concepts and roles from
atomic ones. Expressive role constructors are important in many applications,
but can be computationally problematical. We present an algorithm that decides
satisfiability of the DL ALC extended with transitive and inverse roles and
functional restrictions with respect to general concept inclusion axioms and
role hierarchies; early experiments indicate that this algorithm is well-suited
for implementation. Additionally, we show that ALC extended with just
transitive and inverse roles is still in PSPACE. We investigate the limits of
decidability for this family of DLs, showing that relaxing the constraints
placed on the kinds of roles used in number restrictions leads to the
undecidability of all inference problems. Finally, we describe a number of
optimisation techniques that are crucial in obtaining implementations of the
decision procedures, which, despite the worst-case complexity of the problem,
exhibit good performance with real-life problems.
</dc:description>
 <dc:date>2000-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005013</dc:identifier>
 <dc:identifier>Logic Journal of the IGPL 8(3):239-264, May 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Reasoning for Expressive Description Logics</dc:title>
 <dc:creator>Horrocks, Ian</dc:creator>
 <dc:creator>Sattler, Ulrike</dc:creator>
 <dc:creator>Tobies, Stephan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1, I.2.3, I.2.4</dc:subject>
 <dc:description>  Description Logics (DLs) are a family of knowledge representation formalisms
mainly characterised by constructors to build complex concepts and roles from
atomic ones. Expressive role constructors are important in many applications,
but can be computationally problematical. We present an algorithm that decides
satisfiability of the DL ALC extended with transitive and inverse roles, role
hierarchies, and qualifying number restrictions. Early experiments indicate
that this algorithm is well-suited for implementation. Additionally, we show
that ALC extended with just transitive and inverse roles is still in PSPACE.
Finally, we investigate the limits of decidability for this family of DLs.
</dc:description>
 <dc:description>Comment: This paper appeared in the Proceedings of LPAR'99</dc:description>
 <dc:date>2000-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005015</identifier>
 <datestamp>2013-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noun Phrase Recognition by System Combination</dc:title>
 <dc:creator>Sang, Erik F. Tjong Kim</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The performance of machine learning algorithms can be improved by combining
the output of different systems. In this paper we apply this idea to the
recognition of noun phrases.We generate different classifiers by using
different representations of the data. By combining the results with voting
techniques described in (Van Halteren et.al. 1998) we manage to improve the
best reported performances on standard data sets for base noun phrases and
arbitrary noun phrases.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2000-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005015</dc:identifier>
 <dc:identifier>Proceedings of NAACL 2000, Seattle, WA, USA</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Testsuites via Instrumentation</dc:title>
 <dc:creator>Broeker, Norbert</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  This paper explores the usefulness of a technique from software engineering,
namely code instrumentation, for the development of large-scale natural
language grammars. Information about the usage of grammar rules in test
sentences is used to detect untested rules, redundant test sentences, and
likely causes of overgeneration. Results show that less than half of a
large-coverage grammar for German is actually tested by two large testsuites,
and that 10-30% of testing time is redundant. The methodology applied can be
seen as a re-use of grammar writing knowledge for testsuite compilation.
</dc:description>
 <dc:description>Comment: 6 pages, LaTeX2e</dc:description>
 <dc:date>2000-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005016</dc:identifier>
 <dc:identifier>Proc. ANLP--NAACL, Seattle/WA, Apr29--May4 2000, pp.325-330</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reasoning with Individuals for the Description Logic SHIQ</dc:title>
 <dc:creator>Horrock, Ian</dc:creator>
 <dc:creator>Sattler, Ulrike</dc:creator>
 <dc:creator>Tobies, Stephan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1, I.2.3, I.2.4</dc:subject>
 <dc:description>  While there has been a great deal of work on the development of reasoning
algorithms for expressive description logics, in most cases only Tbox reasoning
is considered. In this paper we present an algorithm for combined Tbox and Abox
reasoning in the SHIQ description logic. This algorithm is of particular
interest as it can be used to decide the problem of (database) conjunctive
query containment w.r.t. a schema. Moreover, the realisation of an efficient
implementation should be relatively straightforward as it can be based on an
existing highly optimised implementation of the Tbox algorithm in the FaCT
system.
</dc:description>
 <dc:description>Comment: To appear at CADE-17</dc:description>
 <dc:date>2000-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Modular Termination Proofs of General Logic Programs</dc:title>
 <dc:creator>Bossi, Annalisa</dc:creator>
 <dc:creator>Cocco, Nicoletta</dc:creator>
 <dc:creator>Etalle, Sandro</dc:creator>
 <dc:creator>Rossi, Sabina</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2</dc:subject>
 <dc:subject>D.3</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  We propose a modular method for proving termination of general logic programs
(i.e., logic programs with negation). It is based on the notion of acceptable
programs, but it allows us to prove termination in a truly modular way. We
consider programs consisting of a hierarchy of modules and supply a general
result for proving termination by dealing with each module separately. For
programs which are in a certain sense well-behaved, namely well-moded or
well-typed programs, we derive both a simple verification technique and an
iterative proof method. Some examples show how our system allows for greatly
simplified proofs.
</dc:description>
 <dc:description>Comment: 29 pages. To appear in Theory and Practice of Logic Programming</dc:description>
 <dc:date>2000-05-11</dc:date>
 <dc:date>2001-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Scalability of the Answer Extraction System &quot;ExtrAns&quot;</dc:title>
 <dc:creator>Aliod, Diego Moll'a</dc:creator>
 <dc:creator>Hess, Michael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper reports on the scalability of the answer extraction system
ExtrAns. An answer extraction system locates the exact phrases in the documents
that contain the explicit answers to the user queries. Answer extraction
systems are therefore more convenient than document retrieval systems in
situations where the user wants to find specific information in limited time.
  ExtrAns performs answer extraction over UNIX manpages. It has been
constructed by combining available linguistic resources and implementing only a
few modules from scratch. A resolution procedure between the minimal logical
form of the user query and the minimal logical forms of the manpage sentences
finds the answers to the queries. These answers are displayed to the user,
together with pointers to the respective manpages, and the exact phrases that
contribute to the answer are highlighted.
  This paper shows that the increase in response times is not a big issue when
scaling the system up from 30 to 500 documents, and that the response times for
500 documents are still acceptable for a real-time answer extraction system.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2000-05-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005019</dc:identifier>
 <dc:identifier>Applications of Natural Language to Information Systems (NLDB'99).
  Klagenfurt, Austria, 1999, 219-224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Centroid-based summarization of multiple documents: sentence extraction,
  utility-based evaluation, and user studies</dc:title>
 <dc:creator>Radev, Dragomir R.</dc:creator>
 <dc:creator>Jing, Hongyan</dc:creator>
 <dc:creator>Budzikowska, Malgorzata</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We present a multi-document summarizer, called MEAD, which generates
summaries using cluster centroids produced by a topic detection and tracking
system. We also describe two new techniques, based on sentence utility and
subsumption, which we have applied to the evaluation of both single and
multiple document summaries. Finally, we describe two user studies that test
our models of multi-document summarization.
</dc:description>
 <dc:description>Comment: 10 pages Corpus availability at http://perun.si.umich.edu/~radev/mds</dc:description>
 <dc:date>2000-05-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005020</dc:identifier>
 <dc:identifier>NAACL/ANLP Workshop on Automatic Summarization, Seattle, WA, April
  30, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling the Uncertainty in Complex Engineering Systems</dc:title>
 <dc:creator>Guergachi, A.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.6.4</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  Existing procedures for model validation have been deemed inadequate for many
engineering systems. The reason of this inadequacy is due to the high degree of
complexity of the mechanisms that govern these systems. It is proposed in this
paper to shift the attention from modeling the engineering system itself to
modeling the uncertainty that underlies its behavior. A mathematical framework
for modeling the uncertainty in complex engineering systems is developed. This
framework uses the results of computational learning theory. It is based on the
premise that a system model is a learning machine.
</dc:description>
 <dc:description>Comment: 24 pages using ACM style file</dc:description>
 <dc:date>2000-05-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005022</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fractionally-addressed delay lines</dc:title>
 <dc:creator>Rocchesso, Davide</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:description>  While traditional implementations of variable-length digital delay lines are
based on a circular buffer accessed by two pointers, we propose an
implementation where a single fractional pointer is used both for read and
write operations. On modern general-purpose architectures, the proposed method
is nearly as efficient as the popularinterpolated circular buffer, and it
behaves well for delay-length modulations commonly found in digital audio
effects. The physical interpretation of the new implementation shows that it is
suitable for simulating tension or density modulations in wave-propagating
media.
</dc:description>
 <dc:description>Comment: 11 pages, 19 figures, to be published in IEEE Transactions on Speech
  and Audio Processing Corrected ACM-class</dc:description>
 <dc:date>2000-05-17</dc:date>
 <dc:date>2000-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005022</dc:identifier>
 <dc:identifier>IEEE Transactions on Speech and Audio Processing, vol. 8, no. 6,
  november 2000, pp. 717-727</dc:identifier>
 <dc:identifier>doi:10.1109/89.876310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>C++ programming language for an abstract massively parallel SIMD
  architecture</dc:title>
 <dc:creator>Lonardo, Alessandro</dc:creator>
 <dc:creator>Panizzi, Emanuele</dc:creator>
 <dc:creator>Proietti, Benedetto</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>D.2.1</dc:subject>
 <dc:description>  The aim of this work is to define and implement an extended C++ language to
support the SIMD programming paradigm. The C++ programming language has been
extended to express all the potentiality of an abstract SIMD machine consisting
of a central Control Processor and a N-dimensional toroidal array of Numeric
Processors. Very few extensions have been added to the standard C++ with the
goal of minimising the effort for the programmer in learning a new language and
to keep very high the performance of the compiled code. The proposed language
has been implemented as a porting of the GNU C++ Compiler on a SIMD
supercomputer.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2000-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The SAT Phase Transition</dc:title>
 <dc:creator>Xu, Ke</dc:creator>
 <dc:creator>Li, Wei</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.2.m</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  Phase transition is an important feature of SAT problem. For random k-SAT
model, it is proved that as r (ratio of clauses to variables) increases, the
structure of solutions will undergo a sudden change like satisfiability phase
transition when r reaches a threshold point. This phenomenon shows that the
satisfying truth assignments suddenly shift from being relatively different
from each other to being very similar to each other.
</dc:description>
 <dc:description>Comment: 13 pages, 3 figures</dc:description>
 <dc:date>2000-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005024</dc:identifier>
 <dc:identifier>The SAT Phase Transition. Science in China, Series E,
  42(5):494-501, 1999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite-State Reduplication in One-Level Prosodic Morphology</dc:title>
 <dc:creator>Walther, Markus</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Reduplication, a central instance of prosodic morphology, is particularly
challenging for state-of-the-art computational morphology, since it involves
copying of some part of a phonological string. In this paper I advocate a
finite-state method that combines enriched lexical representations via
intersection to implement the copying. The proposal includes a
resource-conscious variant of automata and can benefit from the existence of
lazy algorithms. Finally, the implementation of a complex case from Koasati is
presented.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2000-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005025</dc:identifier>
 <dc:identifier>Proc. NAACL-2000, Seattle/WA, pp.296-302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A One-Time Pad based Cipher for Data Protection in Distributed
  Environments</dc:title>
 <dc:creator>Sobrado, Igor</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:description>  A one-time pad (OTP) based cipher to insure both data protection and
integrity when mobile code arrives to a remote host is presented. Data
protection is required when a mobile agent could retrieve confidential
information that would be encrypted in untrusted nodes of the network; in this
case, information management could not rely on carrying an encryption key. Data
integrity is a prerequisite because mobile code must be protected against
malicious hosts that, by counterfeiting or removing collected data, could cover
information to the server that has sent the agent. The algorithm described in
this article seems to be simple enough, so as to be easily implemented. This
scheme is based on a non-interactive protocol and allows a remote host to
change its own data on-the-fly and, at the same time, protecting information
against handling by other hosts.
</dc:description>
 <dc:description>Comment: 19 pages, 8 PostScript figures (attached), uses ACM/LaTeX macros
  esub2acm.{bst|cls} and pifont package</dc:description>
 <dc:date>2000-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005027</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bayesian Reflection on Surfaces</dc:title>
 <dc:creator>Wolf, David R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.4.1</dc:subject>
 <dc:subject>I.4.4</dc:subject>
 <dc:subject>I.4.5</dc:subject>
 <dc:subject>I.4.10</dc:subject>
 <dc:description>  The topic of this paper is a novel Bayesian continuous-basis field
representation and inference framework. Within this paper several problems are
solved: The maximally informative inference of continuous-basis fields, that is
where the basis for the field is itself a continuous object and not
representable in a finite manner; the tradeoff between accuracy of
representation in terms of information learned, and memory or storage capacity
in bits; the approximation of probability distributions so that a maximal
amount of information about the object being inferred is preserved; an
information theoretic justification for multigrid methodology. The maximally
informative field inference framework is described in full generality and
denoted the Generalized Kalman Filter. The Generalized Kalman Filter allows the
update of field knowledge from previous knowledge at any scale, and new data,
to new knowledge at any other scale. An application example instance, the
inference of continuous surfaces from measurements (for example, camera image
data), is presented.
</dc:description>
 <dc:description>Comment: 34 pages, 1 figure, abbreviated versions presented: Bayesian
  Statistics, Valencia, Spain, 1998; Maximum Entropy and Bayesian Methods,
  Garching, Germany, 1998</dc:description>
 <dc:date>2000-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005027</dc:identifier>
 <dc:identifier>Entropy, Vol.1, Issue 4, 69-98, 1999. http://www.mdpi.org/entropy/</dc:identifier>
 <dc:identifier>doi:10.3390/e1040069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A method for command identification, using modified collision free
  hashing with addition &amp; rotation iterative hash functions (part 1)</dc:title>
 <dc:creator>Skraparlis, Dimitrios</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>B.4.2</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  This paper proposes a method for identification of a user`s fixed string set
(which can be a command/instruction set for a terminal or microprocessor). This
method is fast and has very small memory requirements, compared to a
traditional full string storage and compare method. The user feeds characters
into a microcontroller via a keyboard or another microprocessor sends commands
and the microcontroller hashes the input in order to identify valid commands,
ensuring no collisions between hashed valid strings, while applying further
criteria to narrow collision between random and valid strings. The method
proposed narrows the possibility of the latter kind of collision, achieving
small code and memory-size utilization and very fast execution. Hashing is
achieved using additive &amp; rotating hash functions in an iterative form, which
can be very easily implemented in simple microcontrollers and microprocessors.
Such hash functions are presented and compared according to their efficiency
for a given string/command set, using the program found in the appendix.
</dc:description>
 <dc:description>Comment: 28 pages, includes code</dc:description>
 <dc:date>2000-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ranking suspected answers to natural language questions using predictive
  annotation</dc:title>
 <dc:creator>Radev, Dragomir R.</dc:creator>
 <dc:creator>Prager, John</dc:creator>
 <dc:creator>Samn, Valerie</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  In this paper, we describe a system to rank suspected answers to natural
language questions. We process both corpus and query using a new technique,
predictive annotation, which augments phrases in texts with labels anticipating
their being targets of certain kinds of questions. Given a natural language
question, an IR system returns a set of matching passages, which are then
analyzed and ranked according to various criteria described in this paper. We
provide an evaluation of the techniques based on results from the TREC Q&amp;A
evaluation in which our system participated.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2000-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005029</dc:identifier>
 <dc:identifier>ANLP'00, Seattle, WA, May 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Axiomatizing Causal Reasoning</dc:title>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Causal models defined in terms of a collection of equations, as defined by
Pearl, are axiomatized here. Axiomatizations are provided for three
successively more general classes of causal models: (1) the class of recursive
theories (those without feedback), (2) the class of theories where the
solutions to the equations are unique, (3) arbitrary theories (where the
equations may not have solutions and, if they do, they are not necessarily
unique). It is shown that to reason about causality in the most general third
class, we must extend the language used by Galles and Pearl. In addition, the
complexity of the decision procedures is characterized for all the languages
and classes of models considered.
</dc:description>
 <dc:description>Comment: An earlier version of this paper appeared in UAI '98</dc:description>
 <dc:date>2000-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005030</dc:identifier>
 <dc:identifier>Journal of AI Research, Vol. 12, 2000, pp. 317--337</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005031</identifier>
 <datestamp>2011-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional Plausibility Measures and Bayesian Networks</dc:title>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  A general notion of algebraic conditional plausibility measures is defined.
Probability measures, ranking functions, possibility measures, and (under the
appropriate definitions) sets of probability measures can all be viewed as
defining algebraic conditional plausibility measures. It is shown that
algebraic conditional plausibility measures can be represented using Bayesian
networks.
</dc:description>
 <dc:date>2000-05-30</dc:date>
 <dc:date>2011-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005031</dc:identifier>
 <dc:identifier>Journal Of Artificial Intelligence Research, Volume 14, pages
  359-389, 2001</dc:identifier>
 <dc:identifier>doi:10.1613/jair.817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005032</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Complexity and Phase Transitions</dc:title>
 <dc:creator>Istrate, Gabriel</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Phase transitions in combinatorial problems have recently been shown to be
useful in locating &quot;hard&quot; instances of combinatorial problems. The connection
between computational complexity and the existence of phase transitions has
been addressed in Statistical Mechanics and Artificial Intelligence, but not
studied rigorously.
  We take a step in this direction by investigating the existence of sharp
thresholds for the class of generalized satisfiability problems defined by
Schaefer. In the case when all constraints are clauses we give a complete
characterization of such problems that have a sharp threshold.
  While NP-completeness does not imply (even in this restricted case) the
existence of a sharp threshold, it &quot;almost implies&quot; this, since clausal
generalized satisfiability problems that lack a sharp threshold are either
  1. polynomial time solvable, or
  2. predicted, with success probability lower bounded by some positive
constant by across all the probability range, by a single, trivial procedure.
</dc:description>
 <dc:description>Comment: A (slightly) revised version of the paper submitted to the 15th IEEE
  Conference on Computational Complexity</dc:description>
 <dc:date>2000-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005032</dc:identifier>
 <dc:identifier>doi:10.1109/CCC.2000.856740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0005033</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimethods and separate static typechecking in a language with
  C++-like object model</dc:title>
 <dc:creator>Panizzi, Emanuele</dc:creator>
 <dc:creator>Pastorelli, Bernardo</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.5</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:description>  The goal of this paper is the description and analysis of multimethod
implementation in a new object-oriented, class-based programming language
called OOLANG. The implementation of the multimethod typecheck and selection,
deeply analyzed in the paper, is performed in two phases in order to allow
static typechecking and separate compilation of modules. The first phase is
performed at compile time, while the second is executed at link time and does
not require the modules' source code. OOLANG has syntax similar to C++; the
main differences are the absence of pointers and the realization of
polymorphism through subsumption. It adopts the C++ object model and supports
multiple inheritance as well as virtual base classes. For this reason, it has
been necessary to define techniques for realigning argument and return value
addresses when performing multimethod invocations.
</dc:description>
 <dc:description>Comment: 15 pages, 18 figures</dc:description>
 <dc:date>2000-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0005033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting the Differences: A fast Bayesian classifier neural network</dc:title>
 <dc:creator>Philip, Ninan Sajeeth</dc:creator>
 <dc:creator>Joseph, K. Babu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I1.2</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F1.2</dc:subject>
 <dc:subject>C1.3</dc:subject>
 <dc:description>  A Bayesian classifier that up-weights the differences in the attribute values
is discussed. Using four popular datasets from the UCI repository, some
interesting features of the network are illustrated. The network is suitable
for classification problems.
</dc:description>
 <dc:description>Comment: latex 18pages no figures</dc:description>
 <dc:date>2000-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distorted English Alphabet Identification : An application of Difference
  Boosting Algorithm</dc:title>
 <dc:creator>Philip, Ninan Sajeeth</dc:creator>
 <dc:creator>Joseph, K. Babu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I1.2</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F1.2</dc:subject>
 <dc:subject>C1.3</dc:subject>
 <dc:description>  The difference-boosting algorithm is used on letters dataset from the UCI
repository to classify distorted raster images of English alphabets. In
contrast to rather complex networks, the difference-boosting is found to
produce comparable or better classification efficiency on this complex problem.
</dc:description>
 <dc:description>Comment: latex 14pages no figures</dc:description>
 <dc:date>2000-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Diversity in Natural Language Processing: Combining Parsers</dc:title>
 <dc:creator>Henderson, John C.</dc:creator>
 <dc:creator>Brill, Eric</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Three state-of-the-art statistical parsers are combined to produce more
accurate parses, as well as new bounds on achievable Treebank parsing accuracy.
Two general approaches are presented and two combination techniques are
described for each approach. Both parametric and non-parametric models are
explored. The resulting parsers surpass the best previously published
performance results for the Penn Treebank.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2000-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006003</dc:identifier>
 <dc:identifier>Proceedings of the Fourth Conference on Empirical Methods in
  Natural Language Processing (EMNLP-99), pages 187-194. College Park,
  Maryland, USA. June, 1999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006004</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on &quot;Optimal Static Load Balancing in Distributed Computer
  Systems&quot;</dc:title>
 <dc:creator>Mondal, S. A.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.4 Performance of Systems: modeling techniques</dc:subject>
 <dc:subject>D.4.8 Perfomance:
  modeling and prediction</dc:subject>
 <dc:description>  The problem of minimizing mean response time of generic jobs submitted to a
heterogenous distributed computer systems is considered in this paper. A static
load balancing strategy, in which decision of redistribution of loads does not
depend on the state of the system, is used for this purpose. The article is
closely related to a previous article on the same topic. The present article
points out number of inconsistencies in the previous article, provides a new
formulation, and discusses the impact of new findings, based on the improved
formulation, on the results of the previous article.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2000-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Novelty Detection for Robot Neotaxis</dc:title>
 <dc:creator>Marsland, Stephen</dc:creator>
 <dc:creator>Nehmzow, Ulrich</dc:creator>
 <dc:creator>Shapiro, Jonathan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  The ability of a robot to detect and respond to changes in its environment is
potentially very useful, as it draws attention to new and potentially important
features. We describe an algorithm for learning to filter out previously
experienced stimuli to allow further concentration on novel features. The
algorithm uses a model of habituation, a biological process which causes a
decrement in response with repeated presentation. Experiments with a mobile
robot are presented in which the robot detects the most novel stimulus and
turns towards it (`neotaxis').
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures. In Proceedings of the Second International
  Conference on Neural Computation, 2000</dc:description>
 <dc:date>2000-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Real-Time Novelty Detector for a Mobile Robot</dc:title>
 <dc:creator>Marsland, Stephen</dc:creator>
 <dc:creator>Nehmzow, Ulrich</dc:creator>
 <dc:creator>Shapiro, Jonathan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Recognising new or unusual features of an environment is an ability which is
potentially very useful to a robot. This paper demonstrates an algorithm which
achieves this task by learning an internal representation of `normality' from
sonar scans taken as a robot explores the environment. This model of the
environment is used to evaluate the novelty of each sonar scan presented to it
with relation to the model. Stimuli which have not been seen before, and
therefore have more novelty, are highlighted by the filter. The filter has the
ability to forget about features which have been learned, so that stimuli which
are seen only rarely recover their response over time. A number of robot
experiments are presented which demonstrate the operation of the filter.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures. In Proceedings of EUREL European Advanced
  Robotics Systems Masterclass and Conference, 2000</dc:description>
 <dc:date>2000-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Novelty Detection on a Mobile Robot Using Habituation</dc:title>
 <dc:creator>Marsland, Stephen</dc:creator>
 <dc:creator>Nehmzow, Ulrich</dc:creator>
 <dc:creator>Shapiro, Jonathan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  In this paper a novelty filter is introduced which allows a robot operating
in an un structured environment to produce a self-organised model of its
surroundings and to detect deviations from the learned model. The environment
is perceived using the rob ot's 16 sonar sensors. The algorithm produces a
novelty measure for each sensor scan relative to the model it has learned. This
means that it highlights stimuli which h ave not been previously experienced.
The novelty filter proposed uses a model of hab ituation. Habituation is a
decrement in behavioural response when a stimulus is pre sented repeatedly.
Robot experiments are presented which demonstrate the reliable o peration of
the filter in a number of environments.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures. In From Animals to Animats, The Sixth
  International Conference on Simulation of Adaptive Behaviour, Paris, 2000</dc:description>
 <dc:date>2000-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performing work efficiently in the presence of faults</dc:title>
 <dc:creator>Dwork, Cynthia</dc:creator>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:creator>Waarts, O.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  We consider a system of t synchronous processes that communicate only by
sending messages to one another, and that together must perform $n$ independent
units of work. Processes may fail by crashing; we want to guarantee that in
every execution of the protocol in which at least one process survives, all n
units of work will be performed. We consider three parameters: the number of
messages sent, the total number of units of work performed (including
multiplicities), and time. We present three protocols for solving the problem.
All three are work-optimal, doing O(n+t) work. The first has moderate costs in
the remaining two parameters, sending O(t\sqrt{t}) messages, and taking O(n+t)
time. This protocol can be easily modified to run in any completely
asynchronous system equipped with a failure detection mechanism. The second
sends only O(t log{t}) messages, but its running time is large (exponential in
n and t). The third is essentially time-optimal in the (usual) case in which
there are no failures, and its time complexity degrades gracefully as the
number of failures increases.
</dc:description>
 <dc:date>2000-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006008</dc:identifier>
 <dc:identifier>SIAM Journal on Computing 27:5, 1998, pp. 1457--1491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge and common knowledge in a distributed environment</dc:title>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:creator>Moses, Yoram</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>C.2.2, C.2.4, D.2.4, I.2.4, F.3.1, F.3.1</dc:subject>
 <dc:description>  Reasoning about knowledge seems to play a fundamental role in distributed
systems. Indeed, such reasoning is a central part of the informal intuitive
arguments used in the design of distributed protocols. Communication in a
distributed system can be viewed as the act of transforming the system's state
of knowledge. This paper presents a general framework for formalizing and
reasoning about knowledge in distributed systems. We argue that states of
knowledge of groups of processors are useful concepts for the design and
analysis of distributed protocols. In particular, distributed knowledge
corresponds to knowledge that is ``distributed'' among the members of the
group, while common knowledge corresponds to a fact being ``publicly known''.
The relationship between common knowledge and a variety of desirable actions in
a distributed system is illustrated. Furthermore, it is shown that, formally
speaking, in practical systems common knowledge cannot be attained. A number of
weaker variants of common knowledge that are attainable in many cases of
interest are introduced and investigated.
</dc:description>
 <dc:description>Comment: This paper is copyrighted by ACM and appears in the ACM Digital
  Library</dc:description>
 <dc:date>2000-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006009</dc:identifier>
 <dc:identifier>Journal of the ACM 37:3, 1990, pp. 549--587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006010</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Light Affine Logic (Proof Nets, Programming Notation, P-Time Correctness
  and Completeness)</dc:title>
 <dc:creator>Asperti, Andrea</dc:creator>
 <dc:creator>Roversi, Luca</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  This paper is a structured introduction to Light Affine Logic, and to its
intuitionistic fragment. Light Affine Logic has a polynomially costing cut
elimination (P-Time correctness), and encodes all P-Time Turing machines
(P-Time completeness). P-Time correctness is proved by introducing the Proof
nets for Intuitionistic Light Affine Logic. P-Time completeness is demonstrated
in full details thanks to a very compact program notation. On one side, the
proof of P-Time correctness describes how the complexity of cut elimination is
controlled, thanks to a suitable cut elimination strategy that exploits
structural properties of the Proof nets. This allows to have a good catch on
the meaning of the ``paragraph'' modality, which is a peculiarity of light
logics. On the other side, the proof of P-Time completeness, together with a
lot of programming examples, gives a flavor of the non trivial task of
programming with resource limitations, using Intuitionistic Light Affine Logic
derivations as programs.
</dc:description>
 <dc:date>2000-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bagging and Boosting a Treebank Parser</dc:title>
 <dc:creator>Henderson, John C.</dc:creator>
 <dc:creator>Brill, Eric</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Bagging and boosting, two effective machine learning techniques, are applied
to natural language parsing. Experiments using these techniques with a
trainable statistical parser are described. The best resulting system provides
roughly as large of a gain in F-measure as doubling the corpus size. Error
analysis of the result of the boosting technique reveals some inconsistent
annotations in the Penn Treebank, suggesting a semi-automatic method for
finding inconsistent treebank annotations.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2000-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006011</dc:identifier>
 <dc:identifier>Proceedings of the 1st Meeting of the North American Chapter of
  the Association for Computational Linguistics (NAACL-2000), pages 34-41</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006012</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Diversity for Natural Language Parsing</dc:title>
 <dc:creator>Henderson, John C.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The popularity of applying machine learning methods to computational
linguistics problems has produced a large supply of trainable natural language
processing systems. Most problems of interest have an array of off-the-shelf
products or downloadable code implementing solutions using various techniques.
Where these solutions are developed independently, it is observed that their
errors tend to be independently distributed. This thesis is concerned with
approaches for capitalizing on this situation in a sample problem domain, Penn
Treebank-style parsing.
  The machine learning community provides techniques for combining outputs of
classifiers, but parser output is more structured and interdependent than
classifications. To address this discrepancy, two novel strategies for
combining parsers are used: learning to control a switch between parsers and
constructing a hybrid parse from multiple parsers' outputs.
  Off-the-shelf parsers are not developed with an intention to perform well in
a collaborative ensemble. Two techniques are presented for producing an
ensemble of parsers that collaborate. All of the ensemble members are created
using the same underlying parser induction algorithm, and the method for
producing complementary parsers is only loosely constrained by that chosen
algorithm.
</dc:description>
 <dc:description>Comment: Ph.D. Thesis, Johns Hopkins University. Advisor: Eric Brill. 169
  pages</dc:description>
 <dc:date>2000-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006013</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An evaluation of Naive Bayesian anti-spam filtering</dc:title>
 <dc:creator>Androutsopoulos, Ion</dc:creator>
 <dc:creator>Koutsias, John</dc:creator>
 <dc:creator>Chandrinos, Konstantinos V.</dc:creator>
 <dc:creator>Paliouras, George</dc:creator>
 <dc:creator>Spyropoulos, Constantine D.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>H.4.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:subject>K.4.1</dc:subject>
 <dc:description>  It has recently been argued that a Naive Bayesian classifier can be used to
filter unsolicited bulk e-mail (&quot;spam&quot;). We conduct a thorough evaluation of
this proposal on a corpus that we make publicly available, contributing towards
standard benchmarks. At the same time we investigate the effect of
attribute-set size, training-corpus size, lemmatization, and stop-lists on the
filter's performance, issues that had not been previously explored. After
introducing appropriate cost-sensitive evaluation measures, we reach the
conclusion that additional safety nets are needed for the Naive Bayesian
anti-spam filter to be viable in practice.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2000-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006013</dc:identifier>
 <dc:identifier>Proceedings of the workshop on Machine Learning in the New
  Information Age, G. Potamias, V. Moustakis and M. van Someren (eds.), 11th
  European Conference on Machine Learning, Barcelona, Spain, pp. 9-17, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solaris System Resource Manager: All I Ever Wanted Was My Unfair
  Advantage (And Why You Can't Have It!)</dc:title>
 <dc:creator>Gunther, Neil J.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:subject>D.4.1</dc:subject>
 <dc:subject>D.4.8</dc:subject>
 <dc:description>  Traditional UNIX time-share schedulers attempt to be fair to all users by
employing a round-robin style algorithm for allocating CPU time. Unfortunately,
a loophole exists whereby the scheduler can be biased in favor of a greedy user
running many short CPU-time processes. This loophole is not a defect but an
intrinsic property of the round-robin scheduler that ensures responsiveness to
the short CPU demands associated with multiple interactive users. A new
generation of UNIX system resource management software constrains the scheduler
to be equitable to all users regardless of the number of processes each may be
running. This &quot;fair-share&quot; scheduling draws on the concept of pro rating
resource &quot;shares&quot; across users and groups and then dynamically adjusting CPU
usage to meet those share proportions. The simple notion of statically
allocating these shares, however, belies the potential consequences for
performance as measured by user response time and service level targets. We
demonstrate this point by modeling several simple share allocation scenarios
and analyzing the corresponding performance effects. A brief comparison of
commercial system resource management implementations from HP, IBM, and SUN is
also given.
</dc:description>
 <dc:description>Comment: 17 pages, Updated since the 25th Computer Measurement Group
  Conference, Reno NV, Dec.5-10, 1999</dc:description>
 <dc:date>2000-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006014</dc:identifier>
 <dc:identifier>Proc. CMG'99 Conf. p.194-205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UNIX Resource Managers: Capacity Planning and Resource Issues</dc:title>
 <dc:creator>Gunther, Neil J.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:subject>D.4.1</dc:subject>
 <dc:subject>D.4.8</dc:subject>
 <dc:description>  The latest implementations of commercial UNIX to offer mainframe style
capacity management on enterprise servers include: AIX Workload Manager (WLM),
HP-UX Process Resource Manager (PRM), Solaris Resource Manager (SRM), as well
as SGI and Compaq. The ability to manage server capacity is achieved by making
significant modifications to the standard UNIX operating system so that
processes are inherently tied to specific users. Those users, in turn, are
granted only a certain fraction of system resources. Resource usage is
monitored and compared with each users grant to ensure that the assigned
entitlement constraints are met. In this paper, we begin by clearing up some of
the confusion that has surrounded the motivation and the terminology behind the
new technology. The common theme across each of the commercial implementations
is the introduction of the fair-share scheduler. After reviewing some potential
performance pitfalls, we present capacity planning guidelines for migrating to
automated UNIX resource management.
</dc:description>
 <dc:description>Comment: 12 pages. Fixed formatting problem. To be presented at the SAGE-AU
  Conference, Bond University, Gold Coast, Australia, July 7, 2000</dc:description>
 <dc:date>2000-06-08</dc:date>
 <dc:date>2000-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The X-Files: Investigating Alien Performance in a Thin-client World</dc:title>
 <dc:creator>Gunther, Neil J.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:subject>D.4.8</dc:subject>
 <dc:subject>D.4.9</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>I.6.8</dc:subject>
 <dc:description>  Many scientific applications use the X11 window environment; an open source
windows GUI standard employing a client/server architecture. X11 promotes:
distributed computing, thin-client functionality, cheap desktop displays,
compatibility with heterogeneous servers, remote services and administration,
and greater maturity than newer web technologies. This paper details the
author's investigations into close encounters with alien performance in
X11-based seismic applications running on a 200-node cluster, backed by 2 TB of
mass storage. End-users cited two significant UFOs (Unidentified Faulty
Operations) i) long application launch times and ii) poor interactive response
times. The paper is divided into three major sections describing Close
Encounters of the 1st Kind: citings of UFO experiences, the 2nd Kind: recording
evidence of a UFO, and the 3rd Kind: contact and analysis. UFOs do exist and
this investigation presents a real case study for evaluating workload analysis
and other diagnostic tools.
</dc:description>
 <dc:description>Comment: 13 pages; Invited Lecture at the High Performance Computing
  Conference, University of Tromso, Norway, June 27-30, 1999</dc:description>
 <dc:date>2000-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006016</dc:identifier>
 <dc:identifier>Proc. Hiper'99 Vol.1, p.156</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Turning Speech Into Scripts</dc:title>
 <dc:creator>Rayner, Manny</dc:creator>
 <dc:creator>Hockey, Beth Ann</dc:creator>
 <dc:creator>James, Frankie</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We describe an architecture for implementing spoken natural language dialogue
interfaces to semi-autonomous systems, in which the central idea is to
transform the input speech signal through successive levels of representation
corresponding roughly to linguistic knowledge, dialogue knowledge, and domain
knowledge. The final representation is an executable program in a simple
scripting language equivalent to a subset of Cshell. At each stage of the
translation process, an input is transformed into an output, producing as a
byproduct a &quot;meta-output&quot; which describes the nature of the transformation
performed. We show how consistent use of the output/meta-output distinction
permits a simple and perspicuous treatment of apparently diverse topics
including resolution of pronouns, correction of user misconceptions, and
optimization of scripts. The methods described have been concretely realized in
a prototype speech interface to a simulation of the Personal Satellite
Assistant.
</dc:description>
 <dc:description>Comment: Working notes from AAAI Spring Symposium</dc:description>
 <dc:date>2000-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006017</dc:identifier>
 <dc:identifier>AAAI Spring Symposium on Natural Dialogues with Practical Robotic
  Devices, March 20-22, 2000. Stanford, CA</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006018</identifier>
 <datestamp>2008-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accuracy, Coverage, and Speed: What Do They Mean to Users?</dc:title>
 <dc:creator>James, Frankie</dc:creator>
 <dc:creator>Rayner, Manny</dc:creator>
 <dc:creator>Hockey, Beth Ann</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Speech is becoming increasingly popular as an interface modality, especially
in hands- and eyes-busy situations where the use of a keyboard or mouse is
difficult. However, despite the fact that many have hailed speech as being
inherently usable (since everyone already knows how to talk), most users of
speech input are left feeling disappointed by the quality of the interaction.
Clearly, there is much work to be done on the design of usable spoken
interfaces. We believe that there are two major problems in the design of
speech interfaces, namely, (a) the people who are currently working on the
design of speech interfaces are, for the most part, not interface designers and
therefore do not have as much experience with usability issues as we in the CHI
community do, and (b) speech, as an interface modality, has vastly different
properties than other modalities, and therefore requires different usability
measures.
</dc:description>
 <dc:description>Comment: Position paper for CHI 2000 Workshop on Natural-Language Interaction</dc:description>
 <dc:date>2000-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Compact Architecture for Dialogue Management Based on Scripts and
  Meta-Outputs</dc:title>
 <dc:creator>Rayner, Manny</dc:creator>
 <dc:creator>Hockey, Beth Ann</dc:creator>
 <dc:creator>James, Frankie</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  We describe an architecture for spoken dialogue interfaces to semi-autonomous
systems that transforms speech signals through successive representations of
linguistic, dialogue, and domain knowledge. Each step produces an output, and a
meta-output describing the transformation, with an executable program in a
simple scripting language as the final result. The output/meta-output
distinction permits perspicuous treatment of diverse tasks such as resolving
pronouns, correcting user misconceptions, and optimizing scripts.
</dc:description>
 <dc:date>2000-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006019</dc:identifier>
 <dc:identifier>Language Technology Joint Conference ANLP-NAACL 2000. 29 April - 4
  May 2000, Seattle, WA</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparison of the XTAG and CLE Grammars for English</dc:title>
 <dc:creator>Hockey, Beth Ann</dc:creator>
 <dc:creator>Rayner, Manny</dc:creator>
 <dc:creator>James, Frankie</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  When people develop something intended as a large broad-coverage grammar,
they usually have a more specific goal in mind. Sometimes this goal is covering
a corpus; sometimes the developers have theoretical ideas they wish to
investigate; most often, work is driven by a combination of these two main
types of goal. What tends to happen after a while is that the community of
people working with the grammar starts thinking of some phenomena as
``central'', and makes serious efforts to deal with them; other phenomena are
labelled ``marginal'', and ignored. Before long, the distinction between
``central'' and ``marginal'' becomes so ingrained that it is automatic, and
people virtually stop thinking about the ``marginal'' phenomena. In practice,
the only way to bring the marginal things back into focus is to look at what
other people are doing and compare it with one's own work. In this paper, we
will take two large grammars, XTAG and the CLE, and examine each of them from
the other's point of view. We will find in both cases not only that important
things are missing, but that the perspective offered by the other grammar
suggests simple and practical ways of filling in the holes. It turns out that
there is a pleasing symmetry to the picture. XTAG has a very good treatment of
complement structure, which the CLE to some extent lacks; conversely, the CLE
offers a powerful and general account of adjuncts, which the XTAG grammar does
not fully duplicate. If we examine the way in which each grammar does the thing
it is good at, we find that the relevant methods are quite easy to port to the
other framework, and in fact only involve generalization and systematization of
existing mechanisms.
</dc:description>
 <dc:description>Comment: 5th International Workshop on Tree Adjoining Grammars and Related
  Formalisms. 25-27 May 2000, Paris, France</dc:description>
 <dc:date>2000-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compiling Language Models from a Linguistically Motivated Unification
  Grammar</dc:title>
 <dc:creator>Rayner, Manny</dc:creator>
 <dc:creator>Hockey, Beth Ann</dc:creator>
 <dc:creator>James, Frankie</dc:creator>
 <dc:creator>Bratt, Elizabeth O.</dc:creator>
 <dc:creator>Goldwater, Sharon</dc:creator>
 <dc:creator>Gawron, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Systems now exist which are able to compile unification grammars into
language models that can be included in a speech recognizer, but it is so far
unclear whether non-trivial linguistically principled grammars can be used for
this purpose. We describe a series of experiments which investigate the
question empirically, by incrementally constructing a grammar and discovering
what problems emerge when successively larger versions are compiled into finite
state graph representations and used as language models for a medium-vocabulary
recognition task.
</dc:description>
 <dc:description>Comment: To be published in COLING 2000</dc:description>
 <dc:date>2000-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multicast-based Architecture for IP Mobility: Simulation Analysis and
  Comparison with Basic Mobile IP</dc:title>
 <dc:creator>Helmy, Ahmed</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:description>  With the introduction of a newer generation of wireless devices and
technologies, the need for an efficient architecture for IP mobility is
becoming more apparent. Several architectures have been proposed to support IP
mobility. Most studies, however, show that current architectures, in general,
fall short from satisfying the performance requirements for wireless
applications, mainly audio. Other studies have shown performance improvement by
using multicast to reduce latency and packet loss during handoff. In this
study, we propose a multicast-based architecture to support IP mobility. We
evaluate our approach through simulation, and we compare it to mainstream
approaches for IP mobility, mainly, the Mobile IP protocol. Comparison is
performed according to the required performance criteria, such as smooth
handoff and efficient routing.
  Our simulation results show significant improvement for the proposed
architecture. On average, basic Mobile IP consumes almost twice as much network
bandwidth, and experiences more than twice as much end-to-end and handoff
delays, as does our proposed architecture. Furthermore, we propose an extension
to Mobile IP to support our architecture with minimal modification.
</dc:description>
 <dc:description>Comment: 14 pages, 14 pages (.pdf file)</dc:description>
 <dc:date>2000-06-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dialogue Act Modeling for Automatic Tagging and Recognition of
  Conversational Speech</dc:title>
 <dc:creator>Stolcke, A.</dc:creator>
 <dc:creator>Ries, K.</dc:creator>
 <dc:creator>Coccaro, N.</dc:creator>
 <dc:creator>Shriberg, E.</dc:creator>
 <dc:creator>Bates, R.</dc:creator>
 <dc:creator>Jurafsky, D.</dc:creator>
 <dc:creator>Taylor, P.</dc:creator>
 <dc:creator>Martin, R.</dc:creator>
 <dc:creator>Van Ess-Dykema, C.</dc:creator>
 <dc:creator>Meteer, M.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We describe a statistical approach for modeling dialogue acts in
conversational speech, i.e., speech-act-like units such as Statement, Question,
Backchannel, Agreement, Disagreement, and Apology. Our model detects and
predicts dialogue acts based on lexical, collocational, and prosodic cues, as
well as on the discourse coherence of the dialogue act sequence. The dialogue
model is based on treating the discourse structure of a conversation as a
hidden Markov model and the individual dialogue acts as observations emanating
from the model states. Constraints on the likely sequence of dialogue acts are
modeled via a dialogue act n-gram. The statistical dialogue grammar is combined
with word n-grams, decision trees, and neural networks modeling the
idiosyncratic lexical and prosodic manifestations of each dialogue act. We
develop a probabilistic integration of speech recognition with dialogue
modeling, to improve both speech recognition and dialogue act classification
accuracy. Models are trained and evaluated using a large hand-labeled database
of 1,155 conversations from the Switchboard corpus of spontaneous
human-to-human telephone speech. We achieved good dialogue act labeling
accuracy (65% based on errorful, automatically recognized words and prosody,
and 71% based on word transcripts, compared to a chance baseline accuracy of
35% and human accuracy of 84%) and a small reduction in word recognition error.
</dc:description>
 <dc:description>Comment: 35 pages, 5 figures. Changes in copy editing (note title spelling
  changed)</dc:description>
 <dc:date>2000-06-11</dc:date>
 <dc:date>2000-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006023</dc:identifier>
 <dc:identifier>Computational Linguistics 26(3), 339-373, September 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Prosody Aid the Automatic Classification of Dialog Acts in
  Conversational Speech?</dc:title>
 <dc:creator>Shriberg, E.</dc:creator>
 <dc:creator>Bates, R.</dc:creator>
 <dc:creator>Stolcke, A.</dc:creator>
 <dc:creator>Taylor, P.</dc:creator>
 <dc:creator>Jurafsky, D.</dc:creator>
 <dc:creator>Ries, K.</dc:creator>
 <dc:creator>Coccaro, N.</dc:creator>
 <dc:creator>Martin, R.</dc:creator>
 <dc:creator>Meteer, M.</dc:creator>
 <dc:creator>Van Ess-Dykema, C.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Identifying whether an utterance is a statement, question, greeting, and so
forth is integral to effective automatic understanding of natural dialog.
Little is known, however, about how such dialog acts (DAs) can be automatically
classified in truly natural conversation. This study asks whether current
approaches, which use mainly word information, could be improved by adding
prosodic information. The study is based on more than 1000 conversations from
the Switchboard corpus. DAs were hand-annotated, and prosodic features
(duration, pause, F0, energy, and speaking rate) were automatically extracted
for each DA. In training, decision trees based on these features were inferred;
trees were then applied to unseen test data to evaluate performance.
Performance was evaluated for prosody models alone, and after combining the
prosody models with word information -- either from true words or from the
output of an automatic speech recognizer. For an overall classification task,
as well as three subtasks, prosody made significant contributions to
classification. Feature-specific analyses further revealed that although
canonical features (such as F0 for questions) were important, less obvious
features could compensate if canonical features were removed. Finally, in each
task, integrating the prosodic model with a DA-specific statistical language
model improved performance over that of the language model alone, especially
for the case of recognized words. Results suggest that DAs are redundantly
marked in natural conversation, and that a variety of automatically extractable
prosodic features could aid dialog processing in speech applications.
</dc:description>
 <dc:description>Comment: 55 pages, 10 figures</dc:description>
 <dc:date>2000-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006024</dc:identifier>
 <dc:identifier>Language and Speech 41(3-4), 439-487, 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropy-based Pruning of Backoff Language Models</dc:title>
 <dc:creator>Stolcke, A.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  A criterion for pruning parameters from N-gram backoff language models is
developed, based on the relative entropy between the original and the pruned
model. It is shown that the relative entropy resulting from pruning a single
N-gram can be computed exactly and efficiently for backoff models. The relative
entropy measure can be expressed as a relative change in training set
perplexity. This leads to a simple pruning criterion whereby all N-grams that
change perplexity by less than a threshold are removed from the model.
Experiments show that a production-quality Hub4 LM can be reduced to 26% its
original size without increasing recognition error. We also compare the
approach to a heuristic pruning criterion by Seymore and Rosenfeld (1996), and
show that their approach can be interpreted as an approximation to the relative
entropy criterion. Experimentally, both approaches select similar sets of
N-grams (about 85% overlap), with the exact relative entropy criterion giving
marginally better performance.
</dc:description>
 <dc:description>Comment: 5 pages. Typos in published version fixed</dc:description>
 <dc:date>2000-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006025</dc:identifier>
 <dc:identifier>Proceedings DARPA Broadcast News Transcription and Understanding
  Workshop, pp. 270-274, Lansdowne, VA, 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Correction of Dispersion Error in 2D Waveguide Meshes</dc:title>
 <dc:creator>Fontana, Federico</dc:creator>
 <dc:creator>Rocchesso, Davide</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:description>  An elastic ideal 2D propagation medium, i.e., a membrane, can be simulated by
models discretizing the wave equation on the time-space grid (finite difference
methods), or locally discretizing the solution of the wave equation (waveguide
meshes). The two approaches provide equivalent computational structures, and
introduce numerical dispersion that induces a misalignment of the modes from
their theoretical positions. Prior literature shows that dispersion can be
arbitrarily reduced by oversizing and oversampling the mesh, or by adpting
offline warping techniques. In this paper we propose to reduce numerical
dispersion by embedding warping elements, i.e., properly tuned allpass filters,
in the structure. The resulting model exhibits a significant reduction in
dispersion, and requires less computational resources than a regular mesh
structure having comparable accuracy.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures, to appear in the Proceedings of the International
  Computer Music Conference, 2000. Corrected first reference</dc:description>
 <dc:date>2000-06-12</dc:date>
 <dc:date>2000-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verbal Interactions in Virtual Worlds</dc:title>
 <dc:creator>Nugues, Pierre</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We first discuss respective advantages of language interaction in virtual
worlds and of using 3D images in dialogue systems. Then, we describe an example
of a verbal interaction system in virtual reality: Ulysse. Ulysse is a
conversational agent that helps a user navigate in virtual worlds. It has been
designed to be embedded in the representation of a participant of a virtual
conference and it responds positively to motion orders. Ulysse navigates the
user's viewpoint on his/her behalf in the virtual world. On tests we carried
out, we discovered that users, novices as well as experienced ones have
difficulties moving in a 3D environment. Agents such as Ulysse enable a user to
carry out navigation motions that would have been impossible with classical
interaction devices. From the whole Ulysse system, we have stripped off a
skeleton architecture that we have ported to VRML, Java, and Prolog. We hope
this skeleton helps the design of language applications in virtual worlds.
</dc:description>
 <dc:description>Comment: Position paper for CHI 2000 Workshop on Natural-Language Interaction,
  The Hague, 22 figures</dc:description>
 <dc:date>2000-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trainable Methods for Surface Natural Language Generation</dc:title>
 <dc:creator>Ratnaparkhi, Adwait</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  We present three systems for surface natural language generation that are
trainable from annotated corpora. The first two systems, called NLG1 and NLG2,
require a corpus marked only with domain-specific semantic attributes, while
the last system, called NLG3, requires a corpus marked with both semantic
attributes and syntactic dependency information. All systems attempt to produce
a grammatical natural language phrase from a domain-specific semantic
representation. NLG1 serves a baseline system and uses phrase frequencies to
generate a whole phrase in one step, while NLG2 and NLG3 use maximum entropy
probability models to individually generate each word in the phrase. The
systems NLG2 and NLG3 learn to determine both the word choice and the word
order of the phrase. We present experiments in which we generate phrases to
describe flights in the air travel domain.
</dc:description>
 <dc:description>Comment: LaTeX, 8 pages</dc:description>
 <dc:date>2000-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006028</dc:identifier>
 <dc:identifier>Proceedings of the 1st Meeting of the North American Chapter of
  the Association for Computational Linguistics (NAACL 2000). Pages 194--201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Systematic Performance Evaluation of Multipoint Protocols</dc:title>
 <dc:creator>Helmy, Ahmed</dc:creator>
 <dc:creator>Gupta, Sandeep</dc:creator>
 <dc:creator>Estrin, Deborah</dc:creator>
 <dc:creator>Cerpa, Alberto</dc:creator>
 <dc:creator>Yu, Yan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:subject>C.2.0</dc:subject>
 <dc:description>  The advent of multipoint (multicast-based) applications and the growth and
complexity of the Internet has complicated network protocol design and
evaluation.
  In this paper, we present a method for automatic synthesis of worst and best
case scenarios for multipoint protocol performance evaluation.
  Our method uses a fault-oriented test generation (FOTG) algorithm for
searching the protocol and system state space to synthesize these scenarios.
The algorithm is based on a global finite state machine (FSM) model. We extend
the algorithm with timing semantics to handle end-to-end delays and address
performance criteria. We introduce the notion of a virtual LAN to represent
delays of the underlying multicast distribution tree.
  As a case study, we use our method to evaluate variants of the timer
suppression mechanism, used in various multipoint protocols, with respect to
two performance criteria: overhead of response messages and response time.
Simulation results for reliable multicast protocols show that our method
provides a scalable way for synthesizing worst-case scenarios automatically. We
expect our method to serve as a model for applying systematic scenario
generation to other multipoint protocols.
</dc:description>
 <dc:description>Comment: 23 pages, 12 figures</dc:description>
 <dc:date>2000-06-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiagent Control of Self-reconfigurable Robots</dc:title>
 <dc:creator>Bojinov, Hristo</dc:creator>
 <dc:creator>Casal, Arancha</dc:creator>
 <dc:creator>Hogg, Tad</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:description>  We demonstrate how multiagent systems provide useful control techniques for
modular self-reconfigurable (metamorphic) robots. Such robots consist of many
modules that can move relative to each other, thereby changing the overall
shape of the robot to suit different tasks. Multiagent control is particularly
well-suited for tasks involving uncertain and changing environments. We
illustrate this approach through simulation experiments of Proteo, a
metamorphic robot system currently under development.
</dc:description>
 <dc:description>Comment: 15 pages, 10 color figures, including low-resolution photos of
  prototype hardware</dc:description>
 <dc:date>2000-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006030</dc:identifier>
 <dc:identifier>Artificial Intelligence 142:99-120 (2002)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verifying Termination of General Logic Programs with Concrete Queries</dc:title>
 <dc:creator>Shen, Yi-Dong</dc:creator>
 <dc:creator>Yuan, Li-Yan</dc:creator>
 <dc:creator>You, Jia-Huai</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  We introduce a method of verifying termination of logic programs with respect
to concrete queries (instead of abstract query patterns). A necessary and
sufficient condition is established and an algorithm for automatic verification
is developed. In contrast to existing query pattern-based approaches, our
method has the following features: (1) It applies to all general logic programs
with non-floundering queries. (2) It is very easy to automate because it does
not need to search for a level mapping or a model, nor does it need to compute
an interargument relation based on additional mode or type information. (3) It
bridges termination analysis with loop checking, the two problems that have
been studied separately in the past despite their close technical relation with
each other.
</dc:description>
 <dc:description>Comment: 28 pages, 8 figures</dc:description>
 <dc:date>2000-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation of English and non-English Language Use on the WWW</dc:title>
 <dc:creator>Grefenstette, Gregory</dc:creator>
 <dc:creator>Nioche, Julien</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - General Literature</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>J.5</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:subject>H.5.3</dc:subject>
 <dc:description>  The World Wide Web has grown so big, in such an anarchic fashion, that it is
difficult to describe. One of the evident intrinsic characteristics of the
World Wide Web is its multilinguality. Here, we present a technique for
estimating the size of a language-specific corpus given the frequency of
commonly occurring words in the corpus. We apply this technique to estimating
the number of words available through Web browsers for given languages.
Comparing data from 1996 to data from 1999 and 2000, we calculate the growth of
a number of European languages on the Web. As expected, non-English languages
are growing at a faster pace than English, though the position of English is
still dominant.
</dc:description>
 <dc:date>2000-06-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006032</dc:identifier>
 <dc:identifier>Proceedings of RIAO'2000, &quot;Content-Based Multimedia Information
  Access&quot;, Paris, April 12-14,2000, pp. 237-246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006033</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verifying Termination and Error-Freedom of Logic Programs with block
  Declarations</dc:title>
 <dc:creator>Smaus, Jan-Georg</dc:creator>
 <dc:creator>Hill, Patricia M.</dc:creator>
 <dc:creator>King, Andy</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:description>  We present verification methods for logic programs with delay declarations.
The verified properties are termination and freedom from errors related to
built-ins. Concerning termination, we present two approaches. The first
approach tries to eliminate the well-known problem of speculative output
bindings. The second approach is based on identifying the predicates for which
the textual position of an atom using this predicate is irrelevant with respect
to termination. Three features are distinctive of this work: it allows for
predicates to be used in several modes; it shows that block declarations, which
are a very simple delay construct, are sufficient to ensure the desired
properties; it takes the selection rule into account, assuming it to be as in
most Prolog implementations. The methods can be used to verify existing
programs and assist in writing new programs.
</dc:description>
 <dc:description>Comment: to be published in Theory and Practice of Logic Programming, 40
  pages, 10 figures</dc:description>
 <dc:date>2000-06-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Type Classes and Constraint Handling Rules</dc:title>
 <dc:creator>Glynn, Kevin</dc:creator>
 <dc:creator>Sulzmann, Martin</dc:creator>
 <dc:creator>Stuckey, Peter J.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  Type classes are an elegant extension to traditional, Hindley-Milner based
typing systems. They are used in modern, typed languages such as Haskell to
support controlled overloading of symbols. Haskell 98 supports only
single-parameter and constructor type classes. Other extensions such as
multi-parameter type classes are highly desired but are still not officially
supported by Haskell. Subtle issues arise with extensions, which may lead to a
loss of feasible type inference or ambiguous programs. A proper logical basis
for type class systems seems to be missing. Such a basis would allow extensions
to be characterised and studied rigorously. We propose to employ Constraint
Handling Rules as a tool to study and develop type class systems in a uniform
way.
</dc:description>
 <dc:description>Comment: 14 pages, Workshop on Rule-Based Constraint Reasoning and Programming
  (http://www.informatik.uni-muenchen.de/~fruehwir/cl2000r.html)</dc:description>
 <dc:date>2000-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006035</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Development of the Intersection of a Plane with a Polytope</dc:title>
 <dc:creator>O'Rourke, Joseph</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Define a ``slice'' curve as the intersection of a plane with the surface of a
polytope, i.e., a convex polyhedron in three dimensions. We prove that a slice
curve develops on a plane without self-intersection. The key tool used is a
generalization of Cauchy's arm lemma to permit nonconvex ``openings'' of a
planar convex chain.
</dc:description>
 <dc:description>Comment: 11 pages, 8 figures. Earlier version replaced after I discovered
  Schur's 1921 theorem, whose proof can be followed to establish the key
  generalization of Cauchy's arm lemma, my Theorem 1. Paper revised
  accordingly. New (2006) version corrects two errors in the proofs found by
  Raghavan Dhandapani</dc:description>
 <dc:date>2000-06-26</dc:date>
 <dc:date>2006-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prosody-Based Automatic Segmentation of Speech into Sentences and Topics</dc:title>
 <dc:creator>Shriberg, E.</dc:creator>
 <dc:creator>Stolcke, A.</dc:creator>
 <dc:creator>Hakkani-Tur, D.</dc:creator>
 <dc:creator>Tur, G.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  A crucial step in processing speech audio data for information extraction,
topic detection, or browsing/playback is to segment the input into sentence and
topic units. Speech segmentation is challenging, since the cues typically
present for segmenting text (headers, paragraphs, punctuation) are absent in
spoken language. We investigate the use of prosody (information gleaned from
the timing and melody of speech) for these tasks. Using decision tree and
hidden Markov modeling techniques, we combine prosodic cues with word-based
approaches, and evaluate performance on two speech corpora, Broadcast News and
Switchboard. Results show that the prosodic model alone performs on par with,
or better than, word-based statistical language models -- for both true and
automatically recognized words in news speech. The prosodic model achieves
comparable performance with significantly less training data, and requires no
hand-labeling of prosodic events. Across tasks and corpora, we obtain a
significant improvement over word-only models using a probabilistic combination
of prosodic and lexical information. Inspection reveals that the prosodic
models capture language-independent boundary indicators described in the
literature. Finally, cue usage is task and corpus dependent. For example, pause
and pitch features are highly informative for segmenting news speech, whereas
pause, duration and word-based cues dominate for natural conversation.
</dc:description>
 <dc:description>Comment: 30 pages, 9 figures. To appear in Speech Communication 32(1-2),
  Special Issue on Accessing Information in Spoken Audio, September 2000</dc:description>
 <dc:date>2000-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006036</dc:identifier>
 <dc:identifier>Speech Communication 32(1-2), 127-154, September 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Decision-Theoretic Approach to Resource Allocation in Wireless
  Multimedia Networks</dc:title>
 <dc:creator>Haas, Zygmunt</dc:creator>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:creator>Li, Li</dc:creator>
 <dc:creator>Wicker, Stephen B.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:description>  The allocation of scarce spectral resources to support as many user
applications as possible while maintaining reasonable quality of service is a
fundamental problem in wireless communication. We argue that the problem is
best formulated in terms of decision theory. We propose a scheme that takes
decision-theoretic concerns (like preferences) into account and discuss the
difficulties and subtleties involved in applying standard techniques from the
theory of Markov Decision Processes (MDPs) in constructing an algorithm that is
decision-theoretically optimal. As an example of the proposed framework, we
construct such an algorithm under some simplifying assumptions. Additionally,
we present analysis and simulation results that show that our algorithm meets
its design goals. Finally, we investigate how far from optimal one well-known
heuristic is. The main contribution of our results is in providing insight and
guidance for the design of near-optimal admission-control policies.
</dc:description>
 <dc:description>Comment: To appear, Dial M for Mobility, 2000</dc:description>
 <dc:date>2000-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation and Exactness in Finite State Optimality Theory</dc:title>
 <dc:creator>Gerdemann, Dale</dc:creator>
 <dc:creator>van Noord, Gertjan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Previous work (Frank and Satta 1998; Karttunen, 1998) has shown that
Optimality Theory with gradient constraints generally is not finite state. A
new finite-state treatment of gradient constraints is presented which improves
upon the approximation of Karttunen (1998). The method turns out to be exact,
and very compact, for the syllabification analysis of Prince and Smolensky
(1993).
</dc:description>
 <dc:description>Comment: 10 pages, 1 figure, Finite-State Phonology : SIGPHON 2000, Fifth
  Meeting of the ACL Special Interest Group in Computational Phonology, COLING
  2000</dc:description>
 <dc:date>2000-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006039</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Orthogonal Least Squares Algorithm for the Approximation of a Map and
  its Derivatives with a RBF Network</dc:title>
 <dc:creator>Drioli, Carlo</dc:creator>
 <dc:creator>Rocchesso, Davide</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Radial Basis Function Networks (RBFNs) are used primarily to solve
curve-fitting problems and for non-linear system modeling. Several algorithms
are known for the approximation of a non-linear curve from a sparse data set by
means of RBFNs. However, there are no procedures that permit to define
constrains on the derivatives of the curve. In this paper, the Orthogonal Least
Squares algorithm for the identification of RBFNs is modified to provide the
approximation of a non-linear 1-in 1-out map along with its derivatives, given
a set of training data. The interest on the derivatives of non-linear functions
concerns many identification and control tasks where the study of system
stability and robustness is addressed. The effectiveness of the proposed
algorithm is demonstrated by a study on the stability of a single loop feedback
system.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures, submitted to IEEE Trans. on Systems, Man, and
  Cybernetics</dc:description>
 <dc:date>2000-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correlation over Decomposed Signals: A Non-Linear Approach to Fast and
  Effective Sequences Comparison</dc:title>
 <dc:creator>Costa, Luciano da Fontoura</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Quantitative Biology</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  A novel non-linear approach to fast and effective comparison of sequences is
presented, compared to the traditional cross-correlation operator, and
illustrated with respect to DNA sequences.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure</dc:description>
 <dc:date>2000-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using a Diathesis Model for Semantic Parsing</dc:title>
 <dc:creator>Atserias, Jordi</dc:creator>
 <dc:creator>Castellon, Irene</dc:creator>
 <dc:creator>Civit, Montse</dc:creator>
 <dc:creator>Rigau, German</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:description>  This paper presents a semantic parsing approach for unrestricted texts.
Semantic parsing is one of the major bottlenecks of Natural Language
Understanding (NLU) systems and usually requires building expensive resources
not easily portable to other domains. Our approach obtains a case-role
analysis, in which the semantic roles of the verb are identified. In order to
cover all the possible syntactic realisations of a verb, our system combines
their argument structure with a set of general semantic labelled diatheses
models. Combining them, the system builds a set of syntactic-semantic patterns
with their own role-case representation. Once the patterns are build, we use an
approximate tree pattern-matching algorithm to identify the most reliable
pattern for a sentence. The pattern matching is performed between the
syntactic-semantic patterns and the feature-structure tree representing the
morphological, syntactical and semantic information of the analysed sentence.
For sentences assigned to the correct model, the semantic parsing system we are
presenting identifies correctly more than 73% of possible semantic case-roles.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2000-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006041</dc:identifier>
 <dc:identifier>Proceedins of VEXTAL.1999 pg 385-392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Parsing based on Verbal Subcategorization</dc:title>
 <dc:creator>Atserias, Jordi</dc:creator>
 <dc:creator>Castellon, Irene</dc:creator>
 <dc:creator>Civit, Montse</dc:creator>
 <dc:creator>Rigau, German</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:description>  The aim of this work is to explore new methodologies on Semantic Parsing for
unrestricted texts. Our approach follows the current trends in Information
Extraction (IE) and is based on the application of a verbal subcategorization
lexicon (LEXPIR) by means of complex pattern recognition techniques. LEXPIR is
framed on the theoretical model of the verbal subcategorization developed in
the Pirapides project.
</dc:description>
 <dc:description>Comment: 12 pages, extended version of the paper. Spanish version of the paper
  also available from authors home page</dc:description>
 <dc:date>2000-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006042</dc:identifier>
 <dc:identifier>Conference on Intelligence text Processing and Computational
  Linguistics, CICLing 2000. pg 330-340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constraint compiling into rules formalism constraint compiling into
  rules formalism for dynamic CSPs computing</dc:title>
 <dc:creator>Piechowiak, S.</dc:creator>
 <dc:creator>Rodriguez, J.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  In this paper we present a rule based formalism for filtering variables
domains of constraints. This formalism is well adapted for solving dynamic CSP.
We take diagnosis as an instance problem to illustrate the use of these rules.
A diagnosis problem is seen like finding all the minimal sets of constraints to
be relaxed in the constraint network that models the device to be diagnosed
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2000-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006044</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite-State Non-Concatenative Morphotactics</dc:title>
 <dc:creator>Beesley, Kenneth R.</dc:creator>
 <dc:creator>Karttunen, Lauri</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>A0</dc:subject>
 <dc:subject>F1.1</dc:subject>
 <dc:subject>J5</dc:subject>
 <dc:description>  Finite-state morphology in the general tradition of the Two-Level and Xerox
implementations has proved very successful in the production of robust
morphological analyzer-generators, including many large-scale commercial
systems. However, it has long been recognized that these implementations have
serious limitations in handling non-concatenative phenomena. We describe a new
technique for constructing finite-state transducers that involves reapplying
the regular-expression compiler to its own output. Implemented in an algorithm
called compile-replace, this technique has proved useful for handling
non-concatenative phenomena; and we demonstrate it on Malay full-stem
reduplication and Arabic stem interdigitation.
</dc:description>
 <dc:description>Comment: SIGPHON-2000, Proceedings of the Fifth Workshop of the ACL Special
  Interest Group in Computational Phonology, p. 1-12. Aug. 6, 2000. Luxembourg</dc:description>
 <dc:date>2000-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security Policy Consistency</dc:title>
 <dc:creator>Ribeiro, Carlos</dc:creator>
 <dc:creator>Zuquete, Andre</dc:creator>
 <dc:creator>Ferreira, Paulo</dc:creator>
 <dc:creator>Guedes, Paulo</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:description>  With the advent of wide security platforms able to express simultaneously all
the policies comprising an organization's global security policy, the problem
of inconsistencies within security policies become harder and more relevant.
  We have defined a tool based on the CHR language which is able to detect
several types of inconsistencies within and between security policies and other
specifications, namely workflow specifications.
  Although the problem of security conflicts has been addressed by several
authors, to our knowledge none has addressed the general problem of security
inconsistencies, on its several definitions and target specifications.
</dc:description>
 <dc:description>Comment: To appear in the first CL2000 workshop on Rule-Based Constraint
  Reasoning and Programming</dc:description>
 <dc:date>2000-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006046</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3-Coloring in Time O(1.3289^n)</dc:title>
 <dc:creator>Beigel, Richard</dc:creator>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We consider worst case time bounds for NP-complete problems including 3-SAT,
3-coloring, 3-edge-coloring, and 3-list-coloring. Our algorithms are based on a
constraint satisfaction (CSP) formulation of these problems. 3-SAT is
equivalent to (2,3)-CSP while the other problems above are special cases of
(3,2)-CSP; there is also a natural duality transformation from (a,b)-CSP to
(b,a)-CSP. We give a fast algorithm for (3,2)-CSP and use it to improve the
time bounds for solving the other problems listed above. Our techniques involve
a mixture of Davis-Putnam-style backtracking with more sophisticated matching
and network flow based ideas.
</dc:description>
 <dc:description>Comment: 31 pages, 22 figures. An earlier version of this paper was presented
  at the 36th IEEE Symp. Foundations of Comp. Sci., 1995, and appears as ECCC
  TR 95-033</dc:description>
 <dc:date>2000-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006046</dc:identifier>
 <dc:identifier>J. Algorithms 54:2 (2005) 168-204</dc:identifier>
 <dc:identifier>doi:10.1016/j.jalgor.2004.06.008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0006047</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric Morphology of Granular Materials</dc:title>
 <dc:creator>Schlei, B. R.</dc:creator>
 <dc:creator>Prasad, L.</dc:creator>
 <dc:creator>Skourikhine, A. N.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.4.6</dc:subject>
 <dc:subject>I.4.10</dc:subject>
 <dc:description>  We present a new method to transform the spectral pixel information of a
micrograph into an affine geometric description, which allows us to analyze the
morphology of granular materials. We use spectral and pulse-coupled neural
network based segmentation techniques to generate blobs, and a newly developed
algorithm to extract dilated contours. A constrained Delaunay tesselation of
the contour points results in a triangular mesh. This mesh is the basic
ingredient of the Chodal Axis Transform, which provides a morphological
decomposition of shapes. Such decomposition allows for grain separation and the
efficient computation of the statistical features of granular materials.
</dc:description>
 <dc:description>Comment: 6 pages, 9 figures. For more information visit
  http://www.nis.lanl.gov/~bschlei/labvis/index.html</dc:description>
 <dc:date>2000-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0006047</dc:identifier>
 <dc:identifier>doi:10.1117/12.404821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constraint Exploration and Envelope of Simulation Trajectories</dc:title>
 <dc:creator>Teran, Oswaldo</dc:creator>
 <dc:creator>Edmonds, Bruce</dc:creator>
 <dc:creator>Wallis, Steve</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  The implicit theory that a simulation represents is precisely not in the
individual choices but rather in the 'envelope' of possible trajectories - what
is important is the shape of the whole envelope. Typically a huge amount of
computation is required when experimenting with factors bearing on the dynamics
of a simulation to tease out what affects the shape of this envelope. In this
paper we present a methodology aimed at systematically exploring this envelope.
We propose a method for searching for tendencies and proving their necessity
relative to a range of parameterisations of the model and agents' choices, and
to the logic of the simulation language. The exploration consists of a forward
chaining generation of the trajectories associated to and constrained by such a
range of parameterisations and choices. Additionally, we propose a
computational procedure that helps implement this exploration by translating a
Multi Agent System simulation into a constraint-based search over possible
trajectories by 'compiling' the simulation rules into a more specific form,
namely by partitioning the simulation rules using appropriate modularity in the
simulation. An example of this procedure is exhibited.
  Keywords: Constraint Search, Constraint Logic Programming, Proof, Emergence,
Tendencies
</dc:description>
 <dc:description>Comment: 15 pages, To be presented at the First Workshop on Rule-Based
  Constraint Reasoning and Programming at the First International Conference on
  Computational Logic, London, UK, 24th to 28th July, 2000</dc:description>
 <dc:date>2000-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interval Constraint Solving for Camera Control and Motion Planning</dc:title>
 <dc:creator>Benhamou, Frederic</dc:creator>
 <dc:creator>Goualard, Frederic</dc:creator>
 <dc:creator>Languenou, Eric</dc:creator>
 <dc:creator>Christie, Marc</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:description>  Many problems in robust control and motion planning can be reduced to either
find a sound approximation of the solution space determined by a set of
nonlinear inequalities, or to the ``guaranteed tuning problem'' as defined by
Jaulin and Walter, which amounts to finding a value for some tuning parameter
such that a set of inequalities be verified for all the possible values of some
perturbation vector. A classical approach to solve these problems, which
satisfies the strong soundness requirement, involves some quantifier
elimination procedure such as Collins' Cylindrical Algebraic Decomposition
symbolic method. Sound numerical methods using interval arithmetic and local
consistency enforcement to prune the search space are presented in this paper
as much faster alternatives for both soundly solving systems of nonlinear
inequalities, and addressing the guaranteed tuning problem whenever the
perturbation vector has dimension one. The use of these methods in camera
control is investigated, and experiments with the prototype of a declarative
modeller to express camera motion using a cinematic language are reported and
commented.
</dc:description>
 <dc:description>Comment: 35 pages, 13 figures, revised and extended version of a paper
  published in the proceedings of CP '00</dc:description>
 <dc:date>2000-07-03</dc:date>
 <dc:date>2003-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using compression to identify acronyms in text</dc:title>
 <dc:creator>Yeates, Stuart</dc:creator>
 <dc:creator>Bainbridge, David</dc:creator>
 <dc:creator>Witten, Ian H.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:description>  Text mining is about looking for patterns in natural language text, and may
be defined as the process of analyzing text to extract information from it for
particular purposes. In previous work, we claimed that compression is a key
technology for text mining, and backed this up with a study that showed how
particular kinds of lexical tokens---names, dates, locations, etc.---can be
identified and located in running text, using compression models to provide the
leverage necessary to distinguish different token types (Witten et al., 1999)
</dc:description>
 <dc:description>Comment: 10 pages. A short form published in DCC2000</dc:description>
 <dc:date>2000-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Brainstorm/J: a Java Framework for Intelligent Agents</dc:title>
 <dc:creator>Zunino, Alejandro</dc:creator>
 <dc:creator>Amandi, Analia</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  Despite the effort of many researchers in the area of multi-agent systems
(MAS) for designing and programming agents, a few years ago the research
community began to take into account that common features among different MAS
exists. Based on these common features, several tools have tackled the problem
of agent development on specific application domains or specific types of
agents. As a consequence, their scope is restricted to a subset of the huge
application domain of MAS. In this paper we propose a generic infrastructure
for programming agents whose name is Brainstorm/J. The infrastructure has been
implemented as an object oriented framework. As a consequence, our approach
supports a broader scope of MAS applications than previous efforts, being
flexible and reusable.
</dc:description>
 <dc:description>Comment: 15 pages. To be published in Proceedings of the Second Argentinian
  Symposium on Artificial Intelligence (ASAI'2000 - 29th JAIIO). September
  2000. Tandil, Buenos Aires, Argentina. See
  http://www.exa.unicen.edu.ar/~azunino</dc:description>
 <dc:date>2000-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Systematic Testing of Multicast Routing Protocols: Analysis of Forward
  and Backward Search Techniques</dc:title>
 <dc:creator>Helmy, Ahmed</dc:creator>
 <dc:creator>Estrin, Deborah</dc:creator>
 <dc:creator>Gupta, Sandeep</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>C.2.2, C.2.0</dc:subject>
 <dc:description>  In this paper, we present a new methodology for developing systematic and
automatic test generation algorithms for multipoint protocols. These algorithms
attempt to synthesize network topologies and sequences of events that stress
the protocol's correctness or performance. This problem can be viewed as a
domain-specific search problem that suffers from the state space explosion
problem. One goal of this work is to circumvent the state space explosion
problem utilizing knowledge of network and fault modeling, and multipoint
protocols. The two approaches investigated in this study are based on forward
and backward search techniques. We use an extended finite state machine (FSM)
model of the protocol. The first algorithm uses forward search to perform
reduced reachability analysis. Using domain-specific information for multicast
routing over LANs, the algorithm complexity is reduced from exponential to
polynomial in the number of routers. This approach, however, does not fully
automate topology synthesis. The second algorithm, the fault-oriented test
generation, uses backward search for topology synthesis and uses backtracking
to generate event sequences instead of searching forward from initial states.
Using these algorithms, we have conducted studies for correctness of the
multicast routing protocol PIM. We propose to extend these algorithms to study
end-to-end multipoint protocols using a virtual LAN that represents delays of
the underlying multicast distribution tree.
</dc:description>
 <dc:description>Comment: 26 pages, 20 figures</dc:description>
 <dc:date>2000-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DISCO: An object-oriented system for music composition and sound design</dc:title>
 <dc:creator>Kaper, Hans G.</dc:creator>
 <dc:creator>Tipei, Sever</dc:creator>
 <dc:creator>Wright, Jeff M.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:description>  This paper describes an object-oriented approach to music composition and
sound design. The approach unifies the processes of music making and instrument
building by using similar logic, objects, and procedures. The composition
modules use an abstract representation of musical data, which can be easily
mapped onto different synthesis languages or a traditionally notated score. An
abstract base class is used to derive classes on different time scales. Objects
can be related to act across time scales, as well as across an entire piece,
and relationships between similar objects can replicate traditional music
operations or introduce new ones. The DISCO (Digital Instrument for
Sonification and Composition) system is an open-ended work in progress.
</dc:description>
 <dc:description>Comment: 4 pages, no figures; to be published in Proc. Int'l Computer Music
  Conference 2000 (Berlin, August 2000)</dc:description>
 <dc:date>2000-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data sonification and sound visualization</dc:title>
 <dc:creator>Kaper, Hans G.</dc:creator>
 <dc:creator>Tipei, Sever</dc:creator>
 <dc:creator>Wiebel, Elizabeth</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:description>  This article describes a collaborative project between researchers in the
Mathematics and Computer Science Division at Argonne National Laboratory and
the Computer Music Project of the University of Illinois at Urbana-Champaign.
The project focuses on the use of sound for the exploration and analysis of
complex data sets in scientific computing. The article addresses digital sound
synthesis in the context of DIASS (Digital Instrument for Additive Sound
Synthesis) and sound visualization in a virtual-reality environment by means of
M4CAVE. It describes the procedures and preliminary results of some experiments
in scientific sonification and sound visualization.
</dc:description>
 <dc:description>Comment: 25 pages, 5 figures, 3 tables; preprint of the published paper
  (differing in details)</dc:description>
 <dc:date>2000-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007007</dc:identifier>
 <dc:identifier>Computing in Science and Engineering, Vol. 1 No. 4, July-August
  1999, pp. 48-58</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compiling Language Definitions: The ASF+SDF Compiler</dc:title>
 <dc:creator>Brand, M. G. J. van den</dc:creator>
 <dc:creator>Heering, J.</dc:creator>
 <dc:creator>Klint, P.</dc:creator>
 <dc:creator>Olivier, P. A.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:subject>F.4.2</dc:subject>
 <dc:description>  The ASF+SDF Meta-Environment is an interactive language development
environment whose main application areas are definition of domain-specific
languages, generation of program analysis and transformation tools, production
of software renovation tools, and general specification and prototyping. It
uses conditional rewrite rules to define the dynamic semantics and other
tool-oriented aspects of languages, so the effectiveness of the generated tools
is critically dependent on the quality of the rewrite rule implementation.
  The ASF+SDF rewrite rule compiler generates C code, thus taking advantage of
C's portability and the sophisticated optimization capabilities of current C
compilers as well as avoiding potential abstract machine interface bottlenecks.
It can handle large (10 000+ rule) language definitions and uses an efficient
run-time storage scheme capable of handling large (1 000 000+ node) terms. Term
storage uses maximal subterm sharing (hash-consing), which turns out to be more
effective in the case of ASF+SDF than in Lisp or SML. Extensive benchmarking
has shown the time and space performance of the generated code to be as good as
or better than that of the best current rewrite rule and functional language
compilers.
</dc:description>
 <dc:description>Comment: 36 pages, 5 figures</dc:description>
 <dc:date>2000-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007008</dc:identifier>
 <dc:identifier>ACM Transactions on Programming Languages and Systems 24 4 (July
  2002) 334-368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental construction of minimal acyclic finite-state automata</dc:title>
 <dc:creator>Daciuk, Jan</dc:creator>
 <dc:creator>Mihov, Stoyan</dc:creator>
 <dc:creator>Watson, Bruce</dc:creator>
 <dc:creator>Watson, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  In this paper, we describe a new method for constructing minimal,
deterministic, acyclic finite-state automata from a set of strings. Traditional
methods consist of two phases: the first to construct a trie, the second one to
minimize it. Our approach is to construct a minimal automaton in a single phase
by adding new strings one by one and minimizing the resulting automaton
on-the-fly. We present a general algorithm as well as a specialization that
relies upon the lexicographical ordering of the input strings.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures</dc:description>
 <dc:date>2000-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007009</dc:identifier>
 <dc:identifier>Computational Linguistics, Vol. 26, Number 1, March 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting Applied to Word Sense Disambiguation</dc:title>
 <dc:creator>Escudero, Gerard</dc:creator>
 <dc:creator>Marquez, Lluis</dc:creator>
 <dc:creator>Rigau, German</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  In this paper Schapire and Singer's AdaBoost.MH boosting algorithm is applied
to the Word Sense Disambiguation (WSD) problem. Initial experiments on a set of
15 selected polysemous words show that the boosting approach surpasses Naive
Bayes and Exemplar-based approaches, which represent state-of-the-art accuracy
on supervised WSD. In order to make boosting practical for a real learning
domain of thousands of words, several ways of accelerating the algorithm by
reducing the feature space are studied. The best variant, which we call
LazyBoosting, is tested on the largest sense-tagged corpus available containing
192,800 examples of the 191 most frequent and ambiguous English words. Again,
boosting compares favourably to the other benchmark algorithms.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2000-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007010</dc:identifier>
 <dc:identifier>Proceedings of the 11th European Conference on Machine Learning,
  ECML'2000 pp. 129-141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Naive Bayes and Exemplar-Based approaches to Word Sense Disambiguation
  Revisited</dc:title>
 <dc:creator>Escudero, Gerard</dc:creator>
 <dc:creator>Marquez, Lluis</dc:creator>
 <dc:creator>Rigau, German</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  This paper describes an experimental comparison between two standard
supervised learning methods, namely Naive Bayes and Exemplar-based
classification, on the Word Sense Disambiguation (WSD) problem. The aim of the
work is twofold. Firstly, it attempts to contribute to clarify some confusing
information about the comparison between both methods appearing in the related
literature. In doing so, several directions have been explored, including:
testing several modifications of the basic learning algorithms and varying the
feature space. Secondly, an improvement of both algorithms is proposed, in
order to deal with large attribute sets. This modification, which basically
consists in using only the positive information appearing in the examples,
allows to improve greatly the efficiency of the methods, with no loss in
accuracy. The experiments have been performed on the largest sense-tagged
corpus available containing the most frequent and ambiguous English words.
Results show that the Exemplar-based approach to WSD is generally superior to
the Bayesian approach, especially when a specific metric for dealing with
symbolic attributes is used.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2000-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007011</dc:identifier>
 <dc:identifier>Proceedings of the 14th European Conference on Artificial
  Intelligence, ECAI'2000 pp. 421-425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Learning-based Filters to Detect Rule-based Filtering Obsolescence</dc:title>
 <dc:creator>Wolinski, Francis</dc:creator>
 <dc:creator>Vichot, Frantz</dc:creator>
 <dc:creator>Stricker, Mathieu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  For years, Caisse des Depots et Consignations has produced information
filtering applications. To be operational, these applications require high
filtering performances which are achieved by using rule-based filters. With
this technique, an administrator has to tune a set of rules for each topic.
However, filters become obsolescent over time. The decrease of their
performances is due to diachronic polysemy of terms that involves a loss of
precision and to diachronic polymorphism of concepts that involves a loss of
recall.
  To help the administrator to maintain his filters, we have developed a method
which automatically detects filtering obsolescence. It consists in making a
learning-based control filter using a set of documents which have already been
categorised as relevant or not relevant by the rule-based filter. The idea is
to supervise this filter by processing a differential comparison of its
outcomes with those of the control one.
  This method has many advantages. It is simple to implement since the training
set used by the learning is supplied by the rule-based filter. Thus, both the
making and the use of the control filter are fully automatic. With automatic
detection of obsolescence, learning-based filtering finds a rich application
which offers interesting prospects.
</dc:description>
 <dc:description>Comment: 13 pages, 12 figures, Content-based Multimedia Information Access,
  RIAO 2000</dc:description>
 <dc:date>2000-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Constraint Handling Rules to HPSG</dc:title>
 <dc:creator>Penn, Gerald</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  Constraint Handling Rules (CHR) have provided a realistic solution to an
over-arching problem in many fields that deal with constraint logic
programming: how to combine recursive functions or relations with constraints
while avoiding non-termination problems. This paper focuses on some other
benefits that CHR, specifically their implementation in SICStus Prolog, have
provided to computational linguists working on grammar design tools. CHR rules
are applied by means of a subsumption check and this check is made only when
their variables are instantiated or bound. The former functionality is at best
difficult to simulate using more primitive coroutining statements such as
SICStus when/2, and the latter simply did not exist in any form before CHR.
  For the sake of providing a case study in how these can be applied to grammar
development, we consider the Attribute Logic Engine (ALE), a Prolog
preprocessor for logic programming with typed feature structures, and its
extension to a complete grammar development system for Head-driven Phrase
Structure Grammar (HPSG), a popular constraint-based linguistic theory that
uses typed feature structures. In this context, CHR can be used not only to
extend the constraint language of feature structure descriptions to include
relations in a declarative way, but also to provide support for constraints
with complex antecedents and constraints on the co-occurrence of feature values
that are necessary to interpret the type system of HPSG properly.
</dc:description>
 <dc:description>Comment: To appear, Proceedings of First Workshop on Rule-Based Constraint
  Reasoning and Programming, CL2000; 14 pages</dc:description>
 <dc:date>2000-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007014</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Sound Manifesto</dc:title>
 <dc:creator>O'Donnell, Michael J.</dc:creator>
 <dc:creator>Bisnovatyi, Ilia</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:description>  Computing practice today depends on visual output to drive almost all user
interaction. Other senses, such as audition, may be totally neglected, or used
tangentially, or used in highly restricted specialized ways. We have excellent
audio rendering through D-A conversion, but we lack rich general facilities for
modeling and manipulating sound comparable in quality and flexibility to
graphics. We need co-ordinated research in several disciplines to improve the
use of sound as an interactive information channel.
  Incremental and separate improvements in synthesis, analysis, speech
processing, audiology, acoustics, music, etc. will not alone produce the
radical progress that we seek in sonic practice. We also need to create a new
central topic of study in digital audio research. The new topic will assimilate
the contributions of different disciplines on a common foundation. The key
central concept that we lack is sound as a general-purpose information channel.
We must investigate the structure of this information channel, which is driven
by the co-operative development of auditory perception and physical sound
production. Particular audible encodings, such as speech and music, illuminate
sonic information by example, but they are no more sufficient for a
characterization than typography is sufficient for a characterization of visual
information.
</dc:description>
 <dc:description>Comment: To appear in the conference on Critical Technologies for the Future
  of Computing, part of SPIE's International Symposium on Optical Science and
  Technology, 30 July to 4 August 2000, San Diego, CA</dc:description>
 <dc:date>2000-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007014</dc:identifier>
 <dc:identifier>doi:10.1117/12.409214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Clocks for Transient Fault Repair</dc:title>
 <dc:creator>Herman, Ted</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>D.4.5</dc:subject>
 <dc:description>  Phase clocks are synchronization tools that implement a form of logical time
in distributed systems. For systems tolerating transient faults by self-repair
of damaged data, phase clocks can enable reasoning about the progress of
distributed repair procedures. This paper presents a phase clock algorithm
suited to the model of transient memory faults in asynchronous systems with
read/write registers. The algorithm is self-stabilizing and guarantees accuracy
of phase clocks within O(k) time following an initial state that is k-faulty.
Composition theorems show how the algorithm can be used for the timing of
distributed procedures that repair system outputs.
</dc:description>
 <dc:description>Comment: 22 pages, LaTeX</dc:description>
 <dc:date>2000-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two Steps Feature Selection and Neural Network Classification for the
  TREC-8 Routing</dc:title>
 <dc:creator>Stricker, Mathieu</dc:creator>
 <dc:creator>Vichot, Frantz</dc:creator>
 <dc:creator>Dreyfus, Gerard</dc:creator>
 <dc:creator>Wolinski, Francis</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>K.3.2</dc:subject>
 <dc:description>  For the TREC-8 routing, one specific filter is built for each topic. Each
filter is a classifier trained to recognize the documents that are relevant to
the topic. When presented with a document, each classifier estimates the
probability for the document to be relevant to the topic for which it has been
trained. Since the procedure for building a filter is topic-independent, the
system is fully automatic.
  By making use of a sample of documents that have previously been evaluated as
relevant or not relevant to a particular topic, a term selection is performed,
and a neural network is trained. Each document is represented by a vector of
frequencies of a list of selected terms. This list depends on the topic to be
filtered; it is constructed in two steps. The first step defines the
characteristic words used in the relevant documents of the corpus; the second
one chooses, among the previous list, the most discriminant ones. The length of
the vector is optimized automatically for each topic. At the end of the term
selection, a vector of typically 25 words is defined for the topic, so that
each document which has to be processed is represented by a vector of term
frequencies.
  This vector is subsequently input to a classifier that is trained from the
same sample. After training, the classifier estimates for each document of a
test set its probability of being relevant; for submission to TREC, the top
1000 documents are ranked in order of decreasing relevance.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, Eighth International Text REtrieval Conference
  (TREC-8)</dc:description>
 <dc:date>2000-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fuzzy data: XML may handle it</dc:title>
 <dc:creator>Schweiger, R.</dc:creator>
 <dc:creator>Hoelzer, S.</dc:creator>
 <dc:creator>Dudeck, J.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H3.2</dc:subject>
 <dc:description>  Data modeling is one of the most difficult tasks in application engineering.
The engineer must be aware of the use cases and the required application
services and at a certain point of time he has to fix the data model which
forms the base for the application services. However, once the data model has
been fixed it is difficult to consider changing needs. This might be a problem
in specific domains, which are as dynamic as the healthcare domain. With fuzzy
data we address all those data that are difficult to organize in a single
database. In this paper we discuss a gradual and pragmatic approach that uses
the XML technology to conquer more model flexibility. XML may provide the clue
between unstructured text data and structured database solutions and shift the
paradigm from &quot;organizing the data along a given model&quot; towards &quot;organizing the
data along user requirements&quot;.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures</dc:description>
 <dc:date>2000-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bootstrapping a Tagged Corpus through Combination of Existing
  Heterogeneous Taggers</dc:title>
 <dc:creator>Zavrel, Jakub</dc:creator>
 <dc:creator>Daelemans, Walter</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  This paper describes a new method, Combi-bootstrap, to exploit existing
taggers and lexical resources for the annotation of corpora with new tagsets.
Combi-bootstrap uses existing resources as features for a second level machine
learning module, that is trained to make the mapping to the new tagset on a
very small sample of annotated corpus material. Experiments show that
Combi-bootstrap: i) can integrate a wide variety of existing resources, and ii)
achieves much higher accuracy (up to 44.7 % error reduction) than both the best
single tagger and an ensemble tagger constructed out of the same small training
sample.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2000-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007018</dc:identifier>
 <dc:identifier>Proceedings of the 2nd International Conference on Language
  Resources and Evaluation (LREC 2000), pp. 17--20</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Examples, Counterexamples, and Enumeration Results for Foldings and
  Unfoldings between Polygons and Polytopes</dc:title>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Demaine, Martin L.</dc:creator>
 <dc:creator>Lubiw, Anna</dc:creator>
 <dc:creator>O'Rourke, Joseph</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We investigate how to make the surface of a convex polyhedron (a polytope) by
folding up a polygon and gluing its perimeter shut, and the reverse process of
cutting open a polytope and unfolding it to a polygon. We explore basic
enumeration questions in both directions: Given a polygon, how many foldings
are there? Given a polytope, how many unfoldings are there to simple polygons?
Throughout we give special attention to convex polygons, and to regular
polygons. We show that every convex polygon folds to an infinite number of
distinct polytopes, but that their number of combinatorially distinct gluings
is polynomial. There are, however, simple polygons with an exponential number
of distinct gluings.
  In the reverse direction, we show that there are polytopes with an
exponential number of distinct cuttings that lead to simple unfoldings. We
establish necessary conditions for a polytope to have convex unfoldings,
implying, for example, that among the Platonic solids, only the tetrahedron has
a convex unfolding. We provide an inventory of the polytopes that may unfold to
regular polygons, showing that, for n&gt;6, there is essentially only one class of
such polytopes.
</dc:description>
 <dc:description>Comment: 54 pages, 33 figures</dc:description>
 <dc:date>2000-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polynomial-time Computation via Local Inference Relations</dc:title>
 <dc:creator>Givan, Robert</dc:creator>
 <dc:creator>McAllester, David</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>F.4.m</dc:subject>
 <dc:description>  We consider the concept of a local set of inference rules. A local rule set
can be automatically transformed into a rule set for which bottom-up evaluation
terminates in polynomial time. The local-rule-set transformation gives
polynomial-time evaluation strategies for a large variety of rule sets that
cannot be given terminating evaluation strategies by any other known automatic
technique. This paper discusses three new results. First, it is shown that
every polynomial-time predicate can be defined by an (unstratified) local rule
set. Second, a new machine-recognizable subclass of the local rule sets is
identified. Finally we show that locality, as a property of rule sets, is
undecidable in general.
</dc:description>
 <dc:description>Comment: 22 pages. Appeared in Knowledge Representation and Reasoning,1993.
  Submitted to ACM Transactions on Computational Logic Correction: original
  conference appearance was 1992, not 1993</dc:description>
 <dc:date>2000-07-13</dc:date>
 <dc:date>2000-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PushPush and Push-1 are NP-hard in 2D</dc:title>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Demaine, Martin L.</dc:creator>
 <dc:creator>O'Rourke, Joseph</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We prove that two pushing-blocks puzzles are intractable in 2D. One of our
constructions improves an earlier result that established intractability in 3D
[OS99] for a puzzle inspired by the game PushPush. The second construction
answers a question we raised in [DDO00] for a variant we call Push-1. Both
puzzles consist of unit square blocks on an integer lattice; all blocks are
movable. An agent may push blocks (but never pull them) in attempting to move
between given start and goal positions. In the PushPush version, the agent can
only push one block at a time, and moreover when a block is pushed it slides
the maximal extent of its free range. In the Push-1 version, the agent can only
push one block one square at a time, the minimal extent---one square. Both
NP-hardness proofs are by reduction from SAT, and rely on a common
construction.
</dc:description>
 <dc:description>Comment: 10 pages, 11 figures. Corrects an error in the conference version:
  Proc. of the 12th Canadian Conference on Computational Geometry, August 2000,
  pp. 211-219</dc:description>
 <dc:date>2000-07-13</dc:date>
 <dc:date>2000-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ATLAS: A flexible and extensible architecture for linguistic annotation</dc:title>
 <dc:creator>Bird, Steven</dc:creator>
 <dc:creator>Day, David</dc:creator>
 <dc:creator>Garofolo, John</dc:creator>
 <dc:creator>Henderson, John</dc:creator>
 <dc:creator>Laprun, Christophe</dc:creator>
 <dc:creator>Liberman, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>E.2</dc:subject>
 <dc:subject>H.2.1</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We describe a formal model for annotating linguistic artifacts, from which we
derive an application programming interface (API) to a suite of tools for
manipulating these annotations. The abstract logical model provides for a range
of storage formats and promotes the reuse of tools that interact through this
API. We focus first on ``Annotation Graphs,'' a graph model for annotations on
linear signals (such as text and speech) indexed by intervals, for which
efficient database storage and querying techniques are applicable. We note how
a wide range of existing annotated corpora can be mapped to this annotation
graph model. This model is then generalized to encompass a wider variety of
linguistic ``signals,'' including both naturally occuring phenomena (as
recorded in images, video, multi-modal interactions, etc.), as well as the
derived resources that are increasingly important to the engineering of natural
language processing systems (such as word lists, dictionaries, aligned
bilingual corpora, etc.). We conclude with a review of the current efforts
towards implementing key pieces of this architecture.
</dc:description>
 <dc:description>Comment: 8 pages, 9 figures</dc:description>
 <dc:date>2000-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007022</dc:identifier>
 <dc:identifier>Proceedings of the Second International Conference on Language
  Resources and Evaluation, pp. 1699-1706, Paris: European Language Resources
  Association, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a query language for annotation graphs</dc:title>
 <dc:creator>Bird, Steven</dc:creator>
 <dc:creator>Buneman, Peter</dc:creator>
 <dc:creator>Tan, Wang-Chiew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>E.2</dc:subject>
 <dc:subject>H.2.1</dc:subject>
 <dc:subject>H.2.3</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The multidimensional, heterogeneous, and temporal nature of speech databases
raises interesting challenges for representation and query. Recently,
annotation graphs have been proposed as a general-purpose representational
framework for speech databases. Typical queries on annotation graphs require
path expressions similar to those used in semistructured query languages.
However, the underlying model is rather different from the customary graph
models for semistructured data: the graph is acyclic and unrooted, and both
temporal and inclusion relationships are important. We develop a query language
and describe optimization techniques for an underlying relational
representation.
</dc:description>
 <dc:description>Comment: 8 pages, 10 figures</dc:description>
 <dc:date>2000-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007023</dc:identifier>
 <dc:identifier>Proceedings of the Second International Conference on Language
  Resources and Evaluation, pp. 807-814, Paris: European Language Resources
  Association, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Many uses, many annotations for large speech corpora: Switchboard and
  TDT as case studies</dc:title>
 <dc:creator>Graff, David</dc:creator>
 <dc:creator>Bird, Steven</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>E.2</dc:subject>
 <dc:subject>H.2.5</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper discusses the challenges that arise when large speech corpora
receive an ever-broadening range of diverse and distinct annotations. Two case
studies of this process are presented: the Switchboard Corpus of telephone
conversations and the TDT2 corpus of broadcast news. Switchboard has undergone
two independent transcriptions and various types of additional annotation, all
carried out as separate projects that were dispersed both geographically and
chronologically. The TDT2 corpus has also received a variety of annotations,
but all directly created or managed by a core group. In both cases, issues
arise involving the propagation of repairs, consistency of references, and the
ability to integrate annotations having different formats and levels of detail.
We describe a general framework whereby these issues can be addressed
successfully.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures</dc:description>
 <dc:date>2000-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007024</dc:identifier>
 <dc:identifier>Proceedings of the Second International Conference on Language
  Resources and Evaluation, pp. 427-433, Paris: European Language Resources
  Association, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Moment of Perfect Clarity I: The Parallel Census Technique</dc:title>
 <dc:creator>Glasser, Christian</dc:creator>
 <dc:creator>Hemaspaandra, Lane A.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:description>  We discuss the history and uses of the parallel census technique---an elegant
tool in the study of certain computational objects having polynomially bounded
census functions. A sequel will discuss advances (including Cai, Naik, and
Sivakumar [CNS95] and Glasser [Gla00]), some related to the parallel census
technique and some due to other approaches, in the complexity-class collapses
that follow if NP has sparse hard sets under reductions weaker than (full)
truth-table reductions.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2000-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating E-Commerce and Data Mining: Architecture and Challenges</dc:title>
 <dc:creator>Ansari, Suhail</dc:creator>
 <dc:creator>Kohavi, Ron</dc:creator>
 <dc:creator>Mason, Llew</dc:creator>
 <dc:creator>Zheng, Zijian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  We show that the e-commerce domain can provide all the right ingredients for
successful data mining and claim that it is a killer domain for data mining. We
describe an integrated architecture, based on our expe-rience at Blue Martini
Software, for supporting this integration. The architecture can dramatically
reduce the pre-processing, cleaning, and data understanding effort often
documented to take 80% of the time in knowledge discovery projects. We
emphasize the need for data collection at the application server layer (not the
web server) in order to support logging of data and metadata that is essential
to the discovery process. We describe the data transformation bridges required
from the transaction processing systems and customer event streams (e.g.,
clickstreams) to the data warehouse. We detail the mining workbench, which
needs to provide multiple views of the data through reporting, data mining
algorithms, visualization, and OLAP. We con-clude with a set of challenges.
</dc:description>
 <dc:description>Comment: KDD workshop: WebKDD 2000</dc:description>
 <dc:date>2000-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007026</dc:identifier>
 <dc:identifier>WEBKDD'2000 workshop: Web Mining for E-Commerce -- Challenges and
  Opportunities</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient cache use for stencil operations on structured discretization
  grids</dc:title>
 <dc:creator>Frumkin, Michael A.</dc:creator>
 <dc:creator>Van der Wijngaart, Rob F.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:subject>B.8</dc:subject>
 <dc:description>  We derive tight bounds on cache misses for evaluation of explicit stencil
operators on structured grids. Our lower bound is based on the isoperimetrical
property of the discrete octahedron. Our upper bound is based on good surface
to volume ratio of a parallelepiped spanned by a reduced basis of the inter-
ference lattice of a grid. Measurements show that our algorithm typically
reduces the number of cache misses by factor of three relative to a compiler
optimized code. We show that stencil calculations on grids whose interference
lattice have a short vector feature abnormally high numbers of cache misses. We
call such grids unfavorable and suggest to avoid these in computations by
appropriate padding. By direct measurements on MIPS R10000 we show a good
correlation of abnormally high cache misses and unfavorable three-dimensional
grids.
</dc:description>
 <dc:description>Comment: tex .tar.gz file, including ps file, 16 pagest, 5 figures, 2
  Appendicies</dc:description>
 <dc:date>2000-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Base Encryption: Dynamic algorithms, Keys, and Symbol Set</dc:title>
 <dc:creator>Lin, Po-Han</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>E, E.3</dc:subject>
 <dc:description>  All the current modern encryption algorithms utilize fixed symbols for
plaintext and cyphertext. What I mean by fixed is that there is a set and
limited number of symbols to represent the characters, numbers, and
punctuations. In addition, they are usually the same (the plaintext symbols
have the same and equivalent counterpart in the cyphertext symbols). Almost all
the encryption algorithms rely on a predefined keyspace and length for the
encryption/decription keys, and it is usually fixed (number of bits). In
addition, the algorithms used by the encryptions are static. There is a
predefined number of operatiors, and a predefined order (loops included) of
operations. The algorithm stays the same, and the plaintext and cyphertext
along with the key are churned through this cypherblock.
  Base Encryption does the opposite: It utilizes the novel concepts of base
conversion, symbol remapping, and dynamic algorithms (dynamic operators and
dynamic operations). Base Encryption solves the weakness in todays encryption
schemes, namely... Fixed symbols (base) Fixed keylengths Fixed algorithms
(fixed number of operations and operators)
  Unique features... Immune from plain-text-attacks. Immune from
brute-force-attacks. Can utilize throwaway algorithms (as opposed to throw away
keys). Plug-And-Play engine (other cyphers can be augmentated to it)
</dc:description>
 <dc:description>Comment: html page</dc:description>
 <dc:date>2000-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dimension-Dependent behavior in the satisfability of random k-Horn
  formulae</dc:title>
 <dc:creator>Istrate, Gabriel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We determine the asymptotical satisfiability probability of a random
at-most-k-Horn formula, via a probabilistic analysis of a simple version,
called PUR, of positive unit resolution. We show that for k=k(n)-&gt;oo the
problem can be ``reduced'' to the case k(n)=n, that was solved in
cs.DS/9912001. On the other hand, in the case k= a constant the behavior of PUR
is modeled by a simple queuing chain, leading to a closed-form solution when
k=2. Our analysis predicts an ``easy-hard-easy'' pattern in this latter case.
Under a rescaled parameter, the graphs of satisfaction probability
corresponding to finite values of k converge to the one for the uniform case, a
``dimension-dependent behavior'' similar to the one found experimentally by
Kirkpatrick and Selman (Science'94) for k-SAT. The phenomenon is qualitatively
explained by a threshold property for the number of iterations of PUR makes on
random satisfiable Horn formulas.
</dc:description>
 <dc:date>2000-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A theory of normed simulations</dc:title>
 <dc:creator>Griffioen, W. O. D.</dc:creator>
 <dc:creator>Vaandrager, F. W.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  In existing simulation proof techniques, a single step in a lower-level
specification may be simulated by an extended execution fragment in a
higher-level one. As a result, it is cumbersome to mechanize these techniques
using general purpose theorem provers. Moreover, it is undecidable whether a
given relation is a simulation, even if tautology checking is decidable for the
underlying specification logic. This paper introduces various types of normed
simulations. In a normed simulation, each step in a lower-level specification
can be simulated by at most one step in the higher-level one, for any related
pair of states. In earlier work we demonstrated that normed simulations are
quite useful as a vehicle for the formalization of refinement proofs via
theorem provers. Here we show that normed simulations also have pleasant
theoretical properties: (1) under some reasonable assumptions, it is decidable
whether a given relation is a normed forward simulation, provided tautology
checking is decidable for the underlying logic; (2) at the semantic level,
normed forward and backward simulations together form a complete proof method
for establishing behavior inclusion, provided that the higher-level
specification has finite invisible nondeterminism.
</dc:description>
 <dc:description>Comment: 31 pages, 10figures</dc:description>
 <dc:date>2000-07-19</dc:date>
 <dc:date>2002-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parameter-free Model of Rank Polysemantic Distribution</dc:title>
 <dc:creator>Kromer, Victor</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  A model of rank polysemantic distribution with a minimal number of fitting
parameters is offered. In an ideal case a parameter-free description of the
dependence on the basis of one or several immediate features of the
distribution is possible.
</dc:description>
 <dc:description>Comment: 3 pages, no figures</dc:description>
 <dc:date>2000-07-21</dc:date>
 <dc:date>2000-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007031</dc:identifier>
 <dc:identifier>Proceedings of the 4th conference of the International
  Quantitative Linguistics Association (QUALICO 2000). Prague, August 24-26,
  2000. P. 21-22.The full version (in Russian) is available in Web Journal
  FCCL. See URL http://fccl.ksu.ru/fcclpap.htm</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge on Treelike Spaces</dc:title>
 <dc:creator>Georgatos, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.0</dc:subject>
 <dc:description>  This paper presents a bimodal logic for reasoning about knowledge during
knowledge acquisition. One of the modalities represents (effort during)
non-deterministic time and the other represents knowledge. The semantics of
this logic are tree-like spaces which are a generalization of semantics used
for modeling branching time and historical necessity. A finite system of axiom
schemes is shown to be canonically complete for the formentioned spaces. A
characterization of the satisfaction relation implies the small model property
and decidability for this system.
</dc:description>
 <dc:description>Comment: 31 pages</dc:description>
 <dc:date>2000-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007032</dc:identifier>
 <dc:identifier>Studia Logica, 1(59), 1997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>To Preference via Entrenchment</dc:title>
 <dc:creator>Georgatos, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  We introduce a simple generalization of Gardenfors and Makinson's epistemic
entrenchment called partial entrenchment. We show that preferential inference
can be generated as the sceptical counterpart of an inference mechanism defined
directly on partial entrenchment.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2000-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007033</dc:identifier>
 <dc:identifier>Annals Of Pure And Applied Logic, (96)1-3, pages 141-155, 1999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Competitiveness of On-Line vis-a-vis Conventional Retailing: A
  Preliminary Study</dc:title>
 <dc:creator>Png, Ivan</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>K.4.4</dc:subject>
 <dc:description>  Previous research has directly studied whether on-line retailing is more
competitive than conventional retail markets. The evidence from books and music
CDs is mixed. Here, I use an indirect approach to compare the competitiveness
of on-line with conventional markets. Focusing on the retail market for books,
I identify a peculiarity in the pricing of bestsellers relative to other
titles. Supposing that competitive barriers are lower in on-line retailing, I
analyze how the lower barriers would affect the relative pricing of
bestsellers. The empirical data indicates that on-line retailing is more
competitive than conventional retailing.
</dc:description>
 <dc:description>Comment: 11th NEC Research Symposium</dc:description>
 <dc:date>2000-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mapping WordNets Using Structural Information</dc:title>
 <dc:creator>Daude, J.</dc:creator>
 <dc:creator>Padro, L.</dc:creator>
 <dc:creator>Rigau, G.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We present a robust approach for linking already existing lexical/semantic
hierarchies. We used a constraint satisfaction algorithm (relaxation labeling)
to select --among a set of candidates-- the node in a target taxonomy that
bests matches each node in a source taxonomy. In particular, we use it to map
the nominal part of WordNet 1.5 onto WordNet 1.6, with a very high precision
and a very low remaining ambiguity.
</dc:description>
 <dc:description>Comment: 8 pages, uses epsfig. To appear in ACL'2000 proceedings</dc:description>
 <dc:date>2000-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007035</dc:identifier>
 <dc:identifier>38th Anual Meeting of the Association for Computational
  Linguistics (ACL'2000). Hong Kong, October 2000.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Language identification of controlled systems: Modelling, control and
  anomaly detection</dc:title>
 <dc:creator>Martins, J. F.</dc:creator>
 <dc:creator>Dente, J. A.</dc:creator>
 <dc:creator>Pires, A. J.</dc:creator>
 <dc:creator>Mendes, R. Vilela</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  Formal language techniques have been used in the past to study autonomous
dynamical systems. However, for controlled systems, new features are needed to
distinguish between information generated by the system and input control. We
show how the modelling framework for controlled dynamical systems leads
naturally to a formulation in terms of context-dependent grammars. A learning
algorithm is proposed for on-line generation of the grammar productions, this
formulation being then used for modelling, control and anomaly detection.
Practical applications are described for electromechanical drives. Grammatical
interpolation techniques yield accurate results and the pattern detection
capabilities of the language-based formulation makes it a promising technique
for the early detection of anomalies or faulty behaviour.
</dc:description>
 <dc:description>Comment: 27 pages Latex, 18 figures</dc:description>
 <dc:date>2000-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007036</dc:identifier>
 <dc:identifier>IEEE Trans. in Systems, Man and Cybernetics 31 (2001) 234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Theoretic Properties of Topological Spaces</dc:title>
 <dc:creator>Georgatos, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We study the topological models of a logic of knowledge for topological
reasoning, introduced by Larry Moss and Rohit Parikh. Among our results is a
solution of a conjecture by the formentioned authors, finite satisfiability
property and decidability for the theory of topological models.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2000-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007037</dc:identifier>
 <dc:identifier>In Knowledge Representation and Uncertainty. M. Masuch and L.
  Polos, Eds. Lecture Notes in Artificial Intelligence, vol. 808, pages
  147-159, Springer-Verlag, 1994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modal Logics for Topological Spaces</dc:title>
 <dc:creator>Georgatos, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  In this thesis we shall present two logical systems, MP and MP, for the
purpose of reasoning about knowledge and effort. These logical systems will be
interpreted in a spatial context and therefore, the abstract concepts of
knowledge and effort will be defined by concrete mathematical concepts.
</dc:description>
 <dc:description>Comment: 25 pages, extened abstract of PHD Dissertation</dc:description>
 <dc:date>2000-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ordering-based Representations of Rational Inference</dc:title>
 <dc:creator>Georgatos, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  Rational inference relations were introduced by Lehmann and Magidor as the
ideal systems for drawing conclusions from a conditional base. However, there
has been no simple characterization of these relations, other than its original
representation by preferential models. In this paper, we shall characterize
them with a class of total preorders of formulas by improving and extending
Gardenfors and Makinson's results for expectation inference relations. A second
representation is application-oriented and is obtained by considering a class
of consequence operators that grade sets of defaults according to our reliance
on them. The finitary fragment of this class of consequence operators has been
employed by recent default logic formalisms based on maxiconsistency.
</dc:description>
 <dc:description>Comment: 26 pages, appeared in conference proceedings, contains proofs</dc:description>
 <dc:date>2000-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007039</dc:identifier>
 <dc:identifier>In the Proceedings of the European Workshop on Logics in AI (JELIA
  '96). J.J. Alferes, L.M. Pereira and E. Orlowska, Eds. Lecture Notes in
  Artificial Intelligence, vol. 1126, pages 176-191, Springer-Verlag, 1996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entrenchment Relations: A Uniform Approach to Nonmonotonicity</dc:title>
 <dc:creator>Georgatos, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  We show that Gabbay's nonmonotonic consequence relations can be reduced to a
new family of relations, called entrenchment relations. Entrenchment relations
provide a direct generalization of epistemic entrenchment and expectation
ordering introduced by Gardenfors and Makinson for the study of belief revision
and expectation inference, respectively.
</dc:description>
 <dc:description>Comment: 22 pages, a paper in preliminary form that appeared later in
  conference proceedings</dc:description>
 <dc:date>2000-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007040</dc:identifier>
 <dc:identifier>In the Proceedings of the International Joint Conference on
  Qualitative and Quantitative Practical Reasoning (ESCQARU/FAPR 97), Lecture
  Notes in Artificial Intelligence, vol. 1244, pages 282-297, Springer-Verlag,
  1997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relevance as Deduction: A Logical View of Information Retrieval</dc:title>
 <dc:creator>Amati, Gianni</dc:creator>
 <dc:creator>Georgatos, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>H.3.0</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  The problem of Information Retrieval is, given a set of documents D and a
query q, providing an algorithm for retrieving all documents in D relevant to
q. However, retrieval should depend and be updated whenever the user is able to
provide as an input a preferred set of relevant documents; this process is
known as em relevance feedback. Recent work in IR has been paying great
attention to models which employ a logical approach; the advantage being that
one can have a simple computable characterization of retrieval on the basis of
a pure logical analysis of retrieval. Most of the logical models make use of
probabilities or similar belief functions in order to introduce the inductive
component whereby uncertainty is treated. Their general paradigm is the
following: em find the nature of conditional $d\imp q$ and then define a
probability on the top of it. We just reverse this point of view; first use the
numerical information, frequencies or probabilities, then define your own
logical consequence. More generally, we claim that retrieval is a form of
deduction. We introduce a simple but powerful logical framework of relevance
feedback, derived from the well founded area of nonmonotonic logic. This
description can help us evaluate, describe and compare from a theoretical point
of view previous approaches based on conditionals or probabilities.
</dc:description>
 <dc:description>Comment: 6 pages, Abstract</dc:description>
 <dc:date>2000-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007041</dc:identifier>
 <dc:identifier>In F. Crestani and M. Lalmas, editors, Proceedings of the Second
  Workshop on Information Retrieval, Uncertainty and Logic WIRUL'96, pages
  21--26. University of Glasgow, Glasgow, Scotland, 1996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Geometry Column 39</dc:title>
 <dc:creator>O'Rourke, Joseph</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  The resolution of a decades-old open problem is described: polygonal chains
cannot lock in the plane.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures. To appear in SIGACT News and in Int. J. Comp.
  Geom. Appl</dc:description>
 <dc:date>2000-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007042</dc:identifier>
 <dc:identifier>SIGACT News 31(3): 47-49 (2000)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Min-Max Fine Heaps</dc:title>
 <dc:creator>Nath, Suman Kumar</dc:creator>
 <dc:creator>Chowdhury, Rezaul Alam</dc:creator>
 <dc:creator>Kaykobad, M.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:description>  In this paper we present a new data structure for double ended priority
queue, called min-max fine heap, which combines the techniques used in fine
heap and traditional min-max heap. The standard operations on this proposed
structure are also presented, and their analysis indicates that the new
structure outperforms the traditional one.
</dc:description>
 <dc:description>Comment: 6 pages, pdf file</dc:description>
 <dc:date>2000-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0007044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Managing Periodically Updated Data in Relational Databases: A Stochastic
  Modeling Approach</dc:title>
 <dc:creator>Gal, Avigdor</dc:creator>
 <dc:creator>Eckstein, Jonathan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:description>  Recent trends in information management involve the periodic transcription of
data onto secondary devices in a networked environment, and the proper
scheduling of these transcriptions is critical for efficient data management.
To assist in the scheduling process, we are interested in modeling the
reduction of consistency over time between a relation and its replica, termed
obsolescence of data. The modeling is based on techniques from the field of
stochastic processes, and provides several stochastic models for content
evolution in the base relations of a database, taking referential integrity
constraints into account. These models are general enough to accommodate most
of the common scenarios in databases, including batch insertions and life spans
both with and without memory. As an initial &quot;proof of concept&quot; of the
applicability of our approach, we validate the insertion portion of our model
framework via experiments with real data feeds. We also discuss a set of
transcription protocols which make use of the proposed stochastic model.
</dc:description>
 <dc:date>2000-07-31</dc:date>
 <dc:date>2001-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0007044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boolean Satisfiability with Transitivity Constraints</dc:title>
 <dc:creator>Bryant, Randal E.</dc:creator>
 <dc:creator>Velev, Miroslav N.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I2.3</dc:subject>
 <dc:subject>G2.2</dc:subject>
 <dc:description>  We consider a variant of the Boolean satisfiability problem where a subset E
of the propositional variables appearing in formula Fsat encode a symmetric,
transitive, binary relation over N elements. Each of these relational
variables, e[i,j], for 1 &lt;= i &lt; j &lt;= N, expresses whether or not the relation
holds between elements i and j. The task is to either find a satisfying
assignment to Fsat that also satisfies all transitivity constraints over the
relational variables (e.g., e[1,2] &amp; e[2,3] ==&gt; e[1,3]), or to prove that no
such assignment exists. Solving this satisfiability problem is the final and
most difficult step in our decision procedure for a logic of equality with
uninterpreted functions. This procedure forms the core of our tool for
verifying pipelined microprocessors.
  To use a conventional Boolean satisfiability checker, we augment the set of
clauses expressing Fsat with clauses expressing the transitivity constraints.
We consider methods to reduce the number of such clauses based on the sparse
structure of the relational variables.
  To use Ordered Binary Decision Diagrams (OBDDs), we show that for some sets
E, the OBDD representation of the transitivity constraints has exponential size
for all possible variable orderings. By considering only those relational
variables that occur in the OBDD representation of Fsat, our experiments show
that we can readily construct an OBDD representation of the relevant
transitivity constraints and thus solve the constrained satisfiability problem.
</dc:description>
 <dc:description>Comment: Submitted to ACM Transactions on Computational Logic</dc:description>
 <dc:date>2000-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure of some sand pile model</dc:title>
 <dc:creator>Latapy, M.</dc:creator>
 <dc:creator>Mantaci, R.</dc:creator>
 <dc:creator>Morvan, M.</dc:creator>
 <dc:creator>Phan, H. D.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  SPM (Sand Pile Model) is a simple discrete dynamical system used in physics
to represent granular objects. It is deeply related to integer partitions, and
many other combinatorics problems, such as tilings or rewriting systems. The
evolution of the system started with n stacked grains generates a lattice,
denoted by SPM(n). We study here the structure of this lattice. We first
explain how it can be constructed, by showing its strong self-similarity
property. Then, we define SPM(infini), a natural extension of SPM when one
starts with an infinite number of grains. Again, we give an efficient
construction algorithm and a coding of this lattice using a self-similar tree.
The two approaches give different recursive formulae for the cardinal of
SPM(n), where no closed formula have ever been found.
</dc:description>
 <dc:description>Comment: To appear in Theoretical Computer Science</dc:description>
 <dc:date>2000-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interfacing Constraint-Based Grammars and Generation Algorithms</dc:title>
 <dc:creator>Busemann, Stephan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Constraint-based grammars can, in principle, serve as the major linguistic
knowledge source for both parsing and generation. Surface generation starts
from input semantics representations that may vary across grammars. For many
declarative grammars, the concept of derivation implicitly built in is that of
parsing. They may thus not be interpretable by a generation algorithm. We show
that linguistically plausible semantic analyses can cause severe problems for
semantic-head-driven approaches for generation (SHDG). We use SeReal, a variant
of SHDG and the DISCO grammar of German as our source of examples. We propose a
new, general approach that explicitly accounts for the interface between the
grammar and the generation algorithm by adding a control-oriented layer to the
linguistic knowledge base that reorganizes the semantics in a way suitable for
generation.
</dc:description>
 <dc:description>Comment: 8 pages, uses colacl.sty</dc:description>
 <dc:date>2000-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008003</dc:identifier>
 <dc:identifier>Proc. Workshop on Analysis for Generation, 1st International
  Natural Language Generation Conference, Mitzpe Ramon, Israel, June 12, 2000.
  pp. 14-21</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparing two trainable grammatical relations finders</dc:title>
 <dc:creator>Yeh, Alexander</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Grammatical relationships (GRs) form an important level of natural language
processing, but different sets of GRs are useful for different purposes.
Therefore, one may often only have time to obtain a small training corpus with
the desired GR annotations. On such a small training corpus, we compare two
systems. They use different learning techniques, but we find that this
difference by itself only has a minor effect. A larger factor is that in
English, a different GR length measure appears better suited for finding simple
argument GRs than for finding modifier GRs. We also find that partitioning the
data may help memory-based learning.
</dc:description>
 <dc:description>Comment: 5 pages, uses colacl.sty</dc:description>
 <dc:date>2000-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008004</dc:identifier>
 <dc:identifier>18th International Conference on Computational Linguistics (COLING
  2000), pages 1146-1150, Saarbruecken, Germany, July, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>More accurate tests for the statistical significance of result
  differences</dc:title>
 <dc:creator>Yeh, Alexander</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Statistical significance testing of differences in values of metrics like
recall, precision and balanced F-score is a necessary part of empirical natural
language processing. Unfortunately, we find in a set of experiments that many
commonly used tests often underestimate the significance and so are less likely
to detect differences that exist between different techniques. This
underestimation comes from an independence assumption that is often violated.
We point out some useful tests that do not make this assumption, including
computationally-intensive randomization tests.
</dc:description>
 <dc:description>Comment: 7 pages, uses colacl.sty</dc:description>
 <dc:date>2000-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008005</dc:identifier>
 <dc:identifier>18th International Conference on Computational Linguistics (COLING
  2000), pages 947-953, Saarbruecken, Germany, July, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for Analysing Firewall and Router Access Lists</dc:title>
 <dc:creator>Hazelhurst, Scott</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.0</dc:subject>
 <dc:subject>E.2.0</dc:subject>
 <dc:description>  Network firewalls and routers use a rule database to decide which packets
will be allowed from one network onto another. By filtering packets the
firewalls and routers can improve security and performance. However, as the
size of the rule list increases, it becomes difficult to maintain and validate
the rules, and lookup latency may increase significantly. Ordered binary
decision diagrams (BDDs) - a compact method of representing and manipulating
boolean expressions - are a potential method of representing the rules. This
paper presents a new algorithm for representing such lists as a BDD and then
shows how the resulting boolean expression can be used to analyse rule sets.
</dc:description>
 <dc:description>Comment: 12 pages; revised and shortened version appeared in Workshop on
  Dependable IP Systems and Platforms, In Proc ICDSN, June 2000</dc:description>
 <dc:date>2000-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tagger Evaluation Given Hierarchical Tag Sets</dc:title>
 <dc:creator>Melamed, I. Dan</dc:creator>
 <dc:creator>Resnik, Philip</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>J.5</dc:subject>
 <dc:description>  We present methods for evaluating human and automatic taggers that extend
current practice in three ways. First, we show how to evaluate taggers that
assign multiple tags to each test instance, even if they do not assign
probabilities. Second, we show how to accommodate a common property of manually
constructed ``gold standards'' that are typically used for objective
evaluation, namely that there is often more than one correct answer. Third, we
show how to measure performance when the set of possible tags is
tree-structured in an IS-A hierarchy. To illustrate how our methods can be used
to measure inter-annotator agreement, we show how to compute the kappa
coefficient over hierarchical tag sets.
</dc:description>
 <dc:description>Comment: preprint is 7 pages, laid out differently than printed version</dc:description>
 <dc:date>2000-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008007</dc:identifier>
 <dc:identifier>Computers and the Humanities 34(1-2). Special issue on SENSEVAL.
  pp. 79-84</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Average Similarity Degree between Solutions of Random k-SAT and
  Random CSPs</dc:title>
 <dc:creator>Xu, Ke</dc:creator>
 <dc:creator>Li, Wei</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  To study the structure of solutions for random k-SAT and random CSPs, this
paper introduces the concept of average similarity degree to characterize how
solutions are similar to each other. It is proved that under certain
conditions, as r (i.e. the ratio of constraints to variables) increases, the
limit of average similarity degree when the number of variables approaches
infinity exhibits phase transitions at a threshold point, shifting from a
smaller value to a larger value abruptly. For random k-SAT this phenomenon will
occur when k&gt;4 . It is further shown that this threshold point is also a
singular point with respect to r in the asymptotic estimate of the second
moment of the number of solutions. Finally, we discuss how this work is helpful
to understand the hardness of solving random instances and a possible
application of it to the design of search algorithms.
</dc:description>
 <dc:description>Comment: 22 pages, the final version to appear in Discrete Applied Mathematics</dc:description>
 <dc:date>2000-08-11</dc:date>
 <dc:date>2002-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008008</dc:identifier>
 <dc:identifier>Discrete Applied Mathematics, 136(2004):125-149.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Mining to Measure and Improve the Success of Web Sites</dc:title>
 <dc:creator>Spiliopoulou, Myra</dc:creator>
 <dc:creator>Pohle, Carsten</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  For many companies, competitiveness in e-commerce requires a successful
presence on the web. Web sites are used to establish the company's image, to
promote and sell goods and to provide customer support. The success of a web
site affects and reflects directly the success of the company in the electronic
market. In this study, we propose a methodology to improve the ``success'' of
web sites, based on the exploitation of navigation pattern discovery. In
particular, we present a theory, in which success is modelled on the basis of
the navigation behaviour of the site's users. We then exploit WUM, a navigation
pattern discovery miner, to study how the success of a site is reflected in the
users' behaviour. With WUM we measure the success of a site's components and
obtain concrete indications of how the site should be improved. We report on
our first experiments with an online catalog, the success of which we have
studied. Our mining analysis has shown very promising results, on the basis of
which the site is currently undergoing concrete improvements.
</dc:description>
 <dc:description>Comment: 24 pages, 4 postscript figures and 4 figures containing only text. To
  be published in the Journal of Data Mining and Knowledge Discovery (Kluwer
  Academic Publishers), Special Issue on E-Commerce; subject to some revision</dc:description>
 <dc:date>2000-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flipturning polygons</dc:title>
 <dc:creator>Aichholzer, Oswin</dc:creator>
 <dc:creator>Cortes, Carmen</dc:creator>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Dujmovic, Vida</dc:creator>
 <dc:creator>Erickson, Jeff</dc:creator>
 <dc:creator>Meijer, Henk</dc:creator>
 <dc:creator>Overmars, Mark</dc:creator>
 <dc:creator>Palop, Belen</dc:creator>
 <dc:creator>Ramaswami, Suneeta</dc:creator>
 <dc:creator>Toussaint, Godfried T.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2</dc:subject>
 <dc:description>  A flipturn is an operation that transforms a nonconvex simple polygon into
another simple polygon, by rotating a concavity 180 degrees around the midpoint
of its bounding convex hull edge. Joss and Shannon proved in 1973 that a
sequence of flipturns eventually transforms any simple polygon into a convex
polygon. This paper describes several new results about such flipturn
sequences. We show that any orthogonal polygon is convexified after at most n-5
arbitrary flipturns, or at most 5(n-4)/6 well-chosen flipturns, improving the
previously best upper bound of (n-1)!/2. We also show that any simple polygon
can be convexified by at most n^2-4n+1 flipturns, generalizing earlier results
of Ahn et al. These bounds depend critically on how degenerate cases are
handled; we carefully explore several possibilities. We describe how to
maintain both a simple polygon and its convex hull in O(log^4 n) time per
flipturn, using a data structure of size O(n). We show that although flipturn
sequences for the same polygon can have very different lengths, the shape and
position of the final convex polygon is the same for all sequences and can be
computed in O(n log n) time. Finally, we demonstrate that finding the longest
convexifying flipturn sequence of a simple polygon is NP-hard.
</dc:description>
 <dc:description>Comment: 26 pages, 32 figures, see also
  http://www.uiuc.edu/~jeffe/pubs/flipturn.html</dc:description>
 <dc:date>2000-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>All Pairs Shortest Paths using Bridging Sets and Rectangular Matrix
  Multiplication</dc:title>
 <dc:creator>Zwick, Uri</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  We present two new algorithms for solving the {\em All Pairs Shortest Paths}
(APSP) problem for weighted directed graphs. Both algorithms use fast matrix
multiplication algorithms.
  The first algorithm solves the APSP problem for weighted directed graphs in
which the edge weights are integers of small absolute value in $\Ot(n^{2+\mu})$
time, where $\mu$ satisfies the equation $\omega(1,\mu,1)=1+2\mu$ and
$\omega(1,\mu,1)$ is the exponent of the multiplication of an $n\times n^\mu$
matrix by an $n^\mu \times n$ matrix. Currently, the best available bounds on
$\omega(1,\mu,1)$, obtained by Coppersmith, imply that $\mu&lt;0.575$. The running
time of our algorithm is therefore $O(n^{2.575})$. Our algorithm improves on
the $\Ot(n^{(3+\omega)/2})$ time algorithm, where $\omega=\omega(1,1,1)&lt;2.376$
is the usual exponent of matrix multiplication, obtained by Alon, Galil and
Margalit, whose running time is only known to be $O(n^{2.688})$.
  The second algorithm solves the APSP problem {\em almost} exactly for
directed graphs with {\em arbitrary} non-negative real weights. The algorithm
runs in $\Ot((n^\omega/\eps)\log (W/\eps))$ time, where $\eps&gt;0$ is an error
parameter and W is the largest edge weight in the graph, after the edge weights
are scaled so that the smallest non-zero edge weight in the graph is 1. It
returns estimates of all the distances in the graph with a stretch of at most
$1+\eps$. Corresponding paths can also be found efficiently.
</dc:description>
 <dc:description>Comment: 27 pages, 19 figures, a preliminary version appeared in FOCS'98 under
  a slightly different title</dc:description>
 <dc:date>2000-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying System Combination to Base Noun Phrase Identification</dc:title>
 <dc:creator>Sang, Erik F. Tjong Kim</dc:creator>
 <dc:creator>Daelemans, Walter</dc:creator>
 <dc:creator>Dejean, Herve</dc:creator>
 <dc:creator>Koeling, Rob</dc:creator>
 <dc:creator>Krymolowski, Yuval</dc:creator>
 <dc:creator>Punyakanok, Vasin</dc:creator>
 <dc:creator>Roth, Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We use seven machine learning algorithms for one task: identifying base noun
phrases. The results have been processed by different system combination
methods and all of these outperformed the best individual result. We have
applied the seven learners with the best combinator, a majority vote of the top
five systems, to a standard data set and managed to improve the best published
result for this data set.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2000-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008012</dc:identifier>
 <dc:identifier>Proceedings of COLING 2000, Saarbruecken, Germany</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meta-Learning for Phonemic Annotation of Corpora</dc:title>
 <dc:creator>Hoste, Veronique</dc:creator>
 <dc:creator>Daelemans, Walter</dc:creator>
 <dc:creator>Sang, Erik Tjong Kim</dc:creator>
 <dc:creator>Gillis, Steven</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We apply rule induction, classifier combination and meta-learning (stacked
classifiers) to the problem of bootstrapping high accuracy automatic annotation
of corpora with pronunciation information. The task we address in this paper
consists of generating phonemic representations reflecting the Flemish and
Dutch pronunciations of a word on the basis of its orthographic representation
(which in turn is based on the actual speech recordings). We compare several
possible approaches to achieve the text-to-pronunciation mapping task:
memory-based learning, transformation-based learning, rule induction, maximum
entropy modeling, combination of classifiers in stacked learning, and stacking
of meta-learners. We are interested both in optimal accuracy and in obtaining
insight into the linguistic regularities involved. As far as accuracy is
concerned, an already high accuracy level (93% for Celex and 86% for Fonilex at
word level) for single classifiers is boosted significantly with additional
error reductions of 31% and 38% respectively using combination of classifiers,
and a further 5% using combination of meta-learners, bringing overall word
level accuracy to 96% for the Dutch variant and 92% for the Flemish variant. We
also show that the application of machine learning methods indeed leads to
increased insight into the linguistic regularities determining the variation
between the two pronunciation variants studied.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2000-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008013</dc:identifier>
 <dc:identifier>Proceedings of ICML-2000, Stanford University, CA, USA</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aspects of Pattern-Matching in Data-Oriented Parsing</dc:title>
 <dc:creator>De Pauw, Guy</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  Data-Oriented Parsing (dop) ranks among the best parsing schemes, pairing
state-of-the art parsing accuracy to the psycholinguistic insight that larger
chunks of syntactic structures are relevant grammatical and probabilistic
units. Parsing with the dop-model, however, seems to involve a lot of CPU
cycles and a considerable amount of double work, brought on by the concept of
multiple derivations, which is necessary for probabilistic processing, but
which is not convincingly related to a proper linguistic backbone. It is
however possible to re-interpret the dop-model as a pattern-matching model,
which tries to maximize the size of the substructures that construct the parse,
rather than the probability of the parse. By emphasizing this memory-based
aspect of the dop-model, it is possible to do away with multiple derivations,
opening up possibilities for efficient Viterbi-style optimizations, while still
retaining acceptable parsing accuracy through enhanced context-sensitivity.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2000-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008014</dc:identifier>
 <dc:identifier>Proceedings of the 18th International Conference on Computational
  Linguistics</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temiar Reduplication in One-Level Prosodic Morphology</dc:title>
 <dc:creator>Walther, Markus</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Temiar reduplication is a difficult piece of prosodic morphology. This paper
presents the first computational analysis of Temiar reduplication, using the
novel finite-state approach of One-Level Prosodic Morphology originally
developed by Walther (1999b, 2000). After reviewing both the data and the basic
tenets of One-level Prosodic Morphology, the analysis is laid out in some
detail, using the notation of the FSA Utilities finite-state toolkit (van Noord
1997). One important discovery is that in this approach one can easily define a
regular expression operator which ambiguously scans a string in the left- or
rightward direction for a certain prosodic property. This yields an elegant
account of base-length-dependent triggering of reduplication as found in
Temiar.
</dc:description>
 <dc:description>Comment: 9 pages, 2 figures. Finite-State Phonology: SIGPHON-2000, Proceedings
  of the Fifth Workshop of the ACL Special Interest Group in Computational
  Phonology, pp.13-21. Aug. 6, 2000. Luxembourg</dc:description>
 <dc:date>2000-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Processing Self Corrections in a speech to speech system</dc:title>
 <dc:creator>Spilker, Joerg</dc:creator>
 <dc:creator>Klarner, Martin</dc:creator>
 <dc:creator>Goerz, Guenther</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I 2.7</dc:subject>
 <dc:description>  Speech repairs occur often in spontaneous spoken dialogues. The ability to
detect and correct those repairs is necessary for any spoken language system.
We present a framework to detect and correct speech repairs where all relevant
levels of information, i.e., acoustics, lexis, syntax and semantics can be
integrated. The basic idea is to reduce the search space for repairs as soon as
possible by cascading filters that involve more and more features. At first an
acoustic module generates hypotheses about the existence of a repair. Second a
stochastic model suggests a correction for every hypothesis. Well scored
corrections are inserted as new paths in the word lattice. Finally a lattice
parser decides on accepting the rep air.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2000-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008016</dc:identifier>
 <dc:identifier>Proceedings of COLING 2000, Saarbruecken, Germany; 31.7-4.8; pp
  1116-1120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient probabilistic top-down and left-corner parsing</dc:title>
 <dc:creator>Roark, Brian</dc:creator>
 <dc:creator>Johnson, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper examines efficient predictive broad-coverage parsing without
dynamic programming. In contrast to bottom-up methods, depth-first top-down
parsing produces partial parses that are fully connected trees spanning the
entire left context, from which any kind of non-local dependency or partial
semantic interpretation can in principle be read. We contrast two predictive
parsing approaches, top-down and left-corner parsing, and find both to be
viable. In addition, we find that enhancement with non-local information not
only improves parser accuracy, but also substantially improves the search
efficiency.
</dc:description>
 <dc:description>Comment: 8 pages, 3 tables, 3 figures</dc:description>
 <dc:date>2000-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008017</dc:identifier>
 <dc:identifier>Proceedings of the 37th Annual Meeting of the Association for
  Computational Linguistics, 1999, pages 421-428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Bisimulation Problem for equational graphs of finite out-degree</dc:title>
 <dc:creator>Senizergues, G.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.4.2</dc:subject>
 <dc:subject>F.4.3</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  The &quot;bisimulation problem&quot; for equational graphs of finite out-degree is
shown to be decidable. We reduce this problem to the bisimulation problem for
deterministic rational (vectors of) boolean series on the alphabet of a dpda M.
We then exhibit a complete formal system for deducing equivalent pairs of such
vectors.
</dc:description>
 <dc:description>Comment: 98 pages, 4 figures, submitted to JACM</dc:description>
 <dc:date>2000-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Experimental Comparison of Naive Bayesian and Keyword-Based Anti-Spam
  Filtering with Personal E-mail Messages</dc:title>
 <dc:creator>Androutsopoulos, Ion</dc:creator>
 <dc:creator>Koutsias, John</dc:creator>
 <dc:creator>Chandrinos, Konstantinos V.</dc:creator>
 <dc:creator>Spyropoulos, Constantine D.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>H.4.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:subject>K.4.1</dc:subject>
 <dc:description>  The growing problem of unsolicited bulk e-mail, also known as &quot;spam&quot;, has
generated a need for reliable anti-spam e-mail filters. Filters of this type
have so far been based mostly on manually constructed keyword patterns. An
alternative approach has recently been proposed, whereby a Naive Bayesian
classifier is trained automatically to detect spam messages. We test this
approach on a large collection of personal e-mail messages, which we make
publicly available in &quot;encrypted&quot; form contributing towards standard
benchmarks. We introduce appropriate cost-sensitive measures, investigating at
the same time the effect of attribute-set size, training-corpus size,
lemmatization, and stop lists, issues that have not been explored in previous
experiments. Finally, the Naive Bayesian filter is compared, in terms of
performance, to a filter that uses keyword patterns, and which is part of a
widely used e-mail reader.
</dc:description>
 <dc:date>2000-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008019</dc:identifier>
 <dc:identifier>Proceedings of the 23rd Annual International ACM SIGIR Conference
  on Research and Development in Information Retrieval, N.J. Belkin, P.
  Ingwersen and M.-K. Leong (Eds.), Athens, Greece, July 24-28, 2000, pages
  160-167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explaining away ambiguity: Learning verb selectional preference with
  Bayesian networks</dc:title>
 <dc:creator>Ciaramita, Massimiliano</dc:creator>
 <dc:creator>Johnson, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper presents a Bayesian model for unsupervised learning of verb
selectional preferences. For each verb the model creates a Bayesian network
whose architecture is determined by the lexical hierarchy of Wordnet and whose
parameters are estimated from a list of verb-object pairs found from a corpus.
``Explaining away'', a well-known property of Bayesian networks, helps the
model deal in a natural fashion with word sense ambiguity in the training data.
On a word sense disambiguation test our model performed better than other state
of the art systems for unsupervised learning of selectional preferences.
Computational complexity problems, ways of improving this approach and methods
for implementing ``explaining away'' in other graphical frameworks are
discussed.
</dc:description>
 <dc:date>2000-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008020</dc:identifier>
 <dc:identifier>Proceedings of the 18th International Conference on Computational
  Linguistics, Saarbrucken, Germany, Vol.1, 2000, p.187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compact non-left-recursive grammars using the selective left-corner
  transform and factoring</dc:title>
 <dc:creator>Johnson, Mark</dc:creator>
 <dc:creator>Roark, Brian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The left-corner transform removes left-recursion from (probabilistic)
context-free grammars and unification grammars, permitting simple top-down
parsing techniques to be used. Unfortunately the grammars produced by the
standard left-corner transform are usually much larger than the original. The
selective left-corner transform described in this paper produces a transformed
grammar which simulates left-corner recognition of a user-specified set of the
original productions, and top-down recognition of the others. Combined with two
factorizations, it produces non-left-recursive grammars that are not much
larger than the original.
</dc:description>
 <dc:description>Comment: 7 pages, 5 tables, 2 figures</dc:description>
 <dc:date>2000-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008021</dc:identifier>
 <dc:identifier>Proceedings of the 18th International Conference on Computational
  Linguistics (COLING), 2000, pages 355-361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Learning Approach to Shallow Parsing</dc:title>
 <dc:creator>Mu&#xf1;oz, Marcia</dc:creator>
 <dc:creator>Punyakanok, Vasin</dc:creator>
 <dc:creator>Roth, Dan</dc:creator>
 <dc:creator>Zimak, Dav</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  A SNoW based learning approach to shallow parsing tasks is presented and
studied experimentally. The approach learns to identify syntactic patterns by
combining simple predictors to produce a coherent inference. Two instantiations
of this approach are studied and experimental results for Noun-Phrases (NP) and
Subject-Verb (SV) phrases that compare favorably with the best published
results are presented. In doing that, we compare two ways of modeling the
problem of learning to recognize patterns and suggest that shallow parsing
patterns are better learned using open/close predictors than using
inside/outside predictors.
</dc:description>
 <dc:description>Comment: LaTex 2e, 11 pages, 2 eps figures, 1 bbl file, uses colacl.sty</dc:description>
 <dc:date>2000-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008022</dc:identifier>
 <dc:identifier>Proceedings of EMNLP-VLC'99, pages 168-178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Selectional Restrictions in HPSG</dc:title>
 <dc:creator>Androutsopoulos, Ion</dc:creator>
 <dc:creator>Dale, Robert</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Selectional restrictions are semantic sortal constraints imposed on the
participants of linguistic constructions to capture contextually-dependent
constraints on interpretation. Despite their limitations, selectional
restrictions have proven very useful in natural language applications, where
they have been used frequently in word sense disambiguation, syntactic
disambiguation, and anaphora resolution. Given their practical value, we
explore two methods to incorporate selectional restrictions in the HPSG theory,
assuming that the reader is familiar with HPSG. The first method employs HPSG's
Background feature and a constraint-satisfaction component pipe-lined after the
parser. The second method uses subsorts of referential indices, and blocks
readings that violate selectional restrictions during parsing. While
theoretically less satisfactory, we have found the second method particularly
useful in the development of practical systems.
</dc:description>
 <dc:date>2000-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008023</dc:identifier>
 <dc:identifier>Proceedings of the 18th International Conference on Computational
  Linguistics (COLING), Saarbrucken, Germany, 31 July - 4 August 2000, pages
  15-20</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation of Stochastic Attribute-Value Grammars using an Informative
  Sample</dc:title>
 <dc:creator>Osborne, Miles</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  We argue that some of the computational complexity associated with estimation
of stochastic attribute-value grammars can be reduced by training upon an
informative subset of the full training set. Results using the parsed Wall
Street Journal corpus show that in some circumstances, it is possible to obtain
better estimation results using an informative sample than when training upon
all the available material. Further experimentation demonstrates that with
unlexicalised models, a Gaussian Prior can reduce overfitting. However, when
models are lexicalised and contain overlapping features, overfitting does not
seem to be a problem, and a Gaussian Prior makes minimal difference to
performance. Our approach is applicable for situations when there are an
infeasibly large number of parses in the training set, or else for when
recovery of these parses from a packed representation is itself computationally
expensive.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures. Coling 2000, Saarbr\&quot;{u}cken, Germany. pp
  586--592</dc:description>
 <dc:date>2000-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008024</dc:identifier>
 <dc:identifier>Coling 2000, Saarbr\&quot;{u}cken, Germany. pp 586--592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phutball Endgames are Hard</dc:title>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Demaine, Martin L.</dc:creator>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>F.1.3,K.8.0</dc:subject>
 <dc:description>  We show that, in John Conway's board game Phutball (or Philosopher's
Football), it is NP-complete to determine whether the current player has a move
that immediately wins the game. In contrast, the similar problems of
determining whether there is an immediately winning move in checkers, or a move
that kings a man, are both solvable in polynomial time.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures. Revised to include additional references on the
  complexity of checkers</dc:description>
 <dc:date>2000-08-23</dc:date>
 <dc:date>2001-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008025</dc:identifier>
 <dc:identifier>More Games of No Chance, MSRI Publications 42, 2002, pp. 351-360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noun-phrase co-occurrence statistics for semi-automatic semantic lexicon
  construction</dc:title>
 <dc:creator>Roark, Brian</dc:creator>
 <dc:creator>Charniak, Eugene</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Generating semantic lexicons semi-automatically could be a great time saver,
relative to creating them by hand. In this paper, we present an algorithm for
extracting potential entries for a category from an on-line corpus, based upon
a small set of exemplars. Our algorithm finds more correct terms and fewer
incorrect ones than previous work in this area. Additionally, the entries that
are generated potentially provide broader coverage of the category than would
occur to an individual coding them by hand. Our algorithm finds many terms not
included within Wordnet (many more than previous algorithms), and could be
viewed as an ``enhancer'' of existing broad-coverage resources.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure, 5 tables</dc:description>
 <dc:date>2000-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008026</dc:identifier>
 <dc:identifier>Proceedings of the 36th Annual Meeting of the Association for
  Computational Linguistics and 17th International Conference on Computational
  Linguistics (COLING-ACL), 1998, pages 1110-1116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring efficiency in high-accuracy, broad-coverage statistical
  parsing</dc:title>
 <dc:creator>Roark, Brian</dc:creator>
 <dc:creator>Charniak, Eugene</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Very little attention has been paid to the comparison of efficiency between
high accuracy statistical parsers. This paper proposes one machine-independent
metric that is general enough to allow comparisons across very different
parsing architectures. This metric, which we call ``events considered'',
measures the number of ``events'', however they are defined for a particular
parser, for which a probability must be calculated, in order to find the parse.
It is applicable to single-pass or multi-stage parsers. We discuss the
advantages of the metric, and demonstrate its usefulness by using it to compare
two parsers which differ in several fundamental ways.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2000-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008027</dc:identifier>
 <dc:identifier>Proceedings of the COLING 2000 Workshop on Efficiency in
  Large-Scale Parsing Systems, 2000, pages 29-36</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimators for Stochastic ``Unification-Based'' Grammars</dc:title>
 <dc:creator>Johnson, Mark</dc:creator>
 <dc:creator>Geman, Stuart</dc:creator>
 <dc:creator>Canon, Stephen</dc:creator>
 <dc:creator>Chi, Zhiyi</dc:creator>
 <dc:creator>Riezler, Stefan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Log-linear models provide a statistically sound framework for Stochastic
``Unification-Based'' Grammars (SUBGs) and stochastic versions of other kinds
of grammars. We describe two computationally-tractable ways of estimating the
parameters of such grammars from a training corpus of syntactic analyses, and
apply these to estimate a stochastic version of Lexical-Functional Grammar.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2000-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008028</dc:identifier>
 <dc:identifier>Proc 37th Annual Conference of the Association for Computational
  Linguistics, 1999, pages 535-541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting auxiliary distributions in stochastic unification-based
  grammars</dc:title>
 <dc:creator>Johnson, Mark</dc:creator>
 <dc:creator>Riezler, Stefan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper describes a method for estimating conditional probability
distributions over the parses of ``unification-based'' grammars which can
utilize auxiliary distributions that are estimated by other means. We show how
this can be used to incorporate information about lexical selectional
preferences gathered from other sources into Stochastic ``Unification-based''
Grammars (SUBGs). While we apply this estimator to a Stochastic
Lexical-Functional Grammar, the method is general, and should be applicable to
stochastic versions of HPSGs, categorial grammars and transformational
grammars.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2000-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008029</dc:identifier>
 <dc:identifier>Proc 1st NAACL, 2000, pages 154-161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Metonymy Interpretation Using X NO Y Examples</dc:title>
 <dc:creator>Murata, Masaki</dc:creator>
 <dc:creator>Ma, Qing</dc:creator>
 <dc:creator>Yamamoto, Atsumu</dc:creator>
 <dc:creator>Isahara, Hitoshi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We developed on example-based method of metonymy interpretation. One
advantages of this method is that a hand-built database of metonymy is not
necessary because it instead uses examples in the form ``Noun X no Noun Y (Noun
Y of Noun X).'' Another advantage is that we will be able to interpret
newly-coined metonymic sentences by using a new corpus. We experimented with
metonymy interpretation and obtained a precision rate of 66% when using this
method.
</dc:description>
 <dc:description>Comment: 8 pages. Computation and Language</dc:description>
 <dc:date>2000-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008030</dc:identifier>
 <dc:identifier>SNLP2000, Chiang Mai, Thailand, May 10, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bunsetsu Identification Using Category-Exclusive Rules</dc:title>
 <dc:creator>Murata, Masaki</dc:creator>
 <dc:creator>Uchimoto, Kiyotaka</dc:creator>
 <dc:creator>Ma, Qing</dc:creator>
 <dc:creator>Isahara, Hitoshi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper describes two new bunsetsu identification methods using supervised
learning. Since Japanese syntactic analysis is usually done after bunsetsu
identification, bunsetsu identification is important for analyzing Japanese
sentences. In experiments comparing the four previously available
machine-learning methods (decision tree, maximum-entropy method, example-based
approach and decision list) and two new methods using category-exclusive rules,
the new method using the category-exclusive rules with the highest similarity
performed best.
</dc:description>
 <dc:description>Comment: 7 pages. Computation and Language</dc:description>
 <dc:date>2000-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008031</dc:identifier>
 <dc:identifier>COLING'2000, Saarbrucken, Germany, August, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008032</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Japanese Probabilistic Information Retrieval Using Location and Category
  Information</dc:title>
 <dc:creator>Murata, Masaki</dc:creator>
 <dc:creator>Ma, Qing</dc:creator>
 <dc:creator>Uchimoto, Kiyotaka</dc:creator>
 <dc:creator>Ozaku, Hiromi</dc:creator>
 <dc:creator>Utiyama, Masao</dc:creator>
 <dc:creator>Isahara, Hitoshi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Robertson's 2-poisson information retrieve model does not use location and
category information. We constructed a framework using location and category
information in a 2-poisson model. We submitted two systems based on this
framework to the IREX contest, Japanese language information retrieval contest
held in Japan in 1999. For precision in the A-judgement measure they scored
0.4926 and 0.4827, the highest values among the 15 teams and 22 systems that
participated in the IREX contest. We describe our systems and the comparative
experiments done when various parameters were changed. These experiments
confirmed the effectiveness of using location and category information.
</dc:description>
 <dc:description>Comment: 7,8 pages. Computation and Language. IRAL'2000, Hong Kong, September
  30, 2000</dc:description>
 <dc:date>2000-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Expressions in Japanese-to-English Machine Translation</dc:title>
 <dc:creator>Bond, Francis</dc:creator>
 <dc:creator>Ogura, Kentaro</dc:creator>
 <dc:creator>Uchino, Hajime</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper describes in outline a method for translating Japanese temporal
expressions into English. We argue that temporal expressions form a special
subset of language that is best handled as a special module in machine
translation. The paper deals with problems of lexical idiosyncrasy as well as
the choice of articles and prepositions within temporal expressions. In
addition temporal expressions are considered as parts of larger structures, and
the question of whether to translate them as noun phrases or adverbials is
addressed.
</dc:description>
 <dc:description>Comment: 8 pages, slightly reformatted to avoid obscure style file</dc:description>
 <dc:date>2000-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008033</dc:identifier>
 <dc:identifier>Seventh International Conference on Theoretical and Methodological
  Issues in Machine Translation: TMI-97, Santa Fe, July 1997, pp 55--62</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lexicalized Stochastic Modeling of Constraint-Based Grammars using
  Log-Linear Measures and EM Training</dc:title>
 <dc:creator>Riezler, Stefan</dc:creator>
 <dc:creator>Prescher, Detlef</dc:creator>
 <dc:creator>Kuhn, Jonas</dc:creator>
 <dc:creator>Johnson, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We present a new approach to stochastic modeling of constraint-based grammars
that is based on log-linear models and uses EM for estimation from unannotated
data. The techniques are applied to an LFG grammar for German. Evaluation on an
exact match task yields 86% precision for an ambiguity rate of 5.4, and 90%
precision on a subcat frame match for an ambiguity rate of 25. Experimental
comparison to training from a parsebank shows a 10% gain from EM training.
Also, a new class-based grammar lexicalization is presented, showing a 10% gain
over unlexicalized models.
</dc:description>
 <dc:description>Comment: 8 pages, uses acl2000.sty</dc:description>
 <dc:date>2000-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008034</dc:identifier>
 <dc:identifier>Proceedings of the 38th Annual Meeting of the ACL, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using a Probabilistic Class-Based Lexicon for Lexical Ambiguity
  Resolution</dc:title>
 <dc:creator>Prescher, Detlef</dc:creator>
 <dc:creator>Riezler, Stefan</dc:creator>
 <dc:creator>Rooth, Mats</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.6, I.2.7</dc:subject>
 <dc:description>  This paper presents the use of probabilistic class-based lexica for
disambiguation in target-word selection. Our method employs minimal but precise
contextual information for disambiguation. That is, only information provided
by the target-verb, enriched by the condensed information of a probabilistic
class-based lexicon, is used. Induction of classes and fine-tuning to verbal
arguments is done in an unsupervised manner by EM-based clustering techniques.
The method shows promising results in an evaluation on real-world translations.
</dc:description>
 <dc:description>Comment: 7 pages, uses colacl.sty</dc:description>
 <dc:date>2000-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008035</dc:identifier>
 <dc:identifier>Proceedings of the 18th COLING, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0008036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Constraint Logic Programming. Formal Foundations of
  Quantitative and Statistical Inference in Constraint-Based Natural Language
  Processing</dc:title>
 <dc:creator>Riezler, Stefan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  In this thesis, we present two approaches to a rigorous mathematical and
algorithmic foundation of quantitative and statistical inference in
constraint-based natural language processing. The first approach, called
quantitative constraint logic programming, is conceptualized in a clear logical
framework, and presents a sound and complete system of quantitative inference
for definite clauses annotated with subjective weights. This approach combines
a rigorous formal semantics for quantitative inference based on subjective
weights with efficient weight-based pruning for constraint-based systems. The
second approach, called probabilistic constraint logic programming, introduces
a log-linear probability distribution on the proof trees of a constraint logic
program and an algorithm for statistical inference of the parameters and
properties of such probability models from incomplete, i.e., unparsed data. The
possibility of defining arbitrary properties of proof trees as properties of
the log-linear probability model and efficiently estimating appropriate
parameter values for them permits the probabilistic modeling of arbitrary
context-dependencies in constraint logic programs. The usefulness of these
ideas is evaluated empirically in a small-scale experiment on finding the
correct parses of a constraint-based grammar. In addition, we address the
problem of computational intractability of the calculation of expectations in
the inference task and present various techniques to approximately solve this
task. Moreover, we present an approximate heuristic technique for searching for
the most probable analysis in probabilistic constraint logic programs.
</dc:description>
 <dc:description>Comment: PhD Thesis, 144 pages, University of Tuebingen, 1998</dc:description>
 <dc:date>2000-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0008036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complexity analysis for algorithmically simple strings</dc:title>
 <dc:creator>Soklakov, Andrei N.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:description>  Given a reference computer, Kolmogorov complexity is a well defined function
on all binary strings. In the standard approach, however, only the asymptotic
properties of such functions are considered because they do not depend on the
reference computer. We argue that this approach can be more useful if it is
refined to include an important practical case of simple binary strings.
Kolmogorov complexity calculus may be developed for this case if we restrict
the class of available reference computers. The interesting problem is to
define a class of computers which is restricted in a {\it natural} way modeling
the real-life situation where only a limited class of computers is physically
available to us. We give an example of what such a natural restriction might
look like mathematically, and show that under such restrictions some error
terms, even logarithmic in complexity, can disappear from the standard
complexity calculus.
  Keywords: Kolmogorov complexity; Algorithmic information theory.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2000-09-05</dc:date>
 <dc:date>2002-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Succinct quantum proofs for properties of finite groups</dc:title>
 <dc:creator>Watrous, John</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:description>  In this paper we consider a quantum computational variant of nondeterminism
based on the notion of a quantum proof, which is a quantum state that plays a
role similar to a certificate in an NP-type proof. Specifically, we consider
quantum proofs for properties of black-box groups, which are finite groups
whose elements are encoded as strings of a given length and whose group
operations are performed by a group oracle. We prove that for an arbitrary
group oracle there exist succinct (polynomial-length) quantum proofs for the
Group Non-Membership problem that can be checked with small error in polynomial
time on a quantum computer. Classically this is impossible--it is proved that
there exists a group oracle relative to which this problem does not have
succinct proofs that can be checked classically with bounded error in
polynomial time (i.e., the problem is not in MA relative to the group oracle
constructed). By considering a certain subproblem of the Group Non-Membership
problem we obtain a simple proof that there exists an oracle relative to which
BQP is not contained in MA. Finally, we show that quantum proofs for
non-membership and classical proofs for various other group properties can be
combined to yield succinct quantum proofs for other group properties not having
succinct proofs in the classical setting, such as verifying that a number
divides the order of a group and verifying that a group is not a simple group.
</dc:description>
 <dc:description>Comment: 16 pages, to appear in FOCS'00</dc:description>
 <dc:date>2000-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Extraction of Subcategorization Frames for Czech</dc:title>
 <dc:creator>Sarkar, Anoop</dc:creator>
 <dc:creator>Zeman, Daniel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7, G.3</dc:subject>
 <dc:description>  We present some novel machine learning techniques for the identification of
subcategorization information for verbs in Czech. We compare three different
statistical techniques applied to this problem. We show how the learning
algorithm can be used to discover previously unknown subcategorization frames
from the Czech Prague Dependency Treebank. The algorithm can then be used to
label dependents of a verb in the Czech treebank as either arguments or
adjuncts. Using our techniques, we ar able to achieve 88% precision on unseen
parsed text.
</dc:description>
 <dc:description>Comment: 7 pages. Another version under the name &quot;Learning Verb
  Subcategorization from Corpora: Counting Frame Subsets&quot;, authors: Zeman,
  Sarkar, in proceedings of LREC 2000, Athens, Greece</dc:description>
 <dc:date>2000-09-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009003</dc:identifier>
 <dc:identifier>Proceedings of the 18th International Conference on Computational
  Linguistics (Coling 2000), Universit</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A usage based analysis of CoRR</dc:title>
 <dc:creator>Carr, Les</dc:creator>
 <dc:creator>Hitchcock, Steve</dc:creator>
 <dc:creator>Hall, Wendy</dc:creator>
 <dc:creator>Harnad, Stevan</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>H.4.3</dc:subject>
 <dc:description>  Based on an empirical analysis of author usage of CoRR, and of its
predecessor in the Los Alamos eprint archives, it is shown that CoRR has not
yet been able to match the early growth of the Los Alamos physics archives.
Some of the reasons are implicit in Halpern's paper, and we explore them
further here. In particular we refer to the need to promote CoRR more
effectively for its intended community - computer scientists in universities,
industrial research labs and in government. We take up some points of detail on
this new world of open archiving concerning central versus distributed
self-archiving, publication, the restructuring of the journal publishers'
niche, peer review and copyright.
</dc:description>
 <dc:description>Comment: This is a commentary on &quot;CoRR: A Computing Research Repository&quot; by
  Joseph Y. Halpern (cs.DL/0005003). See also Halpern's response to this and
  other commentaries (cs.DL/0005004)</dc:description>
 <dc:date>2000-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009004</dc:identifier>
 <dc:identifier>ACM Journal of Computer Documentation, Vol. 24, No. 2, May 2000,
  54-59</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009005</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Approximation of Centrality</dc:title>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:creator>Wang, Joseph</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Social studies researchers use graphs to model group activities in social
networks. An important property in this context is the centrality of a vertex:
the inverse of the average distance to each other vertex. We describe a
randomized approximation algorithm for centrality in weighted graphs. For
graphs exhibiting the small world phenomenon, our method estimates the
centrality of all vertices with high probability within a (1+epsilon) factor in
near-linear time.
</dc:description>
 <dc:description>Comment: 2 pages. To appear in 12th ACM/SIAM Symp. Discrete Algorithms (SODA
  2001)</dc:description>
 <dc:date>2000-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009005</dc:identifier>
 <dc:identifier>J. Graph Algorithms &amp; Applications 8(1):27-38, 2004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Algorithms for 3-Coloring, 3-Edge-Coloring, and Constraint
  Satisfaction</dc:title>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We consider worst case time bounds for NP-complete problems including 3-SAT,
3-coloring, 3-edge-coloring, and 3-list-coloring. Our algorithms are based on a
constraint satisfaction (CSP) formulation of these problems; 3-SAT is
equivalent to (2,3)-CSP while the other problems above are special cases of
(3,2)-CSP. We give a fast algorithm for (3,2)-CSP and use it to improve the
time bounds for solving the other problems listed above. Our techniques involve
a mixture of Davis-Putnam-style backtracking with more sophisticated matching
and network flow based ideas.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures. To appear in 12th ACM/SIAM Symp. Discrete
  Algorithms (SODA 2001). This extended abstract summarizes results from
  cs.DS/0006046 &quot;3-coloring in time O(1.3289^n)&quot; (with Richard Beigel) that
  were found after our FOCS 1995 paper on the same subject</dc:description>
 <dc:date>2000-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Classification for Imprecise Environments</dc:title>
 <dc:creator>Provost, Foster</dc:creator>
 <dc:creator>Fawcett, Tom</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  In real-world environments it usually is difficult to specify target
operating conditions precisely, for example, target misclassification costs.
This uncertainty makes building robust classification systems problematic. We
show that it is possible to build a hybrid classifier that will perform at
least as well as the best available classifier for any target conditions. In
some cases, the performance of the hybrid actually can surpass that of the best
known classifier. This robust performance extends across a wide variety of
comparison frameworks, including the optimization of metrics such as accuracy,
expected cost, lift, precision, recall, and workforce utilization. The hybrid
also is efficient to build, to store, and to update. The hybrid is based on a
method for the comparison of classifier performance that is robust to imprecise
class distributions and misclassification costs. The ROC convex hull (ROCCH)
method combines techniques from ROC analysis, decision analysis and
computational geometry, and adapts them to the particulars of analyzing learned
classifiers. The method is efficient and incremental, minimizes the management
of classifier performance data, and allows for clear visual comparisons and
sensitivity analyses. Finally, we point to empirical evidence that a robust
hybrid classifier indeed is needed for many real-world problems.
</dc:description>
 <dc:description>Comment: 24 pages, 12 figures. To be published in Machine Learning Journal.
  For related papers, see http://www.hpl.hp.com/personal/Tom_Fawcett/ROCCH/</dc:description>
 <dc:date>2000-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introduction to the CoNLL-2000 Shared Task: Chunking</dc:title>
 <dc:creator>Sang, Erik F. Tjong Kim</dc:creator>
 <dc:creator>Buchholz, Sabine</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We describe the CoNLL-2000 shared task: dividing text into syntactically
related non-overlapping groups of words, so-called text chunking. We give
background information on the data sets, present a general overview of the
systems that have taken part in the shared task and briefly discuss their
performance.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2000-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009008</dc:identifier>
 <dc:identifier>Proceedings of CoNLL-2000 and LLL-2000, Lisbon, Portugal</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Filter Spam E-Mail: A Comparison of a Naive Bayesian and a
  Memory-Based Approach</dc:title>
 <dc:creator>Androutsopoulos, Ion</dc:creator>
 <dc:creator>Paliouras, Georgios</dc:creator>
 <dc:creator>Karkaletsis, Vangelis</dc:creator>
 <dc:creator>Sakkis, Georgios</dc:creator>
 <dc:creator>Spyropoulos, Constantine D.</dc:creator>
 <dc:creator>Stamatopoulos, Panagiotis</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>H.4.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:subject>K.4.1</dc:subject>
 <dc:description>  We investigate the performance of two machine learning algorithms in the
context of anti-spam filtering. The increasing volume of unsolicited bulk
e-mail (spam) has generated a need for reliable anti-spam filters. Filters of
this type have so far been based mostly on keyword patterns that are
constructed by hand and perform poorly. The Naive Bayesian classifier has
recently been suggested as an effective method to construct automatically
anti-spam filters with superior performance. We investigate thoroughly the
performance of the Naive Bayesian filter on a publicly available corpus,
contributing towards standard benchmarks. At the same time, we compare the
performance of the Naive Bayesian filter to an alternative memory-based
learning approach, after introducing suitable cost-sensitive evaluation
measures. Both methods achieve very accurate spam filtering, outperforming
clearly the keyword-based filter of a widely used e-mail reader.
</dc:description>
 <dc:date>2000-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009009</dc:identifier>
 <dc:identifier>Proceedings of the workshop &quot;Machine Learning and Textual
  Information Access&quot;, 4th European Conference on Principles and Practice of
  Knowledge Discovery in Databases (PKDD-2000), H. Zaragoza, P. Gallinari and
  M. Rajman (Eds.), Lyon, France, September 2000, pp. 1-13</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Crossing Numbers in Quadratic Time</dc:title>
 <dc:creator>Grohe, Martin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We show that for every fixed non-negative integer k there is a quadratic time
algorithm that decides whether a given graph has crossing number at most k and,
if this is the case, computes a drawing of the graph in the plane with at most
k crossings.
</dc:description>
 <dc:date>2000-09-18</dc:date>
 <dc:date>2000-10-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009011</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anaphora Resolution in Japanese Sentences Using Surface Expressions and
  Examples</dc:title>
 <dc:creator>Murata, Masaki</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Anaphora resolution is one of the major problems in natural language
processing. It is also one of the important tasks in machine translation and
man/machine dialogue. We solve the problem by using surface expressions and
examples. Surface expressions are the words in sentences which provide clues
for anaphora resolution. Examples are linguistic data which are actually used
in conversations and texts. The method using surface expressions and examples
is a practical method. This thesis handles almost all kinds of anaphora: i. The
referential property and number of a noun phrase ii. Noun phrase direct
anaphora iii. Noun phrase indirect anaphora iv. Pronoun anaphora v. Verb phrase
ellipsis
</dc:description>
 <dc:description>Comment: 156 pages. Doctoral thesis in Kyoto University, December 1996,
  supervised by M. Nagao</dc:description>
 <dc:date>2000-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Ambiguity in a Multi-Agent System</dc:title>
 <dc:creator>Monz, Christof</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper investigates the formal pragmatics of ambiguous expressions by
modeling ambiguity in a multi-agent system. Such a framework allows us to give
a more refined notion of the kind of information that is conveyed by ambiguous
expressions. We analyze how ambiguity affects the knowledge of the dialog
participants and, especially, what they know about each other after an
ambiguous sentence has been uttered. The agents communicate with each other by
means of a TELL-function, whose application is constrained by an implementation
of some of Grice's maxims. The information states of the multi-agent system
itself are represented as a Kripke structures and TELL is an update function on
those structures. This framework enables us to distinguish between the
information conveyed by ambiguous sentences vs. the information conveyed by
disjunctions, and between semantic ambiguity vs. perceived ambiguity.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2000-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pattern Matching for sets of segments</dc:title>
 <dc:creator>Efrat, Alon</dc:creator>
 <dc:creator>Indyk, Piotr</dc:creator>
 <dc:creator>Venkatasubramanian, Suresh</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  In this paper we present algorithms for a number of problems in geometric
pattern matching where the input consist of a collections of segments in the
plane. Our work consists of two main parts. In the first, we address problems
and measures that relate to collections of orthogonal line segments in the
plane. Such collections arise naturally from problems in mapping buildings and
robot exploration.
  We propose a new measure of segment similarity called a \emph{coverage
measure}, and present efficient algorithms for maximising this measure between
sets of axis-parallel segments under translations. Our algorithms run in time
$O(n^3\polylog n)$ in the general case, and run in time $O(n^2\polylog n)$ for
the case when all segments are horizontal. In addition, we show that when
restricted to translations that are only vertical, the Hausdorff distance
between two sets of horizontal segments can be computed in time roughly
$O(n^{3/2}{\sl polylog}n)$. These algorithms form significant improvements over
the general algorithm of Chew et al. that takes time $O(n^4 \log^2 n)$. In the
second part of this paper we address the problem of matching polygonal chains.
We study the well known \Frd, and present the first algorithm for computing the
\Frd under general translations. Our methods also yield algorithms for
computing a generalization of the \Fr distance, and we also present a simple
approximation algorithm for the \Frd that runs in time $O(n^2\polylog n)$.
</dc:description>
 <dc:description>Comment: To appear in the 12 ACM Symposium on Discrete Algorithms, Jan 2001</dc:description>
 <dc:date>2000-09-19</dc:date>
 <dc:date>2000-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Linguistic and Spatial Information for Document Analysis</dc:title>
 <dc:creator>Aiello, Marco</dc:creator>
 <dc:creator>Monz, Christof</dc:creator>
 <dc:creator>Todoran, Leon</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:subject>H.3.6</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.7</dc:subject>
 <dc:description>  We present a framework to analyze color documents of complex layout. In
addition, no assumption is made on the layout. Our framework combines in a
content-driven bottom-up approach two different sources of information: textual
and spatial. To analyze the text, shallow natural language processing tools,
such as taggers and partial parsers, are used. To infer relations of the
logical layout we resort to a qualitative spatial calculus closely related to
Allen's calculus. We evaluate the system against documents from a color journal
and present the results of extracting the reading order from the journal's
pages. In this case, our analysis is successful as it extracts the intended
reading order from the document.
</dc:description>
 <dc:description>Comment: Appeared in: J. Mariani and D. Harman (Eds.) Proceedings of RIAO'2000
  Content-Based Multimedia Information Access, CID, 2000. pp. 266-275</dc:description>
 <dc:date>2000-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tableaux Calculus for Ambiguous Quantification</dc:title>
 <dc:creator>Monz, Christof</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>F.4.1 I.2.7</dc:subject>
 <dc:description>  Coping with ambiguity has recently received a lot of attention in natural
language processing. Most work focuses on the semantic representation of
ambiguous expressions. In this paper we complement this work in two ways.
First, we provide an entailment relation for a language with ambiguous
expressions. Second, we give a sound and complete tableaux calculus for
reasoning with statements involving ambiguous quantification. The calculus
interleaves partial disambiguation steps with steps in a traditional deductive
process, so as to minimize and postpone branching in the proof process, and
thereby increases its efficiency.
</dc:description>
 <dc:description>Comment: In: H. de Swart (editor). Automated Reasoning with Analytic Tableaux
  and Related Methods, Tableaux'98 LNAI 1397, Springer, 1998, pp. 232-246</dc:description>
 <dc:date>2000-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextual Inference in Computational Semantics</dc:title>
 <dc:creator>Monz, Christof</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  In this paper, an application of automated theorem proving techniques to
computational semantics is considered. In order to compute the presuppositions
of a natural language discourse, several inference tasks arise. Instead of
treating these inferences independently of each other, we show how integrating
techniques from formal approaches to context into deduction can help to compute
presuppositions more efficiently. Contexts are represented as Discourse
Representation Structures and the way they are nested is made explicit. In
addition, a tableau calculus is present which keeps track of contextual
information, and thereby allows to avoid carrying out redundant inference steps
as it happens in approaches that neglect explicit nesting of contexts.
</dc:description>
 <dc:date>2000-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009016</dc:identifier>
 <dc:identifier>In: P. Bouquet, P. Brezillon, L. Serafini, M. Benerecetti, F.
  Castellani (Eds.) 2nd International and Interdisciplinary Conference on
  Modeling and Using Context (CONTEXT'99). Lecture Notes in Artificial
  Intelligence 1688, Springer, 1999, pages 242-255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tableau Calculus for Pronoun Resolution</dc:title>
 <dc:creator>Monz, Christof</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We present a tableau calculus for reasoning in fragments of natural language.
We focus on the problem of pronoun resolution and the way in which it
complicates automated theorem proving for natural language processing. A method
for explicitly manipulating contextual information during deduction is
proposed, where pronouns are resolved against this context during deduction. As
a result, pronoun resolution and deduction can be interleaved in such a way
that pronouns are only resolved if this is licensed by a deduction rule; this
helps us to avoid the combinatorial complexity of total pronoun disambiguation.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2000-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009017</dc:identifier>
 <dc:identifier>In: N.V. Murray (ed.) Automated Reasoning with Analytic Tableaux
  and Related Methods. Lecture Notes in Artificial Intelligence 1617, Springer,
  1999, pages 247-262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Resolution Calculus for Dynamic Semantics</dc:title>
 <dc:creator>Monz, Christof</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper applies resolution theorem proving to natural language semantics.
The aim is to circumvent the computational complexity triggered by natural
language ambiguities like pronoun binding, by interleaving pronoun binding with
resolution deduction. Therefore disambiguation is only applied to expression
that actually occur during derivations.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2000-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009018</dc:identifier>
 <dc:identifier>In: J. Dix, L. Farinas del Cerro, and U. Furbach (eds.) Logics in
  Artificial Intelligence (JELIA'98). Lecture Notes in Artificial Intelligence
  1489, Springer, 1998, pp. 184-198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Presuppositions by Contextual Reasoning</dc:title>
 <dc:creator>Monz, Christof</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper describes how automated deduction methods for natural language
processing can be applied more efficiently by encoding context in a more
elaborate way. Our work is based on formal approaches to context, and we
provide a tableau calculus for contextual reasoning. This is explained by
considering an example from the problem area of presupposition projection.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2000-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009019</dc:identifier>
 <dc:identifier>In: P. Brezillon, R. Turner, J-C. Pomerol and E. Turner (Eds.)
  Proceedings of the AAAI-99 Workshop on Reasoning in Context for AI
  Applications, AAAI Press, 1999, pp. 75-79</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cluster Computing: A High-Performance Contender</dc:title>
 <dc:creator>Baker, Mark</dc:creator>
 <dc:creator>Buyya, Rajkumar</dc:creator>
 <dc:creator>Hyde, Dan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>C0</dc:subject>
 <dc:description>  When you first heard people speak of Piles of PCs, the first thing that came
to mind may have been a cluttered computer room with processors, monitors, and
snarls of cables all around. Collections of computers have undoubtedly become
more sophisticated than in the early days of shared drives and modem
connections. No matter what you call them, Clusters of Workstations (COW),
Networks of Workstations (NOW), Workstation Clusters (WCs), Clusters of PCs
(CoPs), clusters of computers are now filling the processing niche once
occupied by more powerful stand-alone machines. This article discusses the need
for cluster computing technology, Technologies, Components, and Applications,
Supercluster Systems and Issues, The Need for a New Task Force, and Cluster
Computing Educational Resources.
</dc:description>
 <dc:date>2000-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009021</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nimrod/G: An Architecture of a Resource Management and Scheduling System
  in a Global Computational Grid</dc:title>
 <dc:creator>Buyya, Rajkumar</dc:creator>
 <dc:creator>Abramson, David</dc:creator>
 <dc:creator>Giddy, Jon</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C0</dc:subject>
 <dc:description>  The availability of powerful microprocessors and high-speed networks as
commodity components has enabled high performance computing on distributed
systems (wide-area cluster computing). In this environment, as the resources
are usually distributed geographically at various levels (department,
enterprise, or worldwide) there is a great challenge in integrating,
coordinating and presenting them as a single resource to the user; thus forming
a computational grid. Another challenge comes from the distributed ownership of
resources with each resource having its own access policy, cost, and mechanism.
  The proposed Nimrod/G grid-enabled resource management and scheduling system
builds on our earlier work on Nimrod and follows a modular and component-based
architecture enabling extensibility, portability, ease of development, and
interoperability of independently developed components. It uses the Globus
toolkit services and can be easily extended to operate with any other emerging
grid middleware services. It focuses on the management and scheduling of
computations over dynamic resources scattered geographically across the
Internet at department, enterprise, or global level with particular emphasis on
developing scheduling schemes based on the concept of computational economy for
a real test bed, namely, the Globus testbed (GUSTO).
</dc:description>
 <dc:date>2000-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009021</dc:identifier>
 <dc:identifier>HPC Asia 2000, IEEE Press</dc:identifier>
 <dc:identifier>doi:10.1109/HPC.2000.846563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparison between Supervised Learning Algorithms for Word Sense
  Disambiguation</dc:title>
 <dc:creator>Escudero, Gerard</dc:creator>
 <dc:creator>Marquez, Lluis</dc:creator>
 <dc:creator>Rigau, German</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  This paper describes a set of comparative experiments, including cross-corpus
evaluation, between five alternative algorithms for supervised Word Sense
Disambiguation (WSD), namely Naive Bayes, Exemplar-based learning, SNoW,
Decision Lists, and Boosting. Two main conclusions can be drawn: 1) The
LazyBoosting algorithm outperforms the other four state-of-the-art algorithms
in terms of accuracy and ability to tune to new domains; 2) The domain
dependence of WSD systems seems very strong and suggests that some kind of
adaptation or tuning is required for cross-corpus application.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2000-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009022</dc:identifier>
 <dc:identifier>Proceedings of the 4th Conference on Computational Natural
  Language Learning, CoNLL'2000, pp. 31-36</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009023</identifier>
 <datestamp>2011-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Rectilinear Crossing Number of K_10 is 62</dc:title>
 <dc:creator>Brodsky, Alex</dc:creator>
 <dc:creator>Durocher, Stephane</dc:creator>
 <dc:creator>Gethner, Ellen</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  A drawing of a graph G in the plane is said to be a rectilinear drawing of G
if the edges are required to be line segments (as opposed to Jordan curves). We
assume no three vertices are collinear. The rectilinear crossing number of G is
the fewest number of edge crossings attainable over all rectilinear drawings of
G. Thanks to Richard Guy, exact values of the rectilinear crossing number of
K_n, the complete graph on n vertices, for n = 3,...,9, are known (Guy 1972,
White and Beinke 1978, Finch 2000, Sloanes A014540). Since 1971, thanks to the
work of David Singer (1971, Gardiner 1986), the rectilinear crossing number of
K_10 has been known to be either 61 or 62, a deceptively innocent and
tantalizing statement. The difficulty of determining the correct value is
evidenced by the fact that Singer's result has withstood the test of time. In
this paper we use a purely combinatorial argument to show that the rectilinear
crossing number of K_10 is 62. Moreover, using this result, we improve an
asymptotic lower bound for a related problem. Finally, we close with some new
and old open questions that were provoked, in part, by the results of this
paper, and by the tangled history of the problem itself.
</dc:description>
 <dc:description>Comment: 17 Pages, colour figures</dc:description>
 <dc:date>2000-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009023</dc:identifier>
 <dc:identifier>Electronic Journal of Combinatorics. 8(1):R23 1-30. 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing the Depth of a Flat</dc:title>
 <dc:creator>Bern, Marshall</dc:creator>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>g.3</dc:subject>
 <dc:description>  We give algorithms for computing the regression depth of a k-flat for a set
of n points in R^d. The running time is O(n^(d-2) + n log n) when 0 &lt; k &lt; d-1,
faster than the best time bound for hyperplane regression or for data depth.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, 2-page version to appear in ACM/SIAM SODA 2001</dc:description>
 <dc:date>2000-09-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parsing with the Shortest Derivation</dc:title>
 <dc:creator>Bod, Rens</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Common wisdom has it that the bias of stochastic grammars in favor of shorter
derivations of a sentence is harmful and should be redressed. We show that the
common wisdom is wrong for stochastic grammars that use elementary trees
instead of context-free rules, such as Stochastic Tree-Substitution Grammars
used by Data-Oriented Parsing models. For such grammars a non-probabilistic
metric based on the shortest derivation outperforms a probabilistic metric on
the ATIS and OVIS corpora, while it obtains very competitive results on the
Wall Street Journal corpus. This paper also contains the first published
experiments with DOP on the Wall Street Journal.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2000-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009025</dc:identifier>
 <dc:identifier>Proceedings COLING'2000, with a minor correction</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An improved parser for data-oriented lexical-functional analysis</dc:title>
 <dc:creator>Bod, Rens</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We present an LFG-DOP parser which uses fragments from LFG-annotated
sentences to parse new sentences. Experiments with the Verbmobil and Homecentre
corpora show that (1) Viterbi n best search performs about 100 times faster
than Monte Carlo search while both achieve the same accuracy; (2) the DOP
hypothesis which states that parse accuracy increases with increasing fragment
size is confirmed for LFG-DOP; (3) LFG-DOP's relative frequency estimator
performs worse than a discounted frequency estimator; and (4) LFG-DOP
significantly outperforms Tree-DOP is evaluated on tree structures only.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2000-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009026</dc:identifier>
 <dc:identifier>Proceedings ACL'2000, Hong Kong</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Classification Approach to Word Prediction</dc:title>
 <dc:creator>Even-Zohar, Yair</dc:creator>
 <dc:creator>Roth, Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The eventual goal of a language model is to accurately predict the value of a
missing word given its context. We present an approach to word prediction that
is based on learning a representation for each word as a function of words and
linguistics predicates in its context. This approach raises a few new questions
that we address. First, in order to learn good word representations it is
necessary to use an expressive representation of the context. We present a way
that uses external knowledge to generate expressive context representations,
along with a learning method capable of handling the large number of features
generated this way that can, potentially, contribute to each prediction.
Second, since the number of words ``competing'' for each prediction is large,
there is a need to ``focus the attention'' on a smaller subset of these. We
exhibit the contribution of a ``focus of attention'' mechanism to the
performance of the word predictor. Finally, we describe a large scale
experimental study in which the approach presented is shown to yield
significant improvements in word prediction tasks.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2000-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009027</dc:identifier>
 <dc:identifier>NAACL 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009028</identifier>
 <datestamp>2011-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward the Rectilinear Crossing Number of $K_n$: New Drawings, Upper
  Bounds, and Asymptotics</dc:title>
 <dc:creator>Brodsky, Alex</dc:creator>
 <dc:creator>Durocher, Stephane</dc:creator>
 <dc:creator>Gethner, Ellen</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Scheinerman and Wilf (1994) assert that `an important open problem in the
study of graph embeddings is to determine the rectilinear crossing number of
the complete graph K_n.' A rectilinear drawing of K_n is an arrangement of n
vertices in the plane, every pair of which is connected by an edge that is a
line segment. We assume that no three vertices are collinear, and that no three
edges intersect in a point unless that point is an endpoint of all three. The
rectilinear crossing number of K_n is the fewest number of edge crossings
attainable over all rectilinear drawings of K_n.
  For each n we construct a rectilinear drawing of K_n that has the fewest
number of edge crossings and the best asymptotics known to date. Moreover, we
give some alternative infinite families of drawings of K_n with good
asymptotics. Finally, we mention some old and new open problems.
</dc:description>
 <dc:description>Comment: 13 Pages</dc:description>
 <dc:date>2000-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009028</dc:identifier>
 <dc:identifier>Discrete Mathematics. 262(1-3):59-77. 2003</dc:identifier>
 <dc:identifier>doi:10.1016/S0012-365X(02)00491-0</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Concurrent Language Aldwych</dc:title>
 <dc:creator>Huntbach, Matthew</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  Aldwych is proposed as the foundation of a general purpose language for
parallel applications. It works on a rule-based principle, and has aspects
variously of concurrent functional, logic and object-oriented languages, yet it
forms an integrated whole. It is intended to be applicable both for small-scale
parallel programming, and for large-scale open systems.
</dc:description>
 <dc:description>Comment: Presented at RULE 2000, First International Workshop on Rule-Based
  Programming, Montreal, Canada</dc:description>
 <dc:date>2000-09-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0009030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Syntactic Theories to Interpreters: A Specification Language and
  Its Compilation</dc:title>
 <dc:creator>Xiao, Yong</dc:creator>
 <dc:creator>Ariola, Zena M.</dc:creator>
 <dc:creator>Mauny, Michel</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.1</dc:subject>
 <dc:subject>D.1.2</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:description>  Recent years have seen an increasing need of high-level specification
languages and tools generating code from specifications. In this paper, we
introduce a specification language, {\splname}, which is tailored to the
writing of syntactic theories of language semantics. More specifically, the
language supports specifying primitive notions such as dynamic constraints,
contexts, axioms, and inference rules. We also introduce a system which
generates interpreters from {\splname} specifications. A prototype system is
implemented and has been tested on a number of examples, including a syntactic
theory for Verilog.
</dc:description>
 <dc:description>Comment: Accepted in Rule-based Programming Workshop, 2000, 16 pages</dc:description>
 <dc:date>2000-09-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0009030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of an Electro-Hydraulic System Using Neuro-Fuzzy Techniques</dc:title>
 <dc:creator>Branco, P. J. Costa</dc:creator>
 <dc:creator>Dente, J. A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>C.3</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>I.6.5</dc:subject>
 <dc:subject>J.2, J.7</dc:subject>
 <dc:description>  Increasing demands in performance and quality make drive systems fundamental
parts in the progressive automation of industrial processes. Their conventional
models become inappropriate and have limited scope if one requires a precise
and fast performance. So, it is important to incorporate learning capabilities
into drive systems in such a way that they improve their accuracy in realtime,
becoming more autonomous agents with some degree of intelligence. To
investigate this challenge, this chapter presents the development of a learning
control system that uses neuro-fuzzy techniques in the design of a tracking
controller to an experimental electro-hydraulic actuator. We begin the chapter
by presenting the neuro-fuzzy modeling process of the actuator. This part
surveys the learning algorithm, describes the laboratorial system, and presents
the modeling steps as the choice of actuator representative variables, the
acquisition of training and testing data sets, and the acquisition of the
neuro-fuzzy inverse-model of the actuator. In the second part of the chapter,
we use the extracted neuro-fuzzy model and its learning capabilities to design
the actuator position controller based on the feedback-error-learning
technique. Through a set of experimental results, we show the generalization
properties of the controller, its learning capability in actualizing in
realtime the initial neuro-fuzzy inverse-model, and its compensation action
improving the electro-hydraulics tracking performance.
</dc:description>
 <dc:description>Comment: 35 pages</dc:description>
 <dc:date>2000-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010001</dc:identifier>
 <dc:identifier>In: Fusion of Neural Networks, Fuzzy Sets &amp; Genetic Algorithms:
  Industrial Applications, Chapter 4, CRC Press, Boca Raton, Florida, USA.,
  1999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noise Effects in Fuzzy Modelling Systems</dc:title>
 <dc:creator>Branco, P. J. Costa</dc:creator>
 <dc:creator>Dente, J. A.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>I.5.2</dc:subject>
 <dc:description>  Noise is source of ambiguity for fuzzy systems. Although being an important
aspect, the effects of noise in fuzzy modeling have been little investigated.
This paper presents a set of tests using three well-known fuzzy modeling
algorithms. These evaluate perturbations in the extracted rule-bases caused by
noise polluting the learning data, and the corresponding deformations in each
learned functional relation. We present results to show: 1) how these fuzzy
modeling systems deal with noise; 2) how the established fuzzy model structure
influences noise sensitivity of each algorithm; and 3) whose characteristics of
the learning algorithms are relevant to noise attenuation.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2000-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010002</dc:identifier>
 <dc:identifier>In: Computational Intelligence and Applications, pp. 103-108,
  World Scientific and Engineering Society Press, Danvers, USA, 1999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010003</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Torque Ripple Minimization in a Switched Reluctance Drive by Neuro-Fuzzy
  Compensation</dc:title>
 <dc:creator>Henriques, L.</dc:creator>
 <dc:creator>Rolim, L.</dc:creator>
 <dc:creator>Suemitsu, W.</dc:creator>
 <dc:creator>Branco, P. J. Costa</dc:creator>
 <dc:creator>Dente, J. A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Simple power electronic drive circuit and fault tolerance of converter are
specific advantages of SRM drives, but excessive torque ripple has limited its
use to special applications. It is well known that controlling the current
shape adequately can minimize the torque ripple. This paper presents a new
method for shaping the motor currents to minimize the torque ripple, using a
neuro-fuzzy compensator. In the proposed method, a compensating signal is added
to the output of a PI controller, in a current-regulated speed control loop.
Numerical results are presented in this paper, with an analysis of the effects
of changing the form of the membership function of the neuro-fuzzy compensator.
</dc:description>
 <dc:description>Comment: To be published in IEEE Trans. on Magnetics, 2000</dc:description>
 <dc:date>2000-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010003</dc:identifier>
 <dc:identifier>doi:10.1109/20.908911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fuzzy Relational Identification Algorithm and Its Application to
  Predict The Behaviour of a Motor Drive System</dc:title>
 <dc:creator>Branco, P. J. Costa</dc:creator>
 <dc:creator>Dente, J. A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Fuzzy relational identification builds a relational model describing systems
behaviour by a nonlinear mapping between its variables. In this paper, we
propose a new fuzzy relational algorithm based on simplified max-min relational
equation. The algorithm presents an adaptation method applied to gravity-center
of each fuzzy set based on error integral value between measured and predicted
system output, and uses the concept of time-variant universe of discourses. The
identification algorithm also includes a method to attenuate noise influence in
extracted system relational model using a fuzzy filtering mechanism. The
algorithm is applied to one-step forward prediction of a simulated and
experimental motor drive system. The identified model has its input-output
variables (stator-reference current and motor speed signal) treated as fuzzy
sets, whereas the relations existing between them are described by means of a
matrix R defining the relational model extracted by the algorithm. The results
show the good potentialities of the algorithm in predict the behaviour of the
system and attenuate through the fuzzy filtering method possible noise
distortions in the relational model.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2000-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010004</dc:identifier>
 <dc:identifier>In: Fuzzy Sets and Systems, Vol. 109, No. 3, pp. 41-52, Elsevier,
  2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low Ambiguity in Strong, Total, Associative, One-Way Functions</dc:title>
 <dc:creator>Homan, Christopher M.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>f.1.3</dc:subject>
 <dc:description>  Rabi and Sherman present a cryptographic paradigm based on associative,
one-way functions that are strong (i.e., hard to invert even if one of their
arguments is given) and total. Hemaspaandra and Rothe proved that such powerful
one-way functions exist exactly if (standard) one-way functions exist, thus
showing that the associative one-way function approach is as plausible as
previous approaches. In the present paper, we study the degree of ambiguity of
one-way functions. Rabiand Sherman showed that no associative one-way function
(over a universe having at least two elements) can be unambiguous (i.e.,
one-to-one). Nonetheless, we prove that if standard, unambiguous, one-way
functions exist, then there exist strong, total, associative, one-way functions
that are $\mathcal{O}(n)$-to-one. This puts a reasonable upper bound on the
ambiguity.
</dc:description>
 <dc:description>Comment: 18 pages, one tex file, one bbl file</dc:description>
 <dc:date>2000-10-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applications of Data Mining to Electronic Commerce</dc:title>
 <dc:creator>Kohavi, Ron</dc:creator>
 <dc:creator>Provost, Foster</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  Electronic commerce is emerging as the killer domain for data mining
technology.
  The following are five desiderata for success. Seldom are they they all
present in one data mining application.
  1. Data with rich descriptions. For example, wide customer records with many
potentially useful fields allow data mining algorithms to search beyond obvious
correlations.
  2. A large volume of data. The large model spaces corresponding to rich data
demand many training instances to build reliable models.
  3. Controlled and reliable data collection. Manual data entry and integration
from legacy systems both are notoriously problematic; fully automated
collection is considerably better.
  4. The ability to evaluate results. Substantial, demonstrable return on
investment can be very convincing.
  5. Ease of integration with existing processes. Even if pilot studies show
potential benefit, deploying automated solutions to previously manual processes
is rife with pitfalls. Building a system to take advantage of the mined
knowledge can be a substantial undertaking. Furthermore, one often must deal
with social and political issues involved in the automation of a previously
manual business process.
</dc:description>
 <dc:description>Comment: Editorial for special issue</dc:description>
 <dc:date>2000-10-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Theory of Cache-Efficient Algorithms</dc:title>
 <dc:creator>Sen, Sandeep</dc:creator>
 <dc:creator>Chatterjee, Siddhartha</dc:creator>
 <dc:creator>Dumir, Neeraj</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>B.3.2</dc:subject>
 <dc:subject>C.0</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  We describe a model that enables us to analyze the running time of an
algorithm in a computer with a memory hierarchy with limited associativity, in
terms of various cache parameters. Our model, an extension of Aggarwal and
Vitter's I/O model, enables us to establish useful relationships between the
cache complexity and the I/O complexity of computations. As a corollary, we
obtain cache-optimal algorithms for some fundamental problems like sorting,
FFT, and an important subclass of permutations in the single-level cache model.
We also show that ignoring associativity concerns could lead to inferior
performance, by analyzing the average-case cache behavior of mergesort. We
further extend our model to multiple levels of cache with limited associativity
and present optimal algorithms for matrix transpose and sorting. Our techniques
may be used for systematic exploitation of the memory hierarchy starting from
the algorithm design stage, and dealing with the hitherto unresolved problem of
limited associativity.
</dc:description>
 <dc:date>2000-10-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Light Lexicographic path Ordering</dc:title>
 <dc:creator>Cichon, E. A.</dc:creator>
 <dc:creator>Marion, J-Y.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:description>  We introduce syntactic restrictions of the lexicographic path ordering to
obtain the Light Lexicographic Path Ordering. We show that the light
lexicographic path ordering leads to a characterisation of the functions
computable in space bounded by a polynomial in the size of the inputs.
</dc:description>
 <dc:date>2000-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Approach to the Implementation of Overlapping Rules in Standard ML</dc:title>
 <dc:creator>Pucella, Riccardo</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  We describe an approach to programming rule-based systems in Standard ML,
with a focus on so-called overlapping rules, that is rules that can still be
active when other rules are fired. Such rules are useful when implementing
rule-based reactive systems, and to that effect we show a simple implementation
of Loyall's Active Behavior Trees, used to control goal-directed agents in the
Oz virtual environment. We discuss an implementation of our framework using a
reactive library geared towards implementing those kind of systems.
</dc:description>
 <dc:description>Comment: 13 pages. Presented at RULE 2000, First International Workshop on
  Rule-Based Programming, Montreal, Canada</dc:description>
 <dc:date>2000-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010010</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fault Detection using Immune-Based Systems and Formal Language
  Algorithms</dc:title>
 <dc:creator>Martins, J. F.</dc:creator>
 <dc:creator>Branco, P. J. Costa</dc:creator>
 <dc:creator>Pires, A. J.</dc:creator>
 <dc:creator>Dente, J. A.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper describes two approaches for fault detection: an immune-based
mechanism and a formal language algorithm. The first one is based on the
feature of immune systems in distinguish any foreign cell from the body own
cell. The formal language approach assumes the system as a linguistic source
capable of generating a certain language, characterised by a grammar. Each
algorithm has particular characteristics, which are analysed in the paper,
namely in what cases they can be used with advantage. To test their
practicality, both approaches were applied on the problem of fault detection in
an induction motor.
</dc:description>
 <dc:description>Comment: To appear as an Invited paper in IEEE Conference on Decision and
  Control (CDC2000), 6 pages</dc:description>
 <dc:date>2000-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010010</dc:identifier>
 <dc:identifier>doi:10.1109/CDC.2000.914202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010011</identifier>
 <datestamp>2016-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>If P \neq NP then Some Strongly Noninvertible Functions are Invertible</dc:title>
 <dc:creator>Hemaspaandra, Lane A.</dc:creator>
 <dc:creator>Pasanen, Kari</dc:creator>
 <dc:creator>Rothe, J&#xf6;rg</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Rabi, Rivest, and Sherman alter the standard notion of noninvertibility to a
new notion they call strong noninvertibility, and show -- via explicit
cryptographic protocols for secret-key agreement ([RS93,RS97] attribute this to
Rivest and Sherman) and digital signatures [RS93,RS97] -- that strongly
noninvertible functions would be very useful components in protocol design.
Their definition of strong noninvertibility has a small twist (``respecting the
argument given'') that is needed to ensure cryptographic usefulness. In this
paper, we show that this small twist has a large, unexpected consequence:
Unless P=NP, some strongly noninvertible functions are invertible.
</dc:description>
 <dc:description>Comment: Extended and updated version of UR-CS-TR-00-737</dc:description>
 <dc:date>2000-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding consensus in speech recognition: word error minimization and
  other applications of confusion networks</dc:title>
 <dc:creator>Mangu, L.</dc:creator>
 <dc:creator>Brill, E.</dc:creator>
 <dc:creator>Stolcke, A.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We describe a new framework for distilling information from word lattices to
improve the accuracy of speech recognition and obtain a more perspicuous
representation of a set of alternative hypotheses. In the standard MAP decoding
approach the recognizer outputs the string of words corresponding to the path
with the highest posterior probability given the acoustics and a language
model. However, even given optimal models, the MAP decoder does not necessarily
minimize the commonly used performance metric, word error rate (WER). We
describe a method for explicitly minimizing WER by extracting word hypotheses
with the highest posterior probabilities from word lattices. We change the
standard problem formulation by replacing global search over a large set of
sentence hypotheses with local search over a small set of word candidates. In
addition to improving the accuracy of the recognizer, our method produces a new
representation of the set of candidate hypotheses that specifies the sequence
of word-level confusions in a compact lattice format. We study the properties
of confusion networks and examine their use for other tasks, such as lattice
compression, word spotting, confidence annotation, and reevaluation of
recognition hypotheses using higher-level knowledge sources.
</dc:description>
 <dc:description>Comment: 35 pages, 8 figures</dc:description>
 <dc:date>2000-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010012</dc:identifier>
 <dc:identifier>Computer Speech and Language 14(4), 373-400, October 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Public-key based Information Management Model for Mobile Agents</dc:title>
 <dc:creator>Rodriguez, Diego</dc:creator>
 <dc:creator>Sobrado, Igor</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>H.3</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:description>  Mobile code based computing requires development of protection schemes that
allow digital signature and encryption of data collected by the agents in
untrusted hosts. These algorithms could not rely on carrying encryption keys if
these keys could be stolen or used to counterfeit data by hostile hosts and
agents. As a consequence, both information and keys must be protected in a way
that only authorized hosts, that is the host that provides information and the
server that has sent the mobile agent, could modify (by changing or removing)
retrieved data. The data management model proposed in this work allows the
information collected by the agents to be protected against handling by other
hosts in the information network. It has been done by using standard public-key
cryptography modified to support protection of data in distributed environments
without requiring an interactive protocol with the host that has dropped the
agent. Their significance stands on the fact that it is the first model that
supports a full-featured protection of mobile agents allowing remote hosts to
change its own information if required before agent returns to its originating
server.
</dc:description>
 <dc:description>Comment: 7 pages, 0 PostScript figures, uses IEEE/LaTeX macros
  IEEEtran.{bst|cls}</dc:description>
 <dc:date>2000-10-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a cepstrum-based speech detector robust to white noise</dc:title>
 <dc:creator>Skorik, Sergei</dc:creator>
 <dc:creator>Berthommier, Frederic</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.2.1</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:description>  We study effects of additive white noise on the cepstral representation of
speech signals. Distribution of each individual cepstrum coefficient of speech
is shown to depend strongly on noise and to overlap significantly with the
cepstrum distribution of noise. Based on these studies, we suggest a scalar
quantity, V, equal to the sum of weighted cepstral coefficients, which is able
to classify frames containing speech against noise-like frames. The
distributions of V for speech and noise frames are reasonably well separated
above SNR = 5 dB, demonstrating the feasibility of robust speech detector based
on V.
</dc:description>
 <dc:description>Comment: 4 pages pdf format, requires Acrobat Reader v 4.0 or later</dc:description>
 <dc:date>2000-10-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Exponential-Time Completeness of the Circularity Problem for
  Attribute Grammars</dc:title>
 <dc:creator>Wu, Pei-Chi</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>F.4.2</dc:subject>
 <dc:description>  Attribute grammars (AGs) are a formal technique for defining semantics of
programming languages. Existing complexity proofs on the circularity problem of
AGs are based on automata theory, such as writing pushdown acceptor and
alternating Turing machines. They reduced the acceptance problems of above
automata, which are exponential-time (EXPTIME) complete, to the AG circularity
problem. These proofs thus show that the circularity problem is EXPTIME-hard,
at least as hard as the most difficult problems in EXPTIME. However, none has
given a proof for the EXPTIME-completeness of the problem. This paper first
presents an alternating Turing machine for the circularity problem. The
alternating Turing machine requires polynomial space. Thus, the circularity
problem is in EXPTIME and is then EXPTIME-complete.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2000-10-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards rule-based visual programming of generic visual systems</dc:title>
 <dc:creator>Hoffmann, Berthold</dc:creator>
 <dc:creator>Minas, Mark</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.7</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  This paper illustrates how the diagram programming language DiaPlan can be
used to program visual systems. DiaPlan is a visual rule-based language that is
founded on the computational model of graph transformation. The language
supports object-oriented programming since its graphs are hierarchically
structured. Typing allows the shape of these graphs to be specified recursively
in order to increase program security. Thanks to its genericity, DiaPlan allows
to implement systems that represent and manipulate data in arbitrary diagram
notations. The environment for the language exploits the diagram editor
generator DiaGen for providing genericity, and for implementing its user
interface and type checker.
</dc:description>
 <dc:description>Comment: 15 pages, 16 figures contribution to the First International Workshop
  on Rule-Based Programming (RULE'2000), September 19, 2000, Montreal, Canada</dc:description>
 <dc:date>2000-10-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010017</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalization of a 3-D resonator model for the simulation of spherical
  enclosures</dc:title>
 <dc:creator>Rocchesso, Davide</dc:creator>
 <dc:creator>Dutilleux, Pierre</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:description>  A rectangular enclosure has such an even distribution of resonances that it
can be accurately and efficiently modelled using a feedback delay network.
Conversely, a non rectangular shape such as a sphere has a distribution of
resonances that challenges the construction of an efficient model. This work
proposes an extension of the already known feedback delay network structure to
model the resonant properties of a sphere. A specific frequency distribution of
resonances can be approximated, up to a certain frequency, by inserting an
allpass filter of moderate order after each delay line of a feedback delay
network. The structure used for rectangular boxes is therefore augmented with a
set of allpass filters allowing parametric control over the enclosure size and
the boundary properties. This work was motivated by informal listening tests
which have shown that it is possible to identify a basic shape just from the
distribution of its audible resonances.
</dc:description>
 <dc:description>Comment: 39 pages, 16 figures, 6 tables. Accepted for publication in Applied
  Signal Processing</dc:description>
 <dc:date>2000-10-10</dc:date>
 <dc:date>2001-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010017</dc:identifier>
 <dc:identifier>doi:10.1155/S1110865701000105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Internet Packet Filter Management and Rectangle Geometry</dc:title>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:creator>Muthukrishnan, S.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We consider rule sets for internet packet routing and filtering, where each
rule consists of a range of source addresses, a range of destination addresses,
a priority, and an action. A given packet should be handled by the action from
the maximum priority rule that matches its source and destination. We describe
new data structures for quickly finding the rule matching an incoming packet,
in near-linear space, and a new algorithm for determining whether a rule set
contains any conflicts, in time O(n^{3/2}).
</dc:description>
 <dc:description>Comment: 9 pages, 2 figures. To appear at 12th ACM/SIAM Symp. Discrete
  Algorithms (SODA 2001)</dc:description>
 <dc:date>2000-10-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Random Oracle Methodology, Revisited</dc:title>
 <dc:creator>Canetti, Ran</dc:creator>
 <dc:creator>Goldreich, Oded</dc:creator>
 <dc:creator>Halevi, Shai</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:description>  We take a critical look at the relationship between the security of
cryptographic schemes in the Random Oracle Model, and the security of the
schemes that result from implementing the random oracle by so called
&quot;cryptographic hash functions&quot;. The main result of this paper is a negative
one: There exist signature and encryption schemes that are secure in the Random
Oracle Model, but for which any implementation of the random oracle results in
insecure schemes.
  In the process of devising the above schemes, we consider possible
definitions for the notion of a &quot;good implementation&quot; of a random oracle,
pointing out limitations and challenges.
</dc:description>
 <dc:description>Comment: 31 pages</dc:description>
 <dc:date>2000-10-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010019</dc:identifier>
 <dc:identifier>In Proceedings of 30th Annual ACM Symposium on the Theory of
  Computing, pages 209-218, May 1998, ACM</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using existing systems to supplement small amounts of annotated
  grammatical relations training data</dc:title>
 <dc:creator>Yeh, Alexander</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Grammatical relationships (GRs) form an important level of natural language
processing, but different sets of GRs are useful for different purposes.
Therefore, one may often only have time to obtain a small training corpus with
the desired GR annotations. To boost the performance from using such a small
training corpus on a transformation rule learner, we use existing systems that
find related types of annotations.
</dc:description>
 <dc:description>Comment: 7 pages, uses acl2000.sty</dc:description>
 <dc:date>2000-10-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010020</dc:identifier>
 <dc:identifier>38th Annual Meeting of the Association for Computational
  Linguistics (ACL-2000), pages 126-132, Hong Kong, October, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Understanding the Predictability of Stock Markets from the
  Perspective of Computational Complexity</dc:title>
 <dc:creator>Aspnes, James</dc:creator>
 <dc:creator>Fischer, David F.</dc:creator>
 <dc:creator>Fischer, Michael J.</dc:creator>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Kumar, Alok</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>J.1</dc:subject>
 <dc:description>  This paper initiates a study into the century-old issue of market
predictability from the perspective of computational complexity. We develop a
simple agent-based model for a stock market where the agents are traders
equipped with simple trading strategies, and their trades together determine
the stock prices. Computer simulations show that a basic case of this model is
already capable of generating price graphs which are visually similar to the
recent price movements of high tech stocks. In the general model, we prove that
if there are a large number of traders but they employ a relatively small
number of strategies, then there is a polynomial-time algorithm for predicting
future price movements with high accuracy. On the other hand, if the number of
strategies is large, market prediction becomes complete in two new
computational complexity classes CPP and BCPP, which are between P^NP[O(log n)]
and PP. These computational completeness results open up a novel possibility
that the price graph of an actual stock could be sufficiently deterministic for
various prediction goals but appear random to all polynomial-time prediction
algorithms.
</dc:description>
 <dc:description>Comment: The conference version will appear in SODA 2001</dc:description>
 <dc:date>2000-10-14</dc:date>
 <dc:date>2000-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noise-Tolerant Learning, the Parity Problem, and the Statistical Query
  Model</dc:title>
 <dc:creator>Blum, Avrim</dc:creator>
 <dc:creator>Kalai, Adam</dc:creator>
 <dc:creator>Wasserman, Hal</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  We describe a slightly sub-exponential time algorithm for learning parity
functions in the presence of random classification noise. This results in a
polynomial-time algorithm for the case of parity functions that depend on only
the first O(log n log log n) bits of input. This is the first known instance of
an efficient noise-tolerant algorithm for a concept class that is provably not
learnable in the Statistical Query model of Kearns. Thus, we demonstrate that
the set of problems learnable in the statistical query model is a strict subset
of those problems learnable in the presence of noise in the PAC model.
  In coding-theory terms, what we give is a poly(n)-time algorithm for decoding
linear k by n codes in the presence of random noise for the case of k = c log n
loglog n for some c &gt; 0. (The case of k = O(log n) is trivial since one can
just individually check each of the 2^k possible messages and choose the one
that yields the closest codeword.)
  A natural extension of the statistical query model is to allow queries about
statistical properties that involve t-tuples of examples (as opposed to single
examples). The second result of this paper is to show that any class of
functions learnable (strongly or weakly) with t-wise queries for t = O(log n)
is also weakly learnable with standard unary queries. Hence this natural
extension to the statistical query model does not increase the set of weakly
learnable functions.
</dc:description>
 <dc:date>2000-10-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Oracle Complexity and Nontransitivity in Pattern Recognition</dc:title>
 <dc:creator>Bulitko, Vadim</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.5.2</dc:subject>
 <dc:description>  Different mathematical models of recognition processes are known. In the
present paper we consider a pattern recognition algorithm as an oracle
computation on a Turing machine. Such point of view seems to be useful in
pattern recognition as well as in recursion theory. Use of recursion theory in
pattern recognition shows connection between a recognition algorithm comparison
problem and complexity problems of oracle computation. That is because in many
cases we can take into account only the number of sign computations or in other
words volume of oracle information needed. Therefore, the problem of
recognition algorithm preference can be formulated as a complexity optimization
problem of oracle computation. Furthermore, introducing a certain &quot;natural&quot;
preference relation on a set of recognizing algorithms, we discover it to be
nontransitive. This relates to the well known nontransitivity paradox in
probability theory.
  Keywords: Pattern Recognition, Recursion Theory, Nontransitivity, Preference
Relation
</dc:description>
 <dc:date>2000-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring automatic word sense disambiguation with decision lists and
  the Web</dc:title>
 <dc:creator>Agirre, Eneko</dc:creator>
 <dc:creator>Martinez, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The most effective paradigm for word sense disambiguation, supervised
learning, seems to be stuck because of the knowledge acquisition bottleneck. In
this paper we take an in-depth study of the performance of decision lists on
two publicly available corpora and an additional corpus automatically acquired
from the Web, using the fine-grained highly polysemous senses in WordNet.
Decision lists are shown a versatile state-of-the-art technique. The
experiments reveal, among other facts, that SemCor can be an acceptable (0.7
precision for polysemous words) starting point for an all-words system. The
results on the DSO corpus show that for some highly polysemous words 0.7
precision seems to be the current state-of-the-art limit. On the other hand,
independently constructed hand-tagged corpora are not mutually useful, and a
corpus automatically acquired from the Web is shown to fail.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2000-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010024</dc:identifier>
 <dc:identifier>Procedings of the COLING 2000 Workshop on Semantic Annotation and
  Intelligent Content</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extraction of semantic relations from a Basque monolingual dictionary
  using Constraint Grammar</dc:title>
 <dc:creator>Agirre, Eneko</dc:creator>
 <dc:creator>Ansa, Olatz</dc:creator>
 <dc:creator>Arregi, Xabier</dc:creator>
 <dc:creator>Artola, Xabier</dc:creator>
 <dc:creator>de Ilarraza, Arantza Diaz</dc:creator>
 <dc:creator>Lersundi, Mikel</dc:creator>
 <dc:creator>Martinez, David</dc:creator>
 <dc:creator>Sarasola, Kepa</dc:creator>
 <dc:creator>Urizar, Ruben</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper deals with the exploitation of dictionaries for the semi-automatic
construction of lexicons and lexical knowledge bases. The final goal of our
research is to enrich the Basque Lexical Database with semantic information
such as senses, definitions, semantic relations, etc., extracted from a Basque
monolingual dictionary. The work here presented focuses on the extraction of
the semantic relations that best characterise the headword, that is, those of
synonymy, antonymy, hypernymy, and other relations marked by specific relators
and derivation. All nominal, verbal and adjectival entries were treated. Basque
uses morphological inflection to mark case, and therefore semantic relations
have to be inferred from suffixes rather than from prepositions. Our approach
combines a morphological analyser and surface syntax parsing (based on
Constraint Grammar), and has proven very successful for highly inflected
languages such as Basque. Both the effort to write the rules and the actual
processing time of the dictionary have been very low. At present we have
extracted 42,533 relations, leaving only 2,943 (9%) definitions without any
extracted relation. The error rate is extremely low, as only 2.2% of the
extracted relations are wrong.
</dc:description>
 <dc:description>Comment: 11 pages. PostScript format</dc:description>
 <dc:date>2000-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010025</dc:identifier>
 <dc:identifier>Proceedings of EURALEX 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enriching very large ontologies using the WWW</dc:title>
 <dc:creator>Agirre, Eneko</dc:creator>
 <dc:creator>Ansa, Olatz</dc:creator>
 <dc:creator>Hovy, Eduard</dc:creator>
 <dc:creator>Martinez, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper explores the possibility to exploit text on the world wide web in
order to enrich the concepts in existing ontologies. First, a method to
retrieve documents from the WWW related to a concept is described. These
document collections are used 1) to construct topic signatures (lists of
topically related words) for each concept in WordNet, and 2) to build
hierarchical clusters of the concepts (the word senses) that lexicalize a given
word. The overall goal is to overcome two shortcomings of WordNet: the lack of
topical links among concepts, and the proliferation of senses. Topic signatures
are validated on a word sense disambiguation task with good results, which are
improved when the hierarchical clusters are used.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2000-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010026</dc:identifier>
 <dc:identifier>Procedings of the ECAI 2000 Workshop on Ontology Learning</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One Sense per Collocation and Genre/Topic Variations</dc:title>
 <dc:creator>Martinez, David</dc:creator>
 <dc:creator>Agirre, Eneko</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper revisits the one sense per collocation hypothesis using
fine-grained sense distinctions and two different corpora. We show that the
hypothesis is weaker for fine-grained sense distinctions (70% vs. 99% reported
earlier on 2-way ambiguities). We also show that one sense per collocation does
hold across corpora, but that collocations vary from one corpus to the other,
following genre and topic variations. This explains the low results when
performing word sense disambiguation across corpora. In fact, we demonstrate
that when two independent corpora share a related genre/topic, the word sense
disambiguation results would be better. Future work on word sense
disambiguation will have to take into account genre and topic as important
parameters on their models.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2000-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010027</dc:identifier>
 <dc:identifier>Proceedings of the Joint SIGDAT Conference on Empirical Methods in
  Natural Language Processing and Very Large Corpora 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence-Based Abstract Interpretation of Prolog</dc:title>
 <dc:creator>Charlier, Baudouin Le</dc:creator>
 <dc:creator>Rossi, Sabina</dc:creator>
 <dc:creator>Van Hentenryck, Pascal</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2</dc:subject>
 <dc:subject>D.3</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Many abstract interpretation frameworks and analyses for Prolog have been
proposed, which seek to extract information useful for program optimization.
Although motivated by practical considerations, notably making Prolog
competitive with imperative languages, such frameworks fail to capture some of
the control structures of existing implementations of the language.
  In this paper we propose a novel framework for the abstract interpretation of
Prolog which handles the depth-first search rule and the cut operator. It
relies on the notion of substitution sequence to model the result of the
execution of a goal. The framework consists of (i) a denotational concrete
semantics, (ii) a safe abstraction of the concrete semantics defined in terms
of a class of post-fixpoints, and (iii) a generic abstract interpretation
algorithm. We show that traditional abstract domains of substitutions may
easily be adapted to the new framework, and provide experimental evidence of
the effectiveness of our approach. We also show that previous work on
determinacy analysis, that was not expressible by existing abstract
interpretation frameworks, can be seen as an instance of our framework.
</dc:description>
 <dc:description>Comment: 62 pages. To appear in the journal &quot;Theory and Practice of Logic
  Programming&quot;</dc:description>
 <dc:date>2000-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010029</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Modes to Ensure Subject Reduction for Typed Logic Programs with
  Subtyping</dc:title>
 <dc:creator>Smaus, Jan-Georg</dc:creator>
 <dc:creator>Fages, Francois</dc:creator>
 <dc:creator>Deransart, Pierre</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D1.6</dc:subject>
 <dc:subject>D3.3</dc:subject>
 <dc:description>  We consider a general prescriptive type system with parametric polymorphism
and subtyping for logic programs. The property of subject reduction expresses
the consistency of the type system w.r.t. the execution model: if a program is
&quot;well-typed&quot;, then all derivations starting in a &quot;well-typed&quot; goal are again
&quot;well-typed&quot;. It is well-established that without subtyping, this property is
readily obtained for logic programs w.r.t. their standard (untyped) execution
model. Here we give syntactic conditions that ensure subject reduction also in
the presence of general subtyping relations between type constructors. The idea
is to consider logic programs with a fixed dataflow, given by modes.
</dc:description>
 <dc:description>Comment: 27 pages; Research Report of INRIA Rocquencourt, long version of
  paper in FSTTCS 2000 conference, New Delhi</dc:description>
 <dc:date>2000-10-20</dc:date>
 <dc:date>2001-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reduction of Intermediate Alphabets in Finite-State Transducer Cascades</dc:title>
 <dc:creator>Kempe, Andre</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This article describes an algorithm for reducing the intermediate alphabets
in cascades of finite-state transducers (FSTs). Although the method modifies
the component FSTs, there is no change in the overall relation described by the
whole cascade. No additional information or special algorithm, that could
decelerate the processing of input, is required at runtime. Two examples from
Natural Language Processing are used to illustrate the effect of the algorithm
on the sizes of the FSTs and their alphabets. With some FSTs the number of arcs
and symbols shrank considerably.
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures, LaTeX (+ eps)</dc:description>
 <dc:date>2000-10-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010030</dc:identifier>
 <dc:identifier>Proc. TALN 2000, pp. 207-215, Lausanne, Switzerland. October 16-18</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opportunity Cost Algorithms for Combinatorial Auctions</dc:title>
 <dc:creator>Akcoglu, Karhan</dc:creator>
 <dc:creator>Aspnes, James</dc:creator>
 <dc:creator>DasGupta, Bhaskar</dc:creator>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.0</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  Two general algorithms based on opportunity costs are given for approximating
a revenue-maximizing set of bids an auctioneer should accept, in a
combinatorial auction in which each bidder offers a price for some subset of
the available goods and the auctioneer can only accept non-intersecting bids.
Since this problem is difficult even to approximate in general, the algorithms
are most useful when the bids are restricted to be connected node subsets of an
underlying object graph that represents which objects are relevant to each
other. The approximation ratios of the algorithms depend on structural
properties of this graph and are small constants for many interesting families
of object graphs. The running times of the algorithms are linear in the size of
the bid graph, which describes the conflicts between bids. Extensions of the
algorithms allow for efficient processing of additional constraints, such as
budget constraints that associate bids with particular bidders and limit how
many bids from a particular bidder can be accepted.
</dc:description>
 <dc:date>2000-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super Logic Programs</dc:title>
 <dc:creator>Brass, Stefan</dc:creator>
 <dc:creator>Dix, Juergen</dc:creator>
 <dc:creator>Przymusinski, Teodor C.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  The Autoepistemic Logic of Knowledge and Belief (AELB) is a powerful
nonmonotic formalism introduced by Teodor Przymusinski in 1994. In this paper,
we specialize it to a class of theories called `super logic programs'. We argue
that these programs form a natural generalization of standard logic programs.
In particular, they allow disjunctions and default negation of arbibrary
positive objective formulas.
  Our main results are two new and powerful characterizations of the static
semant ics of these programs, one syntactic, and one model-theoretic. The
syntactic fixed point characterization is much simpler than the fixed point
construction of the static semantics for arbitrary AELB theories. The
model-theoretic characterization via Kripke models allows one to construct
finite representations of the inherently infinite static expansions.
  Both characterizations can be used as the basis of algorithms for query
answering under the static semantics. We describe a query-answering interpreter
for super programs which we developed based on the model-theoretic
characterization and which is available on the web.
</dc:description>
 <dc:description>Comment: 47 pages, revised version of the paper submitted 10/2000</dc:description>
 <dc:date>2000-10-25</dc:date>
 <dc:date>2002-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Formal Framework for Linguistic Annotation (revised version)</dc:title>
 <dc:creator>Bird, Steven</dc:creator>
 <dc:creator>Liberman, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>A.1</dc:subject>
 <dc:subject>E.2</dc:subject>
 <dc:subject>H.2.1</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  `Linguistic annotation' covers any descriptive or analytic notations applied
to raw language data. The basic data may be in the form of time functions -
audio, video and/or physiological recordings - or it may be textual. The added
notations may include transcriptions of all sorts (from phonetic features to
discourse structures), part-of-speech and sense tagging, syntactic analysis,
`named entity' identification, co-reference annotation, and so on. While there
are several ongoing efforts to provide formats and tools for such annotations
and to publish annotated linguistic databases, the lack of widely accepted
standards is becoming a critical problem. Proposed standards, to the extent
they exist, have focused on file formats. This paper focuses instead on the
logical structure of linguistic annotations. We survey a wide variety of
existing annotation formats and demonstrate a common conceptual core, the
annotation graph. This provides a formal framework for constructing,
maintaining and searching linguistic annotations, while remaining consistent
with many alternative data structures and file formats.
</dc:description>
 <dc:description>Comment: 29 pages, 20 figures, to appear in Speech Communication, An earlier
  version appeared as cs.CL/9903003</dc:description>
 <dc:date>2000-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Static Analysis Techniques for Equational Logic Programming</dc:title>
 <dc:creator>Verma, Rakesh M.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:description>  An equational logic program is a set of directed equations or rules, which
are used to compute in the obvious way (by replacing equals with ``simpler''
equals). We present static analysis techniques for efficient equational logic
programming, some of which have been implemented in $LR^2$, a laboratory for
developing and evaluating fast, efficient, and practical rewriting techniques.
Two novel features of $LR^2$ are that non-left-linear rules are allowed in most
contexts and it has a tabling option based on the congruence-closure based
algorithm to compute normal forms. Although, the focus of this research is on
the tabling approach some of the techniques are applicable to the untabled
approach as well. Our presentation is in the context of $LR^2$, which is an
interpreter, but some of the techniques apply to compilation as well.
</dc:description>
 <dc:description>Comment: Appeared in 1st ACM SIGPLAN Workshop on Rule-based Programming (RULE
  2000)</dc:description>
 <dc:date>2000-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the Fourth International Workshop on Automated Debugging
  (AADEBUG 2000)</dc:title>
 <dc:creator>Ducasse, M.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Over the past decades automated debugging has seen major achievements.
However, as debugging is by necessity attached to particular programming
paradigms, the results are scattered. The aims of the workshop are to gather
common themes and solutions across programming communities, and to
cross-fertilize ideas. AADEBUG 2000 in Munich follows AADEBUG'93 in Linkoeping,
Sweden; AADEBUG'95 in Saint Malo, France; AADEBUG'97 in Linkoeping, Sweden.
</dc:description>
 <dc:description>Comment: 2 invited talks, 3 articles with demonstration description, 10
  articles, 3 demonstration descriptions, 5 poster abstracts</dc:description>
 <dc:date>2000-10-30</dc:date>
 <dc:date>2001-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lattice Structure and Convergence of a Game of Cards</dc:title>
 <dc:creator>Goles, Eric</dc:creator>
 <dc:creator>Morvan, Michel</dc:creator>
 <dc:creator>Phan, Ha Duong</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  This paper is devoted to the study of the dynamics of a discrete system
related to some self stabilizing protocol on a ring of processors.
</dc:description>
 <dc:description>Comment: 10 pages, 1 figures, submitted. See also:
  http://www.liafa.jussieu.fr/~phan/anglais/public.html</dc:description>
 <dc:date>2000-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the relationship between fuzzy logic and four-valued relevance logic</dc:title>
 <dc:creator>Straccia, Umberto</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  In fuzzy propositional logic, to a proposition a partial truth in [0,1] is
assigned. It is well known that under certain circumstances, fuzzy logic
collapses to classical logic. In this paper, we will show that under dual
conditions, fuzzy logic collapses to four-valued (relevance) logic, where
propositions have truth-value true, false, unknown, or contradiction. As a
consequence, fuzzy entailment may be considered as ``in between'' four-valued
(relevance) entailment and classical entailment.
</dc:description>
 <dc:date>2000-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collecting Graphical Abstract Views of Mercury Program Executions</dc:title>
 <dc:creator>Jahier, Erwan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  A program execution monitor is a program that collects and abstracts
information about program executions. The &quot;collect&quot; operator is a high level,
general purpose primitive which lets users implement their own monitors.
&quot;Collect&quot; is built on top of the Mercury trace. In previous work, we have
demonstrated how this operator can be used to efficiently collect various kinds
of statistics about Mercury program executions. In this article we further
demonstrate the expressive power and effectiveness of &quot;collect&quot; by providing
more monitor examples. In particular, we show how to implement monitors that
generate graphical abstractions of program executions such as proof trees,
control flow graphs and dynamic call graphs. We show how those abstractions can
be easily modified and adapted, since those monitors only require several
dozens of lines of code. Those abstractions are intended to serve as front-ends
of software visualization tools. Although &quot;collect&quot; is currently implemented on
top of the Mercury trace, none of its underlying concepts depend of Mercury and
it can be implemented on top of any tracer for any programming language.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2000-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0010039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Geometry Column 40</dc:title>
 <dc:creator>O'Rourke, Joseph</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  It has recently been established by Below, De Loera, and Richter-Gebert that
finding a minimum size (or even just a small) triangulation of a convex
polyhedron is NP-complete. Their 3SAT-reduction proof is discussed.
</dc:description>
 <dc:description>Comment: 3 pages; 4 figures</dc:description>
 <dc:date>2000-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0010039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Utilizing the World Wide Web as an Encyclopedia: Extracting Term
  Descriptions from Semi-Structured Texts</dc:title>
 <dc:creator>Fujii, Atsushi</dc:creator>
 <dc:creator>Ishikawa, Tetsuya</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  In this paper, we propose a method to extract descriptions of technical terms
from Web pages in order to utilize the World Wide Web as an encyclopedia. We
use linguistic patterns and HTML text structures to extract text fragments
containing term descriptions. We also use a language model to discard
extraneous descriptions, and a clustering method to summarize resultant
descriptions. We show the effectiveness of our method by way of experiments.
</dc:description>
 <dc:description>Comment: 8 pages, 2 Postscript figures</dc:description>
 <dc:date>2000-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011001</dc:identifier>
 <dc:identifier>Proceedings of the 38th Annual Meeting of the Association for
  Computational Linguistics (ACL-2000), pp.488-495, Oct. 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novelty-based Evaluation Method for Information Retrieval</dc:title>
 <dc:creator>Fujii, Atsushi</dc:creator>
 <dc:creator>Ishikawa, Tetsuya</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  In information retrieval research, precision and recall have long been used
to evaluate IR systems. However, given that a number of retrieval systems
resembling one another are already available to the public, it is valuable to
retrieve novel relevant documents, i.e., documents that cannot be retrieved by
those existing systems. In view of this problem, we propose an evaluation
method that favors systems retrieving as many novel documents as possible. We
also used our method to evaluate systems that participated in the IREX
workshop.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2000-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011002</dc:identifier>
 <dc:identifier>Proceedings of the 2nd International Conference on Language
  Resources and Evaluation (LREC-2000), pp.1637-1641, Jun. 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Machine Translation to Two-Stage Cross-Language Information
  Retrieval</dc:title>
 <dc:creator>Fujii, Atsushi</dc:creator>
 <dc:creator>Ishikawa, Tetsuya</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Cross-language information retrieval (CLIR), where queries and documents are
in different languages, needs a translation of queries and/or documents, so as
to standardize both of them into a common representation. For this purpose, the
use of machine translation is an effective approach. However, computational
cost is prohibitive in translating large-scale document collections. To resolve
this problem, we propose a two-stage CLIR method. First, we translate a given
query into the document language, and retrieve a limited number of foreign
documents. Second, we machine translate only those documents into the user
language, and re-rank them based on the translation result. We also show the
effectiveness of our method by way of experiments using Japanese queries and
English technical documents.
</dc:description>
 <dc:description>Comment: 13 pages, 1 Postscript figure</dc:description>
 <dc:date>2000-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011003</dc:identifier>
 <dc:identifier>Proceedings of the 4th Conference of the Association for Machine
  Translation in the Americas (AMTA-2000), pp.13-24, Oct. 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anonymous Oblivious Transfer</dc:title>
 <dc:creator>Mueller-Quade, J.</dc:creator>
 <dc:creator>Imai, H.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>C.2.0</dc:subject>
 <dc:description>  In this short note we want to introduce {\em anonymous oblivious transfer} a
new cryptographic primitive which can be proven to be strictly more powerful
than oblivious transfer. We show that all functions can be robustly realized by
multi party protocols with {\em anonymous oblivious transfer}. No assumption
about possible collusions of cheaters or disruptors have to be made.
Furthermore we shortly discuss how to realize anonymous oblivious transfer with
oblivious broadcast or by quantum cryptography. The protocol of anonymous
oblivious transfer was inspired by a quantum protocol: the anonymous quantum
channel.
</dc:description>
 <dc:description>Comment: 6 pages, some things clearified, especially that a broadcast channel
  is not necessary</dc:description>
 <dc:date>2000-11-04</dc:date>
 <dc:date>2000-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-intrusive on-the-fly data race detection using execution replay</dc:title>
 <dc:creator>Ronsse, Michiel</dc:creator>
 <dc:creator>De Bosschere, Koen</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  This paper presents a practical solution for detecting data races in parallel
programs. The solution consists of a combination of execution replay (RecPlay)
with automatic on-the-fly data race detection. This combination enables us to
perform the data race detection on an unaltered execution (almost no probe
effect). Furthermore, the usage of multilevel bitmaps and snooped matrix clocks
limits the amount of memory used. As the record phase of RecPlay is highly
efficient, there is no need to switch it off, hereby eliminating the
possibility of Heisenbugs because tracing can be left on all the time.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AAdebug 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2000-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Execution replay and debugging</dc:title>
 <dc:creator>Ronsse, Michiel</dc:creator>
 <dc:creator>De Bosschere, Koen</dc:creator>
 <dc:creator>de Kergommeaux, Jacques Chassin</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  As most parallel and distributed programs are internally non-deterministic --
consecutive runs with the same input might result in a different program flow
-- vanilla cyclic debugging techniques as such are useless. In order to use
cyclic debugging tools, we need a tool that records information about an
execution so that it can be replayed for debugging. Because recording
information interferes with the execution, we must limit the amount of
information and keep the processing of the information fast. This paper
contains a survey of existing execution replay techniques and tools.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADebug 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2000-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tree-gram Parsing: Lexical Dependencies and Structural Relations</dc:title>
 <dc:creator>Sima'an, Khalil</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>K.3.2</dc:subject>
 <dc:subject>J.5</dc:subject>
 <dc:description>  This paper explores the kinds of probabilistic relations that are important
in syntactic disambiguation. It proposes that two widely used kinds of
relations, lexical dependencies and structural relations, have complementary
disambiguation capabilities. It presents a new model based on structural
relations, the Tree-gram model, and reports experiments showing that structural
relations should benefit from enrichment by lexical dependencies.
</dc:description>
 <dc:description>Comment: 8 pages. Appeared in Proceedings of the 38th Annual Meeting of the
  Association for Computational Linguistics (ACL'00), Hong Kong, China</dc:description>
 <dc:date>2000-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Lambda-Calculus with letrec, case, constructors and non-determinism</dc:title>
 <dc:creator>Schmidt-Schau&#xdf;, Manfred</dc:creator>
 <dc:creator>Huber, Michael</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:description>  A non-deterministic call-by-need lambda-calculus \calc with case,
constructors, letrec and a (non-deterministic) erratic choice, based on
rewriting rules is investigated. A standard reduction is defined as a variant
of left-most outermost reduction. The semantics is defined by contextual
equivalence of expressions instead of using $\alpha\beta(\eta)$-equivalence. It
is shown that several program transformations are correct, for example all
(deterministic) rules of the calculus, and in addition the rules for garbage
collection, removing indirections and unique copy.
  This shows that the combination of a context lemma and a meta-rewriting on
reductions using complete sets of commuting (forking, resp.) diagrams is a
useful and successful method for providing a semantics of a functional
programming language and proving correctness of program transformations.
</dc:description>
 <dc:date>2000-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Small Maximal Independent Sets and Faster Exact Graph Coloring</dc:title>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We show that, for any n-vertex graph G and integer parameter k, there are at
most 3^{4k-n}4^{n-3k} maximal independent sets I \subset G with |I| &lt;= k, and
that all such sets can be listed in time O(3^{4k-n} 4^{n-3k}). These bounds are
tight when n/4 &lt;= k &lt;= n/3. As a consequence, we show how to compute the exact
chromatic number of a graph in time O((4/3 + 3^{4/3}/4)^n) ~= 2.4150^n,
improving a previous O((1+3^{1/3})^n) ~= 2.4422^n algorithm of Lawler (1976).
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2000-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011009</dc:identifier>
 <dc:identifier>J. Graph Algorithms &amp; Applications 7(2):131-140, 2003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extension Language Automation of Embedded System Debugging</dc:title>
 <dc:creator>Parson, Dale</dc:creator>
 <dc:creator>Schlieder, Bryan</dc:creator>
 <dc:creator>Beatty, Paul</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Embedded systems contain several layers of target processing abstraction.
These layers include electronic circuit, binary machine code, mnemonic assembly
code, and high-level procedural and object-oriented abstractions. Physical and
temporal constraints and artifacts within physically embedded systems make it
impossible for software engineers to operate at a single layer of processor
abstraction. The Luxdbg embedded system debugger exposes these layers to
debugger users, and it adds an additional layer, the extension language layer,
that allows users to extend both the debugger and its target processor
capabilities. Tcl is Luxdbg's extension language. Luxdbg users can apply Tcl to
automate interactive debugging steps, to redirect and to interconnect target
processor input-output facilities, to schedule multiple processor execution, to
log and to react to target processing exceptions, and to automate target system
testing. Inclusion of an extension language like Tcl in a debugger promises
additional advantages for distributed debugging, where debuggers can pass
extension language expressions across computer networks.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADebug 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2000-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Properties of XML Grammars and Languages</dc:title>
 <dc:creator>Berstel, Jean</dc:creator>
 <dc:creator>Boasson, Luc</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>F.4.2</dc:subject>
 <dc:subject>F.4.3</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:description>  XML documents are described by a document type definition (DTD). An
XML-grammar is a formal grammar that captures the syntactic features of a DTD.
We investigate properties of this family of grammars. We show that every
XML-language basically has a unique XML-grammar. We give two characterizations
of languages generated by XML-grammars, one is set-theoretic, the other is by a
kind of saturation property. We investigate decidability problems and prove
that some properties that are undecidable for general context-free languages
become decidable for XML-languages. We also characterize those XML-grammars
that generate regular XML-languages.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2000-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Causes and Explanations: A Structural-Model Approach, Part I: Causes</dc:title>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:creator>Pearl, Judea</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  We propose a new definition of actual cause, using structural equations to
model counterfactuals. We show that the definition yields a plausible and
elegant account of causation that handles well examples which have caused
problems for other definitions and resolves major difficulties in the
traditional account.
</dc:description>
 <dc:description>Comment: Part II of the paper (on Explanation) is also on the arxiv.
  Previously the two parts were submitted as one paper. To appear in the
  British Journal for the Philosophy of Science</dc:description>
 <dc:date>2000-11-07</dc:date>
 <dc:date>2005-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transformation-Based Bottom-Up Computation of the Well-Founded Model</dc:title>
 <dc:creator>Brass, Stefan</dc:creator>
 <dc:creator>Dix, Juergen</dc:creator>
 <dc:creator>Freitag, Burkhard</dc:creator>
 <dc:creator>Zukowski, Ulrich</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  We present a framework for expressing bottom-up algorithms to compute the
well-founded model of non-disjunctive logic programs. Our method is based on
the notion of conditional facts and elementary program transformations studied
by Brass and Dix for disjunctive programs. However, even if we restrict their
framework to nondisjunctive programs, their residual program can grow to
exponential size, whereas for function-free programs our program remainder is
always polynomial in the size of the extensional database (EDB).
  We show that particular orderings of our transformations (we call them
strategies) correspond to well-known computational methods like the alternating
fixpoint approach, the well-founded magic sets method and the magic alternating
fixpoint procedure. However, due to the confluence of our calculi, we come up
with computations of the well-founded model that are provably better than these
methods.
  In contrast to other approaches, our transformation method treats magic set
transformed programs correctly, i.e. it always computes a relevant part of the
well-founded model of the original program.
</dc:description>
 <dc:description>Comment: 43 pages, 3 figures</dc:description>
 <dc:date>2000-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chip-level CMP Modeling and Smart Dummy for HDP and Conformal CVD Films</dc:title>
 <dc:creator>Liu, George Yong</dc:creator>
 <dc:creator>Zhang, Ray F.</dc:creator>
 <dc:creator>Hsu, Kelvin</dc:creator>
 <dc:creator>Camilletti, Lawrence</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>B.7.2</dc:subject>
 <dc:description>  Chip-level CMP modeling is investigated to obtain the post-CMP film profile
thickness across a die from its design layout file and a few film deposition
and CMP parameters. The work covers both HDP and conformal CVD film. The
experimental CMP results agree well with the modeled results. Different
algorithms for filling of dummy structure are compared. A smart algorithm for
dummy filling is presented, which achieves maximal pattern-density uniformity
and CMP planarity.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures; for used software, see
  http://www.cmptechnology.com/</dc:description>
 <dc:date>2000-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011014</dc:identifier>
 <dc:identifier>Proceedings of CMPMIC 99, pp120-127</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Decomposition Theorem for Maximum Weight Bipartite Matchings</dc:title>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Lam, Tak-Wah</dc:creator>
 <dc:creator>Sung, Wing-Kin</dc:creator>
 <dc:creator>Ting, Hing-Fung</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>E1</dc:subject>
 <dc:subject>F2.2</dc:subject>
 <dc:description>  Let G be a bipartite graph with positive integer weights on the edges and
without isolated nodes. Let n, N and W be the node count, the largest edge
weight and the total weight of G. Let k(x,y) be log(x)/log(x^2/y). We present a
new decomposition theorem for maximum weight bipartite matchings and use it to
design an O(sqrt(n)W/k(n,W/N))-time algorithm for computing a maximum weight
matching of G. This algorithm bridges a long-standing gap between the best
known time complexity of computing a maximum weight matching and that of
computing a maximum cardinality matching. Given G and a maximum weight matching
of G, we can further compute the weight of a maximum weight matching of G-{u}
for all nodes u in O(W) time.
</dc:description>
 <dc:description>Comment: The journal version will appear in SIAM Journal on Computing. The
  conference version appeared in ESA 1999</dc:description>
 <dc:date>2000-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing Proxies for Stock Market Indices is Computationally Hard</dc:title>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Tate, Stephen R.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  In this paper, we study the problem of designing proxies (or portfolios) for
various stock market indices based on historical data. We use four different
methods for computing market indices, all of which are formulas used in actual
stock market analysis. For each index, we consider three criteria for designing
the proxy: the proxy must either track the market index, outperform the market
index, or perform within a margin of error of the index while maintaining a low
volatility. In eleven of the twelve cases (all combinations of four indices
with three criteria except the problem of sacrificing return for less
volatility using the price-relative index) we show that the problem is NP-hard,
and hence most likely intractable.
</dc:description>
 <dc:description>Comment: An abstract appeared in the Proceedings of the 10th Annual ACM-SIAM
  Symposium on Discrete Algorithms, 1999</dc:description>
 <dc:date>2000-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Debugging Support for UML Designs</dc:title>
 <dc:creator>Schumann, Johann</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Design of large software systems requires rigorous application of software
engineering methods covering all phases of the software process. Debugging
during the early design phases is extremely important, because late bug-fixes
are expensive.
  In this paper, we describe an approach which facilitates debugging of UML
requirements and designs. The Unified Modeling Language (UML) is a set of
notations for object-orient design of a software system. We have developed an
algorithm which translates requirement specifications in the form of annotated
sequence diagrams into structured statecharts. This algorithm detects conflicts
between sequence diagrams and inconsistencies in the domain knowledge. After
synthesizing statecharts from sequence diagrams, these statecharts usually are
subject to manual modification and refinement. By using the ``backward''
direction of our synthesis algorithm, we are able to map modifications made to
the statechart back into the requirements (sequence diagrams) and check for
conflicts there. Fed back to the user conflicts detected by our algorithm are
the basis for deductive-based debugging of requirements and domain theory in
very early development stages. Our approach allows to generate explanations on
why there is a conflict and which parts of the specifications are affected.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2000-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Buy-and-Hold Strategies for Financial Markets with Bounded Daily
  Returns</dc:title>
 <dc:creator>Chen, Gen-Huey</dc:creator>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Lyuu, Yuh-Dauh</dc:creator>
 <dc:creator>Wong, Hsing-Kuo</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  In the context of investment analysis, we formulate an abstract online
computing problem called a planning game and develop general tools for solving
such a game. We then use the tools to investigate a practical buy-and-hold
trading problem faced by long-term investors in stocks. We obtain the unique
optimal static online algorithm for the problem and determine its exact
competitive ratio. We also compare this algorithm with the popular dollar
averaging strategy using actual market data.
</dc:description>
 <dc:description>Comment: The journal version will appear in SIAM Journal on Computing. A
  preliminary version appeared in Proceedings of the 31st Annual ACM Symposium
  on Theory of Computing, 1999, pages 119--128</dc:description>
 <dc:date>2000-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Moment of Perfect Clarity II: Consequences of Sparse Sets Hard for NP
  with Respect to Weak Reductions</dc:title>
 <dc:creator>Glasser, Christian</dc:creator>
 <dc:creator>Hemaspaandra, Lane A.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:description>  This paper discusses advances, due to the work of Cai, Naik, and Sivakumar
and Glasser, in the complexity class collapses that follow if NP has sparse
hard sets under reductions weaker than (full) truth-table reductions.
</dc:description>
 <dc:description>Comment: 20 pages, 1 table</dc:description>
 <dc:date>2000-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Use of Instrumentation in Grammar Engineering</dc:title>
 <dc:creator>Broeker, Norbert</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  This paper explores the usefulness of a technique from software engineering,
code instrumentation, for the development of large-scale natural language
grammars. Information about the usage of grammar rules in test and corpus
sentences is used to improve grammar and testsuite, as well as adapting a
grammar to a specific genre. Results show that less than half of a
large-coverage grammar for German is actually tested by two large testsuites,
and that 10--30% of testing time is redundant. This methodology applied can be
seen as a re-use of grammar writing knowledge for testsuite compilation.
</dc:description>
 <dc:description>Comment: 7 pages, LaTeX2e, correction includes bibliography</dc:description>
 <dc:date>2000-11-16</dc:date>
 <dc:date>2000-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011020</dc:identifier>
 <dc:identifier>adapted from COLING2000, Saarbruecken/FRG, July31--Aug4 2000,
  pp.118-124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On-the-fly Query-Based Debugging with Examples</dc:title>
 <dc:creator>Lencevicius, Raimondas</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Program errors are hard to find because of the cause-effect gap between the
time when an error occurs and the time when the error becomes apparent to the
programmer. Although debugging techniques such as conditional and data
breakpoints help to find error causes in simple cases, they fail to effectively
bridge the cause-effect gap in many situations. Query-based debuggers offer
programmers an effective tool that provides instant error alert by continuously
checking inter-object relationships while the debugged program is running. To
enable the query-based debugger in the middle of program execution in a
portable way, we propose efficient Java class file instrumentation and discuss
alternative techniques. Although the on-the-fly debugger has a higher overhead
than a dynamic query-based debugger, it offers additional interactive power and
flexibility while maintaining complete portability. To speed up dynamic query
evaluation, our debugger implemented in portable Java uses a combination of
program instrumentation, load-time code generation, query optimization, and
incremental reevaluation. This paper discusses on-the-fly debugging and
demonstrates the query-based debugger application for debugging Java gas tank
applet as well as SPECjvm98 suite applications.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035 14
  pages, 6 figures</dc:description>
 <dc:date>2000-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Apache web server execution tracing using Third Eye</dc:title>
 <dc:creator>Lencevicius, Raimondas</dc:creator>
 <dc:creator>Ran, Alexander</dc:creator>
 <dc:creator>Yairi, Rahav</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Testing of modern software systems that integrate many components developed
by different teams is a difficult task. Third Eye is a framework for tracing
and validating software systems using application domain events. We use formal
descriptions of the constraints between events to identify violations in
execution traces. Third Eye is a flexible and modular framework that can be
used in different products. We present the validation of the Apache Web Server
access policy implementation. The results indicate that our tool is a helpful
addition to software development infrastructure.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035 5
  pages, 2 figures</dc:description>
 <dc:date>2000-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Bidding Algorithms Against Cheating in Multiple-Object Auctions</dc:title>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Qi, Junfeng</dc:creator>
 <dc:creator>Tan, Lei</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  This paper studies some basic problems in a multiple-object auction model
using methodologies from theoretical computer science. We are especially
concerned with situations where an adversary bidder knows the bidding
algorithms of all the other bidders. In the two-bidder case, we derive an
optimal randomized bidding algorithm, by which the disadvantaged bidder can
procure at least half of the auction objects despite the adversary's a priori
knowledge of his algorithm. In the general $k$-bidder case, if the number of
objects is a multiple of $k$, an optimal randomized bidding algorithm is found.
If the $k-1$ disadvantaged bidders employ that same algorithm, each of them can
obtain at least $1/k$ of the objects regardless of the bidding algorithm the
adversary uses. These two algorithms are based on closed-form solutions to
certain multivariate probability distributions. In situations where a
closed-form solution cannot be obtained, we study a restricted class of bidding
algorithms as an approximation to desired optimal algorithms.
</dc:description>
 <dc:date>2000-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011023</dc:identifier>
 <dc:identifier>SIAM Journal on Computing, 28(3):955--969, 1999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for Rewriting Aggregate Queries Using Views</dc:title>
 <dc:creator>Cohen, Sara</dc:creator>
 <dc:creator>Nutt, Werner</dc:creator>
 <dc:creator>Serebrenik, Alexander</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.3</dc:subject>
 <dc:description>  Queries involving aggregation are typical in database applications. One of
the main ideas to optimize the execution of an aggregate query is to reuse
results of previously answered queries. This leads to the problem of rewriting
aggregate queries using views. Due to a lack of theory, algorithms for this
problem were rather ad-hoc. They were sound, but were not proven to be
complete.
  Recently we have given syntactic characterizations for the equivalence of
aggregate queries and applied them to decide when there exist rewritings.
However, these decision procedures do not lend themselves immediately to an
implementation. In this paper, we present practical algorithms for rewriting
queries with $\COUNT$ and $\SUM$. Our algorithms are sound. They are also
complete for important cases. Our techniques can be used to improve well-known
procedures for rewriting non-aggregate queries. These procedures can then be
adapted to obtain algorithms for rewriting queries with $\MIN$ and $\MAX$. The
algorithms presented are a basis for realizing optimizers that rewrite queries
using views.
</dc:description>
 <dc:description>Comment: technical report CW 292 of Katholieke Universiteit Leuven (Short
  version in In Julius Stuller, Jaroslav Pokorn?, Bernhard Thalheim, Yoshifumi
  Masunaga (Eds.): Current Issues in Databases and Information Systems,
  East-European Conference on Advances in Databases and Information Systems
  Held Jointly with International Conference on Database Systems for Advanced
  Applications, ADBIS-DASFAA 2000, Prague, Czech Republic, September 5-8,
  2000.)</dc:description>
 <dc:date>2000-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Termination analysis of logic programs using acceptability with general
  term orders</dc:title>
 <dc:creator>Serebrenik, Alexander</dc:creator>
 <dc:creator>De Schreye, Danny</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  We present a new approach to termination analysis of logic programs. The
essence of the approach is that we make use of general term-orderings (instead
of level mappings), like it is done in transformational approaches to logic
program termination analysis, but that we apply these orderings directly to the
logic program and not to the term-rewrite system obtained through some
transformation. We define some variants of acceptability, based on general
term-orderings, and show how they are equivalent to LD-termination. We develop
a demand driven, constraint-based approach to verify these
acceptability-variants.
  The advantage of the approach over standard acceptability is that in some
cases, where complex level mappings are needed, fairly simple term-orderings
may be easily generated. The advantage over transformational approaches is that
it avoids the transformation step all together.
</dc:description>
 <dc:description>Comment: technical report of K.U.Leuven</dc:description>
 <dc:date>2000-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Can You Fold a Map?</dc:title>
 <dc:creator>Arkin, Esther M.</dc:creator>
 <dc:creator>Bender, Michael A.</dc:creator>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Demaine, Martin L.</dc:creator>
 <dc:creator>Mitchell, Joseph S. B.</dc:creator>
 <dc:creator>Sethia, Saurabh</dc:creator>
 <dc:creator>Skiena, Steven S.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  We explore the following problem: given a collection of creases on a piece of
paper, each assigned a folding direction of mountain or valley, is there a flat
folding by a sequence of simple folds? There are several models of simple
folds; the simplest one-layer simple fold rotates a portion of paper about a
crease in the paper by +-180 degrees. We first consider the analogous questions
in one dimension lower -- bending a segment into a flat object -- which lead to
interesting problems on strings. We develop efficient algorithms for the
recognition of simply foldable 1D crease patterns, and reconstruction of a
sequence of simple folds. Indeed, we prove that a 1D crease pattern is
flat-foldable by any means precisely if it is by a sequence of one-layer simple
folds.
  Next we explore simple foldability in two dimensions, and find a surprising
contrast: ``map'' folding and variants are polynomial, but slight
generalizations are NP-complete. Specifically, we develop a linear-time
algorithm for deciding foldability of an orthogonal crease pattern on a
rectangular piece of paper, and prove that it is (weakly) NP-complete to decide
foldability of (1) an orthogonal crease pattern on a orthogonal piece of paper,
(2) a crease pattern of axis-parallel and diagonal (45-degree) creases on a
square piece of paper, and (3) crease patterns without a mountain/valley
assignment.
</dc:description>
 <dc:description>Comment: 24 pages, 19 figures. Version 3 includes several improvements thanks
  to referees, including formal definitions of simple folds, more figures,
  table summarizing results, new open problems, and additional references</dc:description>
 <dc:date>2000-11-20</dc:date>
 <dc:date>2003-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extended Abstract - Model-Based Debugging of Java Programs</dc:title>
 <dc:creator>Mateis, Cristinel</dc:creator>
 <dc:creator>Stumptner, Markus</dc:creator>
 <dc:creator>Wieland, Dominik</dc:creator>
 <dc:creator>Wotawa, Franz</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Model-based reasoning is a central concept in current research into
intelligent diagnostic systems. It is based on the assumption that sources of
incorrect behavior in technical devices can be located and identified via the
existence of a model describing the basic properties of components of a certain
application domain. When actual data concerning the misbehavior of a system
composed from such components is available, a domain-independent diagnosis
engine can be used to infer which parts of the system contribute to the
observed behavior. This paper describes the application of the model-based
approach to the debugging of Java programs written in a subset of Java. We show
how a simple dependency model can be derived from a program, demonstrate the
use of the model for debugging and reducing the required user interactions,
give a comparison of the functional dependency model with program slicing, and
finally discuss some current research issues.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2000-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Retrieval from Captioned Image Databases Using Natural Language
  Processing</dc:title>
 <dc:creator>Elworthy, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  It might appear that natural language processing should improve the accuracy
of information retrieval systems, by making available a more detailed analysis
of queries and documents. Although past results appear to show that this is not
so, if the focus is shifted to short phrases rather than full documents, the
situation becomes somewhat different. The ANVIL system uses a natural language
technique to obtain high accuracy retrieval of images which have been annotated
with a descriptive textual caption. The natural language techniques also allow
additional contextual information to be derived from the relation between the
query and the caption, which can help users to understand the overall
collection of retrieval results. The techniques have been successfully used in
a information retrieval system which forms both a testbed for research and the
basis of a commercial system.
</dc:description>
 <dc:description>Comment: Proceedings of CIKM 2000</dc:description>
 <dc:date>2000-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Systematic Debugging of Attribute Grammars</dc:title>
 <dc:creator>Ikezoe, Yohei</dc:creator>
 <dc:creator>Sasaki, Akira</dc:creator>
 <dc:creator>Ohshima, Yoshiki</dc:creator>
 <dc:creator>Wakita, Ken</dc:creator>
 <dc:creator>Sassa, Masataka</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Although attribute grammars are commonly used for compiler construction,
little investigation has been conducted on debugging attribute grammars. The
paper proposes two types of systematic debugging methods, an algorithmic
debugging and slice-based debugging, both tailored for attribute grammars. By
means of query-based interaction with the developer, our debugging methods
effectively narrow the potential bug space in the attribute grammar description
and eventually identify the incorrect attribution rule. We have incorporated
this technology in our visual debugging tool called Aki.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2000-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Logic Programming Approaches for Representing and Solving Constraint
  Satisfaction Problems: A Comparison</dc:title>
 <dc:creator>Pelov, Nikolay</dc:creator>
 <dc:creator>De Mot, Emmanuel</dc:creator>
 <dc:creator>Denecker, Marc</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  Many logic programming based approaches can be used to describe and solve
combinatorial search problems. On the one hand there is constraint logic
programming which computes a solution as an answer substitution to a query
containing the variables of the constraint satisfaction problem. On the other
hand there are systems based on stable model semantics, abductive systems, and
first order logic model generators which compute solutions as models of some
theory. This paper compares these different approaches from the point of view
of knowledge representation (how declarative are the programs) and from the
point of view of performance (how good are they at solving typical problems).
</dc:description>
 <dc:description>Comment: 15 pages, 3 eps-figures</dc:description>
 <dc:date>2000-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011030</dc:identifier>
 <dc:identifier>LPAR 2000, Lecture Notes in Artificial Intelligence, vol. 1955,
  Springer, 2000, pp. 225-239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SimLab 1.1, Software for Sensitivity and Uncertainty Analysis, tool for
  sound modelling</dc:title>
 <dc:creator>Giglioli, N.</dc:creator>
 <dc:creator>Saltelli, A.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  The aim of this paper is to present and describe SimLab 1.1 (Simulation
Laboratory for Uncertainty and Sensitivity Analysis) software designed for
Monte Carlo analysis that is based on performing multiple model evaluations
with probabilistically selected model input. The results of these evaluations
are used to determine both the uncertainty in model predictions and the input
variables that drive this uncertainty. This methodology is essential in
situations where a decision has to be taken based on the model results; typical
examples include risk and emergency management systems, financial analysis and
many others. It is also highly recommended as part of model validation, even
where the models are used for diagnostic purposes, as an element of sound model
building. SimLab allows an exploration of the space of possible alternative
model assumptions and structure on the prediction of the model, thereby testing
both the quality of the model and the robustness of the model based inference.
</dc:description>
 <dc:description>Comment: 11 pages, pdf format, to be submitted to JACM</dc:description>
 <dc:date>2000-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Top-down induction of clustering trees</dc:title>
 <dc:creator>Blockeel, Hendrik</dc:creator>
 <dc:creator>De Raedt, Luc</dc:creator>
 <dc:creator>Ramon, Jan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  An approach to clustering is presented that adapts the basic top-down
induction of decision trees method towards clustering. To this aim, it employs
the principles of instance based learning. The resulting methodology is
implemented in the TIC (Top down Induction of Clustering trees) system for
first order clustering. The TIC system employs the first order logical decision
tree representation of the inductive logic programming system Tilde. Various
experiments with TIC are presented, in both propositional and relational
domains.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures</dc:description>
 <dc:date>2000-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011032</dc:identifier>
 <dc:identifier>Machine Learning, Proceedings of the 15th International Conference
  (J. Shavlik, ed.), Morgan Kaufmann, 1998, pp. 55-63</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Web Mining Research: A Survey</dc:title>
 <dc:creator>Kosala, Raymond</dc:creator>
 <dc:creator>Blockeel, Hendrik</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  With the huge amount of information available online, the World Wide Web is a
fertile area for data mining research. The Web mining research is at the cross
road of research from several research communities, such as database,
information retrieval, and within AI, especially the sub-areas of machine
learning and natural language processing. However, there is a lot of confusions
when comparing research efforts from different point of views. In this paper,
we survey the research in the area of Web mining, point out some confusions
regarded the usage of the term Web mining and suggest three Web mining
categories. Then we situate some of the research with respect to these three
categories. We also explore the connection between the Web mining categories
and the related agent paradigm. For the survey, we focus on representation
issues, on the process, on the learning algorithm, and on the application of
the recent works as the criteria. We conclude the paper with some research
issues.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2000-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011033</dc:identifier>
 <dc:identifier>ACM SIGKDD Explorations, 2(1):1-15, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011034</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic interpretation of temporal information by abductive inference</dc:title>
 <dc:creator>Verdoolaege, Sven</dc:creator>
 <dc:creator>Denecker, Marc</dc:creator>
 <dc:creator>Schelkens, Ness</dc:creator>
 <dc:creator>De Schreye, Danny</dc:creator>
 <dc:creator>Van Eynde, Frank</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Besides temporal information explicitly available in verbs and adjuncts, the
temporal interpretation of a text also depends on general world knowledge and
default assumptions. We will present a theory for describing the relation
between, on the one hand, verbs, their tenses and adjuncts and, on the other,
the eventualities and periods of time they represent and their relative
temporal locations.
  The theory is formulated in logic and is a practical implementation of the
concepts described in Ness Schelkens et al. We will show how an abductive
resolution procedure can be used on this representation to extract temporal
information from texts.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2000-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011035</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Abductive reasoning with temporal information</dc:title>
 <dc:creator>Verdoolaege, Sven</dc:creator>
 <dc:creator>Denecker, Marc</dc:creator>
 <dc:creator>Van Eynde, Frank</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Texts in natural language contain a lot of temporal information, both
explicit and implicit. Verbs and temporal adjuncts carry most of the explicit
information, but for a full understanding general world knowledge and default
assumptions have to be taken into account. We will present a theory for
describing the relation between, on the one hand, verbs, their tenses and
adjuncts and, on the other, the eventualities and periods of time they
represent and their relative temporal locations, while allowing interaction
with general world knowledge.
  The theory is formulated in an extension of first order logic and is a
practical implementation of the concepts described in Van Eynde 2001 and
Schelkens et al. 2000. We will show how an abductive resolution procedure can
be used on this representation to extract temporal information from texts. The
theory presented here is an extension of that in Verdoolaege et al. 2000,
adapted to VanEynde 2001, with a simplified and extended analysis of adjuncts
and with more emphasis on how a model can be constructed.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2000-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Termination Analysis of Programs Containing Arithmetic
  Predicates</dc:title>
 <dc:creator>Dershowitz, Nachum</dc:creator>
 <dc:creator>Lindenstrauss, Naomi</dc:creator>
 <dc:creator>Sagiv, Yehoshua</dc:creator>
 <dc:creator>Serebrenik, Alexander</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  For logic programs with arithmetic predicates, showing termination is not
easy, since the usual order for the integers is not well-founded. A new method,
easily incorporated in the TermiLog system for automatic termination analysis,
is presented for showing termination in this case.
  The method consists of the following steps: First, a finite abstract domain
for representing the range of integers is deduced automatically. Based on this
abstraction, abstract interpretation is applied to the program. The result is a
finite number of atoms abstracting answers to queries which are used to extend
the technique of query-mapping pairs. For each query-mapping pair that is
potentially non-terminating, a bounded (integer-valued) termination function is
guessed. If traversing the pair decreases the value of the termination
function, then termination is established. Simple functions often suffice for
each query-mapping pair, and that gives our approach an edge over the classical
approach of using a single termination function for all loops, which must
inevitably be more complicated and harder to guess automatically. It is worth
noting that the termination of McCarthy's 91 function can be shown
automatically using our method.
  In summary, the proposed approach is based on combining a finite abstraction
of the integers with the technique of the query-mapping pairs, and is
essentially capable of dividing a termination proof into several cases, such
that a simple termination function suffices for each case. Consequently, the
whole process of proving termination can be done automatically in the framework
of TermiLog and similar systems.
</dc:description>
 <dc:description>Comment: Appeared also in Electronic Notes in Computer Science vol. 30</dc:description>
 <dc:date>2000-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A syntactical analysis of non-size-increasing polynomial time
  computation</dc:title>
 <dc:creator>Aehlig, Klaus</dc:creator>
 <dc:creator>Schwichtenberg, Helmut</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  A syntactical proof is given that all functions definable in a certain affine
linear typed lambda-calculus with iteration in all types are polynomial time
computable. The proof provides explicit polynomial bounds that can easily be
calculated.
</dc:description>
 <dc:description>Comment: 20 pages (latex), revised submission (expanded proofs, extended
  references, new section on tree iteration)</dc:description>
 <dc:date>2000-11-23</dc:date>
 <dc:date>2001-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011037</dc:identifier>
 <dc:identifier>ACM Transactions on Computational Logic 3(3), 383-401 (2002)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Provably Fast and Accurate Recovery of Evolutionary Trees through
  Harmonic Greedy Triplets</dc:title>
 <dc:creator>Csuros, Miklos</dc:creator>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  We give a greedy learning algorithm for reconstructing an evolutionary tree
based on a certain harmonic average on triplets of terminal taxa. After the
pairwise distances between terminal taxa are estimated from sequence data, the
algorithm runs in O(n^2) time using O(n) work space, where n is the number of
terminal taxa. These time and space complexities are optimal in the sense that
the size of an input distance matrix is n^2 and the size of an output tree is
n. Moreover, in the Jukes-Cantor model of evolution, the algorithm recovers the
correct tree topology with high probability using sample sequences of length
polynomial in (1) n, (2) the logarithm of the error probability, and (3) the
inverses of two small parameters.
</dc:description>
 <dc:description>Comment: The paper will appear in SIAM Journal on Computing</dc:description>
 <dc:date>2000-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Complete Characterization of Complete Intersection-Type Theories</dc:title>
 <dc:creator>Dezani-Ciancaglini, M.</dc:creator>
 <dc:creator>Honsell, F.</dc:creator>
 <dc:creator>Alessi, F.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.3.3</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>D.1.1</dc:subject>
 <dc:description>  We characterize those intersection-type theories which yield complete
intersection-type assignment systems for lambda-calculi, with respect to the
three canonical set-theoretical semantics for intersection-types: the inference
semantics, the simple semantics and the F-semantics. These semantics arise by
taking as interpretation of types subsets of applicative structures, as
interpretation of the intersection constructor set-theoretic inclusion, and by
taking the interpretation of the arrow constructor a' la Scott, with respect to
either any possible functionality set, or the largest one, or the least one.
  These results strengthen and generalize significantly all earlier results in
the literature, to our knowledge, in at least three respects. First of all the
inference semantics had not been considered before. Secondly, the
characterizations are all given just in terms of simple closure conditions on
the preorder relation on the types, rather than on the typing judgments
themselves. The task of checking the condition is made therefore considerably
more tractable. Lastly, we do not restrict attention just to lambda-models, but
to arbitrary applicative structures which admit an interpretation function.
Thus we allow also for the treatment of models of restricted lambda-calculi.
Nevertheless the characterizations we give can be tailored just to the case of
lambda-models.
</dc:description>
 <dc:description>Comment: 26 pages, no figure</dc:description>
 <dc:date>2000-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Do All Fragments Count?</dc:title>
 <dc:creator>Bod, Rens</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We aim at finding the minimal set of fragments which achieves maximal parse
accuracy in Data Oriented Parsing. Experiments with the Penn Wall Street
Journal treebank show that counts of almost arbitrary fragments within parse
trees are important, leading to improved parse accuracy over previous models
tested on this treebank. We isolate a number of dependency relations which
previous models neglect but which contribute to higher parse accuracy.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2000-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011040</dc:identifier>
 <dc:identifier>Technical Report COMP-11-12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EquiX---A Search and Query Language for XML</dc:title>
 <dc:creator>Cohen, Sara</dc:creator>
 <dc:creator>Kanza, Yaron</dc:creator>
 <dc:creator>Kogan, Yakov</dc:creator>
 <dc:creator>Nutt, Werner</dc:creator>
 <dc:creator>Sagiv, Yehoshua</dc:creator>
 <dc:creator>Serebrenik, Alexander</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.3</dc:subject>
 <dc:description>  EquiX is a search language for XML that combines the power of querying with
the simplicity of searching. Requirements for such languages are discussed and
it is shown that EquiX meets the necessary criteria. Both a graphical abstract
syntax and a formal concrete syntax are presented for EquiX queries. In
addition, the semantics is defined and an evaluation algorithm is presented.
The evaluation algorithm is polynomial under combined complexity.
  EquiX combines pattern matching, quantification and logical expressions to
query both the data and meta-data of XML documents. The result of a query in
EquiX is a set of XML documents. A DTD describing the result documents is
derived automatically from the query.
</dc:description>
 <dc:description>Comment: technical report of Hebrew University Jerusalem Israel</dc:description>
 <dc:date>2000-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Order-consistent programs are cautiously monotonic</dc:title>
 <dc:creator>Turner, Hudson</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  Some normal logic programs under the answer set (stable model) semantics lack
the appealing property of &quot;cautious monotonicity.&quot; That is, augmenting a
program with one of its consequences may cause it to lose another of its
consequences. The syntactic condition of &quot;order-consistency&quot; was shown by Fages
to guarantee existence of an answer set. This note establishes that
order-consistent programs are not only consistent, but cautiously monotonic.
  From this it follows that they are also &quot;cumulative.&quot; That is, augmenting an
order-consistent with some of its consequences does not alter its consequences.
In fact, as we show, its answer sets remain unchanged.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2000-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rewriting Calculus: Foundations and Applications</dc:title>
 <dc:creator>Cirstea, Horatiu</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>I.1</dc:subject>
 <dc:subject>D.1</dc:subject>
 <dc:subject>D.3</dc:subject>
 <dc:subject>F.4.0</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  This thesis is devoted to the study of a calculus that describes the
application of conditional rewriting rules and the obtained results at the same
level of representation. We introduce the rewriting calculus, also called the
rho-calculus, which generalizes the first order term rewriting and
lambda-calculus, and makes possible the representation of the non-determinism.
In our approach the abstraction operator as well as the application operator
are objects of calculus. The result of a reduction in the rewriting calculus is
either an empty set representing the application failure, or a singleton
representing a deterministic result, or a set having several elements
representing a not-deterministic choice of results.
  In this thesis we concentrate on the properties of the rewriting calculus
where a syntactic matching is used in order to bind the variables to their
current values. We define evaluation strategies ensuring the confluence of the
calculus and we show that these strategies become trivial for restrictions of
the general rewriting calculus to simpler calculi like the lambda-calculus. The
rewriting calculus is not terminating in the untyped case but the strong
normalization is obtained for the simply typed calculus.
  In the rewriting calculus extended with an operator allowing to test the
application failure we define terms representing innermost and outermost
normalizations with respect to a set of rewriting rules. By using these terms,
we obtain a natural and concise description of the conditional rewriting.
Finally, starting from the representation of the conditional rewriting rules,
we show how the rewriting calculus can be used to give a semantics to ELAN, a
language based on the application of rewriting rules controlled by strategies.
</dc:description>
 <dc:description>Comment: PhD Thesis in French</dc:description>
 <dc:date>2000-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011043</dc:identifier>
 <dc:language>fr</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scaling Up Inductive Logic Programming by Learning from Interpretations</dc:title>
 <dc:creator>Blockeel, Hendrik</dc:creator>
 <dc:creator>De Raedt, Luc</dc:creator>
 <dc:creator>Jacobs, Nico</dc:creator>
 <dc:creator>Demoen, Bart</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  When comparing inductive logic programming (ILP) and attribute-value learning
techniques, there is a trade-off between expressive power and efficiency.
Inductive logic programming techniques are typically more expressive but also
less efficient. Therefore, the data sets handled by current inductive logic
programming systems are small according to general standards within the data
mining community. The main source of inefficiency lies in the assumption that
several examples may be related to each other, so they cannot be handled
independently.
  Within the learning from interpretations framework for inductive logic
programming this assumption is unnecessary, which allows to scale up existing
ILP algorithms. In this paper we explain this learning setting in the context
of relational databases. We relate the setting to propositional data mining and
to the classical ILP setting, and show that learning from interpretations
corresponds to learning from multiple relations and thus extends the
expressiveness of propositional learning, while maintaining its efficiency to a
large extent (which is not the case in the classical ILP setting).
  As a case study, we present two alternative implementations of the ILP system
Tilde (Top-down Induction of Logical DEcision trees): Tilde-classic, which
loads all data in main memory, and Tilde-LDS, which loads the examples one by
one. We experimentally compare the implementations, showing Tilde-LDS can
handle large data sets (in the order of 100,000 examples or 100 MB) and indeed
scales up linearly in the number of examples.
</dc:description>
 <dc:description>Comment: 37 pages</dc:description>
 <dc:date>2000-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011044</dc:identifier>
 <dc:identifier>Data Mining and Knowledge Discovery 3(1), pp. 59-93, 1999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Index Assignment for Multichannel Communication under Failure</dc:title>
 <dc:creator>Berger-Wolf, Tanya Y.</dc:creator>
 <dc:creator>Reingold, Edward M.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We consider the problem of multiple description scalar quantizers and
describing the achievable rate-distortion tuples in that setting. We formulate
it as a combinatorial optimization problem of arranging numbers in a matrix to
minimize the maximum difference between the largest and the smallest number in
any row or column. We develop a technique for deriving lower bounds on the
distortion at given channel rates. The approach is constructive, thus allowing
an algorithm that gives a closely matching upper bound. For the case of two
communication channels with equal rates, the bounds coincide, thus giving the
precise lowest achievable distortion at fixed rates. The bounds are within a
small constant for higher number of channels. To the best of our knowledge,
this is the first result concerning systems with more than two communication
channels. The problem is also equivalent to the bandwidth minimization problem
of Hamming graphs.
</dc:description>
 <dc:description>Comment: 10 pages, 12 figures. First appeard in SODA 99, submitted to IEEE
  Transactions on Information Theory</dc:description>
 <dc:date>2000-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Available Stabilizing Heaps</dc:title>
 <dc:creator>Herman, Ted</dc:creator>
 <dc:creator>Masuzawa, Toshimitsu</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>E.2</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:description>  This paper describes a heap construction that supports insert and delete
operations in arbitrary (possibly illegitimate) states. After any sequence of
at most O(m) heap operations, the heap state is guarantee to be legitimate,
where m is the initial number of items in the heap. The response from each
operation is consistent with its effect on the data structure, even for
illegitimate states. The time complexity of each operation is O(lg K) where K
is the capacity of the data structure; when the heap's state is legitimate the
time complexity is O(lg n) for n equal to the number items in the heap.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2000-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0011047</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dancing links</dc:title>
 <dc:creator>Knuth, Donald E.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The author presents two tricks to accelerate depth-first search algorithms
for a class of combinatorial puzzle problems, such as tiling a tray by a fixed
set of polyominoes. The first trick is to implement each assumption of the
search with reversible local operations on doubly linked lists. By this trick,
every step of the search affects the data incrementally.
  The second trick is to add a ghost square that represents the identity of
each polyomino. Thus puts the rule that each polyomino be used once on the same
footing as the rule that each square be covered once. The coding simplifies to
a more abstract form which is equivalent to 0-1 integer programming. More
significantly for the total computation time, the search can naturally switch
between placing a fixed polyomino or covering a fixed square at different
stages, according to a combined heuristic.
  Finally the author reports excellent performance for his algorithm for some
familiar puzzles. These include tiling a hexagon by 19 hexiamonds and the N
queens problem for N up to 18.
</dc:description>
 <dc:description>Comment: Abstract added by Greg Kuperberg</dc:description>
 <dc:date>2000-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0011047</dc:identifier>
 <dc:identifier>Millenial Perspectives in Computer Science, 2000, 187--214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012001</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Available and Stabilizing 2-3 Trees</dc:title>
 <dc:creator>Herman, Ted</dc:creator>
 <dc:creator>Masuzawa, Toshimitsu</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>D.4.5</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:description>  Transient faults corrupt the content and organization of data structures. A
recovery technique dealing with such faults is stabilization, which guarantees,
following some number of operations on the data structure, that content of the
data structure is legitimate. Another notion of fault tolerance is
availability, which is the property that operations continue to be applied
during the period of recovery after a fault, and successful updates are not
lost while the data structure stabilizes to a legitimate state. The available,
stabilizing 2-3 tree supports find, insert, and delete operations, each with
O(lg n) complexity when the tree's state is legitimate and contains n items.
For an illegitimate state, these operations have O(lg K) complexity where K is
the maximum capacity of the tree. Within O(t) operations, the state of the tree
is guaranteed to be legitimate, where t is the number of nodes accessible via
some path from the tree's root at the initial state. This paper resolves, for
the first time, issues of dynamic allocation and pointer organization in a
stabilizing data structure.
</dc:description>
 <dc:description>Comment: 22 pages, 5 figures</dc:description>
 <dc:date>2000-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012002</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Shuffling to Reduce Disorder in Adaptive Sorting Scheme</dc:title>
 <dc:creator>Karim, Md. Enamul</dc:creator>
 <dc:creator>Mahmood, Abdun Naser</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  In this paper we present a random shuffling scheme to apply with adaptive
sorting algorithms. Adaptive sorting algorithms utilize the presortedness
present in a given sequence. We have probabilistically increased the amount of
presortedness present in a sequence by using a random shuffling technique that
requires little computation. Theoretical analysis suggests that the proposed
scheme can improve the performance of adaptive sorting. Experimental results
show that it significantly reduces the amount of disorder present in a given
sequence and improves the execution time of adaptive sorting algorithm as well.
</dc:description>
 <dc:description>Comment: 7 pages, 2 tables</dc:description>
 <dc:date>2000-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Questions for a Materialist Philosophy Implying the Equivalence of
  Computers and Human Cognition</dc:title>
 <dc:creator>Snyder, Douglas M.</dc:creator>
 <dc:subject>Computer Science - General Literature</dc:subject>
 <dc:subject>A.0</dc:subject>
 <dc:description>  Issues related to a materialist philosophy are explored as concerns the
implied equivalence of computers running software and human observers. One
issue explored concerns the measurement process in quantum mechanics. Another
issue explored concerns the nature of experience as revealed by the existence
of dreams. Some difficulties stemming from a materialist philosophy as regards
these issues are pointed out. For example, a gedankenexperiment involving what
has been called &quot;negative&quot; observation is discussed that illustrates the
difficulty with a materialist assumption in quantum mechanics. Based on an
exploration of these difficulties, specifications are outlined briefly that
would provide a means to demonstrate the equivalence of of computers running
software and human experience given a materialist assumption.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2000-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Performance of heavily loaded agents</dc:title>
 <dc:creator>Ozcan, Fatma</dc:creator>
 <dc:creator>Subrahmanian, VS</dc:creator>
 <dc:creator>Dix, Juergen</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.12</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>D.2.12</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:description>  With the increase in agent-based applications, there are now agent systems
that support \emph{concurrent} client accesses. The ability to process large
volumes of simultaneous requests is critical in many such applications. In such
a setting, the traditional approach of serving these requests one at a time via
queues (e.g. \textsf{FIFO} queues, priority queues) is insufficient.
Alternative models are essential to improve the performance of such
\emph{heavily loaded} agents. In this paper, we propose a set of
\emph{cost-based algorithms} to \emph{optimize} and \emph{merge} multiple
requests submitted to an agent. In order to merge a set of requests, one first
needs to identify commonalities among such requests. First, we provide an
\emph{application independent framework} within which an agent developer may
specify relationships (called \emph{invariants}) between requests. Second, we
provide two algorithms (and various accompanying heuristics) which allow an
agent to automatically rewrite requests so as to avoid redundant work---these
algorithms take invariants associated with the agent into account. Our
algorithms are independent of any specific agent framework. For an
implementation, we implemented both these algorithms on top of the \impact
agent development platform, and on top of a (non-\impact) geographic database
agent. Based on these implementations, we conducted experiments and show that
our algorithms are considerably more efficient than methods that use the $A^*$
algorithm.
</dc:description>
 <dc:description>Comment: 63 pages, 26 figures, 10 tables</dc:description>
 <dc:date>2000-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Value Withdrawal Explanation in CSP</dc:title>
 <dc:creator>Ferrand, Gerard</dc:creator>
 <dc:creator>Lesaint, Willy</dc:creator>
 <dc:creator>Tessier, Alexandre</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  This work is devoted to constraint solving motivated by the debugging of
constraint logic programs a la GNU-Prolog. The paper focuses only on the
constraints. In this framework, constraint solving amounts to domain reduction.
A computation is formalized by a chaotic iteration. The computed result is
described as a closure. This model is well suited to the design of debugging
notions and tools, for example failure explanations or error diagnosis. In this
paper we detail an application of the model to an explanation of a value
withdrawal in a domain. Some other works have already shown the interest of
such a notion of explanation not only for failure analysis.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2000-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Support for Debugging Automatically Parallelized Programs</dc:title>
 <dc:creator>Hood, Robert</dc:creator>
 <dc:creator>Jost, Gabriele</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  We describe a system that simplifies the process of debugging programs
produced by computer-aided parallelization tools. The system uses relative
debugging techniques to compare serial and parallel executions in order to show
where the computations begin to differ. If the original serial code is correct,
errors due to parallelization will be isolated by the comparison.
  One of the primary goals of the system is to minimize the effort required of
the user. To that end, the debugging system uses information produced by the
parallelization tool to drive the comparison process. In particular, the
debugging system relies on the parallelization tool to provide information
about where variables may have been modified and how arrays are distributed
across multiple processes. User effort is also reduced through the use of
dynamic instrumentation. This allows us to modify the program execution without
changing the way the user builds the executable.
  The use of dynamic instrumentation also permits us to compare the executions
in a fine-grained fashion and only involve the debugger when a difference has
been detected. This reduces the overhead of executing instrumentation.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2000-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kima - an Automated Error Correction System for Concurrent Logic
  Programs</dc:title>
 <dc:creator>Ajiro, Yasuhiro</dc:creator>
 <dc:creator>Ueda, Kazunori</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  We have implemented Kima, an automated error correction system for concurrent
logic programs. Kima corrects near-misses such as wrong variable occurrences in
the absence of explicit declarations of program properties. Strong
moding/typing and constraint-based analysis are turning to play fundamental
roles in debugging concurrent logic programs as well as in establishing the
consistency of communication protocols and data types. Mode/type analysis of
Moded Flat GHC is a constraint satisfaction problem with many simple mode/type
constraints, and can be solved efficiently. We proposed a simple and efficient
technique which, given a non-well-moded/typed program, diagnoses the
``reasons'' of inconsistency by finding minimal inconsistent subsets of
mode/type constraints. Since each constraint keeps track of the symbol
occurrence in the program, a minimal subset also tells possible sources of
program errors. Kima realizes automated correction by replacing symbol
occurrences around the possible sources and recalculating modes and types of
the rewritten programs systematically. As long as bugs are near-misses, Kima
proposes a rather small number of alternatives that include an intended
program.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2000-12-13</dc:date>
 <dc:date>2001-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General Framework for Automatic Termination Analysis of Logic Programs</dc:title>
 <dc:creator>Dershowitz, Nachum</dc:creator>
 <dc:creator>Lindenstrauss, Naomi</dc:creator>
 <dc:creator>Sagiv, Yehoshua</dc:creator>
 <dc:creator>Serebrenik, Alexander</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:description>  This paper describes a general framework for automatic termination analysis
of logic programs, where we understand by ``termination'' the finitenes s of
the LD-tree constructed for the program and a given query. A general property
of mappings from a certain subset of the branches of an infinite LD-tree into a
finite set is proved. From this result several termination theorems are
derived, by using different finite sets. The first two are formulated for the
predicate dependency and atom dependency graphs. Then a general result for the
case of the query-mapping pairs relevant to a program is proved (cf.
\cite{Sagiv,Lindenstrauss:Sagiv}). The correctness of the {\em TermiLog} system
described in \cite{Lindenstrauss:Sagiv:Serebrenik} follows from it. In this
system it is not possible to prove termination for programs involving
arithmetic predicates, since the usual order for the integers is not
well-founded. A new method, which can be easily incorporated in {\em TermiLog}
or similar systems, is presented, which makes it possible to prove termination
for programs involving arithmetic predicates. It is based on combining a finite
abstraction of the integers with the technique of the query-mapping pairs, and
is essentially capable of dividing a termination proof into several cases, such
that a simple termination function suffices for each case. Finally several
possible extensions are outlined.
</dc:description>
 <dc:date>2000-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Failure Causes through Automated Testing</dc:title>
 <dc:creator>Cleve, Holger</dc:creator>
 <dc:creator>Zeller, Andreas</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  A program fails. Under which circumstances does this failure occur? One
single algorithm, the delta debugging algorithm, suffices to determine these
failure-inducing circumstances. Delta debugging tests a program systematically
and automatically to isolate failure-inducing circumstances such as the program
input, changes to the program code, or executed statements.
</dc:description>
 <dc:date>2000-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Role of Commutativity in Constraint Propagation Algorithms</dc:title>
 <dc:creator>Apt, Krzysztof R.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:subject>I.1.3</dc:subject>
 <dc:description>  Constraint propagation algorithms form an important part of most of the
constraint programming systems. We provide here a simple, yet very general
framework that allows us to explain several constraint propagation algorithms
in a systematic way. In this framework we proceed in two steps. First, we
introduce a generic iteration algorithm on partial orderings and prove its
correctness in an abstract setting. Then we instantiate this algorithm with
specific partial orderings and functions to obtain specific constraint
propagation algorithms.
  In particular, using the notions commutativity and semi-commutativity, we
show that the {\tt AC-3}, {\tt PC-2}, {\tt DAC} and {\tt DPC} algorithms for
achieving (directional) arc consistency and (directional) path consistency are
instances of a single generic algorithm. The work reported here extends and
simplifies that of Apt \citeyear{Apt99b}.
</dc:description>
 <dc:description>Comment: 35 pages. To appear in ACM TOPLAS</dc:description>
 <dc:date>2000-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012011</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Universal Theory of Artificial Intelligence based on
  Algorithmic Probability and Sequential Decision Theory</dc:title>
 <dc:creator>Hutter, Marcus</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:description>  Decision theory formally solves the problem of rational agents in uncertain
worlds if the true environmental probability distribution is known.
Solomonoff's theory of universal induction formally solves the problem of
sequence prediction for unknown distribution. We unify both theories and give
strong arguments that the resulting universal AIXI model behaves optimal in any
computable environment. The major drawback of the AIXI model is that it is
uncomputable. To overcome this problem, we construct a modified algorithm
AIXI^tl, which is still superior to any other time t and space l bounded agent.
The computation time of AIXI^tl is of the order t x 2^l.
</dc:description>
 <dc:description>Comment: 8 two-column pages, latex2e, 1 figure, submitted to ijcai</dc:description>
 <dc:date>2000-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012011</dc:identifier>
 <dc:identifier>Lecture Notes in Artificial Intelligence (LNAI 2167), Proc. 12th
  Eurpean Conf. on Machine Learning, ECML (2001) 226--238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012012</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A brief overview of the MAD debugging activities</dc:title>
 <dc:creator>Kranzlmueller, Dieter</dc:creator>
 <dc:creator>Schaubschlaeger, Christian</dc:creator>
 <dc:creator>Volkert, Jens</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Debugging parallel and distributed programs is a difficult activitiy due to
the multiplicity of sequential bugs, the existence of malign effects like race
conditions and deadlocks, and the huge amounts of data that have to be
processed. These problems are addressed by the Monitoring And Debugging
environment MAD, which offers debugging functionality based on a graphical
representation of a program's execution. The target applications of MAD are
parallel programs applying the standard Message-Passing Interface MPI, which is
used extensively in the high-performance computing domain. The highlights of
MAD are interactive inspection mechanisms including visualization of
distributed arrays, the possibility to graphically place breakpoints, a
mechanism for monitor overhead removal, and the evaluation of racing messages
occuring due to nondeterminism in the code.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035 (6
  pages, 2 figures)</dc:description>
 <dc:date>2000-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012013</identifier>
 <datestamp>2016-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Equity Tax and Shelter</dc:title>
 <dc:creator>Levin, Leonid A.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  Taxes have major costs beyond the collected revenue: deadweight from
distorted incentives, compliance and enforcement costs, etc. A simple market
mechanism, the Equity Tax, avoids these problems for the trickiest cases:
corporate, dividend, and capital gains taxes.
  It exploits the ability of the share prices to reflect the expected true
annual return (as perceived by investors, not as defined by law) and works only
for publicly held corporations. Since going or staying public cannot be forced,
and for some constitutional reasons too, the conversion to equity tax must be a
voluntary contract. Repeated reconversions would be costly (all capital gains
are realized) and thus rare. The converts and their shareholders pay no income,
dividend, or capital gain taxes. Instead, they give the IRS, say, 2% of stock
per year to auction promptly. Debts are the lender's assets: its status, not
the debtor's, determines their equity-tax or income-tax treatment.
  The system looks too simple to be right. However, it does have no loopholes
(thus lowering the revenue-neutral tax rate), no compliance costs, requires
little regulation, and leaves all business decisions tax neutral. The total
capital the equity taxed sector absorbs is the only thing the tax could
possibly distort. The rates should match so as to minimize this distortion. The
equity tax enlarges the pre-tax profit since this is what the taxpayers
maximize, not a different after-tax net. The wealth shelter is paid for by
efficiency, not by lost tax.
</dc:description>
 <dc:description>Comment: 10 pages. Appendix modified</dc:description>
 <dc:date>2000-12-17</dc:date>
 <dc:date>2016-09-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012013</dc:identifier>
 <dc:identifier>Tax Notes 93(9):1203-1208 (11/26/2001)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Slicing of Constraint Logic Programs</dc:title>
 <dc:creator>Szilagyi, Gyongyi</dc:creator>
 <dc:creator>Gyimothy, Tibor</dc:creator>
 <dc:creator>Maluszynski, Jan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Slicing is a program analysis technique originally developed for imperative
languages. It facilitates understanding of data flow and debugging.
  This paper discusses slicing of Constraint Logic Programs. Constraint Logic
Programming (CLP) is an emerging software technology with a growing number of
applications. Data flow in constraint programs is not explicit, and for this
reason the concepts of slice and the slicing techniques of imperative languages
are not directly applicable.
  This paper formulates declarative notions of slice suitable for CLP. They
provide a basis for defining slicing techniques (both dynamic and static) based
on variable sharing. The techniques are further extended by using groundness
information.
  A prototype dynamic slicer of CLP programs implementing the presented ideas
is briefly described together with the results of some slicing experiments.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2000-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Well-Typed Logic Programs Are not Wrong</dc:title>
 <dc:creator>Deransart, Pierre</dc:creator>
 <dc:creator>Smaus, Jan-Georg</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  We consider prescriptive type systems for logic programs (as in Goedel or
Mercury). In such systems, the typing is static, but it guarantees an
operational property: if a program is &quot;well-typed&quot;, then all derivations
starting in a &quot;well-typed&quot; query are again &quot;well-typed&quot;. This property has been
called subject reduction. We show that this property can also be phrased as a
property of the proof-theoretic semantics of logic programs, thus abstracting
from the usual operational (top-down) semantics. This proof-theoretic view
leads us to questioning a condition which is usually considered necessary for
subject reduction, namely the head condition. It states that the head of each
clause must have a type which is a variant (and not a proper instance) of the
declared type. We provide a more general condition, thus reestablishing a
certain symmetry between heads and body atoms. The condition ensures that in a
derivation, the types of two unified terms are themselves unifiable. We discuss
possible implications of this result. We also discuss the relationship between
the head condition and polymorphic recursion, a concept known in functional
programming.
</dc:description>
 <dc:description>Comment: 21 pages, 7 figures</dc:description>
 <dc:date>2000-12-20</dc:date>
 <dc:date>2001-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Virtual Java Simulation Lab for Computer Science Students</dc:title>
 <dc:creator>Diaz, Javier</dc:creator>
 <dc:creator>Queiruga, Claudia</dc:creator>
 <dc:creator>Claudia, Villar</dc:creator>
 <dc:creator>Fava, Laura</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:description>  The VJ-Lab is a project oriented to improve the students learning process of
Computer Science degree at the National University of La Plata. The VJ-Lab is a
Web application with Java based simulations. Java can be used to provide
simulation environments with simple pictorial interfaces that can help students
to understand the subject. There are many fields in which it is difficult to
give students a feel for the subject that they are learning. Computer based
simulations offer a fun and effective way to enable students to learn by doing.
Both, practicing skills and applying knowledge are both allowed in simulated
worlds. We will focus on the VJ-Lab project overview, the work in progress and
some Java based simulations running. They imitate the behavior of data network
protocol and data structure algorithms. These applets are produced by the
students of the 'Software Development Laboratory' course.
</dc:description>
 <dc:description>Comment: 3 pages, WebNet 2000 (World Conference on the WWW and Internet) -
  AACE (Association for the Advancement of Computing Education)</dc:description>
 <dc:date>2000-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Robust Quantum Computation</dc:title>
 <dc:creator>Leung, Debbie W.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>F.1.m</dc:subject>
 <dc:description>  Quantum computation is a subject of much theoretical promise, but has not
been realized in large scale, despite the discovery of fault-tolerant
procedures to overcome decoherence. Part of the reason is that the
theoretically modest requirements still present daunting experimental
challenges. The goal of this Dissertation is to reduce various resources
required for robust quantum computation, focusing on quantum error correcting
codes and solution NMR quantum computation. A variety of techniques have been
developed, including high rate quantum codes for amplitude damping, relaxed
criteria for quantum error correction, systematic construction of
fault-tolerant gates, recipes for quantum process tomography, techniques in
bulk thermal state computation, and efficient decoupling techniques to
implement selective coupled logic gates. A detailed experimental study of a
quantum error correcting code in NMR is also presented. The Dissertation
clarifies and extends results previously reported in quant-ph/9610043,
quant-ph/9704002, quant-ph/9811068, quant-ph/9904100, quant-ph/9906112,
quant-ph/0002039. Additionally, a procedure for quantum process tomography
using maximally entangled states, and a review on NMR quantum computation are
included.
</dc:description>
 <dc:description>Comment: 243 pages, PhD Dissertation, Stanford University, July 2000</dc:description>
 <dc:date>2000-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource-distribution via Boolean constraints</dc:title>
 <dc:creator>Harland, James</dc:creator>
 <dc:creator>Pym, David</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We consider the problem of searching for proofs in sequential presentations
of logics with multiplicative (or intensional) connectives. Specifically, we
start with the multiplicative fragment of linear logic and extend, on the one
hand, to linear logic with its additives and, on the other, to the additives of
the logic of bunched implications, BI. We give an algebraic method for
calculating the distribution of the side-formulae in multiplicative rules which
allows the occurrence or non-occurrence of a formula on a branch of a proof to
be determined once sufficient information is available. Each formula in the
conclusion of such a rule is assigned a Boolean expression. As a search
proceeds, a set of Boolean constraint equations is generated. We show that a
solution to such a set of equations determines a proof corresponding to the
given search. We explain a range of strategies, from the lazy to the eager, for
solving sets of constraint equations. We indicate how to apply our methods
systematically to large family of relevant systems.
</dc:description>
 <dc:description>Comment: Submission to ACM Transactions on Computational Logic</dc:description>
 <dc:date>2000-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on Power-Laws of Internet Topology</dc:title>
 <dc:creator>Chou, Hongsong</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  The three Power-Laws proposed by Faloutsos et al(1999) are important
discoveries among many recent works on finding hidden rules in the seemingly
chaotic Internet topology. In this note, we want to point out that the first
two laws discovered by Faloutsos et al(1999, hereafter, {\it Faloutsos' Power
Laws}) are in fact equivalent. That is, as long as any one of them is true, the
other can be derived from it, and {\it vice versa}. Although these two laws are
equivalent, they provide different ways to measure the exponents of their
corresponding power law relations. We also show that these two measures will
give equivalent results, but with different error bars. We argue that for nodes
of not very large out-degree($\leq 32$ in our simulation), the first Faloutsos'
Power Law is superior to the second one in giving a better estimate of the
exponent, while for nodes of very large out-degree($&gt; 32$) the power law
relation may not be present, at least for the relation between the frequency of
out-degree and node out-degree.
</dc:description>
 <dc:description>Comment: 16 pages, 3 figures</dc:description>
 <dc:date>2000-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Creativity and Delusions: A Neurocomputational Approach</dc:title>
 <dc:creator>Mendes, Daniele Quintella</dc:creator>
 <dc:creator>de Carvalho, Luis Alfredo Vidal</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:description>  Thinking is one of the most interesting mental processes. Its complexity is
sometimes simplified and its different manifestations are classified into
normal and abnormal, like the delusional and disorganized thought or the
creative one. The boundaries between these facets of thinking are fuzzy causing
difficulties in medical, academic, and philosophical discussions. Considering
the dopaminergic signal-to-noise neuronal modulation in the central nervous
system, and the existence of semantic maps in human brain, a self-organizing
neural network model was developed to unify the different thought processes
into a single neurocomputational substrate. Simulations were performed varying
the dopaminergic modulation and observing the different patterns that emerged
at the semantic map. Assuming that the thought process is the total pattern
elicited at the output layer of the neural network, the model shows how the
normal and abnormal thinking are generated and that there are no borders
between their different manifestations. Actually, a continuum of different
qualitative reasoning, ranging from delusion to disorganization of thought, and
passing through the normal and the creative thinking, seems to be more
plausible. The model is far from explaining the complexities of human thinking
but, at least, it seems to be a good metaphorical and unifying view of the many
facets of this phenomenon usually studied in separated settings.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures</dc:description>
 <dc:date>2000-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012021</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Benchmark for Image Retrieval using Distributed Systems over the
  Internet: BIRDS-I</dc:title>
 <dc:creator>Gunther, Neil J.</dc:creator>
 <dc:creator>Beretta, Giordano B.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>D.2.8</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:description>  The performance of CBIR algorithms is usually measured on an isolated
workstation. In a real-world environment the algorithms would only constitute a
minor component among the many interacting components. The Internet
dramati-cally changes many of the usual assumptions about measuring CBIR
performance. Any CBIR benchmark should be designed from a networked systems
standpoint. These benchmarks typically introduce communication overhead because
the real systems they model are distributed applications. We present our
implementation of a client/server benchmark called BIRDS-I to measure image
retrieval performance over the Internet. It has been designed with the trend
toward the use of small personalized wireless systems in mind. Web-based CBIR
implies the use of heteroge-neous image sets, imposing certain constraints on
how the images are organized and the type of performance metrics applicable.
BIRDS-I only requires controlled human intervention for the compilation of the
image collection and none for the generation of ground truth in the measurement
of retrieval accuracy. Benchmark image collections need to be evolved
incrementally toward the storage of millions of images and that scaleup can
only be achieved through the use of computer-aided compilation. Finally, our
scoring metric introduces a tightly optimized image-ranking window.
</dc:description>
 <dc:description>Comment: 24 pages, To appear in the Proc. SPIE Internet Imaging Conference
  2001</dc:description>
 <dc:date>2000-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012021</dc:identifier>
 <dc:identifier>doi:10.1117/12.411898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance and Scalability Models for a Hypergrowth e-Commerce Web Site</dc:title>
 <dc:creator>Gunther, Neil J.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:subject>D.2.8</dc:subject>
 <dc:subject>D.4.8</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:description>  The performance of successful Web-based e-commerce services has all the
allure of a roller-coaster ride: accelerated fiscal growth combined with the
ever-present danger of running out of server capacity. This chapter presents a
case study based on the author's own capacity planning engagement with one of
the hottest e-commerce Web sites in the world. Several spreadsheet techniques
are presented for forecasting both short-term and long-term trends in the
consumption of server capacity. Two new performance metrics are introduced for
site planning and procurement: the effective demand, and the doubling period.
</dc:description>
 <dc:description>Comment: 15 pages; To appear in the book entitled &quot;Performance Engineering -
  State of the Art and Current Trends,&quot; Lecture Notes in Computer Science,
  Springer-Verlag Heidelberg, 2001</dc:description>
 <dc:date>2000-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Tale of One-way Functions</dc:title>
 <dc:creator>Levin, Leonid A.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - General Literature</dc:subject>
 <dc:subject>F.1</dc:subject>
 <dc:subject>F.0</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  The existence of one-way functions is arguably the most important problem in
computer theory. The article discusses and refines a number of concepts
relevant to this problem. For instance, it gives the first combinatorial
complete owf, i.e., a function which is one-way if any function is. There are
surprisingly many subtleties in basic definitions. Some of these subtleties are
discussed or hinted at in the literature and some are overlooked. Here, a
unified approach is attempted.
</dc:description>
 <dc:description>Comment: Small changes. 16 pages in English; 18 pages in Russian (KOI8
  encoding, translated by Alexander Shen)</dc:description>
 <dc:date>2000-12-26</dc:date>
 <dc:date>2003-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012023</dc:identifier>
 <dc:identifier>Problems of Information Transmission (= Problemy Peredachi
  Informatsii), 39(1):92-103, 2003</dc:identifier>
 <dc:language>en</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0012024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Byzantine Agreement with Faulty Majority using Bounded Broadcast</dc:title>
 <dc:creator>Considine, Jeffrey</dc:creator>
 <dc:creator>Levin, Leonid A.</dc:creator>
 <dc:creator>Metcalf, David</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:description>  Byzantine Agreement introduced in [Pease, Shostak, Lamport, 80] is a widely
used building block of reliable distributed protocols. It simulates broadcast
despite the presence of faulty parties within the network, traditionally using
only private unicast links. Under such conditions, Byzantine Agreement requires
more than 2/3 of the parties to be compliant. [Fitzi, Maurer, 00], constructed
a Byzantine Agreement protocol for any compliant majority based on an
additional primitive allowing transmission to any two parties simultaneously.
They proposed a problem of generalizing these results to wider channels and
fewer compliant parties. We prove that 2f &lt; kh condition is necessary and
sufficient for implementing broadcast with h compliant and f faulty parties
using k-cast channels.
</dc:description>
 <dc:description>Comment: 4 pages; round-up gap between bounds removed</dc:description>
 <dc:date>2000-12-26</dc:date>
 <dc:date>2003-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0012024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Differentiation Tools in Optimization Software</dc:title>
 <dc:creator>Mor&#xe9;, Jorge J.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  We discuss the role of automatic differentiation tools in optimization
software. We emphasize issues that are important to large-scale optimization
and that have proved useful in the installation of nonlinear solvers in the
NEOS Server. Our discussion centers on the computation of the gradient and
Hessian matrix for partially separable functions and shows that the gradient
and Hessian matrix can be computed with guaranteed bounds in time and memory
requirements
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2001-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Debugging In Java Using OCL And JDI</dc:title>
 <dc:creator>Murray, David J.</dc:creator>
 <dc:creator>Parson, Dale E.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Correctness constraints provide a foundation for automated debugging within
object-oriented systems. This paper discusses a new approach to incorporating
correctness constraints into Java development environments. Our approach uses
the Object Constraint Language (&quot;OCL&quot;) as a specification language and the Java
Debug Interface (&quot;JDI&quot;) as a verification API. OCL provides a standard language
for expressing object-oriented constraints that can integrate with Unified
Modeling Language (&quot;UML&quot;) software models. JDI provides a standard Java API
capable of supporting type-safe and side effect free runtime constraint
evaluation. The resulting correctness constraint mechanism: (1) entails no
programming language modifications; (2) requires neither access nor changes to
existing source code; and (3) works with standard off-the-shelf Java virtual
machines (&quot;VMs&quot;). A prototype correctness constraint auditor is presented to
demonstrate the utility of this mechanism for purposes of automated debugging.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. See cs.SE/0010035</dc:description>
 <dc:date>2001-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101003</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Signal-Theoretic Characterization of Waveguide Mesh Geometries for
  Models of Two--Dimensional Wave Propagation in Elastic Media</dc:title>
 <dc:creator>Fontana, Federico</dc:creator>
 <dc:creator>Rocchesso, Davide</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:description>  Waveguide Meshes are efficient and versatile models of wave propagation along
a multidimensional ideal medium. The choice of the mesh geometry affects both
the computational cost and the accuracy of simulations. In this paper, we focus
on 2D geometries and use multidimensional sampling theory to compare the
square, triangular, and hexagonal meshes in terms of sampling efficiency and
dispersion error under conditions of critical sampling. The analysis shows that
the triangular geometry exhibits the most desirable tradeoff between accuracy
and computational cost.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures, 1 table, to appear on IEEE Transactions on Speech
  and Audio Processing, vol. 9, no. 2, february 2001</dc:description>
 <dc:date>2001-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decomposing Finite Abelian Groups</dc:title>
 <dc:creator>Cheung, Kevin K. H.</dc:creator>
 <dc:creator>Mosca, Michele</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>F.1</dc:subject>
 <dc:description>  This paper describes a quantum algorithm for efficiently decomposing finite
Abelian groups. Such a decomposition is needed in order to apply the Abelian
hidden subgroup algorithm. Such a decomposition (assuming the Generalized
Riemann Hypothesis) also leads to an efficient algorithm for computing class
numbers (known to be at least as difficult as factoring).
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2001-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Slicing Event Traces of Large Software Systems</dc:title>
 <dc:creator>Smith, Raymond</dc:creator>
 <dc:creator>Korel, Bogdan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Debugging of large software systems consisting of many processes accessing
shared resources is a very difficult task. Many commercial systems record
essential events during system execution for post-mortem analysis. However, the
event traces of large and long-running systems can be quite voluminous.
Analysis of such event traces to identify sources of incorrect behavior can be
very tedious, error-prone, and inefficient. In this paper, we propose a novel
technique of slicing event traces as a means of reducing the number of events
for analysis. This technique identifies events that may have influenced
observed incorrect system behavior. In order to recognize influencing events
several types of dependencies between events are identified. These dependencies
are determined automatically from an event trace. In order to improve the
precision of slicing we propose to use additional dependencies, referred to as
cause-effect dependencies, which can further reduce the size of sliced event
traces. Our initial experience has shown that this slicing technique can
significantly reduce the size of event traces for analysis.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2001-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Moebius Transformations for Information Visualization and
  Meshing</dc:title>
 <dc:creator>Bern, Marshall</dc:creator>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  We give linear-time quasiconvex programming algorithms for finding a Moebius
transformation of a set of spheres in a unit ball or on the surface of a unit
sphere that maximizes the minimum size of a transformed sphere. We can also use
similar methods to maximize the minimum distance among a set of pairs of input
points. We apply these results to vertex separation and symmetry display in
spherical graph drawing, viewpoint selection in hyperbolic browsing, element
size control in conformal structured mesh generation, and brain flat mapping.
</dc:description>
 <dc:description>Comment: 16 pages, 7 figures. Revised to include connection to brain
  flat-mapping</dc:description>
 <dc:date>2001-01-11</dc:date>
 <dc:date>2001-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assertion checker for the C programming language based on computations
  over event traces</dc:title>
 <dc:creator>Auguston, Mikhail</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  This paper suggests an approach to the development of software testing and
debugging automation tools based on precise program behavior models. The
program behavior model is defined as a set of events (event trace) with two
basic binary relations over events -- precedence and inclusion, and represents
the temporal relationship between actions. A language for the computations over
event traces is developed that provides a basis for assertion checking,
debugging queries, execution profiles, and performance measurements. The
approach is nondestructive, since assertion texts are separated from the target
program source code and can be maintained independently. Assertions can capture
the dynamic properties of a particular target program and can formalize the
general knowledge of typical bugs and debugging strategies. An event grammar
provides a sound basis for assertion language implementation via target program
automatic instrumentation. An implementation architecture and preliminary
experiments with a prototype assertion checker for the C programming language
are discussed.
</dc:description>
 <dc:description>Comment: Proceedings of AADEBUG 2000 Fourth International Workshop on
  Automated Debugging Munich, Germany, 28-30 August 2000</dc:description>
 <dc:date>2001-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101008</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Knowledge-based Automated Debugger in Learning System</dc:title>
 <dc:creator>Zin, Abdullah Mohd</dc:creator>
 <dc:creator>Aljunid, Syed Ahmad</dc:creator>
 <dc:creator>Shukur, Zarina</dc:creator>
 <dc:creator>Nordin, Mohd Jan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Currently, programming instructors continually face the problem of helping to
debug students' programs. Although there currently exist a number of debuggers
and debugging tools in various platforms, most of these projects or products
are crafted through the needs of software maintenance, and not through the
perspective of teaching of programming. Moreover, most debuggers are too
general, meant for experts as well as not user-friendly. We propose a new
knowledge-based automated debugger to be used as a user-friendly tool by the
students to self-debug their own programs. Stereotyped code (cliche) and bugs
cliche will be stored as library of plans in the knowledge-base. Recognition of
correct code or bugs is based on pattern matching and constraint satisfaction.
Given a syntax error-free program and its specification, this debugger called
Adil (Automated Debugger in Learning system) will be able locate, pinpoint and
explain logical errors of programs. If there are no errors, it will be able to
explain the meaning of the program. Adil is based on the design of the
Conceiver, an automated program understanding system developed at Universiti
Kebangsaan Malaysia.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2001-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generation of and Debugging with Logical Pre and Postconditions</dc:title>
 <dc:creator>Navarro, Angel Herrranz-Nieva Juan Jose Moreno</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.5, F.3.1</dc:subject>
 <dc:description>  This paper shows the debugging facilities provided by the SLAM system. The
SLAM system includes i) a specification language that integrates algebraic
specifications and model-based specifications using the object oriented model.
Class operations are defined by using rules each of them with logical pre and
postconditions but with a functional flavour. ii) A development environment
that, among other features, is able to generate readable code in a high level
object oriented language. iii) The generated code includes (part of) the pre
and postconditions as assertions, that can be automatically checked in the
debug mode execution of programs. We focus on this last aspect.
  The SLAM language is expressive enough to describe many useful properties and
these properties are translated into a Prolog program that is linked (via an
adequate interface) with the user program. The debugging execution of the
program interacts with the Prolog engine which is responsible for checking
properties.
</dc:description>
 <dc:description>Comment: In M. Ducasse (ed), proceedings of the Fourth International Workshop
  on Automated Debugging (AADEBUG 2000), August 2000, Munich. cs.SE/0010035</dc:description>
 <dc:date>2001-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Even Faster and More Unifying Algorithm for Comparing Trees via
  Unbalanced Bipartite Matchings</dc:title>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Lam, Tak-Wah</dc:creator>
 <dc:creator>Sung, Wing-Kin</dc:creator>
 <dc:creator>Ting, Hing-Fung</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  A widely used method for determining the similarity of two labeled trees is
to compute a maximum agreement subtree of the two trees. Previous work on this
similarity measure is only concerned with the comparison of labeled trees of
two special kinds, namely, uniformly labeled trees (i.e., trees with all their
nodes labeled by the same symbol) and evolutionary trees (i.e., leaf-labeled
trees with distinct symbols for distinct leaves). This paper presents an
algorithm for comparing trees that are labeled in an arbitrary manner. In
addition to this generality, this algorithm is faster than the previous
algorithms.
  Another contribution of this paper is on maximum weight bipartite matchings.
We show how to speed up the best known matching algorithms when the input
graphs are node-unbalanced or weight-unbalanced. Based on these enhancements,
we obtain an efficient algorithm for a new matching problem called the
hierarchical bipartite matching problem, which is at the core of our maximum
agreement subtree algorithm.
</dc:description>
 <dc:description>Comment: To appear in Journal of Algorithms</dc:description>
 <dc:date>2001-01-13</dc:date>
 <dc:date>2001-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple-Size Divide-and-Conquer Recurrences</dc:title>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:subject>Computer Science - General Literature</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:description>  This short note reports a master theorem on tight asymptotic solutions to
divide-and-conquer recurrences with more than one recursive term: for example,
T(n) = 1/4 T(n/16) + 1/3 T(3n/5) + 4 T(n/100) + 10 T(n/300) + n^2.
</dc:description>
 <dc:date>2001-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101011</dc:identifier>
 <dc:identifier>SIGACT News, 28(2):67--69, June 1997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communities of Practice in the Distributed International Environment</dc:title>
 <dc:creator>Hildreth, Paul</dc:creator>
 <dc:creator>Kimble, Chris</dc:creator>
 <dc:creator>Wright, Peter</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.5.3</dc:subject>
 <dc:description>  Modern commercial organisations are facing pressures which have caused them
to lose personnel. When they lose people, they also lose their knowledge.
Organisations also have to cope with the internationalisation of business
forcing collaboration and knowledge sharing across time and distance. Knowledge
Management (KM) claims to tackle these issues. This paper looks at an area
where KM does not offer sufficient support, that is, the sharing of knowledge
that is not easy to articulate.
  The focus in this paper is on Communities of Practice in commercial
organisations. We do this by exploring knowledge sharing in Lave and Wenger's
[1] theory of Communities of Practice and investigating how Communities of
Practice may translate to a distributed international environment. The paper
reports on two case studies that explore the functioning of Communities of
Practice across international boundaries.
</dc:description>
 <dc:description>Comment: Available from
  http://www-users.cs.york.ac.uk/~kimble/research/publics.html</dc:description>
 <dc:date>2001-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101012</dc:identifier>
 <dc:identifier>Journal of Knowledge Management, 4(1), March 2000, pp 27 - 37</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Classification of Symbolic Transition Systems</dc:title>
 <dc:creator>Henzinger, Thomas A.</dc:creator>
 <dc:creator>Majumdar, Rupak</dc:creator>
 <dc:creator>Raskin, Jean-Francois</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  We define five increasingly comprehensive classes of infinite-state systems,
called STS1--5, whose state spaces have finitary structure. For four of these
classes, we provide examples from hybrid systems.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2001-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the problem of computing the well-founded semantics</dc:title>
 <dc:creator>Lonc, Zbigniew</dc:creator>
 <dc:creator>Truszczynski, Miroslaw</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  The well-founded semantics is one of the most widely studied and used
semantics of logic programs with negation. In the case of finite propositional
programs, it can be computed in polynomial time, more specifically, in
O(|At(P)|size(P)) steps, where size(P) denotes the total number of occurrences
of atoms in a logic program P. This bound is achieved by an algorithm
introduced by Van Gelder and known as the alternating-fixpoint algorithm.
Improving on the alternating-fixpoint algorithm turned out to be difficult. In
this paper we study extensions and modifications of the alternating-fixpoint
approach. We then restrict our attention to the class of programs whose rules
have no more than one positive occurrence of an atom in their bodies. For
programs in that class we propose a new implementation of the
alternating-fixpoint method in which false atoms are computed in a top-down
fashion. We show that our algorithm is faster than other known algorithms and
that for a wide class of programs it is linear and so, asymptotically optimal.
</dc:description>
 <dc:description>Comment: 19 pages, 4 figures, accepted for publication Theory and Practice of
  Logic Programming</dc:description>
 <dc:date>2001-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101014</dc:identifier>
 <dc:identifier>Theory and Practice of Logic Programming, 1(5), 591-609, 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorial Toolbox for Protein Sequence Design and Landscape Analysis
  in the Grand Canonical Model</dc:title>
 <dc:creator>Aspnes, James</dc:creator>
 <dc:creator>Hartling, Julia</dc:creator>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Kim, Junhyong</dc:creator>
 <dc:creator>Shah, Gauri</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  In modern biology, one of the most important research problems is to
understand how protein sequences fold into their native 3D structures. To
investigate this problem at a high level, one wishes to analyze the protein
landscapes, i.e., the structures of the space of all protein sequences and
their native 3D structures. Perhaps the most basic computational problem at
this level is to take a target 3D structure as input and design a fittest
protein sequence with respect to one or more fitness functions of the target 3D
structure. We develop a toolbox of combinatorial techniques for protein
landscape analysis in the Grand Canonical model of Sun, Brem, Chan, and Dill.
The toolbox is based on linear programming, network flow, and a linear-size
representation of all minimum cuts of a network. It not only substantially
expands the network flow technique for protein sequence design in Kleinberg's
seminal work but also is applicable to a considerably broader collection of
computational problems than those considered by Kleinberg. We have used this
toolbox to obtain a number of efficient algorithms and hardness results. We
have further used the algorithms to analyze 3D structures drawn from the
Protein Data Bank and have discovered some novel relationships between such
native 3D structures and the Grand Canonical model.
</dc:description>
 <dc:date>2001-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dynamic Programming Approach to De Novo Peptide Sequencing via Tandem
  Mass Spectrometry</dc:title>
 <dc:creator>Chen, Ting</dc:creator>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Tepel, Matthew</dc:creator>
 <dc:creator>Rush, John</dc:creator>
 <dc:creator>Church, George M.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  The tandem mass spectrometry fragments a large number of molecules of the
same peptide sequence into charged prefix and suffix subsequences, and then
measures mass/charge ratios of these ions. The de novo peptide sequencing
problem is to reconstruct the peptide sequence from a given tandem mass
spectral data of k ions. By implicitly transforming the spectral data into an
NC-spectrum graph G=(V,E) where |V|=2k+2, we can solve this problem in
O(|V|+|E|) time and O(|V|) space using dynamic programming. Our approach can be
further used to discover a modified amino acid in O(|V||E|) time and to analyze
data with other types of noise in O(|V||E|) time. Our algorithms have been
implemented and tested on actual experimental data.
</dc:description>
 <dc:description>Comment: A preliminary version appeared in Proceedings of the 11th Annual
  ACM-SIAM Symposium on Discrete Algorithms, pages 389--398, 2000</dc:description>
 <dc:date>2001-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Checking Properties within Fairness and Behavior Abstractions</dc:title>
 <dc:creator>Ultes-Nitsche, Ulrich</dc:creator>
 <dc:creator>Wolper, Pierre</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  This paper is motivated by the fact that verifying liveness properties under
a fairness condition is often problematic, especially when abstraction is used.
It shows that using a more abstract notion than truth under fairness,
specifically the concept of a property being satisfied within fairness can lead
to interesting possibilities. Technically, it is first established that
deciding satisfaction within fairness is a PSPACE-complete problem and it is
shown that properties satisfied within fairness can always be satisfied by some
fair implementation. Thereafter, the interaction between behavior abstraction
and satisfaction within fairness is studied and it is proved that satisfaction
of properties within fairness can be verified on behavior abstractions, if the
abstraction homomorphism is weakly continuation-closed.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2001-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GPCG: A Case Study in the Performance and Scalability of Optimization
  Algorithms</dc:title>
 <dc:creator>Benson, Steven J.</dc:creator>
 <dc:creator>McInnes, Lois Curfman</dc:creator>
 <dc:creator>Mor&#xe9;, Jorge J.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  GPCG is an algorithm within the Toolkit for Advanced Optimization (TAO) for
solving bound constrained, convex quadratic problems. Originally developed by
More' and Toraldo, this algorithm was designed for large-scale problems but had
been implemented only for a single processor. The TAO implementation is
available for a wide range of high-performance architecture, and has been
tested on up to 64 processors to solve problems with over 2.5 million
variables.
</dc:description>
 <dc:description>Comment: title + 16 pages</dc:description>
 <dc:date>2001-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101019</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>General Loss Bounds for Universal Sequence Prediction</dc:title>
 <dc:creator>Hutter, Marcus</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  The Bayesian framework is ideally suited for induction problems. The
probability of observing $x_t$ at time $t$, given past observations
$x_1...x_{t-1}$ can be computed with Bayes' rule if the true distribution $\mu$
of the sequences $x_1x_2x_3...$ is known. The problem, however, is that in many
cases one does not even have a reasonable estimate of the true distribution. In
order to overcome this problem a universal distribution $\xi$ is defined as a
weighted sum of distributions $\mu_i\inM$, where $M$ is any countable set of
distributions including $\mu$. This is a generalization of Solomonoff
induction, in which $M$ is the set of all enumerable semi-measures. Systems
which predict $y_t$, given $x_1...x_{t-1}$ and which receive loss $l_{x_t y_t}$
if $x_t$ is the true next symbol of the sequence are considered. It is proven
that using the universal $\xi$ as a prior is nearly as good as using the
unknown true distribution $\mu$. Furthermore, games of chance, defined as a
sequence of bets, observations, and rewards are studied. The time needed to
reach the winning zone is bounded in terms of the relative entropy of $\mu$ and
$\xi$. Extensions to arbitrary alphabets, partial and delayed prediction, and
more active systems are discussed.
</dc:description>
 <dc:description>Comment: 8 two-column pages, LaTeX2e</dc:description>
 <dc:date>2001-01-21</dc:date>
 <dc:date>2001-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101019</dc:identifier>
 <dc:identifier>Proc. 18th Int. Conf. on Machine Learning ICML (2001) 210-217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>More Robust Multiparty Protocols with Oblivious Transfer</dc:title>
 <dc:creator>Mueller-Quade, J.</dc:creator>
 <dc:creator>Imai, H.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:description>  With oblivious transfer multiparty protocols become possible even in the
presence of a faulty majority. But all known protocols can be aborted by just
one disruptor.
  This paper presents more robust solutions for multiparty protocols with
oblivious transfer. This additional robustness against disruptors weakens the
security of the protocol and the guarantee that the result is correct. We can
observe a trade off between robustness against disruption and security and
correctness.
  We give an application to quantum multiparty protocols. These allow the
implementation of oblivious transfer and the protocols of this paper relative
to temporary assumptions, i.e., the security increases after the termination of
the protocol.
</dc:description>
 <dc:description>Comment: 13 pages, major revision</dc:description>
 <dc:date>2001-01-22</dc:date>
 <dc:date>2001-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fast General Methodology for Information-Theoretically Optimal
  Encodings of Graphs</dc:title>
 <dc:creator>He, Xin</dc:creator>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Lu, Hsueh-I</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We propose a fast methodology for encoding graphs with
information-theoretically minimum numbers of bits. Specifically, a graph with
property pi is called a pi-graph. If pi satisfies certain properties, then an
n-node m-edge pi-graph G can be encoded by a binary string X such that (1) G
and X can be obtained from each other in O(n log n) time, and (2) X has at most
beta(n)+o(beta(n)) bits for any continuous super-additive function beta(n) so
that there are at most 2^{beta(n)+o(beta(n))} distinct n-node pi-graphs. The
methodology is applicable to general classes of graphs; this paper focuses on
planar graphs. Examples of such pi include all conjunctions over the following
groups of properties: (1) G is a planar graph or a plane graph; (2) G is
directed or undirected; (3) G is triangulated, triconnected, biconnected,
merely connected, or not required to be connected; (4) the nodes of G are
labeled with labels from {1, ..., ell_1} for ell_1 &lt;= n; (5) the edges of G are
labeled with labels from {1, ..., ell_2} for ell_2 &lt;= m; and (6) each node
(respectively, edge) of G has at most ell_3 = O(1) self-loops (respectively,
ell_4 = O(1) multiple edges). Moreover, ell_3 and ell_4 are not required to be
O(1) for the cases of pi being a plane triangulation. These examples are novel
applications of small cycle separators of planar graphs and are the only
nontrivial classes of graphs, other than rooted trees, with known
polynomial-time information-theoretically optimal coding schemes.
</dc:description>
 <dc:date>2001-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101021</dc:identifier>
 <dc:identifier>SIAM Journal on Computing, 30(3):838--846, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantics and Termination of Simply-Moded Logic Programs with Dynamic
  Scheduling</dc:title>
 <dc:creator>Bossi, Annalisa</dc:creator>
 <dc:creator>Etalle, Sandro</dc:creator>
 <dc:creator>Rossi, Sabina</dc:creator>
 <dc:creator>Smaus, Jan-Georg</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  In logic programming, dynamic scheduling refers to a situation where the
selection of the atom in each resolution (computation) step is determined at
runtime, as opposed to a fixed selection rule such as the left-to-right one of
Prolog. This has applications e.g. in parallel programming. A mechanism to
control dynamic scheduling is provided in existing languages in the form of
delay declarations.
  Input-consuming derivations were introduced to describe dynamic scheduling
while abstracting from the technical details. In this paper, we first formalise
the relationship between delay declarations and input-consuming derivations,
showing in many cases a one-to-one correspondence. Then, we define a
model-theoretic semantics for input-consuming derivations of simply-moded
programs. Finally, for this class of programs, we provide a necessary and
sufficient criterion for termination.
</dc:description>
 <dc:description>Comment: 25 pages, long version of paper with same title at ESOP 2001</dc:description>
 <dc:date>2001-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Properties of Input-Consuming Derivations</dc:title>
 <dc:creator>Bossi, Annalisa</dc:creator>
 <dc:creator>Etalle, Sandro</dc:creator>
 <dc:creator>Rossi, Sabina</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  We study the properties of input-consuming derivations of moded logic
programs. Input-consuming derivations can be used to model the behavior of
logic programs using dynamic scheduling and employing constructs such as delay
declarations.
  We consider the class of nicely-moded programs and queries. We show that for
these programs a weak version of the well-known switching lemma holds also for
input-consuming derivations. Furthermore, we show that, under suitable
conditions, there exists an algebraic characterization of termination of
input-consuming derivations.
</dc:description>
 <dc:description>Comment: 33 pages</dc:description>
 <dc:date>2001-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On-Line Difference Maximization</dc:title>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Tate, Stephen R.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  In this paper we examine problems motivated by on-line financial problems and
stochastic games. In particular, we consider a sequence of entirely arbitrary
distinct values arriving in random order, and must devise strategies for
selecting low values followed by high values in such a way as to maximize the
expected gain in rank from low values to high values.
  First, we consider a scenario in which only one low value and one high value
may be selected. We give an optimal on-line algorithm for this scenario, and
analyze it to show that, surprisingly, the expected gain is n-O(1), and so
differs from the best possible off-line gain by only a constant additive term
(which is, in fact, fairly small -- at most 15).
  In a second scenario, we allow multiple nonoverlapping low/high selections,
where the total gain for our algorithm is the sum of the individual pair gains.
We also give an optimal on-line algorithm for this problem, where the expected
gain is n^2/8-\Theta(n\log n). An analysis shows that the optimal expected
off-line gain is n^2/6+\Theta(1), so the performance of our on-line algorithm
is within a factor of 3/4 of the best off-line strategy.
</dc:description>
 <dc:date>2001-01-23</dc:date>
 <dc:date>2001-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101024</dc:identifier>
 <dc:identifier>SIAM Journal on Discrete Mathematics, 12(1):78-90, 1999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decomposing Non-Redundant Sharing by Complementation</dc:title>
 <dc:creator>Zaffanella, Enea</dc:creator>
 <dc:creator>Hill, Patricia M.</dc:creator>
 <dc:creator>Bagnara, Roberto</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Complementation, the inverse of the reduced product operation, is a technique
for systematically finding minimal decompositions of abstract domains. File'
and Ranzato advanced the state of the art by introducing a simple method for
computing a complement. As an application, they considered the extraction by
complementation of the pair-sharing domain PS from the Jacobs and Langen's
set-sharing domain SH. However, since the result of this operation was still
SH, they concluded that PS was too abstract for this. Here, we show that the
source of this result lies not with PS but with SH and, more precisely, with
the redundant information contained in SH with respect to ground-dependencies
and pair-sharing. In fact, a proper decomposition is obtained if the
non-redundant version of SH, PSD, is substituted for SH. To establish the
results for PSD, we define a general schema for subdomains of SH that includes
PSD and Def as special cases. This sheds new light on the structure of PSD and
exposes a natural though unexpected connection between Def and PSD. Moreover,
we substantiate the claim that complementation alone is not sufficient to
obtain truly minimal decompositions of domains. The right solution to this
problem is to first remove redundancies by computing the quotient of the domain
with respect to the observable behavior, and only then decompose it by
complementation.
</dc:description>
 <dc:description>Comment: To appear on Theory and Practice of Logic Programming. 30 pages, 4
  figures</dc:description>
 <dc:date>2001-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic computations whose history is independent of the order of
  asynchronous updating</dc:title>
 <dc:creator>Gacs, Peter</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:description>  Consider a network of processors (sites) in which each site x has a finite
set N(x) of neighbors. There is a transition function f that for each site x
computes the next state \xi(x) from the states in N(x). But these transitions
(updates) are applied in arbitrary order, one or many at a time. If the state
of site x at time t is \eta(x,t) then let us define the sequence \zeta(x,0),
\zeta(x,1), ... by taking the sequence \eta(x,0), \eta(x,1), ..., and deleting
repetitions. The function f is said to have invariant histories if the sequence
\zeta(x,i), (while it lasts, in case it is finite) depends only on the initial
configuration, not on the order of updates.
  This paper shows that though the invariant history property is typically
undecidable, there is a useful simple sufficient condition, called
commutativity: For any configuration, for any pair x,y of neighbors, if the
updating would change both \xi(x) and \xi(y) then the result of updating first
x and then y is the same as the result of doing this in the reverse order.
</dc:description>
 <dc:date>2001-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Open Archives Initiative protocol development and implementation at
  arXiv</dc:title>
 <dc:creator>Warner, Simeon</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:description>  I outline the involvement of the Los Alamos e-print archive (arXiv) within
the Open Archives Initiative (OAI) and describe the implementation of the data
provider side of the OAI protocol v1.0. I highlight the ways in which we map
the existing structure of arXiv onto elements of the protocol.
</dc:description>
 <dc:description>Comment: 15 pages. Expanded version of talk presented at Open Archives
  Initiative Open Meeting in Washington, DC, USA on 23 January 2001</dc:description>
 <dc:date>2001-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Constructions of Hybrid Algorithms</dc:title>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Ma, Yuan</dc:creator>
 <dc:creator>Sipser, Michael</dc:creator>
 <dc:creator>Yin, Yiqun</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We study on-line strategies for solving problems with hybrid algorithms.
There is a problem Q and w basic algorithms for solving Q. For some lambda &lt;=
w, we have a computer with lambda disjoint memory areas, each of which can be
used to run a basic algorithm and store its intermediate results. In the worst
case, only one basic algorithm can solve Q in finite time, and all the other
basic algorithms run forever without solving Q. To solve Q with a hybrid
algorithm constructed from the basic algorithms, we run a basic algorithm for
some time, then switch to another, and continue this process until Q is solved.
The goal is to solve Q in the least amount of time. Using competitive ratios to
measure the efficiency of a hybrid algorithm, we construct an optimal
deterministic hybrid algorithm and an efficient randomized hybrid algorithm.
This resolves an open question on searching with multiple robots posed by
Baeza-Yates, Culberson and Rawlins. We also prove that our randomized algorithm
is optimal for lambda = 1, settling a conjecture of Kao, Reif and Tate.
</dc:description>
 <dc:date>2001-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101028</dc:identifier>
 <dc:identifier>Journal of Algorithms, 29:142--164, 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tap Tips: Lightweight Discovery of Touchscreen Targets</dc:title>
 <dc:creator>Aoki, Paul M.</dc:creator>
 <dc:creator>Hurst, Amy</dc:creator>
 <dc:creator>Woodruff, Allison</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>H.5.4</dc:subject>
 <dc:subject>I.3.6</dc:subject>
 <dc:description>  We describe tap tips, a technique for providing touch-screen target location
hints. Tap tips are lightweight in that they are non-modal, appear only when
needed, require a minimal number of user gestures, and do not add to the
standard touchscreen gesture vocabulary. We discuss our implementation of tap
tips in an electronic guidebook system and some usability test results.
</dc:description>
 <dc:date>2001-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101029</dc:identifier>
 <dc:identifier>Extended Abstracts, ACM SIGCHI Conf. on Human Factors in Computing
  Systems, Seattle, WA, March 2001, 237-238. ACM Press.</dc:identifier>
 <dc:identifier>doi:10.1145/634067.634208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tree Contractions and Evolutionary Trees</dc:title>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  An evolutionary tree is a rooted tree where each internal vertex has at least
two children and where the leaves are labeled with distinct symbols
representing species. Evolutionary trees are useful for modeling the
evolutionary history of species. An agreement subtree of two evolutionary trees
is an evolutionary tree which is also a topological subtree of the two given
trees. We give an algorithm to determine the largest possible number of leaves
in any agreement subtree of two trees T_1 and T_2 with n leaves each. If the
maximum degree d of these trees is bounded by a constant, the time complexity
is O(n log^2(n)) and is within a log(n) factor of optimal. For general d, this
algorithm runs in O(n d^2 log(d) log^2(n)) time or alternatively in O(n d
sqrt(d) log^3(n)) time.
</dc:description>
 <dc:date>2001-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101030</dc:identifier>
 <dc:identifier>SIAM Journal on Computing, 27(6):1592--1616, December 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cavity Matchings, Label Compressions, and Unrooted Evolutionary Trees</dc:title>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Lam, Tak-Wah</dc:creator>
 <dc:creator>Sung, Wing-Kin</dc:creator>
 <dc:creator>Ting, Hing-Fung</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  We present an algorithm for computing a maximum agreement subtree of two
unrooted evolutionary trees. It takes O(n^{1.5} log n) time for trees with
unbounded degrees, matching the best known time complexity for the rooted case.
Our algorithm allows the input trees to be mixed trees, i.e., trees that may
contain directed and undirected edges at the same time. Our algorithm adopts a
recursive strategy exploiting a technique called label compression. The
backbone of this technique is an algorithm that computes the maximum weight
matchings over many subgraphs of a bipartite graph as fast as it takes to
compute a single matching.
</dc:description>
 <dc:date>2001-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101031</dc:identifier>
 <dc:identifier>SIAM Journal on Computing, 30(2):602--624, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Total Protection of Analytic Invariant Information in Cross Tabulated
  Tables</dc:title>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>H.2.0</dc:subject>
 <dc:description>  To protect sensitive information in a cross tabulated table, it is a common
practice to suppress some of the cells in the table. An analytic invariant is a
power series in terms of the suppressed cells that has a unique feasible value
and a convergence radius equal to +\infty. Intuitively, the information
contained in an invariant is not protected even though the values of the
suppressed cells are not disclosed. This paper gives an optimal linear-time
algorithm for testing whether there exist nontrivial analytic invariants in
terms of the suppressed cells in a given set of suppressed cells. This paper
also presents NP-completeness results and an almost linear-time algorithm for
the problem of suppressing the minimum number of cells in addition to the
sensitive ones so that the resulting table does not leak analytic invariant
information about a given set of suppressed cells.
</dc:description>
 <dc:date>2001-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101032</dc:identifier>
 <dc:identifier>SIAM Journal on Computing, 26(1):231--242, February 1997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear-Time Succinct Encodings of Planar Graphs via Canonical Orderings</dc:title>
 <dc:creator>He, Xin</dc:creator>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Lu, Hsueh-I</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Let G be an embedded planar undirected graph that has n vertices, m edges,
and f faces but has no self-loop or multiple edge. If G is triangulated, we can
encode it using {4/3}m-1 bits, improving on the best previous bound of about
1.53m bits. In case exponential time is acceptable, roughly 1.08m bits have
been known to suffice. If G is triconnected, we use at most
(2.5+2\log{3})\min\{n,f\}-7 bits, which is at most 2.835m bits and smaller than
the best previous bound of 3m bits. Both of our schemes take O(n) time for
encoding and decoding.
</dc:description>
 <dc:date>2001-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101033</dc:identifier>
 <dc:identifier>SIAM Journal on Discrete Mathematics, 12(3):317--325, 1999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Security Equals Graph Connectivity</dc:title>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>H.2.0</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  To protect sensitive information in a cross tabulated table, it is a common
practice to suppress some of the cells in the table. This paper investigates
four levels of data security of a two-dimensional table concerning the
effectiveness of this practice. These four levels of data security protect the
information contained in, respectively, individual cells, individual rows and
columns, several rows or columns as a whole, and a table as a whole. The paper
presents efficient algorithms and NP-completeness results for testing and
achieving these four levels of data security. All these complexity results are
obtained by means of fundamental equivalences between the four levels of data
security of a table and four types of connectivity of a graph constructed from
that table.
</dc:description>
 <dc:date>2001-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101034</dc:identifier>
 <dc:identifier>SIAM Journal on Discrete Mathematics, 9:87--100, 1996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Guidebook, the Friend, and the Room: Visitor Experience in a
  Historic House</dc:title>
 <dc:creator>Woodruff, Allison</dc:creator>
 <dc:creator>Aoki, Paul M.</dc:creator>
 <dc:creator>Hurst, Amy</dc:creator>
 <dc:creator>Szymanski, Margaret H.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>J.5</dc:subject>
 <dc:description>  In this paper, we describe an electronic guidebook prototype and report on a
study of its use in a historic house. Supported by mechanisms in the guidebook,
visitors constructed experiences that had a high degree of interaction with
three entities: the guidebook, their companions, and the house and its
contents. For example, we found that most visitors played audio descriptions
played through speakers (rather than using headphones or reading textual
descriptions) to facilitate communication with their companions.
</dc:description>
 <dc:date>2001-01-28</dc:date>
 <dc:date>2001-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101035</dc:identifier>
 <dc:identifier>Extended Abstracts, ACM SIGCHI Conf. on Human Factors in Computing
  Systems, Seattle, WA, March 2001, 273-274. ACM Press.</dc:identifier>
 <dc:identifier>doi:10.1145/634067.634229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0101036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Generalized Universal Law of Generalization</dc:title>
 <dc:creator>Chater, Nick</dc:creator>
 <dc:creator>Vitanyi, Paul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  It has been argued by Shepard that there is a robust psychological law that
relates the distance between a pair of items in psychological space and the
probability that they will be confused with each other. Specifically, the
probability of confusion is a negative exponential function of the distance
between the pair of items. In experimental contexts, distance is typically
defined in terms of a multidimensional Euclidean space-but this assumption
seems unlikely to hold for complex stimuli. We show that, nonetheless, the
Universal Law of Generalization can be derived in the more complex setting of
arbitrary stimuli, using a much more universal measure of distance. This
universal distance is defined as the length of the shortest program that
transforms the representations of the two items of interest into one another:
the algorithmic information distance. It is universal in the sense that it
minorizes every computable distance: it is the smallest computable distance. We
show that the universal law of generalization holds with probability going to
one-provided the confusion probabilities are computable. We also give a
mathematically more appealing form
</dc:description>
 <dc:description>Comment: 17 pages LaTeX, Submitted</dc:description>
 <dc:date>2001-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0101036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmarking Optimization Software with Performance Profiles</dc:title>
 <dc:creator>Dolan, Elizabeth D.</dc:creator>
 <dc:creator>Mor&#xe9;, Jorge J.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  We propose performance profiles-distribution functions for a performance
metric-as a tool for benchmarking and comparing optimization software. We show
that performance profiles combine the best features of other tools for
performance evaluation.
</dc:description>
 <dc:description>Comment: 13 pages plus title and toc pages</dc:description>
 <dc:date>2001-02-01</dc:date>
 <dc:date>2004-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102001</dc:identifier>
 <dc:identifier>Math. Program., Ser. A 91: 201-213 (2002)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Automated Classification of Web Sites</dc:title>
 <dc:creator>Pierre, John M.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.5.2</dc:subject>
 <dc:subject>H.5.4</dc:subject>
 <dc:description>  In this paper we discuss several issues related to automated text
classification of web sites. We analyze the nature of web content and metadata
in relation to requirements for text features. We find that HTML metatags are a
good source of text features, but are not in wide use despite their role in
search engine rankings. We present an approach for targeted spidering including
metadata extraction and opportunistic crawling of specific semantic hyperlinks.
We describe a system for automatically classifying web sites into industry
categories and present performance results based on different combinations of
text features and training data. This system can serve as the basis for a
generalized framework for automated metadata creation.
</dc:description>
 <dc:description>Comment: 12 pages, etendu.sty</dc:description>
 <dc:date>2001-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Pricing of European Asian Options with Provable Accuracy:
  Single-stock and Basket Options</dc:title>
 <dc:creator>Akcoglu, Karhan</dc:creator>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Raghavan, Shuba</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  This paper develops three polynomial-time pricing techniques for European
Asian options with provably small errors, where the stock prices follow
binomial trees or trees of higher-degree. The first technique is the first
known Monte Carlo algorithm with analytical error bounds suitable for pricing
single-stock options with meaningful confidence and speed. The second technique
is a general recursive bucketing-based scheme that can use the
Aingworth-Motwani-Oldham aggregation algorithm, Monte-Carlo simulation and
possibly others as the base-case subroutine. This scheme enables robust
trade-offs between accuracy and time over subtrees of different sizes. For
long-term options or high frequency price averaging, it can price single-stock
options with smaller errors in less time than the base-case algorithms
themselves. The third technique combines Fast Fourier Transform with
bucketing-based schemes for pricing basket options. This technique takes
polynomial time in the number of days and the number of stocks, and does not
add any errors to those already incurred in the companion bucketing scheme.
This technique assumes that the price of each underlying stock moves
independently.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2001-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Geometry Column 41</dc:title>
 <dc:creator>O'Rourke, Joseph</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  The recent result that n congruent balls in R^d have at most 4 distinct
geometric permutations is described.
</dc:description>
 <dc:description>Comment: To appear in SIGACT News and in Internat. J. Comput. Geom. Appl</dc:description>
 <dc:date>2001-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compact Encodings of Planar Graphs via Canonical Orderings and Multiple
  Parentheses</dc:title>
 <dc:creator>Chuang, Richie Chih-Nan</dc:creator>
 <dc:creator>Garg, Ashim</dc:creator>
 <dc:creator>He, Xin</dc:creator>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Lu, Hsueh-I</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:description>  Let G be a plane graph of n nodes, m edges, f faces, and no self-loop. G need
not be connected or simple (i.e., free of multiple edges). We give three sets
of coding schemes for G which all take O(m+n) time for encoding and decoding.
Our schemes employ new properties of canonical orderings for planar graphs and
new techniques of processing strings of multiple types of parentheses.
  For applications that need to determine in O(1) time the adjacency of two
nodes and the degree of a node, we use 2m+(5+1/k)n + o(m+n) bits for any
constant k &gt; 0 while the best previous bound by Munro and Raman is 2m+8n +
o(m+n). If G is triconnected or triangulated, our bit count decreases to 2m+3n
+ o(m+n) or 2m+2n + o(m+n), respectively. If G is simple, our bit count is
(5/3)m+(5+1/k)n + o(n) for any constant k &gt; 0. Thus, if a simple G is also
triconnected or triangulated, then 2m+2n + o(n) or 2m+n + o(n) bits suffice,
respectively.
  If only adjacency queries are supported, the bit counts for a general G and a
simple G become 2m+(14/3)n + o(m+n) and (4/3)m+5n + o(n), respectively.
  If we only need to reconstruct G from its code, a simple and triconnected G
uses roughly 2.38m + O(1) bits while the best previous bound by He, Kao, and Lu
is 2.84m.
</dc:description>
 <dc:description>Comment: 24 pages; 3 figures; a preliminary version appeared in the
  Proceedings of ICALP'98, LNCS 1443, pp. 118-129. (The 2nd version contains
  some minor changes.)</dc:description>
 <dc:date>2001-02-07</dc:date>
 <dc:date>2001-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102006</identifier>
 <datestamp>2015-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Orderly Spanning Trees with Applications</dc:title>
 <dc:creator>Chiang, Yi-Ting</dc:creator>
 <dc:creator>Lin, Ching-Chi</dc:creator>
 <dc:creator>Lu, Hsueh-I</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:description>  We introduce and study the {\em orderly spanning trees} of plane graphs. This
algorithmic tool generalizes {\em canonical orderings}, which exist only for
triconnected plane graphs. Although not every plane graph admits an orderly
spanning tree, we provide an algorithm to compute an {\em orderly pair} for any
connected planar graph $G$, consisting of a plane graph $H$ of $G$, and an
orderly spanning tree of $H$. We also present several applications of orderly
spanning trees: (1) a new constructive proof for Schnyder's Realizer Theorem,
(2) the first area-optimal 2-visibility drawing of $G$, and (3) the best known
encodings of $G$ with O(1)-time query support. All algorithms in this paper run
in linear time.
</dc:description>
 <dc:description>Comment: 25 pages, 7 figures, A preliminary version appeared in Proceedings of
  the 12th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2001),
  Washington D.C., USA, January 7-9, 2001, pp. 506-515</dc:description>
 <dc:date>2001-02-07</dc:date>
 <dc:date>2002-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102006</dc:identifier>
 <dc:identifier>SIAM Journal on Computing 34(4): 924-945 (2005)</dc:identifier>
 <dc:identifier>doi:10.1137/S0097539702411381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Common-Face Embeddings of Planar Graphs</dc:title>
 <dc:creator>Chen, Zhi-Zhong</dc:creator>
 <dc:creator>He, Xin</dc:creator>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Given a planar graph G and a sequence C_1,...,C_q, where each C_i is a family
of vertex subsets of G, we wish to find a plane embedding of G, if any exists,
such that for each i in {1,...,q}, there is a face F_i in the embedding whose
boundary contains at least one vertex from each set in C_i. This problem has
applications to the recovery of topological information from geographical data
and the design of constrained layouts in VLSI. Let I be the input size, i.e.,
the total number of vertices and edges in G and the families C_i, counting
multiplicity. We show that this problem is NP-complete in general. We also show
that it is solvable in O(I log I) time for the special case where for each
input family C_i, each set in C_i induces a connected subgraph of the input
graph G. Note that the classical problem of simply finding a planar embedding
is a further special case of this case with q=0. Therefore, the processing of
the additional constraints C_1,...,C_q only incurs a logarithmic factor of
overhead.
</dc:description>
 <dc:description>Comment: A preliminary version appeared in the Proceedings of the 10th Annual
  ACM-SIAM Symposium on Discrete Algorithms, 1999, pp. 195-204</dc:description>
 <dc:date>2001-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Bid Sequences for Multiple-Object Auctions with Unequal Budgets</dc:title>
 <dc:creator>Chen, Yuyu</dc:creator>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Lu, Hsueh-I</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  In a multiple-object auction, every bidder tries to win as many objects as
possible with a bidding algorithm. This paper studies position-randomized
auctions, which form a special class of multiple-object auctions where a
bidding algorithm consists of an initial bid sequence and an algorithm for
randomly permuting the sequence. We are especially concerned with situations
where some bidders know the bidding algorithms of others. For the case of only
two bidders, we give an optimal bidding algorithm for the disadvantaged bidder.
Our result generalizes previous work by allowing the bidders to have unequal
budgets. One might naturally anticipate that the optimal expected numbers of
objects won by the bidders would be proportional to their budgets.
Surprisingly, this is not true. Our new algorithm runs in optimal O(n) time in
a straightforward manner. The case with more than two bidders is open.
</dc:description>
 <dc:description>Comment: A preliminary version appeared in In D. T. Lee and S. H. Teng,
  editors, Lecture Notes in Computer Science 1969: Proceedings of the 11th
  Annual International Symposium on Algorithms and Computation, pages 84--95,
  New York, NY, 2000. Springer-Verlag</dc:description>
 <dc:date>2001-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Augmentation for Bipartite Componentwise Biconnectivity in
  Linear Time</dc:title>
 <dc:creator>Hsu, Tsan-sheng</dc:creator>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  A graph is componentwise biconnected if every connected component either is
an isolated vertex or is biconnected. We present a linear-time algorithm for
the problem of adding the smallest number of edges to make a bipartite graph
componentwise biconnected while preserving its bipartiteness. This algorithm
has immediate applications for protecting sensitive information in statistical
tables.
</dc:description>
 <dc:description>Comment: A preliminary version appeared in T. Asano, Y. Igarashi, H.
  Nagamochi, S. Miyano, and S. Suri, editors, Lecture Notes in Computer Science
  1178: Proceedings of the 7th Annual International Symposium on Algorithms and
  Computation, pages 213--222. Springer-Verlag, New York, NY, 1996</dc:description>
 <dc:date>2001-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Enhanced Double Digest Problem for DNA Physical Mapping</dc:title>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Samet, Jared</dc:creator>
 <dc:creator>Sung, Wing-Kin</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  The double digest problem is a common NP-hard approach to constructing
physical maps of DNA sequences. This paper presents a new approach called the
enhanced double digest problem. Although this new problem is also NP-hard, it
can be solved in linear time in certain theoretically interesting cases.
</dc:description>
 <dc:description>Comment: A preliminary version appeared in M. Halldorsson, editor, Lecture
  Notes in Computer Science 1851: Proceedings of the 7th Scandinavian Workshop
  on Algorithm Theory, pages 383--392. Springer-Verlag, New York, NY, 2000</dc:description>
 <dc:date>2001-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Price Dynamics in Bandwidth Markets for Point-to-point Connections</dc:title>
 <dc:creator>Rasmusson, Lars</dc:creator>
 <dc:creator>Aurell, Erik</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Condensed Matter - Soft Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>C.2.3</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:description>  We simulate a network of N routers and M network users making concurrent
point-to-point connections by buying and selling router capacity from each
other. The resources need to be acquired in complete sets, but there is only
one spot market for each router. In order to describe the internal dynamics of
the market, we model the observed prices by N-dimensional Ito-processes.
Modeling using stochastic processes is novel in this context of describing
interactions between end-users in a system with shared resources, and allows a
standard set of mathematical tools to be applied. The derived models can also
be used to price contingent claims on network capacity and thus to price
complex network services such as quality of service levels, multicast, etc.
</dc:description>
 <dc:description>Comment: 18 pages, 10 postscript figures</dc:description>
 <dc:date>2001-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chaos for Stream Cipher</dc:title>
 <dc:creator>Philip, Ninan Sajeeth</dc:creator>
 <dc:creator>Joseph, K. Babu</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>A0</dc:subject>
 <dc:description>  This paper discusses mixing of chaotic systems as a dependable method for
secure communication. Distribution of the entropy function for steady state as
well as plaintext input sequences are analyzed. It is shown that the mixing of
chaotic sequences results in a sequence that does not have any state dependence
on the information encrypted by them. The generated output states of such a
cipher approach the theoretical maximum for both complexity measures and cycle
length. These features are then compared with some popular ciphers.
</dc:description>
 <dc:description>Comment: 8 pages 6 figures</dc:description>
 <dc:date>2001-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102012</dc:identifier>
 <dc:identifier>In proceedings of ADCOM 2000, Tata McGraw Hill 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Multi-Prover Interactive Proof Systems with Limited Prior
  Entanglement</dc:title>
 <dc:creator>Kobayashi, Hirotada</dc:creator>
 <dc:creator>Matsumoto, Keiji</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  This paper gives the first formal treatment of a quantum analogue of
multi-prover interactive proof systems. It is proved that the class of
languages having quantum multi-prover interactive proof systems is necessarily
contained in NEXP, under the assumption that provers are allowed to share at
most polynomially many prior-entangled qubits. This implies that, in
particular, if provers do not share any prior entanglement with each other, the
class of languages having quantum multi-prover interactive proof systems is
equal to NEXP. Related to these, it is shown that, in the case a prover does
not have his private qubits, the class of languages having quantum
single-prover interactive proof systems is also equal to NEXP.
</dc:description>
 <dc:description>Comment: LaTeX2e, 19 pages, 2 figures, title changed, some of the sections are
  fully revised, journal version in Journal of Computer and System Sciences</dc:description>
 <dc:date>2001-02-19</dc:date>
 <dc:date>2003-06-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102013</dc:identifier>
 <dc:identifier>Journal of Computer and System Sciences, 66(3):429--450, 2003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the predictability of Rainfall in Kerala- An application of ABF
  Neural Network</dc:title>
 <dc:creator>Philip, Ninan Sajeeth</dc:creator>
 <dc:creator>Joseph, K. Babu</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>A0</dc:subject>
 <dc:description>  Rainfall in Kerala State, the southern part of Indian Peninsula in particular
is caused by the two monsoons and the two cyclones every year. In general,
climate and rainfall are highly nonlinear phenomena in nature giving rise to
what is known as the `butterfly effect'. We however attempt to train an ABF
neural network on the time series rainfall data and show for the first time
that in spite of the fluctuations resulting from the nonlinearity in the
system, the trends in the rainfall pattern in this corner of the globe have
remained unaffected over the past 87 years from 1893 to 1980. We also
successfully filter out the chaotic part of the system and illustrate that its
effects are marginal over long term predictions.
</dc:description>
 <dc:date>2001-02-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-convex cost functionals in boosting algorithms and methods for panel
  selection</dc:title>
 <dc:creator>Visentin, Marco</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>G.1.2</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.6.5</dc:subject>
 <dc:description>  In this document we propose a new improvement for boosting techniques as
proposed in Friedman '99 by the use of non-convex cost functional. The idea is
to introduce a correlation term to better deal with forecasting of additive
time series. The problem is discussed in a theoretical way to prove the
existence of minimizing sequence, and in a numerical way to propose a new
&quot;ArgMin&quot; algorithm. The model has been used to perform the touristic presence
forecast for the winter season 1999/2000 in Trentino (italian Alps).
</dc:description>
 <dc:date>2001-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Scientific Data Management System for Irregular Applications</dc:title>
 <dc:creator>No, Jaechun</dc:creator>
 <dc:creator>Thakur, Rajeev</dc:creator>
 <dc:creator>Kaushik, Dinesh</dc:creator>
 <dc:creator>Freitag, Lori</dc:creator>
 <dc:creator>Choudhary, Alok</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>B.4</dc:subject>
 <dc:subject>B.4.3</dc:subject>
 <dc:description>  Many scientific applications are I/O intensive and generate or access large
data sets, spanning hundreds or thousands of &quot;files.&quot; Management, storage,
efficient access, and analysis of this data present an extremely challenging
task. We have developed a software system, called Scientific Data Manager
(SDM), that uses a combination of parallel file I/O and database support for
high-performance scientific data management. SDM provides a high-level API to
the user and internally, uses a parallel file system to store real data and a
database to store application-related metadata. In this paper, we describe how
we designed and implemented SDM to support irregular applications. SDM can
efficiently handle the reading and writing of data in an irregular mesh as well
as the distribution of index values. We describe the SDM user interface and how
we implemented it to achieve high performance. SDM makes extensive use of
MPI-IO's noncontiguous collective I/O functions. SDM also uses the concept of a
history file to optimize the cost of the index distribution using the metadata
stored in the database. We present performance results with two irregular
applications, a CFD code called FUN3D and a Rayleigh-Taylor instability code,
on the SGI Origin2000 at Argonne National Laboratory.
</dc:description>
 <dc:description>Comment: 7 pages + title page</dc:description>
 <dc:date>2001-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Components and Interfaces of a Process Management System for Parallel
  Programs</dc:title>
 <dc:creator>Butler, Ralph</dc:creator>
 <dc:creator>Gropp, William</dc:creator>
 <dc:creator>Lusk, Ewing</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.1.4</dc:subject>
 <dc:description>  Parallel jobs are different from sequential jobs and require a different type
of process management. We present here a process management system for parallel
programs such as those written using MPI. A primary goal of the system, which
we call MPD (for multipurpose daemon), is to be scalable. By this we mean that
startup of interactive parallel jobs comprising thousands of processes is
quick, that signals can be quickly delivered to processes, and that stdin,
stdout, and stderr are managed intuitively. Our primary target is parallel
machines made up of clusters of SMPs, but the system is also useful in more
tightly integrated environments. We describe how MPD enables much faster
startup and better runtime management of parallel jobs. We show how close
control of stdio can support the easy implementation of a number of convenient
system utilities, even a parallel debugger. We describe a simple but general
interface that can be used to separate any process manager from a parallel
library, which we use to keep MPD separate from MPICH.
</dc:description>
 <dc:description>Comment: 12 pages, Workshop on Clusters and Computational Grids for Scientific
  Computing, Sept. 24-27, 2000, Le Chateau de Faverges de la Tour, France</dc:description>
 <dc:date>2001-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An effective Procedure for Speeding up Algorithms</dc:title>
 <dc:creator>Hutter, Marcus</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>F.2.3</dc:subject>
 <dc:description>  The provably asymptotically fastest algorithm within a factor of 5 for
formally described problems will be constructed. The main idea is to enumerate
all programs provably equivalent to the original problem by enumerating all
proofs. The algorithm could be interpreted as a generalization and improvement
of Levin search, which is, within a multiplicative constant, the fastest
algorithm for inverting functions. Blum's speed-up theorem is avoided by taking
into account only programs for which a correctness proof exists. Furthermore,
it is shown that the fastest program that computes a certain function is also
one of the shortest programs provably computing this function. To quantify this
statement, the definition of Kolmogorov complexity is extended, and two new
natural measures for the complexity of a function are defined.
</dc:description>
 <dc:description>Comment: 10 LaTeX pages</dc:description>
 <dc:date>2001-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102018</dc:identifier>
 <dc:identifier>Workshop on Mathematical approaches to Biological Computation
  (MaBiC 2001) and Workshop on Algorithmic Information Theory (TAI 2001)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Easy and Hard Constraint Ranking in OT: Algorithms and Complexity</dc:title>
 <dc:creator>Eisner, Jason</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We consider the problem of ranking a set of OT constraints in a manner
consistent with data.
  We speed up Tesar and Smolensky's RCD algorithm to be linear on the number of
constraints. This finds a ranking so each attested form x_i beats or ties a
particular competitor y_i. We also generalize RCD so each x_i beats or ties all
possible competitors.
  Alas, this more realistic version of learning has no polynomial algorithm
unless P=NP! Indeed, not even generation does. So one cannot improve
qualitatively upon brute force:
  Merely checking that a single (given) ranking is consistent with given forms
is coNP-complete if the surface forms are fully observed and Delta_2^p-complete
if not. Indeed, OT generation is OptP-complete. As for ranking, determining
whether any consistent ranking exists is coNP-hard (but in Delta_2^p) if the
forms are fully observed, and Sigma_2^p-complete if not.
  Finally, we show that generation and ranking are easier in derivational
theories: in P, and NP-complete.
</dc:description>
 <dc:description>Comment: 12 pages, online proceedings version (small corrections and
  clarifications to printed version)</dc:description>
 <dc:date>2001-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102019</dc:identifier>
 <dc:identifier>Jason Eisner, Lauri Karttunen and Alain Theriault (eds.),
  Finite-State Phonology: Proceedings of the 5th Workshop of the ACL Special
  Interest Group in Computational Phonology (SIGPHON), pp. 22-33. Luxembourg,
  August 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Syllable Phonotactic Modelling</dc:title>
 <dc:creator>Belz, Anja</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper describes a novel approach to constructing phonotactic models. The
underlying theoretical approach to phonological description is the
multisyllable approach in which multiple syllable classes are defined that
reflect phonotactically idiosyncratic syllable subcategories. A new
finite-state formalism, OFS Modelling, is used as a tool for encoding,
automatically constructing and generalising phonotactic descriptions.
Language-independent prototype models are constructed which are instantiated on
the basis of data sets of phonological strings, and generalised with a
clustering algorithm. The resulting approach enables the automatic construction
of phonotactic models that encode arbitrarily close approximations of a
language's set of attested phonological forms. The approach is applied to the
construction of multi-syllable word-level phonotactic models for German,
English and Dutch.
</dc:description>
 <dc:description>Comment: 11 pages, 4 tables, 9 figures, workshop</dc:description>
 <dc:date>2001-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102020</dc:identifier>
 <dc:identifier>Jason Eisner, Lauri Karttunen and Alain Theriault (eds.),
  Finite-State Phonology: Proceedings of the 5th Workshop of the ACL Special
  Interest Group in Computational Phonology (SIGPHON), pp. 46-56. Luxembourg,
  August 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Taking Primitive Optimality Theory Beyond the Finite State</dc:title>
 <dc:creator>Albro, Daniel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Primitive Optimality Theory (OTP) (Eisner, 1997a; Albro, 1998), a
computational model of Optimality Theory (Prince and Smolensky, 1993), employs
a finite state machine to represent the set of active candidates at each stage
of an Optimality Theoretic derivation, as well as weighted finite state
machines to represent the constraints themselves. For some purposes, however,
it would be convenient if the set of candidates were limited by some set of
criteria capable of being described only in a higher-level grammar formalism,
such as a Context Free Grammar, a Context Sensitive Grammar, or a Multiple
Context Free Grammar (Seki et al., 1991). Examples include reduplication and
phrasal stress models. Here we introduce a mechanism for OTP-like Optimality
Theory in which the constraints remain weighted finite state machines, but sets
of candidates are represented by higher-level grammars. In particular, we use
multiple context-free grammars to model reduplication in the manner of
Correspondence Theory (McCarthy and Prince, 1995), and develop an extended
version of the Earley Algorithm (Earley, 1970) to apply the constraints to a
reduplicating candidate set.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures, workshop</dc:description>
 <dc:date>2001-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102021</dc:identifier>
 <dc:identifier>Jason Eisner, Lauri Karttunen and Alain Theriault (eds.),
  Finite-State Phonology: Proceedings of the 5th Workshop of the ACL Special
  Interest Group in Computational Phonology (SIGPHON), pp. 57-67. Luxembourg,
  August 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite-State Phonology: Proceedings of the 5th Workshop of the ACL
  Special Interest Group in Computational Phonology (SIGPHON)</dc:title>
 <dc:creator>Eisner, Jason</dc:creator>
 <dc:creator>Karttunen, Lauri</dc:creator>
 <dc:creator>Theriault, Alain</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Home page of the workshop proceedings, with pointers to the individually
archived papers. Includes front matter from the printed version of the
proceedings.
</dc:description>
 <dc:description>Comment: HTML page, Conference programme, short abstracts, links to papers,
  preface</dc:description>
 <dc:date>2001-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102022</dc:identifier>
 <dc:identifier>Jason Eisner, Lauri Karttunen and Alain Theriault (eds.),
  Finite-State Phonology: Proceedings of the 5th Workshop of the ACL Special
  Interest Group in Computational Phonology (SIGPHON). Luxembourg, August 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Factored Notation for Interval I/O</dc:title>
 <dc:creator>van Emden, M. H.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>B.4.m</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  This note addresses the input and output of intervals in the sense of
interval arithmetic and interval constraints. The most obvious, and so far most
widely used notation, for intervals has drawbacks that we remedy with a new
notation that we propose to call factored notation. It is more compact and
allows one to find a good trade-off between interval width and ease of reading.
We describe how such a trade-off can be based on the information yield (in the
sense of information theory) of the last decimal shown.
</dc:description>
 <dc:date>2001-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>P-Immune Sets with Holes Lack Self-Reducibility Properties</dc:title>
 <dc:creator>Hemaspaandra, Lane A.</dc:creator>
 <dc:creator>Hempel, Harald</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  No P-immune set having exponential gaps is positive-Turing self-reducible.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2001-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Effective Fixpoint Semantics for Linear Logic Programs</dc:title>
 <dc:creator>Bozzano, Marco</dc:creator>
 <dc:creator>Delzanno, Giorgio</dc:creator>
 <dc:creator>Martelli, Maurizio</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  In this paper we investigate the theoretical foundation of a new bottom-up
semantics for linear logic programs, and more precisely for the fragment of
LinLog that consists of the language LO enriched with the constant 1. We use
constraints to symbolically and finitely represent possibly infinite
collections of provable goals. We define a fixpoint semantics based on a new
operator in the style of Tp working over constraints. An application of the
fixpoint operator can be computed algorithmically. As sufficient conditions for
termination, we show that the fixpoint computation is guaranteed to converge
for propositional LO. To our knowledge, this is the first attempt to define an
effective fixpoint semantics for linear logic programs. As an application of
our framework, we also present a formal investigation of the relations between
LO and Disjunctive Logic Programming. Using an approach based on abstract
interpretation, we show that DLP fixpoint semantics can be viewed as an
abstraction of our semantics for LO. We prove that the resulting abstraction is
correct and complete for an interesting class of LO programs encoding Petri
Nets.
</dc:description>
 <dc:description>Comment: 39 pages, 5 figures. To appear in Theory and Practice of Logic
  Programming</dc:description>
 <dc:date>2001-02-23</dc:date>
 <dc:date>2001-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mathematical Model of Word Length on the Basis of the Cebanov-Fucks
  Distribution with Uniform Parameter Distribution</dc:title>
 <dc:creator>Kromer, Victor</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The data on 13 typologically different languages have been processed using a
two-parameter word length model, based on 1-displaced uniform Poisson
distribution. Statistical dependencies of the 2nd parameter on the 1st one are
revealed for the German texts and genre of letters.
</dc:description>
 <dc:description>Comment: 4 pages, 1 table, 2 figures.Submitted to Conference on Informatics
  and Telecommunications, to be held in Sibirian State University of
  Telecommunications (Novosibirsk, Russia) in April, 2001</dc:description>
 <dc:date>2001-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102026</dc:identifier>
 <dc:identifier>Kromer V.W. Matematiceskaja model' dliny slova na osnove
  raspredelenija Cebanova-Fuksa s ravnomernym raspredeleniem parametra //
  Informatika i problemy telekommunikacij: Mezdunarodnaja naucno-techniceskaja
  konferencija (SibGUTI, 26-27 aprelja 2001 g.) Materialy konferencii. -
  Novosibirsk: Isd-vo SibGUTI, 2001. - S. 74-75.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gene Expression Programming: a New Adaptive Algorithm for Solving
  Problems</dc:title>
 <dc:creator>Ferreira, Candida</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:description>  Gene expression programming, a genotype/phenotype genetic algorithm (linear
and ramified), is presented here for the first time as a new technique for the
creation of computer programs. Gene expression programming uses character
linear chromosomes composed of genes structurally organized in a head and a
tail. The chromosomes function as a genome and are subjected to modification by
means of mutation, transposition, root transposition, gene transposition, gene
recombination, and one- and two-point recombination. The chromosomes encode
expression trees which are the object of selection. The creation of these
separate entities (genome and expression tree) with distinct functions allows
the algorithm to perform with high efficiency that greatly surpasses existing
adaptive techniques. The suite of problems chosen to illustrate the power and
versatility of gene expression programming includes symbolic regression,
sequence induction with and without constant creation, block stacking, cellular
automata rules for the density-classification problem, and two problems of
boolean concept learning: the 11-multiplexer and the GP rule problem.
</dc:description>
 <dc:description>Comment: 22 pages, 17 figures</dc:description>
 <dc:date>2001-02-25</dc:date>
 <dc:date>2001-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102027</dc:identifier>
 <dc:identifier>Complex Systems, 13(2): 87-129, 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communities of Practice: Going Virtual</dc:title>
 <dc:creator>Kimble, Chris</dc:creator>
 <dc:creator>Hildreth, Paul</dc:creator>
 <dc:creator>Wright, Peter</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>H.5.3</dc:subject>
 <dc:description>  With the current trends towards downsizing, outsourcing and globalisation,
modern organisations are reducing the numbers of people they employ. In
addition, organisations now have to cope with the increasing
internationalisation of business forcing collaboration and knowledge sharing
across time and distance simultaneously. There is a need for new ways of
thinking about how knowledge is shared in distributed groups. In this paper we
explore a relatively new approach to knowledge sharing using Lave and Wenger's
(1991) theory of Communities of Practice (CoPs). We investigate whether CoPs
might translate to a geographically distributed international environment
through a case study that explores the functioning of a CoP across national
boundaries.
</dc:description>
 <dc:description>Comment: Draft version available from
  http://www-users.cs.york.ac.uk/~kimble/research/publics.html</dc:description>
 <dc:date>2001-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102028</dc:identifier>
 <dc:identifier>Chapter 13 in Knowledge Management and Business Model Innovation,
  Idea Group Publishing, Hershey (USA)/London (UK), 2001. pp 220 - 234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer based Information Systems and Managers' Work</dc:title>
 <dc:creator>Kimble, Chris</dc:creator>
 <dc:creator>McLoughlin, Kevin</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>K.4.3</dc:subject>
 <dc:description>  This paper identifies three categories of model: the Technology Impact Model;
the Social Impact Model and the Integrationist Model, which imply different
views of the &quot;impact&quot; of Information Technology on work organisation. These
models are used to structure data from case studies conducted by the authors to
explore the implications of the use of computer-based information systems for
managers' work. The paper argues that the &quot;impact&quot; of information systems is
not a single stable and predictable outcome but a non-linear ongoing process
that changes and evolves over time. It also argues that the actions of
individuals and groups within an organisation are not wholly determined by
outside forces: people can and do react to, and shape, systems in different
ways. In this sense, the &quot;impact&quot; of computer-based information systems on
managers' work reflects decisions made by managers themselves about how the
technology is used.
</dc:description>
 <dc:description>Comment: Available from
  http://www-users.cs.york.ac.uk/~kimble/research/publics.html</dc:description>
 <dc:date>2001-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102029</dc:identifier>
 <dc:identifier>New Technology, Work and Employment, 10 (1), March, 1995. pp 56 -
  67</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0102030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Soundness, Idempotence and Commutativity of Set-Sharing</dc:title>
 <dc:creator>Hill, Patricia M.</dc:creator>
 <dc:creator>Bagnara, Roberto</dc:creator>
 <dc:creator>Zaffanella, Enea</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  It is important that practical data-flow analyzers are backed by reliably
proven theoretical results. Abstract interpretation provides a sound
mathematical framework and necessary generic properties for an abstract domain
to be well-defined and sound with respect to the concrete semantics. In logic
programming, the abstract domain Sharing is a standard choice for sharing
analysis for both practical work and further theoretical study. In spite of
this, we found that there were no satisfactory proofs for the key properties of
commutativity and idempotence that are essential for Sharing to be well-defined
and that published statements of the soundness of Sharing assume the
occurs-check. This paper provides a generalization of the abstraction function
for Sharing that can be applied to any language, with or without the
occurs-check. Results for soundness, idempotence and commutativity for abstract
unification using this abstraction function are proven.
</dc:description>
 <dc:description>Comment: 48 pages</dc:description>
 <dc:date>2001-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0102030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Construction of an algorithm in parallel for the Fast Fourier Transform</dc:title>
 <dc:creator>Higuera, G. Mario A.</dc:creator>
 <dc:creator>Sarria, Humberto</dc:creator>
 <dc:creator>Fonseca, Diana</dc:creator>
 <dc:creator>Idarraga, John</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  It has been designed,built and executed a code for the Fast Fourier Transform
(FFT),compiled and executed in a cluster of 2^n computers under the operating
system MacOS and using the routines MacMPI. As practical application,the code
has been used to obtain the transformed from an astronomic imagen,to execute a
filter on its and with a transformed inverse to recover the image with the
variates given by the filter.The computers arrangement are installed in the
Observatorio Astronomico National in Colombia under the name OAN Cluster and in
this has been executed several applications.
</dc:description>
 <dc:date>2001-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Neural Network Model of the Tip-of-the-Tongue Phenomenon
  Based on Synthesized Memory-Psycholinguistic-Metacognitive Approach</dc:title>
 <dc:creator>Gopych, Petro M.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  A new three-stage computer artificial neural network model of the
tip-of-the-tongue phenomenon is proposed. Each word's node is build from some
interconnected learned auto-associative two-layer neural networks each of which
represents separate word's semantic, lexical, or phonological components. The
model synthesizes memory, psycholinguistic, and metamemory approaches, bridges
speech errors and naming chronometry research traditions, and can explain
quantitatively many tip-of-the-tongue effects.
</dc:description>
 <dc:description>Comment: Proceedings of The Second International Conference
  Internet-Education-Science-2000 (IES-2000): New Informational and Computer
  Technologies in Education and Science, held on October 10-12, 2000 in
  Vinnytsia, Ukraine, page 273</dc:description>
 <dc:date>2001-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Policies with External Memory</dc:title>
 <dc:creator>Peshkin, Leonid</dc:creator>
 <dc:creator>Meuleau, Nicolas</dc:creator>
 <dc:creator>Kaelbling, Leslie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  In order for an agent to perform well in partially observable domains, it is
usually necessary for actions to depend on the history of observations. In this
paper, we explore a {\it stigmergic} approach, in which the agent's actions
include the ability to set and clear bits in an external memory, and the
external memory is included as part of the input to the agent. In this case, we
need to learn a reactive policy in a highly non-Markovian domain. We explore
two algorithms: SARSA(\lambda), which has had empirical success in partially
observable domains, and VAPS, a new algorithm due to Baird and Moore, with
convergence guarantees in partially observable domains. We compare the
performance of these two algorithms on benchmark problems.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2001-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103003</dc:identifier>
 <dc:identifier>In Bratko, I., and Dzeroski, S., eds., Machine Learning:
  Proceedings of the Sixteenth International Conference, pp. 307-314. Morgan
  Kaufmann, San Francisco, CA</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rapid Application Evolution and Integration Through Document
  Metamorphosis</dc:title>
 <dc:creator>Aoki, Paul M.</dc:creator>
 <dc:creator>Smith, Ian E.</dc:creator>
 <dc:creator>Thornton, James D.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.3</dc:subject>
 <dc:subject>D.2.11</dc:subject>
 <dc:subject>K.6.3</dc:subject>
 <dc:description>  The Harland document management system implements a data model in which
document (object) structure can be altered by mixin-style multiple inheritance
at any time. This kind of structural fluidity has long been supported by
knowledge-base management systems, but its use has primarily been in support of
reasoning and inference. In this paper, we report our experiences building and
supporting several non-trivial applications on top of this data model. Based on
these experiences, we argue that structural fluidity is convenient for
data-intensive applications other than knowledge-base management. Specifically,
we suggest that this flexible data model is a natural fit for the decoupled
programming methodology that arises naturally when using enterprise component
frameworks.
</dc:description>
 <dc:date>2001-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Source-Filter Decomposition of Harmonic Sounds</dc:title>
 <dc:creator>Bisnovatyi, Ilia</dc:creator>
 <dc:creator>O'Donnell, Michael J.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>H 5.5</dc:subject>
 <dc:subject>G 1.0</dc:subject>
 <dc:description>  This paper describes a method for decomposing steady-state instrument data
into excitation and formant filter components. The input data, taken from
several series of recordings of acoustical instruments is analyzed in the
frequency domain, and for each series a model is built, which most accurately
represents the data as a source-filter system. The source part is taken to be a
harmonic excitation system with frequency-invariant magnitudes, and the filter
part is considered to be responsible for all spectral inhomogenieties. This
method has been applied to the SHARC database of steady state instrument data
to create source-filter models for a large number of acoustical instruments.
Subsequent use of such models can have a wide variety of applications,
including improvements to wavetable and physical modeling synthesis, high
quality pitch shifting, and creation of &quot;hybrid&quot; instrument timbres.
</dc:description>
 <dc:description>Comment: Preliminary results reported at DAFx-99, in &quot;Decomposition of Steady
  State Instrument Data into Excitation System and Formant Filter Components&quot;,
  http://www.tele.ntnu.no/akustikk/meetings/DAFx99/bisnovatyi.pdf 5 pages + 2
  appendices (6 graphs, 1 table)</dc:description>
 <dc:date>2001-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible Software Framework for Modal Synthesis</dc:title>
 <dc:creator>Bisnovatyi, Ilia</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>H 5.5</dc:subject>
 <dc:subject>I 6.3</dc:subject>
 <dc:description>  Modal synthesis is an important area of physical modeling whose exploration
in the past has been held back by a large number of control parameters, the
scarcity of general-purpose design tools and the difficulty of obtaining the
computational power required for real-time synthesis. This paper presents an
overview of a flexible software framework facilitating the design and control
of instruments based on modal synthesis. The framework is designed as a
hierarchy of polymorphic synthesis objects, representing modal structures of
various complexity. As a method of generalizing all interactions among the
elements of a modal system, an abstract notion of {\it energy} is introduced,
and a set of energy transfer functions is provided. Such abstraction leads to a
design where the dynamics of interactions can be largely separated from the
specifics of particular modal structures, yielding an easily configurable and
expandable system. A real-time version of the framework has been implemented as
a set of C++ classes along with an integrating shell and a GUI, and is
currently being used to design and play modal instruments, as well as to survey
fundamental properties of various modal algorithms.
</dc:description>
 <dc:description>Comment: Presented at DAFx00,
  http://profs.sci.univr.it/~dafx/DAFx-final-papers.html</dc:description>
 <dc:date>2001-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103006</dc:identifier>
 <dc:identifier>in Proceedings of COST-G6 Conference on Digital Audio Effects
  (DAFx-00), Dec 7-9, 2000, Verona, Italy</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-parameter Model of Word Length &quot;Language - Genre&quot;</dc:title>
 <dc:creator>Kromer, Victor</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  A two-parameter model of word length measured by the number of syllables
comprising it is proposed. The first parameter is dependent on language type,
the second one - on text genre and reflects the degree of completion of
synergetic processes of language optimization.
</dc:description>
 <dc:description>Comment: 2 pages, 1 figure. In Russian</dc:description>
 <dc:date>2001-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103007</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Limits of Horn Logic Programs</dc:title>
 <dc:creator>Ma, Shilong</dc:creator>
 <dc:creator>Sui, Yuefei</dc:creator>
 <dc:creator>Xu, Ke</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Given a sequence $\{\Pi_n\}$ of Horn logic programs, the limit $\Pi$ of
$\{\Pi_n\}$ is the set of the clauses such that every clause in $\Pi$ belongs
to almost every $\Pi_n$ and every clause in infinitely many $\Pi_n$'s belongs
to $\Pi$ also. The limit program $\Pi$ is still Horn but may be infinite. In
this paper, we consider if the least Herbrand model of the limit of a given
Horn logic program sequence $\{\Pi_n\}$ equals the limit of the least Herbrand
models of each logic program $\Pi_n$. It is proved that this property is not
true in general but holds if Horn logic programs satisfy an assumption which
can be syntactically checked and be satisfied by a class of Horn logic
programs. Thus, under this assumption we can approach the least Herbrand model
of the limit $\Pi$ by the sequence of the least Herbrand models of each finite
program $\Pi_n$. We also prove that if a finite Horn logic program satisfies
this assumption, then the least Herbrand model of this program is recursive.
Finally, by use of the concept of stability from dynamical systems, we prove
that this assumption is exactly a sufficient condition to guarantee the
stability of fixed points for Horn logic programs.
</dc:description>
 <dc:description>Comment: 11 pages, added new results. Welcome any comments to
  kexu@nlsde.buaa.edu.cn</dc:description>
 <dc:date>2001-03-08</dc:date>
 <dc:date>2002-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103008</dc:identifier>
 <dc:identifier>In P. J. Stuckey (Ed.): Proc. of 18th ICLP (short paper), LNCS
  2401, p. 467, Denmark, 2002.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103009</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward an architecture for quantum programming</dc:title>
 <dc:creator>Bettelli, S.</dc:creator>
 <dc:creator>Serafini, L.</dc:creator>
 <dc:creator>Calarco, T.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:description>  It is becoming increasingly clear that, if a useful device for quantum
computation will ever be built, it will be embodied by a classical computing
machine with control over a truly quantum subsystem, this apparatus performing
a mixture of classical and quantum computation.
  This paper investigates a possible approach to the problem of programming
such machines: a template high level quantum language is presented which
complements a generic general purpose classical language with a set of quantum
primitives. The underlying scheme involves a run-time environment which
calculates the byte-code for the quantum operations and pipes it to a quantum
device controller or to a simulator.
  This language can compactly express existing quantum algorithms and reduce
them to sequences of elementary operations; it also easily lends itself to
automatic, hardware independent, circuit simplification. A publicly available
preliminary implementation of the proposed ideas has been realized using the
C++ language.
</dc:description>
 <dc:description>Comment: 23 pages, 5 figures, A4paper. Final version accepted by EJPD (&quot;swap&quot;
  replaced by &quot;invert&quot; for Qops). Preliminary implementation available at:
  http://sra.itc.it/people/serafini/quantum-computing/qlang.html</dc:description>
 <dc:date>2001-03-08</dc:date>
 <dc:date>2003-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103009</dc:identifier>
 <dc:identifier>Eur. Phys. J. D, Vol. 25, No. 2, pp. 181-200 (2003)</dc:identifier>
 <dc:identifier>doi:10.1140/epjd/e2003-00242-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103010</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Magical Number Seven Plus or Minus Two: Syntactic Structure Recognition
  in Japanese and English Sentences</dc:title>
 <dc:creator>Murata, Masaki</dc:creator>
 <dc:creator>Uchimoto, Kiyotaka</dc:creator>
 <dc:creator>Ma, Qing</dc:creator>
 <dc:creator>Isahara, Hitoshi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  George A. Miller said that human beings have only seven chunks in short-term
memory, plus or minus two. We counted the number of bunsetsus (phrases) whose
modifiees are undetermined in each step of an analysis of the dependency
structure of Japanese sentences, and which therefore must be stored in
short-term memory. The number was roughly less than nine, the upper bound of
seven plus or minus two. We also obtained similar results with English
sentences under the assumption that human beings recognize a series of words,
such as a noun phrase (NP), as a unit. This indicates that if we assume that
the human cognitive units in Japanese and English are bunsetsu and NP
respectively, analysis will support Miller's $7 \pm 2$ theory.
</dc:description>
 <dc:description>Comment: 9 pages. Computation and Language. This paper is included in the book
  entitled by &quot;Computational Linguistics and Intelligent Text Processing,
  Second International Conference, CICLing 2001, Mexico City, February 2001
  Proceedings&quot;, Alexander Gelbukh (Ed.), Springer Publisher, ISSN 0302-9743,
  ISBN 3-540-41687-0</dc:description>
 <dc:date>2001-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103010</dc:identifier>
 <dc:identifier>CICLing'2001, Mexico City, February 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Machine-Learning Approach to Estimating the Referential Properties of
  Japanese Noun Phrases</dc:title>
 <dc:creator>Murata, Masaki</dc:creator>
 <dc:creator>Uchimoto, Kiyotaka</dc:creator>
 <dc:creator>Ma, Qing</dc:creator>
 <dc:creator>Isahara, Hitoshi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The referential properties of noun phrases in the Japanese language, which
has no articles, are useful for article generation in Japanese-English machine
translation and for anaphora resolution in Japanese noun phrases. They are
generally classified as generic noun phrases, definite noun phrases, and
indefinite noun phrases. In the previous work, referential properties were
estimated by developing rules that used clue words. If two or more rules were
in conflict with each other, the category having the maximum total score given
by the rules was selected as the desired category. The score given by each rule
was established by hand, so the manpower cost was high. In this work, we
automatically adjusted these scores by using a machine-learning method and
succeeded in reducing the amount of manpower needed to adjust these scores.
</dc:description>
 <dc:description>Comment: 9 pages. Computation and Language. This paper is included in the book
  entitled by &quot;Computational Linguistics and Intelligent Text Processing,
  Second International Conference, CICLing 2001, Mexico City, February 2001
  Proceedings&quot;, Alexander Gelbukh (Ed.), Springer Publisher, ISSN 0302-9743,
  ISBN 3-540-41687-0</dc:description>
 <dc:date>2001-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103011</dc:identifier>
 <dc:identifier>CICLing'2001, Mexico City, February 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103012</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meaning Sort - Three examples: dictionary construction, tagged corpus
  construction, and information presentation system</dc:title>
 <dc:creator>Murata, Masaki</dc:creator>
 <dc:creator>Kanzaki, Kyoko</dc:creator>
 <dc:creator>Uchimoto, Kiyotaka</dc:creator>
 <dc:creator>Ma, Qing</dc:creator>
 <dc:creator>Isahara, Hitoshi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  It is often useful to sort words into an order that reflects relations among
their meanings as obtained by using a thesaurus. In this paper, we introduce a
method of arranging words semantically by using several types of `{\sf is-a}'
thesauri and a multi-dimensional thesaurus. We also describe three major
applications where a meaning sort is useful and show the effectiveness of a
meaning sort. Since there is no doubt that a word list in meaning-order is
easier to use than a word list in some random order, a meaning sort, which can
easily produce a word list in meaning-order, must be useful and effective.
</dc:description>
 <dc:description>Comment: 14 pages. Computation and Language. This paper is included in the
  book entitled by &quot;Computational Linguistics and Intelligent Text Processing,
  Second International Conference&quot;, Springer Publisher</dc:description>
 <dc:date>2001-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103012</dc:identifier>
 <dc:identifier>CICLing'2001, Mexico City, February 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CRL at Ntcir2</dc:title>
 <dc:creator>Murata, Masaki</dc:creator>
 <dc:creator>Utiyama, Masao</dc:creator>
 <dc:creator>Ma, Qing</dc:creator>
 <dc:creator>Ozaku, Hiromi</dc:creator>
 <dc:creator>Isahara, Hitoshi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We have developed systems of two types for NTCIR2. One is an enhenced version
of the system we developed for NTCIR1 and IREX. It submitted retrieval results
for JJ and CC tasks. A variety of parameters were tried with the system. It
used such characteristics of newspapers as locational information in the CC
tasks. The system got good results for both of the tasks. The other system is a
portable system which avoids free parameters as much as possible. The system
submitted retrieval results for JJ, JE, EE, EJ, and CC tasks. The system
automatically determined the number of top documents and the weight of the
original query used in automatic-feedback retrieval. It also determined
relevant terms quite robustly. For EJ and JE tasks, it used document expansion
to augment the initial queries. It achieved good results, except on the CC
tasks.
</dc:description>
 <dc:description>Comment: 11 pages. Computation and Language. This paper describes our results
  of information retrieval in the NTCIR2 contest</dc:description>
 <dc:date>2001-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103014</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster-than-light effects and negative group delays in optics and
  electronics, and their applications</dc:title>
 <dc:creator>Chiao, Raymond Y.</dc:creator>
 <dc:creator>Hickmann, Jandir M.</dc:creator>
 <dc:creator>Solli, Daniel</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>B.7.0</dc:subject>
 <dc:description>  Recent manifestations of apparently faster-than-light effects confirmed our
predictions that the group velocity in transparent optical media can exceed c.
Special relativity is not violated by these phenomena. Moreover, in the
electronic domain, the causality principle does not forbid negative group
delays of analytic signals in electronic circuits, in which the peak of an
output pulse leaves the exit port of a circuit before the peak of the input
pulse enters the input port. Furthermore, pulse distortion for these
superluminal analytic signals can be negligible in both the optical and
electronic domains. Here we suggest an extension of these ideas to the
microelectronic domain. The underlying principle is that negative feedback can
be used to produce negative group delays. Such negative group delays can be
used to cancel out the positive group delays due to transistor latency (e.g.,
the finite RC rise time of MOSFETS caused by their intrinsic gate capacitance),
as well as the propagation delays due to the interconnects between transistors.
Using this principle, it is possible to speed up computer systems.
</dc:description>
 <dc:description>Comment: 13 pages, 5 figures, 2001 Photonic West Plenary Talk</dc:description>
 <dc:date>2001-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103014</dc:identifier>
 <dc:identifier>doi:10.1117/12.432562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fitness Uniform Selection to Preserve Genetic Diversity</dc:title>
 <dc:creator>Hutter, Marcus</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:description>  In evolutionary algorithms, the fitness of a population increases with time
by mutating and recombining individuals and by a biased selection of more fit
individuals. The right selection pressure is critical in ensuring sufficient
optimization progress on the one hand and in preserving genetic diversity to be
able to escape from local optima on the other. We propose a new selection
scheme, which is uniform in the fitness values. It generates selection pressure
towards sparsely populated fitness regions, not necessarily towards higher
fitness, as is the case for all other selection schemes. We show that the new
selection scheme can be much more effective than standard selection schemes.
</dc:description>
 <dc:description>Comment: 13 LaTeX pages, 1 eps figure</dc:description>
 <dc:date>2001-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103015</dc:identifier>
 <dc:identifier>Proceedings of the 2002 Congress on Evolutionary Computation
  (CEC-2002) 783-788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103016</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Search in Power-Law Networks</dc:title>
 <dc:creator>Adamic, L. A.</dc:creator>
 <dc:creator>Lukose, R. M.</dc:creator>
 <dc:creator>Puniyani, A. R.</dc:creator>
 <dc:creator>Huberman, B. A.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  Many communication and social networks have power-law link distributions,
containing a few nodes which have a very high degree and many with low degree.
The high connectivity nodes play the important role of hubs in communication
and networking, a fact which can be exploited when designing efficient search
algorithms. We introduce a number of local search strategies which utilize high
degree nodes in power-law graphs and which have costs which scale sub-linearly
with the size of the graph. We also demonstrate the utility of these strategies
on the Gnutella peer-to-peer network.
</dc:description>
 <dc:description>Comment: 17 pages, 14 figures</dc:description>
 <dc:date>2001-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103016</dc:identifier>
 <dc:identifier>Phys. Rev. E 64, 046135 (2001)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.64.046135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nice point sets can have nasty Delaunay triangulations</dc:title>
 <dc:creator>Erickson, Jeff</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.m</dc:subject>
 <dc:description>  We consider the complexity of Delaunay triangulations of sets of points in
R^3 under certain practical geometric constraints. The spread of a set of
points is the ratio between the longest and shortest pairwise distances. We
show that in the worst case, the Delaunay triangulation of n points in R^3 with
spread D has complexity Omega(min{D^3, nD, n^2}) and O(min{D^4, n^2}). For the
case D = Theta(sqrt{n}), our lower bound construction consists of a uniform
sample of a smooth convex surface with bounded curvature. We also construct a
family of smooth connected surfaces such that the Delaunay triangulation of any
good point sample has near-quadratic complexity.
</dc:description>
 <dc:description>Comment: 11 pages, 8 figures, to appear in Proc. SCG '01</dc:description>
 <dc:date>2001-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Existential Theory of Equations with Rational Constraints in Free
  Groups is PSPACE-Complete</dc:title>
 <dc:creator>Diekert, Volker</dc:creator>
 <dc:creator>Gutierrez, Claudio</dc:creator>
 <dc:creator>Hagenah, Christian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>F.4</dc:subject>
 <dc:description>  It is known that the existential theory of equations in free groups is
decidable. This is a famous result of Makanin. On the other hand it has been
shown that the scheme of his algorithm is not primitive recursive. In this
paper we present an algorithm that works in polynomial space, even in the more
general setting where each variable has a rational constraint, that is, the
solution has to respect a specification given by a regular word language. Our
main result states that the existential theory of equations in free groups with
rational constraints is PSPACE-complete. We obtain this result as a corollary
of the corresponding statement about free monoids with involution.
</dc:description>
 <dc:description>Comment: 45 pages. LaTeX source</dc:description>
 <dc:date>2001-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the NP-completeness of Finding an Optimal Strategy in Games with
  Common Payoffs</dc:title>
 <dc:creator>Chu, Francis</dc:creator>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  Consider a very simple class of (finite) games: after an initial move by
nature, each player makes one move. Moreover, the players have common
interests: at each node, all the players get the same payoff. We show that the
problem of determining whether there exists a joint strategy where each player
has an expected payoff of at least r is NP-complete as a function of the number
of nodes in the extensive-form representation of the game.
</dc:description>
 <dc:description>Comment: To appear, International Journal of Game Theory</dc:description>
 <dc:date>2001-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Belief Revision: A Critique</dc:title>
 <dc:creator>Friedman, Nir</dc:creator>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.4, F.4.1</dc:subject>
 <dc:description>  We examine carefully the rationale underlying the approaches to belief change
taken in the literature, and highlight what we view as methodological problems.
We argue that to study belief change carefully, we must be quite explicit about
the ``ontology'' or scenario underlying the belief change process. This is
something that has been missing in previous work, with its focus on postulates.
Our analysis shows that we must pay particular attention to two issues that
have often been taken for granted: The first is how we model the agent's
epistemic state. (Do we use a set of beliefs, or a richer structure, such as an
ordering on worlds? And if we use a set of beliefs, in what language are these
beliefs are expressed?) We show that even postulates that have been called
``beyond controversy'' are unreasonable when the agent's beliefs include
beliefs about her own epistemic state as well as the external world. The second
is the status of observations. (Are observations known to be true, or just
believed? In the latter case, how firm is the belief?) Issues regarding the
status of observations arise particularly when we consider iterated belief
revision, and we must confront the possibility of revising by p and then by
not-p.
</dc:description>
 <dc:description>Comment: An early version of the paper appeared in KR '96</dc:description>
 <dc:date>2001-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103020</dc:identifier>
 <dc:identifier>Journal of Logic, Language, and Information, vol. 8, 1999, pp.
  401-420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Clock Synchronization with one qubit</dc:title>
 <dc:creator>Harrelson, Chris</dc:creator>
 <dc:creator>Kerenidis, Iordanis</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:description>  The clock synchronization problem is to determine the time difference T
between two spatially separated parties. We improve on I. Chuang's quantum
clock synchronization algorithm and show that it is possible to obtain T to n
bits of accuracy while communicating only one qubit in one direction and using
an O(2^n) frequency range. We also prove a quantum lower bound of \Omega(2^n)
for the product of the transmitted qubits and the range of frequencies, thus
showing that our algorithm is optimal.
</dc:description>
 <dc:description>Comment: LaTeX, 5 pages</dc:description>
 <dc:date>2001-03-27</dc:date>
 <dc:date>2001-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure, Efficient Data Transport and Replica Management for
  High-Performance Data-Intensive Computing</dc:title>
 <dc:creator>Allcock, Bill</dc:creator>
 <dc:creator>Bester, Joe</dc:creator>
 <dc:creator>Bresnahan, John</dc:creator>
 <dc:creator>Chervenak, Ann L.</dc:creator>
 <dc:creator>Foster, Ian</dc:creator>
 <dc:creator>Kesselman, Carl</dc:creator>
 <dc:creator>Meder, Sam</dc:creator>
 <dc:creator>Nefedova, Veronika</dc:creator>
 <dc:creator>Quesnel, Darcy</dc:creator>
 <dc:creator>Tuecke, Steven</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>C.1.4</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:description>  An emerging class of data-intensive applications involve the geographically
dispersed extraction of complex scientific information from very large
collections of measured or computed data. Such applications arise, for example,
in experimental physics, where the data in question is generated by
accelerators, and in simulation science, where the data is generated by
supercomputers. So-called Data Grids provide essential infrastructure for such
applications, much as the Internet provides essential services for applications
such as e-mail and the Web. We describe here two services that we believe are
fundamental to any Data Grid: reliable, high-speed transporet and replica
management. Our high-speed transport service, GridFTP, extends the popular FTP
protocol with new features required for Data Grid applciations, such as
striping and partial file access. Our replica management service integrates a
replica catalog with GridFTP transfers to provide for the creation,
registration, location, and management of dataset replicas. We present the
design of both services and also preliminary performance results. Our
implementations exploit security and other services provided by the Globus
Toolkit.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2001-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dualheap Selection Algorithm - A Call for Analysis</dc:title>
 <dc:creator>Sepesi, Greg</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:description>  An algorithm is presented that efficiently solves the selection problem:
finding the k-th smallest member of a set. Relevant to a divide-and-conquer
strategy, the algorithm also partitions a set into small and large valued
subsets. Applied recursively, this partitioning results in a sorted set. The
algorithm's applicability is therefore much broader than just the selection
problem. The presented algorithm is based upon R.W. Floyd's 1964 algorithm that
constructs a heap from the bottom-up. Empirically, the presented algorithm's
performance appears competitive with the popular quickselect algorithm, a
variant of C.A.R. Hoare's 1962 quicksort algorithm. Furthermore, constructing a
heap from the bottom-up is an inherently parallel process (processors can work
independently and simultaneously on subheap construction), suggesting a
performance advantage with parallel implementations. Given the presented
algorithm's broad applicability, simplicity, serial performance, and parallel
nature, further study is warranted. Specifically, worst-case analysis is an
important but still unsolved problem.
</dc:description>
 <dc:description>Comment: 6 pages, 13 figures</dc:description>
 <dc:date>2001-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Notes on computing peaks in k-levels and parametric spanning trees</dc:title>
 <dc:creator>Katoh, Naoki</dc:creator>
 <dc:creator>Tokuyama, Takeshi</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F2.2</dc:subject>
 <dc:description>  We give an algorithm to compute all the local peaks in the $k$-level of an
arrangement of $n$ lines in $O(n \log n) + \tilde{O}((kn)^{2/3})$ time. We can
also find $\tau$ largest peaks in $O(n \log ^2 n) + \tilde{O}((\tau n)^{2/3})$
time. Moreover, we consider the longest edge in a parametric minimum spanning
tree (in other words, a bottleneck edge for connectivity), and give an
algorithm to compute the parameter value (within a given interval)
maximizing/minimizing the length of the longest edge in MST. The time
complexity is $\tilde{O}(n^{8/7}k^{1/7} + n k^{1/3})$
</dc:description>
 <dc:description>Comment: ACM SCG'01</dc:description>
 <dc:date>2001-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Anatomy of the Grid - Enabling Scalable Virtual Organizations</dc:title>
 <dc:creator>Foster, Ian</dc:creator>
 <dc:creator>Kesselman, Carl</dc:creator>
 <dc:creator>Tuecke, Steven</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.1.4</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  &quot;Grid&quot; computing has emerged as an important new field, distinguished from
conventional distributed computing by its focus on large-scale resource
sharing, innovative applications, and, in some cases, high-performance
orientation. In this article, we define this new field. First, we review the
&quot;Grid problem,&quot; which we define as flexible, secure, coordinated resource
sharing among dynamic collections of individuals, institutions, and
resources-what we refer to as virtual organizations. In such settings, we
encounter unique authentication, authorization, resource access, resource
discovery, and other challenges. It is this class of problem that is addressed
by Grid technologies. Next, we present an extensible and open Grid
architecture, in which protocols, services, application programming interfaces,
and software development kits are categorized according to their roles in
enabling resource sharing. We describe requirements that we believe any such
mechanisms must satisfy, and we discuss the central role played by the
intergrid protocols that enable interoperability among different Grid systems.
Finally, we discuss how Grid technologies relate to other contemporary
technologies, including enterprise integration, application service provider,
storage service provider, and peer-to-peer computing. We maintain that Grid
concepts and technologies complement and have much to contribute to these other
approaches.
</dc:description>
 <dc:description>Comment: 24 pages, 5 figures</dc:description>
 <dc:date>2001-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0103026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Decision Tree of Bigrams is an Accurate Predictor of Word Sense</dc:title>
 <dc:creator>Pedersen, Ted</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper presents a corpus-based approach to word sense disambiguation
where a decision tree assigns a sense to an ambiguous word based on the bigrams
that occur nearby. This approach is evaluated using the sense-tagged corpora
from the 1998 SENSEVAL word sense disambiguation exercise. It is more accurate
than the average results reported for 30 of 36 words, and is more accurate than
the best results for 19 of 36 words.
</dc:description>
 <dc:description>Comment: Proceedings of the Second Meeting of the North American Chapter of
  the Association for Computational Linguistics (NAACL-01), June 2-7, 2001,
  Pittsburgh, PA; 8 pages</dc:description>
 <dc:date>2001-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0103026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mantaining Dynamic Matrices for Fully Dynamic Transitive Closure</dc:title>
 <dc:creator>Demetrescu, Camil</dc:creator>
 <dc:creator>Italiano, Giuseppe F.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  In this paper we introduce a general framework for casting fully dynamic
transitive closure into the problem of reevaluating polynomials over matrices.
With this technique, we improve the best known bounds for fully dynamic
transitive closure. In particular, we devise a deterministic algorithm for
general directed graphs that achieves $O(n^2)$ amortized time for updates,
while preserving unit worst-case cost for queries. In case of deletions only,
our algorithm performs updates faster in O(n) amortized time.
  Our matrix-based approach yields an algorithm for directed acyclic graphs
that breaks through the $O(n^2)$ barrier on the single-operation complexity of
fully dynamic transitive closure. We can answer queries in $O(n^\epsilon)$ time
and perform updates in $O(n^{\omega(1,\epsilon,1)-\epsilon}+n^{1+\epsilon})$
time, for any $\epsilon\in[0,1]$, where $\omega(1,\epsilon,1)$ is the exponent
of the multiplication of an $n\times n^{\epsilon}$ matrix by an
$n^{\epsilon}\times n$ matrix. The current best bounds on
$\omega(1,\epsilon,1)$ imply an $O(n^{0.58})$ query time and an $O(n^{1.58})$
update time. Our subquadratic algorithm is randomized, and has one-side error.
</dc:description>
 <dc:description>Comment: 52 pages, 5 figures</dc:description>
 <dc:date>2001-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Replica Selection in the Globus Data Grid</dc:title>
 <dc:creator>Vazhkudai, Sudharshan</dc:creator>
 <dc:creator>Tuecke, Steven</dc:creator>
 <dc:creator>Foster, Ian</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.1.4</dc:subject>
 <dc:description>  The Globus Data Grid architecture provides a scalable infrastructure for the
management of storage resources and data that are distributed across Grid
environments. These services are designed to support a variety of scientific
applications, ranging from high-energy physics to computational genomics, that
require access to large amounts of data (terabytes or even petabytes) with
varied quality of service requirements. By layering on a set of core services,
such as data transport, security, and replica cataloging, one can construct
various higher-level services. In this paper, we discuss the design and
implementation of a high-level replica selection service that uses information
regarding replica location and user preferences to guide selection from among
storage replica alternatives. We first present a basic replica selection
service design, then show how dynamic information collected using Globus
information service capabilities concerning storage system properties can help
improve and optimize the selection process. We demonstrate the use of Condor's
ClassAds resource description and matchmaking mechanism as an efficient tool
for representing and matching storage resource capabilities and policies
against application requirements.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures</dc:description>
 <dc:date>2001-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chain Programs for Writing Deterministic Metainterpreters</dc:title>
 <dc:creator>Rosenblueth, David A.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:description>  Many metainterpreters found in the logic programming literature are
nondeterministic in the sense that the selection of program clauses is not
determined. Examples are the familiar &quot;demo&quot; and &quot;vanilla&quot; metainterpreters.
For some applications this nondeterminism is convenient. In some cases,
however, a deterministic metainterpreter, having an explicit selection of
clauses, is needed. Such cases include (1) conversion of OR parallelism into
AND parallelism for &quot;committed-choice&quot; processors, (2) logic-based,
imperative-language implementation of search strategies, and (3) simulation of
bounded-resource reasoning.
  Deterministic metainterpreters are difficult to write because the programmer
must be concerned about the set of unifiers of the children of a node in the
derivation tree. We argue that it is both possible and advantageous to write
these metainterpreters by reasoning in terms of object programs converted into
a syntactically restricted form that we call &quot;chain&quot; form, where we can forget
about unification, except for unit clauses. We give two transformations
converting logic programs into chain form, one for &quot;moded&quot; programs (implicit
in two existing exhaustive-traversal methods for committed-choice execution),
and one for arbitrary definite programs. As illustrations of our approach we
show examples of the three applications mentioned above.
</dc:description>
 <dc:description>Comment: 30 pages. To appear in the journal &quot;Theory and Practice of Logic
  Programming&quot;</dc:description>
 <dc:date>2001-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Counting: counting members of a subset without revealing their
  identities</dc:title>
 <dc:creator>Kiselyov, Oleg</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>E.3</dc:subject>
 <dc:description>  Suppose there is a group of N people some of whom possess a specific
property. For example, their wealth is above or below a threshold, they voted
for a particular candidate, they have a certain disease, etc. The group wants
to find out how many of its members posses the property -- without revealing
the identities. Unless of course it turns out that all members do or do not
have the attribute of interest. However, in all other cases the counting
algorithm should guarantee that nobody can find out if a particular individual
possesses the property unless all the other N-1 members of the group collude.
  The present article describes a method to solve the confidential counting
problem with only 3*N-2 pairwise communications, or 2*N broadcasts (the last
N-1 pairwise communications are merely to announce the result). The counting
algorithm does not require any trusted third parties. All communications
between parties involved can be conducted in public without compromising the
security of counting.
</dc:description>
 <dc:date>2001-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bootstrapping Structure using Similarity</dc:title>
 <dc:creator>van Zaanen, Menno</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2, I.2.6, I.2.7</dc:subject>
 <dc:description>  In this paper a new similarity-based learning algorithm, inspired by string
edit-distance (Wagner and Fischer, 1974), is applied to the problem of
bootstrapping structure from scratch. The algorithm takes a corpus of
unannotated sentences as input and returns a corpus of bracketed sentences. The
method works on pairs of unstructured sentences or sentences partially
bracketed by the algorithm that have one or more words in common. It finds
parts of sentences that are interchangeable (i.e. the parts of the sentences
that are different in both sentences). These parts are taken as possible
constituents of the same type. While this corresponds to the basic
bootstrapping step of the algorithm, further structure may be learned from
comparison with other (similar) sentences.
  We used this method for bootstrapping structure from the flat sentences of
the Penn Treebank ATIS corpus, and compared the resulting structured sentences
to the structured sentences in the ATIS corpus. Similarly, the algorithm was
tested on the OVIS corpus. We obtained 86.04 % non-crossing brackets precision
on the ATIS corpus and 89.39 % non-crossing brackets precision on the OVIS
corpus.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2001-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104005</dc:identifier>
 <dc:identifier>Computational Linguistics in the Netherlands 1999 - Selected
  Papers from the Tenth CLIN Meeting, pages 235-245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ABL: Alignment-Based Learning</dc:title>
 <dc:creator>van Zaanen, Menno</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper introduces a new type of grammar learning algorithm, inspired by
string edit distance (Wagner and Fischer, 1974). The algorithm takes a corpus
of flat sentences as input and returns a corpus of labelled, bracketed
sentences. The method works on pairs of unstructured sentences that have one or
more words in common. When two sentences are divided into parts that are the
same in both sentences and parts that are different, this information is used
to find parts that are interchangeable. These parts are taken as possible
constituents of the same type. After this alignment learning step, the
selection learning step selects the most probable constituents from all
possible constituents.
  This method was used to bootstrap structure on the ATIS corpus (Marcus et
al., 1993) and on the OVIS (Openbaar Vervoer Informatie Systeem (OVIS) stands
for Public Transport Information System.) corpus (Bonnema et al., 1997). While
the results are encouraging (we obtained up to 89.25 % non-crossing brackets
precision), this paper will point out some of the shortcomings of our approach
and will suggest possible solutions.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2001-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104006</dc:identifier>
 <dc:identifier>Proceedings of the 18th International Conference on Computational
  Linguistics (COLING); Saarbrucken, Germany. pages 961-967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104007</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bootstrapping Syntax and Recursion using Alignment-Based Learning</dc:title>
 <dc:creator>van Zaanen, Menno</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper introduces a new type of unsupervised learning algorithm, based on
the alignment of sentences and Harris's (1951) notion of interchangeability.
The algorithm is applied to an untagged, unstructured corpus of natural
language sentences, resulting in a labelled, bracketed version of the corpus.
Firstly, the algorithm aligns all sentences in the corpus in pairs, resulting
in a partition of the sentences consisting of parts of the sentences that are
similar in both sentences and parts that are dissimilar. This information is
used to find (possibly overlapping) constituents. Next, the algorithm selects
(non-overlapping) constituents. Several instances of the algorithm are applied
to the ATIS corpus (Marcus et al., 1993) and the OVIS (Openbaar Vervoer
Informatie Systeem (OVIS) stands for Public Transport Information System.)
corpus (Bonnema et al., 1997). Apart from the promising numerical results, the
most striking result is that even the simplest algorithm based on alignment
learns recursion.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2001-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104007</dc:identifier>
 <dc:identifier>Proceedings of the Seventeenth International Conference on Machine
  Learning. pages 1063-1070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104008</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Event Indexing Systems for Efficient Selection and Analysis of HERA Data</dc:title>
 <dc:creator>Bauerdick, L. A. T.</dc:creator>
 <dc:creator>Fox-Murphy, Adrian</dc:creator>
 <dc:creator>Haas, Tobias</dc:creator>
 <dc:creator>Stonjek, Stefan</dc:creator>
 <dc:creator>Tassi, Enrico</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  The design and implementation of two software systems introduced to improve
the efficiency of offline analysis of event data taken with the ZEUS Detector
at the HERA electron-proton collider at DESY are presented. Two different
approaches were made, one using a set of event directories and the other using
a tag database based on a commercial object-oriented database management
system. These are described and compared. Both systems provide quick direct
access to individual collision events in a sequential data store of several
terabytes, and they both considerably improve the event analysis efficiency. In
particular the tag database provides a very flexible selection mechanism and
can dramatically reduce the computing time needed to extract small subsamples
from the total event sample. Gains as large as a factor 20 have been obtained.
</dc:description>
 <dc:description>Comment: Accepted for publication in Computer Physics Communications</dc:description>
 <dc:date>2001-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104008</dc:identifier>
 <dc:identifier>Comput.Phys.Commun. 137 (2001) 236-246</dc:identifier>
 <dc:identifier>doi:10.1016/S0010-4655(01)00162-X</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Recommendation Algorithms by Graph Analysis</dc:title>
 <dc:creator>Mirza, Batul J.</dc:creator>
 <dc:creator>Keller, Benjamin J.</dc:creator>
 <dc:creator>Ramakrishnan, Naren</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>H.4.2</dc:subject>
 <dc:description>  We present a novel framework for evaluating recommendation algorithms in
terms of the `jumps' that they make to connect people to artifacts. This
approach emphasizes reachability via an algorithm within the implicit graph
structure underlying a recommender dataset, and serves as a complement to
evaluation in terms of predictive accuracy. The framework allows us to consider
questions relating algorithmic parameters to properties of the datasets. For
instance, given a particular algorithm `jump,' what is the average path length
from a person to an artifact? Or, what choices of minimum ratings and jumps
maintain a connected graph? We illustrate the approach with a common jump
called the `hammock' using movie recommender datasets.
</dc:description>
 <dc:date>2001-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Type Arithmetics: Computation based on the theory of types</dc:title>
 <dc:creator>Kiselyov, Oleg</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>F.3.3</dc:subject>
 <dc:subject>F.4.2</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  The present paper shows meta-programming turn programming, which is rich
enough to express arbitrary arithmetic computations. We demonstrate a type
system that implements Peano arithmetics, slightly generalized to negative
numbers. Certain types in this system denote numerals. Arithmetic operations on
such types-numerals - addition, subtraction, and even division - are expressed
as type reduction rules executed by a compiler. A remarkable trait is that
division by zero becomes a type error - and reported as such by a compiler.
</dc:description>
 <dc:description>Comment: 1 HTML page, 1 C++ source code file</dc:description>
 <dc:date>2001-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Potholes on the Royal Road</dc:title>
 <dc:creator>Belding, Theodore C.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>I.2.m</dc:subject>
 <dc:description>  It is still unclear how an evolutionary algorithm (EA) searches a fitness
landscape, and on what fitness landscapes a particular EA will do well. The
validity of the building-block hypothesis, a major tenet of traditional genetic
algorithm theory, remains controversial despite its continued use to justify
claims about EAs. This paper outlines a research program to begin to answer
some of these open questions, by extending the work done in the royal road
project. The short-term goal is to find a simple class of functions which the
simple genetic algorithm optimizes better than other optimization methods, such
as hillclimbers. A dialectical heuristic for searching for such a class is
introduced. As an example of using the heuristic, the simple genetic algorithm
is compared with a set of hillclimbers on a simple subset of the
hyperplane-defined functions, the pothole functions.
</dc:description>
 <dc:description>Comment: 8 pages; to appear in GECCO 2001</dc:description>
 <dc:date>2001-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>System Support for Bandwidth Management and Content Adaptation in
  Internet Applications</dc:title>
 <dc:creator>Andersen, David G.</dc:creator>
 <dc:creator>Bansal, Deepak</dc:creator>
 <dc:creator>Curtis, Dorothy</dc:creator>
 <dc:creator>Seshan, Srinivasan</dc:creator>
 <dc:creator>Balakrishnan, Hari</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:subject>D.4.4</dc:subject>
 <dc:description>  This paper describes the implementation and evaluation of an operating system
module, the Congestion Manager (CM), which provides integrated network flow
management and exports a convenient programming interface that allows
applications to be notified of, and adapt to, changing network conditions. We
describe the API by which applications interface with the CM, and the
architectural considerations that factored into the design. To evaluate the
architecture and API, we describe our implementations of TCP; a streaming
layered audio/video application; and an interactive audio application using the
CM, and show that they achieve adaptive behavior without incurring much
end-system overhead. All flows including TCP benefit from the sharing of
congestion information, and applications are able to incorporate new
functionality such as congestion control and adaptive behavior.
</dc:description>
 <dc:description>Comment: 14 pages, appeared in OSDI 2000</dc:description>
 <dc:date>2001-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104012</dc:identifier>
 <dc:identifier>Proc. OSDI 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shooting Over or Under the Mark: Towards a Reliable and Flexible
  Anticipation in the Economy</dc:title>
 <dc:creator>Matsuno, Koichiro</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>J.1</dc:subject>
 <dc:description>  The real monetary economy is grounded upon monetary flow equilibration or the
activity of actualizing monetary flow continuity at each economic agent except
for the central bank. Every update of monetary flow continuity at each agent
constantly causes monetary flow equilibration at the neighborhood agents. Every
monetary flow equilibration as the activity of shooting the mark identified as
monetary flow continuity turns out to be off the mark, and constantly generate
the similar activities in sequence. Monetary flow equilibration ceaselessly
reverberating in the economy performs two functions. One is to seek an
organization on its own, and the other is to perturb the ongoing organization.
Monetary flow equilibration as the agency of seeking and perturbing its
organization also serves as a means of predicting its behavior. The likely
organizational behavior could be the one that remains most robust against
monetary flow equilibration as an agency of applying perturbations.
</dc:description>
 <dc:date>2001-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104013</dc:identifier>
 <dc:identifier>Int. J. Comp. Anticipatory Syst. 5 (2000), 305-314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracing a Faint Fingerprint of the Invisible Hand?</dc:title>
 <dc:creator>Matsuno, Koichiro</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>J.1</dc:subject>
 <dc:description>  Any economic agent constituting the monetary economy maintains the activity
of monetary flow equilibration for fulfilling the condition of monetary flow
continuity in the record, except at the central bank. At the same time,
monetary flow equilibration at one economic agent constantly induces at other
agents in the economy further flow disequilibrium to be eliminated
subsequently. We propose the rate of monetary flow disequilibration as a figure
measuring the progressive movement of the economy. The rate of disequilibration
was read out of both the Japanese and the United States monetary economy
recorded over the last fifty years.
</dc:description>
 <dc:date>2001-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of Support Vector Machine to detect an association between a
  disease or trait and multiple SNP variations</dc:title>
 <dc:creator>Kim, Gene</dc:creator>
 <dc:creator>Kim, MyungHo</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantitative Biology</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  After the completion of human genome sequence was anounced, it is evident
that interpretation of DNA sequences is an immediate task to work on. For
understanding their signals, improvement of present sequence analysis tools and
developing new ones become necessary. Along this current trend, we attack one
of the fundamental questions, which set of SNP(single nucleotide polymorphism)
variations is related to a specific disease or trait is. For, in the whole DNA
sequence, it is known that people have different DNAs only at SNP locations,
and moreover, the total SNPs are less than 5 millions, finding an association
between SNP variations and certain disease or trait is believed to be one of
the essential steps not only for genetic researches but for drug design and
discovery. In this paper, we are going to present a method of detecting whether
there is an association between multiple SNP variations and a trait or disease.
The method exploits the Support Vector Machine which has been attracting lots
of attentions recently.
</dc:description>
 <dc:date>2001-04-17</dc:date>
 <dc:date>2001-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Gibbs Representation of 3D Rotations</dc:title>
 <dc:creator>Peterson, Ian R.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>B.2.4</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>I.4.0</dc:subject>
 <dc:description>  This paper revisits the little-known Gibbs-Rodrigues representation of
rotations in a three-dimensional space and demonstrates a set of algorithms for
handling it. In this representation the rotation is itself represented as a
three-dimensional vector. The vector is parallel to the axis of rotation and
its three components transform covariantly on change of coordinates. The
mapping from rotations to vectors is 1:1 apart from computation error. The
discontinuities of the representation require special handling but are not
problematic. The rotation matrix can be generated efficiently from the vector
without the use of transcendental functions, and vice-versa. The representation
is more efficient than Euler angles, has affinities with Hassenpflug's Argyris
angles and is very closely related to the quaternion representation. While the
quaternion representation avoids the discontinuities inherent in any
3-component representation, this problem is readily overcome. The present paper
gives efficient algorithms for computing the set of rotations which map a given
vector to another of the same length and the rotation which maps a given pair
of vectors to another pair of the same length and subtended angle.
</dc:description>
 <dc:description>Comment: 10 pages, 0 figures, PDF 3.0</dc:description>
 <dc:date>2001-04-18</dc:date>
 <dc:date>2003-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Search Techniques for Constrained Portfolio Selection Problems</dc:title>
 <dc:creator>Schaerf, Andrea</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>J.1</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  We consider the problem of selecting a portfolio of assets that provides the
investor a suitable balance of expected return and risk. With respect to the
seminal mean-variance model of Markowitz, we consider additional constraints on
the cardinality of the portfolio and on the quantity of individual shares. Such
constraints better capture the real-world trading system, but make the problem
more difficult to be solved with exact methods. We explore the use of local
search techniques, mainly tabu search, for the portfolio selection problem. We
compare and combine previous work on portfolio selection that makes use of the
local search approach and we propose new algorithms that combine different
neighborhood relations. In addition, we show how the use of randomization and
of a simple form of adaptiveness simplifies the setting of a large number of
critical parameters. Finally, we show how our techniques perform on public
benchmarks.
</dc:description>
 <dc:description>Comment: 22 pages, 3 figures</dc:description>
 <dc:date>2001-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Several new domain-type and boundary-type numerical discretization
  schemes with radial basis function</dc:title>
 <dc:creator>Chen, W.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>G.1.3</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:description>  This paper is concerned with a few novel RBF-based numerical schemes
discretizing partial differential equations. For boundary-type methods, we
derive the indirect and direct symmetric boundary knot methods (BKM). The
resulting interpolation matrix of both is always symmetric irrespective of
boundary geometry and conditions. In particular, the direct BKM applies the
practical physical variables rather than expansion coefficients and becomes
very competitive to the boundary element method. On the other hand, based on
the multiple reciprocity principle, we invent the RBF-based boundary particle
method (BPM) for general inhomogeneous problems without a need using inner
nodes. The direct and symmetric BPM schemes are also developed.
  For domain-type RBF discretization schemes, by using the Green integral we
develop a new Hermite RBF scheme called as the modified Kansa method (MKM),
which differs from the symmetric Hermite RBF scheme in that the MKM discretizes
both governing equation and boundary conditions on the same boundary nodes. The
local spline version of the MKM is named as the finite knot method (FKM). Both
MKM and FKM significantly reduce calculation errors at nodes adjacent to
boundary. In addition, the nonsingular high-order fundamental or general
solution is strongly recommended as the RBF in the domain-type methods and dual
reciprocity method approximation of particular solution relating to the BKM.
  It is stressed that all the above discretization methods of boundary-type and
domain-type are symmetric, meshless, and integration-free. The spline-based
schemes will produce desirable symmetric sparse banded interpolation matrix. In
appendix, we present a Hermite scheme to eliminate edge effect on the RBF
geometric modeling and imaging.
</dc:description>
 <dc:description>Comment: Welcome any comments to wenc@ifi.uio.no or chenw6@hotmail.com</dc:description>
 <dc:date>2001-04-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Nonlocal Language Modeling via Hierarchical Topic-Based
  Adaptation</dc:title>
 <dc:creator>Florian, Radu</dc:creator>
 <dc:creator>Yarowsky, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper presents a novel method of generating and applying hierarchical,
dynamic topic-based language models. It proposes and evaluates new cluster
generation, hierarchical smoothing and adaptive topic-probability estimation
techniques. These combined models help capture long-distance lexical
dependencies. Experiments on the Broadcast News corpus show significant
improvement in perplexity (10.5% overall and 33.5% on target vocabulary).
</dc:description>
 <dc:description>Comment: 8 pages, 29 figures, presented at ACL99, College Park, Maryland</dc:description>
 <dc:date>2001-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104019</dc:identifier>
 <dc:identifier>Proceedings of the 37th Annual Meeting of the ACL, pages 167-174,
  College Park, Maryland</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coaxing Confidences from an Old Friend: Probabilistic Classifications
  from Transformation Rule Lists</dc:title>
 <dc:creator>Florian, Radu</dc:creator>
 <dc:creator>Henderson, John C.</dc:creator>
 <dc:creator>Ngai, Grace</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Transformation-based learning has been successfully employed to solve many
natural language processing problems. It has many positive features, but one
drawback is that it does not provide estimates of class membership
probabilities.
  In this paper, we present a novel method for obtaining class membership
probabilities from a transformation-based rule list classifier. Three
experiments are presented which measure the modeling accuracy and cross-entropy
of the probabilistic classifier on unseen data and the degree to which the
output probabilities from the classifier can be used to estimate confidences in
its classification decisions.
  The results of these experiments show that, for the task of text chunking,
the estimates produced by this technique are more informative than those
generated by a state-of-the-art decision tree.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures, presented at EMNLP 2000</dc:description>
 <dc:date>2001-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104020</dc:identifier>
 <dc:identifier>Proceedings of the Fifth Conference on Empirical Methods in
  Natural Language Processing, pages 26-34, Hong Kong (2000)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disjunction and modular goal-directed proof search</dc:title>
 <dc:creator>Stone, Matthew</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  This paper explores goal-directed proof search in first-order multi-modal
logic. The key issue is to design a proof system that respects the modularity
and locality of assumptions of many modal logics. By forcing ambiguities to be
considered independently, modular disjunctions in particular can be used to
construct efficiently executable specifications in reasoning tasks involving
partial information that otherwise might require prohibitive search. To achieve
this behavior requires prior proof-theoretic justifications of logic
programming to be extended, strengthened, and combined with proof-theoretic
analyses of modal deduction in a novel way.
</dc:description>
 <dc:date>2001-04-30</dc:date>
 <dc:date>2002-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0104022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Microplanning with Communicative Intentions: The SPUD System</dc:title>
 <dc:creator>Stone, Matthew</dc:creator>
 <dc:creator>Doran, Christine</dc:creator>
 <dc:creator>Webber, Bonnie</dc:creator>
 <dc:creator>Bleam, Tonia</dc:creator>
 <dc:creator>Palmer, Martha</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The process of microplanning encompasses a range of problems in Natural
Language Generation (NLG), such as referring expression generation, lexical
choice, and aggregation, problems in which a generator must bridge underlying
domain-specific representations and general linguistic representations. In this
paper, we describe a uniform approach to microplanning based on declarative
representations of a generator's communicative intent. These representations
describe the results of NLG: communicative intent associates the concrete
linguistic structure planned by the generator with inferences that show how the
meaning of that structure communicates needed information about some
application domain in the current discourse context. Our approach, implemented
in the SPUD (sentence planning using description) microplanner, uses the
lexicalized tree-adjoining grammar formalism (LTAG) to connect structure to
meaning and uses modal logic programming to connect meaning to context. At the
same time, communicative intent representations provide a resource for the
process of NLG. Using representations of communicative intent, a generator can
augment the syntax, semantics and pragmatics of an incomplete sentence
simultaneously, and can assess its progress on the various problems of
microplanning incrementally. The declarative formulation of communicative
intent translates into a well-defined methodology for designing grammatical and
conceptual resources which the generator can use to achieve desired
microplanning behavior in a specified domain.
</dc:description>
 <dc:date>2001-04-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0104022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correction of Errors in a Modality Corpus Used for Machine Translation
  by Using Machine-learning Method</dc:title>
 <dc:creator>Murata, Masaki</dc:creator>
 <dc:creator>Utiyama, Masao</dc:creator>
 <dc:creator>Uchimoto, Kiyotaka</dc:creator>
 <dc:creator>Ma, Qing</dc:creator>
 <dc:creator>Isahara, Hitoshi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We performed corpus correction on a modality corpus for machine translation
by using such machine-learning methods as the maximum-entropy method. We thus
constructed a high-quality modality corpus based on corpus correction. We
compared several kinds of methods for corpus correction in our experiments and
developed a good method for corpus correction.
</dc:description>
 <dc:description>Comment: 9 pages. Computation and Language. This paper is the English
  translation of our Japanese papar</dc:description>
 <dc:date>2001-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Man [and Woman] vs. Machine: A Case Study in Base Noun Phrase Learning</dc:title>
 <dc:creator>Brill, Eric</dc:creator>
 <dc:creator>Ngai, Grace</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  A great deal of work has been done demonstrating the ability of machine
learning algorithms to automatically extract linguistic knowledge from
annotated corpora. Very little work has gone into quantifying the difference in
ability at this task between a person and a machine. This paper is a first step
in that direction.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, presented at ACL 1999</dc:description>
 <dc:date>2001-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105002</dc:identifier>
 <dc:identifier>Proceedings of the 37th Annual Meeting of the Association of
  Computational Linguistics, pages 65-72, College Park, MD, USA (1999)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rule Writing or Annotation: Cost-efficient Resource Usage for Base Noun
  Phrase Chunking</dc:title>
 <dc:creator>Ngai, Grace</dc:creator>
 <dc:creator>Yarowsky, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper presents a comprehensive empirical comparison between two
approaches for developing a base noun phrase chunker: human rule writing and
active learning using interactive real-time human annotation. Several novel
variations on active learning are investigated, and underlying cost models for
cross-modal machine learning comparison are presented and explored. Results
show that it is more efficient and more successful by several measures to train
a system using active learning annotation rather than hand-crafted rule writing
at a comparable level of human labor investment.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures, appeared in ACL2000</dc:description>
 <dc:date>2001-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105003</dc:identifier>
 <dc:identifier>Proceedings of the 38th Annual Meeting of the Association for
  Computational Linguistics, pages 117-125, Hong Kong (2000)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105004</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel implementation of the TRANSIMS micro-simulation</dc:title>
 <dc:creator>Nagel, Kai</dc:creator>
 <dc:creator>Rickert, Marcus</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>I.6</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  This paper describes the parallel implementation of the TRANSIMS traffic
micro-simulation. The parallelization method is domain decomposition, which
means that each CPU of the parallel computer is responsible for a different
geographical area of the simulated region. We describe how information between
domains is exchanged, and how the transportation network graph is partitioned.
An adaptive scheme is used to optimize load balancing. We then demonstrate how
computing speeds of our parallel micro-simulations can be systematically
predicted once the scenario and the computer architecture are known. This makes
it possible, for example, to decide if a certain study is feasible with a
certain computing budget, and how to invest that budget. The main ingredients
of the prediction are knowledge about the parallel implementation of the
micro-simulation, knowledge about the characteristics of the partitioning of
the transportation network graph, and knowledge about the interaction of these
quantities with the computer system. In particular, we investigate the
differences between switched and non-switched topologies, and the effects of 10
Mbit, 100 Mbit, and Gbit Ethernet. keywords: Traffic simulation, parallel
computing, transportation planning, TRANSIMS
</dc:description>
 <dc:date>2001-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Complete WordNet1.5 to WordNet1.6 Mapping</dc:title>
 <dc:creator>Daud&#xe9;, J.</dc:creator>
 <dc:creator>Padr&#xf3;, L.</dc:creator>
 <dc:creator>Rigau, G.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We describe a robust approach for linking already existing lexical/semantic
hierarchies. We use a constraint satisfaction algorithm (relaxation labelling)
to select --among a set of candidates-- the node in a target taxonomy that
bests matches each node in a source taxonomy. In this paper we present the
complete mapping of the nominal, verbal, adjectival and adverbial parts of
WordNet 1.5 onto WordNet 1.6.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures. To appear in proceedings of NAACL'01 Workshop on
  WordNet and Other Lexical Resources</dc:description>
 <dc:date>2001-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105006</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reverse Engineering from Assembler to Formal Specifications via Program
  Transformations</dc:title>
 <dc:creator>Ward, M. P.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.7</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:description>  The FermaT transformation system, based on research carried out over the last
sixteen years at Durham University, De Montfort University and Software
Migrations Ltd., is an industrial-strength formal transformation engine with
many applications in program comprehension and language migration. This paper
is a case study which uses automated plus manually-directed transformations and
abstractions to convert an IBM 370 Assembler code program into a very
high-level abstract specification.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2001-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105006</dc:identifier>
 <dc:identifier>7th Working Conference on Reverse Engineering 2000, 23--25 Nov
  2000, Brisbane, Queensland, Australia. IEEE Computer Society</dc:identifier>
 <dc:identifier>doi:10.1109/WCRE.2000.891448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Polymorphically Typed Logic Programs Using ACI-Unification</dc:title>
 <dc:creator>Smaus, Jan-Georg</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>F.3.3</dc:subject>
 <dc:description>  Analysis of (partial) groundness is an important application of abstract
interpretation. There are several proposals for improving the precision of such
an analysis by exploiting type information, icluding our own work with Hill and
King, where we had shown how the information present in the type declarations
of a program can be used to characterise the degree of instantiation of a term
in a precise and yet inherently finite way. This approach worked for
polymorphically typed programs as in Goedel or HAL. Here, we recast this
approach following works by Codish, Lagoon and Stuckey. To formalise which
properties of terms we want to characterise, we use labelling functions, which
are functions that extract subterms from a term along certain paths. An
abstract term collects the results of all labelling functions of a term. For
the analysis, programs are executed on abstract terms instead of the concrete
ones, and usual unification is replaced by unification modulo an equality
theory which includes the well-known ACI-theory. Thus we generalise the works
by Codish, Lagoon and Stuckey w.r.t. the type systems considered and relate the
works among each other.
</dc:description>
 <dc:description>Comment: 27 pages</dc:description>
 <dc:date>2001-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105008</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Slicing Technique to Software Architectures</dc:title>
 <dc:creator>Zhao, Jianjun</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:subject>D.2.7</dc:subject>
 <dc:subject>D.2.11</dc:subject>
 <dc:description>  Software architecture is receiving increasingly attention as a critical
design level for software systems. As software architecture design resources
(in the form of architectural specifications) are going to be accumulated, the
development of techniques and tools to support architectural understanding,
testing, reengineering, maintenance, and reuse will become an important issue.
This paper introduces a new form of slicing, named architectural slicing, to
aid architectural understanding and reuse. In contrast to traditional slicing,
architectural slicing is designed to operate on the architectural specification
of a software system, rather than the source code of a program. Architectural
slicing provides knowledge about the high-level structure of a software system,
rather than the low-level implementation details of a program. In order to
compute an architectural slice, we present the architecture information flow
graph which can be used to represent information flows in a software
architecture. Based on the graph, we give a two-phase algorithm to compute an
architectural slice.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures</dc:description>
 <dc:date>2001-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105008</dc:identifier>
 <dc:identifier>Proceedings of the 4th IEEE International Conference on
  Engineering of Complex Computer Systems, pp.87-98, August 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Dependence Analysis to Support Software Architecture Understanding</dc:title>
 <dc:creator>Zhao, Jianjun</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:subject>D.2.7</dc:subject>
 <dc:subject>D.2.11</dc:subject>
 <dc:description>  Software architecture is receiving increasingly attention as a critical
design level for software systems. As software architecture design resources
(in the form of architectural descriptions) are going to be accumulated, the
development of techniques and tools to support architectural understanding,
testing, reengineering, maintaining, and reusing will become an important
issue. In this paper we introduce a new dependence analysis technique, named
architectural dependence analysis to support software architecture development.
In contrast to traditional dependence analysis, architectural dependence
analysis is designed to operate on an architectural description of a software
system, rather than the source code of a conventional program. Architectural
dependence analysis provides knowledge of dependences for the high-level
architecture of a software system, rather than the low-level implementation
details of a conventional program.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2001-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105009</dc:identifier>
 <dc:identifier>In M. Li (Ed.), &quot;New Technologies on Computer Software,&quot;
  pp.135-142, International Academic Publishers, September 1997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Assessing the Complexity of Software Architectures</dc:title>
 <dc:creator>Zhao, Jianjun</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.8</dc:subject>
 <dc:subject>D.2.11</dc:subject>
 <dc:description>  This paper proposes some new architectural metrics which are appropriate for
evaluating the architectural attributes of a software system. The main feature
of our approach is to assess the complexity of a software architecture by
analyzing various types of architectural dependences in the architecture.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2001-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105010</dc:identifier>
 <dc:identifier>Proceedings of the 3rd International Software Architecture
  Workshop (ISAW3), pp.163-166, ACM SIGSOFT, November 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Component Programming and Interoperability in Constraint Solver Design</dc:title>
 <dc:creator>Goualard, Frederic</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>D.2</dc:subject>
 <dc:description>  Prolog was once the main host for implementing constraint solvers.
  It seems that it is no longer so. To be useful, constraint solvers have to be
integrable into industrial applications written in imperative or
object-oriented languages; to be efficient, they have to interact with other
solvers. To meet these requirements, many solvers are now implemented in the
form of extensible object-oriented libraries. Following Pfister and Szyperski,
we argue that ``objects are not enough,'' and we propose to design solvers as
component-oriented libraries. We illustrate our approach by the description of
the architecture of a prototype, and we assess its strong points and
weaknesses.
</dc:description>
 <dc:description>Comment: 11 pages, 1 figure, paper accepted at the 6th Annual workshop of the
  ERCIM Working Group on Constraints</dc:description>
 <dc:date>2001-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint and conditional estimation of tagging and parsing models</dc:title>
 <dc:creator>Johnson, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  This paper compares two different ways of estimating statistical language
models. Many statistical NLP tagging and parsing models are estimated by
maximizing the (joint) likelihood of the fully-observed training data. However,
since these applications only require the conditional probability
distributions, these distributions can in principle be learnt by maximizing the
conditional likelihood of the training data. Perhaps somewhat surprisingly,
models estimated by maximizing the joint were superior to models estimated by
maximizing the conditional, even though some of the latter models intuitively
had access to ``more information''.
</dc:description>
 <dc:description>Comment: 8 pages, Proceedings of the ACL 2001</dc:description>
 <dc:date>2001-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dijkstra's Self-Stabilizing Algorithm in Unsupportive Environments</dc:title>
 <dc:creator>Dolev, Shlomi</dc:creator>
 <dc:creator>Herman, Ted</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>B.1.3</dc:subject>
 <dc:subject>B.8.1</dc:subject>
 <dc:subject>D.4.5</dc:subject>
 <dc:description>  The first self-stabilizing algorithm [Dij73] assumed the existence of a
central daemon, that activates one processor at time to change state as a
function of its own state and the state of a neighbor. Subsequent research has
reconsidered this algorithm without the assumption of a central daemon, and
under different forms of communication, such as the model of link registers. In
all of these investigations, one common feature is the atomicity of
communication, whether by shared variables or read/write registers. This paper
weakens the atomicity assumptions for the communication model, proposing
versions of [Dij73] that tolerate various weaker forms of atomicity. First, a
solution for the case of regular registers is presented. Then the case of safe
registers is considered, with both negative and positive results presented. The
paper also presents an implementation of [Dij73] based on registers that have
probabilistically correct behavior, which requires a notion of weak
stabilization.
</dc:description>
 <dc:description>Comment: 12 pages, uses eepic.sty</dc:description>
 <dc:date>2001-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Errata and supplements to: Orthonormal RBF Wavelet and Ridgelet-like
  Series and Transforms for High-Dimensional Problems</dc:title>
 <dc:creator>Chen, W.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>G1.3</dc:subject>
 <dc:subject>G1.8</dc:subject>
 <dc:description>  In recent years some attempts have been done to relate the RBF with wavelets
in handling high dimensional multiscale problems. To the author's knowledge,
however, the orthonormal and bi-orthogonal RBF wavelets are still missing in
the literature. By using the nonsingular general solution and singular
fundamental solution of differential operator, recently the present author,
refer. 3, made some substantial headway to derive the orthonormal RBF wavelets
series and transforms. The methodology can be generalized to create the RBF
wavelets by means of the orthogonal convolution kernel function of various
integral operators. In particular, it is stressed that the presented RBF
wavelets does not apply the tensor product to handle multivariate problems at
all.
  This note is to correct some errata in reference 3 and also to supply a few
latest advances in the study of orthornormal RBF wavelet transforms.
</dc:description>
 <dc:description>Comment: Welcome any comments to wenc@ifi.uio.no</dc:description>
 <dc:date>2001-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The alldifferent Constraint: A Survey</dc:title>
 <dc:creator>van Hoeve, W. J.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  The constraint of difference is known to the constraint programming community
since Lauriere introduced Alice in 1978. Since then, several solving strategies
have been designed for this constraint. In this paper we give both a practical
overview and an abstract comparison of these different strategies.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figures, paper accepted at the 6th Annual workshop of the
  ERCIM Working Group on Constraints</dc:description>
 <dc:date>2001-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic top-down parsing and language modeling</dc:title>
 <dc:creator>Roark, Brian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper describes the functioning of a broad-coverage probabilistic
top-down parser, and its application to the problem of language modeling for
speech recognition. The paper first introduces key notions in language modeling
and probabilistic parsing, and briefly reviews some previous approaches to
using syntactic structure for language modeling. A lexicalized probabilistic
top-down parser is then presented, which performs very well, in terms of both
the accuracy of returned parses and the efficiency with which they are found,
relative to the best broad-coverage statistical parsers. A new language model
which utilizes probabilistic top-down parsing is then outlined, and empirical
results show that it improves upon previous work in test corpus perplexity.
Interpolation with a trigram model yields an exceptional improvement relative
to the improvement observed by other models, demonstrating the degree to which
the information captured by our parsing model is orthogonal to that captured by
a trigram model. A small recognition experiment also demonstrates the utility
of the model.
</dc:description>
 <dc:description>Comment: 28 pages, 6 tables, 8 figures. To appear in Computational Linguistics
  27(2), June 2001</dc:description>
 <dc:date>2001-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization Over Zonotopes and Training Support Vector Machines</dc:title>
 <dc:creator>Bern, Marshall</dc:creator>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:description>  We make a connection between classical polytopes called zonotopes and Support
Vector Machine (SVM) classifiers. We combine this connection with the ellipsoid
method to give some new theoretical results on training SVMs. We also describe
some special properties of soft margin C-SVMs as parameter C goes to infinity.
</dc:description>
 <dc:description>Comment: To appear in Workshop on Algorithms and Data Structures, 2001</dc:description>
 <dc:date>2001-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105018</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HTTP Cookies: Standards, Privacy, and Politics</dc:title>
 <dc:creator>Kristol, David M.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:subject>K.2</dc:subject>
 <dc:description>  How did we get from a world where cookies were something you ate and where
&quot;non-techies&quot; were unaware of &quot;Netscape cookies&quot; to a world where cookies are a
hot-button privacy issue for many computer users? This paper will describe how
HTTP &quot;cookies&quot; work, and how Netscape's original specification evolved into an
IETF Proposed Standard. I will also offer a personal perspective on how what
began as a straightforward technical specification turned into a political
flashpoint when it tried to address non-technical issues such as privacy.
</dc:description>
 <dc:date>2001-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105018</dc:identifier>
 <dc:identifier>ACM Transactions on Internet Technology, Vol. 1, #2, November 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Probabilistic Predictive Syntactic Processing</dc:title>
 <dc:creator>Roark, Brian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This thesis presents a broad-coverage probabilistic top-down parser, and its
application to the problem of language modeling for speech recognition. The
parser builds fully connected derivations incrementally, in a single pass from
left-to-right across the string. We argue that the parsing approach that we
have adopted is well-motivated from a psycholinguistic perspective, as a model
that captures probabilistic dependencies between lexical items, as part of the
process of building connected syntactic structures. The basic parser and
conditional probability models are presented, and empirical results are
provided for its parsing accuracy on both newspaper text and spontaneous
telephone conversations. Modifications to the probability model are presented
that lead to improved performance. A new language model which uses the output
of the parser is then defined. Perplexity and word error rate reduction are
demonstrated over trigram models, even when the trigram is trained on
significantly more data. Interpolation on a word-by-word basis with a trigram
model yields additional improvements.
</dc:description>
 <dc:description>Comment: Ph.D. Thesis, Brown University, Advisor: Mark Johnson. 140 pages, 40
  figures, 27 tables</dc:description>
 <dc:date>2001-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Logical Framework for Convergent Infinite Computations</dc:title>
 <dc:creator>Li, Wei</dc:creator>
 <dc:creator>Ma, Shilong</dc:creator>
 <dc:creator>Sui, Yuefei</dc:creator>
 <dc:creator>Xu, Ke</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>F.4.1, D.1.6</dc:subject>
 <dc:description>  Classical computations can not capture the essence of infinite computations
very well. This paper will focus on a class of infinite computations called
convergent infinite computations}. A logic for convergent infinite computations
is proposed by extending first order theories using Cauchy sequences, which has
stronger expressive power than the first order logic. A class of fixed points
characterizing the logical properties of the limits can be represented by means
of infinite-length terms defined by Cauchy sequences. We will show that the
limit of sequence of first order theories can be defined in terms of distance,
similar to the $\epsilon-N$ style definition of limits in real analysis. On the
basis of infinitary terms, a computation model for convergent infinite
computations is proposed. Finally, the interpretations of logic programs are
extended by introducing real Herbrand models of logic programs and a sufficient
condition for computing a real Herbrand model of Horn logic programs using
convergent infinite computation is given.
</dc:description>
 <dc:description>Comment: 17 pages. Welcome any comments to kexu@nlsde.buaa.edu.cn</dc:description>
 <dc:date>2001-05-09</dc:date>
 <dc:date>2002-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving Composed First-Order Constraints from Discrete-Time Robust
  Control</dc:title>
 <dc:creator>Ratschan, Stefan</dc:creator>
 <dc:creator>Jaulin, Luc</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  This paper deals with a problem from discrete-time robust control which
requires the solution of constraints over the reals that contain both universal
and existential quantifiers. For solving this problem we formulate it as a
program in a (fictitious) constraint logic programming language with explicit
quantifier notation. This allows us to clarify the special structure of the
problem, and to extend an algorithm for computing approximate solution sets of
first-order constraints over the reals to exploit this structure. As a result
we can deal with inputs that are clearly out of reach for current symbolic
solvers.
</dc:description>
 <dc:description>Comment: Presented at the Sixth Annual Workshop of the ERCIM Working Group on
  Constraints</dc:description>
 <dc:date>2001-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Channel Parallel Adaptation Theory for Rule Discovery</dc:title>
 <dc:creator>Fu, Li Min</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I2.6</dc:subject>
 <dc:description>  In this paper, we introduce a new machine learning theory based on
multi-channel parallel adaptation for rule discovery. This theory is
distinguished from the familiar parallel-distributed adaptation theory of
neural networks in terms of channel-based convergence to the target rules. We
show how to realize this theory in a learning system named CFRule. CFRule is a
parallel weight-based model, but it departs from traditional neural computing
in that its internal knowledge is comprehensible. Furthermore, when the model
converges upon training, each channel converges to a target rule. The model
adaptation rule is derived by multi-level parallel weight optimization based on
gradient descent. Since, however, gradient descent only guarantees local
optimization, a multi-channel regression-based optimization strategy is
developed to effectively deal with this problem. Formally, we prove that the
CFRule model can explicitly and precisely encode any given rule set. Also, we
prove a property related to asynchronous parallel convergence, which is a
critical element of the multi-channel parallel adaptation theory for rule
learning. Thanks to the quantizability nature of the CFRule model, rules can be
extracted completely and soundly via a threshold-based mechanism. Finally, the
practical application of the theory is demonstrated in DNA promoter recognition
and hepatitis prognosis prediction.
</dc:description>
 <dc:description>Comment: 21 pages, 1 figure, 7 tables</dc:description>
 <dc:date>2001-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating a 3D Simulation of a Car Accident from a Written Description
  in Natural Language: the CarSim System</dc:title>
 <dc:creator>Dupuy, Sylvain</dc:creator>
 <dc:creator>Egges, Arjan</dc:creator>
 <dc:creator>Legendre, Vincent</dc:creator>
 <dc:creator>Nugues, Pierre</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:description>  This paper describes a prototype system to visualize and animate 3D scenes
from car accident reports, written in French. The problem of generating such a
3D simulation can be divided into two subtasks: the linguistic analysis and the
virtual scene generation. As a means of communication between these two
modules, we first designed a template formalism to represent a written accident
report. The CarSim system first processes written reports, gathers relevant
information, and converts it into a formal description. Then, it creates the
corresponding 3D scene and animates the vehicles.
</dc:description>
 <dc:description>Comment: 8 pages, ACL 2001, Workshop on Temporal and Spatial Information
  Processing</dc:description>
 <dc:date>2001-05-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constraint Propagation in Presence of Arrays</dc:title>
 <dc:creator>Brand, Sebastian</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:description>  We describe the use of array expressions as constraints, which represents a
consequent generalisation of the &quot;element&quot; constraint. Constraint propagation
for array constraints is studied theoretically, and for a set of domain
reduction rules the local consistency they enforce, arc-consistency, is proved.
An efficient algorithm is described that encapsulates the rule set and so
inherits the capability to enforce arc-consistency from the rules.
</dc:description>
 <dc:description>Comment: 10 pages. Accepted at the 6th Annual Workshop of the ERCIM Working
  Group on Constraints, 2001</dc:description>
 <dc:date>2001-05-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Market-Based Reinforcement Learning in Partially Observable Worlds</dc:title>
 <dc:creator>Kwee, Ivo</dc:creator>
 <dc:creator>Hutter, Marcus</dc:creator>
 <dc:creator>Schmidhuber, Juergen</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:description>  Unlike traditional reinforcement learning (RL), market-based RL is in
principle applicable to worlds described by partially observable Markov
Decision Processes (POMDPs), where an agent needs to learn short-term memories
of relevant previous events in order to execute optimal actions. Most previous
work, however, has focused on reactive settings (MDPs) instead of POMDPs. Here
we reimplement a recent approach to market-based RL and for the first time
evaluate it in a toy POMDP setting.
</dc:description>
 <dc:description>Comment: 8 LaTeX pages, 2 postscript figures</dc:description>
 <dc:date>2001-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105025</dc:identifier>
 <dc:identifier>Lecture Notes in Computer Science (LNCS 2130), Proceeding of the
  International Conference on Artificial Neural Networks ICANN (2001) 865-873</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Natural Gesture/Speech Control of a Large Display</dc:title>
 <dc:creator>Kettebekov, S.</dc:creator>
 <dc:creator>Sharma, R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  In recent years because of the advances in computer vision research, free
hand gestures have been explored as means of human-computer interaction (HCI).
Together with improved speech processing technology it is an important step
toward natural multimodal HCI. However, inclusion of non-predefined continuous
gestures into a multimodal framework is a challenging problem. In this paper,
we propose a structured approach for studying patterns of multimodal language
in the context of a 2D-display control. We consider systematic analysis of
gestures from observable kinematical primitives to their semantics as pertinent
to a linguistic structure. Proposed semantic classification of co-verbal
gestures distinguishes six categories based on their spatio-temporal deixis. We
discuss evolution of a computational framework for gesture and speech
integration which was used to develop an interactive testbed (iMAP). The
testbed enabled elicitation of adequate, non-sequential, multimodal patterns in
a narrative mode of HCI. Conducted user studies illustrate significance of
accounting for the temporal alignment of gesture and speech parts in semantic
mapping. Furthermore, co-occurrence analysis of gesture/speech production
suggests syntactic organization of gestures at the lexical level.
</dc:description>
 <dc:description>Comment: Engineering for Human-Computer Interaction (EHCI'01),Toronto, Canada.
  May 11-14, 2001. Lecture Notes in Computer Science, Springer Verlag. 14 pages</dc:description>
 <dc:date>2001-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105027</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounds on sample size for policy evaluation in Markov environments</dc:title>
 <dc:creator>Peshkin, Leonid</dc:creator>
 <dc:creator>Mukherjee, Sayan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>G.2</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Reinforcement learning means finding the optimal course of action in
Markovian environments without knowledge of the environment's dynamics.
Stochastic optimization algorithms used in the field rely on estimates of the
value of a policy. Typically, the value of a policy is estimated from results
of simulating that very policy in the environment. This approach requires a
large amount of simulation as different points in the policy space are
considered. In this paper, we develop value estimators that utilize data
gathered when using one policy to estimate the value of using another policy,
resulting in much more data-efficient algorithms. We consider the question of
accumulating a sufficient experience and give PAC-style bounds.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2001-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105027</dc:identifier>
 <dc:identifier>COLT 2001: The Fourteenth Annual Conference on Computational
  Learning Theory</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When being Weak is Brave: Privacy in Recommender Systems</dc:title>
 <dc:creator>Ramakrishnan, Naren</dc:creator>
 <dc:creator>Keller, Benjamin J.</dc:creator>
 <dc:creator>Mirza, Batul J.</dc:creator>
 <dc:creator>Grama, Ananth Y.</dc:creator>
 <dc:creator>Karypis, George</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>H.4.2</dc:subject>
 <dc:description>  We explore the conflict between personalization and privacy that arises from
the existence of weak ties. A weak tie is an unexpected connection that
provides serendipitous recommendations. However, information about weak ties
could be used in conjunction with other sources of data to uncover identities
and reveal other personal information. In this article, we use a
graph-theoretic model to study the benefit and risk from weak ties.
</dc:description>
 <dc:date>2001-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105029</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coloring k-colorable graphs using relatively small palettes</dc:title>
 <dc:creator>Halperin, Eran</dc:creator>
 <dc:creator>Nathaniel, Ram</dc:creator>
 <dc:creator>Zwick, Uri</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  We obtain the following new coloring results:
  * A 3-colorable graph on $n$ vertices with maximum degree~$\Delta$ can be
colored, in polynomial time, using $O((\Delta \log\Delta)^{1/3} \cdot\log{n})$
colors. This slightly improves an $O((\Delta^{{1}/{3}}
\log^{1/2}\Delta)\cdot\log{n})$ bound given by Karger, Motwani and Sudan. More
generally, $k$-colorable graphs with maximum degree $\Delta$ can be colored, in
polynomial time, using $O((\Delta^{1-{2}/{k}}\log^{1/k}\Delta) \cdot\log{n})$
colors.
  * A 4-colorable graph on $n$ vertices can be colored, in polynomial time,
using $\Ot(n^{7/19})$ colors. This improves an $\Ot(n^{2/5})$ bound given again
by Karger, Motwani and Sudan. More generally, $k$-colorable graphs on $n$
vertices can be colored, in polynomial time, using $\Ot(n^{\alpha_k})$ colors,
where $\alpha_5=97/207$, $\alpha_6=43/79$, $\alpha_7=1391/2315$,
$\alpha_8=175/271$, ...
  The first result is obtained by a slightly more refined probabilistic
analysis of the semidefinite programming based coloring algorithm of Karger,
Motwani and Sudan. The second result is obtained by combining the coloring
algorithm of Karger, Motwani and Sudan, the combinatorial coloring algorithms
of Blum and an extension of a technique of Alon and Kahale (which is based on
the Karger, Motwani and Sudan algorithm) for finding relatively large
independent sets in graphs that are guaranteed to have very large independent
sets. The extension of the Alon and Kahale result may be of independent
interest.
</dc:description>
 <dc:description>Comment: 16 pages, 2 figures. A preliminary version of this paper appeared in
  the proceedings the of 12th ACM-SIAM Symposium on Discrete Algorithm
  (SODA'01) under a slightly different title</dc:description>
 <dc:date>2001-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The OLAC Metadata Set and Controlled Vocabularies</dc:title>
 <dc:creator>Bird, Steven</dc:creator>
 <dc:creator>Simons, Gary</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>H.2.7</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.7.2</dc:subject>
 <dc:subject>J.5</dc:subject>
 <dc:description>  As language data and associated technologies proliferate and as the language
resources community rapidly expands, it has become difficult to locate and
reuse existing resources. Are there any lexical resources for such-and-such a
language? What tool can work with transcripts in this particular format? What
is a good format to use for linguistic data of this type? Questions like these
dominate many mailing lists, since web search engines are an unreliable way to
find language resources. This paper describes a new digital infrastructure for
language resource discovery, based on the Open Archives Initiative, and called
OLAC -- the Open Language Archives Community. The OLAC Metadata Set and the
associated controlled vocabularies facilitate consistent description and
focussed searching. We report progress on the metadata set and controlled
vocabularies, describing current issues and soliciting input from the language
resources community.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures</dc:description>
 <dc:date>2001-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105030</dc:identifier>
 <dc:identifier>Proceedings of the ACL/EACL Workshop on Sharing Tools and
  Resources for Research and Education, Toulouse, July 2001, Association for
  Computational Linguistics</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>State Analysis and Aggregation Study for Multicast-based Micro Mobility</dc:title>
 <dc:creator>Helmy, Ahmed</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:description>  IP mobility addresses the problem of changing the network point-of-attachment
transparently during movement. Mobile IP is the proposed standard by IETF.
Several studies, however, have shown that Mobile IP has several drawbacks, such
as triangle routing and poor handoff performance. Multicast-based mobility has
been proposed as a promising solution to the above problems, incurring less
end-to-end delays and fast smooth handoff. Nonetheless, such architecture
suffers from multicast state scalability problems with the growth in number of
mobile nodes. This architecture also requires ubiquitous multicast deployment
and more complex security measures. To alleviate these problems, we propose an
intra-domain multicast-based mobility solution. A mobility proxy allocates a
multicast address for each mobile that moves to its domain. The mobile uses
this multicast address within a domain for micro mobility. Also, aggregation is
considered to reduce the multicast state. We conduct multicast state analysis
to study the efficiency of several aggregation techniques. We use extensive
simulation to evaluate our protocol's performance over a variety of real and
generated topologies. We take aggregation gain as metric for our evaluation.
  Our simulation results show that in general leaky aggregation obtains better
gains than perfect aggregation. Also, we notice that aggregation gain increases
with the increase in number of visiting mobile nodes and with the decrease in
number of mobility proxies within a domain.
</dc:description>
 <dc:description>Comment: 15 pages, 17 figures, Keywords Micro Mobility, Multicast State,
  Efficient Handoff, Network Simulation, State Aggregation</dc:description>
 <dc:date>2001-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105032</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Cooperate via Policy Search</dc:title>
 <dc:creator>Peshkin, Leonid</dc:creator>
 <dc:creator>Kim, Kee-Eung</dc:creator>
 <dc:creator>Meuleau, Nicolas</dc:creator>
 <dc:creator>Kaelbling, Leslie Pack</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  Cooperative games are those in which both agents share the same payoff
structure. Value-based reinforcement-learning algorithms, such as variants of
Q-learning, have been applied to learning cooperative games, but they only
apply when the game state is completely observable to both agents. Policy
search methods are a reasonable alternative to value-based methods for
partially observable environments. In this paper, we provide a gradient-based
distributed policy-search method for cooperative games and compare the notion
of local optimum to that of Nash equilibrium. We demonstrate the effectiveness
of this method experimentally in a small, partially observable simulated soccer
domain.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2001-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105032</dc:identifier>
 <dc:identifier>Sixteenth Conference on Uncertainty in Artificial Intelligence,
  2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lectures on Reduce and Maple at UAM I - Mexico</dc:title>
 <dc:creator>Toussaint, Marc</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>General Relativity and Quantum Cosmology</dc:subject>
 <dc:subject>I.1.3</dc:subject>
 <dc:description>  These lectures give a brief introduction to the Computer Algebra systems
Reduce and Maple. The aim is to provide a systematic survey of most important
commands and concepts. In particular, this includes a discussion of
simplification schemes and the handling of simplification and substitution
rules (e.g., a Lie Algebra is implemented in Reduce by means of simplification
rules).
  Another emphasis is on the different implementations of tensor calculi and
the exterior calculus by Reduce and Maple and their application in Gravitation
theory and Differential Geometry.
  I held the lectures at the Universidad Autonoma Metropolitana-Iztapalapa,
Departamento de Fisica, Mexico, in November 1999.
</dc:description>
 <dc:description>Comment: 61 pages; supplementary material can be found at
  http://www.neuroinformatik.ruhr-uni-bochum.de/PEOPLE/mt/work/1999mexico/</dc:description>
 <dc:date>2001-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Area of Hypercube Layouts</dc:title>
 <dc:creator>Greenberg, Ronald I.</dc:creator>
 <dc:creator>Guan, Lee</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.1.2</dc:subject>
 <dc:description>  This paper precisely analyzes the wire density and required area in standard
layout styles for the hypercube. The most natural, regular layout of a
hypercube of N^2 nodes in the plane, in a N x N grid arrangement, uses
floor(2N/3)+1 horizontal wiring tracks for each row of nodes. (The number of
tracks per row can be reduced by 1 with a less regular design.) This paper also
gives a simple formula for the wire density at any cut position and a full
characterization of all places where the wire density is maximized (which does
not occur at the bisection).
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, LaTeX</dc:description>
 <dc:date>2001-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105034</dc:identifier>
 <dc:identifier>condensed and revised in Information Processing Letters, v. 84, n.
  1, pp. 41--46, Sep. 2002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Historical Dynamics of Lexical System as Random Walk Process</dc:title>
 <dc:creator>Kromer, Victor</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  It is offered to consider word meanings changes in diachrony as
semicontinuous random walk with reflecting and swallowing screens. The basic
characteristics of word life cycle are defined. Verification of the model has
been realized on the data of Russian words distribution on various age periods.
</dc:description>
 <dc:description>Comment: 4 pages, 1 table, 3 figures. Submitted to conference &quot;Language in
  Sinchrony and Diachrony&quot;, to be held in Petrozavodsk State Pedagogical
  University (Russia), 15-17 October, 2001. (In Russian)</dc:description>
 <dc:date>2001-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105035</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105036</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disjunctive Logic Programs with Inheritance</dc:title>
 <dc:creator>Buccafurri, Francesco</dc:creator>
 <dc:creator>Faber, Wolfgang</dc:creator>
 <dc:creator>Leone, Nicola</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  The paper proposes a new knowledge representation language, called DLP&lt;,
which extends disjunctive logic programming (with strong negation) by
inheritance. The addition of inheritance enhances the knowledge modeling
features of the language providing a natural representation of default
reasoning with exceptions.
  A declarative model-theoretic semantics of DLP&lt; is provided, which is shown
to generalize the Answer Set Semantics of disjunctive logic programs.
  The knowledge modeling features of the language are illustrated by encoding
classical nonmonotonic problems in DLP&lt;.
  The complexity of DLP&lt; is analyzed, proving that inheritance does not cause
any computational overhead, as reasoning in DLP&lt; has exactly the same
complexity as reasoning in disjunctive logic programming. This is confirmed by
the existence of an efficient translation from DLP&lt; to plain disjunctive logic
programming. Using this translation, an advanced KR system supporting the DLP&lt;
language has been implemented on top of the DLV system and has subsequently
been integrated into DLV.
</dc:description>
 <dc:description>Comment: 28 pages; will be published in Theory and Practice of Logic
  Programming</dc:description>
 <dc:date>2001-05-30</dc:date>
 <dc:date>2001-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105036</dc:identifier>
 <dc:identifier>Theory and Practice of Logic Programming 2(3):293-321, 2002</dc:identifier>
 <dc:identifier>doi:10.1017/S1471068402001394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0105037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating Prosodic and Lexical Cues for Automatic Topic Segmentation</dc:title>
 <dc:creator>Tur, G.</dc:creator>
 <dc:creator>Hakkani-Tur, D.</dc:creator>
 <dc:creator>Stolcke, A.</dc:creator>
 <dc:creator>Shriberg, E.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We present a probabilistic model that uses both prosodic and lexical cues for
the automatic segmentation of speech into topically coherent units. We propose
two methods for combining lexical and prosodic information using hidden Markov
models and decision trees. Lexical information is obtained from a speech
recognizer, and prosodic features are extracted automatically from speech
waveforms. We evaluate our approach on the Broadcast News corpus, using the
DARPA-TDT evaluation metrics. Results show that the prosodic model alone is
competitive with word-based segmentation methods. Furthermore, we achieve a
significant reduction in error by combining the prosodic and word-based
knowledge sources.
</dc:description>
 <dc:description>Comment: 27 pages, 8 figures</dc:description>
 <dc:date>2001-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0105037</dc:identifier>
 <dc:identifier>Computation Linguistics 27(1), 31-57, March 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating the satisfiability threshold for random k-XOR-formulas</dc:title>
 <dc:creator>Creignou, Nadia</dc:creator>
 <dc:creator>Daude, Herve</dc:creator>
 <dc:creator>Dubois, Olivier</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>G.2m</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  In this paper we study random linear systems with $k$ variables per equation
over the finite field GF(2), or equivalently $k$-XOR-CNF formulas. In a
previous paper Creignou and Daud\'e proved that the phase transition for the
consistency (satisfiability) of such systems (formulas) exhibits a sharp
threshold. Here we prove that the phase transition occurs as the number of
equations (clauses) is proportional to the number of variables. For any $k\ge
3$ we establish first estimates for the critical ratio. For $k=3$ we get 0.93
as an upper bound, 0.89 as a lower bound, whereas experiments suggest that the
critical ratio is approximately 0.92.
</dc:description>
 <dc:description>Comment: 15 pages, 1 figure</dc:description>
 <dc:date>2001-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving Assembly Line Balancing Problems by Combining IP and CP</dc:title>
 <dc:creator>Bockmayr, Alexander</dc:creator>
 <dc:creator>Pisaruk, Nicolai</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  Assembly line balancing problems consist in partitioning the work necessary
to assemble a number of products among different stations of an assembly line.
We present a hybrid approach for solving such problems, which combines
constraint programming and integer programming.
</dc:description>
 <dc:description>Comment: 10 pages, Sixth Annual Workshop of the ERCIM Working Group on
  Constraints, Prague, June 2001</dc:description>
 <dc:date>2001-06-01</dc:date>
 <dc:date>2001-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on radial basis function computing</dc:title>
 <dc:creator>Chen, W.</dc:creator>
 <dc:creator>He, W.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>G.1.3</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:description>  This note carries three purposes involving our latest advances on the radial
basis function (RBF) approach. First, we will introduce a new scheme employing
the boundary knot method (BKM) to nonlinear convection-diffusion problem. It is
stressed that the new scheme directly results in a linear BKM formulation of
nonlinear problems by using response point-dependent RBFs, which can be solved
by any linear solver. Then we only need to solve a single nonlinear algebraic
equation for desirable unknown at some inner node of interest. The numerical
results demonstrate high accuracy and efficiency of this nonlinear BKM
strategy. Second, we extend the concepts of distance function, which include
time-space and variable transformation distance functions. Finally, we
demonstrate that if the nodes are symmetrically placed, the RBF coefficient
matrices have either centrosymmetric or skew centrosymmetric structures. The
factorization features of such matrices lead to a considerable reduction in the
RBF computing effort. A simple approach is also presented to reduce the
ill-conditioning of RBF interpolation matrices in general cases.
</dc:description>
 <dc:date>2001-06-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106003</dc:identifier>
 <dc:identifier>Int. J. Nonlinear Modelling in Sci. &amp; Engng., 1(1), 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Soft Scheduling</dc:title>
 <dc:creator>Rudova, Hana</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.6.5</dc:subject>
 <dc:description>  Classical notions of disjunctive and cumulative scheduling are studied from
the point of view of soft constraint satisfaction. Soft disjunctive scheduling
is introduced as an instance of soft CSP and preferences included in this
problem are applied to generate a lower bound based on existing discrete
capacity resource. Timetabling problems at Purdue University and Faculty of
Informatics at Masaryk University considering individual course requirements of
students demonstrate practical problems which are solved via proposed methods.
Implementation of general preference constraint solver is discussed and first
computational results for timetabling problem are presented.
</dc:description>
 <dc:description>Comment: 10 pages; accepted to the Sixth Annual Workshop of the ERCIM Working
  Group on Constraints</dc:description>
 <dc:date>2001-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Representation of Legal Contracts</dc:title>
 <dc:creator>Daskalopulu, Aspassia</dc:creator>
 <dc:creator>Sergot, Marek</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:description>  The paper outlines ongoing research on logic-based tools for the analysis and
representation of legal contracts of the kind frequently encountered in
large-scale engineering projects and complex, long-term trading agreements. We
consider both contract formation and contract performance, in each case
identifying the representational issues and the prospects for providing
automated support tools.
</dc:description>
 <dc:date>2001-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106005</dc:identifier>
 <dc:identifier>AI &amp; Society, vol. 11, Nos 1/2, pp. 6-17, 1997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Constraint-Driven System for Contract Assembly</dc:title>
 <dc:creator>Daskalopulu, Aspassia</dc:creator>
 <dc:creator>Sergot, Marek</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>H.4.1</dc:subject>
 <dc:description>  We present an approach for modelling the structure and coarse content of
legal documents with a view to providing automated support for the drafting of
contracts and contract database retrieval. The approach is designed to be
applicable where contract drafting is based on model-form contracts or on
existing examples of a similar type. The main features of the approach are: (1)
the representation addresses the structure and the interrelationships between
the constituent parts of contracts, but not the text of the document itself;
(2) the representation of documents is separated from the mechanisms that
manipulate it; and (3) the drafting process is subject to a collection of
explicitly stated constraints that govern the structure of the documents. We
describe the representation of document instances and of 'generic documents',
which are data structures used to drive the creation of new document instances,
and we show extracts from a sample session to illustrate the features of a
prototype system implemented in MacProlog.
</dc:description>
 <dc:date>2001-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106006</dc:identifier>
 <dc:identifier>Proc. 5th International Conference on Artificial Intelligence and
  Law, ACM Press, pp. 62-69, 1995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling Contractual Arguments</dc:title>
 <dc:creator>Reed, Chris</dc:creator>
 <dc:creator>Daskalopulu, Aspassia</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:description>  One influential approach to assessing the &quot;goodness&quot; of arguments is offered
by the Pragma-Dialectical school (p-d) (Eemeren &amp; Grootendorst 1992). This can
be compared with Rhetorical Structure Theory (RST) (Mann &amp; Thompson 1988), an
approach that originates in discourse analysis. In p-d terms an argument is
good if it avoids committing a fallacy, whereas in RST terms an argument is
good if it is coherent. RST has been criticised (Snoeck Henkemans 1997) for
providing only a partially functional account of argument, and similar
criticisms have been raised in the Natural Language Generation (NLG)
community-particularly by Moore &amp; Pollack (1992)- with regards to its account
of intentionality in text in general. Mann and Thompson themselves note that
although RST can be successfully applied to a wide range of texts from diverse
domains, it fails to characterise some types of text, most notably legal
contracts. There is ongoing research in the Artificial Intelligence and Law
community exploring the potential for providing electronic support to contract
negotiators, focusing on long-term, complex engineering agreements (see for
example Daskalopulu &amp; Sergot 1997). This paper provides a brief introduction to
RST and illustrates its shortcomings with respect to contractual text. An
alternative approach for modelling argument structure is presented which not
only caters for contractual text, but also overcomes the aforementioned
limitations of RST.
</dc:description>
 <dc:date>2001-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106007</dc:identifier>
 <dc:identifier>Proceedings of the 4th International Conference on Argumentation,
  SICSAT, pp. 686-692, 1998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Functional and Relational Box Consistency by Structured
  Propagation in Atomic Constraint Systems</dc:title>
 <dc:creator>van Emden, M. H.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Box consistency has been observed to yield exponentially better performance
than chaotic constraint propagation in the interval constraint system obtained
by decomposing the original expression into primitive constraints. The claim
was made that the improvement is due to avoiding decomposition. In this paper
we argue that the improvement is due to replacing chaotic iteration by a more
structured alternative.
  To this end we distinguish the existing notion of box consistency from
relational box consistency. We show that from a computational point of view it
is important to maintain the functional structure in constraint systems that
are associated with a system of equations. So far, it has only been considered
computationally important that constraint propagation be fair. With the
additional structure of functional constraint systems, one can define and
implement computationally effective, structured, truncated constraint
propagations. The existing algorithm for box consistency is one such. Our
results suggest that there are others worth investigating.
</dc:description>
 <dc:description>Comment: Presented at the Sixth Annual Workshop of the ERCIM Working Group on
  Constraints. 12 pages</dc:description>
 <dc:date>2001-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model Checking Contractual Protocols</dc:title>
 <dc:creator>Daskalopulu, Aspassia</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  This paper discusses how model checking, a technique used for the
verification of behavioural requirements of dynamic systems, can be usefully
deployed for the verification of contracts. A process view of agreements
between parties is taken, whereby a contract is modelled as it evolves over
time in terms of actions or more generally events that effect changes in its
state. Modelling is done with Petri Nets in the spirit of other research work
on the representation of trade procedures. The paper illustrates all the phases
of the verification technique through an example and argues that the approach
is useful particularly in the context of pre-contractual negotiation and
contract drafting. The work reported here is part of a broader project on the
development of logic-based tools for the analysis and representation of legal
contracts.
</dc:description>
 <dc:date>2001-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106009</dc:identifier>
 <dc:identifier>In Breuker, Leenes &amp; Winkels (eds) Legal Knowledge and Information
  Systems, JURIX 2000: The 13th Annual Conference, Frontiers in Artificial
  Intelligence and Applications Series, IOS Press, pp. 35-47, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106010</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling Legal Contracts as Processes</dc:title>
 <dc:creator>Daskalopulu, Aspassia</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  This paper concentrates on the representation of the legal relations that
obtain between parties once they have entered a contractual agreement and their
evolution as the agreement progresses through time. Contracts are regarded as
process and they are analysed in terms of the obligations that are active at
various points during their life span. An informal notation is introduced that
summarizes conveniently the states of an agreement as it evolves over time.
Such a representation enables us to determine what the status of an agreement
is, given an event or a sequence of events that concern the performance of
actions by the agents involved. This is useful both in the context of contract
drafting (where parties might wish to preview how their agreement might evolve)
and in the context of contract performance monitoring (where parties might with
to establish what their legal positions are once their agreement is in force).
The discussion is based on an example that illustrates some typical patterns of
contractual obligations.
</dc:description>
 <dc:date>2001-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106010</dc:identifier>
 <dc:identifier>11th International Conference and Workshop on Database and Expert
  Systems Applications, IEEE C. S. Press, pp. 1074-1079, 2000</dc:identifier>
 <dc:identifier>doi:10.1109/DEXA.2000.875160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational properties of environment-based disambiguation</dc:title>
 <dc:creator>Schuler, William</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  The standard pipeline approach to semantic processing, in which sentences are
morphologically and syntactically resolved to a single tree before they are
interpreted, is a poor fit for applications such as natural language
interfaces. This is because the environment information, in the form of the
objects and events in the application's run-time environment, cannot be used to
inform parsing decisions unless the input sentence is semantically analyzed,
but this does not occur until after parsing in the single-tree semantic
architecture. This paper describes the computational properties of an
alternative architecture, in which semantic analysis is performed on all
possible interpretations during parsing, in polynomial time.
</dc:description>
 <dc:description>Comment: 8 pages, published in Proceedings of the 39th Annual Meeting of the
  ACL 2001</dc:description>
 <dc:date>2001-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Properties of Metaquerying Problems</dc:title>
 <dc:creator>Angiulli, F.</dc:creator>
 <dc:creator>Ben-Eliyahu-Zohary, R.</dc:creator>
 <dc:creator>Ianni, G.</dc:creator>
 <dc:creator>Palopoli, L.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>H.2.3</dc:subject>
 <dc:subject>F.2.0</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  Metaquerying is a datamining technology by which hidden dependencies among
several database relations can be discovered. This tool has already been
successfully applied to several real-world applications. Recent papers provide
only preliminary results about the complexity of metaquerying. In this paper we
define several variants of metaquerying that encompass, as far as we know, all
variants defined in the literature. We study both the combined complexity and
the data complexity of these variants. We show that, under the combined
complexity measure, metaquerying is generally intractable (unless P=NP), lying
sometimes quite high in the complexity hierarchies (as high as NP^PP),
depending on the characteristics of the plausibility index. However, we are
able to single out some tractable and interesting metaquerying cases (whose
combined complexity is LOGCFL-complete). As for the data complexity of
metaquerying, we prove that, in general, this is in TC0, but lies within AC0 in
some simpler cases. Finally, we discuss implementation of metaqueries, by
providing algorithms to answer them.
</dc:description>
 <dc:description>Comment: 32 pages. Partial and preliminary version appeared in Proc. of 19th
  Symposium on Principles of Database Systems, 2000, Dallas, pp. 237-244</dc:description>
 <dc:date>2001-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Set of Equations to Evaluate Objects</dc:title>
 <dc:creator>Ismailova, Larissa</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:description>  The notion of an equational shell is studied to involve the objects and their
environment. Appropriate methods are studied as valid embeddings of refined
objects. The refinement process determines the linkages between the variety of
possible representations giving rise to variants of computations. The case
study is equipped with the adjusted equational systems that validate the
initial applicative framework.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2001-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106013</dc:identifier>
 <dc:identifier>Proceedings of the 3-rd International Workshop on Computer Science
  and Information Technologies CSIT'2001, Ufa, Yangantau, Ruissia</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>L.T.Kuzin: Research Program</dc:title>
 <dc:creator>Wolfengagen, Viacheslav</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>A.0</dc:subject>
 <dc:subject>F.0</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:description>  Lev T. Kuzin (1928--1997) is one of the founders of modern cybernetics and
information science in Russia. He was awarded and honored the USSR State Prize
for inspiring vision into the future of technical cybernetics and his invention
and innovation of key technologies.
  The last years he interested in the computational models of geometrical and
algebraic nature and their applications in various branches of computer science
and information technologies. In the recent years the interest in computation
models based on object notion has grown tremendously stimulating an interest to
Kuzin's ideas. This year of 50th Anniversary of Cybernetics and on the occasion
of his 70th birthday on September 12, 1998 seems especially appropriate for
discussing Kuzin's Research Program.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2001-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106014</dc:identifier>
 <dc:identifier>Proceedings of the 1st International Workshop on Computer Science
  and Information Technologies CSIT'99. Moscow, Russia, January 18--22, 1999.
  Vol. 1, pp. 97--106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106015</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Organizing Encyclopedic Knowledge based on the Web and its Application
  to Question Answering</dc:title>
 <dc:creator>Fujii, Atsushi</dc:creator>
 <dc:creator>Ishikawa, Tetsuya</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:description>  We propose a method to generate large-scale encyclopedic knowledge, which is
valuable for much NLP research, based on the Web. We first search the Web for
pages containing a term in question. Then we use linguistic patterns and HTML
structures to extract text fragments describing the term. Finally, we organize
extracted term descriptions based on word senses and domains. In addition, we
apply an automatically generated encyclopedia to a question answering system
targeting the Japanese Information-Technology Engineers Examination.
</dc:description>
 <dc:description>Comment: 8 pages, Proceedings of the 39th Annual Meeting of the Association
  for Computational Linguistics (To appear)</dc:description>
 <dc:date>2001-06-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106015</dc:identifier>
 <dc:identifier>Proceedings of the 39th Annual Meeting of the Association for
  Computational Linguistics (ACL-EACL 2001), pp.196-203, July. 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>File mapping Rule-based DBMS and Natural Language Processing</dc:title>
 <dc:creator>Novikov, Vjacheslav M.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:description>  This paper describes the system of storage, extract and processing of
information structured similarly to the natural language. For recursive
inference the system uses the rules having the same representation, as the
data. The environment of storage of information is provided with the File
Mapping (SHM) mechanism of operating system. In the paper the main principles
of construction of dynamic data structure and language for record of the
inference rules are stated; the features of available implementation are
considered and the description of the application realizing semantic
information retrieval on the natural language is given.
</dc:description>
 <dc:description>Comment: 17 pages, 3 figures</dc:description>
 <dc:date>2001-06-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An object evaluator to generate flexible applications</dc:title>
 <dc:creator>Ismailova, Larissa</dc:creator>
 <dc:creator>Zinchenko, Konstantin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>H.1</dc:subject>
 <dc:subject>H.2</dc:subject>
 <dc:description>  This paper contains a brief discussion of an object evaluator which is based
on principles of evaluations in a category. The main tool system referred as
the Application Development Environment (ADE) is used to build database
applications involving the graphical user interface (GUI). The separation of a
database access and the user interface is reached by distinguishing the
potential and actual objects. The variety of applications may be generated that
communicate with different and distinct desktop databases. The commutative
diagrams' technique allows to involve retrieval and call of the delayed
procedures.
</dc:description>
 <dc:date>2001-06-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106017</dc:identifier>
 <dc:identifier>Proceedings of the 1-st East-European Symposium on Advances in
  Databases and Information Systems, ADBIS'97, St.-Petersburg, September 2--5,
  1997, Vol. 1, pp. 141--148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building the access pointers to a computation environment</dc:title>
 <dc:creator>Wolfengagen, Viacheslav</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  A common object technique equipped with the categorical and computational
styles is briefly outlined. An object is evaluated by embedding in a host
computational environment which is the domain-ranged structure. An embedded
object is accessed by the pointers generated within the host system. To assist
with an easy extract the result of the evaluation a pre-embedded object is
generated. It is observed as the decomposition into substitutional part and
access function part which are generated during the object evaluation.
</dc:description>
 <dc:date>2001-06-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106018</dc:identifier>
 <dc:identifier>Proceedings of the 1st East-European Symposium on Advances in
  Databases and Information Systems, ADBIS'97, St.-Petersburg, September 2--5,
  1997, Russia. Vol. 1, pp. 117--122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106019</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Playing Games with Algorithms: Algorithmic Combinatorial Game Theory</dc:title>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Hearn, Robert A.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  Combinatorial games lead to several interesting, clean problems in algorithms
and complexity theory, many of which remain open. The purpose of this paper is
to provide an overview of the area to encourage further research. In
particular, we begin with general background in Combinatorial Game Theory,
which analyzes ideal play in perfect-information games, and Constraint Logic,
which provides a framework for showing hardness. Then we survey results about
the complexity of determining ideal play in these games, and the related
problems of solving puzzles, in terms of both polynomial-time algorithms and
computational intractability results. Our review of background and survey of
algorithmic results are by no means complete, but should serve as a useful
primer.
</dc:description>
 <dc:description>Comment: 42 pages, 18 figures. Major revision to survey, and new author. To
  appear in Games of No Chance III</dc:description>
 <dc:date>2001-06-10</dc:date>
 <dc:date>2008-04-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Economic Models for Management of Resources in Grid Computing</dc:title>
 <dc:creator>Buyya, Rajkumar</dc:creator>
 <dc:creator>Stockinger, Heinz</dc:creator>
 <dc:creator>Giddy, Jonathan</dc:creator>
 <dc:creator>Abrams, David</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  The accelerated development in Grid and peer-to-peer computing has positioned
them as promising next generation computing platforms. They enable the creation
of Virtual Enterprises (VE) for sharing resources distributed across the world.
However, resource management, application development and usage models in these
environments is a complex undertaking. This is due to the geographic
distribution of resources that are owned by different organizations. The
resource owners of each of these resources have different usage or access
policies and cost models, and varying loads and availability. In order to
address complex resource management issues, we have proposed a computational
economy framework for resource allocation and for regulating supply and demand
in Grid computing environments. The framework provides mechanisms for
optimizing resource provider and consumer objective functions through trading
and brokering services. In a real world market, there exist various economic
models for setting the price for goods based on supply-and-demand and their
value to the user. They include commodity market, posted price, tenders and
auctions. In this paper, we discuss the use of these models for interaction
between Grid components in deciding resource value and the necessary
infrastructure to realize them. In addition to normal services offered by Grid
computing systems, we need an infrastructure to support interaction protocols,
allocation mechanisms, currency, secure banking, and enforcement services.
Furthermore, we demonstrate the usage of some of these economic models in
resource brokering through Nimrod/G deadline and cost-based scheduling for two
different optimization strategies on the World Wide Grid (WWG) testbed.
</dc:description>
 <dc:description>Comment: Technical Track on Commercial Applications for High-Performance
  Computing, SPIE International Symposium on The Convergence of Information
  Technologies and Communications (ITCom 2001), August 20-24, 2001, Denver,
  Colorado, USA</dc:description>
 <dc:date>2001-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object-oriented solutions</dc:title>
 <dc:creator>Wolfengagen, Viacheslav</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>D.1.1</dc:subject>
 <dc:subject>H.2.1</dc:subject>
 <dc:description>  In this paper are briefly outlined the motivations, mathematical ideas in
use, pre-formalization and assumptions, object-as-functor construction, `soft'
types and concept constructions, case study for concepts based on variable
domains, extracting a computational background, and examples of evaluations.
</dc:description>
 <dc:date>2001-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106021</dc:identifier>
 <dc:identifier>Proceedings of the 2-nd International Workshop on Advances in
  Databases and Information Systems, ADBIS'95, Moscow, June 27 --30, 1995, Vol.
  1, pp. 235--246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One More Revolution to Make: Free Scientific Publishing</dc:title>
 <dc:creator>Apt, Krzysztof R.</dc:creator>
 <dc:subject>Computer Science - General Literature</dc:subject>
 <dc:subject>A.0</dc:subject>
 <dc:description>  Computer scientists are in the position to create new, free high-quality
journals. So what would it take?
</dc:description>
 <dc:description>Comment: Taken from
  http://www.acm.org/pubs/citations/journals/cacm/2001-44-5/p25-apt/ Posted
  with permission of the ACM</dc:description>
 <dc:date>2001-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106022</dc:identifier>
 <dc:identifier>Communications of ACM, 44(5), pp. 25-28</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object-oriented tools for advanced applications</dc:title>
 <dc:creator>Ismailova, Larissa</dc:creator>
 <dc:creator>Zinchenko, Konstantin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  This paper contains a brief discussion of the Application Development
Environment (ADE) that is used to build database applications involving the
graphical user interface (GUI). ADE computing separates the database access and
the user interface. The variety of applications may be generated that
communicate with different and distinct desktop databases. The advanced
techniques allows to involve remote or stored procedures retrieval and call.
</dc:description>
 <dc:date>2001-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106023</dc:identifier>
 <dc:identifier>Proceedings of the 3-rd International Workshop on Advances in
  Databases and Information Systems, ADBIS'96, Moscow, September 10 --13, 1996,
  Vol. 2, pp. 27--31</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Objects and their computational framework</dc:title>
 <dc:creator>Wolfengagen, Viacheslav</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>D.1.1</dc:subject>
 <dc:subject>H.2.1</dc:subject>
 <dc:description>  Most of the object notions are embedded into a logical domain, especially
when dealing with a database theory. Thus, their properties within a
computational domain are not yet studied properly. The main topic of this paper
is to analyze different concepts of the distinct computational primitive frames
to extract the useful object properties and their possible advantages. Some
important metaoperators are used to unify the approaches and to establish their
possible correspondences.
</dc:description>
 <dc:date>2001-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106024</dc:identifier>
 <dc:identifier>Proceedings of the 3-rd International Workshop on Advances in
  Databases and Information Systems, ADBIS'96, Moscow, September 10 --13, 1996,
  Vol. 1, pp. 66--74</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Integration and Computational Logic</dc:title>
 <dc:creator>Dimopoulos, Yannis</dc:creator>
 <dc:creator>Kakas, Antonis</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>H.2.m</dc:subject>
 <dc:subject>I.2.m</dc:subject>
 <dc:description>  Information Integration is a young and exciting field with enormous research
and commercial significance in the new world of the Information Society. It
stands at the crossroad of Databases and Artificial Intelligence requiring
novel techniques that bring together different methods from these fields.
Information from disparate heterogeneous sources often with no a-priori common
schema needs to be synthesized in a flexible, transparent and intelligent way
in order to respond to the demands of a query thus enabling a more informed
decision by the user or application program. The field although relatively
young has already found many practical applications particularly for
integrating information over the World Wide Web. This paper gives a brief
introduction of the field highlighting some of the main current and future
research issues and application areas. It attempts to evaluate the current and
potential role of Computational Logic in this and suggests some of the problems
where logic-based techniques could be used.
</dc:description>
 <dc:description>Comment: 53 Pages</dc:description>
 <dc:date>2001-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Event Driven Computations for Relational Query Language</dc:title>
 <dc:creator>Ismailova, Larissa</dc:creator>
 <dc:creator>Zinchenko, Konstantin</dc:creator>
 <dc:creator>Bourmistrova, Lioubouv</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  This paper deals with an extended model of computations which uses the
parameterized families of entities for data objects and reflects a preliminary
outline of this problem. Some topics are selected out, briefly analyzed and
arranged to cover a general problem. The authors intended more to discuss the
particular topics, their interconnection and computational meaning as a panel
proposal, so that this paper is not yet to be evaluated as a closed journal
paper. To save space all the technical and implementation features are left for
the future paper.
  Data object is a schematic entity and modelled by the partial function. A
notion of type is extended by the variable domains which depend on events and
types. A variable domain is built from the potential and schematic individuals
and generates the valid families of types depending on a sequence of events.
Each valid type consists of the actual individuals which are actual relatively
the event or script. In case when a type depends on the script then
corresponding view for data objects is attached, otherwise a snapshot is
generated. The type thus determined gives an upper range for typed variables so
that the local ranges are event driven resulting is the families of actual
individuals. An expressive power of the query language is extended using the
extensional and intentional relations.
</dc:description>
 <dc:date>2001-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106026</dc:identifier>
 <dc:identifier>Proceedings of the 1-st International Workshop on Computer Science
  and Information Technologies CSIT'99, Moscow, Russia, 1999. Vol.1, pp. 43--52</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Event Driven Objects</dc:title>
 <dc:creator>Wolfengagen, Viacheslav</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>D.1.1</dc:subject>
 <dc:subject>H.2.1</dc:subject>
 <dc:description>  A formal consideration in this paper is given for the essential notations to
characterize the object that is distinguished in a problem domain. The distinct
object is represented by another idealized object, which is a schematic
element. When the existence of an element is significant, then a class of these
partial elements is dropped down into actual, potential and virtual objects.
The potential objects are gathered into the variable domains which are the
extended ranges for unbound variables. The families of actual objects are shown
to be parameterized with the types and events. The transitions between events
are shown to be driven by the scripts. A computational framework arises which
is described by the commutative diagrams.
</dc:description>
 <dc:date>2001-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106027</dc:identifier>
 <dc:identifier>Proceedings of the 1-st International Workshop on Computer Science
  and Information Technologies CSIT'99, Moscow, Russia, 1999. Vol.1, pp. 88--97</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pricing Virtual Paths with Quality-of-Service Guarantees as Bundle
  Derivatives</dc:title>
 <dc:creator>Rasmusson, Lars</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>C.2.3</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:description>  We describe a model of a communication network that allows us to price
complex network services as financial derivative contracts based on the spot
price of the capacity in individual routers. We prove a theorem of a Girsanov
transform that is useful for pricing linear derivatives on underlying assets,
which can be used to price many complex network services, and it is used to
price an option that gives access to one of several virtual channels between
two network nodes, during a specified future time interval. We give the
continuous time hedging strategy, for which the option price is independent of
the service providers attitude towards risk. The option price contains the
density function of a sum of lognormal variables, which has to be evaluated
numerically.
</dc:description>
 <dc:description>Comment: 22 pages (15 in main tex and 7 appendix), 5 postscript figures</dc:description>
 <dc:date>2001-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Views with Description Logics in ADE: Application Development
  Environment</dc:title>
 <dc:creator>Ismailova, Larissa</dc:creator>
 <dc:creator>Kosikov, Sergey</dc:creator>
 <dc:creator>Zinchenko, Konstantin</dc:creator>
 <dc:creator>Mikhaylov, Alexey</dc:creator>
 <dc:creator>Bourmistrova, Lioubouv</dc:creator>
 <dc:creator>Berezovskaya, Anastassiya</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>D.1.1</dc:subject>
 <dc:subject>H.2.1</dc:subject>
 <dc:description>  Any of views is formally defined within description logics that were
established as a family of logics for modeling complex hereditary structures
and have a suitable expressive power. This paper considers the Application
Development Environment (ADE) over generalized variable concepts that are used
to build database applications involving the supporting views. The front-end
user interacts the database via separate ADE access mechanism intermediated by
view support. The variety of applications may be generated that communicate
with different and distinct desktop databases in a data warehouse. The advanced
techniques allows to involve remote or stored procedures retrieval and call.
</dc:description>
 <dc:date>2001-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106029</dc:identifier>
 <dc:identifier>Proceedings of the 2-nd International Workshop on Computer Science
  and Information Technologies CSIT'2000, Ufa, Yangantau, Russia, 2000. Vol.1,
  pp. 153--161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Logic, Individuals and Concepts</dc:title>
 <dc:creator>Wolfengagen, Viacheslav</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>D.1.1</dc:subject>
 <dc:subject>H.2.1</dc:subject>
 <dc:description>  This extended abstract gives a brief outline of the connections between the
descriptions and variable concepts. Thus, the notion of a concept is extended
to include both the syntax and semantics features. The evaluation map in use is
parameterized by a kind of computational environment, the index, giving rise to
indexed concepts. The concepts are inhabited into language by the descriptions
from the higher order logic. In general the idea of object-as-functor should
assist the designer to outline a programming tool in conceptual shell style.
</dc:description>
 <dc:date>2001-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106030</dc:identifier>
 <dc:identifier>Proceedings of the 2-nd International Workshop on Computer Science
  and Information Technologies CSIT'2000, Ufa, Yangantau, Russia, 2000. Vol.1,
  pp. 141--145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complexity Results and Practical Algorithms for Logics in Knowledge
  Representation</dc:title>
 <dc:creator>Tobies, Stephan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Description Logics (DLs) are used in knowledge-based systems to represent and
reason about terminological knowledge of the application domain in a
semantically well-defined manner. In this thesis, we establish a number of
novel complexity results and give practical algorithms for expressive DLs that
provide different forms of counting quantifiers.
  We show that, in many cases, adding local counting in the form of qualifying
number restrictions to DLs does not increase the complexity of the inference
problems, even if binary coding of numbers in the input is assumed. On the
other hand, we show that adding different forms of global counting restrictions
to a logic may increase the complexity of the inference problems dramatically.
  We provide exact complexity results and a practical, tableau based algorithm
for the DL SHIQ, which forms the basis of the highly optimized DL system iFaCT.
  Finally, we describe a tableau algorithm for the clique guarded fragment
(CGF), which we hope will serve as the basis for an efficient implementation of
a CGF reasoner.
</dc:description>
 <dc:description>Comment: Ph.D. Thesis</dc:description>
 <dc:date>2001-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hinged Kite Mirror Dissection</dc:title>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Any two polygons of equal area can be partitioned into congruent sets of
polygonal pieces, and in many cases one can connect the pieces by flexible
hinges while still allowing the connected set to form both polygons. However it
is open whether such a hinged dissection always exists. We solve a special case
of this problem, by showing that any asymmetric polygon always has a hinged
dissection to its mirror image. Our dissection forms a chain of kite-shaped
pieces, found by a circle-packing algorithm for quadrilateral mesh generation.
A hinged mirror dissection of a polygon with n sides can be formed with O(n)
kites in O(n log n) time.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2001-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>location.location.location: Internet Addresses as Evolving Property</dc:title>
 <dc:creator>Yee, Kenton K.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>C.0</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>K.0</dc:subject>
 <dc:subject>K.1</dc:subject>
 <dc:subject>K.4</dc:subject>
 <dc:subject>K.4.4</dc:subject>
 <dc:subject>K.5</dc:subject>
 <dc:subject>K.5.1</dc:subject>
 <dc:subject>K.7.4</dc:subject>
 <dc:description>  I describe recent developments in the rules governing registration and
ownership of Internet and World Wide Web addresses or &quot;domain names.&quot; I
consider the idea that &quot;virtual&quot; properties like domain names are more similar
to real estate than to trademarks. Therefore, it would be economically
efficient to grant domain name owners stronger rights than those of trademarks
and copyright holders.
</dc:description>
 <dc:description>Comment: Related articles and background materials may be obtained from
  http://www.columbia.edu/~kky2001/pubs.html</dc:description>
 <dc:date>2001-06-13</dc:date>
 <dc:date>2005-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106033</dc:identifier>
 <dc:identifier>Southern California Interdisciplinary Law Journal (1998) Volume 6,
  No. 2, pp. 201-243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving equations in the relational algebra</dc:title>
 <dc:creator>Biskup, Joachim</dc:creator>
 <dc:creator>Paredaens, Jan</dc:creator>
 <dc:creator>Schwentick, Thomas</dc:creator>
 <dc:creator>Bussche, Jan Van den</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>F.4.2</dc:subject>
 <dc:subject>H.2.3</dc:subject>
 <dc:description>  Enumerating all solutions of a relational algebra equation is a natural and
powerful operation which, when added as a query language primitive to the
nested relational algebra, yields a query language for nested relational
databases, equivalent to the well-known powerset algebra. We study
\emph{sparse} equations, which are equations with at most polynomially many
solutions. We look at their complexity, and compare their expressive power with
that of similar notions in the powerset algebra.
</dc:description>
 <dc:description>Comment: Minor revision, accepted for publication in SIAM Journal on Computing</dc:description>
 <dc:date>2001-06-14</dc:date>
 <dc:date>2003-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polymorphic type inference for the relational algebra</dc:title>
 <dc:creator>Bussche, Jan Van den</dc:creator>
 <dc:creator>Waller, Emmanuel</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>D.3.3, H.2.3</dc:subject>
 <dc:description>  We give a polymorphic account of the relational algebra. We introduce a
formalism of ``type formulas'' specifically tuned for relational algebra
expressions, and present an algorithm that computes the ``principal'' type for
a given expression. The principal type of an expression is a formula that
specifies, in a clear and concise manner, all assignments of types (sets of
attributes) to relation names, under which a given relational algebra
expression is well-typed, as well as the output type that expression will have
under each of these assignments. Topics discussed include complexity and
polymorphic expressive power.
</dc:description>
 <dc:date>2001-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence and Error Bounds for Universal Prediction of Nonbinary
  Sequences</dc:title>
 <dc:creator>Hutter, Marcus</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>F.2.3</dc:subject>
 <dc:description>  Solomonoff's uncomputable universal prediction scheme $\xi$ allows to predict
the next symbol $x_k$ of a sequence $x_1...x_{k-1}$ for any Turing computable,
but otherwise unknown, probabilistic environment $\mu$. This scheme will be
generalized to arbitrary environmental classes, which, among others, allows the
construction of computable universal prediction schemes $\xi$. Convergence of
$\xi$ to $\mu$ in a conditional mean squared sense and with $\mu$ probability 1
is proven. It is shown that the average number of prediction errors made by the
universal $\xi$ scheme rapidly converges to those made by the best possible
informed $\mu$ scheme. The schemes, theorems and proofs are given for general
finite alphabet, which results in additional complications as compared to the
binary case. Several extensions of the presented theory and results are
outlined. They include general loss functions and bounds, games of chance,
infinite alphabet, partial and delayed prediction, classification, and more
active systems.
</dc:description>
 <dc:description>Comment: 11 LaTeX pages</dc:description>
 <dc:date>2001-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106036</dc:identifier>
 <dc:identifier>Lecture Notes in Artificial Intelligence (LNAI 2167), Proc. 12th
  Eurpean Conf. on Machine Learning (ECML) (2001) 239-250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using the No-Search Easy-Hard Technique for Downward Collapse</dc:title>
 <dc:creator>Hemaspaandra, Edith</dc:creator>
 <dc:creator>Hemaspaandra, Lane A.</dc:creator>
 <dc:creator>Hempel, Harald</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:description>  The top part of the preceding figure [figure appears in actual paper] shows
some classes from the (truth-table) bounded-query and boolean hierarchies. It
is well-known that if either of these hierarchies collapses at a given level,
then all higher levels of that hierarchy collapse to that same level. This is a
standard ``upward translation of equality'' that has been known for over a
decade. The issue of whether these hierarchies can translate equality {\em
downwards\/} has proven vastly more challenging. In particular, with regard to
the figure above, consider the following claim:
  $$P_{m-tt}^{\Sigma_k^p} = P_{m+1-tt}^{\Sigma_k^p} \implies
  DIFF_m(\Sigma_k^p) coDIFF_m(\Sigma_k^p) = BH(\Sigma_k^p). (*) $$
  This claim, if true, says that equality translates downwards between levels
of the bounded-query hierarchy and the boolean hierarchy levels that (before
the fact) are immediately below them.
  Until recently, it was not known whether (*) {\em ever\/} held, except for
the degenerate cases $m=0$ and $k=0$. Then Hemaspaandra, Hemaspaandra, and
Hempel \cite{hem-hem-hem:j:downward-translation} proved that (*) holds for all
$m$, for $k &gt; 2$. Buhrman and Fortnow~\cite{buh-for:j:two-queries} then showed
that, when $k=2$, (*) holds for the case $m = 1$. In this paper, we prove that
for the case $k=2$, (*) holds for all values of $m$. Since there is an oracle
relative to which ``for $k=1$, (*) holds for all $m$'' fails
\cite{buh-for:j:two-queries}, our achievement of the $k=2$ case cannot to be
strengthened to $k=1$ by any relativizable proof technique. The new downward
translation we obtain also tightens the collapse in the polynomial hierarchy
implied by a collapse in the bounded-query hierarchy of the second level of the
polynomial hierarchy.
</dc:description>
 <dc:description>Comment: 22 pages. Also appears as URCS technical report</dc:description>
 <dc:date>2001-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple and Effective Distributed Computing with a Scheduling Service</dc:title>
 <dc:creator>Mackie, David M.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.m</dc:subject>
 <dc:subject>D.m</dc:subject>
 <dc:description>  High-throughput computing projects require the solution of large numbers of
problems. In many cases, these problems can be solved on desktop PCs, or can be
broken down into independent &quot;PC-solvable&quot; sub-problems. In such cases, the
projects are high-performance computing projects, but only because of the sheer
number of the needed calculations. We briefly describe our efforts to increase
the throughput of one such project. We then explain how to easily set up a
distributed computing facility composed of standard networked PCs running
Windows 95, 98, 2000, or NT. The facility requires no special software or
hardware, involves little or no re-coding of application software, and operates
almost invisibly to the owners of the PCs. Depending on the number and quality
of PCs recruited, performance can rival that of supercomputers.
</dc:description>
 <dc:description>Comment: 5 pgs., 5 figs., a step-by-step &quot;how-to&quot; report plus a case study,
  for networked PCs with Windows</dc:description>
 <dc:date>2001-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Residual Rescaling: An Analysis and Generalization of LSI</dc:title>
 <dc:creator>Ando, Rie Kubota</dc:creator>
 <dc:creator>Lee, Lillian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We consider the problem of creating document representations in which
inter-document similarity measurements correspond to semantic similarity. We
first present a novel subspace-based framework for formalizing this task. Using
this framework, we derive a new analysis of Latent Semantic Indexing (LSI),
showing a precise relationship between its performance and the uniformity of
the underlying distribution of documents over topics. This analysis helps
explain the improvements gained by Ando's (2000) Iterative Residual Rescaling
(IRR) algorithm: IRR can compensate for distributional non-uniformity. A
further benefit of our framework is that it provides a well-motivated,
effective method for automatically determining the rescaling factor IRR depends
on, leading to further improvements. A series of experiments over various
settings and with several evaluation metrics validates our claims.
</dc:description>
 <dc:description>Comment: To appear in the proceedings of SIGIR 2001. 11 pages</dc:description>
 <dc:date>2001-06-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106039</dc:identifier>
 <dc:identifier>Proceedings of the 24th SIGIR, pp. 154--162, 2001.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stacking classifiers for anti-spam filtering of e-mail</dc:title>
 <dc:creator>Sakkis, G.</dc:creator>
 <dc:creator>Androutsopoulos, I.</dc:creator>
 <dc:creator>Paliouras, G.</dc:creator>
 <dc:creator>Karkaletsis, V.</dc:creator>
 <dc:creator>Spyropoulos, C. D.</dc:creator>
 <dc:creator>Stamatopoulos, P.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>H.4.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:subject>K.4.1</dc:subject>
 <dc:description>  We evaluate empirically a scheme for combining classifiers, known as stacked
generalization, in the context of anti-spam filtering, a novel cost-sensitive
application of text categorization. Unsolicited commercial e-mail, or &quot;spam&quot;,
floods mailboxes, causing frustration, wasting bandwidth, and exposing minors
to unsuitable content. Using a public corpus, we show that stacking can improve
the efficiency of automatically induced anti-spam filters, and that such
filters can be used in real-life applications.
</dc:description>
 <dc:date>2001-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106040</dc:identifier>
 <dc:identifier>Proceedings of &quot;Empirical Methods in Natural Language Processing&quot;
  (EMNLP 2001), L. Lee and D. Harman (Eds.), pp. 44-50, Carnegie Mellon
  University, Pittsburgh, PA, 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106041</identifier>
 <datestamp>2016-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Complete Graph Isomorphisms and Hamiltonian Cycles from
  Partial Ones</dc:title>
 <dc:creator>Grosse, Andr&#xe9;</dc:creator>
 <dc:creator>Rothe, Joerg</dc:creator>
 <dc:creator>Wechsung, Gerd</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We prove that computing a single pair of vertices that are mapped onto each
other by an isomorphism $\phi$ between two isomorphic graphs is as hard as
computing $\phi$ itself. This result optimally improves upon a result of
G\'{a}l et al. We establish a similar, albeit slightly weaker, result about
computing complete Hamiltonian cycles of a graph from partial Hamiltonian
cycles.
</dc:description>
 <dc:description>Comment: 12 pages, appears as part of a ICTCS 2001 paper of the same authors</dc:description>
 <dc:date>2001-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MACE 2.0 Reference Manual and Guide</dc:title>
 <dc:creator>McCune, William</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  MACE is a program that searches for finite models of first-order statements.
The statement to be modeled is first translated to clauses, then to relational
clauses; finally for the given domain size, the ground instances are
constructed. A Davis-Putnam-Loveland-Logeman procedure decides the
propositional problem, and any models found are translated to first-order
models. MACE is a useful complement to the theorem prover Otter, with Otter
searching for proofs and MACE looking for countermodels.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2001-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using the Distribution of Performance for Studying Statistical NLP
  Systems and Corpora</dc:title>
 <dc:creator>Krymolowski, Yuval</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Statistical NLP systems are frequently evaluated and compared on the basis of
their performances on a single split of training and test data. Results
obtained using a single split are, however, subject to sampling noise. In this
paper we argue in favour of reporting a distribution of performance figures,
obtained by resampling the training data, rather than a single number. The
additional information from distributions can be used to make statistically
quantified statements about differences across parameter settings, systems, and
corpora.
</dc:description>
 <dc:description>Comment: To be presented in ACL/EACL Workshop on Evaluation for Language and
  Dialogue Systems</dc:description>
 <dc:date>2001-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Sequential Model for Multi-Class Classification</dc:title>
 <dc:creator>Even-Zohar, Yair</dc:creator>
 <dc:creator>Roth, Dan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.67</dc:subject>
 <dc:description>  Many classification problems require decisions among a large number of
competing classes. These tasks, however, are not handled well by general
purpose learning methods and are usually addressed in an ad-hoc fashion. We
suggest a general approach -- a sequential learning model that utilizes
classifiers to sequentially restrict the number of competing classes while
maintaining, with high probability, the presence of the true outcome in the
candidates set. Some theoretical and computational properties of the model are
discussed and we argue that these are important in NLP-like domains. The
advantages of the model are illustrated in an experiment in part-of-speech
tagging.
</dc:description>
 <dc:date>2001-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on the Complexity of Computing the Smallest Four-Coloring of
  Planar Graphs</dc:title>
 <dc:creator>Grosse, Andre</dc:creator>
 <dc:creator>Rothe, Joerg</dc:creator>
 <dc:creator>Wechsung, Gerd</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We show that computing the lexicographically first four-coloring for planar
graphs is P^{NP}-hard. This result optimally improves upon a result of Khuller
and Vazirani who prove this problem to be NP-hard, and conclude that it is not
self-reducible in the sense of Schnorr, assuming P \neq NP. We discuss this
application to non-self-reducibility and provide a general related result.
</dc:description>
 <dc:description>Comment: 9 pages, appears in part in an ICTCS 2001 paper by the same authors,
  minor revision of the above</dc:description>
 <dc:date>2001-06-21</dc:date>
 <dc:date>2006-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expressing the cone radius in the relational calculus with real
  polynomial constraints</dc:title>
 <dc:creator>Geerts, Floris</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>H.2.3</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  We show that there is a query expressible in first-order logic over the reals
that returns, on any given semi-algebraic set A, for every point a radius
around which A is conical. We obtain this result by combining famous results
from calculus and real algebraic geometry, notably Sard's theorem and Thom's
first isotopy lemma, with recent algorithmic results by Rannou.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2001-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling informational novelty in a conversational system with a hybrid
  statistical and grammar-based approach to natural language generation</dc:title>
 <dc:creator>Ratnaparkhi, Adwait</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We present a hybrid statistical and grammar-based system for surface natural
language generation (NLG) that uses grammar rules, conditions on using those
grammar rules, and corpus statistics to determine the word order. We also
describe how this surface NLG module is implemented in a prototype
conversational system, and how it attempts to model informational novelty by
varying the word order. Using a combination of rules and statistical
information, the conversational system expresses the novel information
differently than the given information, based on the run-time dialog state. We
also discuss our plans for evaluating the generation strategy.
</dc:description>
 <dc:date>2001-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106047</dc:identifier>
 <dc:identifier>Proceedings of the NAACL Workshop on Adaptation in Dialogue
  Systems, June 4, 2001, Pittsburgh, PA, USA</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106048</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On some optimization problems for star-free graphs</dc:title>
 <dc:creator>Naidenko, V. G.</dc:creator>
 <dc:creator>Orlovich, Yu. L.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>G.1.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  It is shown that in star-free graphs the maximum independent set problem, the
minimum dominating set problem and the minimum independent dominating set
problem are approximable up to constant factor by any maximal independent set.
</dc:description>
 <dc:description>Comment: 6 pages, in Russian</dc:description>
 <dc:date>2001-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106048</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106049</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recursively Undecidable Properties of NP</dc:title>
 <dc:creator>Naidenko, V. G.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.0</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  We show that there cannot be any algorithm that for a given nondeterministic
polynomial-time Turing machine determinates whether or not the language
recognized by this machine belongs to P
</dc:description>
 <dc:description>Comment: 3 pages</dc:description>
 <dc:date>2001-06-25</dc:date>
 <dc:date>2001-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classes of Terminating Logic Programs</dc:title>
 <dc:creator>Pedreschi, Dino</dc:creator>
 <dc:creator>Ruggieri, Salvatore</dc:creator>
 <dc:creator>Smaus, Jan-Georg</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  Termination of logic programs depends critically on the selection rule, i.e.
the rule that determines which atom is selected in each resolution step. In
this article, we classify programs (and queries) according to the selection
rules for which they terminate. This is a survey and unified view on different
approaches in the literature. For each class, we present a sufficient, for most
classes even necessary, criterion for determining that a program is in that
class. We study six classes: a program strongly terminates if it terminates for
all selection rules; a program input terminates if it terminates for selection
rules which only select atoms that are sufficiently instantiated in their input
positions, so that these arguments do not get instantiated any further by the
unification; a program local delay terminates if it terminates for local
selection rules which only select atoms that are bounded w.r.t. an appropriate
level mapping; a program left-terminates if it terminates for the usual
left-to-right selection rule; a program exists-terminates if there exists a
selection rule for which it terminates; finally, a program has bounded
nondeterminism if it only has finitely many refutations. We propose a
semantics-preserving transformation from programs with bounded nondeterminism
into strongly terminating programs. Moreover, by unifying different formalisms
and making appropriate assumptions, we are able to establish a formal hierarchy
between the different classes.
</dc:description>
 <dc:description>Comment: 50 pages. The following mistake was corrected: In figure 5, the first
  clause for insert was insert([],X,[X])</dc:description>
 <dc:date>2001-06-25</dc:date>
 <dc:date>2002-07-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106050</dc:identifier>
 <dc:identifier>Theory and Practice of Logic Programming, 2(3), 369-418, 2002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Users Guide for SnadiOpt: A Package Adding Automatic Differentiation to
  Snopt</dc:title>
 <dc:creator>Gertz, E. Michael</dc:creator>
 <dc:creator>Gill, Philip E.</dc:creator>
 <dc:creator>Muetherig, Julia</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.1.4</dc:subject>
 <dc:description>  SnadiOpt is a package that supports the use of the automatic differentiation
package ADIFOR with the optimization package Snopt. Snopt is a general-purpose
system for solving optimization problems with many variables and constraints.
It minimizes a linear or nonlinear function subject to bounds on the variables
and sparse linear or nonlinear constraints. It is suitable for large-scale
linear and quadratic programming and for linearly constrained optimization, as
well as for general nonlinear programs. The method used by Snopt requires the
first derivatives of the objective and constraint functions to be available.
The SnadiOpt package allows users to avoid the time-consuming and error-prone
process of evaluating and coding these derivatives. Given Fortran code for
evaluating only the values of the objective and constraints, SnadiOpt
automatically generates the code for evaluating the derivatives and builds the
relevant Snopt input files and sparse data structures.
</dc:description>
 <dc:description>Comment: pages i-iv, 1-23</dc:description>
 <dc:date>2001-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Acceptability with general orderings</dc:title>
 <dc:creator>De Schreye, Danny</dc:creator>
 <dc:creator>Serebrenik, Alexander</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  We present a new approach to termination analysis of logic programs. The
essence of the approach is that we make use of general orderings (instead of
level mappings), like it is done in transformational approaches to logic
program termination analysis, but we apply these orderings directly to the
logic program and not to the term-rewrite system obtained through some
transformation. We define some variants of acceptability, based on general
orderings, and show how they are equivalent to LD-termination. We develop a
demand driven, constraint-based approach to verify these
acceptability-variants.
  The advantage of the approach over standard acceptability is that in some
cases, where complex level mappings are needed, fairly simple orderings may be
easily generated. The advantage over transformational approaches is that it
avoids the transformation step all together.
  {\bf Keywords:} termination analysis, acceptability, orderings.
</dc:description>
 <dc:description>Comment: To appear in &quot;Computational Logic: From Logic Programming into the
  Future&quot;</dc:description>
 <dc:date>2001-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inference of termination conditions for numerical loops</dc:title>
 <dc:creator>Serebrenik, Alexander</dc:creator>
 <dc:creator>De Schreye, Danny</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  We present a new approach to termination analysis of numerical computations
in logic programs. Traditional approaches fail to analyse them due to non
well-foundedness of the integers. We present a technique that allows to
overcome these difficulties. Our approach is based on transforming a program in
way that allows integrating and extending techniques originally developed for
analysis of numerical computations in the framework of query-mapping pairs with
the well-known framework of acceptability. Such an integration not only
contributes to the understanding of termination behaviour of numerical
computations, but also allows to perform a correct analysis of such
computations automatically, thus, extending previous work on a
constraints-based approach to termination. In the last section of the paper we
discuss possible extensions of the technique, including incorporating general
term orderings.
</dc:description>
 <dc:description>Comment: Presented at WST2001</dc:description>
 <dc:date>2001-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software Toolkit for Building Embedded and Distributed Knowledge-based
  Systems</dc:title>
 <dc:creator>Soshnikov, Dmitri</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>D.2.12</dc:subject>
 <dc:description>  The paper discusses the basic principles and the architecture of the software
toolkit for constructing knowledge-based systems which can be used
cooperatively over computer networks and also embedded into larger software
systems in different ways. Presented architecture is based on frame knowledge
representation and production rules, which also allows to interface high-level
programming languages and relational databases by exposing corresponding
classes or database tables as frames. Frames located on the remote computers
can also be transparently accessed and used in inference, and the dynamic
knowledge for specific frames can also be transferred over the network. The
issues of implementation of such a system are addressed, which use Java
programming language, CORBA and XML for external knowledge representation.
Finally, some applications of the toolkit are considered, including e-business
approach to knowledge sharing, intelligent web behaviours, etc.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures; check http://www.soshnikov.com for details</dc:description>
 <dc:date>2001-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106054</dc:identifier>
 <dc:identifier>Soshnikov D. Software Toolkit for Building Distributed and
  Embedded Knowledge-Based Systems. In Proceedings of the 2nd International
  Workshop on Computer Science and Information Technologies, Ufa, USATU
  Publishers, 2000. pp. 103--111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Seamless Integration of Association Rule Mining with Database Systems</dc:title>
 <dc:creator>Gopalan, Raj P.</dc:creator>
 <dc:creator>Nuruddin, Tariq</dc:creator>
 <dc:creator>Sucahyo, Yudho Giri</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  The need for Knowledge and Data Discovery Management Systems (KDDMS) that
support ad hoc data mining queries has been long recognized. A significant
amount of research has gone into building tightly coupled systems that
integrate association rule mining with database systems. In this paper, we
describe a seamless integration scheme for database queries and association
rule discovery using a common query optimizer for both. Query trees of
expressions in an extended algebra are used for internal representation in the
optimizer. The algebraic representation is flexible enough to deal with
constrained association rule queries and other variations of association rule
specifications. We propose modularization to simplify the query tree for
complex tasks in data mining. It paves the way for making use of existing
algorithms for constructing query plans in the optimization process. How the
integration scheme we present will facilitate greater user control over the
data mining process is also discussed. The work described in this paper forms
part of a larger project for fully integrating data mining with database
management.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2001-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized Two-Process Wait-Free Test-and-Set</dc:title>
 <dc:creator>Tromp, John</dc:creator>
 <dc:creator>Vitanyi, Paul</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We present the first explicit, and currently simplest, randomized algorithm
for 2-process wait-free test-and-set. It is implemented with two 4-valued
single writer single reader atomic variables. A test-and-set takes at most 11
expected elementary steps, while a reset takes exactly 1 elementary step. Based
on a finite-state analysis, the proofs of correctness and expected length are
compressed into one table.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures, LaTeX source; Submitted</dc:description>
 <dc:date>2001-06-28</dc:date>
 <dc:date>2002-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106057</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exposing and harvesting metadata using the OAI metadata harvesting
  protocol: A tutorial</dc:title>
 <dc:creator>Warner, Simeon</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:description>  In this article I outline the ideas behind the Open Archives Initiative
metadata harvesting protocol (OAIMH), and attempt to clarify some common
misconceptions. I then consider how the OAIMH protocol can be used to expose
and harvest metadata. Perl code examples are given as practical illustration.
</dc:description>
 <dc:description>Comment: 13 pages, 1 figure. Example programs included (download source).
  HEPLW version (HTML) available online at
  http://library.cern.ch/HEPLW/4/papers/3/</dc:description>
 <dc:date>2001-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106057</dc:identifier>
 <dc:identifier>High Energy Physics Libraries Webzine, Issue 4, June 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling the Long-Term Archival of Signed Documents through Time
  Stamping</dc:title>
 <dc:creator>Maniatis, Petros</dc:creator>
 <dc:creator>Giuli, T. J.</dc:creator>
 <dc:creator>Baker, Mary</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:description>  In this paper we describe how to build a trusted reliable distributed service
across administrative domains in a peer-to-peer network. The application we use
to motivate our work is a public key time stamping service called Prokopius.
The service provides a secure, verifiable but distributable stable archive that
maintains time stamped snapshots of public keys over time. This in turn allows
clients to verify time stamped documents or certificates that rely on formerly
trusted public keys that are no longer in service or where the signer no longer
exists. We find that such a service can time stamp the snapshots of public keys
in a network of 148 nodes at the granularity of a couple of days, even in the
worst case where an adversary causes the maximal amount of damage allowable
within our fault model.
</dc:description>
 <dc:description>Comment: 25 pages, 10 figures, unpublished</dc:description>
 <dc:date>2001-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0106059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CHR as grammar formalism. A first report</dc:title>
 <dc:creator>Christiansen, Henning</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.4.2</dc:subject>
 <dc:description>  Grammars written as Constraint Handling Rules (CHR) can be executed as
efficient and robust bottom-up parsers that provide a straightforward,
non-backtracking treatment of ambiguity. Abduction with integrity constraints
as well as other dynamic hypothesis generation techniques fit naturally into
such grammars and are exemplified for anaphora resolution, coordination and
text interpretation.
</dc:description>
 <dc:description>Comment: 12 pages. Presented at ERCIM Workshop on Constraints, Prague, Czech
  Republic, June 18-20, 2001</dc:description>
 <dc:date>2001-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0106059</dc:identifier>
 <dc:identifier>Proc. of ERCIM Workshop on Constraints, Prague, Czech Republic,
  June 18-20, 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Network Traffic in Switched Ethernet Systems</dc:title>
 <dc:creator>Field, Tony</dc:creator>
 <dc:creator>Harder, Uli</dc:creator>
 <dc:creator>Harrison, Peter</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.5</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:subject>D.2.8</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  A 100 Mbps Ethernet link between a college campus and the outside world was
monitored with a dedicated PC and the measured data analysed for its
statistical properties. Similar measurements were taken at an internal node of
the network. The networks in both cases are a full-duplex switched Ethernet.
Inter-event interval histograms and power spectra of the throughput aggregated
for 10ms bins were used to analyse the measured traffic. For most investigated
cases both methods reveal that the traffic behaves according to a power law.
The results will be used in later studies to parameterise models for network
traffic.
</dc:description>
 <dc:description>Comment: 12 pages, 14 figures, using infocom.cls (included) and graphicx (not
  included); all power spectrum plots replaced with new ones; minor typos in
  figure captions corrected</dc:description>
 <dc:date>2001-07-02</dc:date>
 <dc:date>2001-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing Constraint Propagation with Composition Operators</dc:title>
 <dc:creator>Granvilliers, Laurent</dc:creator>
 <dc:creator>Monfroy, Eric</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  Constraint propagation is a general algorithmic approach for pruning the
search space of a CSP. In a uniform way, K. R. Apt has defined a computation as
an iteration of reduction functions over a domain. He has also demonstrated the
need for integrating static properties of reduction functions (commutativity
and semi-commutativity) to design specialized algorithms such as AC3 and DAC.
We introduce here a set of operators for modeling compositions of reduction
functions. Two of the major goals are to tackle parallel computations, and
dynamic behaviours (such as slow convergence).
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2001-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower Bounds for Zero-knowledge on the Internet</dc:title>
 <dc:creator>Kilian, Joe</dc:creator>
 <dc:creator>Petrank, Erez</dc:creator>
 <dc:creator>Rackoff, Charles</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:description>  We consider zero knowledge interactive proofs in a richer, more realistic
communication environment. In this setting, one may simultaneously engage in
many interactive proofs, and these proofs may take place in an asynchronous
fashion. It is known that zero-knowledge is not necessarily preserved in such
an environment; we show that for a large class of protocols, it cannot be
preserved. Any 4 round (computational) zero-knowledge interactive proof (or
argument) for a non-trivial language L is not black-box simulatable in the
asynchronous setting.
</dc:description>
 <dc:date>2001-07-02</dc:date>
 <dc:date>2001-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Concurrent and Resettable Zero-Knowledge Proofs for NP</dc:title>
 <dc:creator>Kilian, Joe</dc:creator>
 <dc:creator>Petrank, Erez</dc:creator>
 <dc:creator>Richardson, Ransom</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:description>  A proof is concurrent zero-knowledge if it remains zero-knowledge when many
copies of the proof are run in an asynchronous environment, such as the
Internet. It is known that zero-knowledge is not necessarily preserved in such
an environment. Designing concurrent zero-knowledge proofs is a fundamental
issue in the study of zero-knowledge since known zero-knowledge protocols
cannot be run in a realistic modern computing environment. In this paper we
present a concurrent zero-knowledge proof systems for all languages in NP.
Currently, the proof system we present is the only known proof system that
retains the zero-knowledge property when copies of the proof are allowed to run
in an asynchronous environment. Our proof system has $\tilde{O}(\log^2 k)$
rounds (for a security parameter $k$), which is almost optimal, as it is shown
by Canetti Kilian Petrank and Rosen that black-box concurrent zero-knowledge
requires $\tilde{\Omega}(\log k)$ rounds.
  Canetti, Goldreich, Goldwasser and Micali introduced the notion of {\em
resettable} zero-knowledge, and modified an earlier version of our proof system
to obtain the first resettable zero-knowledge proof system. This protocol
requires $k^{\theta(1)}$ rounds. We note that their technique also applies to
our current proof system, yielding a resettable zero-knowledge proof for NP
with $\tilde{O}(\log^2 k)$ rounds.
</dc:description>
 <dc:description>Comment: This paper is a join of two works. The preliminary versions of these
  works appeared in the Proceeedings of Advances in Cryptology - EUROCRYPT
  '99}, May 1999, Lecture Notes in Computer Science Vol. 1592 Springer 1999,
  pp. 415-431, and in the Proceedings of the thirty third annual ACM Symposium
  on Theory of Computing, ACM Press, 2001</dc:description>
 <dc:date>2001-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Role of Conceptual Relations in Word Sense Disambiguation</dc:title>
 <dc:creator>Fernandez-Amoros, David</dc:creator>
 <dc:creator>Gonzalo, Julio</dc:creator>
 <dc:creator>Verdejo, Felisa</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We explore many ways of using conceptual distance measures in Word Sense
Disambiguation, starting with the Agirre-Rigau conceptual density measure. We
use a generalized form of this measure, introducing many (parameterized)
refinements and performing an exhaustive evaluation of all meaningful
combinations. We finally obtain a 42% improvement over the original algorithm,
and show that measures of conceptual distance are not worse indicators for
sense disambiguation than measures based on word-coocurrence (exemplified by
the Lesk algorithm). Our results, however, reinforce the idea that only a
combination of different sources of knowledge might eventually lead to accurate
word sense disambiguation.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figures, published in the proceedings of NLDB'01</dc:description>
 <dc:date>2001-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Looking Under the Hood : Tools for Diagnosing your Question Answering
  Engine</dc:title>
 <dc:creator>Breck, Eric</dc:creator>
 <dc:creator>Light, Marc</dc:creator>
 <dc:creator>Mann, Gideon S.</dc:creator>
 <dc:creator>Riloff, Ellen</dc:creator>
 <dc:creator>Anand, Brianne Brown Pranav</dc:creator>
 <dc:creator>Rooth, Mats</dc:creator>
 <dc:creator>Thelen, Michael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  In this paper we analyze two question answering tasks : the TREC-8 question
answering task and a set of reading comprehension exams. First, we show that
Q/A systems perform better when there are multiple answer opportunities per
question. Next, we analyze common approaches to two subproblems: term overlap
for answer sentence identification, and answer typing for short answer
extraction. We present general tools for analyzing the strengths and
limitations of techniques for these subproblems. Our results quantify the
limitations of both term overlap and answer typing to distinguish between
competing answer candidates.
</dc:description>
 <dc:description>Comment: Revision of paper appearing in the Proceedings of the Workshop on
  Open-Domain Question Answering</dc:description>
 <dc:date>2001-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Risk Profile Problem for Stock Portfolio Optimization</dc:title>
 <dc:creator>Kao, Ming-Yang</dc:creator>
 <dc:creator>Nolte, Andreas</dc:creator>
 <dc:creator>Tate, Stephen R.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>E1</dc:subject>
 <dc:subject>F2</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.1.10</dc:subject>
 <dc:subject>G.2</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  This work initiates research into the problem of determining an optimal
investment strategy for investors with different attitudes towards the
trade-offs of risk and profit. The probability distribution of the return
values of the stocks that are considered by the investor are assumed to be
known, while the joint distribution is unknown. The problem is to find the best
investment strategy in order to minimize the probability of losing a certain
percentage of the invested capital based on different attitudes of the
investors towards future outcomes of the stock market.
  For portfolios made up of two stocks, this work shows how to exactly and
quickly solve the problem of finding an optimal portfolio for aggressive or
risk-averse investors, using an algorithm based on a fast greedy solution to a
maximum flow problem. However, an investor looking for an average-case
guarantee (so is neither aggressive or risk-averse) must deal with a more
difficult problem. In particular, it is #P-complete to compute the distribution
function associated with the average-case bound. On the positive side,
approximate answers can be computed by using random sampling techniques similar
to those for high-dimensional volume estimation. When k&gt;2 stocks are
considered, it is proved that a simple solution based on the same flow concepts
as the 2-stock algorithm would imply that P = NP, so is highly unlikely. This
work gives approximation algorithms for this case as well as exact algorithms
for some important special cases.
</dc:description>
 <dc:description>Comment: A preliminary version of this work appeared in Proceedings of the
  32nd Annual ACM Symposium on Theory of Computing, pages 228--234, 2000. The
  final version will appear in E. J. Kontoghiorghes, B. Rustem, and S. Siokos,
  editors, Applied Optimization: Computational Methods in Decision-Making,
  Economics and Finance. Kluwer Academic Publishers, Dordrecht, 2002</dc:description>
 <dc:date>2001-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107008</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complex Tilings</dc:title>
 <dc:creator>Durand, Bruno</dc:creator>
 <dc:creator>Levin, Leonid A.</dc:creator>
 <dc:creator>Shen, Alexander</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  We study the minimal complexity of tilings of a plane with a given tile set.
We note that every tile set admits either no tiling or some tiling with O(n)
Kolmogorov complexity of its n-by-n squares. We construct tile sets for which
this bound is tight: all n-by-n squares in all tilings have complexity at least
n. This adds a quantitative angle to classical results on non-recursivity of
tilings -- that we also develop in terms of Turing degrees of unsolvability.
  Keywords: Tilings, Kolmogorov complexity, recursion theory
</dc:description>
 <dc:description>Comment: An extended abstract of a weaker version of this article appeared in
  Proceedings of the Annual ACM Symposium on Theory of Computing (STOC), 2001</dc:description>
 <dc:date>2001-07-04</dc:date>
 <dc:date>2007-09-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107008</dc:identifier>
 <dc:identifier>Journal of Symbolic Logic 73(2):593-613, 2008</dc:identifier>
 <dc:identifier>doi:10.2178/jsl/1208359062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Blueprint for Building Serverless Applications on the Net</dc:title>
 <dc:creator>Khan, A. I.</dc:creator>
 <dc:creator>Spindler, R.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>C.1.4</dc:subject>
 <dc:subject>D.2.11</dc:subject>
 <dc:description>  A peer-to-peer application architecture is proposed that has the potential to
eliminate the back-end servers for hosting services on the Internet. The
proposed application architecture has been modeled as a distributed system for
delivering an Internet service. The service thus created, though chaotic and
fraught with uncertainties, would be highly scalable and capable of achieving
unprecedented levels of robustness and viability with the increase in the
number of the users. The core issues relating to the architecture, such as
service discovery, distributed application architecture components, and
inter-application communications, have been analysed. It is shown that the
communications for the coordination of various functions, among the cooperating
instances of the application, may be optimised using a divide-and-conquer
strategy. Finally, the areas where future work needs to be directed have been
identified.
</dc:description>
 <dc:description>Comment: 23 pages, 9 Figures</dc:description>
 <dc:date>2001-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for Boolean Function Query Properties</dc:title>
 <dc:creator>Aaronson, Scott</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We present new algorithms to compute fundamental properties of a Boolean
function given in truth-table form. Specifically, we give an O(N^2.322 log N)
algorithm for block sensitivity, an O(N^1.585 log N) algorithm for `tree
decomposition,' and an O(N) algorithm for `quasisymmetry.' These algorithms are
based on new insights into the structure of Boolean functions that may be of
independent interest. We also give a subexponential-time algorithm for the
space-bounded quantum query complexity of a Boolean function. To prove this
algorithm correct, we develop a theory of limited-precision representation of
unitary operators, building on work of Bernstein and Vazirani.
</dc:description>
 <dc:description>Comment: 13 pages, no figures, earlier version submitted to SIAM J. Comp</dc:description>
 <dc:date>2001-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Broadcast in Wireless Networks with Unknown Topology</dc:title>
 <dc:creator>Clementi, Andrea E. F.</dc:creator>
 <dc:creator>Monti, Angelo</dc:creator>
 <dc:creator>Silvestri, Riccardo</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  A multi-hop synchronous wirelss network is said to be unknown if the nodes
have no knowledge of the topology. A basic task in wireless network is that of
broadcasting a message (created by a fixed source node) to all nodes of the
network. The multi-broadcast that consists in performing a set of r independent
broadcasts. In this paper, we study the completion and the termination time of
distributed protocols for both the (single) broadcast and the multi-broadcast
operations on unknown networks as functions of the number of nodes n, the
maximum eccentricity D, the maximum in-degree Delta, and the congestion c of
the networks. We establish new connections between these operations and some
combinatorial concepts, such as selective families, strongly-selective families
(also known as superimposed codes), and pairwise r-different families. Such
connections, combined with a set of new lower and upper bounds on the size of
the above families, allow us to derive new lower bounds and new distributed
protocols for the broadcast and multi-broadcast operations. In particular, our
upper bounds are almost tight and improve exponentially over the previous
bounds when D and Delta are polylogarithmic in n. Network topologies having
``small'' eccentricity and ``small'' degree (such as bounded-degree expanders)
are often used in practice to achieve efficient communication.
</dc:description>
 <dc:description>Comment: 27 pages, 1 figure, 1 table</dc:description>
 <dc:date>2001-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Three-Stage Quantitative Neural Network Model of the Tip-of-the-Tongue
  Phenomenon</dc:title>
 <dc:creator>Gopych, Petro M.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  A new three-stage computer artificial neural network model of the
tip-of-the-tongue phenomenon is shortly described, and its stochastic nature
was demonstrated. A way to calculate strength and appearance probability of
tip-of-the-tongue states, neural network mechanism of feeling-of-knowing
phenomenon are proposed. The model synthesizes memory, psycholinguistic, and
metamemory approaches, bridges speech errors and naming chronometry research
traditions. A model analysis of a tip-of-the-tongue case from Anton Chekhov's
short story 'A Horsey Name' is performed. A new 'throw-up-one's-arms effect' is
defined.
</dc:description>
 <dc:description>Comment: Proceedings of the IX-th International Conference
  Knowledge-Dialog-Solution (KDS-2001), held on June 19-22, 2001 in
  St-Petersburg, Russia, pages 158-165 (in Russian)</dc:description>
 <dc:date>2001-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107012</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Logic Programming Paradigm and Prolog</dc:title>
 <dc:creator>Apt, Krzysztof R.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:description>  This is a tutorial on logic programming and Prolog appropriate for a course
on programming languages for students familiar with imperative programming.
</dc:description>
 <dc:description>Comment: 37 pages; unpublished</dc:description>
 <dc:date>2001-07-10</dc:date>
 <dc:date>2001-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transformations of CCP programs</dc:title>
 <dc:creator>Etalle, Sandro</dc:creator>
 <dc:creator>Gabbrielli, Maurizio</dc:creator>
 <dc:creator>Meo, Maria Chiara</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:description>  We introduce a transformation system for concurrent constraint programming
(CCP). We define suitable applicability conditions for the transformations
which guarantee that the input/output CCP semantics is preserved also when
distinguishing deadlocked computations from successful ones and when
considering intermediate results of (possibly) non-terminating computations.
  The system allows us to optimize CCP programs while preserving their intended
meaning: In addition to the usual benefits that one has for sequential
declarative languages, the transformation of concurrent programs can also lead
to the elimination of communication channels and of synchronization points, to
the transformation of non-deterministic computations into deterministic ones,
and to the crucial saving of computational space. Furthermore, since the
transformation system preserves the deadlock behavior of programs, it can be
used for proving deadlock freeness of a given program wrt a class of queries.
To this aim it is sometimes sufficient to apply our transformations and to
specialize the resulting program wrt the given queries in such a way that the
obtained program is trivially deadlock free.
</dc:description>
 <dc:description>Comment: To appear in ACM TOPLAS</dc:description>
 <dc:date>2001-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Neel to NPC: Colouring Small Worlds</dc:title>
 <dc:creator>Svenson, Pontus</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>F.2.m</dc:subject>
 <dc:description>  In this note, we present results for the colouring problem on small world
graphs created by rewiring square, triangular, and two kinds of cubic (with
coordination numbers 5 and 6) lattices. As the rewiring parameter p tends to 1,
we find the expected crossover to the behaviour of random graphs with
corresponding connectivity. However, for the cubic lattices there is a region
near p=0 for which the graphs are colourable. This could in principle be used
as an additional heuristic for solving real world colouring or scheduling
problems. Small worlds with connectivity 5 and p ~ 0.1 provide an interesting
ensemble of graphs whose colourability is hard to determine. For square
lattices, we get good data collapse plotting the fraction of colourable graphs
against the rescaled parameter parameter $p N^{-\nu}$ with $\nu = 1.35$. No
such collapse can be obtained for the data from lattices with coordination
number 5 or 6.
</dc:description>
 <dc:description>Comment: 4 pages, 6 figures</dc:description>
 <dc:date>2001-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introduction to the CoNLL-2001 Shared Task: Clause Identification</dc:title>
 <dc:creator>Sang, Erik F. Tjong Kim</dc:creator>
 <dc:creator>Dejean, Herve</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We describe the CoNLL-2001 shared task: dividing text into clauses. We give
background information on the data sets, present a general overview of the
systems that have taken part in the shared task and briefly discuss their
performance.
</dc:description>
 <dc:date>2001-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107016</dc:identifier>
 <dc:identifier>In: Walter Daelemans and Remi Zajac (eds.), Proceedings of
  CoNLL-2001, Toulouse, France, 2001, pp. 53-57</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Computational Grammars</dc:title>
 <dc:creator>Nerbonne, John</dc:creator>
 <dc:creator>Belz, Anja</dc:creator>
 <dc:creator>Cancedda, Nicola</dc:creator>
 <dc:creator>Dejean, Herve</dc:creator>
 <dc:creator>Hammerton, James</dc:creator>
 <dc:creator>Koeling, Rob</dc:creator>
 <dc:creator>Konstantopoulos, Stasinos</dc:creator>
 <dc:creator>Osborne, Miles</dc:creator>
 <dc:creator>Thollard, Franck</dc:creator>
 <dc:creator>Sang, Erik F. Tjong Kim</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper reports on the &quot;Learning Computational Grammars&quot; (LCG) project, a
postdoc network devoted to studying the application of machine learning
techniques to grammars suitable for computational use. We were interested in a
more systematic survey to understand the relevance of many factors to the
success of learning, esp. the availability of annotated data, the kind of
dependencies in the data, and the availability of knowledge bases (grammars).
We focused on syntax, esp. noun phrase (NP) syntax.
</dc:description>
 <dc:date>2001-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107017</dc:identifier>
 <dc:identifier>In: Walter Daelemans and Remi Zajac (eds.), Proceedings of
  CoNLL-2001, Toulouse, France, 2001, pp. 97-104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining a self-organising map with memory-based learning</dc:title>
 <dc:creator>Hammerton, James</dc:creator>
 <dc:creator>Sang, Erik F. Tjong Kim</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Memory-based learning (MBL) has enjoyed considerable success in corpus-based
natural language processing (NLP) tasks and is thus a reliable method of
getting a high-level of performance when building corpus-based NLP systems.
However there is a bottleneck in MBL whereby any novel testing item has to be
compared against all the training items in memory base. For this reason there
has been some interest in various forms of memory editing whereby some method
of selecting a subset of the memory base is employed to reduce the number of
comparisons. This paper investigates the use of a modified self-organising map
(SOM) to select a subset of the memory items for comparison. This method
involves reducing the number of comparisons to a value proportional to the
square root of the number of training items. The method is tested on the
identification of base noun-phrases in the Wall Street Journal corpus, using
sections 15 to 18 for training and section 20 for testing.
</dc:description>
 <dc:date>2001-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107018</dc:identifier>
 <dc:identifier>In: Walter Daelemans and Remi Zajac (eds.), Proceedings of
  CoNLL-2001, Toulouse, France, 2001, pp. 9-14</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Natural Language Generation to Indicative Summarization</dc:title>
 <dc:creator>Kan, Min-Yen</dc:creator>
 <dc:creator>McKeown, Kathleen R.</dc:creator>
 <dc:creator>Klavans, Judith L.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The task of creating indicative summaries that help a searcher decide whether
to read a particular document is a difficult task. This paper examines the
indicative summarization task from a generation perspective, by first analyzing
its required content via published guidelines and corpus analysis. We show how
these summaries can be factored into a set of document features, and how an
implemented content planner uses the topicality document feature to create
indicative multidocument query-based summaries.
</dc:description>
 <dc:description>Comment: 8 pages, published in Proc. of 8th European Workshop on NLG</dc:description>
 <dc:date>2001-07-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transformation-Based Learning in the Fast Lane</dc:title>
 <dc:creator>Ngai, Grace</dc:creator>
 <dc:creator>Florian, Radu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Transformation-based learning has been successfully employed to solve many
natural language processing problems. It achieves state-of-the-art performance
on many natural language processing tasks and does not overtrain easily.
However, it does have a serious drawback: the training time is often
intorelably long, especially on the large corpora which are often used in NLP.
In this paper, we present a novel and realistic method for speeding up the
training time of a transformation-based learner without sacrificing
performance. The paper compares and contrasts the training time needed and
performance achieved by our modified learner with two other systems: a standard
transformation-based learner, and the ICA system \cite{hepple00:tbl}. The
results of these experiments show that our system is able to achieve a
significant improvement in training time while still achieving the same
performance as a standard transformation-based learner. This is a valuable
contribution to systems and algorithms which utilize transformation-based
learning at any part of the execution.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, presented at NAACL 2001</dc:description>
 <dc:date>2001-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107020</dc:identifier>
 <dc:identifier>Proceedings of the Second Conference of the North American Chapter
  of the Association for Computational Linguistics, pages 40-47, Pittsburgh,
  PA, USA</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multidimensional Transformation-Based Learning</dc:title>
 <dc:creator>Florian, Radu</dc:creator>
 <dc:creator>Ngai, Grace</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper presents a novel method that allows a machine learning algorithm
following the transformation-based learning paradigm \cite{brill95:tagging} to
be applied to multiple classification tasks by training jointly and
simultaneously on all fields. The motivation for constructing such a system
stems from the observation that many tasks in natural language processing are
naturally composed of multiple subtasks which need to be resolved
simultaneously; also tasks usually learned in isolation can possibly benefit
from being learned in a joint framework, as the signals for the extra tasks
usually constitute inductive bias.
  The proposed algorithm is evaluated in two experiments: in one, the system is
used to jointly predict the part-of-speech and text chunks/baseNP chunks of an
English corpus; and in the second it is used to learn the joint prediction of
word segment boundaries and part-of-speech tagging for Chinese. The results
show that the simultaneous learning of multiple tasks does achieve an
improvement in each task upon training the same tasks sequentially. The
part-of-speech tagging result of 96.63% is state-of-the-art for individual
systems on the particular train/test split.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, presented at CONLL 2001</dc:description>
 <dc:date>2001-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107021</dc:identifier>
 <dc:identifier>Proceedings of the 5th Computational Natural Language Learning
  Workshop (CoNNL-2001), pages 1-8, Toulouse, France</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An interactive semantics of logic programming</dc:title>
 <dc:creator>Bruni, Roberto</dc:creator>
 <dc:creator>Montanari, Ugo</dc:creator>
 <dc:creator>Rossi, Francesca</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  We apply to logic programming some recently emerging ideas from the field of
reduction-based communicating systems, with the aim of giving evidence of the
hidden interactions and the coordination mechanisms that rule the operational
machinery of such a programming paradigm. The semantic framework we have chosen
for presenting our results is tile logic, which has the advantage of allowing a
uniform treatment of goals and observations and of applying abstract
categorical tools for proving the results. As main contributions, we mention
the finitary presentation of abstract unification, and a concurrent and
coordinated abstract semantics consistent with the most common semantics of
logic programming. Moreover, the compositionality of the tile semantics is
guaranteed by standard results, as it reduces to check that the tile systems
associated to logic programs enjoy the tile decomposition property. An
extension of the approach for handling constraint systems is also discussed.
</dc:description>
 <dc:description>Comment: 42 pages, 24 figure, 3 tables, to appear in the CUP journal of Theory
  and Practice of Logic Programming</dc:description>
 <dc:date>2001-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107023</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vertex-Unfoldings of Simplicial Polyhedra</dc:title>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:creator>Erickson, Jeff</dc:creator>
 <dc:creator>Hart, George W.</dc:creator>
 <dc:creator>O'Rourke, Joseph</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We present two algorithms for unfolding the surface of any polyhedron, all of
whose faces are triangles, to a nonoverlapping, connected planar layout. The
surface is cut only along polyhedron edges. The layout is connected, but it may
have a disconnected interior: the triangles are connected at vertices, but not
necessarily joined along edges.
</dc:description>
 <dc:description>Comment: 10 pages; 7 figures; 8 references</dc:description>
 <dc:date>2001-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107023</dc:identifier>
 <dc:identifier>Discrete Geometry: In honor of W. Kuperberg's 60th birthday, Pure
  and Appl. Math. 253, Marcel Dekker, pp. 215-228, 2003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enumerating Foldings and Unfoldings between Polygons and Polytopes</dc:title>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Demaine, Martin L.</dc:creator>
 <dc:creator>Lubiw, Anna</dc:creator>
 <dc:creator>O'Rourke, Joseph</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  We pose and answer several questions concerning the number of ways to fold a
polygon to a polytope, and how many polytopes can be obtained from one polygon;
and the analogous questions for unfolding polytopes to polygons. Our answers
are, roughly: exponentially many, or nondenumerably infinite.
</dc:description>
 <dc:description>Comment: 12 pages; 10 figures; 10 references. Revision of version in
  Proceedings of the Japan Conference on Discrete and Computational Geometry,
  Tokyo, Nov. 2000, pp. 9-12. See also cs.CG/0007019</dc:description>
 <dc:date>2001-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107024</dc:identifier>
 <dc:identifier>Graphs and Combinatorics 18(1) 93-104 (2002)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer validated proofs of a toolset for adaptable arithmetic</dc:title>
 <dc:creator>Boldo, Sylvie</dc:creator>
 <dc:creator>Daumas, Marc</dc:creator>
 <dc:creator>Moreau-Finot, Claire</dc:creator>
 <dc:creator>Thery, Laurent</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  Most existing implementations of multiple precision arithmetic demand that
the user sets the precision {\em a priori}. Some libraries are said adaptable
in the sense that they dynamically change the precision of each intermediate
operation individually to deliver the target accuracy according to the actual
inputs. We present in this text a new adaptable numeric core inspired both from
floating point expansions and from on-line arithmetic.
  The numeric core is cut down to four tools. The tool that contains arithmetic
operations is proved to be correct. The proofs have been formally checked by
the Coq assistant. Developing the proofs, we have formally proved many results
published in the literature and we have extended a few of them. This work may
let users (i) develop application specific adaptable libraries based on the
toolset and / or (ii) write new formal proofs based on the set of validated
facts.
</dc:description>
 <dc:description>Comment: 21 pages, web links</dc:description>
 <dc:date>2001-07-19</dc:date>
 <dc:date>2001-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Annotated revision programs</dc:title>
 <dc:creator>Marek, Victor</dc:creator>
 <dc:creator>Pivkina, Inna</dc:creator>
 <dc:creator>Truszczynski, Miroslaw</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  Revision programming is a formalism to describe and enforce updates of belief
sets and databases. That formalism was extended by Fitting who assigned
annotations to revision atoms. Annotations provide a way to quantify the
confidence (probability) that a revision atom holds. The main goal of our paper
is to reexamine the work of Fitting, argue that his semantics does not always
provide results consistent with intuition, and to propose an alternative
treatment of annotated revision programs. Our approach differs from that
proposed by Fitting in two key aspects: we change the notion of a model of a
program and we change the notion of a justified revision. We show that under
this new approach fundamental properties of justified revisions of standard
revision programs extend to the annotated case.
</dc:description>
 <dc:description>Comment: 30 pages, to appear in Artificial Intelligence Journal</dc:description>
 <dc:date>2001-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107026</dc:identifier>
 <dc:identifier>Artificial Intelligence Journal, 138 (2002), pp. 149-180.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fixed-parameter complexity of semantics for logic programs</dc:title>
 <dc:creator>Lonc, Zbigniew</dc:creator>
 <dc:creator>Truszczynski, Miroslaw</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:description>  A decision problem is called parameterized if its input is a pair of strings.
One of these strings is referred to as a parameter. The problem: given a
propositional logic program P and a non-negative integer k, decide whether P
has a stable model of size no more than k, is an example of a parameterized
decision problem with k serving as a parameter. Parameterized problems that are
NP-complete often become solvable in polynomial time if the parameter is fixed.
The problem to decide whether a program P has a stable model of size no more
than k, where k is fixed and not a part of input, can be solved in time
O(mn^k), where m is the size of P and n is the number of atoms in P. Thus, this
problem is in the class P. However, algorithms with the running time given by a
polynomial of order k are not satisfactory even for relatively small values of
k.
  The key question then is whether significantly better algorithms (with the
degree of the polynomial not dependent on k) exist. To tackle it, we use the
framework of fixed-parameter complexity. We establish the fixed-parameter
complexity for several parameterized decision problems involving models,
supported models and stable models of logic programs. We also establish the
fixed-parameter complexity for variants of these problems resulting from
restricting attention to Horn programs and to purely negative programs. Most of
the problems considered in the paper have high fixed-parameter complexity.
Thus, it is unlikely that fixing bounds on models (supported models, stable
models) will lead to fast algorithms to decide the existence of such models.
</dc:description>
 <dc:description>Comment: Submission to ACM TOCL; full version of the paper published in the
  Proceedings of ICLP 2001 (Springer Verlag)</dc:description>
 <dc:date>2001-07-19</dc:date>
 <dc:date>2001-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107027</dc:identifier>
 <dc:identifier>ACM Transactions on Computational Logic, 4 (2003), pp. 91-119.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Propositional satisfiability in answer-set programming</dc:title>
 <dc:creator>East, Deborah</dc:creator>
 <dc:creator>Truszczynski, Miroslaw</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  We show that propositional logic and its extensions can support answer-set
programming in the same way stable logic programming and disjunctive logic
programming do. To this end, we introduce a logic based on the logic of
propositional schemata and on a version of the Closed World Assumption. We call
it the extended logic of propositional schemata with CWA (PS+, in symbols). An
important feature of this logic is that it supports explicit modeling of
constraints on cardinalities of sets. In the paper, we characterize the class
of problems that can be solved by finite PS+ theories. We implement a
programming system based on the logic PS+ and design and implement a solver for
processing theories in PS+. We present encouraging performance results for our
approach --- we show it to be competitive with smodels, a state-of-the-art
answer-set programming system based on stable logic programming.
</dc:description>
 <dc:description>Comment: 15 pages, Proceedings of KI 2001 (Springer Verlag)</dc:description>
 <dc:date>2001-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>aspps --- an implementation of answer-set programming with propositional
  schemata</dc:title>
 <dc:creator>Truszczynski, Deborah East. Miroslaw</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>D.I.6</dc:subject>
 <dc:description>  We present an implementation of an answer-set programming paradigm, called
aspps (short for answer-set programming with propositional schemata). The
system aspps is designed to process PS+ theories. It consists of two basic
modules. The first module, psgrnd, grounds an PS+ theory. The second module,
referred to as aspps, is a solver. It computes models of ground PS+ theories.
</dc:description>
 <dc:description>Comment: 4 pages; Proceedings of LPNMR 2001 (Springer Verlag)</dc:description>
 <dc:date>2001-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconciliation of a Quantum-Distributed Gaussian Key</dc:title>
 <dc:creator>Van Assche, G.</dc:creator>
 <dc:creator>Cardinal, J.</dc:creator>
 <dc:creator>Cerf, N. J.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>E.3</dc:subject>
 <dc:description>  Two parties, Alice and Bob, wish to distill a binary secret key out of a list
of correlated variables that they share after running a quantum key
distribution protocol based on continuous-spectrum quantum carriers. We present
a novel construction that allows the legitimate parties to get equal bit
strings out of correlated variables by using a classical channel, with as few
leaked information as possible. This opens the way to securely correcting
non-binary key elements. In particular, the construction is refined to the case
of Gaussian variables as it applies directly to recent continuous-variable
protocols for quantum key distribution.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures. Submitted to the IEEE for possible publication.
  Revised version to improve its clarity</dc:description>
 <dc:date>2001-07-20</dc:date>
 <dc:date>2002-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107030</dc:identifier>
 <dc:identifier>IEEE Trans. Inform. Theory, vol. 50, p. 394, Feb. 2004</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2003.822618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity of Clickomania</dc:title>
 <dc:creator>Biedl, Therese C.</dc:creator>
 <dc:creator>Demaine, Erik D.</dc:creator>
 <dc:creator>Demaine, Martin L.</dc:creator>
 <dc:creator>Fleischer, Rudolf</dc:creator>
 <dc:creator>Jacobsen, Lars</dc:creator>
 <dc:creator>Munro, J. Ian</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  We study a popular puzzle game known variously as Clickomania and Same Game.
Basically, a rectangular grid of blocks is initially colored with some number
of colors, and the player repeatedly removes a chosen connected monochromatic
group of at least two square blocks, and any blocks above it fall down. We show
that one-column puzzles can be solved, i.e., the maximum possible number of
blocks can be removed, in linear time for two colors, and in polynomial time
for an arbitrary number of colors. On the other hand, deciding whether a puzzle
is solvable (all blocks can be removed) is NP-complete for two columns and five
colors, or five columns and three colors.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures. To appear in More Games of No Chance, edited by
  R. J. Nowakowski</dc:description>
 <dc:date>2001-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coupled Clustering: a Method for Detecting Structural Correspondence</dc:title>
 <dc:creator>Marx, Zvika</dc:creator>
 <dc:creator>Dagan, Ido</dc:creator>
 <dc:creator>Buhmann, Joachim</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  This paper proposes a new paradigm and computational framework for
identification of correspondences between sub-structures of distinct composite
systems. For this, we define and investigate a variant of traditional data
clustering, termed coupled clustering, which simultaneously identifies
corresponding clusters within two data sets. The presented method is
demonstrated and evaluated for detecting topical correspondences in textual
corpora.
</dc:description>
 <dc:description>Comment: html with 5 figures</dc:description>
 <dc:date>2001-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107032</dc:identifier>
 <dc:identifier>In: C. E. Brodley and A. P. Danyluk (eds.), Proceedings of the
  18th International Conference on Machine Learning (ICML 2001), pp. 353-360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Yet another zeta function and learning</dc:title>
 <dc:creator>Rivin, Igor</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  We study the convergence speed of the batch learning algorithm, and compare
its speed to that of the memoryless learning algorithm and of learning with
memory (as analyzed in joint work with N. Komarova). We obtain precise results
and show in particular that the batch learning algorithm is never worse than
the memoryless learning algorithm (at least asymptotically). Its performance
vis-a-vis learning with full memory is less clearcut, and depends on
certainprobabilistic assumptions. These results necessitate theintroduction of
the moment zeta function of a probability distribution and the study of some of
its properties.
</dc:description>
 <dc:date>2001-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NEOS Server 4.0 Administrative Guide</dc:title>
 <dc:creator>Dolan, Elizabeth D.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  The NEOS Server 4.0 provides a general Internet-based client/server as a link
between users and software applications. The administrative guide covers the
fundamental principals behind the operation of the NEOS Server, installation
and trouble-shooting of the Server software, and implementation details of
potential interest to a NEOS Server administrator. The guide also discusses
making new software applications available through the Server, including areas
of concern to remote solver administrators such as maintaining security,
providing usage instructions, and enforcing reasonable restrictions on jobs.
The administrative guide is intended both as an introduction to the NEOS Server
and as a reference for use when running the Server.
</dc:description>
 <dc:description>Comment: 45 pages including front matter, 3 figures</dc:description>
 <dc:date>2001-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Web Content Accessibility Guidelines for Current Research
  Information Systems (CRIS)</dc:title>
 <dc:creator>Lopatenko, A.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>D.2.12</dc:subject>
 <dc:subject>E.2</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:description>  The most exciting challenge for CRIS is to create a service for research
information which should be wide-spread, distributed and actual like Google,
but at the same time structured, trusted, with a complex search and navigation
similar to today CRIS application. The core technology for such a &quot;new&quot; CRIS is
the semantic web technology to integrate database contents with HTML and XML
web pages for being provided to the research interested public. One (at the
moment the best) possible way is to use RDF (Resource Description Framework)
which is also recommended by the W3 consortium.
</dc:description>
 <dc:description>Comment: 25 pages</dc:description>
 <dc:date>2001-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107035</dc:identifier>
 <dc:identifier>Second Interim Report of Extencion Centre, Vienna University of
  Technology, 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0107036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TeXmacs interfaces to Maxima, MuPAD and REDUCE</dc:title>
 <dc:creator>Grozin, A. G.</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:subject>I.1.3</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  GNU TeXmacs is a free wysiwyg word processor providing an excellent
typesetting quality of texts and formulae. It can also be used as an interface
to Computer Algebra Systems (CASs). In the present work, interfaces to three
general-purpose CASs have been implemented.
</dc:description>
 <dc:description>Comment: Talk at 5 Int. Workshop on Computer Algebra and its Applications to
  Physics, Dubna, June 28-30; 9 pages, prepared in TeXmacs and exported as
  LaTeX, 6 PostScript figures included</dc:description>
 <dc:date>2001-07-29</dc:date>
 <dc:date>2001-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0107036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Cactus Worm: Experiments with Dynamic Resource Discovery and
  Allocation in a Grid Environment</dc:title>
 <dc:creator>Allen, Gabrielle</dc:creator>
 <dc:creator>Angulo, David</dc:creator>
 <dc:creator>Foster, Ian</dc:creator>
 <dc:creator>Lanfermann, Gerd</dc:creator>
 <dc:creator>Liu, Chuang</dc:creator>
 <dc:creator>Radke, Thomas</dc:creator>
 <dc:creator>Seidel, Ed</dc:creator>
 <dc:creator>Shalf, John</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  The ability to harness heterogeneous, dynamically available &quot;Grid&quot; resources
is attractive to typically resource-starved computational scientists and
engineers, as in principle it can increase, by significant factors, the number
of cycles that can be delivered to applications. However, new adaptive
application structures and dynamic runtime system mechanisms are required if we
are to operate effectively in Grid environments. In order to explore some of
these issues in a practical setting, we are developing an experimental
framework, called Cactus, that incorporates both adaptive application
structures for dealing with changing resource characteristics and adaptive
resource selection mechanisms that allow applications to change their resource
allocations (e.g., via migration) when performance falls outside specified
limits. We describe here the adaptive resource selection mechanisms and
describe how they are used to achieve automatic application migration to
&quot;better&quot; resources following performance degradation. Our results provide
insights into the architectural structures required to support adaptive
resource selection. In addition, we suggest that this &quot;Cactus Worm&quot; is an
interesting challenge problem for Grid computing.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures, to be published in International Journal of
  Supercomputing Applications</dc:description>
 <dc:date>2001-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounded Concurrent Timestamp Systems Using Vector Clocks</dc:title>
 <dc:creator>Haldar, Sibsankar</dc:creator>
 <dc:creator>Vitanyi, Paul</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>B.3.2</dc:subject>
 <dc:subject>B.4.3</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>D.4.1</dc:subject>
 <dc:subject>D.4.4</dc:subject>
 <dc:description>  Shared registers are basic objects used as communication mediums in
asynchronous concurrent computation. A concurrent timestamp system is a higher
typed communication object, and has been shown to be a powerful tool to solve
many concurrency control problems. It has turned out to be possible to
construct such higher typed objects from primitive lower typed ones. The next
step is to find efficient constructions. We propose a very efficient wait-free
construction of bounded concurrent timestamp systems from 1-writer multireader
registers. This finalizes, corrects, and extends, a preliminary bounded
multiwriter construction proposed by the second author in 1986. That work
partially initiated the current interest in wait-free concurrent objects, and
introduced a notion of discrete vector clocks in distributed algorithms.
</dc:description>
 <dc:description>Comment: LaTeX source, 35 pages; To apper in: J. Assoc. Comp. Mach</dc:description>
 <dc:date>2001-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Partial Evaluation Approach to Information Personalization</dc:title>
 <dc:creator>Ramakrishnan, Naren</dc:creator>
 <dc:creator>Perugini, Saverio</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:subject>H.4.2</dc:subject>
 <dc:subject>H5.2</dc:subject>
 <dc:subject>H5.4</dc:subject>
 <dc:description>  Information personalization refers to the automatic adjustment of information
content, structure, and presentation tailored to an individual user. By
reducing information overload and customizing information access,
personalization systems have emerged as an important segment of the Internet
economy. This paper presents a systematic modeling methodology - PIPE
(`Personalization is Partial Evaluation') - for personalization.
Personalization systems are designed and implemented in PIPE by modeling an
information-seeking interaction in a programmatic representation. The
representation supports the description of information-seeking activities as
partial information and their subsequent realization by partial evaluation, a
technique for specializing programs. We describe the modeling methodology at a
conceptual level and outline representational choices. We present two
application case studies that use PIPE for personalizing web sites and describe
how PIPE suggests a novel evaluation criterion for information system designs.
Finally, we mention several fundamental implications of adopting the PIPE model
for personalization and when it is (and is not) applicable.
</dc:description>
 <dc:description>Comment: Comprehensive overview of the PIPE model for personalization</dc:description>
 <dc:date>2001-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Links tell us about lexical and semantic Web content</dc:title>
 <dc:creator>Menczer, Filippo</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  The latest generation of Web search tools is beginning to exploit hypertext
link information to improve ranking\cite{Brin98,Kleinberg98} and
crawling\cite{Menczer00,Ben-Shaul99etal,Chakrabarti99} algorithms. The hidden
assumption behind such approaches, a correlation between the graph structure of
the Web and its content, has not been tested explicitly despite increasing
research on Web topology\cite{Lawrence98,Albert99,Adamic99,Butler00}. Here I
formalize and quantitatively validate two conjectures drawing connections from
link information to lexical and semantic Web content. The clink-content
conjecture states that a page is similar to the pages that link to it, i.e.,
one can infer the lexical content of a page by looking at the pages that link
to it. I also show that lexical inferences based on link cues are quite
heterogeneous across Web communities. The link-cluster conjecture states that
pages about the same topic are clustered together, i.e., one can infer the
meaning of a page by looking at its neighbours. These results explain the
success of the newest search technologies and open the way for more dynamic and
scalable methods to locate information in a topic or user driven way.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures</dc:description>
 <dc:date>2001-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bit of Progress in Language Modeling</dc:title>
 <dc:creator>Goodman, Joshua</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  In the past several years, a number of different language modeling
improvements over simple trigram models have been found, including caching,
higher-order n-grams, skipping, interpolated Kneser-Ney smoothing, and
clustering. We present explorations of variations on, or of the limits of, each
of these techniques, including showing that sentence mixture models may have
more potential. While all of these techniques have been studied separately,
they have rarely been studied in combination. We find some significant
interactions, especially with smoothing and clustering techniques. We compare a
combination of all techniques together to a Katz smoothed trigram model with no
count cutoffs. We achieve perplexity reductions between 38% and 50% (1 bit of
entropy), depending on training data size, as well as a word error rate
reduction of 8.9%. Our perplexity reductions are perhaps the highest reported
compared to a fair baseline. This is the extended version of the paper; it
contains additional details and proofs, and is designed to be a good
introduction to the state of the art in language modeling.
</dc:description>
 <dc:description>Comment: 73 pages, extended version of paper to appear in Computer Speech and
  Language</dc:description>
 <dc:date>2001-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classes for Fast Maximum Entropy Training</dc:title>
 <dc:creator>Goodman, Joshua</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Maximum entropy models are considered by many to be one of the most promising
avenues of language modeling research. Unfortunately, long training times make
maximum entropy research difficult. We present a novel speedup technique: we
change the form of the model to use classes. Our speedup works by creating two
maximum entropy models, the first of which predicts the class of each word, and
the second of which predicts the word itself. This factoring of the model leads
to fewer non-zero indicator functions, and faster normalization, achieving
speedups of up to a factor of 35 over one of the best previous techniques. It
also results in typically slightly lower perplexities. The same trick can be
used to speed training of other machine learning techniques, e.g. neural
networks, applied to any problem with a large number of outputs, such as
language modeling.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2001-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108006</dc:identifier>
 <dc:identifier>Proceedings of ICASSP-2001, Utah, May 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Abstract versus Concrete Computation on Metric Partial Algebras</dc:title>
 <dc:creator>Tucker, J. V.</dc:creator>
 <dc:creator>Zucker, J. I.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  A model of computation is abstract if, when applied to any algebra, the
resulting programs for computable functions and sets on that algebra are
invariant under isomorphisms, and hence do not depend on a representation for
the algebra. Otherwise it is concrete. Intuitively, concrete models depend on
the implementation of the algebra.
  The difference is particularly striking in the case of topological partial
algebras, and notably in algebras over the reals. We investigate the
relationship between abstract and concrete models of partial metric algebras.
In the course of this investigation, interesting aspects of continuity,
extensionality and non-determinism are uncovered.
</dc:description>
 <dc:description>Comment: 75 pages, AMSTeX, 3 figures</dc:description>
 <dc:date>2001-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Methods of Declarative Logic Programming for Intelligent
  Information Agents</dc:title>
 <dc:creator>Eiter, T.</dc:creator>
 <dc:creator>Fink, M.</dc:creator>
 <dc:creator>Sabbatini, G.</dc:creator>
 <dc:creator>Tompits, H.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:description>  The search for information on the web is faced with several problems, which
arise on the one hand from the vast number of available sources, and on the
other hand from their heterogeneity. A promising approach is the use of
multi-agent systems of information agents, which cooperatively solve advanced
information-retrieval problems. This requires capabilities to address complex
tasks, such as search and assessment of sources, query planning, information
merging and fusion, dealing with incomplete information, and handling of
inconsistency. In this paper, our interest is in the role which some methods
from the field of declarative logic programming can play in the realization of
reasoning capabilities for information agents. In particular, we are interested
in how they can be used and further developed for the specific needs of this
application domain. We review some existing systems and current projects, which
address information-integration problems. We then focus on declarative
knowledge-representation methods, and review and evaluate approaches from logic
programming and nonmonotonic reasoning for information agents. We discuss
advantages and drawbacks, and point out possible extensions and open issues.
</dc:description>
 <dc:description>Comment: 66 pages, 1 figure, to be published in &quot;Theory and Practice of Logic
  Programming&quot;</dc:description>
 <dc:date>2001-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial Neurons with Arbitrarily Complex Internal Structures</dc:title>
 <dc:creator>Kohring, G. A.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:description>  Artificial neurons with arbitrarily complex internal structure are
introduced. The neurons can be described in terms of a set of internal
variables, a set activation functions which describe the time evolution of
these variables and a set of characteristic functions which control how the
neurons interact with one another. The information capacity of attractor
networks composed of these generalized neurons is shown to reach the maximum
allowed bound. A simple example taken from the domain of pattern recognition
demonstrates the increased computational power of these neurons. Furthermore, a
specific class of generalized neurons gives rise to a simple transformation
relating attractor networks of generalized neurons to standard three layer
feed-forward networks. Given this correspondence, we conjecture that the
maximum information capacity of a three layer feed-forward network is 2 bits
per weight.
</dc:description>
 <dc:description>Comment: 22 pages, 2 figures</dc:description>
 <dc:date>2001-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108009</dc:identifier>
 <dc:identifier>Neurocomputing, vol. 47, pp. 103-118 (2002).</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108010</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on Tiling under Tomographic Constraints</dc:title>
 <dc:creator>Chrobak, Marek</dc:creator>
 <dc:creator>Couperus, Peter</dc:creator>
 <dc:creator>Durr, Christoph</dc:creator>
 <dc:creator>Woeginger, Gerhard</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  Given a tiling of a 2D grid with several types of tiles, we can count for
every row and column how many tiles of each type it intersects. These numbers
are called the_projections_. We are interested in the problem of reconstructing
a tiling which has given projections. Some simple variants of this problem,
involving tiles that are 1x1 or 1x2 rectangles, have been studied in the past,
and were proved to be either solvable in polynomial time or NP-complete. In
this note we make progress toward a comprehensive classification of various
tiling reconstruction problems, by proving NP-completeness results for several
sets of tiles.
</dc:description>
 <dc:description>Comment: added one author and a few theorems</dc:description>
 <dc:date>2001-08-21</dc:date>
 <dc:date>2002-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Classes of Functions for which No Free Lunch Results Hold</dc:title>
 <dc:creator>Igel, Christian</dc:creator>
 <dc:creator>Toussaint, Marc</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  In a recent paper it was shown that No Free Lunch results hold for any subset
F of the set of all possible functions from a finite set X to a finite set Y
iff F is closed under permutation of X. In this article, we prove that the
number of those subsets can be neglected compared to the overall number of
possible subsets. Further, we present some arguments why problem classes
relevant in practice are not likely to be closed under permutation.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure, see http://www.neuroinformatik.ruhr-uni-bochum.de/</dc:description>
 <dc:date>2001-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108012</identifier>
 <datestamp>2007-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A polynomial axles-detection algorithm for a four-contacts treadle</dc:title>
 <dc:creator>Crocetti, Giancarlo</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  This submission was removed because it contained proprietary information that
was distributed without permission.
</dc:description>
 <dc:description>Comment: Removed by arXiv admin</dc:description>
 <dc:date>2001-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergent Approximate Solving of First-Order Constraints by Approximate
  Quantifiers</dc:title>
 <dc:creator>Ratschan, Stefan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  Exactly solving first-order constraints (i.e., first-order formulas over a
certain predefined structure) can be a very hard, or even undecidable problem.
In continuous structures like the real numbers it is promising to compute
approximate solutions instead of exact ones. However, the quantifiers of the
first-order predicate language are an obstacle to allowing approximations to
arbitrary small error bounds. In this paper we solve the problem by modifying
the first-order language and replacing the classical quantifiers with
approximate quantifiers. These also have two additional advantages: First, they
are tunable, in the sense that they allow the user to decide on the trade-off
between precision and efficiency. Second, they introduce additional
expressivity into the first-order language by allowing reasoning over the size
of solution sets.
</dc:description>
 <dc:date>2001-08-22</dc:date>
 <dc:date>2002-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What's Fit To Print: The Effect Of Ownership Concentration On Product
  Variety In Daily Newspaper Markets</dc:title>
 <dc:creator>George, Lisa M.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m Miscellaneous</dc:subject>
 <dc:description>  This paper examines the effect of ownership concentration on product
position, product variety and readership in markets for daily newspapers. US
antitrust policy presumes that mergers reduce the amount and diversity of
content available to consumers. However, the effects of consolidation in
differentiated product markets cannot be determined solely from theory. Because
multi-product firms internalize business stealing, mergers may encourage firms
to reposition products, leading to more, not less, variety. Using data on
reporter assignments from 1993-1999, results show that differentiation and
variety increase with concentration. Moreover, there is evidence that
additional variety increases readership, suggesting that concentration benefits
consumers.
</dc:description>
 <dc:description>Comment: 29th TPRC Conference, 2001</dc:description>
 <dc:date>2001-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spiders and Crawlers and Bots, Oh My: The Economic Efficiency and Public
  Policy of Contracts that Restrict Data Collection</dc:title>
 <dc:creator>Rosenfeld, Jeffrey M.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m</dc:subject>
 <dc:description>  Recent trends reveal the search by companies for a legal hook to prevent the
undesired and unauthorized copying of information posted on websites. In the
center of this controversy are metasites, websites that display prices for a
variety of vendors. Metasites function by implementing shopbots, which extract
pricing data from other vendors' websites. Technological mechanisms have proved
unsuccessful in blocking shopbots, and in response, websites have asserted a
variety of legal claims. Two recent cases, which rely on the troublesome
trespass to chattels doctrine, suggest that contract law may provide a less
demanding legal method of preventing the search of websites by data robots. If
blocking collection of pricing data is as simple as posting an online contract,
the question arises whether this end result is desirable and legally viable.
</dc:description>
 <dc:description>Comment: 29th TPRC Conference, 2001</dc:description>
 <dc:date>2001-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verifying Sequential Consistency on Shared-Memory Multiprocessors by
  Model Checking</dc:title>
 <dc:creator>Qadeer, Shaz</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>B.3.3</dc:subject>
 <dc:subject>C.1.2</dc:subject>
 <dc:description>  The memory model of a shared-memory multiprocessor is a contract between the
designer and programmer of the multiprocessor. The sequential consistency
memory model specifies a total order among the memory (read and write) events
performed at each processor. A trace of a memory system satisfies sequential
consistency if there exists a total order of all memory events in the trace
that is both consistent with the total order at each processor and has the
property that every read event to a location returns the value of the last
write to that location.
  Descriptions of shared-memory systems are typically parameterized by the
number of processors, the number of memory locations, and the number of data
values. It has been shown that even for finite parameter values, verifying
sequential consistency on general shared-memory systems is undecidable. We
observe that, in practice, shared-memory systems satisfy the properties of
causality and data independence. Causality is the property that values of read
events flow from values of write events. Data independence is the property that
all traces can be generated by renaming data values from traces where the
written values are distinct from each other. If a causal and data independent
system also has the property that the logical order of write events to each
location is identical to their temporal order, then sequential consistency can
be verified algorithmically. Specifically, we present a model checking
algorithm to verify sequential consistency on such systems for a finite number
of processors and memory locations and an arbitrary number of data values.
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2001-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security Considerations for Remote Electronic Voting over the Internet</dc:title>
 <dc:creator>Rubin, Aviel D.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>K.4.1</dc:subject>
 <dc:description>  This paper discusses the security considerations for remote electronic voting
in public elections. In particular, we examine the feasibility of running
national federal elections over the Internet. The focus of this paper is on the
limitations of the current deployed infrastructure in terms of the security of
the hosts and the Internet itself. We conclude that at present, our
infrastructure is inadequate for remote Internet voting.
</dc:description>
 <dc:date>2001-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bipartite graph partitioning and data clustering</dc:title>
 <dc:creator>Zha, H.</dc:creator>
 <dc:creator>He, X.</dc:creator>
 <dc:creator>Ding, C.</dc:creator>
 <dc:creator>Gu, M.</dc:creator>
 <dc:creator>Simon, H.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>G.1.3</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Many data types arising from data mining applications can be modeled as
bipartite graphs, examples include terms and documents in a text corpus,
customers and purchasing items in market basket analysis and reviewers and
movies in a movie recommender system. In this paper, we propose a new data
clustering method based on partitioning the underlying bipartite graph. The
partition is constructed by minimizing a normalized sum of edge weights between
unmatched pairs of vertices of the bipartite graph. We show that an approximate
solution to the minimization problem can be obtained by computing a partial
singular value decomposition (SVD) of the associated edge weight matrix of the
bipartite graph. We point out the connection of our clustering algorithm to
correspondence analysis used in multivariate analysis. We also briefly discuss
the issue of assigning data objects to multiple clusters. In the experimental
results, we apply our clustering algorithm to the problem of document
clustering to illustrate its effectiveness and efficiency.
</dc:description>
 <dc:description>Comment: Proceedings of ACM CIKM 2001, the Tenth International Conference on
  Information and Knowledge Management, 2001</dc:description>
 <dc:date>2001-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Unix Commands for Parallel Processors: A High-Performance
  Implementation</dc:title>
 <dc:creator>Ong, E.</dc:creator>
 <dc:creator>Lusk, E.</dc:creator>
 <dc:creator>Gropp, W.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  We describe a family of MPI applications we call the Parallel Unix Commands.
These commands are natural parallel versions of common Unix user commands such
as ls, ps, and find, together with a few similar commands particular to the
parallel environment. We describe the design and implementation of these
programs and present some performance results on a 256-node Linux cluster. The
Parallel Unix Commands are open source and freely available.
</dc:description>
 <dc:description>Comment: 9 pages, 2 figures</dc:description>
 <dc:date>2001-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108019</dc:identifier>
 <dc:identifier>in Recent Advances in Parallel Virtual Machine and Message Passing
  Interface, eds. Y. Cotronis and J. Dongarra, Lecture Notes in Computer
  Science, Vol. 2131, Springer-Verlag, pp. 410-418, Sept. 2001.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108020</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flipping Cubical Meshes</dc:title>
 <dc:creator>Bern, Marshall</dc:creator>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:creator>Erickson, Jeff</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:description>  We define and examine flip operations for quadrilateral and hexahedral
meshes, similar to the flipping transformations previously used in triangular
and tetrahedral mesh generation.
</dc:description>
 <dc:description>Comment: 20 pages, 24 figures. Expanded journal version of paper from 10th
  International Meshing Roundtable. This version removes some unwanted
  paragraph breaks from the previous version; the text is unchanged</dc:description>
 <dc:date>2001-08-27</dc:date>
 <dc:date>2002-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108020</dc:identifier>
 <dc:identifier>Engineering with Computers 18(3):173-187, 2002</dc:identifier>
 <dc:identifier>doi:10.1007/s003660200016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Geometry Column 42</dc:title>
 <dc:creator>Mitchell, Joseph S. B.</dc:creator>
 <dc:creator>O'Rourke, Joseph</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2</dc:subject>
 <dc:description>  A compendium of thirty previously published open problems in computational
geometry is presented.
</dc:description>
 <dc:description>Comment: 7 pages; 72 references</dc:description>
 <dc:date>2001-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108021</dc:identifier>
 <dc:identifier>SIGACT News, 32(3) Issue, 120 Sep. 2001, 63--72</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Portability of Syntactic Structure for Language Modeling</dc:title>
 <dc:creator>Chelba, Ciprian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The paper presents a study on the portability of statistical syntactic
knowledge in the framework of the structured language model (SLM). We
investigate the impact of porting SLM statistics from the Wall Street Journal
(WSJ) to the Air Travel Information System (ATIS) domain. We compare this
approach to applying the Microsoft rule-based parser (NLPwin) for the ATIS data
and to using a small amount of data manually parsed at UPenn for gathering the
intial SLM statistics. Surprisingly, despite the fact that it performs modestly
in perplexity (PPL), the model initialized on WSJ parses outperforms the other
initialization methods based on in-domain annotated data, achieving a
significant 0.4% absolute and 7% relative reduction in word error rate (WER)
over a baseline system whose word error rate is 5.8%; the improvement measured
relative to the minimum WER achievable on the N-best lists we worked with is
12%.
</dc:description>
 <dc:description>Comment: ICASSP 2001, Salt Lake City; 4 pages</dc:description>
 <dc:date>2001-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108022</dc:identifier>
 <dc:identifier>ICASSP 2001 Proceedings</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0108023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Extraction Using the Structured Language Model</dc:title>
 <dc:creator>Chelba, Ciprian</dc:creator>
 <dc:creator>Mahajan, Milind</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The paper presents a data-driven approach to information extraction (viewed
as template filling) using the structured language model (SLM) as a statistical
parser. The task of template filling is cast as constrained parsing using the
SLM. The model is automatically trained from a set of sentences annotated with
frame/slot labels and spans. Training proceeds in stages: first a constrained
syntactic parser is trained such that the parses on training data meet the
specified semantic spans, then the non-terminal labels are enriched to contain
semantic information and finally a constrained syntactic+semantic parser is
trained on the parse trees resulting from the previous stage. Despite the small
amount of training data used, the model is shown to outperform the slot level
accuracy of a simple semantic grammar authored manually for the MiPad ---
personal information management --- task.
</dc:description>
 <dc:description>Comment: EMNLP'01, Pittsburgh; 8 pages</dc:description>
 <dc:date>2001-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0108023</dc:identifier>
 <dc:identifier>EMNLP/NAACL 2001 Conference Proceedings</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Abstract Computability, Algebraic Specification and Initiality</dc:title>
 <dc:creator>Tucker, J. V.</dc:creator>
 <dc:creator>Zucker, J. I.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  computable functions are defined by abstract finite deterministic algorithms
on many-sorted algebras. We show that there exist finite universal algebraic
specifications that specify uniquely (up to isomorphism) (i) all abstract
computable functions on any many-sorted algebra; and (ii) all functions
effectively approximable by abstract computable functions on any metric
algebra.
  We show that there exist universal algebraic specifications for all the
classically computable functions on the set R of real numbers. The algebraic
specifications used are mainly bounded universal equations and conditional
equations. We investigate the initial algebra semantics of these
specifications, and derive situations where algebraic specifications define
precisely the computable functions.
</dc:description>
 <dc:description>Comment: To appear in ACM Transactions on Computational Logic (57 pages;
  AMSTeX)</dc:description>
 <dc:date>2001-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic asynchronous pi-calculus</dc:title>
 <dc:creator>Herescu, Oltea Mihaela</dc:creator>
 <dc:creator>Palamidessi, Catuscia</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  We propose an extension of the asynchronous pi-calculus with a notion of
random choice. We define an operational semantics which distinguishes between
probabilistic choice, made internally by the process, and nondeterministic
choice, made externally by an adversary scheduler. This distinction will allow
us to reason about the probabilistic correctness of algorithms under certain
schedulers. We show that in this language we can solve the electoral problem,
which was proved not possible in the asynchronous $\pi$-calculus. Finally, we
show an implementation of the probabilistic asynchronous pi-calculus in a
Java-like language.
</dc:description>
 <dc:description>Comment: Report version (longer and more complete than the FoSSaCs 2000
  version)</dc:description>
 <dc:date>2001-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109002</dc:identifier>
 <dc:identifier>Jerzy Tiuryn, editor, Proceedings of FOSSACS 2000 (Part of ETAPS
  2000), volume 1784 of Lecture Notes in Computer Science, pages 146--160.
  Springer-Verlag, 2000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the generalized dining philosophers problem</dc:title>
 <dc:creator>Herescu, Oltea Mihaela</dc:creator>
 <dc:creator>Palamidessi, Catuscia</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.4.1</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  We consider a generalization of the dining philosophers problem to arbitrary
connection topologies. We focus on symmetric, fully distributed systems, and we
address the problem of guaranteeing progress and lockout-freedom, even in
presence of adversary schedulers, by using randomized algorithms. We show that
the well-known algorithms of Lehmann and Rabin do not work in the generalized
case, and we propose an alternative algorithm based on the idea of letting the
philosophers assign a random priority to their adjacent forks.
</dc:description>
 <dc:date>2001-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109003</dc:identifier>
 <dc:identifier>Proc. of the 20th ACM Symposium on Principles of Distributed
  Computing (PODC), pages 81-89, ACM, 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109004</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Computing on a PC Cluster</dc:title>
 <dc:creator>Luo, X. Q.</dc:creator>
 <dc:creator>Gregory, E. B.</dc:creator>
 <dc:creator>Yang, J. C.</dc:creator>
 <dc:creator>Wang, Y. L.</dc:creator>
 <dc:creator>Chang, D.</dc:creator>
 <dc:creator>Lin, Y.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  The tremendous advance in computer technology in the past decade has made it
possible to achieve the performance of a supercomputer on a very small budget.
We have built a multi-CPU cluster of Pentium PC capable of parallel
computations using the Message Passing Interface (MPI). We will discuss the
configuration, performance, and application of the cluster to our work in
physics.
</dc:description>
 <dc:description>Comment: 3 pages, uses Latex and aipproc.cls</dc:description>
 <dc:date>2001-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109004</dc:identifier>
 <dc:identifier>Advanced Computing and Analysis Techniques in Physics Research:
  VII International Workshop; ACAT 2000, American Institute of Physics (2001)
  270-272</dc:identifier>
 <dc:identifier>doi:10.1063/1.1405325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Architectural Framework for Large-Scale Multicast in Mobile Ad Hoc
  Networks</dc:title>
 <dc:creator>Helmy, Ahmed</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  Emerging ad hoc networks are infrastructure-less networks consisting of
wireless devices with various power constraints, capabilities and mobility
characteristics. An essential capability in future ad hoc networks is the
ability to provide scalable multicast services. This paper presents a novel
adaptive architecture to support multicast services in large-scale wide-area ad
hoc networks. Existing works on multicast in ad hoc networks address only small
size networks. Our main design goals are scalability, robustness and
efficiency. We propose a self-configuring hierarchy extending zone-based
routing with the notion of contacts based on the small world graphs phenomenon
and new metrics of stability and mobility. We introduce a new geographic-based
multicast address allocation scheme coupled with adaptive anycast based on
group popularity. Our scheme is the first of its kind and promises efficient
and robust operation in the common case. Also, based on the new concept of
rendezvous regions, we provide a bootstrap mechanism for the multicast service;
a challenge generally ignored in previous work.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures</dc:description>
 <dc:date>2001-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Properties of Update Sequences Based on Causal Rejection</dc:title>
 <dc:creator>Eiter, T.</dc:creator>
 <dc:creator>Fink, M.</dc:creator>
 <dc:creator>Sabbatini, G.</dc:creator>
 <dc:creator>Tompits, H.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:description>  We consider an approach to update nonmonotonic knowledge bases represented as
extended logic programs under answer set semantics. New information is
incorporated into the current knowledge base subject to a causal rejection
principle enforcing that, in case of conflicts, more recent rules are preferred
and older rules are overridden. Such a rejection principle is also exploited in
other approaches to update logic programs, e.g., in dynamic logic programming
by Alferes et al. We give a thorough analysis of properties of our approach, to
get a better understanding of the causal rejection principle. We review
postulates for update and revision operators from the area of theory change and
nonmonotonic reasoning, and some new properties are considered as well. We then
consider refinements of our semantics which incorporate a notion of minimality
of change. As well, we investigate the relationship to other approaches,
showing that our approach is semantically equivalent to inheritance programs by
Buccafurri et al. and that it coincides with certain classes of dynamic logic
programs, for which we provide characterizations in terms of graph conditions.
Therefore, most of our results about properties of causal rejection principle
apply to these approaches as well. Finally, we deal with computational
complexity of our approach, and outline how the update semantics and its
refinements can be implemented on top of existing logic programming engines.
</dc:description>
 <dc:description>Comment: 59 pages, 2 figures, 3 tables, to be published in &quot;Theory and
  Practice of Logic Programming&quot;</dc:description>
 <dc:date>2001-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Voice vs Data: Estimates of Media Usage and Network Traffic</dc:title>
 <dc:creator>Noll, A. Michael</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m Miscellaneous</dc:subject>
 <dc:description>  The popular conception is that data traffic nearly, if not already, exceeds
voice traffic on backbone networks. However, the results of research reported
in this paper imply that voice traffic greatly exceeds data traffic when real
users are asked to estimate their usage of a wide variety of media. Media usage
was surveyed for students in New York City and in Los Angeles. Other than
significant differences in radio listening, e-mails, and downloads, the usage
was quite similar. Telephone usage (wired and wireless) was nearly an hour per
day. When converted to bits, the telephone traffic was much greater than the
data traffic over the Internet. This paper reports on the details of the two
user studies. The traffic implications of the results are estimated. The
finding that voice exceeds data will then be reconciled with the popular
opposite conception.
</dc:description>
 <dc:description>Comment: 29th TPRC Conference, 2001</dc:description>
 <dc:date>2001-09-05</dc:date>
 <dc:date>2001-09-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Role of Incentives for Opening Monopoly Markets: Comparing GTE and
  BOC Cooperation with Local Entrants</dc:title>
 <dc:creator>Mini, Federico</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m Miscellaneous</dc:subject>
 <dc:description>  While the 1996 Telecommunications Act requires all incumbent local telephone
companies to cooperate with local entrants, section 271 of the Act provides the
Bell companies (but not GTE) additional incentives to cooperate. Using an
original data set, I compare the negotiations of AT&amp;T, as a local entrant, with
GTE and with the Bell companies in states where both operate. My results
suggest that the differential incentives matter: The Bells accommodate entry
more than does GTE, as evidenced in quicker agreements, less litigation, and
more favorable prices offered for network access. Consistent with this, there
is more entry into Bell territories
</dc:description>
 <dc:description>Comment: 29th TPRC Conference, 2001</dc:description>
 <dc:date>2001-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Effect of Native Language on Internet Usage</dc:title>
 <dc:creator>Gandal, Neil</dc:creator>
 <dc:creator>Shapiro, Carl</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m Miscellaneous</dc:subject>
 <dc:description>  Our goal is to distinguish between the following two hypotheses: (A) The
Internet will remain disproportionately in English and will, over time, cause
more people to learn English as second language and thus solidify the role of
English as a global language. This outcome will prevail even though there are
more native Chinese and Spanish speakers than there are native English
speakers. (B) As the Internet matures, it will more accurately reflect the
native languages spoken around the world (perhaps weighted by purchasing power)
and will not promote English as a global language.
  English's &quot;early lead&quot; on the web is more likely to persist if those who are
not native English speakers frequently access the large number of English
language web sites that are currently available. In that case, many existing
web sites will have little incentive to develop non-English versions of their
sites, and new sites will tend to gravitate towards English. The key empirical
question, therefore, is whether individuals whose native language is not
English use the Web, or certain types of Web sites, less than do native English
speakers. In order to examine this issue empirically, we employ a unique data
set on Internet use at the individual level in Canada from Media Metrix. Canada
provides an ideal setting to examine this issue because English is one of the
two official languages.
  Our preliminary results suggest that English web sites are not a barrier to
Internet use for French-speaking Quebecois. These preliminary results are
consistent with the scenario in which the Internet will promote English as a
global language.
</dc:description>
 <dc:description>Comment: 29th TPRC Conference, 2001</dc:description>
 <dc:date>2001-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anaphora and Discourse Structure</dc:title>
 <dc:creator>Webber, Bonnie</dc:creator>
 <dc:creator>Stone, Matthew</dc:creator>
 <dc:creator>Joshi, Aravind</dc:creator>
 <dc:creator>Knott, Alistair</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We argue in this paper that many common adverbial phrases generally taken to
signal a discourse relation between syntactically connected units within
discourse structure, instead work anaphorically to contribute relational
meaning, with only indirect dependence on discourse structure. This allows a
simpler discourse structure to provide scaffolding for compositional semantics,
and reveals multiple ways in which the relational meaning conveyed by adverbial
connectives can interact with that associated with discourse structure. We
conclude by sketching out a lexicalised grammar for discourse that facilitates
discourse interpretation as a product of compositional rules, anaphor
resolution and inference.
</dc:description>
 <dc:description>Comment: 45 pages, 17 figures. Revised resubmission to Computational
  Linguistics</dc:description>
 <dc:date>2001-09-09</dc:date>
 <dc:date>2002-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication Complexity and Secure Function Evaluation</dc:title>
 <dc:creator>Naor, Moni</dc:creator>
 <dc:creator>Nissim, Kobbi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:description>  We suggest two new methodologies for the design of efficient secure
protocols, that differ with respect to their underlying computational models.
In one methodology we utilize the communication complexity tree (or branching
for f and transform it into a secure protocol. In other words, &quot;any function f
that can be computed using communication complexity c can be can be computed
securely using communication complexity that is polynomial in c and a security
parameter&quot;. The second methodology uses the circuit computing f, enhanced with
look-up tables as its underlying computational model. It is possible to
simulate any RAM machine in this model with polylogarithmic blowup. Hence it is
possible to start with a computation of f on a RAM machine and transform it
into a secure protocol.
  We show many applications of these new methodologies resulting in protocols
efficient either in communication or in computation. In particular, we
exemplify a protocol for the &quot;millionaires problem&quot;, where two participants
want to compare their values but reveal no other information. Our protocol is
more efficient than previously known ones in either communication or
computation.
</dc:description>
 <dc:date>2001-09-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is There a There There: Towards Greater Certainty for Internet
  Jurisdiction</dc:title>
 <dc:creator>Geist, Michael</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m Miscellaneous</dc:subject>
 <dc:description>  The unique challenge presented by the Internet is that compliance with local
laws is rarely sufficient to assure a business that it has limited its exposure
to legal risk. The paper identifies why the challenge of adequately accounting
for the legal risk arising from Internet jurisdiction has been aggravated in
recent years by the adoption of the Zippo legal framework, commonly referred to
as the passive versus active test. The test provides parties with only limited
guidance and often results in detrimental judicial decisions from a policy
perspective. Given the inadequacies of the Zippo passive versus active test,
the paper argues that it is now fitting to identify a more effective standard
for determining when it is appropriate to assert jurisdiction in cases
involving predominantly Internet-based contacts. The solution submitted in the
paper is to move toward a targeting-based analysis. Unlike the Zippo approach,
a targeting analysis would seek to identify the intentions of the parties and
to assess the steps taken to either enter or avoid a particular jurisdiction.
Targeting would also lessen the reliance on effects-based analysis, the source
of considerable uncertainty since Internet-based activity can ordinarily be
said to create some effects in most jurisdictions. To identify the appropriate
criteria for a targeting test, the paper recommends returning to the core
jurisdictional principle -- foreseeability. Foreseeability in the targeting
context depends on three factors -- contracts, technology, and actual or
implied knowledge.
</dc:description>
 <dc:description>Comment: 29th TPRC Conference, 2001</dc:description>
 <dc:date>2001-09-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109012</dc:identifier>
 <dc:identifier>16 (3) Berkeley Tech. LJ (forthcoming 2001)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conceptual Analysis of Lexical Taxonomies: The Case of WordNet Top-Level</dc:title>
 <dc:creator>Gangemi, Aldo</dc:creator>
 <dc:creator>Guarino, Nicola</dc:creator>
 <dc:creator>Oltramari, Alessandro</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H3.1</dc:subject>
 <dc:description>  In this paper we propose an analysis and an upgrade of WordNet's top-level
synset taxonomy. We briefly review WordNet and identify its main semantic
limitations. Some principles from a forthcoming OntoClean methodology are
applied to the ontological analysis of WordNet. A revised top-level taxonomy is
proposed, which is meant to be more conceptually rigorous, cognitively
transparent, and efficiently exploitable in several applications.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures, 2 tables, submitted to FOIS 2001</dc:description>
 <dc:date>2001-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assigning Satisfaction Values to Constraints: An Algorithm to Solve
  Dynamic Meta-Constraints</dc:title>
 <dc:creator>van der Linden, Janet</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D3.3</dc:subject>
 <dc:description>  The model of Dynamic Meta-Constraints has special activity constraints which
can activate other constraints. It also has meta-constraints which range over
other constraints. An algorithm is presented in which constraints can be
assigned one of five different satisfaction values, which leads to the
assignment of domain values to the variables in the CSP. An outline of the
model and the algorithm is presented, followed by some initial results for two
problems: a simple classic CSP and the Car Configuration Problem. The algorithm
is shown to perform few backtracks per solution, but to have overheads in the
form of historical records required for the implementation of state.
</dc:description>
 <dc:description>Comment: 11 pages. Proceedings ERCIM WG on Constraints (Prague, June 2001)</dc:description>
 <dc:date>2001-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting Trees for Anti-Spam Email Filtering</dc:title>
 <dc:creator>Carreras, Xavier</dc:creator>
 <dc:creator>Marquez, Lluis</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  This paper describes a set of comparative experiments for the problem of
automatically filtering unwanted electronic mail messages. Several variants of
the AdaBoost algorithm with confidence-rated predictions [Schapire &amp; Singer,
99] have been applied, which differ in the complexity of the base learners
considered. Two main conclusions can be drawn from our experiments: a) The
boosting-based methods clearly outperform the baseline learning algorithms
(Naive Bayes and Induction of Decision Trees) on the PU1 corpus, achieving very
high levels of the F1 measure; b) Increasing the complexity of the base
learners allows to obtain better ``high-precision'' classifiers, which is a
very important issue when misclassification costs are considered.
</dc:description>
 <dc:description>Comment: 7 pages, 13 figures</dc:description>
 <dc:date>2001-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109015</dc:identifier>
 <dc:identifier>Proceedings of RANLP-2001, pp. 58-64, Bulgaria, 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communications Convergence, Spectrum Use and Regulatory Constraints, Or
  Property Rights, Flexible Spectrum Use and Satellite v. Terrestrial Uses and
  Users</dc:title>
 <dc:creator>Webbink, Douglas W.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m Miscellaneous</dc:subject>
 <dc:description>  As far as many consumers and businessmen and women are concerned,
increasingly wireline and wireless services, including those provided by
terrestrial and satellite systems, are considered to be substitutes and
sometimes complements, regardless of the laws and regulations applicable to
them. At the same time, many writers and even government agencies (such as the
FCC) have suggested that users of the spectrum should be given more
property-like rights in the use of the spectrum and at a minimum should be
given much more flexibility in how they may use the spectrum. Two recent
developments have important implications with respect to &quot;convergence,&quot;
spectrum property rights and flexible use of the spectrum. The first
development involves several proposals to provide terrestrial wireless services
within spectrum in use or planned to be used to provide satellite services. The
second development is the passage of the 2000 ORBIT Act which specifically
forbids the use of license auctions to select among mutually exclusive
applicants to provide international or global satellite communications service.
The purpose of this paper is to discuss some of the questions raised by these
two events, but not necessarily to provide definitive answers or solutions.
</dc:description>
 <dc:description>Comment: 29th TPRC Conference, 2001</dc:description>
 <dc:date>2001-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning from the Success of MPI</dc:title>
 <dc:creator>Gropp, William D.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  The Message Passing Interface (MPI) has been extremely successful as a
portable way to program high-performance parallel computers. This success has
occurred in spite of the view of many that message passing is difficult and
that other approaches, including automatic parallelization and directive-based
parallelism, are easier to use. This paper argues that MPI has succeeded
because it addresses all of the important issues in providing a parallel
programming model.
</dc:description>
 <dc:description>Comment: 12 pages, 1 figure</dc:description>
 <dc:date>2001-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109018</identifier>
 <datestamp>2016-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Complexity of Exact-Four-Colorability</dc:title>
 <dc:creator>Rothe, J&#xf6;rg</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Let $M_k \seq \nats$ be a given set that consists of $k$ noncontiguous
integers. Define $\exactcolor{M_k}$ to be the problem of determining whether
$\chi(G)$, the chromatic number of a given graph $G$, equals one of the $k$
elements of the set $M_k$ exactly. In 1987, Wagner \cite{wag:j:min-max} proved
that $\exactcolor{M_k}$ is $\bhlevel{2k}$-complete, where $M_k = \{6k+1, 6k+3,
&gt;..., 8k-1 \}$ and $\bhlevel{2k}$ is the $2k$th level of the boolean hierarchy
over $\np$. In particular, for $k = 1$, it is DP-complete to determine whether
$\chi(G) = 7$, where $\DP = \bhlevel{2}$. Wagner raised the question of how
small the numbers in a $k$-element set $M_k$ can be chosen such that
$\exactcolor{M_k}$ still is $\bhlevel{2k}$-complete. In particular, for $k =
1$, he asked if it is DP-complete to determine whether $\chi(G) = 4$. In this
note, we solve this question of Wagner and determine the precise threshold $t
\in \{4, 5, 6, 7\}$ for which the problem $\exactcolor{\{t\}}$ jumps from NP to
DP-completeness: It is DP-complete to determine whether $\chi(G) = 4$, yet
$\exactcolor{\{3\}}$ is in $\np$. More generally, for each $k \geq 1$, we show
that $\exactcolor{M_k}$ is $\bhlevel{2k}$-complete for $M_k = \{3k+1, 3k+3,...,
5k-1\}$.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2001-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109019</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracing Execution of Software for Design Coverage</dc:title>
 <dc:creator>Lencevicius, Raimondas</dc:creator>
 <dc:creator>Metz, Edu</dc:creator>
 <dc:creator>Ran, Alexander</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Test suites are designed to validate the operation of a system against
requirements. One important aspect of a test suite design is to ensure that
system operation logic is tested completely. A test suite should drive a system
through all abstract states to exercise all possible cases of its operation.
This is a difficult task. Code coverage tools support test suite designers by
providing the information about which parts of source code are covered during
system execution. Unfortunately, code coverage tools produce only source code
coverage information. For a test engineer it is often hard to understand what
the noncovered parts of the source code do and how they relate to requirements.
We propose a generic approach that provides design coverage of the executed
software simplifying the development of new test suites. We demonstrate our
approach on common design abstractions such as statecharts, activity diagrams,
message sequence charts and structure diagrams. We implement the design
coverage using Third Eye tracing and trace analysis framework. Using design
coverage, test suites could be created faster by focussing on untested design
elements.
</dc:description>
 <dc:description>Comment: Short version of this paper to be published in Proceedings of 16th
  IEEE International Conference on Automated Software Engineering (ASE 2001).
  13 pages, 9 figures</dc:description>
 <dc:date>2001-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109019</dc:identifier>
 <dc:identifier>doi:10.1109/ASE.2001.989822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling Semantic Association and Conceptual Inheritance for Semantic
  Analysis</dc:title>
 <dc:creator>Vaillant, Pascal</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Allowing users to interact through language borders is an interesting
challenge for information technology. For the purpose of a computer assisted
language learning system, we have chosen icons for representing meaning on the
input interface, since icons do not depend on a particular language. However, a
key limitation of this type of communication is the expression of articulated
ideas instead of isolated concepts. We propose a method to interpret sequences
of icons as complex messages by reconstructing the relations between concepts,
so as to build conceptual graphs able to represent meaning and to be used for
natural language sentence generation. This method is based on an electronic
dictionary containing semantic information.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, LaTeX 2e using Springer LNCS class, with packages
  epsf and amssymb. Proceedings of the 4th International Conference on Text,
  Speech and Dialogue (TSD 2001), Zelezna Ruda, Czech Republic, 10-13 Sept.
  2001</dc:description>
 <dc:date>2001-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109020</dc:identifier>
 <dc:identifier>Springer LNCS (LNAI) 2166 (2001), 54-61</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competing DNS Roots: Creative Destruction or Just Plain Destruction?</dc:title>
 <dc:creator>Mueller, Milton L.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m</dc:subject>
 <dc:description>  The Internet Domain Name System (DNS) is a hierarchical name space that
enables the assignment of unique, mnemonic identifiers to Internet hosts and
the consistent mapping of these names to IP addresses. The root of the domain
name system is the top of the hierarchy and is currently managed by a
quasi-private centralized regulatory authority, the Internet Corporation for
Assigned Names and Numbers (ICANN). This paper identifies and discusses the
economic and policy issues raised by competing DNS roots. The paper provides a
precise definition of root-competition and shows that multiple roots are a
species of standards competition, in which network externalities play a major
role. The paper performs a structural analysis of the different forms that
competing DNS roots can take and their effects on end-user compatibility. It
then explores the policy implications of the various forms of competition.
  The thesis of the paper is that root competition is caused by a severe
disjunction between the demand for and supply of top-level domain names. ICANN
has authorized a tiny number of new top-level domains (7) and subjected their
operators to excruciatingly slow and expensive contractual negotiations. The
growth of alternate DNS roots is an attempt to bypass that bottleneck. The
paper arrives at the policy conclusion that competition among DNS roots should
be permitted and is a healthy outlet for inefficiency or abuses of power by the
dominant root administrator.
</dc:description>
 <dc:date>2001-09-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interactive Timetabling</dc:title>
 <dc:creator>Muller, Tomas</dc:creator>
 <dc:creator>Bartak, Roman</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F2.2</dc:subject>
 <dc:description>  Timetabling is a typical application of constraint programming whose task is
to allocate activities to slots in available resources respecting various
constraints like precedence and capacity. In this paper we present a basic
concept, a constraint model, and the solving algorithms for interactive
timetabling. Interactive timetabling combines automated timetabling (the
machine allocates the activities) with user interaction (the user can interfere
with the process of timetabling). Because the user can see how the timetabling
proceeds and can intervene this process, we believe that such approach is more
convenient than full automated timetabling which behaves like a black-box. The
contribution of this paper is twofold: we present a generic model to describe
timetabling (and scheduling in general) problems and we propose an interactive
algorithm for solving such problems.
</dc:description>
 <dc:description>Comment: 12 pages. Proceedings ERCIM WG on Constraints (Prague, June 2001)</dc:description>
 <dc:date>2001-09-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating Multiple Knowledge Sources for Robust Semantic Parsing</dc:title>
 <dc:creator>Atserias, Jordi</dc:creator>
 <dc:creator>Padro, Lluis</dc:creator>
 <dc:creator>Rigau, German</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This work explores a new robust approach for Semantic Parsing of unrestricted
texts. Our approach considers Semantic Parsing as a Consistent Labelling
Problem (CLP), allowing the integration of several knowledge types (syntactic
and semantic) obtained from different sources (linguistic and statistic). The
current implementation obtains 95% accuracy in model identification and 72% in
case-role filling.
</dc:description>
 <dc:date>2001-09-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109023</dc:identifier>
 <dc:identifier>Proceedings of Euroconference on Recent Advances in Natural
  Language Processing (RANLP'01), p.8-14. Tzigov Chark, Bulgaria. Sept. 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verification of Timed Automata Using Rewrite Rules and Strategies</dc:title>
 <dc:creator>Beffara, Emmanuel</dc:creator>
 <dc:creator>Bournez, Olivier</dc:creator>
 <dc:creator>Kacem, Hassen</dc:creator>
 <dc:creator>Kirchner, Claude</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  ELAN is a powerful language and environment for specifying and prototyping
deduction systems in a language based on rewrite rules controlled by
strategies. Timed automata is a class of continuous real-time models of
reactive systems for which efficient model-checking algorithms have been
devised. In this paper, we show that these algorithms can very easily be
prototyped in the ELAN system. This paper argues through this example that
rewriting based systems relying on rules and strategies are a good framework to
prototype, study and test rather efficiently symbolic model-checking
algorithms, i.e. algorithms which involve combination of graph exploration
rules, deduction rules, constraint solving techniques and decision procedures.
</dc:description>
 <dc:date>2001-09-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Global Constraints: A First View</dc:title>
 <dc:creator>Bartak, Roman</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:description>  Global constraints proved themselves to be an efficient tool for modelling
and solving large-scale real-life combinatorial problems. They encapsulate a
set of binary constraints and using global reasoning about this set they filter
the domains of involved variables better than arc consistency among the set of
binary constraints. Moreover, global constraints exploit semantic information
to achieve more efficient filtering than generalised consistency algorithms for
n-ary constraints. Continued expansion of constraint programming (CP) to
various application areas brings new challenges for design of global
constraints. In particular, application of CP to advanced planning and
scheduling (APS) requires dynamic additions of new variables and constraints
during the process of constraint satisfaction and, thus, it would be helpful if
the global constraints could adopt new variables. In the paper, we give a
motivation for such dynamic global constraints and we describe a dynamic
version of the well-known alldifferent constraint.
</dc:description>
 <dc:description>Comment: 11 pages. Proceedings ERCIM WG on Constraints (Prague, June 2001)</dc:description>
 <dc:date>2001-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conceptualising Regulatory Change - Explaining Shifts in
  Telecommunications Governance</dc:title>
 <dc:creator>Simpson, Seamus</dc:creator>
 <dc:creator>Wilkinson, Rorden</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m Miscellaneous</dc:subject>
 <dc:description>  Drawing on perspectives from telecommunications policy and neo-Gramscian
understandings of international political economy, this paper offers an
explanation and analysis of the shifting patterns of regulation which have been
evident in the telecommunications sector in recent years. It aims to illustrate
explain and explore the implications of the movement of regulatory sovereignty
away from the nation-state, through regional conduits, to global organisations
in the crystallisation of a world system of telecommunications governance.
  Our central argument is that telecommunications governance has evolved from a
regulatory arena characterised, in large part, by national diversity, to one
wherein a more convergent global multilayered system is emerging. We suggest
that the epicentre of this regulatory system is the relatively new World Trade
Organisation (WTO). Working in concert with the WTO are existing
well-established nodes regulation. In further complement, we see regional
regulatory projects, notably the European Union (EU), as important conduits and
nodes of regulation in the consolidation of a global regulatory regime.
  By way of procedure, we first explore the utility of a neo-Gramscian approach
for understanding the development of global regulatory frameworks. Second, we
survey something of the recent history - and, in extension, conventional wisdom
- of telecommunications regulation at national and regional levels. Third, we
demonstrate how a multilayered system of global telecommunications regulation
has emerged centred around the regulatory authority of the WTO. Finally, we
offer our concluding comments.
</dc:description>
 <dc:description>Comment: 29th TPRC conference, 2001</dc:description>
 <dc:date>2001-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Routing Permutations in Partitioned Optical Passive Star Networks</dc:title>
 <dc:creator>Mei, Alessandro</dc:creator>
 <dc:creator>Rizzi, Romeo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>C.1.4</dc:subject>
 <dc:description>  It is shown that a POPS network with g groups and d processors per group can
efficiently route any permutation among the n=dg processors. The number of
slots used is optimal in the worst case, and is at most the double of the
optimum for all permutations p such that p(i)&lt;&gt;i for all i.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2001-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Walks in Routing Landscapes</dc:title>
 <dc:creator>Michalareas, T.</dc:creator>
 <dc:creator>Sacks, L.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:description>  In this paper we present a combinatorial optimisation view on the routing
problem for connectionless packet networks by using the metaphor of a
landscape. We examine the main properties of the routing landscapes as we
define them and how they can help us on the evaluation of the problem
difficulty and the generation of effective algorithms. We also present the
random walk statistical technique to evaluate the main properties of those
landscapes and a number of examples to demonstrate the use of the method.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures</dc:description>
 <dc:date>2001-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning class-to-class selectional preferences</dc:title>
 <dc:creator>Agirre, E.</dc:creator>
 <dc:creator>Martinez, D.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Selectional preference learning methods have usually focused on word-to-class
relations, e.g., a verb selects as its subject a given nominal class. This
papers extends previous statistical models to class-to-class preferences, and
presents a model that learns selectional preferences for classes of verbs. The
motivation is twofold: different senses of a verb may have different
preferences, and some classes of verbs can share preferences. The model is
tested on a word sense disambiguation task which uses subject-verb and
object-verb relationships extracted from a small sense-disambiguated corpus.
</dc:description>
 <dc:date>2001-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109029</dc:identifier>
 <dc:identifier>Proceedings of the Workshop &quot;Computational Natural Language
  Learning&quot; (CoNLL-2001). In conjunction with ACL'2001/EACL'2001. Toulouse,
  France. 6-7th July 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Sources for Word Sense Disambiguation</dc:title>
 <dc:creator>Agirre, Eneko</dc:creator>
 <dc:creator>Martinez, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Two kinds of systems have been defined during the long history of WSD:
principled systems that define which knowledge types are useful for WSD, and
robust systems that use the information sources at hand, such as, dictionaries,
light-weight ontologies or hand-tagged corpora. This paper tries to systematize
the relation between desired knowledge types and actual information sources. We
also compare the results for a wide range of algorithms that have been
evaluated on a common test setting in our research group. We hope that this
analysis will help change the shift from systems based on information sources
to systems based on knowledge sources. This study might also shed some light on
semi-automatic acquisition of desired knowledge types from existing resources.
</dc:description>
 <dc:date>2001-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109030</dc:identifier>
 <dc:identifier>Proceedings of the Fourth International Conference TSD 2001, Plzen
  (Pilsen), Czech Republic, September 2001. Published in the Springer Verlag
  Lecture Notes in Computer Science series. Vaclav Matousek, Pavel Mautner,
  Roman Moucek, Karel Tauser (eds.)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enriching WordNet concepts with topic signatures</dc:title>
 <dc:creator>Agirre, Eneko</dc:creator>
 <dc:creator>Ansa, Olatz</dc:creator>
 <dc:creator>Hovy, Eduard</dc:creator>
 <dc:creator>Martinez, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper explores the possibility of enriching the content of existing
ontologies. The overall goal is to overcome the lack of topical links among
concepts in WordNet. Each concept is to be associated to a topic signature,
i.e., a set of related words with associated weights. The signatures can be
automatically constructed from the WWW or from sense-tagged corpora. Both
approaches are compared and evaluated on a word sense disambiguation task. The
results show that it is possible to construct clean signatures from the WWW
using some filtering techniques.
</dc:description>
 <dc:description>Comment: Author list corrected</dc:description>
 <dc:date>2001-09-18</dc:date>
 <dc:date>2001-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109031</dc:identifier>
 <dc:identifier>Proceedings of the NAACL workshop on WordNet and Other lexical
  Resources: Applications, Extensions and Customizations. Pittsburg, 2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Internet, 1995-2000: Access, Civic Involvement, and Social
  Interaction</dc:title>
 <dc:creator>Katz, James</dc:creator>
 <dc:creator>Rice, Ronald E.</dc:creator>
 <dc:creator>Aspden, Philip</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m Miscellaneous</dc:subject>
 <dc:description>  Our research, which began fielding surveys in 1995, and which have been
repeated with variation in 1996, 1997 and 2000, was apparently the first to use
national random telephone survey methods to track social and community aspects
of Internet use, and to compare users and non-users. It also seems to be among
the first that used these methods to compare users with non-users in regards to
communication, social and community issues. The work has been largely supported
by grants from the Markle Foundation of New York City as well as the Robert
Wood Johnson Foundation.
  Abridged, see full text for complete abstract.
</dc:description>
 <dc:description>Comment: 29th TPRC Conference, 2001</dc:description>
 <dc:date>2001-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CLP versus LS on Log-based Reconciliation Problems</dc:title>
 <dc:creator>Fages, Francois</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:description>  Nomadic applications create replicas of shared objects that evolve
independently while they are disconnected. When reconnecting, the system has to
reconcile the divergent replicas. In the log-based approach to reconciliation,
such as in the IceCube system, the input is a common initial state and logs of
actions that were performed on each replica. The output is a consistent global
schedule that maximises the number of accepted actions. The reconciler merges
the logs according to the schedule, and replays the operations in the merged
log against the initial state, yielding to a reconciled common final state.
  In this paper, we show the NP-completeness of the log-based reconciliation
problem and present two programs for solving it. Firstly, a constraint logic
program (CLP) that uses integer constraints for expressing precedence
constraints, boolean constraints for expressing dependencies between actions,
and some heuristics for guiding the search. Secondly, a stochastic local search
method with Tabu heuristic (LS), that computes solutions in an incremental
fashion but does not prove optimality. One difficulty in the LS modeling lies
in the handling of both boolean variables and integer variables, and in the
handling of the objective function which differs from a max-CSP problem.
Preliminary evaluation results indicate better performance for the CLP program
which, on somewhat realistic benchmarks, finds nearly optimal solutions up to a
thousands of actions and proves optimality up to a hundreds of actions.
</dc:description>
 <dc:description>Comment: Article presented at the 6th ERCIM workshop of the Constraint Group,
  Prague, Czech Republic, June 2001</dc:description>
 <dc:date>2001-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relevant Knowledge First - Reinforcement Learning and Forgetting in
  Knowledge Based Configuration</dc:title>
 <dc:creator>Kreuz, Ingo</dc:creator>
 <dc:creator>Roller, Dieter</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>H.4.2</dc:subject>
 <dc:subject>I.2.0</dc:subject>
 <dc:subject>I.2.1</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  In order to solve complex configuration tasks in technical domains, various
knowledge based methods have been developed. However their applicability is
often unsuccessful due to their low efficiency. One of the reasons for this is
that (parts of the) problems have to be solved again and again, instead of
being &quot;learnt&quot; from preceding processes. However, learning processes bring with
them the problem of conservatism, for in technical domains innovation is a
deciding factor in competition. On the other hand a certain amount of
conservatism is often desired since uncontrolled innovation as a rule is also
detrimental. This paper proposes the heuristic RKF (Relevant Knowledge First)
for making decisions in configuration processes based on the so-called
relevance of objects in a knowledge base. The underlying relevance-function has
two components, one based on reinforcement learning and the other based on
forgetting (fading). Relevance of an object increases with its successful use
and decreases with age when it is not used. RKF has been developed to speed up
the configuration process and to improve the quality of the solutions relative
to the reward value that is given by users.
</dc:description>
 <dc:description>Comment: pdf-file, 33 pages, 17 figures</dc:description>
 <dc:date>2001-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109035</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revenge of the Bell Heads: How the Net Heads Lost Control of the
  Internet</dc:title>
 <dc:creator>Frieden, Rob</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m Miscellaneous</dc:subject>
 <dc:description>  A dichotomy in regulatory treatment and corporate cultures exists between
Internet Service Providers (ISPs) and telecommunication carriers. Telephone
company executives (Bell Heads) may resent regulation, but they accept their
fate and work creatively to exploit anomalies and opportunities to secure a
regulation-conferred competitive advantage. Most ISP executives (Net Heads)
appear to embrace a libertarian attitude, strongly opposing any government
involvement. Despite the clash of cultures, the telecommunications and Internet
worlds have merged. Such convergence jeopardizes the ability of Net Heads to
avoid some degree of regulation, particularly when they offer services
functionally equivalent to what their Bell Head counterparts offer.
  This paper will assess the regulatory consequences when telecommunication and
Internet services converge in the marketplace and in terms of operating
technologies. The paper identifies commercial developments in the Internet to
support the view that the Internet has become more hierarchical and more like
telecommunication networks. The paper concludes that telecommunication carriers
will display superior skill in working the regulatory process to their
advantage. The paper suggests that Bell Heads will outmaneuver Net Heads
particularly when the revenue siphoning effect of Internet-mediated services
offsets the revenues generated from ISP leases of telecommunication
transmission capacity.
</dc:description>
 <dc:date>2001-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competition and Price Dispersion in International Long Distance Calling</dc:title>
 <dc:creator>Ennis, Sean F.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m Miscellaneous</dc:subject>
 <dc:description>  This paper examines the relationship between changes in telecommunications
provider concentration on international long distance routes and changes in
prices on those routes. Overall, decreased concentration is associated with
significantly lower prices to consumers of long distance services. However, the
relationship between concentration and price varies according to the type of
long distance plan considered. For the international flagship plans frequently
selected by more price-conscious consumers of international long distance,
increased competition on a route is associated with lower prices. In contrast,
for the basic international plans that are the default selection for consumers,
increased competition on a route is actually associated with higher prices.
Thus, somewhat surprisingly, price dispersion appears to increase as
competition increases.
</dc:description>
 <dc:description>Comment: 29th TPRC Conference, 2001</dc:description>
 <dc:date>2001-09-19</dc:date>
 <dc:date>2001-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Antitrust, Intellectual Property and Standard-Setting Organizations</dc:title>
 <dc:creator>Lemley, Mark A.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m</dc:subject>
 <dc:description>  Standard-setting organizations (SSOs) regularly encounter situations in which
one or more companies claim to own proprietary rights that cover a proposed
industry standard. The industry cannot adopt the standard without the
permission of the intellectual property owner (or owners).
  How SSOs respond to those who assert intellectual property rights is
critically important. Whether or not private companies retain intellectual
property rights in group standards will determine whether a standard is &quot;open&quot;
or &quot;closed.&quot; It will determine who can sell compliant products, and it may well
influence whether the standard adopted in the market is one chosen by a group
or one offered by a single company. SSO rules governing intellectual property
rights will also affect how standards change as technology improves.
  Given the importance of SSO rules governing intellectual property rights,
there has been surprisingly little treatment of SSOs or their intellectual
property rules in the legal literature. My aim in this article is to fill that
void. To do so, I have surveyed the intellectual property policies of dozens of
SSOs, primarily but not exclusively in the computer networking and
telecommunications industries.
</dc:description>
 <dc:description>Comment: 29th TPRC Conference 2001</dc:description>
 <dc:date>2001-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0109038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crisis of Public Utility Deregulation and the Unrecognized Welfare State</dc:title>
 <dc:creator>Cherry, Barbara A.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.m Miscellaneous</dc:subject>
 <dc:description>  Successful achievement of public policies requires satisfaction of conditions
affecting political feasibility for policy adoption and maintenance as well as
economic viability of the desired activity or enterprise. This paper discusses
the difficulties of satisfying these joint constraints given the legacy of the
common law doctrines of &quot;just price&quot; and &quot;businesses affected with a public
interest.&quot; In this regard, it is helpful to view traditional public utility
regulation as a form of welfare state regulation, as it suffers from similar
political problems from policy retrenchment. The retrenchment problems are
examined in the context of the electricity crisis in California as well as the
passage and implementation of the Telecommunications Act of 1996. As expected,
retrenchment from low residential retail rates - the most universalistic
benefit for customers - faces the greatest political resistance. The societal
trade-offs between monopoly and competition must be reexamined in light of the
greater instability and political difficulties under a deregulatory regime.
</dc:description>
 <dc:description>Comment: 29th TPRC Conference, 2001</dc:description>
 <dc:date>2001-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/cs/0109038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="147000" completeListSize="155308">2369777|148001</resumptionToken>
</ListRecords>
</OAI-PMH>
