<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:39:58Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|139001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01872</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum-Phase HRTF Modeling of Pinna Spectral Notches using Group Delay
  Decomposition</dc:title>
 <dc:creator>C, Sandeep Reddy</dc:creator>
 <dc:creator>Hegde, Rajesh M</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Accurate reconstruction of HRTFs is important in the design and development
of high quality 3D binaural sound synthesis systems. Conventionally, minimum
phase HRTF model development for reconstruction of HRTFs has been limited to
minimum phase-pure delay models which ignore the all pass component of the
HRTF. In this paper, a novel method for minimum phase HRTF modeling of Pinna
Spectral Notches (PSNs) using group delay decomposition is proposed. The
proposed minimum phase model captures the PSNs contributed by both the minimum
phase and all pass component of the HRTF thus facilitating an accurate
reconstruction of the HRTFs for all spatial angles which was hitherto not
possible in the minimum phase-pure delay model. The purely minimum phase HRTF
components and their corresponding spatial angles are first identified using a
Fourier Bessel Series method that ensures a continuous evolution of the PSNs.
The minimum phase-pure delay model is used to reconstruct HRTF for these
spatial angles. Subsequently, the spatial angles which require both the minimum
phase and all pass component of the HRTF are also identified. For these spatial
angles, a second order all pass filter is cascaded with the minimum phase-pure
delay HRTF model. The all pass filter designed in this work captures the
spectral cues contributed by the all pass component of the HRTF. The minimum
phase HRTF model proposed in this work is able to reconstruct accurate HRTFs
since it is able to capture PSNs with a high degree of resolution. Performance
of the proposed minimum phase HRTF model is evaluated by conducting experiments
on PSN extraction, cross coherence analysis, and 3d binaural sound synthesis.
Both objective and subjective evaluation results obtained using CIPIC, KEMAR,
and the MiPS database are used to indicate the significance of the proposed
model in 3D binaural sound synthesis.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01877</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Transmission in Linear Multihop Relaying Networks</dc:title>
 <dc:creator>Yao, Jianping</dc:creator>
 <dc:creator>Zhou, Xiangyun</dc:creator>
 <dc:creator>Liu, Yuan</dc:creator>
 <dc:creator>Feng, Suili</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies the design and secrecy performance of linear multihop
networks, in the presence of randomly distributed eavesdroppers in a
large-scale two-dimensional space. Depending on whether there is feedback from
the receiver to the transmitter, we study two transmission schemes: on-off
transmission (OFT) and non-on-off transmission (NOFT). In the OFT scheme,
transmission is suspended if the instantaneous received signal-to-noise ratio
(SNR) falls below a given threshold, whereas there is no suspension of
transmission in the NOFT scheme. We investigate the optimal design of the
linear multiple network in terms of the optimal rate parameters of the wiretap
code as well as the optimal number of hops. These design parameters are highly
interrelated since more hops reduces the distance of per-hop communication
which completely changes the optimal design of the wiretap coding rates.
Despite the analytical difficulty, we are able to characterize the optimal
designs and the resulting secure transmission throughput in mathematically
tractable forms in the high SNR regime. Our numerical results demonstrate that
our analytical results obtained in the high SNR regime are accurate at
practical SNR values. Hence, these results provide useful guidelines for
designing linear multihop networks with targeted physical layer security
performance.
</dc:description>
 <dc:description>Comment: 13 pages, 8 figures, Accepted for publication at the IEEE
  Transactions on Wireless Communications</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01888</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information capacity of direct detection optical transmission systems</dc:title>
 <dc:creator>Mecozzi, Antonio</dc:creator>
 <dc:creator>Shtaif, Mark</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  We show that the spectral efficiency of a direct detection transmission
system is at most 1 bit/s/Hz less than the spectral efficiency of a system
employing coherent detection with the same modulation format. Correspondingly,
the capacity per complex degree of freedom in systems using direct detection is
lower by at most 1 bit.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01889</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RAN: Radical analysis networks for zero-shot learning of Chinese
  characters</dc:title>
 <dc:creator>Zhang, Jianshu</dc:creator>
 <dc:creator>Zhu, Yixing</dc:creator>
 <dc:creator>Du, Jun</dc:creator>
 <dc:creator>Dai, Lirong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Chinese characters have a huge set of character categories, more than 20,000
and the number is still increasing as more and more novel characters continue
being created. However, the enormous characters can be decomposed into a few
fundamental structural radicals, only about 500. This paper introduces the
Radical Analysis Networks (RAN) that recognize Chinese characters by
identifying radicals and analyzing 2D spatial structures between them. The
proposed RAN first extracts visual features from Chinese character input by
employing convolutional neural networks as an encoder. Then a decoder based on
recurrent neural networks is employed, who aims to generate a caption of
Chinese character by detecting radicals and 2D structures through a spatial
attention mechanism. The manner of treating Chinese character input as a
composition of radicals rather than a single picture severely reduces the size
of vocabulary and enables RAN to possess the ability of recognizing unseen
Chinese character classes only if their radicals have been seen, called
zero-shot learning. We test a simple implementation of RAN on experiments of
recognizing printed Chinese characters with seen and unseen classes and RAN
simultaneously obtains convincing performance on unseen classes and
state-of-the-art performance on seen classes.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01894</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Frontier Stitching for Remote Neural Network Watermarking</dc:title>
 <dc:creator>Merrer, Erwan Le</dc:creator>
 <dc:creator>Perez, Patrick</dc:creator>
 <dc:creator>Tr&#xe9;dan, Gilles</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The state of the art performance of deep learning models comes at a high cost
for companies and institutions, due to the tedious data collection and the
heavy processing requirements. Recently, Uchida et al. (2017) proposed to
watermark convolutional neural networks by embedding information into their
weights. While this is a clear progress towards model protection, this
technique solely allows for extracting the watermark from a network that one
accesses locally and entirely. This is a clear impediment, as leaked models can
be re-used privately, and thus not released publicly for ownership inspection.
  Instead, we aim at allowing the extraction of the watermark from a neural
network (or any other machine learning model) that is operated remotely, and
available through a service API. To this end, we propose to operate on the
model's action itself, tweaking slightly its decision frontiers so that a set
of specific queries convey the desired information.
  In present paper, we formally introduce the problem and propose a novel
zero-bit watermarking algorithm that makes use of adversarial model examples.
While limiting the loss of performance of the protected model, this algorithm
allows subsequent extraction of the watermark using only few remote queries. We
experiment this approach on the MNIST dataset with three types of neural
networks, demonstrating that e.g., watermarking with 100 images incurs a slight
accuracy degradation, while being resilient to most removal attacks.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01897</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple and efficient GPU parallelization of existing H-Matrix
  accelerated BEM code</dc:title>
 <dc:creator>Vater, Kerstin</dc:creator>
 <dc:creator>Betcke, Timo</dc:creator>
 <dc:creator>Dilba, Boris</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper, we demonstrate how GPU-accelerated BEM routines can be used in
a simple black-box fashion to accelerate fast boundary element formulations
based on Hierarchical Matrices (H-Matrices) with ACA (Adaptive Cross
Approximation). In particular, we focus on the expensive evaluation of the
discrete weak form of boundary operators associated with the Laplace and the
Helmholtz equation in three space dimensions. The method is based on offloading
the CPU assembly of elements during the ACA assembly onto a GPU device and to
use threading strategies across ACA blocks to create sufficient workload for
the GPU. The proposed GPU strategy is designed such that it can be implemented
in existing code with minimal changes to the surrounding application structure.
This is in particular interesting for existing legacy code that is not from the
ground-up designed with GPU computing in mind. Our benchmark study gives
realistic impressions of the benefits of GPU-accelerated BEM simulations by
using state-of-the-art multi-threaded computations on modern high-performance
CPUs as a reference, rather than drawing synthetic comparisons with
single-threaded codes. Speed-up plots illustrate that performance gains up to a
factor of 5.5 could be realized with GPU computing under these conditions. This
refers to a boundary element model with about 4 million unknowns, whose
H-Matrix weak form associated with a real-valued (Laplace) boundary operator is
set up in only 100 minutes harnessing the two GPUs instead of 9 hours when
using the 20 CPU cores at disposal only. The benchmark study is followed by a
particularly demanding real-life application, where we compute the scattered
high-frequency sound field of a submarine to demonstrate the increase in
overall application performance from moving to a GPU-based ACA assembly.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01904</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the complexity of hazard-free circuits</dc:title>
 <dc:creator>Ikenmeyer, Christian</dc:creator>
 <dc:creator>Komarath, Balagopal</dc:creator>
 <dc:creator>Lenzen, Christoph</dc:creator>
 <dc:creator>Lysikov, Vladimir</dc:creator>
 <dc:creator>Mokhov, Andrey</dc:creator>
 <dc:creator>Sreenivasaiah, Karteek</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>03D15, 68Q17</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  The problem of constructing hazard-free Boolean circuits dates back to the
1940s and is an important problem in circuit design. Our main lower-bound
result unconditionally shows the existence of functions whose circuit
complexity is polynomially bounded while every hazard-free implementation is
provably of exponential size. Previous lower bounds on the hazard-free
complexity were only valid for depth 2 circuits. The same proof method yields
that every subcubic implementation of Boolean matrix multiplication must have
hazards.
  These results follow from a crucial structural insight: Hazard-free
complexity is a natural generalization of monotone complexity to all (not
necessarily monotone) Boolean functions. Thus, we can apply known monotone
complexity lower bounds to find lower bounds on the hazard-free complexity. We
also lift these methods from the monotone setting to prove exponential
hazard-free complexity lower bounds for non-monotone functions.
  As our main upper-bound result we show how to efficiently convert a Boolean
circuit into a bounded-bit hazard-free circuit with only a polynomially large
blow-up in the number of gates. Previously, the best known method yielded
exponentially large circuits in the worst case, so our algorithm gives an
exponential improvement.
  As a side result we establish the NP-completeness of several hazard detection
problems.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01912</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The TensorFlow Partitioning and Scheduling Problem: It's the Critical
  Path!</dc:title>
 <dc:creator>Mayer, Ruben</dc:creator>
 <dc:creator>Mayer, Christian</dc:creator>
 <dc:creator>Laich, Larissa</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  State-of-the-art data flow systems such as TensorFlow impose iterative
calculations on large graphs that need to be partitioned on heterogeneous
devices such as CPUs, GPUs, and TPUs. However, partitioning can not be viewed
in isolation. Each device has to select the next graph vertex to be executed,
i.e., perform local scheduling decisions. Both problems, partitioning and
scheduling, are NP-complete by themselves but have to be solved in combination
in order to minimize overall execution time of an iteration. In this paper, we
propose several heuristic strategies to solve the partitioning and scheduling
problem in TensorFlow. We simulate the performance of the proposed strategies
in heterogeneous environments with communication-intensive workloads that are
common to TensorFlow. Our findings indicate that the best partitioning and
scheduling heuristics are those that focus on minimizing the execution time of
the critical path in the graph. Those strategies provide a speed-up of up to 4
times in comparison to strategies that are agnostic to the critical path, such
as hash-based partitioning and FIFO scheduling.
</dc:description>
 <dc:description>Comment: 6 pages. To be published in Proceedings of DIDL '17: Workshop on
  Distributed Infrastructures for Deep Learning, hosted by ACM Middleware 2017
  Conference. https://doi.org/10.1145/3154842.3154843</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01912</dc:identifier>
 <dc:identifier>doi:10.1145/3154842.3154843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01919</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Integral Histogram Computations on GPU for Real-Time Video
  Analytics</dc:title>
 <dc:creator>Poostchi, Mahdieh</dc:creator>
 <dc:creator>Palaniappan, Kannappan</dc:creator>
 <dc:creator>Li, Da</dc:creator>
 <dc:creator>Becchi, Michela</dc:creator>
 <dc:creator>Bunyak, Filiz</dc:creator>
 <dc:creator>Seetharaman, Guna</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In many Multimedia content analytics frameworks feature likelihood maps
represented as histograms play a critical role in the overall algorithm.
Integral histograms provide an efficient computational framework for extracting
multi-scale histogram-based regional descriptors in constant time which are
considered as the principle building blocks of many video content analytics
frameworks. We evaluate four different mappings of the integral histogram
computation onto Graphics Processing Units (GPUs) using different kernel
optimization strategies. Our kernels perform cumulative sums on row and column
histograms in a cross-weave or wavefront scan order, use different data
organization and scheduling methods that is shown to critically affect
utilization of GPU resources (cores and shared memory). Tiling the 3-D array
into smaller regular data blocks significantly speeds up the efficiency of the
computation compared to a strip-based organization. The tiled integral
histogram using a diagonal wavefront scan has the best performance of about
300.4 frames/sec for 640 x 480 images and 32 bins with a speedup factor of
about 120 using GTX Titan X graphics card compared to a single threaded
sequential CPU implementation. Double-buffering has been exploited to overlap
computation and communication across sequence of images. Mapping integral
histogram bins computations onto multiple GPUs enables us to process 32 giga
bytes integral histogram data (of 64MB Image and 128 bins) with a frame rate of
0.73 Hz and speedup factor of 153X over single-threaded CPU implementation and
the speedup of 45X over 16-threaded CPU implementation.
</dc:description>
 <dc:description>Comment: GPU Implementation of Integral Histogram</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01920</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Complexity and Approximability of Optimal Sensor Selection for
  Kalman Filtering</dc:title>
 <dc:creator>Ye, Lintao</dc:creator>
 <dc:creator>Roy, Sandip</dc:creator>
 <dc:creator>Sundaram, Shreyas</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Given a linear dynamical system, we consider the problem of selecting (at
design-time) an optimal set of sensors (subject to certain budget constraints)
to minimize the trace of the steady state error covariance matrix of the Kalman
filter. Previous work has shown that this problem is NP-hard for certain
classes of systems and sensor costs; in this paper, we show that the problem
remains NP-hard even for the special case where the system is stable and all
sensor costs are identical. Furthermore, we show the stronger result that there
is no constant-factor (polynomial-time) approximation algorithm for this
problem. This contrasts with other classes of sensor selection problems studied
in the literature, which typically pursue constant-factor approximations by
leveraging greedy algorithms and submodularity of the cost function. Here, we
provide a specific example showing that greedy algorithms can perform
arbitrarily poorly for the problem of design-time sensor selection for Kalman
filtering.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01921</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$A^{4}NT$: Author Attribute Anonymity by Adversarial Training of Neural
  Machine Translation</dc:title>
 <dc:creator>Shetty, Rakshith</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:creator>Fritz, Mario</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Text-based analysis methods allow to reveal privacy relevant author
attributes such as gender, age and identify of the text's author. Such methods
can compromise the privacy of an anonymous author even when the author tries to
remove privacy sensitive content. In this paper, we propose an automatic
method, called Adversarial Author Attribute Anonymity Neural Translation
($A^4NT$), to combat such text-based adversaries. We combine
sequence-to-sequence language models used in machine translation and generative
adversarial networks to obfuscate author attributes. Unlike machine translation
techniques which need paired data, our method can be trained on unpaired
corpora of text containing different authors. Importantly, we propose and
evaluate techniques to impose constraints on our $A^4NT$ to preserve the
semantics of the input text. $A^4NT$ learns to make minimal changes to the
input text to successfully fool author attribute classifiers, while aiming to
maintain the meaning of the input. We show through experiments on two different
datasets and three settings that our proposed method is effective in fooling
the author attribute classifiers and thereby improving the anonymity of
authors.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01927</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Foundry of Human Activities and Infrastructures</dc:title>
 <dc:creator>Allen, Robert B.</dc:creator>
 <dc:creator>Yang, Eunsang</dc:creator>
 <dc:creator>Timakum, Tatsawan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Direct representation knowledgebases can enhance and even provide an
alternative to document-centered digital libraries. Here we consider realist
semantic modeling of everyday activities and infrastructures in such
knowledgebases. Because we want to integrate a wide variety of topics, a
collection of ontologies (a foundry) and a range of other knowledge resources
are needed. We first consider modeling the routine procedures that support
human activities and technologies. Next, we examine the interactions of
technologies with aspects of social organization. Then, we consider approaches
and issues for developing and validating explanations of the relationships
among various entities.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01938</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single-Carrier Modulation versus OFDM for Millimeter-Wave Wireless MIMO</dc:title>
 <dc:creator>Buzzi, Stefano</dc:creator>
 <dc:creator>D'Andrea, Carmen</dc:creator>
 <dc:creator>Foggi, Tommaso</dc:creator>
 <dc:creator>Ugolini, Alessandro</dc:creator>
 <dc:creator>Colavolpe, Giulio</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper presents results on the achievable spectral efficiency and on the
energy efficiency for a wireless multiple-input-multiple-output (MIMO) link
operating at millimeter wave frequencies (mmWave) in a typical 5G scenario. Two
different single-carrier modem schemes are considered, i.e., a traditional
modulation scheme with linear equalization at the receiver, and a
single-carrier modulation with cyclic prefix, frequency-domain equalization and
FFT-based processing at the receiver; these two schemes are compared with a
conventional MIMO-OFDM transceiver structure. Our analysis jointly takes into
account the peculiar characteristics of MIMO channels at mmWave frequencies,
the use of hybrid (analog-digital) pre-coding and post-coding beamformers, the
finite cardinality of the modulation structure, and the non-linear behavior of
the transmitter power amplifiers. Our results show that the best performance is
achieved by single-carrier modulation with time-domain equalization, which
exhibits the smallest loss due to the non-linear distortion, and whose
performance can be further improved by using advanced equalization schemes.
Results also confirm that performance gets severely degraded when the link
length exceeds 90-100 meters and the transmit power falls below 0 dBW.
</dc:description>
 <dc:description>Comment: accepted for publication on IEEE Transactions on Communications</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01938</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2017.2771334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01939</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Advanced Analytics for Connected Cars Cyber Security</dc:title>
 <dc:creator>Levi, Matan</dc:creator>
 <dc:creator>Allouche, Yair</dc:creator>
 <dc:creator>Kontorovich, Aryeh</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The vehicular connectivity revolution is fueling the automotive industry's
most significant transformation seen in decades. However, as modern vehicles
become more connected, they also become much more vulnerable to cyber-attacks.
In this paper, a fully working machine learning approach is proposed to protect
connected vehicles (fleets and individuals) against such attacks. We present a
system that monitors different vehicle's interfaces (Network, CAN and OS),
extracts relevant information based on configurable rules and sends it to a
trained generative model to detect deviations from normal behavior. Using
configurable data collector, we provide a higher level of data abstraction as
the model is trained based on events instead of raw data, which has a
noise-filtering effect and eliminates the need to retrain the model whenever a
protocol changes. We present a new approach for detecting anomalies, tailored
to the temporal nature of our domain. Adapting the hybrid approach of Gutflaish
et al. (2017) to the fully temporal setting, we first train a Hidden Markov
Model to learn normal vehicle behavior, and then a regression model to
calibrate the likelihood threshold for anomaly. Using this architecture, our
method detects sophisticated and realistic anomalies, which are missed by other
existing methods monitoring the CAN bus only. We also demonstrate the
superiority of adaptive thresholds over static ones. Furthermore, our approach
scales efficiently from monitoring individual cars to serving large fleets. We
demonstrate the competitive advantage of our model via encouraging empirical
results.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01941</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correcting Bursty and Localized Deletions Using Guess &amp; Check Codes</dc:title>
 <dc:creator>Hanna, Serge Kas</dc:creator>
 <dc:creator>Rouayheb, Salim El</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of constructing binary codes for correcting deletions
that are localized within certain parts of the codeword that are unknown a
priori. The model that we study is when $\delta \leq w$ deletions occur in a
window of size at most $w$ bits. These $\delta$ deletions are not necessarily
consecutive, but are restricted to the window of size $w$. The localized
deletions model is a generalization of the bursty model, in which all the
deleted bits are consecutive. In this paper, we propose new explicit codes,
based on the family of Guess &amp; Check codes [1,2], that can correct, with high
probability, $\delta \leq w$ deletions that are localized within a single
window of size at most $w=\mathcal{O}(\log k)$, where $k$ is the length of the
information message. These codes have efficient deterministic encoding and
decoding algorithms; and logarithmic redundancy in $k$. We also generalize
these codes to deletions that are localized within multiple windows in the
codeword.
</dc:description>
 <dc:description>Comment: A shorter version of this paper was presented at the 55th Annual
  Allerton Conference on Communication, Control, and Computing. arXiv admin
  note: text overlap with arXiv:1705.09569</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01946</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mandarin tone modeling using recurrent neural networks</dc:title>
 <dc:creator>Huang, Hao</dc:creator>
 <dc:creator>Hu, Ying</dc:creator>
 <dc:creator>Xu, Haihua</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  We propose an Encoder-Classifier framework to model the Mandarin tones using
recurrent neural networks (RNN). In this framework, extracted frames of
features for tone classification are fed in to the RNN and casted into a fixed
dimensional vector (tone embedding) and then classified into tone types using a
softmax layer along with other auxiliary inputs. We investigate various
configurations that help to improve the model, including pooling, feature
splicing and utilization of syllable-level tone embeddings. Besides, tone
embeddings and durations of the contextual syllables are exploited to
facilitate tone classification. Experimental results on Mandarin tone
classification show the proposed network setups improve tone classification
accuracy. The results indicate that the RNN encoder-classifier based tone model
flexibly accommodates heterogeneous inputs (sequential and segmental) and hence
has the advantages from both the sequential classification tone models and
segmental classification tone models.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01947</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Word problems in Elliott monoids</dc:title>
 <dc:creator>Mundici, Daniele</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>46L80</dc:subject>
 <dc:description>  Algorithmic issues concerning Elliott local semigroups are seldom considered
in the literature, although these combinatorial structures completely classify
AF algebras. In general, the addition operation of an Elliott local semigroup
is {\it partial}, but for every AF algebra $\mathfrak B$ whose Murray-von
Neumann order of projections is a lattice, this operation is uniquely
extendible to the addition of an involutive monoid $E(\mathfrak B)$. Let
$\mathfrak M_1$ be the Farey AF algebra introduced by the present author in
1988 and rediscovered by F. Boca in 2008. The freeness properties of the
involutive monoid $E(\mathfrak M_1)$ yield a natural word problem for every AF
algebra $\mathfrak B$ with singly generated $E(\mathfrak B)$, because
$\mathfrak B$ is automatically a quotient of $\mathfrak M_1$. Given two
formulas $\phi$ and $\psi$ in the language of involutive monoids, the problem
asks to decide whether $\phi$ and $\psi$ code the same equivalence of
projections of $\mathfrak B$. This mimics the classical definition of the word
problem of a group presented by generators and relations. We show that the word
problem of $\mathfrak M_1$ is solvable in polynomial time, and so is the word
problem of the Behnke-Leptin algebras $\mathcal A_{n,k}$, and of the
Effros-Shen algebras $\mathfrak F_{\theta}$, for $\theta\in [0,1]\setminus
\mathbb Q$ a real algebraic number, or $\theta = 1/e$. We construct a quotient
of $\mathfrak M_1$ having a G\&quot;odel incomplete word problem, and show that no
primitive quotient of $\mathfrak M_1$ is G\&quot;odel incomplete.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01960</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Iterative Scheme for Leverage-based Approximate Aggregation</dc:title>
 <dc:creator>Han, Shanshan</dc:creator>
 <dc:creator>Wang, Hongzhi</dc:creator>
 <dc:creator>Wan, Jialin</dc:creator>
 <dc:creator>Li, Jianzhong</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Currently data explosion poses great challenges to approximate aggregation on
efficiency and accuracy. To address this problem, we propose a novel approach
to calculate aggregation answers in high accuracy using only a small share of
data. We introduce leverages to reflect individual differences of samples from
the statistical perspective. Two kinds of estimators, the leverage-based
estimator and the sketch estimator (a &quot;rough picture&quot; of the aggregation
answer), are in constraint relations and iteratively improved according to the
actual conditions until their difference is below a threshold. Due to the
iteration mechanism and the leverages, our approach achieves high accuracy.
Moreover, some features, including not requiring recording sampled data and
easy to extend to various execution modes (such as, the online mode), make our
approach well suited to deal with big data. Experiments show that our approach
has extraordinary performance, and when compared with the uniform sampling, our
approach can achieve high-quality answers with only 1/3 of the same sample
size.
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01968</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deformable Deep Convolutional Generative Adversarial Network in
  Microwave Based Hand Gesture Recognition System</dc:title>
 <dc:creator>Zhang, Jiajun</dc:creator>
 <dc:creator>Shi, Zhiguo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Traditional vision-based hand gesture recognition systems is limited under
dark circumstances. In this paper, we build a hand gesture recognition system
based on microwave transceiver and deep learning algorithm. A Doppler radar
sensor with dual receiving channels at 5.8GHz is used to acquire a big database
of hand gestures signals. The received hand gesture signals are then processed
with time-frequency analysis. Based on these big databases of hand gesture, we
propose a new machine learning architecture called deformable deep
convolutional generative adversarial network. Experimental results show the new
architecture can upgrade the recognition rate by 10% and the deformable kernel
can reduce the testing time cost by 30%.
</dc:description>
 <dc:description>Comment: Accepted by International Conference on Wireless Communications and
  Signal Processing 2017</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01970</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal transport maps for distribution preserving operations on latent
  spaces of Generative Models</dc:title>
 <dc:creator>Agustsson, Eirikur</dc:creator>
 <dc:creator>Sage, Alexander</dc:creator>
 <dc:creator>Timofte, Radu</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Generative models such as Variational Auto Encoders (VAEs) and Generative
Adversarial Networks (GANs) are typically trained for a fixed prior
distribution in the latent space, such as uniform or Gaussian. After a trained
model is obtained, one can sample the Generator in various forms for
exploration and understanding, such as interpolating between two samples,
sampling in the vicinity of a sample or exploring differences between a pair of
samples applied to a third sample. In this paper, we show that the latent space
operations used in the literature so far induce a distribution mismatch between
the resulting outputs and the prior distribution the model was trained on. To
address this, we propose to use distribution matching transport maps to ensure
that such latent space operations preserve the prior distribution, while
minimally modifying the original operation. Our experimental results validate
that the proposed operations give higher quality samples compared to the
original operations.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01972</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constant-Factor Approximation for Ordered k-Median</dc:title>
 <dc:creator>Byrka, Jaros&#x142;aw</dc:creator>
 <dc:creator>Sornat, Krzysztof</dc:creator>
 <dc:creator>Spoerhase, Joachim</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W25, 68W20, 68W40, 90B80, 91C20, 90C05</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2</dc:subject>
 <dc:description>  We study the Ordered k-Median problem, in which the solution is evaluated by
first sorting the client connection costs and then multiplying them with a
predefined non-increasing weight vector (higher connection costs are taken with
larger weights). The problem unifies many fundamental clustering and location
problems such as k-Median and k-Center. This generality, however, renders the
problem intriguing from the algorithmic perspective. Recently, Aouad and Segev
proposed a sophisticated local-search based O(log n) approximation algorithm
for Ordered k-Median, extending the result by Tamir (2001) for the case of a
rectangular weight vector, also known as k-Facility p-Centrum. The existence of
a constant-factor approximation algorithm remained open, even for the special
case with a rectangular weight vector.
  Our main result is an LP-rounding constant-factor approximation algorithm for
the (general) Ordered k-Median problem.
  We first provide a new analysis of the rounding process by Charikar and Li
(2012) for k-Median, when applied to a fractional solution obtained from
solving an LP with a carefully modified objective function, results in an
elegant 15-approximation for the rectangular case. In our analysis, the
connection cost of a single client is partly charged to a deterministic budget
related to a combinatorial bound based on guessing, and partly to a budget
whose expected value is bounded with respect to the fractional LP-solution.
Next we analyze objective-oblivious clustering that allows to handle multiple
rectangles in the weight vector. Finally, with a more involved argument, we
show that the clever distance bucketing by Aouad and Segev can be combined with
the objective-oblivious version of our LP-rounding for the rectangular case,
and that it results in a true, polynomial time, constant-factor approximation
algorithm.
</dc:description>
 <dc:description>Comment: 20 pages, 3 algorithms</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01977</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Multi-resource Allocation with Little Communication Overhead</dc:title>
 <dc:creator>Alam, Syed Eqbal</dc:creator>
 <dc:creator>Shorten, Robert</dc:creator>
 <dc:creator>Wirth, Fabian</dc:creator>
 <dc:creator>Yu, Jia Yuan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We propose a distributed algorithm to solve a special distributed
multi-resource allocation problem with no direct inter-agent communication. We
do so by extending a recently introduced additive-increase
multiplicative-decrease (AIMD) algorithm, which only uses very little
communication between the system and agents. Namely, a control unit broadcasts
a one-bit signal to agents whenever one of the allocated resources exceeds
capacity. Agents then respond to this signal in a probabilistic manner. In the
proposed algorithm, each agent is unaware of the resource allocation of other
agents. We also propose a version of the AIMD algorithm for multiple binary
resources (e.g., parking spaces). Binary resources are indivisible unit-demand
resources, and each agent either allocated one unit of the resource or none. In
empirical results, we observe that in both cases, the average allocations
converge over time to optimal allocations.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01980</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Almost Polynomial Hardness of Node-Disjoint Paths in Grids</dc:title>
 <dc:creator>Chuzhoy, Julia</dc:creator>
 <dc:creator>Kim, David H. K.</dc:creator>
 <dc:creator>Nimavat, Rachit</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the classical Node-Disjoint Paths (NDP) problem, we are given an
$n$-vertex graph $G=(V,E)$, and a collection $M=\{(s_1,t_1),\ldots,(s_k,t_k)\}$
of pairs of its vertices, called source-destination, or demand pairs. The goal
is to route as many of the demand pairs as possible, where to route a pair we
need to select a path connecting it, so that all selected paths are disjoint in
their vertices. The best current algorithm for NDP achieves an
$O(\sqrt{n})$-approximation, while, until recently, the best negative result
was a factor $\Omega(\log^{1/2-\epsilon}n)$-hardness of approximation, for any
constant $\epsilon$, unless $NP \subseteq ZPTIME(n^{poly \log n})$. In a recent
work, the authors have shown an improved $2^{\Omega(\sqrt{\log n})}$-hardness
of approximation for NDP, unless $NP\subseteq DTIME(n^{O(\log n)})$, even if
the underlying graph is a subgraph of a grid graph, and all source vertices lie
on the boundary of the grid. Unfortunately, this result does not extend to grid
graphs.
  The approximability of the NDP problem on grid graphs has remained a
tantalizing open question, with the best current upper bound of
$\tilde{O}(n^{1/4})$, and the best current lower bound of APX-hardness. In this
paper we come close to resolving the approximability of NDP in general, and NDP
in grids in particular. Our main result is that NDP is
$2^{\Omega(\log^{1-\epsilon} n)}$-hard to approximate for any constant
$\epsilon$, assuming that $NP\not\subseteq RTIME(n^{poly\log n})$, and that it
is $n^{\Omega (1/(\log \log n)^2)}$-hard to approximate, assuming that for some
constant $\delta&gt;0$, $NP \not \subseteq RTIME(2^{n^{\delta}})$. These results
hold even for grid graphs and wall graphs, and extend to the closely related
Edge-Disjoint Paths problem, even in wall graphs.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01981</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>INDIGO-DataCloud:A data and computing platform to facilitate seamless
  access to e-infrastructures</dc:title>
 <dc:creator>Collaboration, INDIGO-DataCloud</dc:creator>
 <dc:creator>:</dc:creator>
 <dc:creator>Salomoni, D.</dc:creator>
 <dc:creator>Gaido, L.</dc:creator>
 <dc:creator>Campos, I.</dc:creator>
 <dc:creator>de Lucas, J. Marco</dc:creator>
 <dc:creator>Solagna, P.</dc:creator>
 <dc:creator>Gomes, J.</dc:creator>
 <dc:creator>Matyska, L.</dc:creator>
 <dc:creator>Fuhrmann, P.</dc:creator>
 <dc:creator>Hardt, M.</dc:creator>
 <dc:creator>donvito, G.</dc:creator>
 <dc:creator>Dutka, L.</dc:creator>
 <dc:creator>Plociennik, M.</dc:creator>
 <dc:creator>Barbera, R.</dc:creator>
 <dc:creator>Aiftimiei, C.</dc:creator>
 <dc:creator>Blanquer, I.</dc:creator>
 <dc:creator>Ceccanti, A.</dc:creator>
 <dc:creator>David, M.</dc:creator>
 <dc:creator>Lopez-Garcia, A.</dc:creator>
 <dc:creator>Molto, G.</dc:creator>
 <dc:creator>Orviz, P.</dc:creator>
 <dc:creator>Sustr, Z.</dc:creator>
 <dc:creator>Viljoen, M.</dc:creator>
 <dc:creator>Aguilar, F.</dc:creator>
 <dc:creator>Alves, L.</dc:creator>
 <dc:creator>Bonving, A.</dc:creator>
 <dc:creator>Bruno, R.</dc:creator>
 <dc:creator>Davidovic, D.</dc:creator>
 <dc:creator>Fargetta, M.</dc:creator>
 <dc:creator>Chen, Y.</dc:creator>
 <dc:creator>Fiore, S.</dc:creator>
 <dc:creator>Kurkcuoglu, Z.</dc:creator>
 <dc:creator>Lloret, L.</dc:creator>
 <dc:creator>Martins, J.</dc:creator>
 <dc:creator>Nuzzo, A.</dc:creator>
 <dc:creator>Nassisi, P.</dc:creator>
 <dc:creator>Pina, J.</dc:creator>
 <dc:creator>Sciacca, E.</dc:creator>
 <dc:creator>Spiga, D.</dc:creator>
 <dc:creator>Tangaro, M.</dc:creator>
 <dc:creator>Urbaniak, M.</dc:creator>
 <dc:creator>Wegh, B.</dc:creator>
 <dc:creator>Zok, T.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper describes the achievements of the H2020 project INDIGO-DataCloud.
The project has provided e-infrastructures with tools, applications and cloud
framework enhancements to manage the demanding requirements of scientific
communities, either locally or through enhanced interfaces. The middleware
developed allows to federate hybrid resources, to easily write, port and run
scientific applications to the cloud. In particular, we have extended existing
PaaS (Platform as a Service) solutions, allowing public and private
e-infrastructures, including those provided by EGI, EUDAT, and Helix Nebula, to
integrate their existing services and make them available through AAI services
compliant with GEAN interfederation policies, thus guaranteeing transparency
and trust in the provisioning of such services. Our middleware facilitates the
execution of applications using containers on Cloud and Grid based
infrastructures, as well as on HPC clusters. Our developments are freely
downloadable as open source components, and are already being integrated into
many scientific applications.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01984</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PersonRank: Detecting Important People in Images</dc:title>
 <dc:creator>Li, Wei-Hong</dc:creator>
 <dc:creator>Li, Benchao</dc:creator>
 <dc:creator>Zheng, Wei-Shi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Always, some individuals in images are more important/attractive than others
in some events such as presentation, basketball game or speech. However, it is
challenging to find important people among all individuals in images directly
based on their spatial or appearance information due to the existence of
diverse variations of pose, action, appearance of persons and various changes
of occasions. We overcome this difficulty by constructing a multiple
Hyper-Interaction Graph to treat each individual in an image as a node and
inferring the most active node referring to interactions estimated by various
types of clews. We model pairwise interactions between persons as the edge
message communicated between nodes, resulting in a bidirectional
pairwise-interaction graph. To enrich the personperson interaction estimation,
we further introduce a unidirectional hyper-interaction graph that models the
consensus of interaction between a focal person and any person in a local
region around. Finally, we modify the PageRank algorithm to infer the
activeness of persons on the multiple Hybrid-Interaction Graph (HIG), the union
of the pairwise-interaction and hyperinteraction graphs, and we call our
algorithm the PersonRank. In order to provide publicable datasets for
evaluation, we have contributed a new dataset called Multi-scene Important
People Image Dataset and gathered a NCAA Basketball Image Dataset from sports
game sequences. We have demonstrated that the proposed PersonRank outperforms
related methods clearly and substantially.
</dc:description>
 <dc:description>Comment: 8 pages, conference</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01984</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01985</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-tuning Tree-LSTM for phrase-level sentiment classification on a
  Polish dependency treebank. Submission to PolEval task 2</dc:title>
 <dc:creator>Korbak, Tomasz</dc:creator>
 <dc:creator>&#x17b;ak, Paulina</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We describe a variant of Child-Sum Tree-LSTM deep neural network (Tai et al,
2015) fine-tuned for working with dependency trees and morphologically rich
languages using the example of Polish. Fine-tuning included applying a custom
regularization technique (zoneout, described by (Krueger et al., 2016), and
further adapted for Tree-LSTMs) as well as using pre-trained word embeddings
enhanced with sub-word information (Bojanowski et al., 2016). The system was
implemented in PyTorch and evaluated on phrase-level sentiment labeling task as
part of the PolEval competition.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01987</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entrograms and coarse graining of dynamics on complex networks</dc:title>
 <dc:creator>Faccin, Mauro</dc:creator>
 <dc:creator>Schaub, Michael T.</dc:creator>
 <dc:creator>Delvenne, Jean-Charles</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>05C82</dc:subject>
 <dc:description>  Using an information theoretic point of view, we investigate how a dynamics
acting on a network can be coarse grained through the use of graph partitions.
Specifically, we are interested in how aggregating the state space of a Markov
process according to a partition impacts on the thus obtained lower-dimensional
dynamics. We highlight that for a dynamics on a particular graph there may be
multiple coarse grained descriptions that capture different, incomparable
features of the original process. For instance, a coarse graining induced by
one partition may be commensurate with a time-scale separation in the dynamics,
while another coarse graining may correspond to a different lower-dimensional
dynamics that preserves the Markov property of the original process. Taking
inspiration from the literature of Computational Mechanics, we find that a
convenient tool to summarise and visualise such dynamical properties of a
coarse grained model (partition) is the entrogram. The entrogram gathers
certain information-theoretic measures, which quantify how information flows
across time steps. These information theoretic quantities include the entropy
rate, as well as a measure for the memory contained in the process, i.e., how
well the dynamics can be approximated by a first order Markov process. We use
the entrogram to investigate how specific macro-scale connection patterns in
the state-space transition graph of the original dynamics result in desirable
properties of coarse grained descriptions. We thereby provide a fresh
perspective on the interplay between structure and dynamics in networks, and
the process of partitioning from an information theoretic perspective. We focus
on networks that may be approximated by both a core-periphery or a clustered
organization, and highlight that each of these coarse grained descriptions can
capture different aspects of a Markov process acting on the network.
</dc:description>
 <dc:description>Comment: 17 pages, 6 figues</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01987</dc:identifier>
 <dc:identifier>Journal of Complex Networks, cnx055, 2017</dc:identifier>
 <dc:identifier>doi:10.1093/comnet/cnx055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01991</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mitigating Adversarial Effects Through Randomization</dc:title>
 <dc:creator>Xie, Cihang</dc:creator>
 <dc:creator>Wang, Jianyu</dc:creator>
 <dc:creator>Zhang, Zhishuai</dc:creator>
 <dc:creator>Ren, Zhou</dc:creator>
 <dc:creator>Yuille, Alan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks have demonstrated their powerful ability on
various tasks in recent years. However, they are extremely vulnerable to
adversarial examples. I.e., clean images, with imperceptible perturbations
added, can easily cause convolutional neural networks to fail. In this paper,
we propose to utilize randomization to mitigate adversarial effects.
Specifically, we use two randomization operations: random resizing, which
resizes the input images to a random size, and random padding, which pads zeros
around the input images in a random manner. Extensive experiments demonstrate
that the proposed randomization method is very effective at defending against
both single-step and iterative attacks. Our method also enjoys the following
advantages: 1) no additional training or fine-tuning, 2) very few additional
computations, 3) compatible with other adversarial defense methods. By
combining the proposed randomization method with an adversarially trained
model, it achieves a normalized score of 0.924 (ranked No.2 among 107 defense
teams) in the NIPS 2017 adversarial examples defense challenge, which is far
better than using adversarial training alone with a normalized score of 0.773
(ranked No.56). The code is public available at
https://github.com/cihangxie/NIPS2017_adv_challenge_defense.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2018, code available at
  https://github.com/cihangxie/NIPS2017_adv_challenge_defense</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01996</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Goal-oriented adaptive mesh refinement for non-symmetric functional
  settings</dc:title>
 <dc:creator>Keith, Brendan</dc:creator>
 <dc:creator>Astaneh, Ali Vaziri</dc:creator>
 <dc:creator>Demkowicz, Leszek</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65N30, 65N12, 65N15</dc:subject>
 <dc:description>  In this article, a Petrov-Galerkin duality theory is developed. This theory
is then used to motivate goal-oriented adaptive mesh refinement strategies for
use with discontinuous Petrov-Galerkin (DPG) methods. The focus of this article
is mainly on broken ultraweak variational formulations of steady boundary value
problems, however, many of the ideas presented within are general enough that
they be extended to any such well-posed variational formulation. The proposed
goal-oriented adaptive mesh refinement procedures require the construction of
refinement indicators for both a primal problem and a dual problem. The primal
problem is simply the system of linear equations coming from a standard DPG
method. The dual problem is a similar system of equations, coming from a new
method which is dual to DPG; having the same coefficient matrix as the DPG
method but a different load. We refer to this new finite element method as a
DPG* method. A thorough analysis of DPG* methods, as stand-alone finite element
methods, is not given here but will be provided in subsequent articles. For DPG
methods, the current theory of a posteriori error estimation is reviewed and
the reliability estimate in [13, Theorem 2.1] is improved on. For DPG* methods,
three different classes of refinement indicators are derived and several
contributions are made towards rigorous a posteriori error estimation. At the
closure of the article, results of numerical experiments with Poisson's
boundary value problem in a three-dimensional domain are provided. These
results clearly demonstrate the utility of goal-oriented adaptive mesh
refinement with DPG methods for quantities of interest with either interior or
boundary terms.
</dc:description>
 <dc:description>Comment: 41 pages</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02000</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reducing Certification Granularity to Increase Adaptability of Avionics
  Software</dc:title>
 <dc:creator>Rayrole, Martin</dc:creator>
 <dc:creator>Faura, David</dc:creator>
 <dc:creator>Gatti, Marc</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>68M15</dc:subject>
 <dc:description>  A strong certification process is required to insure the safety of airplanes,
and more specifically the robustness of avionics applications. To implement
this process, the development of avionics software must follow long and costly
procedures. Most of these procedures have to be reexecuted each time the
software is modified. In this paper, we propose a framework to reduce the cost
and time impact of a software modification. With this new approach, the piece
of software likely to change is isolated from the rest of the application, so
it can be certified independently. This helps the system integrator to adapt an
avionics application to the specificities of the target airplane, without the
need for a new certification of the application.
</dc:description>
 <dc:description>Comment: IEEE/AIAA 32nd Digital Avionics Systems Conference (DASC), 2013</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02000</dc:identifier>
 <dc:identifier>doi:10.1109/DASC.2013.6712637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02010</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial Generation of Big Data for Improving Image Classification: A
  Generative Adversarial Network Approach on SAR Data</dc:title>
 <dc:creator>Marmanis, Dimitrios</dc:creator>
 <dc:creator>Yao, Wei</dc:creator>
 <dc:creator>Adam, Fathalrahman</dc:creator>
 <dc:creator>Datcu, Mihai</dc:creator>
 <dc:creator>Reinartz, Peter</dc:creator>
 <dc:creator>Schindler, Konrad</dc:creator>
 <dc:creator>Wegner, Jan Dirk</dc:creator>
 <dc:creator>Stilla, Uwe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Very High Spatial Resolution (VHSR) large-scale SAR image databases are still
an unresolved issue in the Remote Sensing field. In this work, we propose such
a dataset and use it to explore patch-based classification in urban and
periurban areas, considering 7 distinct semantic classes. In this context, we
investigate the accuracy of large CNN classification models and pre-trained
networks for SAR imaging systems. Furthermore, we propose a Generative
Adversarial Network (GAN) for SAR image generation and test, whether the
synthetic data can actually improve classification accuracy.
</dc:description>
 <dc:description>Comment: Submitted for review in &quot;Big Data from Space 2017&quot; conference</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02012</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hi, how can I help you?: Automating enterprise IT support help desks</dc:title>
 <dc:creator>Mani, Senthil</dc:creator>
 <dc:creator>Gantayat, Neelamadhav</dc:creator>
 <dc:creator>Aralikatte, Rahul</dc:creator>
 <dc:creator>Gupta, Monika</dc:creator>
 <dc:creator>Dechu, Sampath</dc:creator>
 <dc:creator>Sankaran, Anush</dc:creator>
 <dc:creator>Khare, Shreya</dc:creator>
 <dc:creator>Mitchell, Barry</dc:creator>
 <dc:creator>Subramanian, Hemamalini</dc:creator>
 <dc:creator>Venkatarangan, Hema</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Question answering is one of the primary challenges of natural language
understanding. In realizing such a system, providing complex long answers to
questions is a challenging task as opposed to factoid answering as the former
needs context disambiguation. The different methods explored in the literature
can be broadly classified into three categories namely: 1) classification
based, 2) knowledge graph based and 3) retrieval based. Individually, none of
them address the need of an enterprise wide assistance system for an IT support
and maintenance domain. In this domain the variance of answers is large ranging
from factoid to structured operating procedures; the knowledge is present
across heterogeneous data sources like application specific documentation,
ticket management systems and any single technique for a general purpose
assistance is unable to scale for such a landscape. To address this, we have
built a cognitive platform with capabilities adopted for this domain. Further,
we have built a general purpose question answering system leveraging the
platform that can be instantiated for multiple products, technologies in the
support domain. The system uses a novel hybrid answering model that
orchestrates across a deep learning classifier, a knowledge graph based context
disambiguation module and a sophisticated bag-of-words search system. This
orchestration performs context switching for a provided question and also does
a smooth hand-off of the question to a human expert if none of the automated
techniques can provide a confident answer. This system has been deployed across
675 internal enterprise IT support and maintenance projects.
</dc:description>
 <dc:description>Comment: To appear in IAAI 2018</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02013</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Language Modeling by Jointly Learning Syntax and Lexicon</dc:title>
 <dc:creator>Shen, Yikang</dc:creator>
 <dc:creator>Lin, Zhouhan</dc:creator>
 <dc:creator>Huang, Chin-Wei</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a neural language model capable of unsupervised syntactic
structure induction. The model leverages the structure information to form
better semantic representations and better language modeling. Standard
recurrent neural networks are limited by their structure and fail to
efficiently use syntactic information. On the other hand, tree-structured
recursive networks usually require additional structural supervision at the
cost of human expert annotation. In this paper, We propose a novel neural
language model, called the Parsing-Reading-Predict Networks (PRPN), that can
simultaneously induce the syntactic structure from unannotated sentences and
leverage the inferred structure to learn a better language model. In our model,
the gradient can be directly back-propagated from the language model loss into
the neural parsing network. Experiments show that the proposed model can
discover the underlying syntactic structure and achieve state-of-the-art
performance on word/character-level language model tasks.
</dc:description>
 <dc:description>Comment: 16 pages, 5 figures, under review as a conference paper</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02014</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Cars Meet Distributed Computing: Data Storage as an Example</dc:title>
 <dc:creator>Tseng, Lewis</dc:creator>
 <dc:creator>Higuchi, Takamasa</dc:creator>
 <dc:creator>Altintas, Onur</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  As cars are ubiquitous they could play a major role in a next generation
communication and computation framework. In the last years, the development of
vehicle-to-vehicle communication and vehicle-to-infrastructure communication
took huge steps forward and therefore gives us the tools to build &quot;mobile
computing service&quot; on cars equipped with computation capabilities. Recently,
several groups of researchers independently proposed the design of &quot;vehicular
clouds&quot; that materializes the concept. In this paper, we introduce a new
paradigm of the vehicular clouds, followed by a case study of data storage on
top of the proposed cloud. Finally, we present several challenges and
opportunities in the intersection of vehicular clouds and distributed
computing.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02017</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NeST: A Neural Network Synthesis Tool Based on a Grow-and-Prune Paradigm</dc:title>
 <dc:creator>Dai, Xiaoliang</dc:creator>
 <dc:creator>Yin, Hongxu</dc:creator>
 <dc:creator>Jha, Niraj K.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Neural networks (NNs) have begun to have a pervasive impact on various
applications of machine learning. However, the problem of finding an optimal NN
architecture for large applications has remained open for several decades.
Conventional approaches search for the optimal NN architecture through
extensive trial-and-error. Such a procedure is quite inefficient. In addition,
the generated NN architectures incur substantial redundancy. To address these
problems, we propose an NN synthesis tool (NeST) that automatically generates
very compact architectures for a given dataset. NeST starts with a seed NN
architecture. It iteratively tunes the architecture with gradient-based growth
and magnitude-based pruning of neurons and connections. Our experimental
results show that NeST yields accurate yet very compact NNs with a wide range
of seed architecture selection. For example, for the LeNet-300-100 (LeNet-5) NN
architecture derived from the MNIST dataset, we reduce network parameters by
34.1x (74.3x) and floating-point operations (FLOPs) by 35.8x (43.7x). For the
AlexNet NN architecture derived from the ImageNet dataset, we reduce network
parameters by 15.7x and FLOPs by 4.6x. All these results are the current
state-of-the-art for these architectures.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02026</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full-Duplex Cloud Radio Access Network: Stochastic Design and Analysis</dc:title>
 <dc:creator>Shojaeifard, Arman</dc:creator>
 <dc:creator>Wong, Kai-Kit</dc:creator>
 <dc:creator>Yu, Wei</dc:creator>
 <dc:creator>Zheng, Gan</dc:creator>
 <dc:creator>Tang, Jie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Full-duplex (FD) has emerged as a disruptive communications paradigm for
enhancing the achievable spectral efficiency (SE), thanks to the recent major
breakthroughs in self-interference (SI) mitigation. The FD versus half-duplex
(HD) SE gain, in cellular networks, is however largely limited by the
mutual-interference (MI) between the downlink (DL) and the uplink (UL). A
potential remedy for tackling the MI bottleneck is through cooperative
communications. This paper provides a stochastic design and analysis of FD
enabled cloud radio access network (C-RAN) under the Poisson point process
(PPP)-based abstraction model of multi-antenna radio units (RUs) and user
equipments (UEs). We consider different disjoint and user-centric approaches
towards the formation of finite clusters in the C-RAN. Contrary to most
existing studies, we explicitly take into consideration non-isotropic fading
channel conditions and finite-capacity fronthaul links. Accordingly,
upper-bound expressions for the C-RAN DL and UL SEs, involving the statistics
of all intended and interfering signals, are derived. The performance of the FD
C-RAN is investigated through the proposed theoretical framework and
Monte-Carlo (MC) simulations. The results indicate that significant FD versus
HD C-RAN SE gains can be achieved, particularly in the presence of
sufficient-capacity fronthaul links and advanced interference cancellation
capabilities.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02030</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Optimal Energy Harvesting Receiver Design in MIMO Systems</dc:title>
 <dc:creator>Kariminezhad, Ali</dc:creator>
 <dc:creator>Sezgin, Aydin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate a multiple-input multiple-output (MIMO) system
with simultaneous information detection (ID) and energy harvesting (EH)
receiver. This point- to-point system operates in the vicinity of active
interfering nodes. The receiver performs power splitting where a portion of
received signal undergoes analog energy harvesting circuitry. Further, the
information content of the other portion is extracted after performing digital
beamforming. In this MIMO system, information carrier eigen-modes are not
necessarily the eigen- modes with the strongest energy level. Hence, it is
beneficial to perform independent beamforming at the receiver of MIMO-P2P
channel. Here, we utilize a hybrid analog/digital beamforming for the purpose
of simultaneous ID and EH in such scenarios. This design, provides extra design
degrees-of-freedom in eigen-mode selection for ID and EH purposes
independently. Worst- case performance of this receiver structure is discussed.
Finally, its benefits is compared to the classical receiver structure and the
gains are highlighted.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02032</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Convex Integer Programming: Sum Multicoloring and Bounded
  Neighborhood Diversity</dc:title>
 <dc:creator>Gaven&#x10d;iak, Tom&#xe1;&#x161;</dc:creator>
 <dc:creator>Knop, Du&#x161;an</dc:creator>
 <dc:creator>Kouteck&#xfd;, Martin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  In the past 30 years, results regarding special classes of integer linear
(and, more generally, convex) programs ourished. Applications in the field of
parameterized complexity were called for and the call has been answered,
demonstrating the importance of connecting the two fields. The classical result
due to Lenstra states that solving Integer Linear Programming in Fixed
dimension is polynomial. Later, Khachiyan and Porkolab has extended this result
to optimizing a quasiconvex function over a convex set. While applications of
the former result have been known for over 10 years, it seems the latter result
has not been applied much in the parameterized setting yet. We give one such
application.
  Specifically, we deal with the Sum Coloring problem and a generalization
thereof called Sum-Total Multicoloring, which is similar to the preemptive Sum
Multicoloring problem. In Sum Coloring, we are given a graph $G = (V,E)$ and
the goal is to find a proper coloring $c\colon V\to \mathbb{N}$ minimizing
$\sum_{v\in V} c(v)$. By formulating these problems as convex integer
programming in small dimension, we show fixed-parameter tractability results
for these problems when parameterized by the neighborhood diversity of G, a
parameter generalizing the vertex cover number of G.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02033</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Cosmological Parameters from the Dark Matter Distribution</dc:title>
 <dc:creator>Ravanbakhsh, Siamak</dc:creator>
 <dc:creator>Oliva, Junier</dc:creator>
 <dc:creator>Fromenteau, Sebastien</dc:creator>
 <dc:creator>Price, Layne C.</dc:creator>
 <dc:creator>Ho, Shirley</dc:creator>
 <dc:creator>Schneider, Jeff</dc:creator>
 <dc:creator>Poczos, Barnabas</dc:creator>
 <dc:subject>Astrophysics - Cosmology and Nongalactic Astrophysics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A grand challenge of the 21st century cosmology is to accurately estimate the
cosmological parameters of our Universe. A major approach to estimating the
cosmological parameters is to use the large-scale matter distribution of the
Universe. Galaxy surveys provide the means to map out cosmic large-scale
structure in three dimensions. Information about galaxy locations is typically
summarized in a &quot;single&quot; function of scale, such as the galaxy correlation
function or power-spectrum. We show that it is possible to estimate these
cosmological parameters directly from the distribution of matter. This paper
presents the application of deep 3D convolutional networks to volumetric
representation of dark-matter simulations as well as the results obtained using
a recently proposed distribution regression framework, showing that machine
learning techniques are comparable to, and can sometimes outperform,
maximum-likelihood point estimates using &quot;cosmological models&quot;. This opens the
way to estimating the parameters of our Universe with higher accuracy.
</dc:description>
 <dc:description>Comment: ICML 2016</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02035</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FAMOUS: Fast Approximate string Matching using OptimUm search Schemes</dc:title>
 <dc:creator>Kianfar, Kiavash</dc:creator>
 <dc:creator>Pockrandt, Christopher</dc:creator>
 <dc:creator>Torkamandi, Bahman</dc:creator>
 <dc:creator>Luo, Haochen</dc:creator>
 <dc:creator>Reinert, Knut</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Finding approximate occurrences of a pattern in a text using a full-text
index is a central problem in bioinformatics. Bidirectional indices have opened
new possibilities for solving the problem as they allow the search to be
started from anywhere within the pattern and extended in both directions. In
particular, use of search schemes (partitioning the pattern into several pieces
and searching the pieces in certain orders with bounds on the number of errors
in each piece) has shown significant potential in speeding up approximate
matching. However, finding the optimal search scheme to maximize the search
speed is a difficult combinatorial optimization problem. In this paper, we
propose, for the first time, a method to solve the optimal search scheme
problem for Hamming distance with given number of pieces. Our method is based
on formulating the problem as a mixed integer program (MIP). We show that the
optimal solutions found by our MIP significantly improve upon previously
published ad-hoc solutions. Our MIP can solve problems of considerable size to
optimality in reasonable time and has the attractive property of finding
near-optimal solutions for much larger problems in a very short amount of time.
In addition, we present FAMOUS (Fast Approximate string Matching using OptimUm
search Schemes), a bidirectional search (for Hamming and edit distance)
implemented in SeqAn that performs the search based on the optimal search
schemes from our MIP. We show that FAMOUS is up to 35 times faster than
standard backtracking and anticipate that it will improve many tools as a new
core component for approximate matching and NGS data analysis. We exemplify
this by searching Illumina reads completely in our index at a speed comparable
to or faster than current read mapping tools. Finally, we pose several open
problems regarding our MIP formulation and use of its solutions in
bidirectional search.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02036</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Maximum Entropy Distributions Everywhere</dc:title>
 <dc:creator>Straszak, Damian</dc:creator>
 <dc:creator>Vishnoi, Nisheeth K.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of computing the maximum entropy distribution with a
specified expectation over a large discrete domain. Maximum entropy
distributions arise and have found numerous applications in economics, machine
learning and various sub-disciplines of mathematics and computer science. The
key computational questions related to maximum entropy distributions are
whether they have succinct descriptions and whether they can be efficiently
computed. Here we provide positive answers to both of these questions for very
general domains and, importantly, with no restriction on the expectation. This
completes the picture left open by the prior work on this problem which
requires that the expectation vector is polynomially far in the interior of the
convex hull of the domain. As a consequence we obtain a general algorithmic
tool and show how it can be applied to derive several old and new results in a
unified manner. In particular, our results imply that certain recent continuous
optimization formulations, for instance, for discrete counting and optimization
problems, the matrix scaling problem, and the worst case Brascamp-Lieb
constants in the rank-1 regime, are efficiently computable. Attaining these
implications requires reformulating the underlying problem as a version of
maximum entropy computation where optimization also involves the expectation
vector and, hence, cannot be assumed to be sufficiently deep in the interior.
The key new technical ingredient in our work is a polynomial bound on the bit
complexity of near-optimal dual solutions to the maximum entropy convex
program. This result is obtained by a geometrical reasoning that involves
convex analysis and polyhedral geometry, avoiding combinatorial arguments based
on the specific structure of the domain. We also provide a lower bound on the
bit complexity of near-optimal solutions showing the tightness of our results.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02037</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized Nonnegative Matrix Factorization</dc:title>
 <dc:creator>Erichson, N. Benjamin</dc:creator>
 <dc:creator>Mendible, Ariana</dc:creator>
 <dc:creator>Wihlborn, Sophie</dc:creator>
 <dc:creator>Kutz, J. Nathan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Nonnegative matrix factorization (NMF) is a powerful tool for data mining.
However, the emergence of `big data' has severely challenged our ability to
compute this fundamental decomposition using deterministic algorithms. This
paper presents a randomized hierarchical alternating least squares (HALS)
algorithm to compute the NMF. By deriving a smaller matrix from the nonnegative
input data, a more efficient nonnegative decomposition can be computed. Our
algorithm scales to big data applications while attaining a near-optimal
factorization, i.e., the algorithm scales with the target rank of the data
rather than the ambient dimension of measurement space. The proposed algorithm
is evaluated using synthetic and real world data and shows substantial speedups
compared to deterministic HALS.
</dc:description>
 <dc:description>Comment: Submitted to the journal Pattern Recognition Letters</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02038</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An efficient quantum algorithm for generative machine learning</dc:title>
 <dc:creator>Gao, Xun</dc:creator>
 <dc:creator>Zhang, Zhengyu</dc:creator>
 <dc:creator>Duan, Luming</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A central task in the field of quantum computing is to find applications
where quantum computer could provide exponential speedup over any classical
computer. Machine learning represents an important field with broad
applications where quantum computer may offer significant speedup. Several
quantum algorithms for discriminative machine learning have been found based on
efficient solving of linear algebraic problems, with potential exponential
speedup in runtime under the assumption of effective input from a quantum
random access memory. In machine learning, generative models represent another
large class which is widely used for both supervised and unsupervised learning.
Here, we propose an efficient quantum algorithm for machine learning based on a
quantum generative model. We prove that our proposed model is exponentially
more powerful to represent probability distributions compared with classical
generative models and has exponential speedup in training and inference at
least for some instances under a reasonable assumption in computational
complexity theory. Our result opens a new direction for quantum machine
learning and offers a remarkable example in which a quantum algorithm shows
exponential improvement over any classical algorithm in an important
application field.
</dc:description>
 <dc:description>Comment: 7+15 pages, 3+6 figures</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02046</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of graph filters and filterbanks</dc:title>
 <dc:creator>Tremblay, Nicolas</dc:creator>
 <dc:creator>Gon&#xe7;alves, Paulo</dc:creator>
 <dc:creator>Borgnat, Pierre</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Basic operations in graph signal processing consist in processing signals
indexed on graphs either by filtering them, to extract specific part out of
them, or by changing their domain of representation, using some transformation
or dictionary more adapted to represent the information contained in them. The
aim of this chapter is to review general concepts for the introduction of
filters and representations of graph signals. We first begin by recalling the
general framework to achieve that, which put the emphasis on introducing some
spectral domain that is relevant for graph signals to define a Graph Fourier
Transform. We show how to introduce a notion of frequency analysis for graph
signals by looking at their variations. Then, we move to the introduction of
graph filters, that are defined like the classical equivalent for 1D signals or
2D images, as linear systems which operate on each frequency of a signal. Some
examples of filters and of their implementations are given. Finally, as
alternate representations of graph signals, we focus on multiscale transforms
that are defined from filters. Continuous multiscale transforms such as
spectral wavelets on graphs are reviewed, as well as the versatile approaches
of filterbanks on graphs. Several variants of graph filterbanks are discussed,
for structured as well as arbitrary graphs, with a focus on the central point
of the choice of the decimation or aggregation operators.
</dc:description>
 <dc:description>Comment: chapter in collective book</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02053</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Community Structure in Dynamic Social Networks Using the
  Concept of Leadership</dc:title>
 <dc:creator>Javadi, Saeed Haji Seyed</dc:creator>
 <dc:creator>Gharani, Pedram</dc:creator>
 <dc:creator>Khadivi, Shahram</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Detecting community structure in social networks is a fundamental problem
empowering us to identify groups of actors with similar interests. There have
been extensive works focusing on finding communities in static networks,
however, in reality, due to dynamic nature of social networks, they are
evolving continuously. Ignoring the dynamic aspect of social networks, neither
allows us to capture evolutionary behavior of the network nor to predict the
future status of individuals. Aside from being dynamic, another significant
characteristic of real-world social networks is the presence of leaders, i.e.
nodes with high degree centrality having a high attraction to absorb other
members and hence to form a local community. In this paper, we devised an
efficient method to incrementally detect communities in highly dynamic social
networks using the intuitive idea of importance and persistence of community
leaders over time. Our proposed method is able to find new communities based on
the previous structure of the network without recomputing them from scratch.
This unique feature, enables us to efficiently detect and track communities
over time rapidly. Experimental results on the synthetic and real-world social
networks demonstrate that our method is both effective and efficient in
discovering communities in dynamic social networks.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02056</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput Maximization for Delay-Sensitive Random Access Communication</dc:title>
 <dc:creator>Malak, Derya</dc:creator>
 <dc:creator>Huang, Howard</dc:creator>
 <dc:creator>Andrews, Jeffrey G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider a single cell uplink in which many devices randomly transmit a
data payload to the base station. Given a fixed latency constraint per device,
we propose a time and frequency slotted random access scheme with
retransmissions, which when necessary, are Chase combined at the receiver. We
analyze the proposed setting at constant SNR. We characterize the scaling of
random access throughput versus the latency, by optimizing the number of
retransmissions and the number of frequency bins. For infinite block length
(IBL), we conclude that at low SNR devices should completely share the time and
frequency resources. For high SNR, however, the number of frequency bins should
scale with altered load, and the slot duration for each retransmission is
determined by the outage tolerance. Since infinite packet sizes are not
possible, we extend our model to the finite block length (FBL) regime and
characterize the gap versus the IBL regime. We also provide some new results
for FBL capacity to bound the probability of outage. The proposed random access
model gives an upper bound for the total uplink traffic that can be
successfully decoded for a single receive antenna given the latency constraint,
and provides insights for 5G cellular system design.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02059</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of research activities of universities of Ukraine and
  Belarus: a set of bibliometric indicators and its implementation</dc:title>
 <dc:creator>Lazarev, Vladimir</dc:creator>
 <dc:creator>Nazarovets, Serhii</dc:creator>
 <dc:creator>Skalaban, Alexey</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Monitoring bibliometric indicators of University rankings is considered as a
subject of a University library activity. In order to fulfill comparative
assessment of research activities of the universities of Ukraine and Belarus
the authors introduced a set of bibliometric indicators. A comparative
assessment of the research activities of corresponding universities was
fulfilled; the data on the leading universities are presented. The sensitivity
of the one of the indicators to rapid changes of the research activity of
universities and the fact that the other one is normalized across the fields of
science condition advantage of the proposed set over the one that was used in
practice of the corresponding national rankings.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02059</dc:identifier>
 <dc:identifier>Romanian Journal of Library and Information Science. 2017, 13(3):
  75-84</dc:identifier>
 <dc:identifier>doi:10.26660/rrbsi.2017.13.3.75</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02066</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wirelessly Powered Crowd Sensing: Joint Power Transfer, Sensing,
  Compression, and Transmission</dc:title>
 <dc:creator>Li, Xiaoyang</dc:creator>
 <dc:creator>You, Changsheng</dc:creator>
 <dc:creator>Andreev, Sergey</dc:creator>
 <dc:creator>Gong, Yi</dc:creator>
 <dc:creator>Huang, Kaibin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Leveraging massive numbers of sensors in user equipment as well as
opportunistic human mobility, mobile crowd sensing (MCS) has emerged as a
powerful paradigm, where prolonging battery life of constrained devices and
motivating human involvement are two key design challenges. To address these,
we envision a novel framework, named wirelessly powered crowd sensing (WPCS),
which integrates MCS with wireless power transfer (WPT) for supplying the
involved devices with extra energy and thus facilitating user incentivization.
This paper considers a multiuser WPCS system where an access point (AP)
transfers energy to multiple mobile sensors (MSs), each of which performs data
sensing, compression, and transmission. Assuming lossless (data) compression,
an optimization problem is formulated to simultaneously maximize data utility
and minimize energy consumption at the operator side, by jointly controlling
wireless-power allocation at the AP as well as sensing-data sizes, compression
ratios, and sensor-transmission durations at the MSs. Given fixed compression
ratios, the proposed optimal power allocation policy has the threshold-based
structure with respect to a defined crowd-sensing priority function for each MS
depending on both the operator configuration and the MS information. Further,
for fixed sensing-data sizes, the optimal compression policy suggests that
compression can reduce the total energy consumption at each MS only if the
sensing-data size is sufficiently large. Our solution is also extended to the
case of lossy compression, while extensive simulations are offered to confirm
the efficiency of the contributed mechanisms.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02068</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Multimodal to Unimodal Webpages for Developing Countries</dc:title>
 <dc:creator>Sandeep, Vidyapu</dc:creator>
 <dc:creator>Saradhi, V Vijaya</dc:creator>
 <dc:creator>Bhattacharya, Samit</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The multimodal web elements such as text and images are associated with
inherent memory costs to store and transfer over the Internet. With the limited
network connectivity in developing countries, webpage rendering gets delayed in
the presence of high-memory demanding elements such as images (relative to
text). To overcome this limitation, we propose a Canonical Correlation Analysis
(CCA) based computational approach to replace high-cost modality with an
equivalent low-cost modality. Our model learns a common subspace for low-cost
and high-cost modalities that maximizes the correlation between their visual
features. The obtained common subspace is used for determining the low-cost
(text) element of a given high-cost (image) element for the replacement. We
analyze the cost-saving performance of the proposed approach through an
eye-tracking experiment conducted on real-world webpages. Our approach reduces
the memory-cost by at least 83.35% by replacing images with text.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2017 Workshop on Machine Learning for the
  Developing World</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02074</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Abnormality Detection in Medical Imaging</dc:title>
 <dc:creator>Wu, Dufan</dc:creator>
 <dc:creator>Kim, Kyungsang</dc:creator>
 <dc:creator>Dong, Bin</dc:creator>
 <dc:creator>Li, Quanzheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Nearly all of the deep learning based image analysis methods work on
reconstructed images, which are obtained from original acquisitions via solving
inverse problems. The reconstruction algorithms are designed for human
observers, but not necessarily optimized for DNNs. It is desirable to train the
DNNs directly from the original data which lie in a different domain with the
images. In this work, we proposed an end-to-end DNN for abnormality detection
in medical imaging. A DNN was built as the unrolled version of iterative
reconstruction algorithms to map the acquisitions to images, and followed by a
3D convolutional neural network (CNN) to detect the abnormality in the
reconstructed images. The two networks were trained jointly in order to
optimize the entire DNN for the detection task from the original acquisitions.
The DNN was implemented for lung nodule detection in low-dose chest CT. The
proposed end-to-end DNN demonstrated better sensitivity and accuracy for the
task compared to a two-step approach, in which the reconstruction and detection
DNNs were trained separately. A significant reduction of false positive rate on
suspicious lesions were observed, which is crucial for the known over-diagnosis
in low-dose lung CT imaging. The images reconstructed by the proposed
end-to-end network also presented enhanced details in the region of interest.
</dc:description>
 <dc:description>Comment: Under review at ICLR 2018</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02076</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Structural Parameterizations of the Edge Disjoint Paths Problem</dc:title>
 <dc:creator>Ganian, Robert</dc:creator>
 <dc:creator>Ordyniak, Sebastian</dc:creator>
 <dc:creator>Ramanujan, M. S.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper we revisit the classical Edge Disjoint Paths (EDP) problem,
where one is given an undirected graph G and a set of terminal pairs P and asks
whether G contains a set of pairwise edge-disjoint paths connecting every
terminal pair in P. Our focus lies on structural parameterizations for the
problem that allow for efficient (polynomial-time or fpt) algorithms. As our
first result, we answer an open question stated in Fleszar, Mnich, and
Spoerhase (2016), by showing that the problem can be solved in polynomial time
if the input graph has a feedback vertex set of size one. We also show that EDP
parameterized by the treewidth and the maximum degree of the input graph is
fixed-parameter tractable.
  Having developed two novel algorithms for EDP using structural restrictions
on the input graph, we then turn our attention towards the augmented graph,
i.e., the graph obtained from the input graph after adding one edge between
every terminal pair. In constrast to the input graph, where EDP is known to
remain NP-hard even for treewidth two, a result by Zhou et al. (2000) shows
that EDP can be solved in non-uniform polynomial time if the augmented graph
has constant treewidth; we note that the possible improvement of this result to
an fpt-algorithm has remained open since then. We show that this is highly
unlikely by establishing the W[1]-hardness of the problem parameterized by the
treewidth (and even feedback vertex set) of the augmented graph. Finally, we
develop an fpt-algorithm for EDP by exploiting a novel structural parameter of
the augmented graph.
</dc:description>
 <dc:description>Comment: Accepted for ISAAC 2017</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02078</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully-Dynamic Bin Packing with Limited Repacking</dc:title>
 <dc:creator>Gupta, Anupam</dc:creator>
 <dc:creator>Guruganesh, Guru</dc:creator>
 <dc:creator>Kumar, Amit</dc:creator>
 <dc:creator>Wajc, David</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We consider the bin packing problem in a fully-dynamic setting, where new
items can arrive and old items may depart. The objective here is to obtain
algorithms achieving low asymptotic competitive ratio while changing the
packing sparingly between updates. We associate with each item $i$ a movement
cost $c_i\geq 0$. We wish to achieve good approximation guarantees while
incurring a movement cost of $\beta\cdot c_i$, either in the worst case, or in
an amortized sense, for $\beta$ as small as possible. We refer to this $\beta$
as the recourse of the algorithm.
  We obtain tight or near-tight results for this problem for the following
settings:
  (1) For general movement costs (the $c_i$s are unconstrained), we show that
with constant recourse one can almost match the best asymptotic competitive
ratio of online bin packing, and show a complementary lower bound:
fully-dynamic bin packing with small recourse is at least as hard as its online
counterpart.
  (2) For unit movement costs ($c_i=1$ for all $i$), we use an LP-based
approach to show a sharp threshold of $\alpha \approx 1.3871$. Specifically, we
show that for any $\epsilon&gt;0$, any algorithm with asymptotic competitive ratio
$\alpha-\epsilon$ must suffer either polynomially large additive terms or
recourse. On the positive side, for any $\epsilon&gt;0$, we give an algorithm with
asymptotic competitive ratio of $\alpha+\epsilon$, with an $O(\epsilon^{-2})$
additive term and recourse $O(\epsilon^{-2})$.
  (3) For volume movement costs ($c_i=s_i$ for all $i$), we show a tight
tradeoff between competitive ratio and amortized recourse.
  Hence, for amortized recourse, our work gives nearly-matching upper and lower
bounds for all these three natural settings. Our last two results add to the
small list of problems for which tight or nearly-tight tradeoffs between
amortized recourse and asymptotic competitive ratio are known.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02079</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cone Detection using a Combination of LiDAR and Vision-based Machine
  Learning</dc:title>
 <dc:creator>Messikommer, Nico</dc:creator>
 <dc:creator>Schaefer, Simon</dc:creator>
 <dc:creator>Dub&#xe9;, Renaud</dc:creator>
 <dc:creator>Pfeiffer, Mark</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The classification and the position estimation of objects become more and
more relevant as the field of robotics is expanding in diverse areas of
society. In this Bachelor Thesis, we developed a cone detection algorithm for
an autonomous car using a LiDAR sensor and a colour camera. By evaluating
simple constraints, the LiDAR detection algorithm preselects cone candidates in
the 3 dimensional space. The candidates are projected into the image plane of
the colour camera and an image candidate is cropped out. A convolutional neural
networks classifies the image candidates as cone or not a cone. With the fusion
of the precise position estimation of the LiDAR sensor and the high
classification accuracy of a neural network, a reliable cone detection
algorithm was implemented. Furthermore, a path planning algorithm generates a
path around the detected cones. The final system detects cones even at higher
velocity and has the potential to drive fully autonomous around the cones.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02085</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Speed Reading via Skim-RNN</dc:title>
 <dc:creator>Seo, Minjoon</dc:creator>
 <dc:creator>Min, Sewon</dc:creator>
 <dc:creator>Farhadi, Ali</dc:creator>
 <dc:creator>Hajishirzi, Hannaneh</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Inspired by the principles of speed reading, we introduce Skim-RNN, a
recurrent neural network (RNN) that dynamically decides to update only a small
fraction of the hidden state for relatively unimportant input tokens. Skim-RNN
gives computational advantage over an RNN that always updates the entire hidden
state. Skim-RNN uses the same input and output interfaces as a standard RNN and
can be easily used instead of RNNs in existing models. In our experiments, we
show that Skim-RNN can achieve significantly reduced computational cost without
losing accuracy compared to standard RNNs across five different natural
language tasks. In addition, we demonstrate that the trade-off between accuracy
and speed of Skim-RNN can be dynamically controlled during inference time in a
stable manner. Our analysis also shows that Skim-RNN running on a single CPU
offers lower latency compared to standard RNNs on GPUs.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02087</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Workflow-Based Big Data Analytics in The Cloud Environment Present
  Research Status and Future Prospects</dc:title>
 <dc:creator>Khan, Samiya</dc:creator>
 <dc:creator>Shakil, Kashish Ara</dc:creator>
 <dc:creator>Alam, Mansaf</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Workflow is a common term used to describe a systematic breakdown of tasks
that need to be performed to solve a problem. This concept has found best use
in scientific and business applications for streamlining and improving the
performance of the underlying processes targeted towards achieving an outcome.
The growing complexity of big data analytical problems has invited the use of
scientific workflows for performing complex tasks for specific domain
applications. This research investigates the efficacy of workflow-based big
data analytics in the cloud environment, giving insights on the research
already performed in the area and possible future research directions in the
field.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02087</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02088</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer activity learning from system call time series</dc:title>
 <dc:creator>Hastings, Curt</dc:creator>
 <dc:creator>Mainieri, Ronnie</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>68T05</dc:subject>
 <dc:description>  Using a previously introduced similarity function for the stream of system
calls generated by a computer, we engineer a program-in-execution classifier
using deep learning methods. Tested on malware classification, it significantly
outperforms current state of the art. We provide a series of performance
measures and tests to demonstrate the capabilities, including measurements from
production use. We show how the system scales linearly with the number of
endpoints. With the system we estimate the total number of malware families
created over the last 10 years as 3450, in line with reasonable economic
constraints. The more limited rate for new malware families than previously
acknowledged implies that machine learning malware classifiers risk being
tested on their training set; we achieve F1 = 0.995 in a test carefully
designed to mitigate this risk.
</dc:description>
 <dc:description>Comment: 27 pages, 6 figures</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02114</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounding and Counting Linear Regions of Deep Neural Networks</dc:title>
 <dc:creator>Serra, Thiago</dc:creator>
 <dc:creator>Tjandraatmadja, Christian</dc:creator>
 <dc:creator>Ramalingam, Srikumar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we study the representational power of deep neural networks
(DNN) that belong to the family of piecewise-linear (PWL) functions, based on
PWL activation units such as rectifier or maxout. We investigate the complexity
of such networks by studying the number of linear regions of the PWL function.
Typically, a PWL function from a DNN can be seen as a large family of linear
functions acting on millions of such regions. We directly build upon the work
of Montufar et al. (2014), Montufar (2017) and Raghu et al. (2017) by refining
the upper and lower bounds on the number of linear regions for rectified and
maxout networks. In addition to achieving tighter bounds, we also develop a
novel method to perform exact enumeration or counting of the number of linear
regions with a mixed-integer linear formulation that maps the input space to
output. We use this new capability to visualize how the number of linear
regions change while training DNNs.
</dc:description>
 <dc:description>Comment: Conference submission, version after rebuttal</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2018-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02120</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Small Resolution Proofs for QBF using Dependency Treewidth</dc:title>
 <dc:creator>Eiben, Eduard</dc:creator>
 <dc:creator>Ganian, Robert</dc:creator>
 <dc:creator>Ordyniak, Sebastian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In spite of the close connection between the evaluation of quantified Boolean
formulas (QBF) and propositional satisfiability (SAT), tools and techniques
which exploit structural properties of SAT instances are known to fail for QBF.
This is especially true for the structural parameter treewidth, which has
allowed the design of successful algorithms for SAT but cannot be
straightforwardly applied to QBF since it does not take into account the
interdependencies between quantified variables.
  In this work we introduce and develop dependency treewidth, a new structural
parameter based on treewidth which allows the efficient solution of QBF
instances. Dependency treewidth pushes the frontiers of tractability for QBF by
overcoming the limitations of previously introduced variants of treewidth for
QBF. We augment our results by developing algorithms for computing the
decompositions that are required to use the parameter.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02123</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistency of Maximum Likelihood for Continuous-Space Network Models</dc:title>
 <dc:creator>Shalizi, Cosma Rohilla</dc:creator>
 <dc:creator>Asta, Dena</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Network analysis needs tools to infer distributions over graphs of arbitrary
size from a single graph. Assuming the distribution is generated by a
continuous latent space model which obeys certain natural symmetry and
smoothness properties, we establish three levels of consistency for
non-parametric maximum likelihood inference as the number of nodes grows: (i)
the estimated locations of all nodes converge in probability on their true
locations; (ii) the distribution over locations in the latent space converges
on the true distribution; and (iii) the distribution over graphs of arbitrary
size converges.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02124</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Projection Theorems Using Effective Dimension</dc:title>
 <dc:creator>Lutz, Neil</dc:creator>
 <dc:creator>Stull, D. M.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  In this paper we use the theory of computing to study fractal dimensions of
projections in Euclidean spaces. A fundamental result in fractal geometry is
Marstrand's projection theorem, which shows that for every analytic set E, for
almost every line L, the Hausdorff dimension of the orthogonal projection of E
onto L is maximal. We use Kolmogorov complexity to give two new results on the
Hausdorff and packing dimensions of orthogonal projections onto lines. The
first shows that the conclusion of Marstrand's theorem holds whenever the
Hausdorff and packing dimensions agree on the set E, even if E is not analytic.
Our second result gives a lower bound on the packing dimension of projections
of arbitrary sets. Finally, we give a new proof of Marstrand's theorem using
the theory of computing.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02128</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequential Multi-Class Labeling in Crowdsourcing</dc:title>
 <dc:creator>Kang, Qiyu</dc:creator>
 <dc:creator>Tay, Wee Peng</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider a crowdsourcing platform where workers' responses to questions
posed by a crowdsourcer are used to determine the hidden state of a multi-class
labeling problem. As workers may be unreliable, we propose to perform
sequential questioning in which the questions posed to the workers are designed
based on previous questions and answers. We propose a Partially-Observable
Markov Decision Process (POMDP) framework to determine the best questioning
strategy, subject to the crowdsourcer's budget constraint. As this POMDP
formulation is in general intractable, we develop a suboptimal approach based
on a $q$-ary Ulam-R\'enyi game. We also propose a sampling heuristic, which can
be used in tandem with standard POMDP solvers, using our Ulam-R\'enyi strategy.
We demonstrate through simulations that our approaches outperform a
non-sequential strategy based on error correction coding and which does not
utilize workers' previous responses.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02131</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing Sparse Connectivity Patterns in Neural Networks</dc:title>
 <dc:creator>Dey, Sourya</dc:creator>
 <dc:creator>Huang, Kuan-Wen</dc:creator>
 <dc:creator>Beerel, Peter A.</dc:creator>
 <dc:creator>Chugg, Keith M.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel way of reducing the number of parameters in the
storage-hungry fully connected classification layers of a neural network by
using pre-defined sparsity, where the majority of connections are absent prior
to starting training. Our results indicate that convolutional neural networks
can operate without any loss of accuracy at less than 0.5% classification layer
connection density, or less than 5% overall network connection density. We also
investigate the effects of pre-defining the sparsity of networks with only
fully connected layers. Based on our sparsifying technique, we introduce the
`scatter' metric to characterize the quality of a particular connection
pattern. As proof of concept, we show results on CIFAR, MNIST and a new dataset
on classifying Morse code symbols, which highlights some interesting trends and
limits of sparse connection patterns.
</dc:description>
 <dc:description>Comment: Submitted to 6th International Conference on Learning Representations
  (ICLR 2018). Changed page header to reflect this, it was previously saying
  'Published ... in ICLR 2018'</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02132</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weighted Transformer Network for Machine Translation</dc:title>
 <dc:creator>Ahmed, Karim</dc:creator>
 <dc:creator>Keskar, Nitish Shirish</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  State-of-the-art results on neural machine translation often use attentional
sequence-to-sequence models with some form of convolution or recursion. Vaswani
et al. (2017) propose a new architecture that avoids recurrence and convolution
completely. Instead, it uses only self-attention and feed-forward layers. While
the proposed architecture achieves state-of-the-art results on several machine
translation tasks, it requires a large number of parameters and training
iterations to converge. We propose Weighted Transformer, a Transformer with
modified attention layers, that not only outperforms the baseline network in
BLEU score but also converges 15-40% faster. Specifically, we replace the
multi-head attention by multiple self-attention branches that the model learns
to combine during the training process. Our model improves the state-of-the-art
performance by 0.5 BLEU points on the WMT 2014 English-to-German translation
task and by 0.4 on the English-to-French translation task.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02137</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ICN-aware Network Slicing Framework for Mobile Data Distribution</dc:title>
 <dc:creator>Chakraborti, Asit</dc:creator>
 <dc:creator>Amin, Syed Obaid</dc:creator>
 <dc:creator>Azgin, Aytac</dc:creator>
 <dc:creator>Ravindran, Ravishankar</dc:creator>
 <dc:creator>Wang, Guoqiang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Network slicing offers an opportunity to realize ICN as a slice in 5G
deployment. We demonstrate this through a generic service orchestration
framework operating on commodity compute, storage and bandwidth resource pool
to realize multiple ICN service slices. Specifically, we show the dynamic
creation of real-time audio/video conferencing slices, over which
multi-participant communication is enabled. These slices leverage ICN features
of name-based routing, integrated security, inherent support for multicasting
and mobility, and in-network caching-and-computing to scale and deliver
services efficiently, while dynamically adapting to varying service demands.
Proposed framework also enables mobility-on-demand feature as a service over an
ICN slice to more effectively support producer mobility over multi-access
links, such as LTE, Wifi and Ethernet, as will be demonstrated with our demo.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02141</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal rates of entropy estimation over Lipschitz balls</dc:title>
 <dc:creator>Han, Yanjun</dc:creator>
 <dc:creator>Jiao, Jiantao</dc:creator>
 <dc:creator>Weissman, Tsachy</dc:creator>
 <dc:creator>Wu, Yihong</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  We consider the problem of minimax estimation of the entropy of a density
over Lipschitz balls. Dropping the usual assumption that the density is bounded
away from zero, we obtain the minimax rates $(n\ln n)^{-\frac{s}{s+d}} +
n^{-1/2}$ for $0&lt;s\leq 2$ in arbitrary dimension $d$, where $s$ is the
smoothness parameter and $n$ is the number of independent samples. Using a
two-stage approximation technique, which first approximate the density by its
kernel-smoothed version, and then approximate the non-smooth functional by
polynomials, we construct entropy estimators that attain the minimax rate of
convergence, shown optimal by matching lower bounds.
  One of the key steps in analyzing the bias relies on a novel application of
the Hardy-Littlewood maximal inequality, which also leads to a new inequality
on Fisher information that might be of independent interest.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02144</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Joint 3D-2D based Method for Free Space Detection on Roads</dc:title>
 <dc:creator>Patra, Suvam</dc:creator>
 <dc:creator>Maheshwari, Pranjal</dc:creator>
 <dc:creator>Yadav, Shashank</dc:creator>
 <dc:creator>Arora, Chetan</dc:creator>
 <dc:creator>Banerjee, Subhashis</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we address the problem of road segmentation and free space
detection in the context of autonomous driving. Traditional methods either use
3-dimensional (3D) cues such as point clouds obtained from LIDAR, RADAR or
stereo cameras or 2-dimensional (2D) cues such as lane markings, road
boundaries and object detection. Typical 3D point clouds do not have enough
resolution to detect fine differences in heights such as between road and
pavement. Image based 2D cues fail when encountering uneven road textures such
as due to shadows, potholes, lane markings or road restoration. We propose a
novel free road space detection technique combining both 2D and 3D cues. In
particular, we use CNN based road segmentation from 2D images and plane/box
fitting on sparse depth data obtained from SLAM as priors to formulate an
energy minimization using conditional random field (CRF), for road pixels
classification. While the CNN learns the road texture and is unaffected by
depth boundaries, the 3D information helps in overcoming texture based
classification failures. Finally, we use the obtained road segmentation with
the 3D depth data from monocular SLAM to detect the free space for the
navigation purposes. Our experiments on KITTI odometry dataset, Camvid dataset,
as well as videos captured by us, validate the superiority of the proposed
approach over the state of the art.
</dc:description>
 <dc:description>Comment: Accepted for publication at IEEE WACV 2018</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02149</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Disguised Plagiarism</dc:title>
 <dc:creator>Mahmoud, Hatem A.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Source code plagiarism detection is a problem that has been addressed several
times before; and several tools have been developed for that purpose. In this
research project we investigated a set of possible disguises that can be
mechanically applied to plagiarized source code to defeat plagiarism detection
tools. We propose a preprocessor to be used with existing plagiarism detection
tools to &quot;normalize&quot; source code before checking it, thus making such disguises
ineffective.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02150</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ADS: Adaptive and Dynamic Scaling Mechanism for Multimedia Conferencing
  Services in the Cloud</dc:title>
 <dc:creator>Soltanian, Abbas</dc:creator>
 <dc:creator>Naboulsi, Diala</dc:creator>
 <dc:creator>Salahuddin, Mohammad A.</dc:creator>
 <dc:creator>Glitho, Roch</dc:creator>
 <dc:creator>Elbiaze, Halima</dc:creator>
 <dc:creator>Wette, Constant</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Multimedia conferencing is used extensively in a wide range of applications,
such as online games and distance learning. These applications need to
efficiently scale the conference size as the number of participants fluctuates.
Cloud is a technology that addresses the scalability issue. However, the
proposed cloud-based solutions have several shortcomings in considering the
future demand of applications while meeting both Quality of Service (QoS)
requirements and efficiency in resource usage. In this paper, we propose an
Adaptive and Dynamic Scaling mechanism (ADS) for multimedia conferencing
services in the cloud. This mechanism enables scalable and elastic resource
allocation with respect to the number of participants. ADS produces a
cost-efficient scaling schedule while considering the QoS requirements and the
future demand of the conferencing service. We formulate the problem using
Integer Linear Programming (ILP) and design a heuristic for it. Simulation
results show that ADS mechanism elastically scales conferencing services.
Moreover, the ADS heuristic is shown to outperform a greedy algorithm from a
resource-efficiency perspective.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02152</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconstructing Gene Trees From Fitch's Xenology Relation</dc:title>
 <dc:creator>Gei&#xdf;, Manuela</dc:creator>
 <dc:creator>Anders, John</dc:creator>
 <dc:creator>Stadler, Peter F.</dc:creator>
 <dc:creator>Wieseke, Nicolas</dc:creator>
 <dc:creator>Hellmuth, Marc</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Two genes are xenologs in the sense of Fitch if they are separated by at
least one horizontal gene transfer event. Horizonal gene transfer is asymmetric
in the sense that the transferred copy is distinguished from the one that
remains within the ancestral lineage. Hence xenology is more precisely thought
of as a non-symmetric relation: y is xenologous to x if y has been horizontally
transferred at least once since it diverged from the least common ancestor of x
and y. We show that xenology relations are characterized by a small set of
forbidden induced subgraphs on three vertices. Furthermore, each xenology
relation can be derived from a unique least-resolved edge-labeled phylogenetic
tree. This tree and its edge labeling can be computed in polynomial time. The
fact that being a xenology relation is a heritable graph property, finally has
far-reaching consequences on approximation problems associated with xenology
relations.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02159</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Bayesian Sampling with Monte Carlo EM</dc:title>
 <dc:creator>Roychowdhury, Anirban</dc:creator>
 <dc:creator>Parthasarathy, Srinivasan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a novel technique for learning the mass matrices in samplers
obtained from discretized dynamics that preserve some energy function. Existing
adaptive samplers use Riemannian preconditioning techniques, where the mass
matrices are functions of the parameters being sampled. This leads to
significant complexities in the energy reformulations and resultant dynamics,
often leading to implicit systems of equations and requiring inversion of
high-dimensional matrices in the leapfrog steps. Our approach provides a
simpler alternative, by using existing dynamics in the sampling step of a Monte
Carlo EM framework, and learning the mass matrices in the M step with a novel
online technique. We also propose a way to adaptively set the number of samples
gathered in the E step, using sampling error estimates from the leapfrog
dynamics. Along with a novel stochastic sampler based on Nos\'{e}-Poincar\'{e}
dynamics, we use this framework with standard Hamiltonian Monte Carlo (HMC) as
well as newer stochastic algorithms such as SGHMC and SGNHT, and show strong
performance on synthetic and real high-dimensional sampling scenarios; we
achieve sampling accuracies comparable to Riemannian samplers while being
significantly faster.
</dc:description>
 <dc:description>Comment: In Proc. 30th Advances in Neural Information Processing Systems
  (NIPS), 2017 (to appear)</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02161</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Fr\'echet distance of surfaces is computable</dc:title>
 <dc:creator>Neumann, Eike</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We show that the Fr\'echet distance of two-dimensional parametrised surfaces
in a metric space is computable. This settles a long-standing open question in
computational geometry.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02162</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TAMU at KBP 2017: Event Nugget Detection and Coreference Resolution</dc:title>
 <dc:creator>Choubey, Prafulla Kumar</dc:creator>
 <dc:creator>Huang, Ruihong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we describe TAMU's system submitted to the TAC KBP 2017 event
nugget detection and coreference resolution task. Our system builds on the
statistical and empirical observations made on training and development data.
We found that modifiers of event nuggets tend to have unique syntactic
distribution. Their parts-of-speech tags and dependency relations provides them
essential characteristics that are useful in identifying their span and also
defining their types and realis status. We further found that the joint
modeling of event span detection and realis status identification performs
better than the individual models for both tasks. Our simple system designed
using minimal features achieved the micro-average F1 scores of 57.72, 44.27 and
42.47 for event span detection, type identification and realis status
classification tasks respectively. Also, our system achieved the CoNLL F1 score
of 27.20 in event coreference resolution task.
</dc:description>
 <dc:description>Comment: TAC KBP 2017</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02165</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The menu complexity of &quot;one-and-a-half-dimensional&quot; mechanism design</dc:title>
 <dc:creator>Saxena, Raghuvansh R.</dc:creator>
 <dc:creator>Schvartzman, Ariel</dc:creator>
 <dc:creator>Weinberg, S. Matthew</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study the menu complexity of optimal and approximately-optimal auctions in
the context of the &quot;FedEx&quot; problem, a so-called &quot;one-and-a-half-dimensional&quot;
setting where a single bidder has both a value and a deadline for receiving an
[FGKK16]. The menu complexity of an auction is equal to the number of distinct
(allocation, price) pairs that a bidder might receive [HN13]. We show the
following when the bidder has $n$ possible deadlines:
  - Exponential menu complexity is necessary to be exactly optimal: There exist
instances where the optimal mechanism has menu complexity is $2^n-1$. This
matches exactly the upper bound provided by Fiat et al.'s algorithm, and
resolves one of their open questions [FGKK16].
  - Fully polynomial menu complexity is necessary and sufficient for
approximation: For all instances, there exists a mechanism guaranteeing a
multiplicative (1-\epsilon)-approximation to the optimal revenue with menu
complexity $O(n^{3/2}\sqrt{\frac{\min\{n/\epsilon,\ln(v_{\max})\}}{\epsilon}})
= O(n^2/\epsilon)$, where $v_{\max}$ denotes the largest value in the support
of integral distributions.
  - There exist instances where any mechanism guaranteeing a multiplicative
$(1-O(1/n^2))$-approximation to the optimal revenue requires menu complexity
$\Omega(n^2)$.
  Our main technique is the polygon approximation of concave functions
[Rote19], and our results here should be of independent interest. We further
show how our techniques can be used to resolve an open question of [DW17] on
the menu complexity of optimal auctions for a budget-constrained buyer.
</dc:description>
 <dc:description>Comment: Accepted to SODA 2018</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02168</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Monetary Loss Due to Passive and Active Attacks on MIMO Smart
  Grid Communications</dc:title>
 <dc:creator>Shafie, Ahmed El</dc:creator>
 <dc:creator>Chihaoui, Hamadi</dc:creator>
 <dc:creator>Hamila, Ridha</dc:creator>
 <dc:creator>Al-Dhahir, Naofal</dc:creator>
 <dc:creator>Gastli, Adel</dc:creator>
 <dc:creator>Ben-Brahim, Lazhar</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider multiple source nodes (consumers) communicating wirelessly their
energy demands to the meter data-management system (MDMS) over the subarea
gateway(s). We quantify the impacts of passive and active security attacks on
the wireless communications system's reliability and security as well as the
energy-demand estimation-error cost in dollars paid by the utility. We adopt a
multiple-input multiple-output multi-antenna-eavesdropper (MIMOME) wiretap
channel model. To secure the MIMO wireless communication system, the legitimate
nodes generate artificial noise (AN) vectors to mitigate the effect of the
passive eavesdropping attacks. In addition, we propose a redundant design where
multiple gateways are assumed to coexist in each subarea to forward the
consumers' energy-demand messages. We quantify the redundant designs impact on
the communication reliability between the consumers and the MDMS and on the
energy-demand estimation-error cost.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02173</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthetic and Natural Noise Both Break Neural Machine Translation</dc:title>
 <dc:creator>Belinkov, Yonatan</dc:creator>
 <dc:creator>Bisk, Yonatan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Character-based neural machine translation (NMT) models alleviate
out-of-vocabulary issues, learn morphology, and move us closer to completely
end-to-end translation systems. Unfortunately, they are also very brittle and
easily falter when presented with noisy data. In this paper, we confront NMT
models with synthetic and natural sources of noise. We find that
state-of-the-art models fail to translate even moderately noisy texts that
humans have no trouble comprehending. We explore two approaches to increase
model robustness: structure-invariant word representations and robust training
on noisy texts. We find that a model based on a character convolutional neural
network is able to simultaneously learn representations robust to multiple
kinds of noise.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02173</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02181</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile Encryption Gateway (MEG) for Email Encryption</dc:title>
 <dc:creator>Rehm, Gregory B</dc:creator>
 <dc:creator>Thompson, Michael</dc:creator>
 <dc:creator>Busenius, Brad</dc:creator>
 <dc:creator>Fowler, Jennifer</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Email cryptography applications often suffer from major problems that prevent
their widespread implementation. MEG, or the Mobile Encryption Gateway aims to
fix the issues associated with email encryption by ensuring that encryption is
easy to perform while still maintaining data security. MEG performs automatic
decryption and encryption of all emails using PGP. Users do not need to
understand the internal workings of the encryption process to use the
application. MEG is meant to be email-client-agnostic, enabling users to employ
virtually any email service to send messages. Encryption actions are performed
on the user's mobile device, which means their keys and data remain personal.
MEG can also tackle network effect problems by inviting non-users to join. Most
importantly, MEG uses end-to-end encryption, which ensures that all aspects of
the encrypted information remains private. As a result, we are hopeful that MEG
will finally solve the problem of practical email encryption.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02186</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quickest Change Detection under Transient Dynamics: Theory and
  Asymptotic Analysis</dc:title>
 <dc:creator>Zou, Shaofeng</dc:creator>
 <dc:creator>Fellouris, Georgios</dc:creator>
 <dc:creator>Veeravalli, Venugopal V.</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The problem of quickest change detection (QCD) under transient dynamics is
studied, where the change from the initial distribution to the final persistent
distribution does not happen instantaneously, but after a series of transient
phases. The observations within the different phases are generated by different
distributions. The objective is to detect the change as quickly as possible,
while controlling the average run length (ARL) to false alarm, when the
durations of the transient phases are completely unknown. Two algorithms are
considered, the dynamic Cumulative Sum (CuSum) algorithm, proposed in earlier
work, and a newly constructed weighted dynamic CuSum algorithm. Both algorithms
admit recursions that facilitate their practical implementation, and they are
adaptive to the unknown transient durations. Specifically, their asymptotic
optimality is established with respect to both Lorden's and Pollak's criteria
as the ARL to false alarm and the durations of the transient phases go to
infinity at any relative rate. Numerical results are provided to demonstrate
the adaptivity of the proposed algorithms, and to validate the theoretical
results.
</dc:description>
 <dc:description>Comment: submitted to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02194</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Derandomizing Local Distributed Algorithms</dc:title>
 <dc:creator>Ghaffari, Mohsen</dc:creator>
 <dc:creator>Harris, David G.</dc:creator>
 <dc:creator>Kuhn, Fabian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The gap between the known randomized and deterministic local distributed
algorithms underlies arguably the most fundamental and central open question in
distributed graph algorithms. In this paper, we develop a generic and clean
recipe for derandomizing randomized LOCAL algorithms and transforming them into
efficient deterministic LOCAL algorithm. We also exhibit how this simple recipe
leads to significant improvements on a number of problems, in cases resolving
known open problems. Two sample end-results are as follows:
  - An improved distributed hypergraph maximal matching algorithm, which
improves on that of Fischer, Ghaffari, and Kuhn [FOCS'17], and leads to
improved algorithms for edge-coloring, maximum matching approximation, and low
out-degree edge orientation. The first gives an improved algorithm for Open
Problem 11.4 of the book of Barenboim and Elkin, and the last gives the first
positive resolution of their Open Problem 11.10.
  - An improved distributed algorithm for the Lov\'{a}sz Local Lemma, which
gets closer to a conjecture of Chang and Pettie [FOCS'17], and moreover leads
to improved distributed algorithms for problems such as defective coloring and
$k$-SAT.
</dc:description>
 <dc:description>Comment: 37 pages</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02195</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alpha-expansion is Exact on Stable Instances</dc:title>
 <dc:creator>Lang, Hunter</dc:creator>
 <dc:creator>Sontag, David</dc:creator>
 <dc:creator>Vijayaraghavan, Aravindan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Approximate algorithms for structured prediction problems---such as the
popular alpha-expansion algorithm (Boykov et al. 2001) in computer
vision---typically far exceed their theoretical performance guarantees on
real-world instances. These algorithms often find solutions that are very close
to optimal. The goal of this paper is to partially explain the performance of
alpha-expansion on MAP inference in Ferromagnetic Potts models (FPMs). Our main
results use the connection between energy minimization in FPMs and the Uniform
Metric Labeling problem to give a stability condition under which the
alpha-expansion algorithm provably recovers the optimal MAP solution. This
theoretical result complements the numerous empirical observations of
alpha-expansion's performance. Additionally, we give a different stability
condition under which an LP-based algorithm recovers the optimal solution.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02198</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regret Bounds and Regimes of Optimality for User-User and Item-Item
  Collaborative Filtering</dc:title>
 <dc:creator>Bresler, Guy</dc:creator>
 <dc:creator>Karzand, Mina</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider an online model for recommendation systems, with each user being
recommended an item at each time-step and providing 'like' or 'dislike'
feedback. A latent variable model specifies the user preferences: both users
and items are clustered into types. All users of a given type have identical
preferences for the items, and similarly, items of a given type are either all
liked or all disliked by a given user. The model captures structure in both the
item and user spaces, and in this paper, we assume that the type preference
matrix is randomly generated. We describe two algorithms inspired by user-user
and item-item collaborative filtering (CF), modified to explicitly make
exploratory recommendations, and prove performance guarantees in terms of their
expected regret. For two regimes of model parameters, with structure only in
item space or only in user space, we prove information-theoretic lower bounds
on regret that match our upper bounds up to logarithmic factors. Our analysis
elucidates system operating regimes in which existing CF algorithms are nearly
optimal.
</dc:description>
 <dc:description>Comment: 37 pages</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02201</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reactive Integrated Mission and Motion planning</dc:title>
 <dc:creator>Partovi, Alireza</dc:creator>
 <dc:creator>da Silva, Rafael Rodrigues</dc:creator>
 <dc:creator>Lin, Hai</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Correct-by-construction manipulation planning in a dynamic environment, where
other agents can manipulate objects in the workspace, is a challenging problem.
The tight coupling of actions and motions between agents and complexity of
mission specifications makes the problem computationally intractable.
  This paper presents a reactive integrated mission and motion planning for
mobile-robot manipulator systems operating in a partially known environment. We
introduce a multi-layered synergistic framework that receives high-level
mission specifications expressed in linear temporal logic and generates
dynamically-feasible and collision-free motion trajectories to achieve it. In
the high-level layer, a mission planner constructs a symbolic two-player game
between the robots and their environment to synthesis a strategy that adapts to
changes in the workspace imposed by other robots. A bilateral synergistic layer
is developed to map the designed mission plan to an integrated task and motion
planner, constructing a set of robot tasks to move the objects according to the
mission strategy. In the low-level planning stage, verifiable motion
controllers are designed that can be incrementally composed to guarantee a safe
motion planning for each high-level induced task. The proposed framework is
illustrated with a multi-robot warehouse example with the mission of moving
objects to various locations.
</dc:description>
 <dc:description>Comment: ACC 2018 Conference</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02207</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Language-Universal End-to-End Speech Recognition</dc:title>
 <dc:creator>Kim, Suyoun</dc:creator>
 <dc:creator>Seltzer, Michael L.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Building speech recognizers in multiple languages typically involves
replicating a monolingual training recipe for each language, or utilizing a
multi-task learning approach where models for different languages have separate
output labels but share some internal parameters. In this work, we exploit
recent progress in end-to-end speech recognition to create a single
multilingual speech recognition system capable of recognizing any of the
languages seen in training. To do so, we propose the use of a universal
character set that is shared among all languages. We also create a
language-specific gating mechanism within the network that can modulate the
network's internal representations in a language-specific way. We evaluate our
proposed approach on the Microsoft Cortana task across three languages and show
that our system outperforms both the individual monolingual systems and systems
built with a multi-task learning approach. We also show that this model can be
used to initialize a monolingual speech recognizer, and can be used to create a
bilingual model for use in code-switching scenarios.
</dc:description>
 <dc:description>Comment: submitted to ICASSP 2018</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02209</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning of Semantic Audio Representations</dc:title>
 <dc:creator>Jansen, Aren</dc:creator>
 <dc:creator>Plakal, Manoj</dc:creator>
 <dc:creator>Pandya, Ratheet</dc:creator>
 <dc:creator>Ellis, Daniel P. W.</dc:creator>
 <dc:creator>Hershey, Shawn</dc:creator>
 <dc:creator>Liu, Jiayang</dc:creator>
 <dc:creator>Moore, R. Channing</dc:creator>
 <dc:creator>Saurous, Rif A.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Even in the absence of any explicit semantic annotation, vast collections of
audio recordings provide valuable information for learning the categorical
structure of sounds. We consider several class-agnostic semantic constraints
that apply to unlabeled nonspeech audio: (i) noise and translations in time do
not change the underlying sound category, (ii) a mixture of two sound events
inherits the categories of the constituents, and (iii) the categories of events
in close temporal proximity are likely to be the same or related. Without
labels to ground them, these constraints are incompatible with classification
loss functions. However, they may still be leveraged to identify geometric
inequalities needed for triplet loss-based training of convolutional neural
networks. The result is low-dimensional embeddings of the input spectrograms
that recover 41% and 84% of the performance of their fully-supervised
counterparts when applied to downstream query-by-example sound retrieval and
sound event classification tasks, respectively. Moreover, in
limited-supervision settings, our unsupervised embeddings double the
state-of-the-art classification performance.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02211</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Welfare and Profit Maximization from Revealed Preferences</dc:title>
 <dc:creator>Ji, Ziwei</dc:creator>
 <dc:creator>Mehta, Ruta</dc:creator>
 <dc:creator>Telgarsky, Matus</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Consider the seller's problem of finding &quot;optimal&quot; prices for her (divisible)
goods when faced with a set of consumers, given that she can only observe their
purchased bundles at set prices, i.e., access to only revealed preferences
(demand oracle). We study both social welfare and profit maximization under
this setting, assuming concave valuation function of consumers and convex
production cost function of the seller, standard assumptions in economics.
  Recent series of works (Roth et al., 2016, 2017) studied this problem for
various special cases of valuation and cost functions, while making no
assumption on the demand oracle. In this work, for social-welfare maximization,
we obtain a natural interpretation of the revealed preference feedback in the
dual optimization problem, and thereby obtain a simple gradient based
algorithm. This simplifies and improves on (Roth et al., 2016, 2017) at least
by a quadratic factor in terms of query complexity.
  Second, we study social-welfare maximization under the online setting, where
consumers arrive one-by-one in a {\em random order} a.k.a. secretary model. For
the case where consumer valuation can be arbitrary continuous function, we
design a price posting mechanism that achieves average expected social welfare
up to an additive factor of $\frac{1}{\sqrt{m}}$ of maximum social welfare,
where $m$ is the number of consumers.
  Third, for the profit maximization, we obtain the first FPTAS when valuation
and cost functions are separable, with a matching lower bound. For the
non-separable case we show that no PTAS exists, even when only cost function is
non-separable.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02212</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved training for online end-to-end speech recognition systems</dc:title>
 <dc:creator>Kim, Suyoun</dc:creator>
 <dc:creator>Seltzer, Michael L.</dc:creator>
 <dc:creator>Li, Jinyu</dc:creator>
 <dc:creator>Zhao, Rui</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Achieving high accuracy with end-to-end speech recognizers requires careful
parameter initialization prior to training. Otherwise, the networks may fail to
find a good local optimum. This is particularly true for low-latency online
networks, such as unidirectional LSTMs. Currently, the best strategy to train
such systems is to bootstrap the training from a tied-triphone system. However,
this is time consuming, and more importantly, is impossible for languages
without a high-quality pronunciation lexicon. In this work, we propose an
initialization strategy that uses teacher-student learning to transfer
knowledge from a large, well-trained, offline end-to-end speech recognition
model to an online end-to-end model, eliminating the need for a lexicon or any
other linguistic resources. We also explore curriculum learning and label
smoothing and show how they can be combined with the proposed teacher-student
learning for further improvements. We evaluate our methods on a Microsoft
Cortana personal assistant task and show that the proposed method results in a
19% relative improvement in word error rate compared to a randomly-initialized
baseline system.
</dc:description>
 <dc:description>Comment: submitted to ICASSP 2018</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02213</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep
  Neural Networks</dc:title>
 <dc:creator>K&#xf6;ster, Urs</dc:creator>
 <dc:creator>Webb, Tristan J.</dc:creator>
 <dc:creator>Wang, Xin</dc:creator>
 <dc:creator>Nassar, Marcel</dc:creator>
 <dc:creator>Bansal, Arjun K.</dc:creator>
 <dc:creator>Constable, William H.</dc:creator>
 <dc:creator>Elibol, O&#x11f;uz H.</dc:creator>
 <dc:creator>Gray, Scott</dc:creator>
 <dc:creator>Hall, Stewart</dc:creator>
 <dc:creator>Hornof, Luke</dc:creator>
 <dc:creator>Khosrowshahi, Amir</dc:creator>
 <dc:creator>Kloss, Carey</dc:creator>
 <dc:creator>Pai, Ruby J.</dc:creator>
 <dc:creator>Rao, Naveen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep neural networks are commonly developed and trained in 32-bit floating
point format. Significant gains in performance and energy efficiency could be
realized by training and inference in numerical formats optimized for deep
learning. Despite advances in limited precision inference in recent years,
training of neural networks in low bit-width remains a challenging problem.
Here we present the Flexpoint data format, aiming at a complete replacement of
32-bit floating point format training and inference, designed to support modern
deep network topologies without modifications. Flexpoint tensors have a shared
exponent that is dynamically adjusted to minimize overflows and maximize
available dynamic range. We validate Flexpoint by training AlexNet, a deep
residual network and a generative adversarial network, using a simulator
implemented with the neon deep learning framework. We demonstrate that 16-bit
Flexpoint closely matches 32-bit floating point in training all three models,
without any need for tuning of model hyperparameters. Our results suggest
Flexpoint as a promising numerical format for future hardware for training and
inference.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures, accepted in Neural Information Processing
  Systems 2017</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02216</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SegICP-DSR: Dense Semantic Scene Reconstruction and Registration</dc:title>
 <dc:creator>Wong, Jay M.</dc:creator>
 <dc:creator>Wagner, Syler</dc:creator>
 <dc:creator>Lawson, Connor</dc:creator>
 <dc:creator>Kee, Vincent</dc:creator>
 <dc:creator>Hebert, Mitchell</dc:creator>
 <dc:creator>Rooney, Justin</dc:creator>
 <dc:creator>Mariottini, Gian-Luca</dc:creator>
 <dc:creator>Russell, Rebecca</dc:creator>
 <dc:creator>Schneider, Abraham</dc:creator>
 <dc:creator>Chipalkatty, Rahul</dc:creator>
 <dc:creator>Johnson, David M. S.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  To enable autonomous robotic manipulation in unstructured environments, we
present SegICP-DSR, a real- time, dense, semantic scene reconstruction and pose
estimation algorithm that achieves mm-level pose accuracy and standard
deviation (7.9 mm, {\sigma}=7.6 mm and 1.7 deg, {\sigma}=0.7 deg) and suc-
cessfully identified the object pose in 97% of test cases. This represents a
29% increase in accuracy, and a 14% increase in success rate compared to SegICP
in cluttered, unstruc- tured environments. The performance increase of
SegICP-DSR arises from (1) improved deep semantic segmentation under
adversarial training, (2) precise automated calibration of the camera intrinsic
and extrinsic parameters, (3) viewpoint specific ray-casting of the model
geometry, and (4) dense semantic ElasticFusion point clouds for registration.
We benchmark the performance of SegICP-DSR on thousands of pose-annotated video
frames and demonstrate its accuracy and efficacy on two tight tolerance
grasping and insertion tasks using a KUKA LBR iiwa robotic arm.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02217</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Segmentation of Multi-Shaped Overlapping Objects</dc:title>
 <dc:creator>Abhinav, Kumar</dc:creator>
 <dc:creator>Chauhan, Jaideep Singh</dc:creator>
 <dc:creator>Sarkar, Debasis</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we propose a new segmentation algorithm for images containing
convex objects present in multiple shapes with a high degree of overlap. The
proposed algorithm is carried out in two steps, first we identify the visible
contours, segment them using concave points and finally group the segments
belonging to the same object. The next step is to assign a shape identity to
these grouped contour segments. For images containing objects in multiple
shapes we begin first by identifying shape classes of the contours followed by
assigning a shape entity to these classes. We provide a comprehensive
experimentation of our algorithm on two crystal image datasets. One dataset
comprises of images containing objects in multiple shapes overlapping each
other and the other dataset contains standard images with objects present in a
single shape. We test our algorithm against two baselines, with our proposed
algorithm outperforming both the baselines.
</dc:description>
 <dc:description>Comment: Accepted at VISAPP 2018</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02220</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mode Selection Schemes for D2D Enabled Aerial Networks</dc:title>
 <dc:creator>Omri, Aymen</dc:creator>
 <dc:creator>Hasna, Mazen O.</dc:creator>
 <dc:creator>Shakir, Muhammad Zeeshan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we present and evaluate the effect of two mode selection
schemes for device to device (D2D) enabled areal netwroks. The two schemes are
based on a threshold received signal strength (RSS) and an average threshold
D2D distance between two given users to select the D2D mode. While one scheme
triggers the D2D mode based on distance values only, the other scheme can
trigger D2D mode for larger distances if a minimum RSS value is received, for
it to maximize connectivity regions. Numerical results show the advantage of
the presented schemes in offloading traffic from aerial platforms and the
effect of the environment on the performance of D2D enabled aerial networks.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Wireless Communication Letters</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02221</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Linear Variational Principle for Riemann Mapping and Discrete
  Conformality</dc:title>
 <dc:creator>Dym, Nadav</dc:creator>
 <dc:creator>Lipman, Yaron</dc:creator>
 <dc:creator>Slutsky, Raz</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Complex Variables</dc:subject>
 <dc:description>  We consider Riemann mappings from bounded Lipschitz domains in the plane to a
triangle. We show that in this case the Riemann mapping has a linear
variational principle: it is the minimizer of the Dirichlet energy over an
appropriate affine space. By discretizing the variational principle in a
natural way we obtain discrete conformal maps which can be computed by solving
a sparse linear system. We show that these discrete conformal maps converge to
the Riemann mapping uniformly and in $H^1$. Additionally, the discrete
conformal maps are known to be bijective, and we show that the Riemann mapping
between two bounded Lipschitz domains can be approximated arbitrarily well by
composing the Riemann mapping between each Lipschitz domain and the triangle.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02222</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information-Dense Nonlinear Photonic Physical Unclonable Function</dc:title>
 <dc:creator>Grubel, Brian C.</dc:creator>
 <dc:creator>Bosworth, Bryan T.</dc:creator>
 <dc:creator>Kossey, Michael R.</dc:creator>
 <dc:creator>Cooper, A. Brinton</dc:creator>
 <dc:creator>Foster, Mark A.</dc:creator>
 <dc:creator>Foster, Amy C.</dc:creator>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present a comprehensive investigation into the complexity of a new private
key storage apparatus: a novel silicon photonic physical unclonable function
(PUF) based on ultrafast nonlinear optical interactions in a chaotic silicon
microcavity that is both unclonable and impossible to emulate. This device
provides remarkable improvements to total information content (raw
cryptographic material), information density, and key generation rates over
existing optical scattering PUFs and is also more easily integrated with both
CMOS electronics and telecommunications hardware. Our device exploits the
natural nonlinear optical behavior of silicon to neutralize commonly used
attacks against PUFs and vastly enhance device complexity. We confirm this
phenomenon with thorough experimental results on prototype devices and present
a detailed estimate of their total information content. Our compact,
micron-scale approach represents an entirely new generation of ultrafast and
high information density photonic PUF devices that can be directly incorporated
into integrated circuits to ensure authenticity and provide secure physical
storage of private key material.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02229</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence Pairs with Lowest Combined Autocorrelation and Crosscorrelation</dc:title>
 <dc:creator>Katz, Daniel J.</dc:creator>
 <dc:creator>Moore, Eli</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Complex Variables</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>94A55, 42A05, 11B83</dc:subject>
 <dc:description>  For a pair $(f,g)$ of sequences of length $\ell$ whose terms are in
$\{-1,1\}$, Pursley and Sarwate established a lower bound on a combined measure
of crosscorrelation and autocorrelation for $f$ and $g$. They showed that the
sum of the mean square crosscorrelation between $f$ and $g$ and the geometric
mean of $f$'s mean square autocorrelation and $g$'s mean square autocorrelation
must be at least $1$. For randomly selected binary sequences, this quantity is
typically about $2$. In this paper, we show that Pursley and Sarwate's bound is
met precisely when $(f,g)$ is a Golay complementary pair. This result
generalizes to sequences whose terms are arbitrary complex numbers.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02231</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visually-Aware Fashion Recommendation and Design with Generative Image
  Models</dc:title>
 <dc:creator>Kang, Wang-Cheng</dc:creator>
 <dc:creator>Fang, Chen</dc:creator>
 <dc:creator>Wang, Zhaowen</dc:creator>
 <dc:creator>McAuley, Julian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Building effective recommender systems for domains like fashion is
challenging due to the high level of subjectivity and the semantic complexity
of the features involved (i.e., fashion styles). Recent work has shown that
approaches to `visual' recommendation (e.g.~clothing, art, etc.) can be made
more accurate by incorporating visual signals directly into the recommendation
objective, using `off-the-shelf' feature representations derived from deep
networks. Here, we seek to extend this contribution by showing that
recommendation performance can be significantly improved by learning `fashion
aware' image representations directly, i.e., by training the image
representation (from the pixel level) and the recommender system jointly; this
contribution is related to recent work using Siamese CNNs, though we are able
to show improvements over state-of-the-art recommendation techniques such as
BPR and variants that make use of pre-trained visual features. Furthermore, we
show that our model can be used \emph{generatively}, i.e., given a user and a
product category, we can generate new images (i.e., clothing items) that are
most consistent with their personal taste. This represents a first step towards
building systems that go beyond recommending existing items from a product
corpus, but which can be used to suggest styles and aid the design of new
products.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures. Accepted by ICDM'17 as a long paper</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02232</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Realizing ICN in 3GPP's 5G NextGen Core Architecture</dc:title>
 <dc:creator>Ravindran, Ravishankar</dc:creator>
 <dc:creator>Chakraborti, Asit</dc:creator>
 <dc:creator>Amin, Syed Obaid</dc:creator>
 <dc:creator>Azgin, Aytac</dc:creator>
 <dc:creator>Wang, Guoqiang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The proposed 3GPP's 5G Next-generation (NextGen) Core architecture (5GC)
enables the ability to introduce new user and control plane functions within
the context of network slicing to allow greater flexibility in handling of
heterogeneous devices and applications. In this paper, we discuss the
integration of such architecture with future networking technologies by
focusing on the information centric networking (ICN) technology. For that
purpose, we first provide a short description of the proposed 5GC, which is
followed by a discussion on the extensions to 5GC's control and user planes to
support Protocol Data Unit (PDU) sessions from ICN. To illustrate the value of
enabling ICN within 5GC, we focus on two important network services that can be
enabled by ICN data networks. The first case targets mobile edge computing for
a connected car use case, whereas the second case targets seamless mobility
support for ICN sessions. We present these discussions in consideration with
the procedures proposed by 3GPP's 23.501 and 23.502 technical specifications.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02233</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rudin-Shapiro-Like Polynomials with Maximum Asymptotic Merit Factor</dc:title>
 <dc:creator>Katz, Daniel J.</dc:creator>
 <dc:creator>Trunov, Stanislav A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Complex Variables</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>42A05, 94A55, 11B83</dc:subject>
 <dc:description>  Borwein and Mossinghoff investigated the Rudin-Shapiro-like polynomials,
which are infinite families of Littlewood polynomials, that is, polynomials
whose coefficients are all in $\{-1,1\}$. Each family of Rudin-Shapiro-like
polynomials is obtained from a starting polynomial (which we call the seed) by
a recursive construction. These polynomials can be regarded as binary
sequences. Borwein and Mossinghoff show that the asymptotic autocorrelation
merit factor for any such family is at most $3$, and found the seeds of length
$40$ or less that produce the maximum asymptotic merit factor of $3$. The
definition of Rudin-Shapiro-like polynomials was generalized by Katz, Lee, and
Trunov to include polynomials with arbitrary complex coefficients, with the
sole condition that the seed polynomial must have a nonzero constant
coefficient. They proved that the maximum asymptotic merit factor is $3$ for
this larger class. Here we show that a family of such Rudin-Shapiro-like
polynomials achieves asymptotic merit factor $3$ if and only if the seed is the
interleaving of a pair of Golay complementary sequences.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02235</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encoding Neural and Synaptic Functionalities in Electron Spin: A Pathway
  to Efficient Neuromorphic Computing</dc:title>
 <dc:creator>Sengupta, Abhronil</dc:creator>
 <dc:creator>Roy, Kaushik</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Present day computers expend orders of magnitude more computational resources
to perform various cognitive and perception related tasks that humans routinely
perform everyday. This has recently resulted in a seismic shift in the field of
computation where research efforts are being directed to develop a
neurocomputer that attempts to mimic the human brain by nanoelectronic
components and thereby harness its efficiency in recognition problems. Bridging
the gap between neuroscience and nanoelectronics, this paper attempts to
provide a review of the recent developments in the field of spintronic device
based neuromorphic computing. Description of various spin-transfer torque
mechanisms that can be potentially utilized for realizing device structures
mimicking neural and synaptic functionalities is provided. A cross-layer
perspective extending from the device to the circuit and system level is
presented to envision the design of an All-Spin neuromorphic processor enabled
with on-chip learning functionalities. Device-circuit-algorithm co-simulation
framework calibrated to experimental results suggest that such All-Spin
neuromorphic systems can potentially achieve almost two orders of magnitude
energy improvement in comparison to state-of-the-art CMOS implementations.
</dc:description>
 <dc:description>Comment: The paper will appear in a future issue of Applied Physics Reviews</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02245</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Challenges in Disentangling Independent Factors of Variation</dc:title>
 <dc:creator>Szab&#xf3;, Attila</dc:creator>
 <dc:creator>Hu, Qiyang</dc:creator>
 <dc:creator>Portenier, Tiziano</dc:creator>
 <dc:creator>Zwicker, Matthias</dc:creator>
 <dc:creator>Favaro, Paolo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the problem of building models that disentangle independent factors
of variation. Such models could be used to encode features that can efficiently
be used for classification and to transfer attributes between different images
in image synthesis. As data we use a weakly labeled training set. Our weak
labels indicate what single factor has changed between two data samples,
although the relative value of the change is unknown. This labeling is of
particular interest as it may be readily available without annotation costs. To
make use of weak labels we introduce an autoencoder model and train it through
constraints on image pairs and triplets. We formally prove that without
additional knowledge there is no guarantee that two images with the same factor
of variation will be mapped to the same feature. We call this issue the
reference ambiguity. Moreover, we show the role of the feature dimensionality
and adversarial training. We demonstrate experimentally that the proposed model
can successfully transfer attributes on several datasets, but show also cases
when the reference ambiguity occurs.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2018</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02246</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Theory of Slicing for Probabilistic Control-Flow Graphs</dc:title>
 <dc:creator>Amtoft, Torben</dc:creator>
 <dc:creator>Banerjee, Anindya</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present a theory for slicing probabilistic imperative programs --
containing random assignments, and ``observe'' statements (for conditioning) --
represented as probabilistic control-flow graphs (pCFGs) whose nodes modify
probability distributions.
  We show that such a representation allows direct adaptation of standard
machinery such as data and control dependence, postdominators, relevant
variables, etc to the probabilistic setting. We separate the specification of
slicing from its implementation: first we develop syntactic conditions that a
slice must satisfy; next we prove that any such slice is semantically correct;
finally we give an algorithm to compute the least slice. To generate smaller
slices, we may in addition take advantage of knowledge that certain loops will
terminate (almost) always.
  A key feature of our syntactic conditions is that they involve two disjoint
slices such that the variables of one slice are probabilistically independent
of the variables of the other. This leads directly to a proof of correctness of
probabilistic slicing. In a companion article we show adequacy of the semantics
of pCFGs with respect to the standard semantics of structured probabilistic
programs.
</dc:description>
 <dc:description>Comment: Expanded and revised version of a paper originally appearing in
  Foundations of Software Science and Computation Structures - 19th
  International Conference, FOSSACS 2016</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02254</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Doppler-Radar Based Hand Gesture Recognition System Using Convolutional
  Neural Networks</dc:title>
 <dc:creator>Zhang, Jiajun</dc:creator>
 <dc:creator>Tao, Jinkun</dc:creator>
 <dc:creator>Huangfu, Jiangtao</dc:creator>
 <dc:creator>Shi, Zhiguo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Hand gesture recognition has long been a hot topic in human computer
interaction. Traditional camera-based hand gesture recognition systems cannot
work properly under dark circumstances. In this paper, a Doppler Radar based
hand gesture recognition system using convolutional neural networks is
proposed. A cost-effective Doppler radar sensor with dual receiving channels at
5.8GHz is used to acquire a big database of four standard gestures. The
received hand gesture signals are then processed with time-frequency analysis.
Convolutional neural networks are used to classify different gestures.
Experimental results verify the effectiveness of the system with an accuracy of
98%. Besides, related factors such as recognition distance and gesture scale
are investigated.
</dc:description>
 <dc:description>Comment: Best Paper Award of International Conference on Communications,
  Signal Processing, and Systems 2017</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02255</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Normalizing Flows</dc:title>
 <dc:creator>Zheng, Guoqing</dc:creator>
 <dc:creator>Yang, Yiming</dc:creator>
 <dc:creator>Carbonell, Jaime</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Bayesian posterior inference is prevalent in various machine learning
problems. Variational inference provides one way to approximate the posterior
distribution, however its expressive power is limited and so is the accuracy of
resulting approximation. Recently, there has a trend of using neural networks
to approximate the variational posterior distribution due to the flexibility of
neural network architecture. One way to construct flexible variational
distribution is to warp a simple density into a complex by normalizing flows,
where the resulting density can be analytically evaluated. However, there is a
trade-off between the flexibility of normalizing flow and computation cost for
efficient transformation. In this paper, we propose a simple yet effective
architecture of normalizing flows, ConvFlow, based on convolution over the
dimensions of random input vector. Experiments on synthetic and real world
posterior inference problems demonstrate the effectiveness and efficiency of
the proposed method.
</dc:description>
 <dc:description>Comment: Under review at ICLR 2018</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02256</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Semantics for Probabilistic Control-Flow Graphs</dc:title>
 <dc:creator>Amtoft, Torben</dc:creator>
 <dc:creator>Banerjee, Anindya</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  This article develops a novel operational semantics for probabilistic
control-flow graphs (pCFGs) of probabilistic imperative programs with random
assignment and &quot;observe&quot; (or conditioning) statements. The semantics transforms
probability distributions (on stores) as control moves from one node to another
in pCFGs. We relate this semantics to a standard, expectation-transforming,
denotational semantics of structured probabilistic imperative programs, by
translating structured programs into (unstructured) pCFGs, and proving adequacy
of the translation. This shows that the operational semantics can be used
without loss of information, and is faithful to the &quot;intended&quot; semantics and
hence can be used to reason about, for example, the correctness of
transformations (as we do in a companion article).
</dc:description>
 <dc:description>Comment: In a companion paper, also just submitted to arXiv, the semantics is
  used to reason about slicing. So as to make each paper self-contained, there
  is some overlap between them</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02257</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep
  Multitask Networks</dc:title>
 <dc:creator>Chen, Zhao</dc:creator>
 <dc:creator>Badrinarayanan, Vijay</dc:creator>
 <dc:creator>Lee, Chen-Yu</dc:creator>
 <dc:creator>Rabinovich, Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep multitask networks, in which one neural network produces multiple
predictive outputs, are more scalable and often better regularized than their
single-task counterparts. Such advantages can potentially lead to gains in both
speed and performance, but multitask networks are also difficult to train
without finding the right balance between tasks. We present a novel gradient
normalization (GradNorm) technique which automatically balances the multitask
loss function by directly tuning the gradients to equalize task training rates.
We show that for various network architectures, for both regression and
classification tasks, and on both synthetic and real datasets, GradNorm
improves accuracy and reduces overfitting over single networks, static
baselines, and other adaptive multitask loss balancing techniques. GradNorm
also matches or surpasses the performance of exhaustive grid search methods,
despite only involving a single asymmetry hyperparameter $\alpha$. Thus, what
was once a tedious search process which incurred exponentially more compute for
each task added can now be accomplished within a few training runs,
irrespective of the number of tasks. Ultimately, we hope to demonstrate that
gradient manipulation affords us great control over the training dynamics of
multitask networks and may be one of the keys to unlocking the potential of
multitask learning.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, submitted to ICLR 2018. Revised to include more
  detail and for improved clarity</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02258</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Barrier Enabled IO Stack for Flash Storage</dc:title>
 <dc:creator>Won, Youjip</dc:creator>
 <dc:creator>Jung, Jaemin</dc:creator>
 <dc:creator>Choi, Gyeongyeol</dc:creator>
 <dc:creator>Oh, Joontaek</dc:creator>
 <dc:creator>Son, Seongbae</dc:creator>
 <dc:creator>Hwang, Jooyoung</dc:creator>
 <dc:creator>Cho, Sangyeun</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  This work is dedicated to eliminating the overhead of guaranteeing the
storage order in modern IO stack. The existing block device adopts
prohibitively expensive resort in ensuring the storage order among write
requests: interleaving successive write requests with transfer and flush.
Exploiting the cache barrier command for the Flash storage, we overhaul the IO
scheduler, the dispatch module and the filesystem so that these layers are
orchestrated to preserve the ordering condition imposed by the application can
be delivered to the storage. Key ingredients of Barrier Enabled IO stack are
Epoch based IO scheduling, Order Preserving Dispatch, and Dual Mode Journaling.
Barrier enabled IO stack successfully eliminates the root cause of excessive
overhead in enforcing the storage order. Dual Mode Journaling in BarrierFS
dedicates the separate threads to effectively decouple the control plane and
data plane of the journal commit. We implement Barrier Enabled IO Stack in
server as well as in mobile platform. SQLite performance increases by 270% and
75%, in server and in smartphone, respectively. Relaxing the durability of a
transaction, SQLite performance and MySQL performance increases as much as by
73X and by 43X, respectively, in server storage.
</dc:description>
 <dc:description>Comment: 15 pages, 15 figures, 71 references</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02271</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-order Tensor Completion for Data Recovery via Sparse Tensor-train
  Optimization</dc:title>
 <dc:creator>Yuan, Longhao</dc:creator>
 <dc:creator>Zhao, Qibin</dc:creator>
 <dc:creator>Cao, Jianting</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we aim at the problem of tensor data completion. Tensor-train
decomposition is adopted because of its powerful representation performance and
tensor order linear scalability. We propose an algorithm named STTO (Sparse
Tensor-train Optimization) which considers incomplete data as sparse tensor and
uses first-order optimization method to find the factors of tensor-train
decomposition. Our algorithm is shown to perform well in simulation experiments
at both low-order cases and high-order cases. We also employ a tensorization
method to transform data to a higher-order to enhance the performance of our
algorithm. The image recovery experiment results in various cases manifest that
our method outperforms other completion algorithms. Especially when the missing
rate is very high, e.g. 90% to 99%, our method can achieve much better
performance than other state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 5 pages (include 1 page of reference) ICASSP 2018</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02274</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Water Mass Method and Its Application to Integrated Heat and
  Electricity Dispatch Considering Thermal Dynamics</dc:title>
 <dc:creator>Chen, Yuwei</dc:creator>
 <dc:creator>Guo, Qinglai</dc:creator>
 <dc:creator>Sun, Hongbin</dc:creator>
 <dc:creator>Li, Zhengshuo</dc:creator>
 <dc:creator>Pan, Zhaoguang</dc:creator>
 <dc:creator>Wu, Wenchuan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Currently, most district heating networks are running in a heat-setting mode,
limiting the adjustment of the electrical power of combined heat and power
(CHP) units. By considering the electrical power system (EPS) and district
heating system (DHS) together, the peak regulatory capability of CHP units can
be improved and renewable energy accommodation can be promoted. In this paper,
a tractable integrated heat and electricity dispatch (IHED) model is described
that addresses the thermal dynamic characteristics of pipelines and buildings
to increase flexibility. To deal with the complexity of the optimization model,
a water mass method (WMM) for pipeline thermal dynamics is proposed. Benefiting
from the WMM, the proposed IHED model is an ordinary, non-linear model. An
iterative algorithm based on the generalized Benders decomposition, and a
sequential approach combined with the iterative algorithm and IPOPT, are
proposed to solve the IHED model. Compared with a steady state model without
thermal dynamics, considering the thermal dynamic characteristics in the DHS
can further expand the peak regulatory capabilities of CHP units. The WMM is
tested in the thermal dynamic simulations compared to an existing node method
and a commercial simulation software. And the proposed solution strategy is
verified in a small-scale system and a practical system. The simulation results
of case studies are discussed to demonstrate the feasibility and economy of the
dispatch model proposed here.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02274</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02276</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Lightning Never Strikes the Same State Twice</dc:title>
 <dc:creator>Zhandry, Mark</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Public key quantum money can be seen as a version of the quantum no-cloning
theorem that holds even when the quantum states can be verified by the
adversary. In this work, investigate quantum lightning, a formalization of
&quot;collision-free quantum money&quot; defined by Lutomirski et al. [ICS'10], where
no-cloning holds even when the adversary herself generates the quantum state to
be cloned. We then study quantum money and quantum lightning, showing the
following results:
  - We demonstrate the usefulness of quantum lightning by showing several
potential applications, such as generating random strings with a proof of
entropy, to completely decentralized cryptocurrency without a block-chain,
where transactions is instant and local.
  - We give win-win results for quantum money/lightning, showing that either
signatures/hash functions/commitment schemes meet very strong recently proposed
notions of security, or they yield quantum money or lightning.
  - We construct quantum lightning under the assumed multi-collision resistance
of random degree-2 systems of polynomials.
  - We show that instantiating the quantum money scheme of Aaronson and
Christiano [STOC'12] with indistinguishability obfuscation that is secure
against quantum computers yields a secure quantum money scheme
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02279</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>StealthDB: a Scalable Encrypted Database with Full SQL Query Support</dc:title>
 <dc:creator>Gribov, Alexey</dc:creator>
 <dc:creator>Vinayagamurthy, Dhinakaran</dc:creator>
 <dc:creator>Gorbunov, Sergey</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Encrypted database systems provide a great method for protecting sensitive
data in untrusted infrastructures. These systems are built using either
special-purpose cryptographic algorithms that support operations over encrypted
data, or by leveraging trusted computing co-processors. Strong cryptographic
algorithms usually result in high performance overheads (e.g., public-key
encryptions, garbled circuits), while weaker algorithms (e.g., order-preserving
encryption) result in large leakage profiles. On the other hand, some encrypted
database systems (e.g., Cipherbase, TrustedDB) leverage non-standard trusted
computing devices, and are designed to work around their specific architectural
limitations.
  In this work we build StealthDB -- an encrypted database system from Intel
SGX. Our system can run on any newer generation Intel CPU. StealthDB has a very
small trusted computing base, scales to large datasets, requires no DBMS
changes, and provides strong security guarantees at steady state and during
query execution.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02281</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Autoregressive Neural Machine Translation</dc:title>
 <dc:creator>Gu, Jiatao</dc:creator>
 <dc:creator>Bradbury, James</dc:creator>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Li, Victor O. K.</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Existing approaches to neural machine translation condition each output word
on previously generated outputs. We introduce a model that avoids this
autoregressive property and produces its outputs in parallel, allowing an order
of magnitude lower latency during inference. Through knowledge distillation,
the use of input token fertilities as a latent variable, and policy gradient
fine-tuning, we achieve this at a cost of as little as 2.0 BLEU points relative
to the autoregressive Transformer network used as a teacher. We demonstrate
substantial cumulative improvements associated with each of the three aspects
of our training strategy, and validate our approach on IWSLT 2016
English-German and two WMT language pairs. By sampling fertilities in parallel
at inference time, our non-autoregressive model achieves near-state-of-the-art
performance of 29.8 BLEU on WMT 2016 English-Romanian.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2018</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02282</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Walkback: Learning a Transition Operator as a Stochastic
  Recurrent Net</dc:title>
 <dc:creator>Goyal, Anirudh</dc:creator>
 <dc:creator>Ke, Nan Rosemary</dc:creator>
 <dc:creator>Ganguli, Surya</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose a novel method to directly learn a stochastic transition operator
whose repeated application provides generated samples. Traditional undirected
graphical models approach this problem indirectly by learning a Markov chain
model whose stationary distribution obeys detailed balance with respect to a
parameterized energy function. The energy function is then modified so the
model and data distributions match, with no guarantee on the number of steps
required for the Markov chain to converge. Moreover, the detailed balance
condition is highly restrictive: energy based models corresponding to neural
networks must have symmetric weights, unlike biological neural circuits. In
contrast, we develop a method for directly learning arbitrarily parameterized
transition operators capable of expressing non-equilibrium stationary
distributions that violate detailed balance, thereby enabling us to learn more
biologically plausible asymmetric neural networks and more general non-energy
based dynamical systems. The proposed training objective, which we derive via
principled variational methods, encourages the transition operator to &quot;walk
back&quot; in multi-step trajectories that start at data-points, as quickly as
possible back to the original data points. We present a series of experimental
results illustrating the soundness of the proposed approach, Variational
Walkback (VW), on the MNIST, CIFAR-10, SVHN and CelebA datasets, demonstrating
superior samples compared to earlier attempts to learn a transition operator.
We also show that although each rapid training trajectory is limited to a
finite but variable number of steps, our transition operator continues to
generate good samples well past the length of such trajectories, thereby
demonstrating the match of its non-equilibrium stationary distribution to the
data distribution. Source Code: http://github.com/anirudh9119/walkback_nips17
</dc:description>
 <dc:description>Comment: To appear at NIPS 2017</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02287</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance analysis of carrier aggregation for various mobile network
  implementations scenario based on spectrum allocated</dc:title>
 <dc:creator>Kiwoli, Liston</dc:creator>
 <dc:creator>Sam, Anael</dc:creator>
 <dc:creator>Manasseh, Emmanuel</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Carrier Aggregation (CA) is one of the Long Term Evolution Advanced (LTE-A)
features that allow mobile network operators (MNO) to combine multiple
component carriers (CCs) across the available spectrum to create a wider
bandwidth channel for increasing the network data throughput and overall
capacity. CA has a potential to enhance data rates and network performance in
the downlink, uplink, or both, and it can support aggregation of frequency
division duplexing (FDD) as well as time division duplexing (TDD). The
technique enables the MNO to exploit fragmented spectrum allocations and can be
utilized to aggregate licensed and unlicensed carrier spectrum as well. This
paper analyzes the performance gains and complexity level that arises from the
aggregation of three inter-band component carriers (3CC) as compared to the
aggregation of 2CC using a Vienna LTE System Level simulator. The results show
a considerable growth in the average cell throughput when 3CC aggregations are
implemented over the 2CC aggregation, at the expense of reduction in the
fairness index. The reduction in the fairness index implies that, the scheduler
has an increased task in resource allocations due to the added component
carrier. Compensating for such decrease in the fairness index could result into
scheduler design complexity. The proposed scheme can be adopted in combining
various component carriers, to increase the bandwidth and hence the data rates.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02290</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intelligent Collision Management in Dynamic Environments for
  Human-Centered Robots</dc:title>
 <dc:creator>Kim, Kwan Suk</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this context, a major focus of this thesis is on unintentional collisions,
where a straight goal is to eliminate injury from users and passerby's via
realtime sensing and control systems. A less obvious focus is to combine
collision response with tools from motion planning in order to produce
intelligent safety behaviors that ensure the safety of multiple people or
objects. Yet, an even more challenging problem is to anticipate future
collisions between objects external to the robot and have the robot intervene
to prevent imminent accidents. In this dissertation, we study all of these
sophisticated flavors of collision reaction and intervention. We investigate
in-depth multiple key and interesting topics related to collisions and safety
of mobile robots and robotic manipulators operating in human environments.
Overall we deeply investigate collisions from many perspectives and develop
techniques that borrow and contribute to the areas of mechatronic design,
sensor processing, feedback controls, motion planning, and probabilistic
reasoning methods. The result of this study is a set of key experiments and
guidelines to deal with collisions in mobile robots and robotic manipulators.
This study aims at influencing future studies on field operations of robots and
accelerate the employment of advanced robots in our daily environments without
compromising our safety.
</dc:description>
 <dc:description>Comment: Dissertation</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02292</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explicit Deep Holes of Reed-Solomon Codes</dc:title>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Wan, Daqing</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B05</dc:subject>
 <dc:description>  In this paper, deep holes of Reed-Solomon (RS) codes are studied. A new class
of deep holes for generalized affine RS codes is given if the evaluation set
satisfies certain combinatorial structure. Three classes of deep holes for
projective Reed-Solomon (PRS) codes are constructed explicitly. In particular,
deep holes of PRS codes with redundancy three are completely obtained when the
characteristic of the finite field is odd. Most (asymptotically of ratio $1$)
of the deep holes of PRS codes with redundancy four are also obtained.
</dc:description>
 <dc:description>Comment: 31 pages</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02293</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pre-shared Key Agreement for Secure Public Wi-Fi</dc:title>
 <dc:creator>Jeon, Seokseong</dc:creator>
 <dc:creator>Yu, Chansu</dc:creator>
 <dc:creator>Suh, Young-Joo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper presents a novel pre-shared key (PSK) agreement scheme to
establish a secure connection between a Wi-Fi client and access point (AP)
without prior knowledge of a password. The standard IEEE 802.11 security
method, Robust Security Network Association, widely known as Wi-Fi Protected
Access (WPA) and WPA2, derives a shared cryptographic key if and only if a user
provides an identical password which an AP possesses, causing ofinconvenience
of obtaining and entering the password. In this paper, a proposed scheme,
Secure Open AP (SOAP), adopts two public key algorithms, the elliptic curve
Diffie-Hellman key exchange algorithm (ECDH) and digital signature algorithm
(ECDSA) to establish a secure connection between a client and an AP without
having prior knowledge of a password. Implementation and experiment results
demonstrate the viability of the proposed scheme.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02293</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02294</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AppSwitch: Resolving the Application Identity Crisis</dc:title>
 <dc:creator>Subhraveti, Dinesh</dc:creator>
 <dc:creator>Goli, Sri</dc:creator>
 <dc:creator>Hallyn, Serge</dc:creator>
 <dc:creator>Chamarthy, Ravi</dc:creator>
 <dc:creator>Kozyrakis, Christos</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  Networked applications traditionally derive their identity from the identity
of the host on which they run. The default application identity acquired from
the host results in subtle and substantial problems related to application
deployment, discovery and access, especially for modern distributed
applications. A number of mechanisms and workarounds, often quite elaborate,
are used to address those problems but they only address them indirectly and
incompletely.
  This paper presents AppSwitch, a novel transport layer network element that
decouples applications from underlying network at the system call layer and
enables them to be identified independently of the network. Without requiring
changes to existing applications or infrastructure, it removes the cost and
complexity associated with operating distributed applications while offering a
number of benefits including an efficient implementation of common network
functions such as application firewall and load balancer. Experiments with our
implementation show that AppSwitch model also effectively removes the
performance penalty associated with unnecessary data path processing that is
typical in those application environments.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02295</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quality-Efficiency Trade-offs in Machine Learning for Text Processing</dc:title>
 <dc:creator>Baeza-Yates, Ricardo</dc:creator>
 <dc:creator>Liaghat, Zeinab</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Data mining, machine learning, and natural language processing are powerful
techniques that can be used together to extract information from large texts.
Depending on the task or problem at hand, there are many different approaches
that can be used. The methods available are continuously being optimized, but
not all these methods have been tested and compared in a set of problems that
can be solved using supervised machine learning algorithms. The question is
what happens to the quality of the methods if we increase the training data
size from, say, 100 MB to over 1 GB? Moreover, are quality gains worth it when
the rate of data processing diminishes? Can we trade quality for time
efficiency and recover the quality loss by just being able to process more
data? We attempt to answer these questions in a general way for text processing
tasks, considering the trade-offs involving training data size, learning time,
and quality obtained. We propose a performance trade-off framework and apply it
to three important text processing problems: Named Entity Recognition,
Sentiment Analysis and Document Classification. These problems were also chosen
because they have different levels of object granularity: words, paragraphs,
and documents. For each problem, we selected several supervised machine
learning algorithms and we evaluated the trade-offs of them on large publicly
available data sets (news, reviews, patents). To explore these trade-offs, we
use different data subsets of increasing size ranging from 50 MB to several GB.
We also consider the impact of the data set and the evaluation technique. We
find that the results do not change significantly and that most of the time the
best algorithms is the fastest. However, we also show that the results for
small data (say less than 100 MB) are different from the results for big data
and in those cases the best algorithm is much harder to determine.
</dc:description>
 <dc:description>Comment: Ten pages, long version of paper that will be presented at IEEE Big
  Data 2017 (8 pages)</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02301</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?</dc:title>
 <dc:creator>Raghu, Maithra</dc:creator>
 <dc:creator>Irpan, Alex</dc:creator>
 <dc:creator>Andreas, Jacob</dc:creator>
 <dc:creator>Kleinberg, Robert</dc:creator>
 <dc:creator>Le, Quoc V.</dc:creator>
 <dc:creator>Kleinberg, Jon</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep reinforcement learning has achieved many recent successes, but our
understanding of its strengths and limitations is hampered by the lack of rich
environments in which we can fully characterize optimal behavior, and
correspondingly diagnose individual actions against such a characterization.
Here we consider a family of combinatorial games, arising from work of Erdos,
Selfridge, and Spencer, and we propose their use as environments for evaluating
and comparing different approaches to reinforcement learning. These games have
a number of appealing features: they are challenging for current learning
approaches, but they form (i) a low-dimensional, simply parametrized
environment where (ii) there is a linear closed form solution for optimal
behavior from any state, and (iii) the difficulty of the game can be tuned by
changing environment parameters in an interpretable way. We use these
Erdos-Selfridge-Spencer games not only to compare different algorithms, but
also to compare approaches based on supervised and reinforcement learning, to
analyze the power of multi-agent approaches in improving performance, and to
evaluate generalization to environments outside the training set.
</dc:description>
 <dc:description>Comment: New experiments on Fatal Mistakes in Supervised Learning vs RL,
  additional linear baselines added</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02303</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Computation of Security Strategies of Matrix Games with
  Growing Action Set</dc:title>
 <dc:creator>Li, Lichun</dc:creator>
 <dc:creator>Langbort, Cedric</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper studies how to efficiently update the saddle-point strategy, or
security strategy of one player in a matrix game when the other player develops
new actions in the game. It is well known that the saddle-point strategy of one
player can be computed by solving a linear program. Developing a new action
will add a new constraint to the existing LP. Therefore, our problem becomes
how to solve the new LP with a new constraint efficiently. Considering the
potentially huge number of constraints, which corresponds to the large size of
the other player's action set, we use shadow vertex simplex method, whose
computational complexity is lower than linear with respect to the size of the
constraints, as the basis of our iterative algorithm. We first rebuild the main
theorems in shadow vertex method with relaxed assumption to make sure such
method works well in our model, then analyze the probability that the old
optimum remains optimal in the new LP, and finally provides the iterative
shadow vertex method whose computational complexity is shown to be strictly
less than that of shadow vertex method. The simulation results demonstrates our
main results about the probability of re-computing the optimum and the
computational complexity of the iterative shadow vertex method.
</dc:description>
 <dc:description>Comment: submitted to special issue in the journal Dynamic Games and
  Applications</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02305</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Heavily-Weighted Features in Data Streams</dc:title>
 <dc:creator>Tai, Kai Sheng</dc:creator>
 <dc:creator>Sharan, Vatsal</dc:creator>
 <dc:creator>Bailis, Peter</dc:creator>
 <dc:creator>Valiant, Gregory</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce a new sub-linear space data structure---the Weight-Median
Sketch---that captures the most heavily weighted features in linear classifiers
trained over data streams. This enables memory-limited execution of several
statistical analyses over streams, including online feature selection,
streaming data explanation, relative deltoid detection, and streaming
estimation of pointwise mutual information. In contrast with related sketches
that capture the most commonly occurring features (or items) in a data stream,
the Weight-Median Sketch captures the features that are most discriminative of
one stream (or class) compared to another. The Weight-Median sketch adopts the
core data structure used in the Count-Sketch, but, instead of sketching counts,
it captures sketched gradient updates to the model parameters. We provide a
theoretical analysis of this approach that establishes recovery guarantees in
the online learning setting, and demonstrate substantial empirical improvements
in accuracy-memory trade-offs over alternatives, including count-based sketches
and feature hashing.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02308</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security Strategies of Both Players in Asymmetric Information Zero-Sum
  Stochastic Games with an Informed Controller</dc:title>
 <dc:creator>Li, Lichun</dc:creator>
 <dc:creator>Langbort, Cedric</dc:creator>
 <dc:creator>Shamma, Jeff S.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper considers a zero-sum two-player asymmetric information stochastic
game where only one player knows the system state, and the transition law is
controlled by the informed player only. For the informed player, it has been
shown that the security strategy only depends on the belief and the current
stage. We provide LP formulations whose size is only linear in the size of the
uninformed player's action set to compute both history based and belief based
security strategies. For the uninformed player, we focus on the regret, the
difference between 0 and the future payoff guaranteed by the uninformed player
in every possible state. Regret is a real vector of the same size as the
belief, and depends only on the action of the informed player and the strategy
of the uninformed player. This paper shows that the uninformed player has a
security strategy that only depends on the regret and the current stage. LP
formulations are then given to compute the history based security strategy, the
regret at every stage, and the regret based security strategy. The size of the
LP formulations are again linear in the size of the uninformed player action
set. Finally, an intrusion detection problem is studied to demonstrate the main
results in this paper.
</dc:description>
 <dc:description>Comment: submitted to special issue in the journal Dynamic Games and
  Applications</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02309</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Overcomplete HMMs</dc:title>
 <dc:creator>Sharan, Vatsal</dc:creator>
 <dc:creator>Kakade, Sham</dc:creator>
 <dc:creator>Liang, Percy</dc:creator>
 <dc:creator>Valiant, Gregory</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of learning overcomplete HMMs---those that have many
hidden states but a small output alphabet. Despite having significant practical
importance, such HMMs are poorly understood with no known positive or negative
results for efficient learning. In this paper, we present several new
results---both positive and negative---which help define the boundaries between
the tractable and intractable settings. Specifically, we show positive results
for a large subclass of HMMs whose transition matrices are sparse,
well-conditioned, and have small probability mass on short cycles. On the other
hand, we show that learning is impossible given only a polynomial number of
samples for HMMs with a small output alphabet and whose transition matrices are
random regular graphs with large degree. We also discuss these results in the
context of learning HMMs which can capture long-term dependencies.
</dc:description>
 <dc:description>Comment: 24 pages, 6 figures, NIPS 2017</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02313</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperative Spectrum Sensing Scheduling in Multi-channel Cognitive Radio
  Networks: A broad perspective</dc:title>
 <dc:creator>Chauhan, Prakash</dc:creator>
 <dc:creator>Deka, Sanjib K.</dc:creator>
 <dc:creator>Devi, Monisha</dc:creator>
 <dc:creator>Sarma, Nityananda</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Cooperative spectrum sensing has been proven to improve sensing performance
of cognitive users in presence of spectral diversity. For multi-channel CRN
(MC-CRN), designing a cooperative spectrum sensing scheme becomes quite
challenging as it needs an optimal sensing scheduling scheme, which schedules
cognitive users to different channels such that a good balance between
detection performance and the discovery of spectrum holes is achieved. The main
issue associated with cooperative spectrum sensing scheduling (CSSS) scheme is
the design of an optimal schedule that could specify which SUs should be
assigned to which channels at what time to achieve maximal network throughput
with minimal amount of energy and satisfying the desirable sensing accuracy. In
this regard, designing an efficient CSSS scheme for MC-CRN is of utmost
importance for practical implementation of CRN. In this article, we explore
CSSS problem from a broad perspective and present the different objectives and
the inherent issues and challenges arise in designing the CSSS scheme. We also
discuss the different methods used for modeling of the CSSS scheme for MC-CRN.
Further, a few future research directions are listed which need investigation
while developing the solution for CSSS problem.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figure</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02316</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepRain: ConvLSTM Network for Precipitation Prediction using
  Multichannel Radar Data</dc:title>
 <dc:creator>Kim, Seongchan</dc:creator>
 <dc:creator>Hong, Seungkyun</dc:creator>
 <dc:creator>Joh, Minsu</dc:creator>
 <dc:creator>Song, Sa-kwang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Accurate rainfall forecasting is critical because it has a great impact on
people's social and economic activities. Recent trends on various literatures
show that Deep Learning (Neural Network) is a promising methodology to tackle
many challenging tasks. In this study, we introduce a brand-new data-driven
precipitation prediction model called DeepRain. This model predicts the amount
of rainfall from weather radar data, which is three-dimensional and
four-channel data, using convolutional LSTM (ConvLSTM). ConvLSTM is a variant
of LSTM (Long Short-Term Memory) containing a convolution operation inside the
LSTM cell. For the experiment, we used radar reflectivity data for a two-year
period whose input is in a time series format in units of 6 min divided into 15
records. The output is the predicted rainfall information for the input data.
Experimental results show that two-stacked ConvLSTM reduced RMSE by 23.0%
compared to linear regression.
</dc:description>
 <dc:description>Comment: Climate Informatics Workshop 2017</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02317</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Player Bandits Models Revisited</dc:title>
 <dc:creator>Besson, Lilian</dc:creator>
 <dc:creator>Kaufmann, Emilie</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Multi-player Multi-Armed Bandits (MAB) have been extensively studied in the
literature, motivated by applications to Cognitive Radio systems. Driven by
such applications as well, we motivate the introduction of several levels of
feedback for multi-player MAB algorithms. Most existing work assume that
sensing information is available to the algorithm. Under this assumption, we
improve the state-of-the-art lower bound for the regret of any decentralized
algorithms and introduce two algorithms, RandTopM and MCTopM, that are shown to
empirically outperform existing algorithms. Moreover, we provide strong
theoretical guarantees for these algorithms, including a notion of asymptotic
optimality in terms of the number of selections of bad arms. We then introduce
a promising heuristic, called Selfish, that can operate without sensing
information, which is crucial for emerging applications to Internet of Things
networks. We investigate the empirical performance of this algorithm and
provide some first theoretical elements for the understanding of its behavior.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02318</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-uniform time-scaling of Carnatic music transients</dc:title>
 <dc:creator>Viraraghavan, Venkata Subramanian</dc:creator>
 <dc:creator>Pal, Arpan</dc:creator>
 <dc:creator>Aravind, R</dc:creator>
 <dc:creator>Murthy, Hema</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Gamakas are an integral aspect of Carnatic Music, a form of classical music
prevalent in South India. They are used in ragas, which may be seen as melodic
scales and/or a set of characteristic melodic phrases. Gamakas exhibit
continuous pitch variation often spanning several semitones. In this paper, we
study how gamakas scale with tempo and propose a novel approach to change the
tempo of Carnatic music pieces. The music signal is viewed as consisting of
constant-pitch segments and transients. The transients show continuous pitch
variation and we consider their analyses from a theoretical stand-point. We
next observe the non-uniform ratios of time-scaling of constant-pitch segments,
transients and silence in excerpts from nine concert renditions of varnams in
six ragas. The results indicate that the changing tempo of Carnatic music does
not change the duration of transients significantly. We report listening tests
on our algorithm to slow down Carnatic music that is consistent with this
observation.
</dc:description>
 <dc:description>Comment: The non-uniform time-scaling of CP-notes and transients in Carnatic
  concert renditions is new; it has not been reported earlier in the
  literature, but a reviewer pointed out that the proposed algorithm is
  previously known</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02321</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Maxout Units Downsize Restoration Networks? - Single Image
  Super-Resolution Using Lightweight CNN with Maxout Units</dc:title>
 <dc:creator>Choi, Jae-Seok</dc:creator>
 <dc:creator>Kim, Munchurl</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Rectified linear units (ReLU) are well-known to be helpful in obtaining
faster convergence and thus higher performance for many deep-learning-based
applications. However, networks with ReLU tend to perform poorly when the
number of filter parameters is constrained to a small number. To overcome it,
in this paper, we propose a novel network utilizing maxout units (MU), and show
its effectiveness on super-resolution (SR) applications. In general, the MU has
been known to make the filter sizes doubled in generating the feature maps of
the same sizes in classification problems. In this paper, we first reveal that
the MU can even make the filter sizes halved in restoration problems thus
leading to compaction of the network sizes. To show this, our SR network is
designed without increasing the filter sizes with MU, which outperforms the
state of the art SR methods with a smaller number of filter parameters. To the
best of our knowledge, we are the first to incorporate MU into SR applications
and show promising performance results. In MU, feature maps from a previous
convolutional layer are divided into two parts along channels, which are then
compared element-wise and only their max values are passed to a next layer.
Along with some interesting properties of MU to be analyzed, we further
investigate other variants of MU and their effects. In addition, while ReLU
have a trouble for learning in networks with a very small number of
convolutional filter parameters, MU do not. For SR applications, our MU-based
network reconstructs high-resolution images with comparable quality compared to
previous deep-learning-based SR methods, with lower filter parameters.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02324</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achievable Rate Analysis of Relay Assisted Cooperative NOMA over Rician
  Fading Channels</dc:title>
 <dc:creator>Jha, Pranav Kumar</dc:creator>
 <dc:creator>Kumar, D. Sriram</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Non-orthogonal multiple access (NOMA) is a key to multiple access techniques
for the next generation 5G wireless communication networks. In this paper, to
improve the performance gain of NOMA system, a cooperative fixed
decode-and-forward (DF) relay system model based on NOMA (CRS-NOMA) is studied
over Rician fading channels, considering the achievable rate of signals as the
performance metric. In this technique, by exploiting the concept of NOMA,
unlike the conventional method of cooperative relaying, the second time slot is
also utilized for the realization of information sent from the transmitter end.
Moreover, as the data symbols are transmitted by nodes with full power, the
compulsion of complex power allocation coefficients is precluded. In
conventional cooperative relaying systems, the receiver is only able to receive
a single bit of information, while the receiver can reliably bring in two data
symbols in two-time slots. In this regard, this scheme is able to acquire
higher achievable rate performance than existing cooperative relaying schemes
for larger channel powers over most of the transmit SNR regime. Furthermore, a
mathematical expression is also derived for the total achievable rate of
CRS-NOMA. The results are verified through Monte-Carlo simulations which
validate accuracy and consistency of the derived analytical results.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02326</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Attentive Backtracking: Long-Range Credit Assignment in Recurrent
  Networks</dc:title>
 <dc:creator>Ke, Nan Rosemary</dc:creator>
 <dc:creator>Goyal, Anirudh</dc:creator>
 <dc:creator>Bilaniuk, Olexa</dc:creator>
 <dc:creator>Binas, Jonathan</dc:creator>
 <dc:creator>Charlin, Laurent</dc:creator>
 <dc:creator>Pal, Chris</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A major drawback of backpropagation through time (BPTT) is the difficulty of
learning long-term dependencies, coming from having to propagate credit
information backwards through every single step of the forward computation.
This makes BPTT both computationally impractical and biologically implausible.
For this reason, full backpropagation through time is rarely used on long
sequences, and truncated backpropagation through time is used as a heuristic.
However, this usually leads to biased estimates of the gradient in which longer
term dependencies are ignored. Addressing this issue, we propose an alternative
algorithm, Sparse Attentive Backtracking, which might also be related to
principles used by brains to learn long-term dependencies. Sparse Attentive
Backtracking learns an attention mechanism over the hidden states of the past
and selectively backpropagates through paths with high attention weights. This
allows the model to learn long term dependencies while only backtracking for a
small number of time steps, not just from the recent past but also from
attended relevant past states.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02329</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpreting Convolutional Neural Networks Through Compression</dc:title>
 <dc:creator>Abbasi-Asl, Reza</dc:creator>
 <dc:creator>Yu, Bin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) achieve state-of-the-art performance in
a wide variety of tasks in computer vision. However, interpreting CNNs still
remains a challenge. This is mainly due to the large number of parameters in
these networks. Here, we investigate the role of compression and particularly
pruning filters in the interpretation of CNNs. We exploit our recently-proposed
greedy structural compression scheme that prunes filters in a trained CNN. In
our compression, the filter importance index is defined as the classification
accuracy reduction (CAR) of the network after pruning that filter. The filters
are then iteratively pruned based on the CAR index. We demonstrate the
interpretability of CAR-compressed CNNs by showing that our algorithm prunes
filters with visually redundant pattern selectivity. Specifically, we show the
importance of shape-selective filters for object recognition, as opposed to
color-selective filters. Out of top 20 CAR-pruned filters in AlexNet, 17 of
them in the first layer and 14 of them in the second layer are color-selective
filters. Finally, we introduce a variant of our CAR importance index that
quantifies the importance of each image class to each CNN filter. We show that
the most and the least important class labels present a meaningful
interpretation of each filter that is consistent with the visualized pattern
selectivity of that filter.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2017 Symposium on Interpretable Machine Learning</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02333</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Critique on &quot;Asynchronous Logic Implementation Based on Factorized
  DIMS&quot;</dc:title>
 <dc:creator>Balasubramanian, P</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  This paper comments on &quot;Asynchronous Logic Implementation Based on Factorized
DIMS&quot; [Jour. of Circuits, Systems, and Computers, vol. 26, no. 5, 1750087,
pages 9, May 2017] with respect to two problematic issues: i) the gate orphan
problem implicit in the factorized DIMS approach discussed in the referenced
article which affects the strong-indication, and ii) how the enumeration of
product terms to represent the synthesis cost is skewed in the referenced
article because the logic expression contains sum of products and also product
of sums. It is observed that the referenced article has not provided a general
logic synthesis algorithm excepting only an example illustration involving a
3-input AND gate function. The absence of a general logic synthesis algorithm
would make it difficult to reproduce the research described in the referenced
article. Moreover, the example illustration in the referenced article describes
an unsafe logic decomposition which is not suitable for strong-indication
asynchronous circuit synthesis. Further, a logic synthesis method which safely
decomposes the DIMS solution to synthesize strong-indication asynchronous
circuits is already available in the existing literature, which was neither
cited nor taken up for comparison in the referenced article, which is another
drawback. Subsequently, it is concluded that the referenced article has not
advanced existing knowledge in the field but has caused confusions. Hence, in
the interest of avid readers, this paper additionally highlights some important
and relevant literature which provide valuable information about robust
asynchronous circuit synthesis techniques which employ delay-insensitive codes
for data representation and processing and the 4-phase return-to-zero handshake
protocol for data communication.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02343</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Altitude and Beamwidth Optimization for UAV-Enabled Multiuser
  Communications</dc:title>
 <dc:creator>He, Haiyun</dc:creator>
 <dc:creator>Zhang, Shuowen</dc:creator>
 <dc:creator>Zeng, Yong</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this letter, we study multiuser communication systems enabled by an
unmanned aerial vehicle (UAV) that is equipped with a directional antenna of
adjustable beamwidth. We propose a fly-hover-and-communicate protocol where the
ground terminals (GTs) are partitioned into disjoint clusters that are
sequentially served by the UAV as it hovers above the corresponding cluster
centers. We jointly optimize the UAV's flying altitude and antenna beamwidth
for throughput optimization in three fundamental multiuser communication
models, namely UAV-enabled downlink multicasting (MC), downlink broadcasting
(BC), and uplink multiple access (MAC). Our results show that the optimal UAV
altitude and antenna beamwidth critically depend on the communication model
considered.
</dc:description>
 <dc:description>Comment: to appear in IEEE Communications Letters</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02344</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Use of Commutativity for Cryptology in Secret Communication</dc:title>
 <dc:creator>Koksal, Mehmet Emir</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Commutativity of subsystems in cascade connected forms to form larger systems
gets worthy to improve noise disturbance properties, stability, robustness and
many other properties in system design. In this paper, another benefit of
commutativity property is indicated, as far as the author knowledge for the
first time, and illustrated by examples. This benefit is the gain of a new and
original method for transmission of secret signals when travelling in a
transmission channel. Hence, the paper presents an original and alternative
method in cryptology. Their results are all validated by illustrative examples
and Matlab simulation toolbox Simulink.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02348</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-mode Tracking of a Group of Mobile Agents</dc:title>
 <dc:creator>Kumar, Vikram</dc:creator>
 <dc:creator>Arablouei, Reza</dc:creator>
 <dc:creator>Jurdak, Raja</dc:creator>
 <dc:creator>Kusy, Branislav</dc:creator>
 <dc:creator>Bergmann, Neil W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of tracking a group of mobile nodes with limited
available computational and energy resources given noisy RSSI measurements and
position estimates from group members. The multilateration solutions are known
for energy efficiency. However, these solutions are not directly applicable to
dynamic grouping scenarios where neighbourhoods and resource availability may
frequently change. Existing algorithms such as cluster-based GPS duty-cycling,
individual-based tracking, and multilateration-based tracking can only
partially deal with the challenges of dynamic grouping scenarios. To cope with
these challenges in an effective manner, we propose a new group-based
multi-mode tracking algorithm. The proposed algorithm takes the topological
structure of the group as well as the availability of the resources into
consideration and decides the best solution at any particular time instance. We
consider a clustering approach where a cluster head coordinates the usage of
resources among the cluster members. We evaluate the energy-accuracy trade-off
of the proposed algorithm for various fixed sampling intervals. The evaluation
is based on the 2D position tracks of 40 nodes generated using Reynolds'
flocking model. For a given energy budget, the proposed algorithm reduces the
mean tracking error by up to $20\%$ in comparison to the existing
energy-efficient cooperative algorithms. Moreover, the proposed algorithm is as
accurate as the individual-based tracking while using almost half the energy.
</dc:description>
 <dc:description>Comment: Accepted for publication in the 20th international symposium on
  wireless personal multimedia communications (WPMC-2017)</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02361</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FADO: A Deterministic Detection/Learning Algorithm</dc:title>
 <dc:creator>Pelckmans, Kristiaan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper proposes and studies a detection technique for adversarial
scenarios (dubbed deterministic detection). This technique provides an
alternative detection methodology in case the usual stochastic methods are not
applicable: this can be because the studied phenomenon does not follow a
stochastic sampling scheme, samples are high-dimensional and subsequent
multiple-testing corrections render results overly conservative, sample sizes
are too low for asymptotic results (as e.g. the central limit theorem) to kick
in, or one cannot allow for the small probability of failure inherent to
stochastic approaches. This paper instead designs a method based on insights
from machine learning and online learning theory: this detection algorithm -
named Online FAult Detection (FADO) - comes with theoretical guarantees of its
detection capabilities. A version of the margin is found to regulate the
detection performance of FADO. A precise expression is derived for bounding the
performance, and experimental results are presented assessing the influence of
involved quantities. A case study of scene detection is used to illustrate the
approach. The technology is closely related to the linear perceptron rule,
inherits its computational attractiveness and flexibility towards various
extensions.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02368</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Bayesian Piecewise Sparse Linear Models</dc:title>
 <dc:creator>Asahara, Masato</dc:creator>
 <dc:creator>Fujimaki, Ryohei</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The importance of interpretability of machine learning models has been
increasing due to emerging enterprise predictive analytics, threat of data
privacy, accountability of artificial intelligence in society, and so on.
Piecewise linear models have been actively studied to achieve both accuracy and
interpretability. They often produce competitive accuracy against
state-of-the-art non-linear methods. In addition, their representations (i.e.,
rule-based segmentation plus sparse linear formula) are often preferred by
domain experts. A disadvantage of such models, however, is high computational
cost for simultaneous determinations of the number of &quot;pieces&quot; and cardinality
of each linear predictor, which has restricted their applicability to
middle-scale data sets. This paper proposes a distributed factorized asymptotic
Bayesian (FAB) inference of learning piece-wise sparse linear models on
distributed memory architectures. The distributed FAB inference solves the
simultaneous model selection issue without communicating $O(N)$ data where N is
the number of training samples and achieves linear scale-out against the number
of CPU cores. Experimental results demonstrate that the distributed FAB
inference achieves high prediction accuracy and performance scalability with
both synthetic and benchmark data.
</dc:description>
 <dc:description>Comment: Short version of this paper will be published in IEEE BigData 2017</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02377</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The convergence guarantee of the iterative thresholding algorithm with
  suboptimal feedbacks for large systems</dc:title>
 <dc:creator>Song, Zhanjie</dc:creator>
 <dc:creator>Li, Shidong</dc:creator>
 <dc:creator>Han, Ningning</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Thresholding based iterative algorithms have the trade-off between
effectiveness and optimality. Some are effective but involving sub-matrix
inversions in every step of iterations. For systems of large sizes, such
algorithms can be computationally expensive and/or prohibitive. The null space
tuning algorithm with hard thresholding and feedbacks (NST+HT+FB) has a mean to
expedite its procedure by a suboptimal feedback, in which sub-matrix inversion
is replaced by an eigenvalue-based approximation. The resulting suboptimal
feedback scheme becomes exceedingly effective for large system recovery
problems. An adaptive algorithm based on thresholding, suboptimal feedback and
null space tuning (AdptNST+HT+subOptFB) without a prior knowledge of the
sparsity level is also proposed and analyzed. Convergence analysis is the focus
of this article. Numerical simulations are also carried out to demonstrate the
superior efficiency of the algorithm compared with state-of-the-art iterative
thresholding algorithms at the same level of recovery accuracy, particularly
for large systems.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02383</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An EEG-based Image Annotation System</dc:title>
 <dc:creator>Parekh, Viral</dc:creator>
 <dc:creator>Subramanian, Ramanathan</dc:creator>
 <dc:creator>Roy, Dipanjan</dc:creator>
 <dc:creator>Jawahar, C. V.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The success of deep learning in computer vision has greatly increased the
need for annotated image datasets. We propose an EEG
(Electroencephalogram)-based image annotation system. While humans can
recognize objects in 20-200 milliseconds, the need to manually label images
results in a low annotation throughput. Our system employs brain signals
captured via a consumer EEG device to achieve an annotation rate of up to 10
images per second. We exploit the P300 event-related potential (ERP) signature
to identify target images during a rapid serial visual presentation (RSVP)
task. We further perform unsupervised outlier removal to achieve an F1-score of
0.88 on the test set. The proposed system does not depend on category-specific
EEG signatures enabling the annotation of any new image category without any
model pre-training.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02385</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reversible DNA codes over a family of non-chain rings</dc:title>
 <dc:creator>Gursoy, Fatmanur</dc:creator>
 <dc:creator>Oztas, Elif Segah</dc:creator>
 <dc:creator>Ozkan, Ayten</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B15, 94B05, 92D20</dc:subject>
 <dc:description>  In this work we extend results introduced in [15]. Especially, we solve the
reversibility problem for DNA codes over the non chain ring
$R_{k,s}=F_{4^{2k}}[u_1,\ldots,u_{s}]/\langle u_1^2-u_1,\ldots,
u_s^2-u_s\rangle$. We define an automorphism $\theta$ over $R_{k,s}$ which
helps us both finding the idempotent decomposition of $R_{k,s}$ and solving the
reversibility problem via skew cyclic codes. Moreover, we introduce a
generalized Gray map that preserves DNA reversibility.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02386</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Viewport-aware adaptive 360{\deg} video streaming using tiles for
  virtual reality</dc:title>
 <dc:creator>Ozcinar, Cagri</dc:creator>
 <dc:creator>De Abreu, Ana</dc:creator>
 <dc:creator>Smolic, Aljosa</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  360{\deg} video is attracting an increasing amount of attention in the
context of Virtual Reality (VR). Owing to its very high-resolution
requirements, existing professional streaming services for 360{\deg} video
suffer from severe drawbacks. This paper introduces a novel end-to-end
streaming system from encoding to displaying, to transmit 8K resolution
360{\deg} video and to provide an enhanced VR experience using Head Mounted
Displays (HMDs). The main contributions of the proposed system are about
tiling, integration of the MPEG-Dynamic Adaptive Streaming over HTTP (DASH)
standard, and viewport-aware bitrate level selection. Tiling and adaptive
streaming enable the proposed system to deliver very high-resolution 360{\deg}
video at good visual quality. Further, the proposed viewport-aware bitrate
assignment selects an optimum DASH representation for each tile in a
viewport-aware manner. The quality performance of the proposed system is
verified in simulations with varying network bandwidth using realistic view
trajectories recorded from user experiments. Our results show that the proposed
streaming system compares favorably compared to existing methods in terms of
PSNR and SSIM inside the viewport.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Image Processing (ICIP) 2017</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02386</dc:identifier>
 <dc:identifier>2017 IEEE International Conference on Image Processing (ICIP),
  Beijing, China, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02391</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tutorial on Canonical Correlation Methods</dc:title>
 <dc:creator>Uurtio, Viivi</dc:creator>
 <dc:creator>Monteiro, Jo&#xe3;o M.</dc:creator>
 <dc:creator>Kandola, Jaz</dc:creator>
 <dc:creator>Shawe-Taylor, John</dc:creator>
 <dc:creator>Fernandez-Reyes, Delmiro</dc:creator>
 <dc:creator>Rousu, Juho</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68-01</dc:subject>
 <dc:description>  Canonical correlation analysis is a family of multivariate statistical
methods for the analysis of paired sets of variables. Since its proposition,
canonical correlation analysis has for instance been extended to extract
relations between two sets of variables when the sample size is insufficient in
relation to the data dimensionality, when the relations have been considered to
be non-linear, and when the dimensionality is too large for human
interpretation. This tutorial explains the theory of canonical correlation
analysis including its regularised, kernel, and sparse variants. Additionally,
the deep and Bayesian CCA extensions are briefly reviewed. Together with the
numerical examples, this overview provides a coherent compendium on the
applicability of the variants of canonical correlation analysis. By bringing
together techniques for solving the optimisation problems, evaluating the
statistical significance and generalisability of the canonical correlation
model, and interpreting the relations, we hope that this article can serve as a
hands-on tool for applying canonical correlation methods in data analysis.
</dc:description>
 <dc:description>Comment: 33 pages</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02391</dc:identifier>
 <dc:identifier>ACM Computing Surveys, Vol. 50, No. 6, Article 95. Publication
  date: October 2017</dc:identifier>
 <dc:identifier>doi:10.1145/3136624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02395</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beetle Antennae Search without Parameter Tuning (BAS-WPT) for
  Multi-objective Optimization</dc:title>
 <dc:creator>Jiang, Xiangyuan</dc:creator>
 <dc:creator>Li, Shuai</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Beetle antennae search (BAS) is an efficient meta-heuristic algorithm
inspired by foraging behaviors of beetles. This algorithm includes several
parameters for tuning and the existing results are limited to solve single
objective optimization. This work pushes forward the research on BAS by
providing one variant that releases the tuning parameters and is able to handle
multi-objective optimization. This new approach applies normalization to
simplify the original algorithm and uses a penalty function to exploit
infeasible solutions with low constraint violation to solve the constraint
optimization problem. Extensive experimental studies are carried out and the
results reveal efficacy of the proposed approach to constraint handling.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02395</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02396</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unconstrained Scene Text and Video Text Recognition for Arabic Script</dc:title>
 <dc:creator>Jain, Mohit</dc:creator>
 <dc:creator>Mathew, Minesh</dc:creator>
 <dc:creator>Jawahar, C. V.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Building robust recognizers for Arabic has always been challenging. We
demonstrate the effectiveness of an end-to-end trainable CNN-RNN hybrid
architecture in recognizing Arabic text in videos and natural scenes. We
outperform previous state-of-the-art on two publicly available video text
datasets - ALIF and ACTIV. For the scene text recognition task, we introduce a
new Arabic scene text dataset and establish baseline results. For scripts like
Arabic, a major challenge in developing robust recognizers is the lack of large
quantity of annotated data. We overcome this by synthesising millions of Arabic
text images from a large vocabulary of Arabic words and phrases. Our
implementation is built on top of the model introduced here [37] which is
proven quite effective for English scene text recognition. The model follows a
segmentation-free, sequence to sequence transcription approach. The network
transcribes a sequence of convolutional features from the input image to a
sequence of target labels. This does away with the need for segmenting input
image into constituent characters/glyphs, which is often difficult for Arabic
script. Further, the ability of RNNs to model contextual dependencies yields
superior recognition results.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02413</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ZipNet-GAN: Inferring Fine-grained Mobile Traffic Patterns via a
  Generative Adversarial Neural Network</dc:title>
 <dc:creator>Zhang, Chaoyun</dc:creator>
 <dc:creator>Ouyang, Xi</dc:creator>
 <dc:creator>Patras, Paul</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Large-scale mobile traffic analytics is becoming essential to digital
infrastructure provisioning, public transportation, events planning, and other
domains. Monitoring city-wide mobile traffic is however a complex and costly
process that relies on dedicated probes. Some of these probes have limited
precision or coverage, others gather tens of gigabytes of logs daily, which
independently offer limited insights. Extracting fine-grained patterns involves
expensive spatial aggregation of measurements, storage, and post-processing. In
this paper, we propose a mobile traffic super-resolution technique that
overcomes these problems by inferring narrowly localised traffic consumption
from coarse measurements. We draw inspiration from image processing and design
a deep-learning architecture tailored to mobile networking, which combines
Zipper Network (ZipNet) and Generative Adversarial neural Network (GAN) models.
This enables to uniquely capture spatio-temporal relations between traffic
volume snapshots routinely monitored over broad coverage areas
(`low-resolution') and the corresponding consumption at 0.05 km $^2$ level
(`high-resolution') usually obtained after intensive computation. Experiments
we conduct with a real-world data set demonstrate that the proposed
ZipNet(-GAN) infers traffic consumption with remarkable accuracy and up to
100$\times$ higher granularity as compared to standard probing, while
outperforming existing data interpolation techniques. To our knowledge, this is
the first time super-resolution concepts are applied to large-scale mobile
traffic analysis and our solution is the first to infer fine-grained urban
traffic patterns from coarse aggregates.
</dc:description>
 <dc:description>Comment: To appear ACM CoNEXT 2017</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02421</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Lower Bound for the Information Bottleneck Limit</dc:title>
 <dc:creator>Painsky, Amichai</dc:creator>
 <dc:creator>Tishby, Naftali</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The Information Bottleneck (IB) is a conceptual method for extracting the
most compact, yet informative, representation of a set of variables, with
respect to the target. It generalizes the notion of minimal sufficient
statistics from classical parametric statistics to a broader
information-theoretic sense. The IB curve defines the optimal trade-off between
representation complexity and its predictive power. Specifically, it is
achieved by minimizing the level of mutual information (MI) between the
representation and the original variables, subject to a minimal level of MI
between the representation and the target. This problem is shown to be in
general NP hard. One important exception is the multivariate Gaussian case, for
which the Gaussian IB (GIB) is known to obtain an analytical closed form
solution, similar to Canonical Correlation Analysis (CCA). In this work we
introduce a Gaussian lower bound to the IB curve; we find an embedding of the
data which maximizes its &quot;Gaussian part&quot;, on which we apply the GIB. This
embedding provides an efficient (and practical) representation of any arbitrary
data-set (in the IB sense), which in addition holds the favorable properties of
a Gaussian distribution. Importantly, we show that the optimal Gaussian
embedding is bounded from above by non-linear CCA. This allows a fundamental
limit for our ability to Gaussianize arbitrary data-sets and solve complex
problems by linear methods.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02427</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The ACCompanion v0.1: An Expressive Accompaniment System</dc:title>
 <dc:creator>Cancino-Chac&#xf3;n, Carlos</dc:creator>
 <dc:creator>Bonev, Martin</dc:creator>
 <dc:creator>Durand, Amaury</dc:creator>
 <dc:creator>Grachten, Maarten</dc:creator>
 <dc:creator>Arzt, Andreas</dc:creator>
 <dc:creator>Bishop, Laura</dc:creator>
 <dc:creator>Goebl, Werner</dc:creator>
 <dc:creator>Widmer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  In this paper we present a preliminary version of the ACCompanion, an
expressive accompaniment system for MIDI input. The system uses a probabilistic
monophonic score follower to track the position of the soloist in the score,
and a linear Gaussian model to compute tempo updates. The expressiveness of the
system is powered by the Basis-Mixer, a state-of-the-art computational model of
expressive music performance. The system allows for expressive dynamics, timing
and articulation.
</dc:description>
 <dc:description>Comment: Presented at the Late-Breaking Demo Session of the 18th International
  Society for Music Information Retrieval Conference (ISMIR 2017), Suzhou,
  China, 2017</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02439</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Characteristics of Distortion Radiated from Antenna Arrays with
  Transceiver Nonlinearities</dc:title>
 <dc:creator>Moll&#xe9;n, Christopher</dc:creator>
 <dc:creator>Gustavsson, Ulf</dc:creator>
 <dc:creator>Eriksson, Thomas</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The distortion from massive MIMO (multiple-input--multiple-output) base
stations with nonlinear amplifiers is studied and its radiation pattern is
derived. The distortion is analyzed both in-band and out-of-band. By using an
orthogonal Hermite representation of the amplified signal, the spatial
cross-correlation matrix of the nonlinear distortion is obtained. It shows
that, if the input signal to the amplifiers has a dominant beam, the distortion
is beamformed in the same way as that beam. When there are multiple beams
without any one being dominant, it is shown that the distortion is practically
isotropic. The derived theory is useful to predict how the nonlinear distortion
will behave, to analyze the out-of-band radiation, to do reciprocity
calibration, and to schedule users in the frequency plane to minimize the
effect of in-band distortion.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02441</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Hardware Implementations of Visual Object Trackers</dc:title>
 <dc:creator>El-Shafie, Al-Hussein A.</dc:creator>
 <dc:creator>Habib, S. E. D.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual object tracking is an active topic in the computer vision domain with
applications extending over numerous fields. The main sub-tasks required to
build an object tracker (e.g. object detection, feature extraction and object
tracking) are computation-intensive. In addition, real-time operation of the
tracker is indispensable for almost all of its applications. Therefore,
complete hardware or hardware/software co-design approaches are pursued for
better tracker implementations. This paper presents a literature survey of the
hardware implementations of object trackers over the last two decades. Although
several tracking surveys exist in literature, a survey addressing the hardware
implementations of the different trackers is missing. We believe this survey
would fill the gap and complete the picture with the existing surveys of how to
design an efficient tracker and point out the future directions researchers can
follow in this field. We highlight the lack of hardware implementations for
state-of-the-art tracking algorithms as well as for enhanced classical
algorithms. We also stress the need for measuring the tracking performance of
the hardware-based trackers. Additionally, enough details of the hardware-based
trackers need to be provided to allow reasonable comparison between the
different implementations.
</dc:description>
 <dc:description>Comment: 17 pages, 14 Figures, 6 tables, 84 references</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02447</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection of Wordpress Content Injection Vulnerability</dc:title>
 <dc:creator>Hassan, Md. Maruf</dc:creator>
 <dc:creator>Sarker, Kaushik</dc:creator>
 <dc:creator>Biswas, Saikat</dc:creator>
 <dc:creator>Sharif, Md. Hasan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The popularity of content management software (CMS) is growing vastly to the
web developers and the business people because of its capacity for easy
accessibility, manageability and usability of the distributed website contents.
As per the statistics of Built with, 32% of the web applications are developed
with WordPress(WP) among all other CMSs [1]. It is obvious that quite a good
number of web applications were built with WP in version 4.7.0 and 4.7.1. A
recent research reveals that content injection vulnerability was found
available in the above two versions of WP [2]. Unauthorized content injection
by an intruder in a CMS managed application is one of the serious problems for
the business as well as for the web owner.Therefore, detection of the
vulnerability becomes a critical issue for this time. In this paper, we have
discussed about the root cause of WP content injection of the above versions
and have also proposed a detection model for the given vulnerability. A tool,
SAISAN has been implemented as per our anticipated model and conducted an
examination on 176 WP developed web applications using SAISAN. We achieved the
accuracy of 92% of the result of SAISAN as compared to manual black box testing
outcome.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02447</dc:identifier>
 <dc:identifier>doi:10.5121/ijci.2017.6501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02448</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cortical microcircuits as gated-recurrent neural networks</dc:title>
 <dc:creator>Costa, Rui Ponte</dc:creator>
 <dc:creator>Assael, Yannis M.</dc:creator>
 <dc:creator>Shillingford, Brendan</dc:creator>
 <dc:creator>de Freitas, Nando</dc:creator>
 <dc:creator>Vogels, Tim P.</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Cortical circuits exhibit intricate recurrent architectures that are
remarkably similar across different brain areas. Such stereotyped structure
suggests the existence of common computational principles. However, such
principles have remained largely elusive. Inspired by gated-memory networks,
namely long short-term memory networks (LSTMs), we introduce a recurrent neural
network in which information is gated through inhibitory cells that are
subtractive (subLSTM). We propose a natural mapping of subLSTMs onto known
canonical excitatory-inhibitory cortical microcircuits. Our empirical
evaluation across sequential image classification and language modelling tasks
shows that subLSTM units can achieve similar performance to LSTM units. These
results suggest that cortical circuits can be optimised to solve complex
contextual problems and proposes a novel view on their computational function.
Overall our work provides a step towards unifying recurrent networks as used in
machine learning with their biological counterparts.
</dc:description>
 <dc:description>Comment: To appear in Advances in Neural Information Processing Systems 30
  (NIPS 2017). 13 pages, 2 figures (and 1 supp. figure)</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02450</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shape Representation by Zippable Ribbons</dc:title>
 <dc:creator>Sch&#xfc;ller, Christian</dc:creator>
 <dc:creator>Poranne, Roi</dc:creator>
 <dc:creator>Sorkine-Hornung, Olga</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Shape fabrication from developable parts is the basis for arts such as
papercraft and needlework, as well as modern architecture and CAD in general,
and it has inspired much research. We observe that the assembly of complex 3D
shapes created by existing methods often requires first fabricating many small
flat parts and then carefully following instructions to assemble them together.
Despite its significance, this error prone and tedious process is generally
neglected in the discussion. We propose an approach for shape representation
through a single developable part that attaches to itself and requires no
assembly instructions. Our inspiration comes from the so-called zipit bags,
which are made of a single, long ribbon with a zipper around its boundary. In
order to &quot;assemble&quot; the bag, one simply needs to zip up the ribbon. Our method
operates in the same fashion, but it can be used to approximate any shape.
Given a 3D model, our algorithm produces plans for a single 2D shape that can
be laser cut in few parts from flat fabric or paper. We can then attach a
zipper along the boundary for quick assembly and disassembly, or apply more
traditional approaches, such as gluing and stitching. We show physical and
virtual results that demonstrate the capabilities of our method and the ease
with which shapes can be assembled.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02455</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisionist Simulations: A New Approach to Proving Space Lower Bounds</dc:title>
 <dc:creator>Ellen, Faith</dc:creator>
 <dc:creator>Gelashvili, Rati</dc:creator>
 <dc:creator>Zhu, Leqi</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Determining the space complexity of $x$-obstruction-free $k$-set agreement
for $x\leq k$ is an open problem. In $x$-obstruction-free protocols, processes
are required to return in executions where at most $x$ processes take steps.
The best known upper bound on the number of registers needed to solve this
problem among $n&gt;k$ processes is $n-k+x$ registers. No general lower bound
better than $2$ was known.
  We prove that any $x$-obstruction-free protocol solving $k$-set agreement
among $n&gt;k$ processes uses at least $\lfloor(n-x)/(k+1-x)\rfloor+1$ registers.
Our main tool is a simulation that serves as a reduction from the impossibility
of deterministic wait-free $k$-set agreement: if a protocol uses fewer
registers, then it is possible for $k+1$ processes to simulate the protocol and
deterministically solve $k$-set agreement in a wait-free manner, which is
impossible. A critical component of the simulation is the ability of simulating
processes to revise the past of simulated processes. We introduce a new
augmented snapshot object, which facilitates this.
  We also prove that any space lower bound on the number of registers used by
obstruction-free protocols applies to protocols that satisfy nondeterministic
solo termination. Hence, our lower bound of $\lfloor(n-1)/k\rfloor+1$ for the
obstruction-free ($x=1$) case also holds for randomized wait-free free
protocols. In particular, this gives a tight lower bound of exactly $n$
registers for solving obstruction-free and randomized wait-free consensus.
  Finally, our new techniques can be applied to get a space lower of $\lfloor
n/2\rfloor+1$ for $\epsilon$-approximate agreement, for sufficiently small
$\epsilon$. It requires participating processes to return values within
$\epsilon$ of each other. The best known upper bounds are
$\lceil\log(1/\epsilon)\rceil$ and $n$, while no general lower bounds were
known.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2018-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02456</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-referential basis of undecidable dynamics: from The Liar Paradox
  and The Halting Problem to The Edge of Chaos</dc:title>
 <dc:creator>Prokopenko, Mikhail</dc:creator>
 <dc:creator>Harr&#xe9;, Michael</dc:creator>
 <dc:creator>Lizier, Joseph</dc:creator>
 <dc:creator>Boschetti, Fabio</dc:creator>
 <dc:creator>Peppas, Pavlos</dc:creator>
 <dc:creator>Kauffman, Stuart</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:subject>03Dxx, 68Qxx, 37Fxx</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  In this paper we explore several fundamental relations between formal
systems, algorithms, and dynamical systems, focussing on the roles of
undecidability, universality, diagonalization, and self-reference in each of
these computational frameworks. Some of these interconnections are well-known,
while some are clarified in this study as a result of a fine-grained comparison
between recursive formal systems, Turing machines, and Cellular Automata (CAs).
In particular, we elaborate on the diagonalization argument applied to
distributed computation carried out by CAs, illustrating the key elements of
G\&quot;odel's proof for CAs. The comparative analysis emphasizes three factors
which underlie the capacity to generate undecidable dynamics within the
examined computational frameworks: (i) the program-data duality; (ii) the
potential to access an infinite computational medium; and (iii) the ability to
implement negation. The considered adaptations of G\&quot;odel's proof distinguish
between computational universality and undecidability, and show how the
diagonalization argument exploits, on several levels, the self-referential
basis of undecidability.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02469</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating Queuing Regime into Cognitive Radio Channel Aggregation
  Policies: A Performance Evaluation</dc:title>
 <dc:creator>Esenogho, Ebenezer</dc:creator>
 <dc:creator>Mambou, Elie Ngomseu</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Channel aggregation (CA) is one of the newest concept which cognitive radio
network is bringing to bear for the smooth role out of fifth/next generation
wireless networks. This is the combining of several unused primary user
spectrum holes into a logic usable channel. However, several of these
strategies have been investigated considering the varying nature of wireless
link and adaptive modulation and coding (AMC). Examples are the instant
blocking strategy (IBS) and readjustment based strategy (RBS). This paper
develops and compares two CA policies with queue, which are the IBS with queue
(IBS + Q), and the RBS with queue (RBS+Q). This is in furtherance of previous
proposed work. The aim is to identifying the impact of a queuing regime on the
performance of the secondary network such that any secondary user (SU) that has
not completed its service, as an alternative to dropping or forcibly
terminating the service, it is queued in order to get another opportunity to
access the primary user (PU) channels. The performance is evaluated through a
simulation framework. The results validate that with a welldesigned queuing
regime, capacity, access and other metrics can be improved with significant
reduction in blocking and forced termination probabilities respectively.
</dc:description>
 <dc:description>Comment: 5 pages, 7 figures, conference</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02473</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exposing and exploiting structure: optimal code generation for
  high-order finite element methods</dc:title>
 <dc:creator>Homolya, Mikl&#xf3;s</dc:creator>
 <dc:creator>Kirby, Robert C.</dc:creator>
 <dc:creator>Ham, David A.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Code generation based software platforms, such as Firedrake, have become
popular tools for developing complicated finite element discretisations of
partial differential equations. We extended the code generation infrastructure
in Firedrake with optimisations that can exploit the structure inherent to some
finite elements. This includes sum factorisation on cuboid cells for
continuous, discontinuous, H(div) and H(curl) conforming elements. Our
experiments confirm optimal algorithmic complexity for high-order finite
element assembly. This is achieved through several novel contributions: the
introduction of a more powerful interface between the form compiler and the
library providing the finite elements; a more abstract, smarter library of
finite elements called FInAT that explicitly communicates the structure of
elements; and form compiler algorithms to automatically exploit this exposed
structure.
</dc:description>
 <dc:description>Comment: Submitted to ACM Transactions on Mathematical Software</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02476</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SWOOP: Top-k Similarity Joins over Set Streams</dc:title>
 <dc:creator>Mann, Willi</dc:creator>
 <dc:creator>Augsten, Nikolaus</dc:creator>
 <dc:creator>Jensen, Christian S.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We provide efficient support for applications that aim to continuously find
pairs of similar sets in rapid streams of sets. A prototypical example setting
is that of tweets. A tweet is a set of words, and Twitter emits about half a
billion tweets per day. Our solution makes it possible to efficiently maintain
the top-$k$ most similar tweets from a pair of rapid Twitter streams, e.g., to
discover similar trends in two cities if the streams concern cities.
  Using a sliding window model, the top-$k$ result changes as new sets in the
stream enter the window or existing ones leave the window. Maintaining the
top-$k$ result under rapid streams is challenging. First, when a set arrives,
it may form a new pair for the top-$k$ result with any set already in the
window. Second, when a set leaves the window, all its pairings in the top-$k$
are invalidated and must be replaced. It is not enough to maintain the $k$ most
similar pairs, as less similar pairs may eventually be promoted to the top-$k$
result. A straightforward solution that pairs every new set with all sets in
the window and keeps all pairs for maintaining the top-$k$ result is memory
intensive and too slow. We propose SWOOP, a highly scalable stream join
algorithm that solves these issues. Novel indexing techniques and sophisticated
filters efficiently prune useless pairs as new sets enter the window. SWOOP
incrementally maintains a stock of similar pairs to update the top-$k$ result
at any time, and the stock is shown to be minimal. Our experiments confirm that
SWOOP can deal with stream rates that are orders of magnitude faster than the
rates of existing approaches.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02478</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grafting for Combinatorial Boolean Model using Frequent Itemset Mining</dc:title>
 <dc:creator>Lee, Taito</dc:creator>
 <dc:creator>Matsushima, Shin</dc:creator>
 <dc:creator>Yamanishi, Kenji</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper introduces the combinatorial Boolean model (CBM), which is defined
as the class of linear combinations of conjunctions of Boolean attributes. This
paper addresses the issue of learning CBM from labeled data. CBM is of high
knowledge interpretability but na\&quot;{i}ve learning of it requires exponentially
large computation time with respect to data dimension and sample size. To
overcome this computational difficulty, we propose an algorithm GRAB (GRAfting
for Boolean datasets), which efficiently learns CBM within the
$L_1$-regularized loss minimization framework. The key idea of GRAB is to
reduce the loss minimization problem to the weighted frequent itemset mining,
in which frequent patterns are efficiently computable. We employ benchmark
datasets to empirically demonstrate that GRAB is effective in terms of
computational efficiency, prediction accuracy and knowledge discovery.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02483</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cache-Enabled Physical Layer Security for Video Streaming in
  Backhaul-Limited Cellular Networks</dc:title>
 <dc:creator>Xiang, Lin</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:creator>Wong, Vincent W. S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a novel wireless caching scheme to enhance the
physical layer security of video streaming in cellular networks with limited
backhaul capacity. By proactively sharing video data across a subset of base
stations (BSs) through both caching and backhaul loading, secure cooperative
joint transmission of several BSs can be dynamically enabled in accordance with
the cache status, the channel conditions, and the backhaul capacity. Assuming
imperfect channel state information (CSI) at the transmitters, we formulate a
two-stage non-convex mixed-integer robust optimization problem for minimizing
the total transmit power while providing quality of service (QoS) and
guaranteeing communication secrecy during video delivery, where the caching and
the cooperative transmission policy are optimized in an offline video caching
stage and an online video delivery stage, respectively. Although the formulated
optimization problem turns out to be NP-hard, low-complexity polynomial-time
algorithms, whose solutions are globally optimal under certain conditions, are
proposed for cache training and video delivery control. Caching is shown to be
beneficial as it reduces the data sharing overhead imposed on the
capacity-constrained backhaul links, introduces additional secure degrees of
freedom, and enables a power-efficient communication system design. Simulation
results confirm that the proposed caching scheme achieves simultaneously a low
secrecy outage probability and a high power efficiency. Furthermore, due to the
proposed robust optimization, the performance loss caused by imperfect CSI
knowledge can be significantly reduced when the cache capacity becomes large.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Trans. Wireless Commun.; 17 pages, 5
  figures</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02484</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Handover Exchange Schemes Between Two Cognitive Radio Base
  Stations with and without Buffers</dc:title>
 <dc:creator>Esenogho, Ebenezer</dc:creator>
 <dc:creator>Mambou, Elie Ngomseu</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This article investigates and evaluate a handover exchange scheme between two
secondary users (SUs) moving in different directions across the handover region
of neighbouring cell in a cognitive radio network. More specifically, this
investigation compares the performance of SUs in a cellular cognitive radio
network with and without channel exchange systems. The investigation shows
reduced handover failure, blocking, forced and access probabilities
respectively, for handover exchange scheme with buffer as compared to the other
scenario.
</dc:description>
 <dc:description>Comment: 5 pages, 7 figures, conference</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02487</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep density networks and uncertainty in recommender systems</dc:title>
 <dc:creator>Zeldes, Yoel</dc:creator>
 <dc:creator>Theodorakis, Stavros</dc:creator>
 <dc:creator>Solodnik, Efrat</dc:creator>
 <dc:creator>Rotman, Aviv</dc:creator>
 <dc:creator>Chamiel, Gil</dc:creator>
 <dc:creator>Friedman, Dan</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Building robust online content recommendation systems requires learning
complex interactions between user preferences and content features. The field
has evolved rapidly in recent years from traditional multi-arm bandit and
collaborative filtering techniques, with new methods integrating Deep Learning
models that enable to capture non-linear feature interactions. Despite
progress, the dynamic nature of online recommendations still poses great
challenges, such as finding the delicate balance between exploration and
exploitation. In this paper we provide a novel method, Deep Density Networks
(DDN) which deconvolves measurement and data uncertainties and predicts
probability density of CTR (Click Through Rate), enabling us to perform more
efficient exploration of the feature space. We show the usefulness of using DDN
online in a real world content recommendation system that serves billions of
recommendations per day, and present online and offline results to evaluate the
benefit of using DDN.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02488</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MSR-net:Low-light Image Enhancement Using Deep Convolutional Network</dc:title>
 <dc:creator>Shen, Liang</dc:creator>
 <dc:creator>Yue, Zihan</dc:creator>
 <dc:creator>Feng, Fan</dc:creator>
 <dc:creator>Chen, Quan</dc:creator>
 <dc:creator>Liu, Shihao</dc:creator>
 <dc:creator>Ma, Jie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Images captured in low-light conditions usually suffer from very low
contrast, which increases the difficulty of subsequent computer vision tasks in
a great extent. In this paper, a low-light image enhancement model based on
convolutional neural network and Retinex theory is proposed. Firstly, we show
that multi-scale Retinex is equivalent to a feedforward convolutional neural
network with different Gaussian convolution kernels. Motivated by this fact, we
consider a Convolutional Neural Network(MSR-net) that directly learns an
end-to-end mapping between dark and bright images. Different fundamentally from
existing approaches, low-light image enhancement in this paper is regarded as a
machine learning problem. In this model, most of the parameters are optimized
by back-propagation, while the parameters of traditional models depend on the
artificial setting. Experiments on a number of challenging images reveal the
advantages of our method in comparison with other state-of-the-art methods from
the qualitative and quantitative perspective.
</dc:description>
 <dc:description>Comment: 9pages</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02503</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Splitting Proofs for Interpolation</dc:title>
 <dc:creator>Gleiss, Bernhard</dc:creator>
 <dc:creator>Kovacs, Laura</dc:creator>
 <dc:creator>Suda, Martin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We study interpolant extraction from local first-order refutations. We
present a new theoretical perspective on interpolation based on clearly
separating the condition on logical strength of the formula from the
requirement on the com- mon signature. This allows us to highlight the space of
all interpolants that can be extracted from a refutation as a space of simple
choices on how to split the refuta- tion into two parts. We use this new
insight to develop an algorithm for extracting interpolants which are linear in
the size of the input refutation and can be further optimized using metrics
such as number of non-logical symbols or quantifiers. We implemented the new
algorithm in first-order theorem prover VAMPIRE and evaluated it on a large
number of examples coming from the first-order proving community. Our
experiments give practical evidence that our work improves the state-of-the-art
in first-order interpolation.
</dc:description>
 <dc:description>Comment: 26th Conference on Automated Deduction, 2017</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02508</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quaternion kinematics for the error-state Kalman filter</dc:title>
 <dc:creator>Sol&#xe0;, Joan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This article is an exhaustive revision of concepts and formulas related to
quaternions and rotations in 3D space, and their proper use in estimation
engines such as the error-state Kalman filter.
  The paper includes an in-depth study of the rotation group and its Lie
structure, with formulations using both quaternions and rotation matrices. It
makes special attention in the definition of rotation perturbations,
derivatives and integrals. It provides numerous intuitions and geometrical
interpretations to help the reader grasp the inner mechanisms of 3D rotation.
  The whole material is used to devise precise formulations for error-state
Kalman filters suited for real applications using integration of signals from
an inertial measurement unit (IMU).
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02508</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02509</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure Regularized Bidirectional Recurrent Convolutional Neural
  Network for Relation Classification</dc:title>
 <dc:creator>Wen, Ji</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Relation classification is an important semantic processing task in the field
of natural language processing (NLP). In this paper, we present a novel model,
Structure Regularized Bidirectional Recurrent Convolutional Neural
Network(SR-BRCNN), to classify the relation of two entities in a sentence, and
the new dataset of Chinese Sanwen for named entity recognition and relation
classification. Some state-of-the-art systems concentrate on modeling the
shortest dependency path (SDP) between two entities leveraging convolutional or
recurrent neural networks. We further explore how to make full use of the
dependency relations information in the SDP and how to improve the model by the
method of structure regularization. We propose a structure regularized model to
learn relation representations along the SDP extracted from the forest formed
by the structure regularized dependency tree, which benefits reducing the
complexity of the whole model and helps improve the $F_{1}$ score by 10.3.
Experimental results show that our method outperforms the state-of-the-art
approaches on the Chinese Sanwen task and performs as well on the SemEval-2010
Task 8 dataset\footnote{The Chinese Sanwen corpus this paper developed and used
will be released in the further.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1411.6243 by other authors</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02510</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fault Detection of Broken Rotor Bar in LS-PMSM Using Random Forests</dc:title>
 <dc:creator>Quiroz, Juan C.</dc:creator>
 <dc:creator>Mariun, Norman</dc:creator>
 <dc:creator>Mehrjou, Mohammad Rezazadeh</dc:creator>
 <dc:creator>Izadi, Mahdi</dc:creator>
 <dc:creator>Misron, Norhisam</dc:creator>
 <dc:creator>Radzi, Mohd Amran Mohd</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper proposes a new approach to diagnose broken rotor bar failure in a
line start-permanent magnet synchronous motor (LS-PMSM) using random forests.
The transient current signal during the motor startup was acquired from a
healthy motor and a faulty motor with a broken rotor bar fault. We extracted 13
statistical time domain features from the startup transient current signal, and
used these features to train and test a random forest to determine whether the
motor was operating under normal or faulty conditions. For feature selection,
we used the feature importances from the random forest to reduce the number of
features to two features. The results showed that the random forest classifies
the motor condition as healthy or faulty with an accuracy of 98.8% using all
features and with an accuracy of 98.4% by using only the mean-index and
impulsion features. The performance of the random forest was compared with a
decision tree, Na\&quot;ive Bayes classifier, logistic regression, linear ridge, and
a support vector machine, with the random forest consistently having a higher
accuracy than the other algorithms. The proposed approach can be used in
industry for online monitoring and fault diagnostic of LS-PMSM motors and the
results can be helpful for the establishment of preventive maintenance plans in
factories.
</dc:description>
 <dc:description>Comment: Elsevier Measurement</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02510</dc:identifier>
 <dc:identifier>doi:10.1016/j.measurement.2017.11.004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02512</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-tuning CNN Image Retrieval with No Human Annotation</dc:title>
 <dc:creator>Radenovi&#x107;, Filip</dc:creator>
 <dc:creator>Tolias, Giorgos</dc:creator>
 <dc:creator>Chum, Ond&#x159;ej</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image descriptors based on activations of Convolutional Neural Networks
(CNNs) have become dominant in image retrieval due to their discriminative
power, compactness of the representation, and the efficiency of search.
Training of CNNs, either from scratch or fine-tuning, requires a large amount
of annotated data, where high quality of the annotation is often crucial. In
this work, we propose to fine-tune CNNs for image retrieval on a large
collection of unordered images in a fully automatic manner. Reconstructed 3D
models, obtained by the state-of-the-art retrieval and structure-from-motion
methods, guide the selection of the training data. We show that both hard
positive and hard negative examples, selected by exploiting the geometry and
the camera positions available from the 3D models, enhance the performance in
particular object retrieval. CNN descriptor whitening discriminatively learned
from the same training data outperforms the commonly used PCA whitening. We
propose a novel trainable Generalized-Mean (GeM) pooling layer that generalizes
max and average pooling and show that it boosts retrieval performance. Applying
the proposed method on VGG network achieves state-of-the-art performance on
standard benchmarks: Oxford Buildings, Paris, and Holidays datasets.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1604.02426</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02513</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CGAlgebra: a Mathematica package for conformal geometric algebra</dc:title>
 <dc:creator>Aragon, Jose L.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  A tutorial of the Mathematica package CGAlgebra, for conformal geometric
algebra calculations is presented. Using rule-based programming, the
5-dimensional conformal geometric algebra is implemented and defined functions
simplify the calculations of geometric, outer and inner products, as well as
many other calculations related with geometric transformations. CGAlgebra is
available from https://github.com/jlaragonvera/Geometric-Algebra
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02515</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous DR-submodular Maximization: Structure and Algorithms</dc:title>
 <dc:creator>Bian, An</dc:creator>
 <dc:creator>Levy, Kfir Y.</dc:creator>
 <dc:creator>Krause, Andreas</dc:creator>
 <dc:creator>Buhmann, Joachim M.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  DR-submodular continuous functions are important objectives with wide
real-world applications spanning MAP inference in determinantal point processes
(DPPs), and mean-field inference for probabilistic submodular models, amongst
others. DR-submodularity captures a subclass of non-convex functions that
enables both exact minimization and approximate maximization in polynomial
time.
  In this work we study the problem of maximizing non-monotone DR-submodular
continuous functions under general down-closed convex constraints. We start by
investigating geometric properties that underlie such objectives, e.g., a
strong relation between (approximately) stationary points and global optimum is
proved. These properties are then used to devise two optimization algorithms
with provable guarantees. Concretely, we first devise a &quot;two-phase&quot; algorithm
with $1/4$ approximation guarantee. This algorithm allows the use of existing
methods for finding (approximately) stationary points as a subroutine, thus,
harnessing recent progress in non-convex optimization. Then we present a
non-monotone Frank-Wolfe variant with $1/e$ approximation guarantee and
sublinear convergence rate. Finally, we extend our approach to a broader class
of generalized DR-submodular continuous functions, which captures a wider
spectrum of applications. Our theoretical findings are validated on synthetic
and real-world problem instances.
</dc:description>
 <dc:description>Comment: Appeared in NIPS 2017</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02520</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end learning for music audio tagging at scale</dc:title>
 <dc:creator>Pons, Jordi</dc:creator>
 <dc:creator>Nieto, Oriol</dc:creator>
 <dc:creator>Prockup, Matthew</dc:creator>
 <dc:creator>Schmidt, Erik M.</dc:creator>
 <dc:creator>Ehmann, Andreas F.</dc:creator>
 <dc:creator>Serra, Xavier</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  The lack of data tends to limit the outcomes of deep learning research -
specially, when dealing with end-to-end learning stacks processing raw data
such as waveforms. In this study we make use of musical labels annotated for
1.2 million tracks. This large amount of data allows us to unrestrictedly
explore different front-end paradigms: from assumption-free models - using
waveforms as input with very small convolutional filters; to models that rely
on domain knowledge - log-mel spectrograms with a convolutional neural network
designed to learn temporal and timbral features. Results suggest that while
spectrogram-based models surpass their waveform-based counterparts, the
difference in performance shrinks as more data are employed.
</dc:description>
 <dc:description>Comment: In proceedings of the Workshop on Machine Learning for Audio Signal
  Processing (ML4Audio) at NIPS 2017. Code:
  https://github.com/jordipons/music-audio-tagging-at-scale-models. Demo:
  http://www.jordipons.me/apps/music-audio-tagging-at-scale-demo/</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02524</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Provable quantum state tomography via non-convex methods</dc:title>
 <dc:creator>Kyrillidis, Anastasios</dc:creator>
 <dc:creator>Kalev, Amir</dc:creator>
 <dc:creator>Park, Dohuyng</dc:creator>
 <dc:creator>Bhojanapalli, Srinadh</dc:creator>
 <dc:creator>Caramanis, Constantine</dc:creator>
 <dc:creator>Sanghavi, Sujay</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  With nowadays steadily growing quantum processors, it is required to develop
new quantum tomography tools that are tailored for high-dimensional systems. In
this work, we describe such a computational tool, based on recent ideas from
non-convex optimization. The algorithm excels in the compressed-sensing-like
setting, where only a few data points are measured from a low-rank or
highly-pure quantum state of a high-dimensional system. We show that the
algorithm can practically be used in quantum tomography problems that are
beyond the reach of convex solvers, and, moreover, is faster than other
state-of-the-art non-convex approaches. Crucially, we prove that, despite being
a non-convex program, under mild conditions, the algorithm is guaranteed to
converge to the global minimum of the problem; thus, it constitutes a provable
quantum state tomography protocol.
</dc:description>
 <dc:description>Comment: 21 pages, 26 figures, code included</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:date>2017-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02525</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Robust Bed Making using Deep Imitation Learning with DART</dc:title>
 <dc:creator>Laskey, Michael</dc:creator>
 <dc:creator>Powers, Chris</dc:creator>
 <dc:creator>Joshi, Ruta</dc:creator>
 <dc:creator>Poursohi, Arshan</dc:creator>
 <dc:creator>Goldberg, Ken</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Bed-making is a universal home task that can be challenging for senior
citizens due to reaching motions. Automating bed-making has multiple technical
challenges such as perception in an unstructured environments, deformable
object manipulation, obstacle avoidance and sequential decision making. We
explore how DART, an LfD algorithm for learning robust policies, can be applied
to automating bed making without fiducial markers with a Toyota Human Support
Robot (HSR). By gathering human demonstrations for grasping the sheet and
failure detection, we can learn deep neural network policies that leverage
pre-trained YOLO features to automate the task. Experiments with a 1/2 scale
twin bed and distractors placed on the bed, suggest policies learned on 50
demonstrations with DART achieve 96% sheet coverage, which is over 200% better
than a corner detector baseline using contour detection.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02536</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Few-Shot Adversarial Domain Adaptation</dc:title>
 <dc:creator>Motiian, Saeid</dc:creator>
 <dc:creator>Jones, Quinn</dc:creator>
 <dc:creator>Iranmanesh, Seyed Mehdi</dc:creator>
 <dc:creator>Doretto, Gianfranco</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This work provides a framework for addressing the problem of supervised
domain adaptation with deep models. The main idea is to exploit adversarial
learning to learn an embedded subspace that simultaneously maximizes the
confusion between two domains while semantically aligning their embedding. The
supervised setting becomes attractive especially when there are only a few
target data samples that need to be labeled. In this few-shot learning
scenario, alignment and separation of semantic probability distributions is
difficult because of the lack of data. We found that by carefully designing a
training scheme whereby the typical binary adversarial discriminator is
augmented to distinguish between four different classes, it is possible to
effectively address the supervised adaptation problem. In addition, the
approach has a high speed of adaptation, i.e. it requires an extremely low
number of labeled target training samples, even one per category can be
effective. We then extensively compare this approach to the state of the art in
domain adaptation in two experiments: one using datasets for handwritten digit
recognition, and one using datasets for visual object recognition.
</dc:description>
 <dc:description>Comment: Accepted to NIPS 2017. arXiv admin note: text overlap with
  arXiv:1709.10190</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02540</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safe and Resilient Multi-vehicle Trajectory Planning Under Adversarial
  Intruder</dc:title>
 <dc:creator>Bansal, Somil</dc:creator>
 <dc:creator>Chen, Mo</dc:creator>
 <dc:creator>Tomlin, Claire J.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Provably safe and scalable multi-vehicle trajectory planning is an important
and urgent problem. Hamilton-Jacobi (HJ) reachability is an ideal tool for
analyzing such safety-critical systems and has been successfully applied to
several small-scale problems. However, a direct application of HJ reachability
to multi-vehicle trajectory planning is often intractable due to the &quot;curse of
dimensionality.&quot; To overcome this problem, the sequential trajectory planning
(STP) method, which assigns strict priorities to vehicles, was proposed, STP
allows multi-vehicle trajectory planning to be done with a linearly-scaling
computation complexity. However, if a vehicle not in the set of STP vehicles
enters the system, or even worse, if this vehicle is an adversarial intruder,
the previous formulation requires the entire system to perform replanning, an
intractable task for large-scale systems. In this paper, we make STP more
practical by providing a new algorithm where replanning is only needed only for
a fixed number of vehicles, irrespective of the total number of STP vehicles.
Moreover, this number is a design parameter, which can be chosen based on the
computational resources available during run time. We demonstrate this
algorithm in a representative simulation of an urban airspace environment.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Automatic Control. arXiv admin
  note: text overlap with arXiv:1611.08364</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02545</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Learning for Changing Environments using Coin Betting</dc:title>
 <dc:creator>Jun, Kwang-Sung</dc:creator>
 <dc:creator>Orabona, Francesco</dc:creator>
 <dc:creator>Wright, Stephen</dc:creator>
 <dc:creator>Willett, Rebecca</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A key challenge in online learning is that classical algorithms can be slow
to adapt to changing environments. Recent studies have proposed &quot;meta&quot;
algorithms that convert any online learning algorithm to one that is adaptive
to changing environments, where the adaptivity is analyzed in a quantity called
the strongly-adaptive regret. This paper describes a new meta algorithm that
has a strongly-adaptive regret bound that is a factor of $\sqrt{\log(T)}$
better than other algorithms with the same time complexity, where $T$ is the
time horizon. We also extend our algorithm to achieve a first-order (i.e.,
dependent on the observed losses) strongly-adaptive regret bound for the first
time, to our knowledge. At its heart is a new parameter-free algorithm for the
learning with expert advice (LEA) problem in which experts sometimes do not
output advice for consecutive time steps (i.e., \emph{sleeping} experts). This
algorithm is derived by a reduction from optimal algorithms for the so-called
coin betting problem. Empirical results show that our algorithm outperforms
state-of-the-art methods in both learning with expert advice and metric
learning scenarios.
</dc:description>
 <dc:description>Comment: submitted to a journal. arXiv admin note: substantial text overlap
  with arXiv:1610.04578</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02549</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Remote Sensing Image Fusion Based on Two-stream Fusion Network</dc:title>
 <dc:creator>Liu, Xiangyu</dc:creator>
 <dc:creator>Liu, Qingjie</dc:creator>
 <dc:creator>Wang, Yunhong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Remote sensing image fusion (also known as pan-sharpening) aims at generating
high resolution multi-spectral (MS) image from inputs of a high spatial
resolution single band panchromatic (PAN) image and a low spatial resolution
multi-spectral image. Inspired by the astounding achievements of convolutional
neural networks (CNNs) in a variety of computer vision tasks, in this paper, we
propose a two-stream fusion network (TFNet) to address the problem of
pan-sharpening. Unlike previous CNN based methods that consider pan-sharpening
as a super resolution problem and perform pan-sharpening in pixel level, the
proposed TFNet aims to fuse PAN and MS images in feature level and reconstruct
the pan-sharpened image from the fused features. The TFNet mainly consists of
three parts. The first part is comprised of two networks extracting features
from PAN and MS images, respectively. The subsequent network fuses them
together to form compact features that represent both spatial and spectral
information of PAN and MS images, simultaneously. Finally, the desired high
spatial resolution MS image is recovered from the fused features through an
image reconstruction network. Experiments on Quickbird and \mbox{GaoFen-1}
satellite images demonstrate that the proposed TFNet can fuse PAN and MS
images, effectively, and produce pan-sharpened images competitive with even
superior to state of the arts.
</dc:description>
 <dc:description>Comment: An extension of MMM 2018</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2018-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02552</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explicit Error Bounds for Carleman Linearization</dc:title>
 <dc:creator>Forets, Marcelo</dc:creator>
 <dc:creator>Pouly, Amaury</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We revisit the method of Carleman linearization for systems of ordinary
differential equations with polynomial right-hand sides. This transformation
provides an approximate linearization in a higher-dimensional space through the
exact embedding of polynomial nonlinearities into an infinite-dimensional
linear system, which is then truncated to obtain a finite-dimensional
representation with an additive error. To the best of our knowledge, no
explicit calculation of the error bound has been studied. In this paper, we
propose two strategies to obtain a time-dependent function that locally bounds
the truncation error. In the first approach, we proceed by iterative
backwards-integration of the truncated system. However, the resulting error
bound requires an a priori estimate of the norm of the exact solution for the
given time horizon. To overcome this difficulty, we construct a combinatorial
approach and solve it using generating functions, obtaining a local error bound
that can be computed effectively.
</dc:description>
 <dc:description>Comment: 32 pages, 3 figures</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02574</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Optimization of PDEs with Random Coefficients Using a Multilevel
  Monte Carlo Method</dc:title>
 <dc:creator>Van Barel, Andreas</dc:creator>
 <dc:creator>Vandewalle, Stefan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  This paper addresses optimization problems constrained by partial
differential equations with uncertain coefficients. In particular, the robust
control problem and the average control problem are considered for a tracking
type cost functional with an additional penalty on the variance of the state.
The expressions for the gradient and Hessian corresponding to either problem
contain expected value operators. Due to the large number of uncertainties
considered in our model, we suggest to evaluate these expectations using a
multilevel Monte Carlo (MLMC) method. Under mild assumptions, it is shown that
this results in the gradient and Hessian corresponding to the MLMC estimator of
the original cost functional. Furthermore, we show that the use of certain
correlated samples yields a reduction in the total number of samples required.
Two optimization methods are investigated: the nonlinear conjugate gradient
method and the Newton method. For both, a specific algorithm is provided that
dynamically decides which and how many samples should be taken in each
iteration. The cost of the optimization up to some specified tolerance $\tau$
is shown to be proportional to the cost of a gradient evaluation with requested
root mean square error $\tau$. The algorithms are tested on a model elliptic
diffusion problem with lognormal diffusion coefficient. An additional nonlinear
term is also considered.
</dc:description>
 <dc:description>Comment: This work was presented at the IMG 2016 conference (Dec 5 - Dec 9,
  2016), at the Copper Mountain conference (Mar 26 - Mar 30, 2017), and at the
  FrontUQ conference (Sept 5 - Sept 8, 2017)</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02578</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Captioning and Classification of Dangerous Situations</dc:title>
 <dc:creator>Arriaga, Octavio</dc:creator>
 <dc:creator>Pl&#xf6;ger, Paul</dc:creator>
 <dc:creator>Valdenegro-Toro, Matias</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current robot platforms are being employed to collaborate with humans in a
wide range of domestic and industrial tasks. These environments require
autonomous systems that are able to classify and communicate anomalous
situations such as fires, injured persons, car accidents; or generally, any
potentially dangerous situation for humans. In this paper we introduce an
anomaly detection dataset for the purpose of robot applications as well as the
design and implementation of a deep learning architecture that classifies and
describes dangerous situations using only a single image as input. We report a
classification accuracy of 97 % and METEOR score of 16.2. We will make the
dataset publicly available after this paper is accepted.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02581</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Neural Network Steganalysis's Application to Steganography</dc:title>
 <dc:creator>Sharifzadeh, Mehdi</dc:creator>
 <dc:creator>Agarwal, Chirag</dc:creator>
 <dc:creator>Aloraini, Mohammed</dc:creator>
 <dc:creator>Schonfeld, Dan</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  This paper presents a novel approach to increase the performance bounds of
image steganography under the criteria of minimizing distortion. The proposed
approach utilizes a steganalysis convolutional neural network (CNN) framework
to understand an image's model and embed in less detectable regions to preserve
the model. In other word, the trained steganalysis CNN is used to calculate
derivatives of the statistical model of an image with respect to embedding
changes. The experimental results show that the proposed algorithm outperforms
previous state-of-the-art methods in a wide range of low relative payloads when
compared with HUGO, S-UNIWARD, and HILL by the state-of-the-art steganalysis.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1705.08616</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02586</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>5G Millimeter Wave Cellular System Capacity with Fully Digital
  Beamforming</dc:title>
 <dc:creator>Dutta, Sourjya</dc:creator>
 <dc:creator>Barati, C. Nicolas</dc:creator>
 <dc:creator>Dhananjay, Aditya</dc:creator>
 <dc:creator>Rangan, Sundeep</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Due to heavy reliance of millimeter-wave (mmWave) wireless systems on
directional links, Beamforming (BF) with high-dimensional arrays is essential
for cellular systems in these frequencies. How to perform the array processing
in a power efficient manner is a fundamental challenge. Analog and hybrid BF
require fewer analog-to-digital converters (ADCs), but can only communicate in
a small number of directions at a time,limiting directional search, spatial
multiplexing and control signaling. Digital BF enables flexible spatial
processing, but must be operated at a low quantization resolution to stay
within reasonable power levels. This paper presents a simple additive white
Gaussian noise (AWGN) model to assess the effect of low resolution quantization
of cellular system capacity. Simulations with this model reveal that at
moderate resolutions (3-4 bits per ADC), there is negligible loss in downlink
cellular capacity from quantization. In essence, the low-resolution ADCs limit
the high SNR, where cellular systems typically do not operate. The findings
suggest that low-resolution fully digital BF architectures can be power
efficient, offer greatly enhanced control plane functionality and comparable
data plane performance to analog BF.
</dc:description>
 <dc:description>Comment: To appear in the Proceedings of the 51st Asilomar Conference on
  Signals, Systems, and Computers, 2017</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02597</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards an Economic Analysis of Routing in Payment Channel Networks</dc:title>
 <dc:creator>Engelmann, Felix</dc:creator>
 <dc:creator>Glaser, Florian</dc:creator>
 <dc:creator>Kopp, Henning</dc:creator>
 <dc:creator>Kargl, Frank</dc:creator>
 <dc:creator>Weinhardt, Christof</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Payment channel networks are supposed to overcome technical scalability
limitations of blockchain infrastructure by employing a special overlay network
with fast payment confirmation and only sporadic settlement of netted
transactions on the blockchain. However, they introduce economic routing
constraints that limit decentralized scalability and are currently not well
understood. In this paper, we model the economic incentives for participants in
payment channel networks. We provide the first formal model of payment channel
economics and analyze how the cheapest path can be found. Additionally, our
simulation assesses the long-term evolution of a payment channel network. We
find that even for small routing fees, sometimes it is cheaper to settle the
transaction directly on the blockchain.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, SERIAL '17 Workshop</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02597</dc:identifier>
 <dc:identifier>doi:10.1145/3152824.3152826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02598</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Streaming Robust Submodular Maximization: A Partitioned Thresholding
  Approach</dc:title>
 <dc:creator>Mitrovi&#x107;, Slobodan</dc:creator>
 <dc:creator>Bogunovic, Ilija</dc:creator>
 <dc:creator>Norouzi-Fard, Ashkan</dc:creator>
 <dc:creator>Tarnawski, Jakub</dc:creator>
 <dc:creator>Cevher, Volkan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the classical problem of maximizing a monotone submodular function
subject to a cardinality constraint k, with two additional twists: (i) elements
arrive in a streaming fashion, and (ii) m items from the algorithm's memory are
removed after the stream is finished. We develop a robust submodular algorithm
STAR-T. It is based on a novel partitioning structure and an exponentially
decreasing thresholding rule. STAR-T makes one pass over the data and retains a
short but robust summary. We show that after the removal of any m elements from
the obtained summary, a simple greedy algorithm STAR-T-GREEDY that runs on the
remaining elements achieves a constant-factor approximation guarantee. In two
different data summarization tasks, we demonstrate that it matches or
outperforms existing greedy and streaming methods, even if they are allowed the
benefit of knowing the removed subset in advance.
</dc:description>
 <dc:description>Comment: To appear in NIPS 2017</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02598</dc:identifier>
 <dc:identifier>Proc. of 30th Advances in Neural Information Processing Systems
  (NIPS) 2017, pages 4558-4567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02601</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorial Assortment Optimization</dc:title>
 <dc:creator>Immorlica, Nicole</dc:creator>
 <dc:creator>Lucier, Brendan</dc:creator>
 <dc:creator>Mao, Jieming</dc:creator>
 <dc:creator>Syrgkanis, Vasilis</dc:creator>
 <dc:creator>Tzamos, Christos</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Assortment optimization refers to the problem of designing a slate of
products to offer potential customers, such as stocking the shelves in a
convenience store. The price of each product is fixed in advance, and a
probabilistic choice function describes which product a customer will choose
from any given subset. We introduce the combinatorial assortment problem, where
each customer may select a bundle of products. We consider a model of consumer
choice where the relative value of different bundles is described by a
valuation function, while individual customers may differ in their absolute
willingness to pay, and study the complexity of the resulting optimization
problem. We show that any sub-polynomial approximation to the problem requires
exponentially many demand queries when the valuation function is XOS, and that
no FPTAS exists even for succinctly-representable submodular valuations. On the
positive side, we show how to obtain constant approximations under a
&quot;well-priced&quot; condition, where each product's price is sufficiently high. We
also provide an exact algorithm for $k$-additive valuations, and show how to
extend our results to a learning setting where the seller must infer the
customers' preferences from their purchasing behavior.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02604</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unbounded cache model for online language modeling with open vocabulary</dc:title>
 <dc:creator>Grave, Edouard</dc:creator>
 <dc:creator>Cisse, Moustapha</dc:creator>
 <dc:creator>Joulin, Armand</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recently, continuous cache models were proposed as extensions to recurrent
neural network language models, to adapt their predictions to local changes in
the data distribution. These models only capture the local context, of up to a
few thousands tokens. In this paper, we propose an extension of continuous
cache models, which can scale to larger contexts. In particular, we use a large
scale non-parametric memory component that stores all the hidden activations
seen in the past. We leverage recent advances in approximate nearest neighbor
search and quantization algorithms to store millions of representations while
searching them efficiently. We conduct extensive experiments showing that our
approach significantly improves the perplexity of pre-trained language models
on new distributions, and can scale efficiently to much larger contexts than
previously proposed local cache models.
</dc:description>
 <dc:description>Comment: Accepted to NIPS 2017</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02608</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extractive Multi-document Summarization Using Multilayer Networks</dc:title>
 <dc:creator>Tohalino, Jorge V.</dc:creator>
 <dc:creator>Amancio, Diego R.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Huge volumes of textual information has been produced every single day. In
order to organize and understand such large datasets, in recent years,
summarization techniques have become popular. These techniques aims at finding
relevant, concise and non-redundant content from such a big data. While network
methods have been adopted to model texts in some scenarios, a systematic
evaluation of multilayer network models in the multi-document summarization
task has been limited to a few studies. Here, we evaluate the performance of a
multilayer-based method to select the most relevant sentences in the context of
an extractive multi document summarization (MDS) task. In the adopted model,
nodes represent sentences and edges are created based on the number of shared
words between sentences. Differently from previous studies in multi-document
summarization, we make a distinction between edges linking sentences from
different documents (inter-layer) and those connecting sentences from the same
document (intra-layer). As a proof of principle, our results reveal that such a
discrimination between intra- and inter-layer in a multilayered representation
is able to improve the quality of the generated summaries. This piece of
information could be used to improve current statistical methods and related
textual models.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02613</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Moonshine: Distilling with Cheap Convolutions</dc:title>
 <dc:creator>Crowley, Elliot J.</dc:creator>
 <dc:creator>Gray, Gavin</dc:creator>
 <dc:creator>Storkey, Amos</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Model distillation compresses a trained machine learning model, such as a
neural network, into a smaller alternative such that it could be easily
deployed in a resource limited setting. Unfortunately, this requires
engineering two architectures: a student architecture smaller than the first
teacher architecture but trained to emulate it. In this paper, we present a
distillation strategy that produces a student architecture that is a simple
transformation of the teacher architecture. Recent model distillation methods
allow us to preserve most of the performance of the trained model after
replacing convolutional blocks with a cheap alternative. In addition,
distillation by attention transfer provides student network performance that is
better than training that student architecture directly on data.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02621</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convex Optimization with Nonconvex Oracles</dc:title>
 <dc:creator>Mangoubi, Oren</dc:creator>
 <dc:creator>Vishnoi, Nisheeth K.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In machine learning and optimization, one often wants to minimize a convex
objective function $F$ but can only evaluate a noisy approximation $\hat{F}$ to
it. Even though $F$ is convex, the noise may render $\hat{F}$ nonconvex, making
the task of minimizing $F$ intractable in general. As a consequence, several
works in theoretical computer science, machine learning and optimization have
focused on coming up with polynomial time algorithms to minimize $F$ under
conditions on the noise $F(x)-\hat{F}(x)$ such as its uniform-boundedness, or
on $F$ such as strong convexity. However, in many applications of interest,
these conditions do not hold. Here we show that, if the noise has magnitude
$\alpha F(x) + \beta$ for some $\alpha, \beta &gt; 0$, then there is a polynomial
time algorithm to find an approximate minimizer of $F$. In particular, our
result allows for unbounded noise and generalizes those of Applegate and
Kannan, and Zhang, Liang and Charikar, who proved similar results for the
bounded noise case, and that of Belloni et al. who assume that the noise grows
in a very specific manner and that $F$ is strongly convex. Turning our result
on its head, one may also view our algorithm as minimizing a nonconvex function
$\hat{F}$ that is promised to be related to a convex function $F$ as above. Our
algorithm is a &quot;simulated annealing&quot; modification of the stochastic gradient
Langevin Markov chain and gradually decreases the temperature of the chain to
approach the global minimizer. Analyzing such an algorithm for the unbounded
noise model and a general convex function turns out to be challenging and
requires several technical ideas that might be of independent interest in
deriving non-asymptotic bounds for other simulated annealing based algorithms.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02621</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02629</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtual Astronaut for Scientific Visualization - A Prototype for Santa
  Maria Crater on Mars</dc:title>
 <dc:creator>Wang, Jue</dc:creator>
 <dc:creator>Bennett, Keith J.</dc:creator>
 <dc:creator>Guinness, Edward A.</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  To support scientific visualization of multiple-mission data from Mars, the
Virtual Astronaut (VA) creates an interactive virtual 3D environment built on
the Unity3D Game Engine. A prototype study was conducted based on orbital and
Opportunity Rover data covering Santa Maria Crater in Meridiani Planum on Mars.
The VA at Santa Maria provides dynamic visual representations of the imaging,
compositional, and mineralogical information. The VA lets one navigate through
the scene and provides geomorphic and geologic contexts for the rover
operations. User interactions include in-situ observations visualization,
feature measurement, and an animation control of rover drives. This paper
covers our approach and implementation of the VA system. A brief summary of the
prototype system functions and user feedback is also covered. Based on external
review and comments by the science community, the prototype at Santa Maria has
proven the VA to be an effective tool for virtual geovisual analysis.
</dc:description>
 <dc:description>Comment: 20 pages, 11 figures</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02629</dc:identifier>
 <dc:identifier>Future Internet 2012, 4, 1049-1068</dc:identifier>
 <dc:identifier>doi:10.3390/fi40x000x</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02634</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Internalising Interaction Protocols as First-Class Programming Elements
  in Multi Agent Systems</dc:title>
 <dc:creator>Lillis, David J.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Since their inception, Multi Agent Systems (MASs) have been championed as a
solution for the increasing problem of software complexity. Communities of
distributed autonomous computing entities that are capable of collaborating,
negotiating and acting to solve complex organisational and system management
problems are an attractive proposition. Central to this is the requirement for
agents to possess the capability of interacting with one another in a
structured, consistent and organised manner.
  This thesis presents the Agent Conversation Reasoning Engine (ACRE), which
constitutes a holistic view of communication management for MASs. ACRE is
intended to facilitate the practical development, debugging and deployment of
communication-heavy MASs.
  ACRE has been formally defined in terms of its operational semantics, and a
generic architecture has been proposed to facilitate its integration with a
wide variety of diverse agent development frameworks and Agent Oriented
Programming (AOP) languages. A concrete implementation has also been developed
that uses the Agent Factory AOP framework as its base. This allows ACRE to be
used with a number of different AOP languages, while providing a reference
implementation that other integrations can be modelled upon. A standard is also
proposed for the modelling and sharing of agent-focused interaction protocols
that is independent of the platform within which a concrete ACRE implementation
is run.
  Finally, a user evaluation illustrates the benefits of incorporating
conversation management into agent programming.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02634</dc:identifier>
 <dc:identifier>PhD Thesis, University College Dublin, 2012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02637</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safe Adaptive Importance Sampling</dc:title>
 <dc:creator>Stich, Sebastian U.</dc:creator>
 <dc:creator>Raj, Anant</dc:creator>
 <dc:creator>Jaggi, Martin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>90C25, 68W20, 68Q25</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  Importance sampling has become an indispensable strategy to speed up
optimization algorithms for large-scale applications. Improved adaptive
variants - using importance values defined by the complete gradient information
which changes during optimization - enjoy favorable theoretical properties, but
are typically computationally infeasible. In this paper we propose an efficient
approximation of gradient-based sampling, which is based on safe bounds on the
gradient. The proposed sampling distribution is (i) provably the best sampling
with respect to the given bounds, (ii) always better than uniform sampling and
fixed importance sampling and (iii) can efficiently be computed - in many
applications at negligible extra cost. The proposed sampling scheme is generic
and can easily be integrated into existing algorithms. In particular, we show
that coordinate-descent (CD) and stochastic gradient descent (SGD) can enjoy
significant a speed-up under the novel scheme. The proven efficiency of the
proposed sampling is verified by extensive numerical testing.
</dc:description>
 <dc:description>Comment: To appear at NIPS 2017</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02638</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compression-aware Training of Deep Networks</dc:title>
 <dc:creator>Alvarez, Jose M.</dc:creator>
 <dc:creator>Salzmann, Mathieu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In recent years, great progress has been made in a variety of application
domains thanks to the development of increasingly deeper neural networks.
Unfortunately, the huge number of units of these networks makes them expensive
both computationally and memory-wise. To overcome this, exploiting the fact
that deep networks are over-parametrized, several compression strategies have
been proposed. These methods, however, typically start from a network that has
been trained in a standard manner, without considering such a future
compression. In this paper, we propose to explicitly account for compression in
the training process. To this end, we introduce a regularizer that encourages
the parameter matrix of each layer to have low rank during training. We show
that accounting for compression during training allows us to learn much more
compact, yet at least as effective, models than state-of-the-art compression
techniques.
</dc:description>
 <dc:description>Comment: Accepted at NIPS 2017</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02638</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02651</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Theoretical limitations of Encoder-Decoder GAN architectures</dc:title>
 <dc:creator>Arora, Sanjeev</dc:creator>
 <dc:creator>Risteski, Andrej</dc:creator>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Encoder-decoder GANs architectures (e.g., BiGAN and ALI) seek to add an
inference mechanism to the GANs setup, consisting of a small encoder deep net
that maps data-points to their succinct encodings. The intuition is that being
forced to train an encoder alongside the usual generator forces the system to
learn meaningful mappings from the code to the data-point and vice-versa, which
should improve the learning of the target distribution and ameliorate
mode-collapse. It should also yield meaningful codes that are useful as
features for downstream tasks. The current paper shows rigorously that even on
real-life distributions of images, the encode-decoder GAN training objectives
(a) cannot prevent mode collapse; i.e. the objective can be near-optimal even
when the generated distribution has low and finite support (b) cannot prevent
learning meaningless codes for data -- essentially white noise. Thus if
encoder-decoder GANs do indeed work then it must be due to reasons as yet not
understood, since the training objective can be low even for meaningless
solutions.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02652</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Latent hypernet: Exploring all Layers from Convolutional Neural Networks</dc:title>
 <dc:creator>Jordao, Artur</dc:creator>
 <dc:creator>Kloss, Ricardo</dc:creator>
 <dc:creator>Schwartz, William Robson</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Since Convolutional Neural Networks (ConvNets) are able to simultaneously
learn features and classifiers to discriminate different categories of
activities, recent works have employed ConvNets approaches to perform human
activity recognition (HAR) based on wearable sensors, allowing the removal of
expensive human work and expert knowledge. However, these approaches have their
power of discrimination limited mainly by the large number of parameters that
compose the network and the reduced number of samples available for training.
Inspired by this, we propose an accurate and robust approach, referred to as
Latent HyperNet (LHN). The LHN uses feature maps from early layers (hyper) and
projects them, individually, onto a low dimensionality space (latent). Then,
these latent features are concatenated and presented to a classifier. To
demonstrate the robustness and accuracy of the LHN, we evaluate it using four
different networks architectures in five publicly available HAR datasets based
on wearable sensors, which vary in the sampling rate and number of activities.
Our experiments demonstrate that the proposed LHN is able to produce rich
information, improving the results regarding the original ConvNets.
Furthermore, the method outperforms existing state-of-the-art methods.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02653</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural system identification for large populations separating &quot;what&quot; and
  &quot;where&quot;</dc:title>
 <dc:creator>Klindt, David A.</dc:creator>
 <dc:creator>Ecker, Alexander S.</dc:creator>
 <dc:creator>Euler, Thomas</dc:creator>
 <dc:creator>Bethge, Matthias</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Neuroscientists classify neurons into different types that perform similar
computations at different locations in the visual field. Traditional methods
for neural system identification do not capitalize on this separation of 'what'
and 'where'. Learning deep convolutional feature spaces that are shared among
many neurons provides an exciting path forward, but the architectural design
needs to account for data limitations: While new experimental techniques enable
recordings from thousands of neurons, experimental time is limited so that one
can sample only a small fraction of each neuron's response space. Here, we show
that a major bottleneck for fitting convolutional neural networks (CNNs) to
neural data is the estimation of the individual receptive field locations, a
problem that has been scratched only at the surface thus far. We propose a CNN
architecture with a sparse readout layer factorizing the spatial (where) and
feature (what) dimensions. Our network scales well to thousands of neurons and
short recordings and can be trained end-to-end. We evaluate this architecture
on ground-truth data to explore the challenges and limitations of CNN-based
system identification. Moreover, we show that our network model outperforms
current state-of-the art system identification models of mouse primary visual
cortex.
</dc:description>
 <dc:description>Comment: NIPS 2017</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02659</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing ROOT IO For Analysis</dc:title>
 <dc:creator>Bockelman, Brian</dc:creator>
 <dc:creator>Zhang, Zhe</dc:creator>
 <dc:creator>Pivarski, Jim</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The ROOT I/O (RIO) subsystem is foundational to most HEP experiments - it
provides a file format, a set of APIs/semantics, and a reference implementation
in C++. It is often found at the base of an experiment's framework and is used
to serialize the experiment's data; in the case of an LHC experiment, this may
be hundreds of petabytes of files! Individual physicists will further use RIO
to perform their end-stage analysis, reading from intermediate files they
generate from experiment data.
  RIO is thus incredibly flexible: it must serve as a file format for archival
(optimized for space) and for working data (optimized for read speed). To date,
most of the technical work has focused on improving the former use case. We
present work designed to help improve RIO for analysis. We analyze the
real-world impact of LZ4 to decrease decompression times (and the corresponding
cost in disk space). We introduce new APIs that read RIO data in bulk, removing
the per-event overhead of a C++ function call. We compare the performance with
the existing RIO APIs for simple structure data and show how this can be
complimentary with efforts to improve the parallelism of the RIO stack.
</dc:description>
 <dc:description>Comment: 18th International Workshop on Advanced Computing and Analysis
  Techniques in Physics Research (ACAT)</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02661</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>e-Fair: Aggregation in e-Commerce for Exploiting Economies of Scale</dc:title>
 <dc:creator>Gallo, Pierluigi</dc:creator>
 <dc:creator>Randazzo, Francesco</dc:creator>
 <dc:creator>Gallo, Ignazio</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  In recent years, many new and interesting models of successful online
business have been developed, including competitive models such as auctions,
where the product price tends to rise, and group-buying, where users cooperate
obtaining a dynamic price that tends to go down. We propose the e-fair as a
business model for social commerce, where both sellers and buyers are grouped
to maximize benefits. e-Fairs extend the group-buying model aggregating demand
and supply for price optimization as well as consolidating shipments and
optimize withdrawals for guaranteeing additional savings. e-Fairs work upon
multiple dimensions: time to aggregate buyers, their geographical distribution,
price/quantity curves provided by sellers, and location of withdrawal points.
We provide an analytical model for time and spatial optimization and simulate
realistic scenarios using both real purchase data from an Italian marketplace
and simulated ones. Experimental results demonstrate the potentials offered by
e-fairs and show benefits for all the involved actors.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02666</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor-Generative Adversarial Network with Two-dimensional Sparse
  Coding: Application to Real-time Indoor Localization</dc:title>
 <dc:creator>Zhu, Chenxiao</dc:creator>
 <dc:creator>Xu, Lingqing</dc:creator>
 <dc:creator>Liu, Xiao-Yang</dc:creator>
 <dc:creator>Qian, Feng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Localization technology is important for the development of indoor
location-based services (LBS). Global Positioning System (GPS) becomes invalid
in indoor environments due to the non-line-of-sight issue, so it is urgent to
develop a real-time high-accuracy localization approach for smartphones.
However, accurate localization is challenging due to issues such as real-time
response requirements, limited fingerprint samples and mobile device storage.
To address these problems, we propose a novel deep learning architecture:
Tensor-Generative Adversarial Network (TGAN).
  We first introduce a transform-based 3D tensor to model fingerprint samples.
Instead of those passive methods that construct a fingerprint database as a
prior, our model applies artificial neural network with deep learning to train
network classifiers and then gives out estimations. Then we propose a novel
tensor-based super-resolution scheme using the generative adversarial network
(GAN) that adopts sparse coding as the generator network and a residual
learning network as the discriminator. Further, we analyze the performance of
tensor-GAN and implement a trace-based localization experiment, which achieves
better performance. Compared to existing methods for smartphones indoor
positioning, that are energy-consuming and high demands on devices, TGAN can
give out an improved solution in localization accuracy, response time and
implementation complexity.
</dc:description>
 <dc:description>Comment: 6 pages, 9 figures</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02679</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Variational Inference and Learning in Undirected Graphical Models</dc:title>
 <dc:creator>Kuleshov, Volodymyr</dc:creator>
 <dc:creator>Ermon, Stefano</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many problems in machine learning are naturally expressed in the language of
undirected graphical models. Here, we propose black-box learning and inference
algorithms for undirected models that optimize a variational approximation to
the log-likelihood of the model. Central to our approach is an upper bound on
the log-partition function parametrized by a function q that we express as a
flexible neural network. Our bound makes it possible to track the partition
function during learning, to speed-up sampling, and to train a broad class of
hybrid directed/undirected models via a unified variational inference
framework. We empirically demonstrate the effectiveness of our method on
several popular generative modeling datasets.
</dc:description>
 <dc:description>Comment: Appearing in Proceedings of the 31st Conference on Neural Information
  Processing Systems (NIPS) 2017, Long Beach, CA, USA</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02679</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02695</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Influence in Science: Standing on the Shoulders of Which
  Giants?</dc:title>
 <dc:creator>Mac&#xe9;, Antonin</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  I study the measurement of the influence of scientists based on bibliographic
data. I propose a new measure that accounts for indirect influence and allows
to compare scientists across different fields of science. By contrast, common
measures of influence that &quot;count citations&quot;, such as the h-index, are unable
to satisfy either of these two properties. I use the axiomatic method in two
opposite ways: to highlight the two limitations of citation-counting schemes
and their independence, and to carefully justify the assumptions made in the
construction of the proposed measure.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02702</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning and Model Predictive Control for Self-Tuning Mode-Locked
  Lasers</dc:title>
 <dc:creator>Baumeister, Thomas</dc:creator>
 <dc:creator>Brunton, Steven L.</dc:creator>
 <dc:creator>Kutz, J. Nathan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Nonlinear Sciences - Pattern Formation and Solitons</dc:subject>
 <dc:description>  Self-tuning optical systems are of growing importance in technological
applications such as mode-locked fiber lasers. Such self-tuning paradigms
require {\em intelligent} algorithms capable of inferring approximate models of
the underlying physics and discovering appropriate control laws in order to
maintain robust performance for a given objective. In this work, we demonstrate
the first integration of a {\em deep learning} (DL) architecture with {\em
model predictive control} (MPC) in order to self-tune a mode-locked fiber
laser. Not only can our DL-MPC algorithmic architecture approximate the unknown
fiber birefringence, it also builds a dynamical model of the laser and
appropriate control law for maintaining robust, high-energy pulses despite a
stochastically drifting birefringence. We demonstrate the effectiveness of this
method on a fiber laser which is mode-locked by nonlinear polarization
rotation. The method advocated can be broadly applied to a variety of optical
systems that require robust controllers.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02703</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequential Keystroke Behavioral Biometrics for Mobile User
  Identification via Multi-view Deep Learning</dc:title>
 <dc:creator>Sun, Lichao</dc:creator>
 <dc:creator>Wang, Yuqi</dc:creator>
 <dc:creator>Cao, Bokai</dc:creator>
 <dc:creator>Yu, Philip S.</dc:creator>
 <dc:creator>Srisa-an, Witawas</dc:creator>
 <dc:creator>Leow, Alex D</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  With the rapid growth in smartphone usage, more organizations begin to focus
on providing better services for mobile users. User identification can help
these organizations to identify their customers and then cater services that
have been customized for them. Currently, the use of cookies is the most common
form to identify users. However, cookies are not easily transportable (e.g.,
when a user uses a different login account, cookies do not follow the user).
This limitation motivates the need to use behavior biometric for user
identification. In this paper, we propose DEEPSERVICE, a new technique that can
identify mobile users based on user's keystroke information captured by a
special keyboard or web browser. Our evaluation results indicate that
DEEPSERVICE is highly accurate in identifying mobile users (over 93% accuracy).
The technique is also efficient and only takes less than 1 ms to perform
identification.
</dc:description>
 <dc:description>Comment: 2017 Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02712</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tangent: Automatic Differentiation Using Source Code Transformation in
  Python</dc:title>
 <dc:creator>van Merri&#xeb;nboer, Bart</dc:creator>
 <dc:creator>Wiltschko, Alexander B.</dc:creator>
 <dc:creator>Moldovan, Dan</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Automatic differentiation (AD) is an essential primitive for machine learning
programming systems. Tangent is a new library that performs AD using source
code transformation (SCT) in Python. It takes numeric functions written in a
syntactic subset of Python and NumPy as input, and generates new Python
functions which calculate a derivative. This approach to automatic
differentiation is different from existing packages popular in machine
learning, such as TensorFlow and Autograd. Advantages are that Tangent
generates gradient code in Python which is readable by the user, easy to
understand and debug, and has no runtime overhead. Tangent also introduces
abstractions for easily injecting logic into the generated gradient code,
further improving usability.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02715</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contaminant Removal for Android Malware Detection Systems</dc:title>
 <dc:creator>Sun, Lichao</dc:creator>
 <dc:creator>Wei, Xiaokai</dc:creator>
 <dc:creator>Zhang, Jiawei</dc:creator>
 <dc:creator>He, Lifang</dc:creator>
 <dc:creator>Yu, Philip S.</dc:creator>
 <dc:creator>Srisa-an, Witawas</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A recent report indicates that there is a new malicious app introduced every
4 seconds. This rapid malware distribution rate causes existing malware
detection systems to fall far behind, allowing malicious apps to escape vetting
efforts and be distributed by even legitimate app stores. When trusted
downloading sites distribute malware, several negative consequences ensue.
First, the popularity of these sites would allow such malicious apps to quickly
and widely infect devices. Second, analysts and researchers who rely on machine
learning based detection techniques may also download these apps and mistakenly
label them as benign since they have not been disclosed as malware. These apps
are then used as part of their benign dataset during model training and
testing. The presence of contaminants in benign dataset can compromise the
effectiveness and accuracy of their detection and classification techniques. To
address this issue, we introduce PUDROID (Positive and Unlabeled learning-based
malware detection for Android) to automatically and effectively remove
contaminants from training datasets, allowing machine learning based malware
classifiers and detectors to be more effective and accurate. To further improve
the performance of such detectors, we apply a feature selection strategy to
select pertinent features from a variety of features. We then compare the
detection rates and accuracy of detection systems using two datasets; one using
PUDROID to remove contaminants and the other without removing contaminants. The
results indicate that once we remove contaminants from the datasets, we can
significantly improve both malware detection rate and detection accuracy
</dc:description>
 <dc:description>Comment: 2017 IEEE International Conference on Big Data</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02718</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Curve-Structure Segmentation from Depth Maps: A CNN-based Approach and
  Its Application to Exploring Cultural Heritage Objects</dc:title>
 <dc:creator>Lu, Yuhang</dc:creator>
 <dc:creator>Zhou, Jun</dc:creator>
 <dc:creator>Wang, Jing</dc:creator>
 <dc:creator>Chen, Jun</dc:creator>
 <dc:creator>Smith, Karen</dc:creator>
 <dc:creator>Wilder, Colin</dc:creator>
 <dc:creator>Wang, Song</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Motivated by the important archaeological application of exploring cultural
heritage objects, in this paper we study the challenging problem of
automatically segmenting curve structures that are very weakly stamped or
carved on an object surface in the form of a highly noisy depth map. Different
from most classical low-level image segmentation methods that are known to be
very sensitive to the noise and occlusions, we propose a new supervised
learning algorithm based on Convolutional Neural Network (CNN) to implicitly
learn and utilize more curve geometry and pattern information for addressing
this challenging problem. More specifically, we first propose a Fully
Convolutional Network (FCN) to estimate the skeleton of curve structures and at
each skeleton pixel, a scale value is estimated to reflect the local curve
width. Then we propose a dense prediction network to refine the estimated curve
skeletons. Based on the estimated scale values, we finally develop an adaptive
thresholding algorithm to achieve the final segmentation of curve structures.
In the experiment, we validate the performance of the proposed method on a
dataset of depth images scanned from unearthed pottery sherds dating to the
Woodland period of Southeastern North America.
</dc:description>
 <dc:description>Comment: Accepted by AAAI2018</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02724</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms to Approximate Column-Sparse Packing Problems</dc:title>
 <dc:creator>Brubach, Brian</dc:creator>
 <dc:creator>Sankararaman, Karthik Abinav</dc:creator>
 <dc:creator>Srinivasan, Aravind</dc:creator>
 <dc:creator>Xu, Pan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Column-sparse packing problems arise in several contexts in both
deterministic and stochastic discrete optimization. We present two unifying
ideas, (non-uniform) attenuation and multiple-chance algorithms, to obtain
improved approximation algorithms for some well-known families of such
problems. As three main examples, we attain the integrality gap, up to
lower-order terms, for known LP relaxations for k-column sparse packing integer
programs (Bansal et al., Theory of Computing, 2012) and stochastic k-set
packing (Bansal et al., Algorithmica, 2012), and go &quot;half the remaining
distance&quot; to optimal for a major integrality-gap conjecture of Furedi, Kahn and
Seymour on hypergraph matching (Combinatorica, 1993).
</dc:description>
 <dc:description>Comment: To appear in SODA 2018</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02733</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>State Observers for Sensorless Control of Magnetic Levitation Systems</dc:title>
 <dc:creator>Bobtsov, Alexey</dc:creator>
 <dc:creator>Pyrkin, Anton</dc:creator>
 <dc:creator>Ortega, Romeo</dc:creator>
 <dc:creator>Vedyakov, Alexey</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we address the problem of state observation for sensorless
control of nonlinear magnetic levitation systems, that is, the regulation of
the position of a levitated object measuring only the voltage and current of
the electrical supply. Instrumental for the development of the theory is the
use of parameter estimation-based observers, which combined with the dynamic
regressor extension and mixing parameter estimation technique, allow the
reconstruction of the magnetic flux. With the knowledge of the latter it is
shown that the mechanical coordinates can be estimated with suitably tailored
nonlinear observers. Replacing the observed states, in a certainty equivalent
manner, with a full information globally stabilising law completes the
sensorless controller design. We consider one and two-degrees-of-freedom
systems that, interestingly, demand totally different mathematical approaches
for their solutions. Simulation results are used to illustrate the performance
of the proposed schemes.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02736</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparative Study of Interface Techniques for Transmission and
  Distribution Dynamic Co-Simulation</dc:title>
 <dc:creator>Huang, Qiuhua</dc:creator>
 <dc:creator>Huang, Renke</dc:creator>
 <dc:creator>Fan, Rui</dc:creator>
 <dc:creator>Fuller, Jason</dc:creator>
 <dc:creator>Hardy, Trevor</dc:creator>
 <dc:creator>Zhenyu</dc:creator>
 <dc:creator>Huang</dc:creator>
 <dc:creator>Vittal, Vijay</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Transmission and distribution dynamic co-simulation is a practical and
effective approach to leverage existing simulation tools for transmission and
distribution systems to simulate dynamic stability and performance of
transmission and distribution systems in a systematic manner. Given that these
tools are developed as stand-alone programs and there are inherent differences
between them, interface techniques become critical to bridge them. Two
important unsolved questions are: 1) which interface technique is better and
should be used, and 2) how the modeling and simulation capabilities in these
tools that are available and can be exploited for co-simulation should be
considered when selecting an interface technique. To address these questions,
this paper presents a comparative study for different interface techniques that
can be employed for T and D dynamic co-simulation. The study provides insights
into the pros and cons of each interface technique, and helps researchers make
informed decisions on choosing the interface techniques.
</dc:description>
 <dc:description>Comment: 5 Pages, submitted to IEEE PES GM 2018</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02737</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Robust Adaptive Flux Observer for a Class of Electromechanical Systems</dc:title>
 <dc:creator>Pyrkin, Anton</dc:creator>
 <dc:creator>Vedyakov, Alexey</dc:creator>
 <dc:creator>Ortega, Romeo</dc:creator>
 <dc:creator>Bobtsov, Alexey</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The problem of designing a flux observer for magnetic field electromechanical
systems from noise corrupted measurements of currents and voltages is addressed
in this paper. Imposing a constraint on the systems magnetic energy function,
which allows us to construct an algebraic relation between fluxes and measured
voltages and currents that is independent of the mechanical coordinates, we
identify a class of systems for which a globally convergent adaptive observer
can be designed. A new adaptive observer design technique that effectively
exploits the aforementioned algebraic relation is proposed and successfully
applied to the practically important examples of permanent magnet synchronous
motors and magnetic levitation systems.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02741</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Autoregressive Networks for Online Multi-Object Tracking</dc:title>
 <dc:creator>Fang, Kuan</dc:creator>
 <dc:creator>Xiang, Yu</dc:creator>
 <dc:creator>Savarese, Silvio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The main challenge of online multi-object tracking is to reliably associate
object trajectories with detections in each video frame based on their tracking
history. In this work, we propose the Recurrent Autoregressive Network (RAN), a
temporal generative modeling framework to characterize the appearance and
motion dynamics of multiple objects over time. The RAN couples an external
memory and an internal memory. The external memory explicitly stores previous
inputs of each trajectory in a time window, while the internal memory learns to
summarize long-term tracking history and associate detections by processing the
external memory. We conduct experiments on the MOT 2015 and 2016 datasets to
demonstrate the robustness of our tracking method in highly crowded and
occluded scenes. Our method achieves top-ranked results on the two benchmarks.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures, 6 tables</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02742</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The VACCINE Framework for Building DLP Systems</dc:title>
 <dc:creator>Shvartzshnaider, Yan</dc:creator>
 <dc:creator>Pavlinovic, Zvonimir</dc:creator>
 <dc:creator>Wies, Thomas</dc:creator>
 <dc:creator>Subramanian, Lakshminarayanan</dc:creator>
 <dc:creator>Mittal, Prateek</dc:creator>
 <dc:creator>Nissenbaum, Helen</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Conventional Data Leakage Prevention (DLP) systems suffer from the following
major drawback: Privacy policies that define what constitutes data leakage
cannot be seamlessly defined and enforced across heterogeneous forms of
communication. Administrators have the dual burden of: (1) manually
self-interpreting policies from handbooks to specify rules (which is
error-prone); (2) extracting relevant information flows from heterogeneous
communication protocols and enforcing policies to determine which flows should
be admissible. To address these issues, we present the Verifiable and
ACtionable Contextual Integrity Norms Engine (VACCINE), a framework for
building adaptable and modular DLP systems. VACCINE relies on (1) the theory of
contextual integrity to provide an abstraction layer suitable for specifying
reusable protocol-agnostic leakage prevention rules and (2) programming
language techniques to check these rules against correctness properties and to
enforce them faithfully within a DLP system implementation. We applied VACCINE
to the Family Educational Rights and Privacy Act and Enron Corporation privacy
regulations. We show that by using contextual integrity in conjunction with
verification techniques, we can effectively create reusable privacy rules with
specific correctness guarantees, and check the integrity of information flows
against these rules. Our experiments in emulated enterprise settings indicate
that VACCINE improves over current DLP system design approaches and can be
deployed in enterprises involving tens of thousands of actors.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02743</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Randomized Kaczmarz for Support Recovery of Jointly Sparse
  Corrupted Multiple Measurement Vectors</dc:title>
 <dc:creator>Durgin, Natalie</dc:creator>
 <dc:creator>Grotheer, Rachel</dc:creator>
 <dc:creator>Huang, Chenxi</dc:creator>
 <dc:creator>Li, Shuang</dc:creator>
 <dc:creator>Ma, Anna</dc:creator>
 <dc:creator>Needell, Deanna</dc:creator>
 <dc:creator>Qin, Jing</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  While single measurement vector (SMV) models have been widely studied in
signal processing, there is a surging interest in addressing the multiple
measurement vectors (MMV) problem. In the MMV setting, more than one
measurement vector is available and the multiple signals to be recovered share
some commonalities such as a common support. Applications in which MMV is a
naturally occurring phenomenon include online streaming, medical imaging, and
video recovery. This work presents a stochastic iterative algorithm for the
support recovery of jointly sparse corrupted MMV. We present a variant of the
Sparse Randomized Kaczmarz algorithm for corrupted MMV and compare our proposed
method with an existing Kaczmarz type algorithm for MMV problems. We also
showcase the usefulness of our approach in the online (streaming) setting and
provide empirical evidence that suggests the robustness of the proposed method
to the distribution of the corruption and the number of corruptions occurring.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02751</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IMEX HDG-DG: a coupled implicit hybridized discontinuous Galerkin (HDG)
  and explicit discontinuous Galerkin (DG) approach for shallow water systems</dc:title>
 <dc:creator>Kang, Shinhoo</dc:creator>
 <dc:creator>Giraldo, Francis X.</dc:creator>
 <dc:creator>Bui-Thanh, Tan</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65M60, 65M20, 76B15, 76B60</dc:subject>
 <dc:description>  We propose IMEX HDG-DG schemes for planar and spherical shallow water
systems. Of interest is subcritical flow, where the speed of the gravity wave
is faster than that of nonlinear advection. In order to simulate these flows
efficiently, we split the governing system into a stiff part describing the
gravity wave and a non-stiff part associated with nonlinear advection. The
former is discretized implicitly with the HDG method while an explicit
Runge-Kutta DG discretization is employed for the latter. The proposed IMEX
HDG-DG framework: 1) facilitates high-order solutions both in time and space;
  2) avoids overly small time-step sizes;
  3) requires only one linear system solve per time stage;
  4) relative to DG generates smaller and sparser linear systems while
promoting further parallelism. Numerical results of various test cases
demonstrate that our methods are comparable to explicit Runge-Kutta DG schemes
in terms of accuracy while allowing for much larger time step sizes.
</dc:description>
 <dc:description>Comment: 27 pages, 14 figures</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02751</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02757</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Road Segmentation Using LiDAR Data Processing on an FPGA</dc:title>
 <dc:creator>Lyu, Yecheng</dc:creator>
 <dc:creator>Bai, Lin</dc:creator>
 <dc:creator>Huang, Xinming</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents the FPGA design of a convolutional neural network (CNN)
based road segmentation algorithm for real-time processing of LiDAR data. For
autonomous vehicles, it is important to perform road segmentation and obstacle
detection such that the drivable region can be identified for path planning.
Traditional road segmentation algorithms are mainly based on image data from
cameras, which is subjected to the light condition as well as the quality of
road markings. LiDAR sensor can obtain the 3D geometry information of the
vehicle surroundings with very high accuracy. However, it is a computational
challenge to process a large amount of LiDAR data at real-time. In this work, a
convolutional neural network model is proposed and trained to perform semantic
segmentation using the LiDAR sensor data. Furthermore, an efficient hardware
design is implemented on the FPGA that can process each LiDAR scan in 16.9ms,
which is much faster than the previous works. Evaluated using KITTI road
benchmarks, the proposed solution achieves high accuracy of road segmentation.
</dc:description>
 <dc:description>Comment: Under review at ISCAS 2018</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02758</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stability Analysis of TDD Networks Revisited: A trade-off between
  Complexity and Precision</dc:title>
 <dc:creator>Ibrahim, Rita</dc:creator>
 <dc:creator>Assaad, Mohamad</dc:creator>
 <dc:creator>Sayrac, Berna</dc:creator>
 <dc:creator>Ephremides, Anthony</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we revisit the stability region of a cellular time division
duplex (TDD) network. We characterize the queuing stability region of a network
model that consists of two types of communications: (i) users communicating
with the base station and (ii) users communicating with each other by passing
through the base station. When a communication passes through the base station
(BS) then a packet cannot be delivered to the destination UE until it is first
received by the BS queue from the source UE. Due to the relaying functionality
at the BS level, a coupling is created between the queues of the source users
and the BS queues. In addition, contrarily to the majority of the existing
works where an ON/OFF model of transmission is considered, we assume a link
adaptation model (i.e. multiple rate model) where the bit rate of a link
depends on its radio conditions. The coupling between the queues as well as the
multiple rate model are the main challenges that highly increase the complexity
of the stability region characterization. In this paper, we propose a simple
approach that permits to overcome these challenges and to provide a full
characterization of the exact stability region as a convex polytope with a
finite number of vertices. An approximated model is proposed for reducing the
computational complexity of the exact stability region. For the multi-user
scenario, a trade-off is established between the complexity and the preciseness
of the approximated stability region compared to the exact one. Furthermore,
numerical results are presented to corroborate our claims.
</dc:description>
 <dc:description>Comment: 55 pages one column document, 12 figures</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02758</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02760</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Food Recommender Systems: Important Contributions, Challenges and Future
  Research Directions</dc:title>
 <dc:creator>Trattner, Christoph</dc:creator>
 <dc:creator>Elsweiler, David</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The recommendation of food items is important for many reasons. Attaining
cooking inspiration via digital sources is becoming evermore popular; as are
systems, which recommend other types of food, such as meals in restaurants or
products in supermarkets. Researchers have been studying these kinds of systems
for many years, suggesting not only that can they be a means to help people
find food they might want to eat, but also help them nourish themselves more
healthily. This paper provides a summary of the state-of-the-art of so-called
food recommender systems, highlighting both seminal and most recent approaches
to the problem, as well as important specializations, such as food
recommendation systems for groups of users or systems which promote healthy
eating. We moreover discuss the diverse challenges involved in designing recsys
for food, summarise the lessons learned from past research and outline what we
believe to be important future directions and open questions for the field. In
providing these contributions we hope to provide a useful resource for
researchers and practitioners alike.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02765</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling Surveys Effects in Political Competitions</dc:title>
 <dc:creator>Biondo, A. E.</dc:creator>
 <dc:creator>Pluchino, A.</dc:creator>
 <dc:creator>Rapisarda, A.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper we study the impact of news media and public surveys on the
electoral campaigns for political competitions. We present an agent-based model
that addresses the effective influence of surveys in orienting the opinions of
voters before elections. The dynamics of electoral consensus is studied as a
function of time by investigating different possible scenarios and the effect
of periodic surveys, on the opinions of a small community of voters represented
as a network of agents connected by realistic social relationships. Our
simulations show the possibility to manage opinion consensus in electoral
competitions.
</dc:description>
 <dc:description>Comment: 21 pages, 9 figures</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02768</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Scale Estimation for Monocular SLAM Based on Generic Object
  Detection for Correcting Scale Drift</dc:title>
 <dc:creator>Sucar, Edgar</dc:creator>
 <dc:creator>Hayet, Jean-Bernard</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This work proposes a new, online algorithm for estimating the local scale
correction to apply to the output of a monocular SLAM system and obtain an as
faithful as possible metric reconstruction of the 3D map and of the camera
trajectory. Within a Bayesian framework, it integrates observations from a
deep-learning based generic object detector and a prior on the evolution of the
scale drift. For each observation class, a predefined prior on the heights of
the class objects is used. This allows to define the observations likelihood.
Due to the scale drift inherent to monocular SLAM systems, we integrate a rough
model on the dynamics of scale drift. Quantitative evaluations of the system
are presented on the KITTI dataset, and compared with different approaches. The
results show a superior performance of our proposal in terms of relative
translational error when compared to other monocular systems.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02770</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bandwidth Adaptive &amp; Error Resilient MBR Exact Repair Regenerating Codes</dc:title>
 <dc:creator>Mahdaviani, Kaveh</dc:creator>
 <dc:creator>Khisti, Ashish</dc:creator>
 <dc:creator>Mohajer, Soheil</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Regenerating codes are efficient methods for distributed storage in storage
networks, where node failures are common. They guarantee low cost data
reconstruction and repair through accessing only a predefined number of
arbitrarily chosen storage nodes in the network. In this work we consider two
simultaneous extensions to the original regenerating codes framework introduced
in [1]; i) both data reconstruction and repair are resilient to the presence of
a certain number of erroneous nodes in the network and ii) the number of helper
nodes in every repair is not fixed, but is a flexible parameter that can be
selected during the runtime. We study the fundamental limits of required total
repair bandwidth and provide an upper bound for the storage capacity of these
codes under these assumptions. We then focus on the minimum repair bandwidth
(MBR) case and derive the exact storage capacity by presenting explicit coding
schemes with exact repair, which achieve the upper bound of the storage
capacity in the considered setup. To this end, we first provide a more natural
extension of the well-known Product Matrix (PM) MBR codes [2], modified to
provide flexibility in the choice of number of helpers in each repair, and
simultaneously be robust to erroneous nodes in the network. This is achieved by
proving the non-singularity of family of matrices in large enough finite
fields. We next provide another extension of the PM codes, based on novel
repair schemes which enable flexibility in the number of helpers and robustness
against erroneous nodes without any extra cost in field size compared to the
original PM codes.
</dc:description>
 <dc:description>Comment: This manuscript is submitted to the IEEE Transactions on Information
  Theory</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02771</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Discrimination-Generalization Tradeoff in GANs</dc:title>
 <dc:creator>Zhang, Pengchuan</dc:creator>
 <dc:creator>Liu, Qiang</dc:creator>
 <dc:creator>Zhou, Dengyong</dc:creator>
 <dc:creator>Xu, Tao</dc:creator>
 <dc:creator>He, Xiaodong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Generative adversarial training can be generally understood as minimizing
certain moment matching loss defined by a set of discriminator functions,
typically neural networks. The discriminator set should be large enough to be
able to uniquely identify the true distribution (discriminative), and also be
small enough to go beyond memorizing samples (generalizable). In this paper, we
show that a discriminator set is guaranteed to be discriminative whenever its
linear span is dense in the set of bounded continuous functions. This is a very
mild condition satisfied even by neural networks with a single neuron. Further,
we develop generalization bounds between the learned distribution and true
distribution under different evaluation metrics. When evaluated with neural or
Wasserstein distances, our bounds show that generalization is guaranteed as
long as the discriminator set is small enough, regardless of the size of the
generator or hypothesis set. When evaluated with KL divergence, our bound
provides an explanation on the counter-intuitive behaviors of testing
likelihood in GAN training. Our analysis sheds lights on understanding the
practical performance of GANs.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02776</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fairness and Transmission-Aware Caching and Delivery Policies in
  OFDMA-Based HetNets</dc:title>
 <dc:creator>Rezvani, Sepehr</dc:creator>
 <dc:creator>Mokari, Nader</dc:creator>
 <dc:creator>Javan, Mohammad R.</dc:creator>
 <dc:creator>Jorswieck, Eduard A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>90C11</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  Recently, cache-enabled heterogeneous cellular networks (C-HetNets) have been
emerged as a promising solution for next-generation wireless networks to cope
with exponentially increasing demands for high data rate and low latency
multimedia services. In this paper, we design both the caching and the delivery
policies in the downlink of an orthogonal frequency division multiple access
(OFDMA)-based C-HetNet which operates in two phases: caching phase and delivery
phase. In the caching phase, we propose novel transmission-aware caching
policies by coupling the cache placement strategy and physical-layer
transmission to exploit the benefits of flexible physical transmission
opportunities for access and backhaul links, simultaneously. We specifically
apply a joint optimization of cache placement and ergodic radio resource
allocation for both the access and backhaul links to extend the flexibility of
the cache placement strategies and cover each time period of the delivery
phase. Since most of the current research efforts in cache-assisted wireless
networks neglected the fair treatment of mobile users (MUs), in this work, we
propose two schemes called proportional fairness and min-max fairness schemes.
In the proportional fairness scheme, we minimize the total weighted latency of
MUs while in the min-max fairness scheme, we minimize the maximal latency of
MUs in each cell. In numerical assessments, we investigate the effect of the
proposed fairness and transmission-aware caching policies compared to the
conventional proactive caching strategies which are only based on the contents
popularity and storage capacities.
</dc:description>
 <dc:description>Comment: 38 pages, 7 figures, submitted to IEEE Transactions on Mobile
  Computing (TMC)</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02781</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RubyStar: A Non-Task-Oriented Mixture Model Dialog System</dc:title>
 <dc:creator>Liu, Huiting</dc:creator>
 <dc:creator>Lin, Tao</dc:creator>
 <dc:creator>Sun, Hanfei</dc:creator>
 <dc:creator>Lin, Weijian</dc:creator>
 <dc:creator>Chang, Chih-Wei</dc:creator>
 <dc:creator>Zhong, Teng</dc:creator>
 <dc:creator>Rudnicky, Alexander</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  RubyStar is a dialog system designed to create &quot;human-like&quot; conversation by
combining different response generation strategies. RubyStar conducts a
non-task-oriented conversation on general topics by using an ensemble of
rule-based, retrieval-based and generative methods. Topic detection, engagement
monitoring, and context tracking are used for managing interaction. Predictable
elements of conversation, such as the bot's backstory and simple question
answering are handled by separate modules. We describe a rating scheme we
developed for evaluating response generation. We find that character-level RNN
is an effective generation model for general responses, with proper parameter
settings; however other kinds of conversation topics might benefit from using
other models.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02782</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Block-Sparse Recurrent Neural Networks</dc:title>
 <dc:creator>Narang, Sharan</dc:creator>
 <dc:creator>Undersander, Eric</dc:creator>
 <dc:creator>Diamos, Gregory</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recurrent Neural Networks (RNNs) are used in state-of-the-art models in
domains such as speech recognition, machine translation, and language
modelling. Sparsity is a technique to reduce compute and memory requirements of
deep learning models. Sparse RNNs are easier to deploy on devices and high-end
server processors. Even though sparse operations need less compute and memory
relative to their dense counterparts, the speed-up observed by using sparse
operations is less than expected on different hardware platforms. In order to
address this issue, we investigate two different approaches to induce block
sparsity in RNNs: pruning blocks of weights in a layer and using group lasso
regularization to create blocks of weights with zeros. Using these techniques,
we demonstrate that we can create block-sparse RNNs with sparsity ranging from
80% to 90% with small loss in accuracy. This allows us to reduce the model size
by roughly 10x. Additionally, we can prune a larger dense network to recover
this loss in accuracy while maintaining high block sparsity and reducing the
overall parameter count. Our technique works with a variety of block sizes up
to 32x32. Block-sparse RNNs eliminate overheads related to data storage and
irregular memory accesses while increasing hardware efficiency compared to
unstructured sparsity.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02783</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Imagine Manipulation Goals for Robot Task Planning</dc:title>
 <dc:creator>Paxton, Chris</dc:creator>
 <dc:creator>Katyal, Kapil</dc:creator>
 <dc:creator>Rupprecht, Christian</dc:creator>
 <dc:creator>Arora, Raman</dc:creator>
 <dc:creator>Hager, Gregory D.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Prospection is an important part of how humans come up with new task plans,
but has not been explored in depth in robotics. Predicting multiple task-level
is a challenging problem that involves capturing both task semantics and
continuous variability over the state of the world. Ideally, we would combine
the ability of machine learning to leverage big data for learning the semantics
of a task, while using techniques from task planning to reliably generalize to
new environment. In this work, we propose a method for learning a model
encoding just such a representation for task planning. We learn a neural net
that encodes the $k$ most likely outcomes from high level actions from a given
world. Our approach creates comprehensible task plans that allow us to predict
changes to the environment many time steps into the future. We demonstrate this
approach via application to a stacking task in a cluttered environment, where
the robot must select between different colored blocks while avoiding
obstacles, in order to perform a task. We also show results on a simple
navigation task. Our algorithm generates realistic image and pose predictions
at multiple points in a given task.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02792</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Metric Learning-based Generative Adversarial Network</dc:title>
 <dc:creator>Dou, Zi-Yi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative Adversarial Networks (GANs), as a framework for estimating
generative models via an adversarial process, have attracted huge attention and
have proven to be powerful in a variety of tasks. However, training GANs is
well known for being delicate and unstable, partially caused by its sig- moid
cross entropy loss function for the discriminator. To overcome such a problem,
many researchers directed their attention on various ways to measure how close
the model distribution and real distribution are and have applied dif- ferent
metrics as their objective functions. In this paper, we propose a novel
framework to train GANs based on distance metric learning and we call it Metric
Learning-based Gener- ative Adversarial Network (MLGAN). The discriminator of
MLGANs can dynamically learn an appropriate metric, rather than a static one,
to measure the distance between generated samples and real samples. Afterwards,
MLGANs update the generator under the newly learned metric. We evaluate our ap-
proach on several representative datasets and the experimen- tal results
demonstrate that MLGANs can achieve superior performance compared with several
existing state-of-the-art approaches. We also empirically show that MLGANs
could increase the stability of training GANs.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02793</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Statistics for Image Deconvolution</dc:title>
 <dc:creator>Lee, Matthias</dc:creator>
 <dc:creator>Budavari, Tamas</dc:creator>
 <dc:creator>White, Richard</dc:creator>
 <dc:creator>Gulian, Charles</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present a blind multiframe image-deconvolution method based on robust
statistics. The usual shortcomings of iterative optimization of the likelihood
function are alleviated by minimizing the M-scale of the residuals, which
achieves more uniform convergence across the image. We focus on the
deconvolution of astronomical images, which are among the most challenging due
to their huge dynamic ranges and the frequent presence of large noise-dominated
regions in the images. We show that high-quality image reconstruction is
possible even in super-resolution and without the use of traditional
regularization terms. Using a robust \r{ho}-function is straightforward to
implement in a streaming setting and, hence our method is applicable to the
large volumes of astronomy images. The power of our method is demonstrated on
observations from the Sloan Digital Sky Survey (Stripe 82) and we briefly
discuss the feasibility of a pipeline based on Graphical Processing Units for
the next generation of telescope surveys.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02793</dc:identifier>
 <dc:identifier>doi:10.1016/j.ascom.2017.09.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02795</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate message passing for nonconvex sparse regularization with
  stability and asymptotic analysis</dc:title>
 <dc:creator>Sakata, Ayaka</dc:creator>
 <dc:creator>Xu, Yingying</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We analyze linear regression problem with a nonconvex regularization called
smoothly clipped absolute deviation (SCAD) under overcomplete Gaussian basis
for Gaussian random data. We develop a message passing algorithm SCAD-AMP and
analytically show that the stability condition is corresponding to the AT
condition in spin glass literature. As asymptotic analysis, we show the
correspondence between density evolution of SCAD-AMP and replica symmetric
solution. Numerical experiments confirm that for sufficiently large system
size, SCAD-AMP achieves the optimal performance predicted by replica method.
From replica analysis, phase transition between replica symmetric (RS) and
replica symmetry breaking (RSB) region is found in the parameter space of SCAD.
The appearance of RS region for nonconvex penalty is a great advantage which
indicate the region of smooth landscape of the optimization problem.
Furthermore, we analytically show that the statistical representation
performance of SCAD penalty is improved compared with $\ell_1$-based methods,
and the minimum representation error under RS assumption is obtained at the
edge of RS/RSB phase. The correspondence between the convergence of the
existing coordinate descent algorithm and RS/RSB transition is also indicated.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02799</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fidelity-Weighted Learning</dc:title>
 <dc:creator>Dehghani, Mostafa</dc:creator>
 <dc:creator>Mehrjou, Arash</dc:creator>
 <dc:creator>Gouws, Stephan</dc:creator>
 <dc:creator>Kamps, Jaap</dc:creator>
 <dc:creator>Sch&#xf6;lkopf, Bernhard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Training deep neural networks requires many training samples, but in practice
training labels are expensive to obtain and may be of varying quality, as some
may be from trusted expert labelers while others might be from heuristics or
other sources of weak supervision such as crowd-sourcing. This creates a
fundamental quality versus-quantity trade-off in the learning process. Do we
learn from the small amount of high-quality data or the potentially large
amount of weakly-labeled data? We argue that if the learner could somehow know
and take the label-quality into account when learning the data representation,
we could get the best of both worlds. To this end, we propose
&quot;fidelity-weighted learning&quot; (FWL), a semi-supervised student-teacher approach
for training deep neural networks using weakly-labeled data. FWL modulates the
parameter updates to a student network (trained on the task we care about) on a
per-sample basis according to the posterior confidence of its label-quality
estimated by a teacher (who has access to the high-quality labels). Both
student and teacher are learned from the data. We evaluate FWL on two tasks in
information retrieval and natural language processing where we outperform
state-of-the-art alternative semi-supervised methods, indicating that our
approach makes better use of strong and weak labels, and leads to better
task-dependent data representations.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02805</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The (thin) Bridges of AS Connectivity: Measuring Dependency using AS
  Hegemony</dc:title>
 <dc:creator>Fontugne, Romain</dc:creator>
 <dc:creator>Shah, Anant</dc:creator>
 <dc:creator>Aben, Emile</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Inter-domain routing is a crucial part of the Internet designed for arbitrary
policies, economical models, and topologies. This versatility translates into a
substantially complex system that is hard to comprehend. Monitoring the
inter-domain routing infrastructure is however essential for understanding the
current state of the Internet and improving it. In this paper we design a
methodology to answer two simple questions: Which are the common transit
networks used to reach a certain AS? How much does this AS depends on these
transit networks? To answer these questions we digest AS paths advertised with
the Border Gateway Protocol (BGP) into AS graphs and measure node centrality,
that is the likelihood of an AS to lie on paths between two other ASes. Our
proposal relies solely on the AS hegemony metric, a new way to quantify node
centrality while taking into account the bias towards the partial view offered
by BGP. Our analysis using 14 years of BGP data refines our knowledge on
Internet flattening but also exhibits the consolidated position of tier-1
networks in today's IPv4 and IPv6 Internet. We also study the connectivity to
two content providers (Google and Akamai) and investigate the AS dependency of
networks hosting DNS root servers. These case studies emphasize the benefits of
the proposed method to assist ISPs in planning and assessing infrastructure
deployment.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02807</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster Fuzzing: Reinitialization with Deep Neural Models</dc:title>
 <dc:creator>Nichols, Nicole</dc:creator>
 <dc:creator>Raugas, Mark</dc:creator>
 <dc:creator>Jasper, Robert</dc:creator>
 <dc:creator>Hilliard, Nathan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We improve the performance of the American Fuzzy Lop (AFL) fuzz testing
framework by using Generative Adversarial Network (GAN) models to reinitialize
the system with novel seed files. We assess performance based on the temporal
rate at which we produce novel and unseen code paths. We compare this approach
to seed file generation from a random draw of bytes observed in the training
seed files. The code path lengths and variations were not sufficiently diverse
to fully replace AFL input generation. However, augmenting native AFL with
these additional code paths demonstrated improvements over AFL alone.
Specifically, experiments showed the GAN was faster and more effective than the
LSTM and out-performed a random augmentation strategy, as measured by the
number of unique code paths discovered. GAN helps AFL discover 14.23% more code
paths than the random strategy in the same amount of CPU time, finds 6.16% more
unique code paths, and finds paths that are on average 13.84% longer. Using GAN
shows promise as a reinitialization strategy for AFL to help the fuzzer
exercise deep paths in software.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02809</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Hybrid-parameter Recurrent Neural Networks for Online Handwritten
  Chinese Character Recognition</dc:title>
 <dc:creator>Ren, Haiqing</dc:creator>
 <dc:creator>Wang, Weiqiang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The recurrent neural network (RNN) is appropriate for dealing with temporal
sequences. In this paper, we present a deep RNN with new features and apply it
for online handwritten Chinese character recognition. Compared with the
existing RNN models, three innovations are involved in the proposed system.
First, a new hidden layer function for RNN is proposed for learning temporal
information better. we call it Memory Pool Unit (MPU). The proposed MPU has a
simple architecture. Second, a new RNN architecture with hybrid parameter is
presented, in order to increasing the expression capacity of RNN. The proposed
hybrid-parameter RNN has parameter changes when calculating the iteration at
temporal dimension. Third, we make a adaptation that all the outputs of each
layer are stacked as the output of network. Stacked hidden layer states combine
all the hidden layer states for increasing the expression capacity. Experiments
are carried out on the IAHCC-UCAS2016 dataset and the CASIA-OLHWDB1.1 dataset.
The experimental results show that the hybrid-parameter RNN obtain a better
recognition performance with higher efficiency (fewer parameters and faster
speed). And the proposed Memory Pool Unit is proved to be a simple hidden layer
function and obtains a competitive recognition results.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02810</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Fault Analysis and Subset Selection in Solar Power Grids</dc:title>
 <dc:creator>Bhattacharya, Biswarup</dc:creator>
 <dc:creator>Sinha, Abhishek</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Non-availability of reliable and sustainable electric power is a major
problem in the developing world. Renewable energy sources like solar are not
very lucrative in the current stage due to various uncertainties like weather,
storage, land use among others. There also exists various other issues like
mis-commitment of power, absence of intelligent fault analysis, congestion,
etc. In this paper, we propose a novel deep learning-based system for
predicting faults and selecting power generators optimally so as to reduce
costs and ensure higher reliability in solar power systems. The results are
highly encouraging and they suggest that the approaches proposed in this paper
have the potential to be applied successfully in the developing world.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2017 Workshop on Machine Learning for the
  Developing World</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02816</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-label Image Recognition by Recurrently Discovering Attentional
  Regions</dc:title>
 <dc:creator>Wang, Zhouxia</dc:creator>
 <dc:creator>Chen, Tianshui</dc:creator>
 <dc:creator>Li, Guanbin</dc:creator>
 <dc:creator>Xu, Ruijia</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a novel deep architecture to address multi-label image
recognition, a fundamental and practical task towards general visual
understanding. Current solutions for this task usually rely on an extra step of
extracting hypothesis regions (i.e., region proposals), resulting in redundant
computation and sub-optimal performance. In this work, we achieve the
interpretable and contextualized multi-label image classification by developing
a recurrent memorized-attention module. This module consists of two alternately
performed components: i) a spatial transformer layer to locate attentional
regions from the convolutional feature maps in a region-proposal-free way and
ii) an LSTM (Long-Short Term Memory) sub-network to sequentially predict
semantic labeling scores on the located regions while capturing the global
dependencies of these regions. The LSTM also output the parameters for
computing the spatial transformer. On large-scale benchmarks of multi-label
image classification (e.g., MS-COCO and PASCAL VOC 07), our approach
demonstrates superior performances over other existing state-of-the-arts in
both accuracy and efficiency.
</dc:description>
 <dc:description>Comment: Accepted at ICCV 2017</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02823</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heuristic Search for Structural Constraints in Data Association</dc:title>
 <dc:creator>Zhou, Xiao</dc:creator>
 <dc:creator>Jiang, Peilin</dc:creator>
 <dc:creator>Wang, Fei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The research on multi-object tracking (MOT) is essentially to solve for the
data association assignment, the core of which is to design the association
cost as discriminative as possible. Generally speaking, the match ambiguities
caused by similar appearances of objects and the moving cameras make the data
association perplexing and challenging. In this paper, we propose a new
heuristic method to search for structural constraints (HSSC) of multiple
targets when solving the problem of online multi-object tracking. We believe
that the internal structure among multiple targets in the adjacent frames could
remain constant and stable even though the video sequences are captured by a
moving camera. As a result, the structural constraints are able to cut down the
match ambiguities caused by the moving cameras as well as similar appearances
of the tracked objects. The proposed heuristic method aims to obtain a maximum
match set under the minimum structural cost for each available match pair,
which can be integrated with the raw association costs and make them more
elaborate and discriminative compared with other approaches. In addition, this
paper presents a new method to recover missing targets by minimizing the cost
function generated from both motion and structure cues. Our online multi-object
tracking (MOT) algorithm based on HSSC has achieved the multi-object tracking
accuracy (MOTA) of 25.0 on the public dataset 2DMOT2015[1].
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02824</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RCNF: Real-time Collaborative Network Forensic Scheme for Evidence
  Analysis</dc:title>
 <dc:creator>Moustafa, Nour</dc:creator>
 <dc:creator>Slay, Jill</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Network forensic techniques help in tracking different types of cyber attack
by monitoring and inspecting network traffic. However, with the high speed and
large sizes of current networks, and the sophisticated philosophy of attackers,
in particular mimicking normal behaviour and/or erasing traces to avoid
detection, investigating such crimes demands intelligent network forensic
techniques. This paper suggests a real-time collaborative network Forensic
scheme (RCNF) that can monitor and investigate cyber intrusions. The scheme
includes three components of capturing and storing network data, selecting
important network features using chi-square method and investigating abnormal
events using a new technique called correntropy-variation. We provide a case
study using the UNSW-NB15 dataset for evaluating the scheme, showing its high
performance in terms of accuracy and false alarm rate compared with three
recent state-of-the-art mechanisms.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02825</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Developing Network forensic mechanism for Botnet Activities in
  the IoT based on Machine Learning Techniques</dc:title>
 <dc:creator>Koroniotis, Nickilaos</dc:creator>
 <dc:creator>Moustafa, Nour</dc:creator>
 <dc:creator>Sitnikova, Elena</dc:creator>
 <dc:creator>Slay, Jill</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The IoT is a network of interconnected everyday objects called things that
have been augmented with a small measure of computing capabilities. Lately, the
IoT has been affected by a variety of different botnet activities. As botnets
have been the cause of serious security risks and financial damage over the
years, existing Network forensic techniques cannot identify and track current
sophisticated methods of botnets. This is because commercial tools mainly
depend on signature-based approaches that cannot discover new forms of botnet.
In literature, several studies have conducted the use of Machine Learning ML
techniques in order to train and validate a model for defining such attacks,
but they still produce high false alarm rates with the challenge of
investigating the tracks of botnets. This paper investigates the role of ML
techniques for developing a Network forensic mechanism based on network flow
identifiers that can track suspicious activities of botnets. The experimental
results using the UNSW-NB15 dataset revealed that ML techniques with flow
identifiers can effectively and efficiently detect botnets attacks and their
tracks.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02826</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probability Risk Identification Based Intrusion Detection System for
  SCADA Systems</dc:title>
 <dc:creator>Marsden, Thomas</dc:creator>
 <dc:creator>Moustafa, Nour</dc:creator>
 <dc:creator>Sitnikova, Elena</dc:creator>
 <dc:creator>Creech, Gideon</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  . As Supervisory Control and Data Acquisition (SCADA) systems control several
critical infrastructures, they have connected to the internet. Consequently,
SCADA systems face different sophisticated types of cyber adversaries. This
paper suggests a Probability Risk Identification based Intrusion Detection
System (PRI-IDS) technique based on analysing network traffic of Modbus TCP/IP
for identifying replay attacks. It is acknowledged that Modbus TCP is usually
vulnerable due to its unauthenticated and unencrypted nature. Our technique is
evaluated using a simulation environment by configuring a testbed, which is a
cus- tom SCADA network that is cheap, accurate and scalable. The testbed is
exploited when testing the IDS by sending individual packets from an attacker
located on the same LAN as the Modbus master and slave. The experimental
results demonstrated that the proposed technique can effectively and
efficiently recognise replay attacks.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02827</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inverse Reward Design</dc:title>
 <dc:creator>Hadfield-Menell, Dylan</dc:creator>
 <dc:creator>Milli, Smitha</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:creator>Russell, Stuart</dc:creator>
 <dc:creator>Dragan, Anca</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Autonomous agents optimize the reward function we give them. What they don't
know is how hard it is for us to design a reward function that actually
captures what we want. When designing the reward, we might think of some
specific training scenarios, and make sure that the reward will lead to the
right behavior in those scenarios. Inevitably, agents encounter new scenarios
(e.g., new types of terrain) where optimizing that same reward may lead to
undesired behavior. Our insight is that reward functions are merely
observations about what the designer actually wants, and that they should be
interpreted in the context in which they were designed. We introduce inverse
reward design (IRD) as the problem of inferring the true objective based on the
designed reward and the training MDP. We introduce approximate methods for
solving IRD problems, and use their solution to plan risk-averse behavior in
test MDPs. Empirical results suggest that this approach can help alleviate
negative side effects of misspecified reward functions and mitigate reward
hacking.
</dc:description>
 <dc:description>Comment: Advances in Neural Information Processing Systems 30 (NIPS 2017)</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02828</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy Preservation Intrusion Detection Technique for SCADA Systems</dc:title>
 <dc:creator>Keshk, Marwa</dc:creator>
 <dc:creator>Moustafa, Nour</dc:creator>
 <dc:creator>Sitnikova, Elena</dc:creator>
 <dc:creator>Creech, Gideon</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Supervisory Control and Data Acquisition (SCADA) systems face the absence of
a protection technique that can beat different types of intrusions and protect
the data from disclosure while handling this data using other applications,
specifically Intrusion Detection System (IDS). The SCADA system can manage the
critical infrastructure of industrial control environments. Protecting
sensitive information is a difficult task to achieve in reality with the
connection of physical and digital systems. Hence, privacy preservation
techniques have become effective in order to protect sensitive/private
information and to detect malicious activities, but they are not accurate in
terms of error detection, sensitivity percentage of data disclosure. In this
paper, we propose a new Privacy Preservation Intrusion Detection (PPID)
technique based on the correlation coefficient and Expectation Maximisation
(EM) clustering mechanisms for selecting important portions of data and
recognizing intrusive events. This technique is evaluated on the power system
datasets for multiclass attacks to measure its reliability for detecting
suspicious activities. The experimental results outperform three techniques in
the above terms, showing the efficiency and effectiveness of the proposed
technique to be utilized for current SCADA systems.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02829</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative Anomaly Detection Framework for handling Big Data of Cloud
  Computing</dc:title>
 <dc:creator>Moustafa, Nour</dc:creator>
 <dc:creator>Creech, Gideon</dc:creator>
 <dc:creator>Sitnikova, Elena</dc:creator>
 <dc:creator>Keshk, Marwa</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  With the ubiquitous computing of providing services and applications at
anywhere and anytime, cloud computing is the best option as it offers flexible
and pay-per-use based services to its customers. Nevertheless, security and
privacy are the main challenges to its success due to its dynamic and
distributed architecture, resulting in generating big data that should be
carefully analysed for detecting network vulnerabilities. In this paper, we
propose a Collaborative Anomaly Detection Framework CADF for detecting cyber
attacks from cloud computing environments. We provide the technical functions
and deployment of the framework to illustrate its methodology of implementation
and installation. The framework is evaluated on the UNSW-NB15 dataset to check
its credibility while deploying it in cloud computing environments. The
experimental results showed that this framework can easily handle large-scale
systems as its implementation requires only estimating statistical measures
from network observations. Moreover, the evaluation performance of the
framework outperforms three state-of-the-art techniques in terms of false
positive rate and detection rate.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02831</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SIMILARnet: Simultaneous Intelligent Localization and Recognition
  Network</dc:title>
 <dc:creator>Ghosh, Arna</dc:creator>
 <dc:creator>Bhattacharya, Biswarup</dc:creator>
 <dc:creator>Chowdhury, Somnath Basu Roy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Global Average Pooling (GAP) [4] has been used previously to generate class
activation for image classification tasks. The motivation behind SIMILARnet
comes from the fact that the convolutional filters possess position information
of the essential features and hence, combination of the feature maps could help
us locate the class instances in an image. We propose a biologically inspired
model that is free of differential connections and doesn't require separate
training thereby reducing computation overhead. Our novel architecture
generates promising results and unlike existing methods, the model is not
sensitive to the input image size, thus promising wider application. Codes for
the experiment and illustrations can be found at:
https://github.com/brcsomnath/Advanced-GAP .
</dc:description>
 <dc:description>Comment: 5 pages; 2 figures; 2 tables; All authors have equal contribution</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02833</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Traffic Prediction Based on Random Connectivity in Deep Learning with
  Long Short-Term Memory</dc:title>
 <dc:creator>Hua, Yuxiu</dc:creator>
 <dc:creator>Zhao, Zhifeng</dc:creator>
 <dc:creator>Li, Rongpeng</dc:creator>
 <dc:creator>Chen, Xianfu</dc:creator>
 <dc:creator>Liu, Zhiming</dc:creator>
 <dc:creator>Zhang, Honggang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Traffic prediction plays an important role in evaluating the performance of
telecommunication networks and attracts intense research interests. A
significant number of algorithms and models have been proposed to learn
knowledge from traffic data and improve the prediction accuracy. In the recent
big data era, the relevant research enthusiasm remains and deep learning has
been exploited to extract the useful information in depth. In particular, Long
Short-Term Memory (LSTM), one kind of Recurrent Neural Network (RNN) schemes,
has attracted significant attentions due to the long-range dependency embedded
in the sequential traffic data. However, LSTM has considerable computational
cost, which can not be tolerated in tasks with stringent latency requirement.
In this paper, we propose a deep learning model based on LSTM, called Random
Connectivity LSTM (RCLSTM). Compared to the conventional LSTM, RCLSTM achieves
a significant breakthrough in the architecture formation of neural network,
whose connectivity is determined in a stochastic manner rather than full
connected. So, the neural network in RCLSTM can exhibit certain sparsity, which
means many neural connections are absent (distinguished from the full
connectivity) and thus the number of parameters to be trained is reduced and
much fewer computations are required. We apply the RCLSTM solution to predict
traffic and validate that the RCLSTM with even 35% neural connectivity still
shows a strong capability in traffic prediction. Also, along with increasing
the number of training samples, the performance of RCLSTM becomes closer to the
conventional LSTM. Moreover, the RCLSTM exhibits even superior prediction
accuracy than the conventional LSTM when the length of input traffic sequences
increases.
</dc:description>
 <dc:description>Comment: 7 pages, 10 figures</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02837</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revealing structure components of the retina by deep learning networks</dc:title>
 <dc:creator>Yan, Qi</dc:creator>
 <dc:creator>Yu, Zhaofei</dc:creator>
 <dc:creator>Chen, Feng</dc:creator>
 <dc:creator>Liu, Jian K.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Deep convolutional neural networks (CNNs) have demonstrated impressive
performance on visual object classification tasks. In addition, it is a useful
model for predication of neuronal responses recorded in visual system. However,
there is still no clear understanding of what CNNs learn in terms of visual
neuronal circuits. Visualizing CNN's features to obtain possible connections to
neuronscience underpinnings is not easy due to highly complex circuits from the
retina to higher visual cortex. Here we address this issue by focusing on
single retinal ganglion cells with a simple model and electrophysiological
recordings from salamanders. By training CNNs with white noise images to
predicate neural responses, we found that convolutional filters learned in the
end are resembling to biological components of the retinal circuit. Features
represented by these filters tile the space of conventional receptive field of
retinal ganglion cells. These results suggest that CNN could be used to reveal
structure components of neuronal circuits.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2017 Symposium on Interpretable Machine Learning</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02838</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Cubic Regularization for Fast Nonconvex Optimization</dc:title>
 <dc:creator>Tripuraneni, Nilesh</dc:creator>
 <dc:creator>Stern, Mitchell</dc:creator>
 <dc:creator>Jin, Chi</dc:creator>
 <dc:creator>Regier, Jeffrey</dc:creator>
 <dc:creator>Jordan, Michael I.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper proposes a stochastic variant of a classic algorithm---the
cubic-regularized Newton method [Nesterov and Polyak 2006]. The proposed
algorithm efficiently escapes saddle points and finds approximate local minima
for general smooth, nonconvex functions in only
$\mathcal{\tilde{O}}(\epsilon^{-3.5})$ stochastic gradient and stochastic
Hessian-vector product evaluations. The latter can be computed as efficiently
as stochastic gradients. This improves upon the
$\mathcal{\tilde{O}}(\epsilon^{-4})$ rate of stochastic gradient descent. Our
rate matches the best-known result for finding local minima without requiring
any delicate acceleration or variance-reduction techniques.
</dc:description>
 <dc:description>Comment: The first two authors contributed equally</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02843</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dynamic Solution to the Puzzle of Sea Battle</dc:title>
 <dc:creator>Ju, Fengkui</dc:creator>
 <dc:creator>Grilletti, Gianluca</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The puzzle of sea battle involves an argument that is an instantiation of
reasoning by cases. Its premises include the conditionals &quot;if there is a/no sea
battle tomorrow, it is necessarily so&quot;. It has a fatalistic conclusion. Two
readings of necessity can be distinguished: absolute and relative necessity.
The conditionals are valid for the latter reading. By the restrictor view of
&quot;if&quot; in linguistics, the conditionals are not material implication. Instead,
the if-clauses in them are devices for restricting the discourse domain that
consists of possible futures. As a consequence, the argument is not sound. We
present a dynamic temporal logic to formalize this idea. The base of this logic
is CTL* without the operator until. The logic has a dynamic operator that
shrinks models. The completeness of the logic is shown by reducing the dynamic
operator.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02844</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Auction For Edge Computing Resource Management in Mobile
  Blockchain Networks: A Deep Learning Approach</dc:title>
 <dc:creator>Luong, Nguyen Cong</dc:creator>
 <dc:creator>Xiong, Zehui</dc:creator>
 <dc:creator>Wang, Ping</dc:creator>
 <dc:creator>Niyato, Dusit</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Blockchain has recently been applied in many applications such as bitcoin,
smart grid, and Internet of Things (IoT) as a public ledger of transactions.
However, the use of blockchain in mobile environments is still limited because
the mining process consumes too much computing and energy resources on mobile
devices. Edge computing offered by the Edge Computing Service Provider can be
adopted as a viable solution for offloading the mining tasks from the mobile
devices, i.e., miners, in the mobile blockchain environment. However, a
mechanism needs to be designed for edge resource allocation to maximize the
revenue for the Edge Computing Service Provider and to ensure incentive
compatibility and individual rationality is still open. In this paper, we
develop an optimal auction based on deep learning for the edge resource
allocation. Specifically, we construct a multi-layer neural network
architecture based on an analytical solution of the optimal auction. The neural
networks first perform monotone transformations of the miners' bids. Then, they
calculate allocation and conditional payment rules for the miners. We use
valuations of the miners as the data training to adjust parameters of the
neural networks so as to optimize the loss function which is the expected,
negated revenue of the Edge Computing Service Provider. We show the
experimental results to confirm the benefits of using the deep learning for
deriving the optimal auction for mobile blockchain with high revenue
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02846</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intriguing Properties of Adversarial Examples</dc:title>
 <dc:creator>Cubuk, Ekin D.</dc:creator>
 <dc:creator>Zoph, Barret</dc:creator>
 <dc:creator>Schoenholz, Samuel S.</dc:creator>
 <dc:creator>Le, Quoc V.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  It is becoming increasingly clear that many machine learning classifiers are
vulnerable to adversarial examples. In attempting to explain the origin of
adversarial examples, previous studies have typically focused on the fact that
neural networks operate on high dimensional data, they overfit, or they are too
linear. Here we argue that the origin of adversarial examples is primarily due
to an inherent uncertainty that neural networks have about their predictions.
We show that the functional form of this uncertainty is independent of
architecture, dataset, and training protocol; and depends only on the
statistics of the logit differences of the network, which do not change
significantly during training. This leads to adversarial error having a
universal scaling, as a power-law, with respect to the size of the adversarial
perturbation. We show that this universality holds for a broad range of
datasets (MNIST, CIFAR10, ImageNet, and random data), models (including
state-of-the-art deep networks, linear models, adversarially trained networks,
and networks trained on randomly shuffled labels), and attacks (FGSM, step
l.l., PGD). Motivated by these results, we study the effects of reducing
prediction entropy on adversarial robustness. Finally, we study the effect of
network architectures on adversarial sensitivity. To do this, we use neural
architecture search with reinforcement learning to find adversarially robust
architectures on CIFAR10. Our resulting architecture is more robust to white
\emph{and} black box attacks compared to previous attempts.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02855</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A compressed dynamic self-index for highly repetitive text collections</dc:title>
 <dc:creator>Nishimoto, Takaaki</dc:creator>
 <dc:creator>Takabatake, Yoshimasa</dc:creator>
 <dc:creator>Tabei, Yasuo</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a novel compressed dynamic self-index for highly repetitive text
collections. Signature encoding is a compressed dynamic self-index for highly
repetitive texts and has a large disadvantage that the pattern search for short
patterns is slow. We improve this disadvantage for faster pattern search by
leveraging an idea behind truncated suffix tree and present the first
compressed dynamic self-index named TST-index that supports not only fast
pattern search but also dynamic update operation of index for highly repetitive
texts. Experiments using a benchmark dataset of highly repetitive texts show
that the pattern search of TST-index is significantly improved.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02856</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transductive Zero-Shot Hashing via Coarse-to-Fine Similarity Mining</dc:title>
 <dc:creator>Lai, Hanjiang</dc:creator>
 <dc:creator>Pan, Yan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Zero-shot Hashing (ZSH) is to learn hashing models for novel/target classes
without training data, which is an important and challenging problem. Most
existing ZSH approaches exploit transfer learning via an intermediate shared
semantic representations between the seen/source classes and novel/target
classes. However, due to having disjoint, the hash functions learned from the
source dataset are biased when applied directly to the target classes. In this
paper, we study the transductive ZSH, i.e., we have unlabeled data for novel
classes. We put forward a simple yet efficient joint learning approach via
coarse-to-fine similarity mining which transfers knowledges from source data to
target data. It mainly consists of two building blocks in the proposed deep
architecture: 1) a shared two-streams network, which the first stream operates
on the source data and the second stream operates on the unlabeled data, to
learn the effective common image representations, and 2) a coarse-to-fine
module, which begins with finding the most representative images from target
classes and then further detect similarities among these images, to transfer
the similarities of the source data to the target data in a greedy fashion.
Extensive evaluation results on several benchmark datasets demonstrate that the
proposed hashing method achieves significant improvement over the
state-of-the-art methods.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02857</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Sparse Visual Representations with Leaky Capped Norm
  Regularizers</dc:title>
 <dc:creator>Wangni, Jianqiao</dc:creator>
 <dc:creator>Lin, Dahua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Sparsity inducing regularization is an important part for learning
over-complete visual representations. Despite the popularity of $\ell_1$
regularization, in this paper, we investigate the usage of non-convex
regularizations in this problem. Our contribution consists of three parts.
First, we propose the leaky capped norm regularization (LCNR), which allows
model weights below a certain threshold to be regularized more strongly as
opposed to those above, therefore imposes strong sparsity and only introduces
controllable estimation bias. We propose a majorization-minimization algorithm
to optimize the joint objective function. Second, our study over monocular 3D
shape recovery and neural networks with LCNR outperforms $\ell_1$ and other
non-convex regularizations, achieving state-of-the-art performance and faster
convergence. Third, we prove a theoretical global convergence speed on the 3D
recovery problem. To the best of our knowledge, this is the first convergence
analysis of the 3D recovery problem.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02857</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02860</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constructive Discrepancy Minimization with Hereditary L2 Guarantees</dc:title>
 <dc:creator>Larsen, Kasper Green</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In discrepancy minimization problems, we are given a family of sets
$\mathcal{S} = \{S_1,\dots,S_m\}$, with each $S_i \in \mathcal{S}$ a subset of
some universe $U = \{u_1,\dots,u_n\}$ of $n$ elements. The goal is to find a
coloring $\chi : U \to \{-1,+1\}$ of the elements of $U$ such that each set $S
\in \mathcal{S}$ is colored as evenly as possible. Two classic measures of
discrepancy are $\ell_\infty$-discrepancy defined as
$\textrm{disc}_\infty(\mathcal{S},\chi):=\max_{S \in \mathcal{S}} | \sum_{u_i
\in S} \chi(u_i) |$ and $\ell_2$-discrepancy defined as
$\textrm{disc}_2(\mathcal{S},\chi):=\sqrt{(1/|\mathcal{S}|)\sum_{S \in
\mathcal{S}} \left(\sum_{u_i \in S}\chi(u_i)\right)^2}$. Breakthrough work by
Bansal gave a polynomial time algorithm, based on rounding an SDP, for finding
a coloring $\chi$ such that $\textrm{disc}_\infty(\mathcal{S},\chi) = O(\lg n
\cdot \textrm{herdisc}_\infty(\mathcal{S}))$ where
$\textrm{herdisc}_\infty(\mathcal{S})$ is the hereditary
$\ell_\infty$-discrepancy of $\mathcal{S}$. We complement his work by giving a
polynomial time algorithm for finding a coloring $\chi$ such
$\textrm{disc}_2(\mathcal{S},\chi) = O(\sqrt{\lg n} \cdot
\textrm{herdisc}_2(\mathcal{S}))$ where $\textrm{herdisc}_2(\mathcal{S})$ is
the hereditary $\ell_2$-discrepancy of $\mathcal{S}$. Interestingly, our
algorithm avoids solving an SDP and instead relies simply on computing
eigendecompositions of matrices. To prove that our algorithm has the claimed
guarantees, we also prove new inequalities relating both
$\textrm{herdisc}_\infty$ and $\textrm{herdisc}_2$ to the eigenvalues of the
incidence matrix corresponding to $\mathcal{S}$. Our inequalities improve over
previous work by Chazelle and Lvov, and by Matousek, Nikolov and Talwar. We
believe these inequalities are of independent interest as powerful tools for
proving hereditary discrepancy lower bounds.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02877</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Un r\'esultat intrigant en commande sans mod\`ele</dc:title>
 <dc:creator>Join, C&#xe9;dric</dc:creator>
 <dc:creator>Delaleau, Emmanuel</dc:creator>
 <dc:creator>Fliess, Michel</dc:creator>
 <dc:creator>Moog, Claude H.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  An elementary mathematical example proves, thanks to the Routh-Hurwitz
criterion, a result that is intriguing with respect to today's practical
understanding of model-free control, i.e., an &quot;intelligent&quot; proportional
controller (iP) may turn to be more difficult to tune than an intelligent
proportional-derivative one (iPD). The vast superiority of iPDs when compared
to classic PIDs is shown via computer simulations. The introduction as well as
the conclusion analyse model-free control in the light of recent advances.
</dc:description>
 <dc:description>Comment: in French,
  https://www.openscience.fr/Un-resultat-intrigant-en-commande-sans-modele</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02877</dc:identifier>
 <dc:identifier>ISTE OpenScience Automatique, vol. 1, 2017</dc:identifier>
 <dc:language>fr</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02878</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SWIPT using Hybrid ARQ over Time Varying Channels</dc:title>
 <dc:creator>Abad, Mehdi Salehi Heydar</dc:creator>
 <dc:creator>Ercetin, Ozgur</dc:creator>
 <dc:creator>Nafie, Mohamed</dc:creator>
 <dc:creator>Elbatt, Tamer</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this work, we consider a class of wireless powered devices employing
Hybrid Automatic Repeat reQuest (HARQ) to ensure reliable end-to-end
communications over a time-varying channel. By using Simultaneous Wireless
Information and Power Transfer (SWIPT), the perpetually powered transmitter
transmits information bearing RF signal to the receiver. The receiver has no
power source, and relies on the energy harvested from the received RF blocks
from the transmitter. At each incoming RF signal block, the receiver splits the
incoming RF signal between the energy harvester and information decoder so that
the message is decoded with the least number of re-transmissions. We cast the
problem in a Markovian framework, and we show that the optimal policy
minimizing the expected number of re-transmissions utilizes the incoming RF
signal to either exclusively harvest energy or to accumulate mutual
information. By doing so, we reduce the problem which is a two dimensional
uncountable state Markov chain (MC) into a two dimensional countable state MC
and thus, enable a tractable solution for the optimal policy. For independent
and identically distributed channels, we also prove that practically
simple-to-implement policies such as harvest-first-store-later type of policies
are optimal. However, for the case of time-correlated channels, we demonstrate
that the statistical knowledge of the channel state may significantly improve
the performance when compared to those of the simple-to-implement policies.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02879</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LatentPoison - Adversarial Attacks On The Latent Space</dc:title>
 <dc:creator>Creswell, Antonia</dc:creator>
 <dc:creator>Bharath, Anil A.</dc:creator>
 <dc:creator>Sengupta, Biswa</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Robustness and security of machine learning (ML) systems are intertwined,
wherein a non-robust ML system (classifiers, regressors, etc.) can be subject
to attacks using a wide variety of exploits. With the advent of scalable deep
learning methodologies, a lot of emphasis has been put on the robustness of
supervised, unsupervised and reinforcement learning algorithms. Here, we study
the robustness of the latent space of a deep variational autoencoder (dVAE), an
unsupervised generative framework, to show that it is indeed possible to
perturb the latent space, flip the class predictions and keep the
classification probability approximately equal before and after an attack. This
means that an agent that looks at the outputs of a decoder would remain
oblivious to an attack.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2018</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02880</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance of Balanced Fairness in Resource Pools: A Recursive Approach</dc:title>
 <dc:creator>Bonald, Thomas</dc:creator>
 <dc:creator>Comte, C&#xe9;line</dc:creator>
 <dc:creator>Mathieu, Fabien</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Understanding the performance of a pool of servers is crucial for proper
dimensioning. One of the main challenges is to take into account the complex
interactions between servers that are pooled to process jobs. In particular, a
job can generally not be processed by any server of the cluster due to various
constraints like data locality. In this paper, we represent these constraints
by some assignment graph between jobs and servers. We present a recursive
approach to computing performance metrics like mean response times when the
server capacities are shared according to balanced fairness. While the
computational cost of these formulas can be exponential in the number of
servers in the worst case, we illustrate their practical interest by
introducing broad classes of pool structures that can be exactly analyzed in
polynomial time. This extends considerably the class of models for which
explicit performance metrics are accessible.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02880</dc:identifier>
 <dc:identifier>Proceedings of the ACM on Measurement and Analysis of Computing
  Systems , ACM, 2017, 1 (2), \&amp;\#x3008;10.1145/3154500\&amp;\#x3009</dc:identifier>
 <dc:identifier>doi:10.1145/3154500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02889</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FO and MSO approach to Some Graph Problems: Approximation and Poly time
  Results</dc:title>
 <dc:creator>Harshita, Kona</dc:creator>
 <dc:creator>Mishra, Sounaka</dc:creator>
 <dc:creator>P, Renjith.</dc:creator>
 <dc:creator>Sadagopan, N.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The focus of this paper is two fold. Firstly, we present a logical approach
to graph modification problems such as minimum node deletion, edge deletion,
edge augmentation problems by expressing them as an expression in first order
(FO) logic. As a consequence, it follows that these problems have constant
factor polynomial-time approximation algorithms. In particular, node
deletion/edge deletion on a graph $G$ whose resultant is cograph, split,
threshold, comparable, interval and permutation are $O(1)$ approximable.
Secondly, we present a monadic second order (MSO) logic to minimum graph
modification problems, minimum dominating set problem and minimum coloring
problem and their variants. As a consequence, it follows that these problems
have linear-time algorithms on bounded tree-width graphs. In particular, we
show the existance of linear-time algorithms on bounded tree-width graphs for
star coloring, cd-coloring, rainbow coloring, equitable coloring, total
dominating set, connected dominating set. In a nut shell, this paper presents a
unified framework and an algorithmic scheme through logical expressions for
some graph problems through FO and MSO.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02910</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Run Compressed Rank/Select for Large Alphabets</dc:title>
 <dc:creator>Fuentes-Sep&#xfa;lveda, Jos&#xe9;</dc:creator>
 <dc:creator>K&#xe4;rkk&#xe4;inen, Juha</dc:creator>
 <dc:creator>Kosolobov, Dmitry</dc:creator>
 <dc:creator>Puglisi, Simon J.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Given a string of length $n$ that is composed of $r$ runs of letters from the
alphabet $\{0,1,\ldots,\sigma{-}1\}$ such that $2 \le \sigma \le r$, we
describe a data structure that, provided $r \le n / \log^{\omega(1)} n$, stores
the string in $r\log\frac{n\sigma}{r} + o(r\log\frac{n\sigma}{r})$ bits and
supports select and access queries in $O(\log\frac{\log(n/r)}{\log\log n})$
time and rank queries in $O(\log\frac{\log(n\sigma/r)}{\log\log n})$ time. We
show that $r\log\frac{n(\sigma-1)}{r} - O(\log\frac{n}{r})$ bits are necessary
for any such data structure and, thus, our solution is succinct. We also
describe a data structure that uses $(1 + \epsilon)r\log\frac{n\sigma}{r} +
O(r)$ bits, where $\epsilon &gt; 0$ is an arbitrary constant, with the same query
times but without the restriction $r \le n / \log^{\omega(1)} n$. By simple
reductions to the colored predecessor problem, we show that the query times are
optimal in the important case $r \ge 2^{\log^\delta n}$, for an arbitrary
constant $\delta &gt; 0$. We implement our solution and compare it with the state
of the art, showing that the closest competitors consume 31-46% more space.
</dc:description>
 <dc:description>Comment: 10 pages, 1 figure, 4 tables; accepted to DCC'2018</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02917</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the $q$-Bentness of Boolean Functions</dc:title>
 <dc:creator>Chen, Zhixiong</dc:creator>
 <dc:creator>Gu, Ting</dc:creator>
 <dc:creator>Klapper, Andrew</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  For each non-constant $q$ in the set of $n$-variable Boolean functions, the
{\em $q$-transform} of a Boolean function $f$ is related to the Hamming
distances from $f$ to the functions obtainable from $q$ by nonsingular linear
change of basis. Klapper conjectured that no Boolean function exists with its
$q$-transform coefficients equal to $\pm 2^{n/2}$ (such function is called
$q$-bent). In our early work, we only gave partial results to confirm this
conjecture for small $n$. Here we prove thoroughly that the conjecture is true
by investigating the nonexistence of the partial difference sets in Abelian
groups with special parameters. We also introduce a new family of functions
called almost $q$-bent functions, which are close to $q$-bentness.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02918</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Hypernymy Extraction with Distributional Semantic Classes</dc:title>
 <dc:creator>Panchenko, Alexander</dc:creator>
 <dc:creator>Ustalov, Dmitry</dc:creator>
 <dc:creator>Faralli, Stefano</dc:creator>
 <dc:creator>Ponzetto, Simone P.</dc:creator>
 <dc:creator>Biemann, Chris</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we show for the first time how distributionally-induced
semantic classes can be helpful for extraction of hypernyms. We present a
method for (1) inducing sense-aware semantic classes using distributional
semantics and (2) using these induced semantic classes for filtering noisy
hypernymy relations. Denoising of hypernyms is performed by labeling each
semantic class with its hypernyms. On one hand, this allows us to filter out
wrong extractions using the global structure of the distributionally similar
senses. On the other hand, we infer missing hypernyms via label propagation to
cluster terms. We conduct a large-scale crowdsourcing study showing that
processing of automatically extracted hypernyms using our approach improves the
quality of the hypernymy extraction both in terms of precision and recall.
Furthermore, we show the utility of our method in the domain taxonomy induction
task, achieving the state-of-the-art results on a benchmarking dataset.
</dc:description>
 <dc:description>Comment: Submitted to the Conference on Language Resources and Evaluation
  (LREC 2018)</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02927</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Analysis of Privacy-Aware Personalization Signals by Using Online
  Evaluation Methods</dc:title>
 <dc:creator>Younus, Arjumand</dc:creator>
 <dc:creator>Qureshi, Muhammad Atif</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Personalization despite being an effective solution to the problem
information overload remains tricky on account of multiple dimensions to
consider. Furthermore, the challenge of avoiding overdoing personalization
involves estimation of a user's preferences in relation to different queries.
This work is an attempt to make inferences about when personalization would be
beneficial by relating observable user behavior to his/her social network usage
patterns and user-generated content. User behavior on a search system is
observed by means of team-draft interleaving whereby results from two retrieval
functions are presented in an interleaved manner, and user clicks are utilised
to infer preference for a certain retrieval function. This improves upon
earlier work which had limited usefulness due to reliance on user survey
results; our findings may aid real-time personalization in search systems by
detecting a user-related and query-related personalization signals.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02950</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MaaS and GDPR: an overview</dc:title>
 <dc:creator>Costantini, Federico</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In MaaS (Mobility as a Service), means of transport are virtualized in
mobility resources and provided to users using the Internet. From a legal
perspective, this model of ITS (Intelligent Transport System) raises several
concerns with regard to data protection. This contribution, after a short
description of MaaS and an introduction to the issues of data protection in
ITS, explores the impact of GDPR (General Data Protection Regulation) in the
European Union, detecting possible threats and remedies and suggesting a
plausible approach.
</dc:description>
 <dc:description>Comment: Paper (10 pages) accepted at the international conference Intelligent
  Transport Systems. From research and development to the market uptake,
  Helsinki (Finland) November 29/30, 2017. Not published nor in press</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02952</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Marginal Release Under Local Differential Privacy</dc:title>
 <dc:creator>Kulkarni, Tejas</dc:creator>
 <dc:creator>Cormode, Graham</dc:creator>
 <dc:creator>Srivastava, Divesh</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Many analysis and machine learning tasks require the availability of marginal
statistics on multidimensional datasets while providing strong privacy
guarantees for the data subjects. Applications for these statistics range from
finding correlations in the data to fitting sophisticated prediction models. In
this paper, we provide a set of algorithms for materializing marginal
statistics under the strong model of local differential privacy. We prove the
first tight theoretical bounds on the accuracy of marginals compiled under each
approach, perform empirical evaluation to confirm these bounds, and evaluate
them for tasks such as modeling and correlation testing. Our results show that
releasing information based on (local) Fourier transformations of the input is
preferable to alternatives based directly on (local) marginals.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02968</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-User Frequency-Selective Hybrid MIMO Demonstrated Using 60 GHz RF
  Modules</dc:title>
 <dc:creator>Blandino, Steve</dc:creator>
 <dc:creator>Desset, Claude</dc:creator>
 <dc:creator>Chen, Cheng-Ming</dc:creator>
 <dc:creator>Bourdoux, Andre</dc:creator>
 <dc:creator>Pollin, Sofie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Given the high throughput requirement for 5G, merging millimeter wave
technologies and multi-user MIMO seems a very promising strategy. As hardware
limitations impede to realize a full digital architecture, hybrid MIMO
architectures, using digital precoding and phased antenna arrays, are
considered a feasible solution to implement multi-user MIMO at millimeter wave.
However, real channel propagation and hardware non-idealities can significantly
degrade the performance of such systems. Experimenting the new architecture is
thus crucial to confirm and to support system design. Nevertheless, hybrid MIMO
systems are not yet understood as the effects of the wide channel bandwidths at
millimeter wave, the non-ideal RF front end as well as the imperfections of the
analog beamforming are often neglected. In this paper, we present a 60 GHz
MU-MIMO testbed using phased antenna arrays at both transmitter and receiver.
The base station equipped with a 32 phased antenna array allocates
simultaneously two users. We show that frequency selective hybrid precoding can
efficiently suppress inter-user interference enabling spatial multiplexing in
interference limited scenario doubling the throughput compared to a SISO
scenario and compensating the frequency fluctuation of the channel. In
addition, we report an EVM constellation improvement of 6 dB when comparing the
hybrid MIMO architecture with a fully analog architecture.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures. Submitted to IEEE Vehicular Technology Conference</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02974</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clustering with feature selection using alternating minimization,
  Application to computational biology</dc:title>
 <dc:creator>Gilet, Cyprien</dc:creator>
 <dc:creator>Deprez, Marie</dc:creator>
 <dc:creator>Caillau, Jean-Baptiste</dc:creator>
 <dc:creator>Barlaud, Michel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper deals with unsupervised clustering with feature selection. The
problem is to estimate both labels and a sparse projection matrix of weights.
To address this combinatorial non-convex problem maintaining a strict control
on the sparsity of the matrix of weights, we propose an alternating
minimization of the Frobenius norm criterion. We provide a new efficient
algorithm named K-sparse which alternates k-means with projection-gradient
minimization. The projection-gradient step is a method of splitting type, with
exact projection on the $\ell^1$ ball to promote sparsity. The convergence of
the gradient-projection step is addressed, and a preliminary analysis of the
alternating minimization is made. The Frobenius norm criterion converges as the
number of iterates in Algorithm K-sparse goes to infinity. Experiments on
Single Cell RNA sequencing datasets show that our method significantly improves
the results of PCA k-means, spectral clustering, SIMLR, and Sparcl methods, and
achieves a relevant selection of genes. The complexity of K-sparse is linear in
the number of samples (cells), so that the method scales up to large datasets.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02976</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RPYFMM: Parallel Adaptive Fast Multipole Method for
  Rotne-Prager-Yamakawa Tensor in Biomolecular Hydrodynamics Simulations</dc:title>
 <dc:creator>Guan, W.</dc:creator>
 <dc:creator>Cheng, X.</dc:creator>
 <dc:creator>Huang, J.</dc:creator>
 <dc:creator>Huber, G.</dc:creator>
 <dc:creator>Li, W.</dc:creator>
 <dc:creator>McCammon, J. A.</dc:creator>
 <dc:creator>Zhang, B.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  RPYFMM is a software package for the efficient evaluation of the potential
field governed by the Rotne-Prager-Yamakawa (RPY) tensor interactions in
biomolecular hydrodynamics simulations. In our algorithm, the RPY tensor is
decomposed as a linear combination of four Laplace interactions, each of which
is evaluated using the adaptive fast multipole method (FMM) [1] where the
exponential expansions are applied to diagonalize the multipole-to-local
translation operators. RPYFMM offers a unified execution on both shared and
distributed memory computers by leveraging the DASHMM library [2, 3].
Preliminary numerical results show that the interactions for a molecular system
of 15 million particles (beads) can be computed within one second on a Cray
XC30 cluster using 12, 288 cores, while achieving approximately 54%
strong-scaling efficiency.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02977</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-National Measurement of Polarization in Political Discourse:
  Analyzing floor debate in the U.S. and the Japanese legislatures</dc:title>
 <dc:creator>Sakamoto, Takuto</dc:creator>
 <dc:creator>Takikawa, Hiroki</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Political polarization in public space can seriously hamper the function and
the integrity of contemporary democratic societies. In this paper, we propose a
novel measure of such polarization, which, by way of simple topic modelling,
quantifies differences in collective articulation of public agendas among
relevant political actors. Unlike most other polarization measures, our measure
allows cross-national comparison. Analyzing a large amount of speech records of
legislative debate in the United States Congress and the Japanese Diet over a
long period of time, we have reached two intriguing findings. First, on
average, Japanese political actors are far more polarized in their issue
articulation than their counterparts in the U.S., which is somewhat surprising
given the recent notion of U.S. politics as highly polarized. Second, the
polarization in each country shows its own temporal dynamics in response to a
different set of factors. In Japan, structural factors such as the roles of the
ruling party and the opposition often dominate such dynamics, whereas the U.S.
legislature suffers from persistent ideological differences over particular
issues between major political parties. The analysis confirms a strong
influence of institutional differences on legislative debate in parliamentary
democracies.
</dc:description>
 <dc:description>Comment: To be published in the Proceedings of the 2017 IEEE International
  Conference on Big Data; 7 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02980</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anomalous popularity growth in social tagging ecosystems</dc:title>
 <dc:creator>Hashimoto, Yasuhiro</dc:creator>
 <dc:creator>Oka, Mizuki</dc:creator>
 <dc:creator>Ikegami, Takashi</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In social tagging systems, the diversity of tag vocabulary and the popularity
of such tags continue to increase as they are exposed to selection pressure
derived from our cognitive nature and cultural preferences. This is analogous
to living ecosystems, where mutation and selection play a dominant role. Such
population dynamism, which yields a scaling law, is mathematically modeled by a
simple stochastic process---the Yule--Simon process, which describes how new
words are introduced to the system and then grow. However, in actual web
services, we have observed that a large fluctuation emerges in the popularity
growth of individual tags that cannot be explained by the ordinary selection
mechanism. We introduce a scaling factor to quantify the degree of the
deviation in the popularity growth from the mean-field solution of the
Yule--Simon process, and we discuss possible triggers of such anomalous
popularity behavior.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02998</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computation of time-optimal control problem with variation evolution
  principle</dc:title>
 <dc:creator>Zhang, Sheng</dc:creator>
 <dc:creator>Qian, Wei-Qi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  An effective form of the Variation Evolving Method (VEM), which originates
from the continuous-time dynamics stability theory, is developed for the
classic time-optimal control problem with control constraint. Within the
mathematic derivation, the Pontryagin's Minimum Principle (PMP) optimality
conditions are used. Techniques including limited integrator and corner points
are introduced to capture the right solution. The variation dynamic evolving
equation may be reformulated as the Partial Differential Equation (PDE), and
then discretized as finite-dimensional Initial-value Problem (IVP) to be solved
with common Ordinary Differential Equation (ODE) integration methods. An
illustrative example is solved to show the effectiveness of the method. In
particular, the VEM is further developed to be more flexible in treating the
boundary conditions of the Optimal Control Problem (OCP), by initializing the
transformed IVP with arbitrary initial values of variables.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1709.02242,
  arXiv:1703.10263</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.02998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03016</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DLVM: A modern compiler infrastructure for deep learning systems</dc:title>
 <dc:creator>Wei, Richard</dc:creator>
 <dc:creator>Schwartz, Lane</dc:creator>
 <dc:creator>Adve, Vikram</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Deep learning software demands reliability and performance. However, many of
the existing deep learning frameworks are software libraries that act as an
unsafe DSL in Python and a computation graph interpreter. We present DLVM, a
design and implementation of a compiler infrastructure with a linear algebra
intermediate representation, algorithmic differentiation by adjoint code
generation, domain-specific optimizations and a code generator targeting GPU
via LLVM. Designed as a modern compiler infrastructure inspired by LLVM, DLVM
is more modular and more generic than existing deep learning compiler
frameworks, and supports tensor DSLs with high expressivity. With our
prototypical staged DSL embedded in Swift, we argue that the DLVM system
enables a form of modular, safe and performant frameworks for deep learning.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03018</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Stability in Max-Product and Max-Plus Systems with Markovian
  Jumps</dc:title>
 <dc:creator>Kordonis, Ioannis</dc:creator>
 <dc:creator>Maragos, Petros</dc:creator>
 <dc:creator>Papavassilopoulos, George P.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We study Max-Product and Max-Plus Systems with Markovian Jumps and focus on
stochastic stability problems. At first, a Lyapunov function is derived for the
asymptotically stable deterministic Max-Product Systems. This Lyapunov function
is then adjusted to derive sufficient conditions for the stochastic stability
of Max-Product systems with Markovian Jumps. Many step Lyapunov functions are
then used to derive necessary and sufficient conditions for stochastic
stability. The results for the Max-Product systems are then applied to Max-Plus
systems with Markovian Jumps, using an isomorphism and almost sure bounds for
the asymptotic behavior of the state are obtained. A numerical example
illustrating the application of the stability results on a production system is
also given.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03026</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intelligent Fault Analysis in Electrical Power Grids</dc:title>
 <dc:creator>Bhattacharya, Biswarup</dc:creator>
 <dc:creator>Sinha, Abhishek</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Power grids are one of the most important components of infrastructure in
today's world. Every nation is dependent on the security and stability of its
own power grid to provide electricity to the households and industries. A
malfunction of even a small part of a power grid can cause loss of
productivity, revenue and in some cases even life. Thus, it is imperative to
design a system which can detect the health of the power grid and take
protective measures accordingly even before a serious anomaly takes place. To
achieve this objective, we have set out to create an artificially intelligent
system which can analyze the grid information at any given time and determine
the health of the grid through the usage of sophisticated formal models and
novel machine learning techniques like recurrent neural networks. Our system
simulates grid conditions including stimuli like faults, generator output
fluctuations, load fluctuations using Siemens PSS/E software and this data is
trained using various classifiers like SVM, LSTM and subsequently tested. The
results are excellent with our methods giving very high accuracy for the data.
This model can easily be scaled to handle larger and more complex grid
architectures.
</dc:description>
 <dc:description>Comment: In proceedings of the 29th IEEE International Conference on Tools
  with Artificial Intelligence (ICTAI) 2017 (full paper); 6 pages; 13 figures</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03026</dc:identifier>
 <dc:identifier>doi:10.1109/ICTAI.2017.00151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03028</identifier>
 <datestamp>2017-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simplicity: A New Language for Blockchains</dc:title>
 <dc:creator>O'Connor, Russell</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Simplicity is a typed, combinator-based, functional language without loops
and recursion, designed to be used for crypto-currencies and blockchain
applications. It aims to improve upon existing crypto-currency languages, such
as Bitcoin Script and Ethereum's EVM, while avoiding some of the problems they
face. Simplicity comes with formal denotational semantics defined in Coq, a
popular, general purpose software proof assistant. Simplicity also includes
operational semantics that are defined with an abstract machine that we call
the Bit Machine. The Bit Machine is used as a tool for measuring the
computational space and time resources needed to evaluate Simplicity programs.
Owing to its Turing incompleteness, Simplicity is amenable to static analysis
that can be used to derive upper bounds on the computational resources needed,
prior to execution. While Turing incomplete, Simplicity can express any
finitary function, which we believe is enough to build useful &quot;smart contracts&quot;
for blockchain applications.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03028</dc:identifier>
 <dc:identifier>2017. Proceedings of the 2017 Workshop on Programming Languages
  and Analysis for Security. ACM, New York, NY, USA</dc:identifier>
 <dc:identifier>doi:10.1145/3139337.3139340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03031</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Location-Aided Coordinated Analog Precoding for Uplink Multi-User
  Millimeter Wave Systems</dc:title>
 <dc:creator>Maschietti, Flavio</dc:creator>
 <dc:creator>Gesbert, David</dc:creator>
 <dc:creator>de Kerret, Paul</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Millimeter wave (mmWave) communication is expected to play an important role
in next generation cellular networks, aiming to cope with the bandwidth
shortage affecting conventional wireless carriers. Using side-information has
been proposed as a potential approach to accelerate beam selection in mmWave
massive MIMO (m-MIMO) communications. However, in practice, such information is
not error-free, leading to performance degradation. In the multi-user case, a
wrong beam choice might result in irreducible inter-user interference at the
base station (BS) side. In this paper, we consider location-aided precoder
design in a mmWave uplink scenario with multiple users (UEs). Assuming the
existence of direct device-to-device (D2D) links, we propose a decentralized
coordination mechanism for robust fast beam selection. The algorithm allows for
improved treatment of interference at the BS side and in turn leads to greater
spectral efficiencies.
</dc:description>
 <dc:description>Comment: 17 pages, 4 figures</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03034</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Control of Storage Regeneration with Repair Codes</dc:title>
 <dc:creator>De Pellegrini, Francesco</dc:creator>
 <dc:creator>Azouzi, Rachid El</dc:creator>
 <dc:creator>Silva, Alonso</dc:creator>
 <dc:creator>Hassani, and Olfa</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  High availability of containerized applications requires to perform robust
storage of applications' state. Since basic replication techniques are
extremely costly at scale, storage space requirements can be reduced by means
of erasure or repairing codes. In this paper we address storage regeneration
using repair codes, a robust distributed storage technique with no need to
fully restore the whole state in case of failure. In fact, only the lost
servers' content is replaced. To do so, new cleanslate storage units are made
operational at a cost for activating new storage servers and a cost for the
transfer of repair data. Our goal is to guarantee maximal availability of
containers' state files by a given deadline. activation of servers and
communication cost. Upon a fault occurring at a subset of the storage servers,
we aim at ensuring that they are repaired by a given deadline. We introduce a
controlled fluid model and derive the optimal activation policy to replace
servers under such correlated faults. The solution concept is the optimal
control of regeneration via the Pontryagin minimum principle. We characterise
feasibility conditions and we prove that the optimal policy is of threshold
type. Numerical results describe how to apply the model for system dimensioning
and show the tradeoff between
</dc:description>
 <dc:description>Comment: This research was performed while the first author was visiting Nokia
  Bell Labs</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03037</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A joint separation-classification model for sound event detection of
  weakly labelled data</dc:title>
 <dc:creator>Kong, Qiuqiang</dc:creator>
 <dc:creator>Xu, Yong</dc:creator>
 <dc:creator>Wang, Wenwu</dc:creator>
 <dc:creator>Plumbley, Mark D.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Source separation (SS) aims to separate individual sources from an audio
recording. Sound event detection (SED) aims to detect sound events from an
audio recording. We propose a joint separation-classification (JSC) model
trained only on weakly labelled audio data, that is, only the tags of an audio
recording are known but the time of the events are unknown. First, we propose a
separation mapping from the time-frequency (T-F) representation of an audio to
the T-F segmentation masks the audio events. Second, a classification mapping
is built from each T-F segmentation mask to the presence probability of each
audio event. In the source separation stage, sources of audio events and time
of sound events can be obtained from the T-F segmentation masks. The proposed
method achieves an equal error rate (EER) of 0.14 in SED, outperforming deep
neural network baseline of 0.29. Source separation SDR of 8.08 dB is obtained
by using global weighted rank pooling (GWRP) as probability mapping,
outperforming the global max pooling (GMP) based probability mapping giving SDR
at 0.03 dB. Source code of our work is published.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018, source code available</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03038</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recency-weighted Markovian inference</dc:title>
 <dc:creator>Kalm, Kristjan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We describe a Markov latent state space (MLSS) model, where the latent state
distribution is a decaying mixture over multiple past states. We present a
simple sampling algorithm that allows to approximate such high-order MLSS with
fixed time and memory costs.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03050</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correctness of Speculative Optimizations with Dynamic Deoptimization</dc:title>
 <dc:creator>Fl&#xfc;ckiger, Olivier</dc:creator>
 <dc:creator>Scherer, Gabriel</dc:creator>
 <dc:creator>Yee, Ming-Ho</dc:creator>
 <dc:creator>Goel, Aviral</dc:creator>
 <dc:creator>Ahmed, Amal</dc:creator>
 <dc:creator>Vitek, Jan</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  High-performance dynamic language implementations make heavy use of
speculative optimizations to achieve speeds close to statically compiled
languages. These optimizations are typically performed by a just-in-time
compiler that generates code under a set of assumptions about the state of the
program and its environment. In certain cases, a program may execute code
compiled under assumptions that are no longer valid. The implementation must
then deoptimize the program on-the-fly; this entails finding semantically
equivalent code that does not rely on invalid assumptions, translating program
state to that expected by the target code, and transferring control. This paper
looks at the interaction between optimization and deoptimization, and shows
that reasoning about speculation is surprisingly easy when assumptions are made
explicit in the program representation. This insight is demonstrated on a
compiler intermediate representation, named \sourir, modeled after the
high-level representation for a dynamic language. Traditional compiler
optimizations such constant folding, dead code elimination, and function
inlining are shown to be correct in the presence of assumptions. Furthermore,
the paper establishes the correctness of compiler transformations specific to
deoptimization: namely unrestricted deoptimization, predicate hoisting, and
assume composition.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03063</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automata Minimization: a Functorial Approach</dc:title>
 <dc:creator>Colcombet, Thomas</dc:creator>
 <dc:creator>Petri&#x15f;an, Daniela</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  In this paper we regard languages and their acceptors -- such as
deterministic or weighted automata, transducers, or monoids -- as functors from
input categories that specify the type of the languages and of the machines to
categories that specify the type of outputs.
  Our results are as follows: a) We provide sufficient conditions on the output
category so that minimization of the corresponding automata is guaranteed. b)
We show how to lift adjunctions between the categories for output values to
adjunctions between categories of automata. c) We show how this framework can
be applied to several phenomena in automata theory, starting with
determinization and minimization (previously studied from a coalgebraic and
duality theoretic perspective). We apply in particular these techniques to
Choffrut's minimization algorithm for subsequential transducers and revisit
Brzozowski's minimization algorithm.
</dc:description>
 <dc:description>Comment: 17 pages, knowledge enriched version of the CALCO 2017 proceedings
  paper</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03065</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Application of Mosaic Diagrams to the Visualization of Set
  Relationships</dc:title>
 <dc:creator>Luz, Saturnino</dc:creator>
 <dc:creator>Masoodian, Masood</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We present an application of mosaic diagrams to the visualisation of set
relations. Venn and Euler diagrams are the best known visual representations of
sets and their relationships (intersections, containment or subsets, exclusion
or disjointness). In recent years, alternative forms of visualisation have been
proposed. Among them, linear diagrams have been shown to compare favourably to
Venn and Euler diagrams, in supporting non-interactive assessment of set
relationships. Recent studies that compared several variants of linear diagrams
have demonstrated that users perform best at tasks involving identification of
intersections, disjointness and subsets when using a horizontally drawn linear
diagram with thin lines representing sets, and employing vertical lines as
guide lines. The essential visual task the user needs to perform in order to
interpret this kind of diagram is vertical alignment of parallel lines and
detection of overlaps. Space-filling mosaic diagrams which support this same
visual task have been used in other applications, such as the visualization of
schedules of activities, where they have been shown to be superior to linear
Gantt charts. In this paper, we present an application of mosaic diagrams for
visualization of set relationships, and compare it to linear diagrams in terms
of accuracy, time-to-answer, and subjective ratings of perceived task
difficulty. The study participants exhibited similar performance on both
visualisations, suggesting that mosaic diagrams are a good alternative to Venn
and Euler diagrams, and that the choice between linear diagrams and mosaics may
be solely guided by visual design considerations.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03066</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Derivation of the Heap's Law from the Generalized Zipf's Law</dc:title>
 <dc:creator>Boytsov, Leonid</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  I reproduce a rather simple formal derivation of the Heaps' law from the
generalized Zipf's law, which I previously published in Russian.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03067</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning K-way D-dimensional Discrete Code For Compact Embedding
  Representations</dc:title>
 <dc:creator>Chen, Ting</dc:creator>
 <dc:creator>Min, Martin Renqiang</dc:creator>
 <dc:creator>Sun, Yizhou</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Embedding methods such as word embedding have become pillars for many
applications containing discrete structures. Conventional embedding methods
directly associate each symbol with a continuous embedding vector, which is
equivalent to applying linear transformation based on &quot;one-hot&quot; encoding of the
discrete symbols. Despite its simplicity, such approach yields number of
parameters that grows linearly with the vocabulary size and can lead to
overfitting. In this work we propose a much more compact K-way D-dimensional
discrete encoding scheme to replace the &quot;one-hot&quot; encoding. In &quot;KD encoding&quot;,
each symbol is represented by a $D$-dimensional code, and each of its dimension
has a cardinality of $K$. The final symbol embedding vector can be generated by
composing the code embedding vectors. To learn the semantically meaningful
code, we derive a relaxed discrete optimization technique based on stochastic
gradient descent. By adopting the new coding system, the efficiency of
parameterization can be significantly improved (from linear to logarithmic),
and this can also mitigate the over-fitting problem. In our experiments with
language modeling, the number of embedding parameters can be reduced by 97\%
while achieving similar or better performance.
</dc:description>
 <dc:description>Comment: NIPS'17 DISCML</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03070</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Curing Epidemics on Networks using a Polya Contagion Model</dc:title>
 <dc:creator>Hayhoe, Mikhail</dc:creator>
 <dc:creator>Alajaji, Fady</dc:creator>
 <dc:creator>Gharesifard, Bahman</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We study the curing of epidemics of a network contagion, which is modelled
using a variation of the classical Polya urn process that takes into account
spatial infection among neighbouring nodes. We introduce several quantities for
measuring the overall infection in the network and use them to formulate an
optimal control problem for minimizing the average infection rate using limited
curing resources. We prove the feasibility of this problem under high curing
budgets by deriving conservative lower bounds on the amount of curing per node
that turns our measures of network infection into supermartingales. We also
provide a provably convergent gradient descent algorithm to find the allocation
of curing under limited budgets. Motivated by the fact that this strategy is
computationally expensive, we design a suit of heuristic methods that are
locally implementable and nearly as effective. Extensive simulations run on
largescale networks demonstrate the effectiveness of our proposed strategies.
</dc:description>
 <dc:description>Comment: 12 pages, 11 figures</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03073</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower bounds over Boolean inputs for deep neural networks with ReLU
  gates</dc:title>
 <dc:creator>Mukherjee, Anirbit</dc:creator>
 <dc:creator>Basu, Amitabh</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Motivated by the resurgence of neural networks in being able to solve complex
learning tasks we undertake a study of high depth networks using ReLU gates
which implement the function $x \mapsto \max\{0,x\}$. We try to understand the
role of depth in such neural networks by showing size lowerbounds against such
network architectures in parameter regimes hitherto unexplored. In particular
we show the following two main results about neural nets computing Boolean
functions of input dimension $n$,
  1. We use the method of random restrictions to show almost linear,
$\Omega(\epsilon^{2(1-\delta)}n^{1-\delta})$, lower bound for completely weight
unrestricted LTF-of-ReLU circuits to match the Andreev function on at least
$\frac{1}{2} +\epsilon$ fraction of the inputs for $\epsilon &gt;
\sqrt{2\frac{\log^{\frac {2}{2-\delta}}(n)}{n}}$ for any $\delta \in (0,\frac 1
2)$
  2. We use the method of sign-rank to show exponential in dimension lower
bounds for ReLU circuits ending in a LTF gate and of depths upto $O(n^{\xi})$
with $\xi &lt; \frac{1}{8}$ with some restrictions on the weights in the bottom
most layer. All other weights in these circuits are kept unrestricted. This in
turns also implies the same lowerbounds for LTF circuits with the same
architecture and the same weight restrictions on their bottom most layer.
  Along the way we also show that there exists a $\mathbb{R}^ n\rightarrow
\mathbb{R}$ Sum-of-ReLU-of-ReLU function which Sum-of-ReLU neural nets can
never represent no matter how large they are allowed to be.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03076</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coresets Meet EDCS: Algorithms for Matching and Vertex Cover on Massive
  Graphs</dc:title>
 <dc:creator>Assadi, Sepehr</dc:creator>
 <dc:creator>Bateni, MohammadHossein</dc:creator>
 <dc:creator>Bernstein, Aaron</dc:creator>
 <dc:creator>Mirrokni, Vahab</dc:creator>
 <dc:creator>Stein, Cliff</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Randomized composable coresets were introduced recently as an effective
technique for solving matching and vertex cover problems in various models of
computation. In this technique, one partitions the edges of an input graph
randomly into multiple pieces, compresses each piece into a smaller subgraph,
namely a coreset, and solves the problem on the union of these coresets to find
the solution. By designing small size randomized composable coresets, one can
obtain efficient algorithms, in a black-box way, in multiple computational
models including streaming, distributed communication, and the massively
parallel computation (MPC) model.
  We develop randomized composable coresets of size $\widetilde{O}(n)$ that for
any constant $\varepsilon &gt; 0$, give a $(3/2+\varepsilon)$-approximation to
matching and a $(3+\varepsilon)$-approximation to vertex cover. Our coresets
improve upon the previously best approximation ratio of $O(1)$ for matching and
$O(\log{n})$ for vertex cover. Most notably, our result for matching goes
beyond a 2-approximation, which is a natural barrier for maximum matching in
many models of computation.
  Furthermore, inspired by the recent work of Czumaj et.al. (arXiv 2017), we
study algorithms for matching and vertex cover in the MPC model with only
$\widetilde{O}(n)$ memory per machine. Building on our coreset constructions,
we develop parallel algorithms that give a $(1+\varepsilon)$-approximation to
matching and $O(1)$-approximation to vertex cover in only
$O_{\varepsilon}(\log\log{n})$ MPC rounds and $\widetilde{O}(n)$ memory per
machine.
  A key technical ingredient of our paper is a novel application of edge degree
constrained subgraphs (EDCS). At the heart of our proofs are new structural
properties of EDCS that identify these subgraphs as sparse certificates for
large matchings and small vertex covers which are quite robust to sampling and
composition.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03082</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Offline signature authenticity verification through unambiguously
  connected skeleton segments</dc:title>
 <dc:creator>Montalv&#xe3;o, Jugurta</dc:creator>
 <dc:creator>Miranda, Luiz</dc:creator>
 <dc:creator>Canuto, J&#xe2;nio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A method for offline signature verification is presented in this paper. It is
based on the segmentation of the signature skeleton (through standard image
skeletonization) into unambiguous sequences of points, or unambiguously
connected skeleton segments corresponding to vectorial representations of
signature portions. These segments are assumed to be the fundamental carriers
of useful information for authenticity verification, and are compactly encoded
as sets of 9 scalars (4 sampled coordinates and 1 length measure). Thus
signature authenticity is inferred through Euclidean distance based comparisons
between pairs of such compact representations. The average performance of this
method is evaluated through experiments with offline versions of signatures
from the MCYT-100 database. For comparison purposes, three other approaches are
applied to the same set of signatures, namely: (1) a straightforward approach
based on Dynamic Time Warping distances between segments, (2) a published
method by [shanker2007], also based on DTW, and (3) the average human
performance under equivalent experimental protocol. Results suggest that if
human performance is taken as a goal for automatic verification, then we should
discard signature shape details to approach this goal. Moreover, our best
result -- close to human performance -- was obtained by the simplest strategy,
where equal weights were given to segment shape and length.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03082</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03087</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploration in NetHack with Secret Discovery</dc:title>
 <dc:creator>Campbell, Jonathan C.</dc:creator>
 <dc:creator>Verbrugge, Clark</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Roguelike games generally feature exploration problems as a critical, yet
often repetitive element of gameplay. Automated approaches, however, face
challenges in terms of optimality, as well as due to incomplete information,
such as from the presence of secret doors. This paper presents an algorithmic
approach to exploration of roguelike dungeon environments. Our design aims to
minimize exploration time, balancing coverage and discovery of secret areas
with resource cost. Our algorithm is based on the concept of occupancy maps
popular in robotics, adapted to encourage efficient discovery of secret access
points. Through extensive experimentation on NetHack maps we show that this
technique is significantly more efficient than simpler greedy approaches. We
further investigate optimized parameterization for the algorithm through a
comprehensive data analysis. These results point towards better automation for
players as well as heuristics applicable to fully automated gameplay.
</dc:description>
 <dc:description>Comment: 11 pages, 12 figures</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03087</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03091</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private and Online Optimization of Piecewise Lipschitz Functions</dc:title>
 <dc:creator>Balcan, Maria-Florina</dc:creator>
 <dc:creator>Dick, Travis</dc:creator>
 <dc:creator>Vitercik, Ellen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work, we present online and differentially private optimization
algorithms for a large family of nonconvex functions. This family consists of
piecewise Lipschitz functions, which are ubiquitous across diverse domains. For
example, problems in computational economics and algorithm configuration (also
known as parameter tuning) often reduce to maximizing piecewise Lipschitz
functions. These functions are challenging to optimize privately and online
since a small error can push an optimal point into a nonoptimal region. We
introduce a sufficient and general dispersion condition on these functions that
ensures well-known private and online algorithms have strong utility
guarantees. We show that several important problems from computational
economics and algorithm configuration reduce to optimizing functions that
satisfy this condition. We apply our results to obtain private and online
algorithms for these problems. We thus answer several open questions:
Cohen-Addad and Kanade ['17] asked how to optimize piecewise Lipschitz
functions online and Gupta and Roughgarden ['17] asked what algorithm
configuration problems can be solved online with no regret algorithms.
  In algorithm configuration, the goal is to tune an algorithm's parameters to
optimize its performance over a specific application domain. We analyze greedy
techniques for subset selection problems and SDP-rounding schemes for problems
that can be formulated as integer quadratic programs. In mechanism design and
other pricing problems, the goal is to use information about past consumers to
design auctions and set prices that extract high profit from future consumers.
We analyze the classic classes of second price auctions with reserves and
posted price mechanisms. For all of these settings, our general technique
implies strong utility bounds in the private setting and strong regret bounds
in the online learning setting.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03115</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Cross-Country Comparison of Crowdworker Motivations</dc:title>
 <dc:creator>Posch, Lisa</dc:creator>
 <dc:creator>Bleier, Arnim</dc:creator>
 <dc:creator>Fl&#xf6;ck, Fabian</dc:creator>
 <dc:creator>Strohmaier, Markus</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Crowd employment is a new form of short term employment that has been rapidly
becoming a source of income for a vast number of people around the globe. It
differs considerably from more traditional forms of work, yet similar ethical
and optimization issues arise. One key to tackle such challenges is to
understand what motivates the international crowd workforce. In this work, we
study the motivation of workers involved in one particularly prevalent type of
crowd employment: micro-tasks. We report on the results of applying the
Multidimensional Crowdworker Motivation Scale (MCMS) in ten countries, which
unveil significant international differences.
</dc:description>
 <dc:description>Comment: 3rd Annual International Conference on Computational Social Science
  (IC2S2), 2017</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03121</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for Real-time Gravitational Wave Detection and Parameter
  Estimation: Results with Advanced LIGO Data</dc:title>
 <dc:creator>George, Daniel</dc:creator>
 <dc:creator>Huerta, E. A.</dc:creator>
 <dc:subject>General Relativity and Quantum Cosmology</dc:subject>
 <dc:subject>Astrophysics - High Energy Astrophysical Phenomena</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The recent Nobel-prize-winning detections of gravitational waves from merging
black holes and the subsequent detection of the collision of two neutron stars
in coincidence with electromagnetic observations have inaugurated a new era of
multimessenger astrophysics. To enhance the scope of this emergent field of
science, we pioneered the use of deep learning with convolutional neural
networks, that take time-series inputs, for rapid detection and
characterization of gravitational wave signals. This approach, Deep Filtering,
was initially demonstrated using simulated LIGO noise. In this article, we
present the extension of Deep Filtering using real data from LIGO, for both
detection and parameter estimation of gravitational waves from binary black
hole mergers using continuous data streams from multiple LIGO detectors. We
demonstrate for the first time that machine learning can detect and estimate
the true parameters of real events observed by LIGO. Our results show that Deep
Filtering achieves similar sensitivities and lower errors compared to
matched-filtering while being far more computationally efficient and more
resilient to glitches, allowing real-time processing of weak time-series
signals in non-stationary non-Gaussian noise with minimal resources, and also
enables the detection of new classes of gravitational wave sources that may go
unnoticed with existing detection algorithms. This unified framework for data
analysis is ideally suited to enable coincident detection campaigns of
gravitational waves and their multimessenger counterparts in real-time.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures; First application of deep learning to real LIGO
  events; Includes direct comparison against matched-filtering</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03121</dc:identifier>
 <dc:identifier>doi:10.1016/j.physletb.2017.12.053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03127</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Storage Arbitrage in Real-Time Markets Via Reinforcement Learning</dc:title>
 <dc:creator>Wang, Hao</dc:creator>
 <dc:creator>Zhang, Baosen</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we derive a temporal arbitrage policy for storage via
reinforcement learning. Real-time price arbitrage is an important source of
revenue for storage units, but designing good strategies have proven to be
difficult because of the highly uncertain nature of the prices. Instead of
current model predictive or dynamic programming approaches, we use
reinforcement learning to design a two-thresholds policy. This policy is
learned through repeated charge and discharge actions performed by the storage
unit through updating a value matrix. We design a reward function that does not
only reflect the instant profit of charge/discharge decisions but also
incorporate the history information. Simulation results demonstrate our
designed reward function leads to significant performance improvement compared
with existing algorithms.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03127</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03129</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MarrNet: 3D Shape Reconstruction via 2.5D Sketches</dc:title>
 <dc:creator>Wu, Jiajun</dc:creator>
 <dc:creator>Wang, Yifan</dc:creator>
 <dc:creator>Xue, Tianfan</dc:creator>
 <dc:creator>Sun, Xingyuan</dc:creator>
 <dc:creator>Freeman, William T</dc:creator>
 <dc:creator>Tenenbaum, Joshua B</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  3D object reconstruction from a single image is a highly under-determined
problem, requiring strong prior knowledge of plausible 3D shapes. This
introduces challenges for learning-based approaches, as 3D object annotations
are scarce in real images. Previous work chose to train on synthetic data with
ground truth 3D information, but suffered from domain adaptation when tested on
real data. In this work, we propose MarrNet, an end-to-end trainable model that
sequentially estimates 2.5D sketches and 3D object shape. Our disentangled,
two-step formulation has three advantages. First, compared to full 3D shape,
2.5D sketches are much easier to be recovered from a 2D image; models that
recover 2.5D sketches are also more likely to transfer from synthetic to real
data. Second, for 3D reconstruction from 2.5D sketches, systems can learn
purely from synthetic data. This is because we can easily render realistic 2.5D
sketches without modeling object appearance variations in real images,
including lighting, texture, etc. This further relieves the domain adaptation
problem. Third, we derive differentiable projective functions from 3D shape to
2.5D sketches; the framework is therefore end-to-end trainable on real images,
requiring no human annotations. Our model achieves state-of-the-art performance
on 3D shape reconstruction.
</dc:description>
 <dc:description>Comment: NIPS 2017. The first two authors contributed equally to this paper.
  Project page: http://marrnet.csail.mit.edu</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03129</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03130</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EnergyNet: Energy-based Adaptive Structural Learning of Artificial
  Neural Network Architectures</dc:title>
 <dc:creator>Kristiansen, Gus</dc:creator>
 <dc:creator>Gonzalvo, Xavi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present E NERGY N ET , a new framework for analyzing and building
artificial neural network architectures. Our approach adaptively learns the
structure of the networks in an unsupervised manner. The methodology is based
upon the theoretical guarantees of the energy function of restricted Boltzmann
machines (RBM) of infinite number of nodes. We present experimental results to
show that the final network adapts to the complexity of a given problem.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03141</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Weak Compatibility Condition for Newest Vertex Bisection in any
  dimension</dc:title>
 <dc:creator>Alk&#xe4;mper, Martin</dc:creator>
 <dc:creator>Gaspoz, Fernando</dc:creator>
 <dc:creator>Kl&#xf6;fkorn, Robert</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65N30, 65N50, 65N12</dc:subject>
 <dc:description>  We define a weak compatibility condition for the Newest Vertex Bisection
algorithm on simplex grids of any dimension and show that using this condition
the iterative algorithm terminates successfully. Additionally we provide an
O(n) algorithm that renumbers any simplex grid to fulfil this condition.
Furthermore we conduct experiments to estimate the distance to the standard
compatibility and also the geometric quality of the produced meshes.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03147</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the incorporation of interval-valued fuzzy sets into the Bousi-Prolog
  system: declarative semantics, implementation and applications</dc:title>
 <dc:creator>Rubio-Manzano, Clemente</dc:creator>
 <dc:creator>Pereira-Fari&#xf1;a, Martin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  In this paper we analyse the benefits of incorporating interval-valued fuzzy
sets into the Bousi-Prolog system. A syntax, declarative semantics and im-
plementation for this extension is presented and formalised. We show, by using
potential applications, that fuzzy logic programming frameworks enhanced with
them can correctly work together with lexical resources and ontologies in order
to improve their capabilities for knowledge representation and reasoning.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03156</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Mean Field Games for Learning Optimal Behavior Policy of Large
  Populations</dc:title>
 <dc:creator>Yang, Jiachen</dc:creator>
 <dc:creator>Ye, Xiaojing</dc:creator>
 <dc:creator>Trivedi, Rakshit</dc:creator>
 <dc:creator>Xu, Huan</dc:creator>
 <dc:creator>Zha, Hongyuan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  We consider the problem of representing a large population's behavior policy
that drives the evolution of the population distribution over a discrete state
space. A discrete time mean field game (MFG) is motivated as an interpretable
model founded on game theory for understanding the aggregate effect of
individual actions and predicting the temporal evolution of population
distributions. We achieve a synthesis of MFG and Markov decision processes
(MDP) by showing that a special MFG is reducible to an MDP. This enables us to
broaden the scope of mean field game theory and infer MFG models of large
real-world systems via deep inverse reinforcement learning. Our method learns
both the reward function and forward dynamics of an MFG from real data, and we
report the first empirical test of a mean field game model of a real-world
social media population.
</dc:description>
 <dc:description>Comment: Inference of a mean field game (MFG) model of large population
  behavior via a synthesis of MFG and Markov decision processes. 10 pages plus
  6 pages appendix</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03156</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03165</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing exact minimum cuts without knowing the graph</dc:title>
 <dc:creator>Rubinstein, Aviad</dc:creator>
 <dc:creator>Schramm, Tselil</dc:creator>
 <dc:creator>Weinberg, S. Matthew</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We give query-efficient algorithms for the global min-cut and the s-t cut
problem in unweighted, undirected graphs. Our oracle model is inspired by the
submodular function minimization problem: on query $S \subset V$, the oracle
returns the size of the cut between $S$ and $V \setminus S$.
  We provide algorithms computing an exact minimum $s$-$t$ cut in $G$ with
$\tilde{O}(n^{5/3})$ queries, and computing an exact global minimum cut of $G$
with only $\tilde{O}(n)$ queries (while learning the graph requires
$\tilde{\Theta}(n^2)$ queries).
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03167</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering Order in Unordered Datasets: Generative Markov Networks</dc:title>
 <dc:creator>Tsai, Yao-Hung Hubert</dc:creator>
 <dc:creator>Zhao, Han</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:creator>Jojic, Nebojsa</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The assumption that data samples are independently identically distributed is
the backbone of many learning algorithms. Nevertheless, datasets often exhibit
rich structures in practice, and we argue that there exist some unknown orders
within the data instances. Aiming to find such orders, we introduce a novel
Generative Markov Network (GMN) which we use to extract the order of data
instances automatically. Specifically, we assume that the instances are sampled
from a Markov chain. Our goal is to learn the transitional operator of the
chain as well as the generation order by maximizing the generation probability
under all possible data permutations. One of our key ideas is to use neural
networks as a soft lookup table for approximating the possibly huge, but
discrete transition matrix. This strategy allows us to amortize the space
complexity with a single model and make the transitional operator generalizable
to unseen instances. To ensure the learned Markov chain is ergodic, we propose
a greedy batch-wise permutation scheme that allows fast training. Empirically,
we evaluate the learned Markov chain by showing that GMNs are able to discover
orders among data instances and also perform comparably well to
state-of-the-art methods on the one-shot recognition benchmark task.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03172</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Curve Reconstruction via the Global Statistics of Natural Curves</dc:title>
 <dc:creator>Barnea, Ehud</dc:creator>
 <dc:creator>Ben-Shahar, Ohad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Reconstructing the missing parts of a curve has been the subject of much
computational research, with applications in image inpainting, object
synthesis, etc. Different approaches for solving that problem are typically
based on processes that seek visually pleasing or perceptually plausible
completions. In this work we focus on reconstructing the underlying physically
likely shape by utilizing the global statistics of natural curves. More
specifically, we develop a reconstruction model that seeks the mean physical
curve for a given inducer configuration. This simple model is both
straightforward to compute and it is receptive to diverse additional
information, but it requires enough samples for all curve configurations, a
practical requirement that limits its effective utilization. To address this
practical issue we explore and exploit statistical geometrical properties of
natural curves, and in particular, we show that in many cases the mean curve is
scale invariant and oftentimes it is extensible. This, in turn, allows to boost
the number of examples and thus the robustness of the statistics and its
applicability. The reconstruction results are not only more physically
plausible but they also lead to important insights on the reconstruction
problem, including an elegant explanation why certain inducer configurations
are more likely to yield consistent perceptual completions than others.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03178</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>R(QPS-Serena) and R(QPS-Serenade): Two Novel Augmenting-Path Based
  Algorithms for Computing Approximate Maximum Weight Matching</dc:title>
 <dc:creator>Gong, Long</dc:creator>
 <dc:creator>Jun</dc:creator>
 <dc:creator>Xu</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this addendum, we show that the switching algorithm QPS-SERENA can be
converted R(QPS-SERENA), an algorithm for computing approximate Maximum Weight
Matching (MWM). Empirically, R(QPS-SERENA) computes $(1-\epsilon)$-MWM within
linear time (with respect to the number of edges $N^2$) for any fixed
$\epsilon\in (0,1)$, for complete bipartite graphs with {\it i.i.d.} uniform
edge weight distributions. This efficacy matches that of the state-of-art
solution, although we so far cannot prove any theoretical guarantees on the
time complexities needed to attain a certain approximation ratio. Then, we have
similarly converted QPS-SERENADE to R(QPS-SERENADE), which empirically should
output $(1-\epsilon)$-MWM within only $O(N \log N)$ time for the same type of
complete bipartite graphs as described above.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03179</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-stage Suture Detection for Robot Assisted Anastomosis based on
  Deep Learning</dc:title>
 <dc:creator>Hu, Yang</dc:creator>
 <dc:creator>Gu, Yun</dc:creator>
 <dc:creator>Yang, Jie</dc:creator>
 <dc:creator>Yang, Guang-Zhong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In robotic surgery, task automation and learning from demonstration combined
with human supervision is an emerging trend for many new surgical robot
platforms. One such task is automated anastomosis, which requires bimanual
needle handling and suture detection. Due to the complexity of the surgical
environment and varying patient anatomies, reliable suture detection is
difficult, which is further complicated by occlusion and thread topologies. In
this paper, we propose a multi-stage framework for suture thread detection
based on deep learning. Fully convolutional neural networks are used to obtain
the initial detection and the overlapping status of suture thread, which are
later fused with the original image to learn a gradient road map of the thread.
Based on the gradient road map, multiple segments of the thread are extracted
and linked to form the whole thread using a curvilinear structure detector.
Experiments on two different types of sutures demonstrate the accuracy of the
proposed framework.
</dc:description>
 <dc:description>Comment: Submitted to ICRA 2018</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03180</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep D-bar: Real time Electrical Impedance Tomography Imaging with Deep
  Neural Networks</dc:title>
 <dc:creator>Hamilton, Sarah Jane</dc:creator>
 <dc:creator>Hauptmann, Andreas</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:description>  The mathematical problem for Electrical Impedance Tomography (EIT) is a
highly nonlinear ill-posed inverse problem requiring carefully designed
reconstruction procedures to ensure reliable image generation. D-bar methods
are based on a rigorous mathematical analysis and provide robust direct
reconstructions by using a low-pass filtering of the associated nonlinear
Fourier data. Similarly to low-pass filtering of linear Fourier data, only
using low frequencies in the image recovery process results in blurred images
lacking sharp features such as clear organ boundaries. Convolutional Neural
Networks provide a powerful framework for post-processing such convolved direct
reconstructions. In this study, we demonstrate that these CNN techniques lead
to sharp and reliable reconstructions even for the highly nonlinear inverse
problem of EIT. The network is trained on data sets of simulated examples and
then applied to experimental data without the need to perform an additional
transfer training. Results are presented on experimental EIT data from the ACT4
and KIT4 EIT systems.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03189</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Hyperspherical Learning</dc:title>
 <dc:creator>Liu, Weiyang</dc:creator>
 <dc:creator>Zhang, Yan-Ming</dc:creator>
 <dc:creator>Li, Xingguo</dc:creator>
 <dc:creator>Yu, Zhiding</dc:creator>
 <dc:creator>Dai, Bo</dc:creator>
 <dc:creator>Zhao, Tuo</dc:creator>
 <dc:creator>Song, Le</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Convolution as inner product has been the founding basis of convolutional
neural networks (CNNs) and the key to end-to-end visual representation
learning. Benefiting from deeper architectures, recent CNNs have demonstrated
increasingly strong representation abilities. Despite such improvement, the
increased depth and larger parameter space have also led to challenges in
properly training a network. In light of such challenges, we propose
hyperspherical convolution (SphereConv), a novel learning framework that gives
angular representations on hyperspheres. We introduce SphereNet, deep
hyperspherical convolution networks that are distinct from conventional inner
product based convolutional networks. In particular, SphereNet adopts
SphereConv as its basic convolution operator and is supervised by generalized
angular softmax loss - a natural loss formulation under SphereConv. We show
that SphereNet can effectively encode discriminative representation and
alleviate training difficulty, leading to easier optimization, faster
convergence and comparable (even better) classification accuracy over
convolutional counterparts. We also provide some theoretical insights for the
advantages of learning on hyperspheres. In addition, we introduce the learnable
SphereConv, i.e., a natural improvement over prefixed SphereConv, and
SphereNorm, i.e., hyperspherical learning as a normalization method.
Experiments have verified our conclusions.
</dc:description>
 <dc:description>Comment: To appear in NIPS 2017 (Spotlight)</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03190</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Credible Models</dc:title>
 <dc:creator>Wang, Jiaxuan</dc:creator>
 <dc:creator>Oh, Jeeheh</dc:creator>
 <dc:creator>Wiens, Jenna</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In many settings, it is important that a model be capable of providing
reasons for its predictions (i.e., the model must be interpretable). However,
the model's reasoning may not conform with well-established knowledge. In such
cases, while interpretable, the model lacks \textit{credibility}. In this work,
we formally define credibility in the linear setting and focus on techniques
for learning models that are both accurate and credible. In particular, we
propose a regularization penalty, expert yielded estimates (EYE), that
incorporates expert knowledge about well-known relationships among covariates
and the outcome of interest. We give both theoretical and empirical results
comparing our proposed method to several other regularization techniques.
Across a range of settings, experiments on both synthetic and real data show
that models learned using the EYE penalty are significantly more credible than
those learned using other penalties. Applied to a large-scale patient risk
stratification task, our proposed technique results in a model whose top
features overlap significantly with known clinical risk factors, while still
achieving good predictive performance.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03194</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Long-Term Sequential Prediction Using Expert Advice</dc:title>
 <dc:creator>Burnaev, Eugeny</dc:creator>
 <dc:creator>Korotin, Alexander</dc:creator>
 <dc:creator>V'yugin, Vladimir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  For the prediction with expert advice setting, we consider methods to
construct forecasting algorithms that suffer loss not much more than of any
expert in the pool. In contrast to the standard approach, we investigate the
case of long-term interval forecasting of time series, that is, each expert
issues a sequence of forecasts for a time interval ahead and the master
algorithm combines these forecasts into one aggregated sequence of forecasts.
Two new approaches for aggregating experts long-term interval predictions are
presented. One is based on Vovk's aggregation algorithm and considers sliding
experts, the other applies the approach of Mixing Past Posteriors method to the
long-term prediction. The upper bounds for regret of these algorithms for
adversarial case are obtained. We also present results of numerical experiments
of time series long-term prediction.
</dc:description>
 <dc:description>Comment: 16 pages, 3 figures</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03195</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-Robot Cooperation Framework for Sewing Personalized Stent Grafts</dc:title>
 <dc:creator>Huang, Bidan</dc:creator>
 <dc:creator>Ye, Menglong</dc:creator>
 <dc:creator>Hu, Yang</dc:creator>
 <dc:creator>Vandini, Alessandro</dc:creator>
 <dc:creator>Lee, Su-Lin</dc:creator>
 <dc:creator>Yang, Guang-Zhong</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a multi-robot system for manufacturing personalized
medical stent grafts. The proposed system adopts a modular design, which
includes: a (personalized) mandrel module, a bimanual sewing module, and a
vision module. The mandrel module incorporates the personalized geometry of
patients, while the bimanual sewing module adopts a learning-by-demonstration
approach to transfer human hand-sewing skills to the robots. The human
demonstrations were firstly observed by the vision module and then encoded
using a statistical model to generate the reference motion trajectories. During
autonomous robot sewing, the vision module plays the role of coordinating
multi-robot collaboration. Experiment results show that the robots can adapt to
generalized stent designs. The proposed system can also be used for other
manipulation tasks, especially for flexible production of customized products
and where bimanual or multi-robot cooperation is required.
</dc:description>
 <dc:description>Comment: 10 pages, 12 figures, accepted by IEEE Transactions on Industrial
  Informatics, Key words: modularity, medical device customization, multi-robot
  system, robot learning, visual servoing, robot sewing</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03198</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Directed Sampling for Stochastic Bandits with Graph Feedback</dc:title>
 <dc:creator>Liu, Fang</dc:creator>
 <dc:creator>Buccapatnam, Swapna</dc:creator>
 <dc:creator>Shroff, Ness</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider stochastic multi-armed bandit problems with graph feedback, where
the decision maker is allowed to observe the neighboring actions of the chosen
action. We allow the graph structure to vary with time and consider both
deterministic and Erd\H{o}s-R\'enyi random graph models. For such a graph
feedback model, we first present a novel analysis of Thompson sampling that
leads to tighter performance bound than existing work. Next, we propose new
Information Directed Sampling based policies that are graph-aware in their
decision making. Under the deterministic graph case, we establish a Bayesian
regret bound for the proposed policies that scales with the clique cover number
of the graph instead of the number of actions. Under the random graph case, we
provide a Bayesian regret bound for the proposed policies that scales with the
ratio of the number of actions over the expected number of observations per
iteration. To the best of our knowledge, this is the first analytical result
for stochastic bandits with random graph feedback. Finally, using numerical
evaluations, we demonstrate that our proposed IDS policies outperform existing
approaches, including adaptions of upper confidence bound, $\epsilon$-greedy
and Exp3 algorithms.
</dc:description>
 <dc:description>Comment: Accepted by AAAI 2018</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03204</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Elascale: Autoscaling and Monitoring as a Service</dc:title>
 <dc:creator>Khazaei, Hamzeh</dc:creator>
 <dc:creator>Ravichandiran, Rajsimman</dc:creator>
 <dc:creator>Park, Byungchul</dc:creator>
 <dc:creator>Bannazadeh, Hadi</dc:creator>
 <dc:creator>Tizghadam, Ali</dc:creator>
 <dc:creator>Leon-Garcia, Alberto</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Auto-scalability has become an evident feature for cloud software systems
including but not limited to big data and IoT applications. Cloud application
providers now are in full control over their applications' microservices and
macroservices; virtual machines and containers can be provisioned or
deprovisioned on demand at runtime. Elascale strives to adjust both micro/macro
resources with respect to workload and changes in the internal state of the
whole application stack. Elascale leverages Elasticsearch stack for collection,
analysis and storage of performance metrics. Elascale then uses its default
scaling engine to elastically adapt the managed application. Extendibility is
guaranteed through provider, schema, plug-in and policy elements in the
Elascale by which flexible scalability algorithms, including both reactive and
proactive techniques, can be designed and implemented for various technologies,
infrastructures and software stacks. In this paper, we present the architecture
and initial implementation of Elascale; an instance will be leveraged to add
auto-scalability to a generic IoT application. Due to zero dependency to the
target software system, Elascale can be leveraged to provide auto-scalability
and monitoring as-a-service for any type of cloud software system.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03205</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Grammar Compression Algorithm based on Induced Suffix Sorting</dc:title>
 <dc:creator>Nunes, Daniel Saad Nogueira</dc:creator>
 <dc:creator>Louza, Felipe A.</dc:creator>
 <dc:creator>Gog, Simon</dc:creator>
 <dc:creator>Ayala-Rinc&#xf3;n, Mauricio</dc:creator>
 <dc:creator>Navarro, Gonzalo</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We introduce GCIS, a grammar compression algorithm based on the induced
suffix sorting algorithm SAIS, introduced by Nong et al. in 2009. Our solution
builds on the factorization performed by SAIS during suffix sorting. We
construct a context-free grammar on the input string which can be further
reduced into a shorter string by substituting each substring by its
correspondent factor. The resulting grammar is encoded by exploring some
redundancies, such as common prefixes between suffix rules, which are sorted
according to SAIS framework. When compared to well-known compression tools such
as Re-Pair and 7-zip, our algorithm is competitive and very effective at
handling repetitive string regarding compression ratio, compression and
decompression running time.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03213</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CyCADA: Cycle-Consistent Adversarial Domain Adaptation</dc:title>
 <dc:creator>Hoffman, Judy</dc:creator>
 <dc:creator>Tzeng, Eric</dc:creator>
 <dc:creator>Park, Taesung</dc:creator>
 <dc:creator>Zhu, Jun-Yan</dc:creator>
 <dc:creator>Isola, Phillip</dc:creator>
 <dc:creator>Saenko, Kate</dc:creator>
 <dc:creator>Efros, Alexei A.</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Domain adaptation is critical for success in new, unseen environments.
Adversarial adaptation models applied in feature spaces discover domain
invariant representations, but are difficult to visualize and sometimes fail to
capture pixel-level and low-level domain shifts. Recent work has shown that
generative adversarial networks combined with cycle-consistency constraints are
surprisingly effective at mapping images between domains, even without the use
of aligned image pairs. We propose a novel discriminatively-trained
Cycle-Consistent Adversarial Domain Adaptation model. CyCADA adapts
representations at both the pixel-level and feature-level, enforces
cycle-consistency while leveraging a task loss, and does not require aligned
pairs. Our model can be applied in a variety of visual recognition and
prediction settings. We show new state-of-the-art results across multiple
adaptation tasks, including digit classification and semantic segmentation of
road scenes demonstrating transfer from synthetic to real world domains.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03214</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fingerprint Orientation Refinement through Iterative Smoothing</dc:title>
 <dc:creator>Maponi, Pierluigi</dc:creator>
 <dc:creator>Piergallini, Riccardo</dc:creator>
 <dc:creator>Santarelli, Filippo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a new gradient-based method for the extraction of the orientation
field associated to a fingerprint, and a regularisation procedure to improve
the orientation field computed from noisy fingerprint images. The
regularisation algorithm is based on three new integral operators, introduced
and discussed in this paper. A pre-processing technique is also proposed to
achieve better performances of the algorithm. The results of a numerical
experiment are reported to give an evidence of the efficiency of the proposed
algorithm.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03214</dc:identifier>
 <dc:identifier>Signal &amp; Image Processing: An International Journal, 8(5), 29-43,
  2017</dc:identifier>
 <dc:identifier>doi:10.5121/sipij.2017.8503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03219</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Denotational validation of higher-order Bayesian inference</dc:title>
 <dc:creator>&#x15a;cibior, Adam</dc:creator>
 <dc:creator>Kammar, Ohad</dc:creator>
 <dc:creator>V&#xe1;k&#xe1;r, Matthijs</dc:creator>
 <dc:creator>Staton, Sam</dc:creator>
 <dc:creator>Yang, Hongseok</dc:creator>
 <dc:creator>Cai, Yufei</dc:creator>
 <dc:creator>Ostermann, Klaus</dc:creator>
 <dc:creator>Moss, Sean K.</dc:creator>
 <dc:creator>Heunen, Chris</dc:creator>
 <dc:creator>Ghahramani, Zoubin</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present a modular semantic account of Bayesian inference algorithms for
probabilistic programming languages, as used in data science and machine
learning. Sophisticated inference algorithms are often explained in terms of
composition of smaller parts. However, neither their theoretical justification
nor their implementation reflects this modularity. We show how to conceptualise
and analyse such inference algorithms as manipulating intermediate
representations of probabilistic programs using higher-order functions and
inductive types, and their denotational semantics. Semantic accounts of
continuous distributions use measurable spaces. However, our use of
higher-order functions presents a substantial technical difficulty: it is
impossible to define a measurable space structure over the collection of
measurable functions between arbitrary measurable spaces that is compatible
with standard operations on those functions, such as function application. We
overcome this difficulty using quasi-Borel spaces, a recently proposed
mathematical structure that supports both function spaces and continuous
distributions. We define a class of semantic structures for representing
probabilistic programs, and semantic validity criteria for transformations of
these representations in terms of distribution preservation. We develop a
collection of building blocks for composing representations. We use these
building blocks to validate common inference algorithms such as Sequential
Monte Carlo and Markov Chain Monte Carlo. To emphasize the connection between
the semantic manipulation and its traditional measure theoretic origins, we use
Kock's synthetic measure theory. We demonstrate its usefulness by proving a
quasi-Borel counterpart to the Metropolis-Hastings-Green theorem.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03219</dc:identifier>
 <dc:identifier>Proc. ACM Program. Lang. 2, POPL, Article 60 (January 2018)</dc:identifier>
 <dc:identifier>doi:10.1145/3158148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03225</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-scale Cloze Test Dataset Designed by Teachers</dc:title>
 <dc:creator>Xie, Qizhe</dc:creator>
 <dc:creator>Lai, Guokun</dc:creator>
 <dc:creator>Dai, Zihang</dc:creator>
 <dc:creator>Hovy, Eduard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Cloze test is widely adopted in language exams to evaluate students' language
proficiency. In this paper, we propose the first large-scale human-designed
cloze test dataset CLOTH, in which the questions were used in middle-school and
high-school language exams. With the missing blanks carefully created by
teachers and candidate choices purposely designed to be confusing, CLOTH
requires a deeper language understanding and a wider attention span than
previous automatically generated cloze datasets. We show humans outperform
dedicated designed baseline models by a significant margin, even when the model
is trained on sufficiently large external data. We investigate the source of
the performance gap, trace model deficiencies to some distinct properties of
CLOTH, and identify the limited ability of comprehending a long-term context to
be the key bottleneck.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03226</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly-supervised Relation Extraction by Pattern-enhanced Embedding
  Learning</dc:title>
 <dc:creator>Qu, Meng</dc:creator>
 <dc:creator>Ren, Xiang</dc:creator>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Han, Jiawei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Extracting relations from text corpora is an important task in text mining.
It becomes particularly challenging when focusing on weakly-supervised relation
extraction, that is, utilizing a few relation instances (i.e., a pair of
entities and their relation) as seeds to extract more instances from corpora.
Existing distributional approaches leverage the corpus-level co-occurrence
statistics of entities to predict their relations, and require large number of
labeled instances to learn effective relation classifiers. Alternatively,
pattern-based approaches perform bootstrapping or apply neural networks to
model the local contexts, but still rely on large number of labeled instances
to build reliable models. In this paper, we study integrating the
distributional and pattern-based methods in a weakly-supervised setting, such
that the two types of methods can provide complementary supervision for each
other to build an effective, unified model. We propose a novel co-training
framework with a distributional module and a pattern module. During training,
the distributional module helps the pattern module discriminate between the
informative patterns and other patterns, and the pattern module generates some
highly-confident instances to improve the distributional module. The whole
framework can be effectively optimized by iterating between improving the
pattern module and updating the distributional module. We conduct experiments
on two tasks: knowledge base completion with text corpora and corpus-level
relation extraction. Experimental results prove the effectiveness of our
framework in the weakly-supervised setting.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03229</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dwarf-based Scalable Big Data Benchmarking Methodology</dc:title>
 <dc:creator>Gao, Wanling</dc:creator>
 <dc:creator>Wang, Lei</dc:creator>
 <dc:creator>Zhan, Jianfeng</dc:creator>
 <dc:creator>Luo, Chunjie</dc:creator>
 <dc:creator>Zheng, Daoyi</dc:creator>
 <dc:creator>Jia, Zhen</dc:creator>
 <dc:creator>Xie, Biwei</dc:creator>
 <dc:creator>Zheng, Chen</dc:creator>
 <dc:creator>Yang, Qiang</dc:creator>
 <dc:creator>Wang, Haibin</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Different from the traditional benchmarking methodology that creates a new
benchmark or proxy for every possible workload, this paper presents a scalable
big data benchmarking methodology. Among a wide variety of big data analytics
workloads, we identify eight big data dwarfs, each of which captures the common
requirements of each class of unit of computation while being reasonably
divorced from individual implementations. We implement the eight dwarfs on
different software stacks, e.g., OpenMP, MPI, Hadoop as the dwarf components.
For the purpose of architecture simulation, we construct and tune big data
proxy benchmarks using the directed acyclic graph (DAG)-like combinations of
the dwarf components with different weights to mimic the benchmarks in
BigDataBench. Our proxy benchmarks preserve the micro-architecture, memory, and
I/O characteristics, and they shorten the simulation time by 100s times while
maintain the average micro-architectural data accuracy above 90 percentage on
both X86 64 and ARMv8 processors. We will open-source the big data dwarf
components and proxy benchmarks soon.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03230</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Analysis of Multiple-Turn Reasoning Strategies in Reading
  Comprehension Tasks</dc:title>
 <dc:creator>Shen, Yelong</dc:creator>
 <dc:creator>Liu, Xiaodong</dc:creator>
 <dc:creator>Duh, Kevin</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Reading comprehension (RC) is a challenging task that requires synthesis of
information across sentences and multiple turns of reasoning. Using a
state-of-the-art RC model, we empirically investigate the performance of
single-turn and multiple-turn reasoning on the SQuAD and MS MARCO datasets. The
RC model is an end-to-end neural network with iterative attention, and uses
reinforcement learning to dynamically control the number of turns. We find that
multiple-turn reasoning outperforms single-turn reasoning for all question and
answer types; further, we observe that enabling a flexible number of turns
generally improves upon a fixed multiple-turn strategy. %across all question
types, and is particularly beneficial to questions with lengthy, descriptive
answers. We achieve results competitive to the state-of-the-art on these two
datasets.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03232</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Convex LRMR based Passive SAR Imaging</dc:title>
 <dc:creator>Mason, Eric</dc:creator>
 <dc:creator>Yazici, Birsen</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Passive synthetic aperture radar (SAR) uses existing signals of opportunity
such as communication and broadcasting signals. In our prior work, we have
developed a low-rank matrix recovery (LRMR) method that can reconstruct scenes
with extended and densely distributed point targets, overcoming shortcomings of
conventional methods. The approach is based on correlating two sets of bistatic
measurements, which results in a linear mapping of the tensor product of the
scene reflectivity with itself. Recognizing this tensor product as a rank-one
positive semi-definite (PSD) operator, we pose passive SAR image reconstruction
as a LRMR problem with convex relaxation. In this paper, we present a
performance analysis of the convex LRMR-based passive SAR image reconstruction
method. We use the restricted isometry property (RIP) and show that exact
reconstruction is guaranteed under the condition that the pixel spacing or
resolution satisfies a certain lower bound. We show that for sufficiently large
center frequencies, our method provides superior resolution than that of
Fourier based methods, making it a super-resolution technique. Additionally, we
show that phaseless imaging is a special case of our passive SAR imaging
method. We present extensive numerical simulation to validate our analysis.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Computational Imaging</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03235</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exfiltration of Data from Air-gapped Networks via Unmodulated LED Status
  Indicators</dc:title>
 <dc:creator>Zhou, Zheng</dc:creator>
 <dc:creator>Zhang, Weiming</dc:creator>
 <dc:creator>Yang, Zichong</dc:creator>
 <dc:creator>Yu, Nenghai</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The light-emitting diode(LED) is widely used as an indicator on the
information device. Early in 2002, Loughry et al studied the exfiltration of
LED indicators and found the kind of LEDs unmodulated to indicate some state of
the device can hardly be utilized to establish covert channels. In our paper, a
novel approach is proposed to modulate this kind of LEDs. We use binary
frequency shift keying(B-FSK) to replace on-off keying(OOK) in modulation. In
order to verify the validity, we implement a prototype of an exfiltration
malware. Our experiment show a great improvement in the imperceptibility of
covert communication. It is available to leak data covertly from air-gapped
networks via unmodulated LED status indicators.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03237</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CogSciK: Clustering for Cognitive Science Motivated Decision Making</dc:title>
 <dc:creator>Rivera, Dr. W. A.</dc:creator>
 <dc:creator>Wu, James C.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Computational models of decisionmaking must contend with the variance of
context and any number of possible decisions that a defined strategic actor can
make at a given time. Relying on cognitive science theory, the authors have
created an algorithm that captures the orientation of the actor towards an
object and arrays the possible decisions available to that actor based on their
given intersubjective orientation. This algorithm, like a traditional K-means
clustering algorithm, relies on a core-periphery structure that gives the
likelihood of moves as those closest to the cluster's centroid. The result is
an algorithm that enables unsupervised classification of an array of decision
points belonging to an actor's present state and deeply rooted in cognitive
science theory.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03239</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Learning of Points-To Specifications</dc:title>
 <dc:creator>Bastani, Osbert</dc:creator>
 <dc:creator>Sharma, Rahul</dc:creator>
 <dc:creator>Aiken, Alex</dc:creator>
 <dc:creator>Liang, Percy</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  When analyzing programs, large libraries pose significant challenges to
static points-to analysis. A popular solution is to have a human analyst
provide points-to specifications that summarize relevant behaviors of library
code, which can substantially improve precision and furthermore handle missing
code such as native code. We propose Atlas, a tool that automatically infers
points-to specifications. Atlas synthesizes unit tests that exercise the
library code, and then infers points-to specifications based on observations
from these executions. Atlas automatically infers specifications for the Java
standard library, and produces better results for a client static information
flow analysis on a benchmark of 46 Android apps compared to using existing
handwritten specifications.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03240</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cellular Offloading via Downlink Cache Placement</dc:title>
 <dc:creator>Lv, Bojie</dc:creator>
 <dc:creator>Huang, Lexiang</dc:creator>
 <dc:creator>Wang, Rui</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the downlink file transmission within a finite lifetime is
optimized with the assistance of wireless cache nodes. Specifically, the number
of requests within the lifetime of one file is modeled as a Poisson point
process. The base station multicasts files to downlink users and the selected
the cache nodes, so that the cache nodes can help to forward the files in the
next file request. Thus we formulate the downlink transmission as a Markov
decision process with random number of stages, where transmission power and
time on each transmission are the control policy. Due to random number of file
transmissions, we first proposed a revised Bellman's equation, where the
optimal control policy can be derived. In order to address the prohibitively
huge state space, we also introduce a low-complexity sub-optimal solution based
on an linear approximation of the value function. The approximated value
function can be calculated analytically, so that conventional numerical value
iteration can be eliminated. Moreover, the gap between the approximated value
function and the real value function is bounded analytically. It is shown by
simulation that, with the approximated MDP approach, the proposed algorithm can
significantly reduce the resource consumption at the base station.
</dc:description>
 <dc:description>Comment: Submitted for IEEE ICC 2018</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03243</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to select examples for program synthesis</dc:title>
 <dc:creator>Pu, Yewen</dc:creator>
 <dc:creator>Miranda, Zachery</dc:creator>
 <dc:creator>Solar-Lezama, Armando</dc:creator>
 <dc:creator>Kaelbling, Leslie Pack</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:description>  Program synthesis is a class of regression problems where one seeks a
solution, in the form of a source-code program, mapping the inputs to their
corresponding outputs exactly. Due to its precise and combinatorial nature, it
is commonly formulated as a constraint satisfaction problem, where input-output
examples are encoded as constraints and solved with a constraint solver. A key
challenge of this formulation is scalability: while constraint solvers work
well with few well-chosen examples, a large set of examples can incur
significant overhead in both time and memory. We address this challenge by
constructing a representative subset of examples that is both small and able to
constrain the solver sufficiently. We build the subset one example at a time,
using a neural network to predict the probability of unchosen input-output
examples conditioned on the chosen input-output examples, and adding the least
probable example to the subset. Experiment on a diagram drawing domain shows
our approach produces subsets of examples that are small and representative for
the constraint solver.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03244</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable and massively parallel Monte Carlo photon transport simulations
  for heterogeneous computing platforms</dc:title>
 <dc:creator>Yu, Leiming</dc:creator>
 <dc:creator>Nina-Paravecino, Fanny</dc:creator>
 <dc:creator>Kaeli, David</dc:creator>
 <dc:creator>Fang, Qianqian</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  We present a highly scalable Monte Carlo (MC) three-dimensional photon
transport simulation platform designed for heterogeneous computing systems.
Through the development of a massively parallel MC algorithm using the Open
Computing Language (OpenCL) framework, this research extends our existing
graphics processing unit (GPU)-accelerated MC technique to a highly scalable
vendor-independent heterogeneous computing environment, achieving significantly
improved performance and software portability. A number of parallel computing
techniques are investigated to achieve portable performance over a wide range
of computing hardware. Furthermore, multiple thread-level and device-level
load-balancing strat- egies are developed to obtain efficient simulations using
multiple central processing units (CPUs) and GPUs.
</dc:description>
 <dc:description>Comment: Accepted for Publication in Journal of Biomedical Optics Letters on
  Jan 4, 2018, to appear in Volume 23, Issue 2</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03245</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of the U.S. Patient Referral Network</dc:title>
 <dc:creator>An, Chuankai</dc:creator>
 <dc:creator>O'Malley, A. James</dc:creator>
 <dc:creator>Rockmore, Daniel N.</dc:creator>
 <dc:creator>Stock, Corey D.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>91D30 (Primary), 05C82 (Secondary)</dc:subject>
 <dc:description>  In this paper we analyze the US Patient Referral Network (also called the
Shared Patient Network) and various subnetworks for the years 2009--2015. In
these networks two physicians are linked if a patient encounters both of them
within a specified time-interval, according to the data made available by the
Centers for Medicare and Medicaid Services. We find power law distributions on
most state-level data as well as a core-periphery structure. On a national and
state level, we discover a so-called small-world structure as well as a
&quot;gravity law&quot; of the type found in some large-scale economic networks. Some
physicians play the role of hubs for interstate referral. Strong correlations
between certain network statistics with healthcare system statistics at both
the state and national levels are discovered. The patterns in the referral
network evinced using several statistical analyses involving key metrics
derived from the network illustrate the potential for using network analysis to
provide new insights into the healthcare system and opportunities or mechanisms
for catalyzing improvements.
</dc:description>
 <dc:description>Comment: 38 pages, 11 figures, 10 tables</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03256</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distances in and Layering of a DAG</dc:title>
 <dc:creator>Chitturi, Bhadrachalam</dc:creator>
 <dc:creator>Das, Priyanshu</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>05C12, 05C20, 05C78, 68R01</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  The diameter of an undirected unweighted graph $G=(V,E)$ is the maximum value
of the distance from any vertex $u$ to another vertex $v$ for $u,v \in V$ where
distance i.e. $d(u,v)$ is the length of the shortest path from $u$ to $v$ in
$G$. DAG, is a directed graph without a cycle. We denote the diameter of an
unweighted DAG $G=(V,E)$ by $\delta (G)$. The stretch of a DAG $G$ is the
length of longest path from $u$ to $v$ in $G$, for all choices of $(u, v) \in
V$ denoted by $\Delta (G)$. The diameter of an undirected graph can be computed
in $O(|V|(|V|+|E|))$ time by executing breadth first search $|V|$ times. We
show that stretch and diameter of a DAG can be computed in $O(|V|+|E|)$ time
and $O(|V||E|)$ time respectively.
  A DAG is balanced if and only if a consistent assignment of level numbers to
all vertices is possible. Layering refers to such an assignment. A balanced DAG
is defined. An efficient algorithm that either detects whether a given DAG is
unbalanced or layers it otherwise is designed with a running time of
$O(|V|+|E|)$. \\ Key words: Diameter, directed acyclic graph, longest directed
path, graph algorithms, complexity.
</dc:description>
 <dc:description>Comment: 4 Pages. Minor modification in the way affiliation is written. The
  time complexites of stretch and diameter are reversed. In big O notation V
  and E are changed to |V| and |E| respectively. The last sentence in the
  conclusion is rewritten</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03261</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coordinated trajectory tracking of multiple vertical take-off and
  landing UAVs</dc:title>
 <dc:creator>Zou, Yao</dc:creator>
 <dc:creator>Meng, Ziyang</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper investigates the coordinated trajectory tracking problem of
multiple vertical takeooff and landing (VTOL) unmanned aerial vehicles (UAVs).
The case of unidirectional information flow is considered and the objective is
to drive all the follower VTOL UAVs to accurately track the trajectory of the
leader. Firstly, a novel distributed estimator is developed for each VTOL UAV
to obtain the leader's desired information asymptotically. With the outputs of
the estimators, the solution to the coordinated trajectory tracking problem of
multiple VTOL UAVs is transformed to individually solving the tracking problem
of each VTOL UAV. Due to the under-actuated nature of the VTOL UAV, a
hierarchical framework is introduced for each VTOL UAV such that a command
force and an applied torque are exploited in sequence, then the position
tracking to the estimated desired position and the attitude tracking to the
command attitude are achieved. Moreover, an auxiliary system with proper
parameters is implemented to guarantee the singularity-free command attitude
extraction and to obviate the use of the unavailable desired information. The
stability analysis and simulations effectively validate the achievement of the
coordinated trajectory tracking of multiple VTOL UAVs with the proposed control
approach.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03269</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Canonical-based NPN Boolean Matching Algorithm Utilizing Boolean
  Difference and Cofactor Signature</dc:title>
 <dc:creator>Zhang, Juling</dc:creator>
 <dc:creator>Yang, Guowu</dc:creator>
 <dc:creator>Hung, William N. N.</dc:creator>
 <dc:creator>Wu, Jinzhao</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This paper presents a new compact canonical-based algorithm to solve the
problem of single-output completely specified NPN Boolean matching. We propose
a new signature vector Boolean difference and cofactor (DC) signature vector.
Our algorithm utilizes the Boolean difference, cofactor signature and symmetry
properties to search for canonical transformations. The use of symmetry and
Boolean difference notably reduces the search space and speeds up the Boolean
matching process compared to the algorithm proposed in [1]. We tested our
algorithm on a large number of circuits. The experimental results showed that
the average runtime of our algorithm 37% higher and its average search space
67% smaller compared to [1] when tested on general circuits.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03270</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Scene Parsing and Motion Dynamics in the Future</dc:title>
 <dc:creator>Jin, Xiaojie</dc:creator>
 <dc:creator>Xiao, Huaxin</dc:creator>
 <dc:creator>Shen, Xiaohui</dc:creator>
 <dc:creator>Yang, Jimei</dc:creator>
 <dc:creator>Lin, Zhe</dc:creator>
 <dc:creator>Chen, Yunpeng</dc:creator>
 <dc:creator>Jie, Zequn</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The ability of predicting the future is important for intelligent systems,
e.g. autonomous vehicles and robots to plan early and make decisions
accordingly. Future scene parsing and optical flow estimation are two key tasks
that help agents better understand their environments as the former provides
dense semantic information, i.e. what objects will be present and where they
will appear, while the latter provides dense motion information, i.e. how the
objects will move. In this paper, we propose a novel model to simultaneously
predict scene parsing and optical flow in unobserved future video frames. To
our best knowledge, this is the first attempt in jointly predicting scene
parsing and motion dynamics. In particular, scene parsing enables structured
motion prediction by decomposing optical flow into different groups while
optical flow estimation brings reliable pixel-wise correspondence to scene
parsing. By exploiting this mutually beneficial relationship, our model shows
significantly better parsing and motion prediction results when compared to
well-established baselines and individual prediction models on the large-scale
Cityscapes dataset. In addition, we also demonstrate that our model can be used
to predict the steering angle of the vehicles, which further verifies the
ability of our model to learn latent representations of scene dynamics.
</dc:description>
 <dc:description>Comment: To appear in NIPS 2017</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03272</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Go with the Flow: Compositional Abstractions for Concurrent Data
  Structures (Extended Version)</dc:title>
 <dc:creator>Krishna, Siddharth</dc:creator>
 <dc:creator>Shasha, Dennis</dc:creator>
 <dc:creator>Wies, Thomas</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Concurrent separation logics have helped to significantly simplify
correctness proofs for concurrent data structures. However, a recurring problem
in such proofs is that data structure abstractions that work well in the
sequential setting are much harder to reason about in a concurrent setting due
to complex sharing and overlays. To solve this problem, we propose a novel
approach to abstracting regions in the heap by encoding the data structure
invariant into a local condition on each individual node. This condition may
depend on a quantity associated with the node that is computed as a fixpoint
over the entire heap graph. We refer to this quantity as a flow. Flows can
encode both structural properties of the heap (e.g. the reachable nodes from
the root form a tree) as well as data invariants (e.g. sortedness). We then
introduce the notion of a flow interface, which expresses the relies and
guarantees that a heap region imposes on its context to maintain the local flow
invariant with respect to the global heap. Our main technical result is that
this notion leads to a new semantic model of separation logic. In this model,
flow interfaces provide a general abstraction mechanism for describing complex
data structures. This abstraction mechanism admits proof rules that generalize
over a wide variety of data structures. To demonstrate the versatility of our
approach, we show how to extend the logic RGSep with flow interfaces. We have
used this new logic to prove linearizability and memory safety of nontrivial
concurrent data structures. In particular, we obtain parametric linearizability
proofs for concurrent dictionary algorithms that abstract from the details of
the underlying data structure representation. These proofs cannot be easily
expressed using the abstraction mechanisms provided by existing separation
logics.
</dc:description>
 <dc:description>Comment: This is an extended version of a POPL 2018 conference paper</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03273</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-stream Collaborative Learning with Spatial-Temporal Attention for
  Video Classification</dc:title>
 <dc:creator>Peng, Yuxin</dc:creator>
 <dc:creator>Zhao, Yunzhen</dc:creator>
 <dc:creator>Zhang, Junchao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Video classification is highly important with wide applications, such as
video search and intelligent surveillance. Video naturally consists of static
and motion information, which can be represented by frame and optical flow.
Recently, researchers generally adopt the deep networks to capture the static
and motion information \textbf{\emph{separately}}, which mainly has two
limitations: (1) Ignoring the coexistence relationship between spatial and
temporal attention, while they should be jointly modelled as the spatial and
temporal evolutions of video, thus discriminative video features can be
extracted.(2) Ignoring the strong complementarity between static and motion
information coexisted in video, while they should be collaboratively learned to
boost each other. For addressing the above two limitations, this paper proposes
the approach of two-stream collaborative learning with spatial-temporal
attention (TCLSTA), which consists of two models: (1) Spatial-temporal
attention model: The spatial-level attention emphasizes the salient regions in
frame, and the temporal-level attention exploits the discriminative frames in
video. They are jointly learned and mutually boosted to learn the
discriminative static and motion features for better classification
performance. (2) Static-motion collaborative model: It not only achieves mutual
guidance on static and motion information to boost the feature learning, but
also adaptively learns the fusion weights of static and motion streams, so as
to exploit the strong complementarity between static and motion information to
promote video classification. Experiments on 4 widely-used datasets show that
our TCLSTA approach achieves the best performance compared with more than 10
state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 14 pages, accepted by IEEE Transactions on Circuits and Systems for
  Video Technology</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03278</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feed Forward and Backward Run in Deep Convolution Neural Network</dc:title>
 <dc:creator>Murugan, Pushparaja</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolution Neural Networks (CNN), known as ConvNets are widely used in many
visual imagery application, object classification, speech recognition. After
the implementation and demonstration of the deep convolution neural network in
Imagenet classification in 2012 by krizhevsky, the architecture of deep
Convolution Neural Network is attracted many researchers. This has led to the
major development in Deep learning frameworks such as Tensorflow, caffe, keras,
theno. Though the implementation of deep learning is quite possible by
employing deep learning frameworks, mathematical theory and concepts are harder
to understand for new learners and practitioners. This article is intended to
provide an overview of ConvNets architecture and to explain the mathematical
theory behind it including activation function, loss function, feedforward and
backward propagation. In this article, grey scale image is taken as input
information image, ReLU and Sigmoid activation function are considered for
developing the architecture and cross-entropy loss function are used for
computing the difference between predicted value and actual value. The
architecture is developed in such a way that it can contain one convolution
layer, one pooling layer, and multiple dense layers
</dc:description>
 <dc:description>Comment: 20 pages, 20th International Conference on Computer Vision and Image
  Processing</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03280</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crafting Adversarial Examples For Speech Paralinguistics Applications</dc:title>
 <dc:creator>Gong, Yuan</dc:creator>
 <dc:creator>Poellabauer, Christian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Computational paralinguistic analysis is increasingly being used in a wide
range of applications, including security-sensitive applications such as
speaker verification, deceptive speech detection, and medical diagnosis. While
state-of-the-art machine learning techniques, such as deep neural networks, can
provide robust and accurate speech analysis, they are susceptible to
adversarial attacks. In this work, we propose a novel end-to-end scheme to
generate adversarial examples by perturbing directly the raw waveform of an
audio recording rather than specific acoustic features. Our experiments show
that the proposed adversarial perturbation can lead to a significant
performance drop of state-of-the-art deep neural networks, while only minimally
impairing the audio quality.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03280</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03306</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast camera focus estimation for gaze-based focus control</dc:title>
 <dc:creator>Fuhl, Wolfgang</dc:creator>
 <dc:creator>Santini, Thiago</dc:creator>
 <dc:creator>Kasneci, Enkelejda</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.5</dc:subject>
 <dc:subject>I.4.6</dc:subject>
 <dc:subject>I.4.7</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:description>  Many cameras implement auto-focus functionality. However, they typically
require the user to manually identify the location to be focused on. While such
an approach works for temporally-sparse autofocusing functionality (e.g., photo
shooting), it presents extreme usability problems when the focus must be
quickly switched between multiple areas (and depths) of interest - e.g., in a
gaze-based autofocus approach. This work introduces a novel, real-time
auto-focus approach based on eye-tracking, which enables the user to shift the
camera focus plane swiftly based solely on the gaze information. Moreover, the
proposed approach builds a graph representation of the image to estimate depth
plane surfaces and runs in real time (requiring ~20ms on a single i5 core),
thus allowing for the depth map estimation to be performed dynamically. We
evaluated our algorithm for gaze-based depth estimation against
state-of-the-art approaches based on eight new data sets with flat, skewed, and
round surfaces, as well as publicly available datasets.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03307</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Dual Cyclic and Quantum Codes Over Z2^{\alpha} x (Z2 + uZ2)^{\beta}</dc:title>
 <dc:creator>Aydogdu, Ismail</dc:creator>
 <dc:creator>Abualrub, Taher</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we introduce self-dual cyclic and quantum codes over
Z2^{\alpha} x (Z2 + uZ2)^{\beta}. We determine the conditions for any
Z2Z2[u]-cyclic code to be self-dual, that is, C = C^{\perp}. Since the binary
image of a self-orthogonal Z2Z2[u]-linear code is also a self-orthogonal binary
linear code, we introduce quantum codes over Z2^{\alpha} x (Z2 + uZ2)^{\beta}.
Finally, we present some examples of self-dual cyclic and quantum codes that
have good parameters.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03310</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weak Flip Codes and their Optimality on the Binary Erasure Channel</dc:title>
 <dc:creator>Lin, Hsuan-Yin</dc:creator>
 <dc:creator>Moser, Stefan M.</dc:creator>
 <dc:creator>Chen, Po-Ning</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates fundamental properties of nonlinear binary codes by
looking at the codebook matrix not row-wise (codewords), but column-wise. The
family of weak flip codes is presented and shown to contain many beautiful
properties. In particular the subfamily fair weak flip codes, which goes back
to Berlekamp, Gallager, and Shannon and which was shown to achieve the error
exponent with a fixed number of codewords $M$, can be seen as a generalization
of linear codes to an arbitrary number of codewords. Based on the column-wise
approach, the $r$-wise Hamming distance is introduced as a generalization to
the widely used (pairwise) Hamming distance. It is shown that the minimum
$r$-wise Hamming distance satisfies a generalized $r$-wise Plotkin bound. The
$r$-wise Hamming distance structure of the nonlinear fair weak flip codes is
analyzed and shown to be superior to many codes. In particular, it is proven
that the fair weak flip codes achieve the $r$-wise Plotkin bound with equality
for all $r$. In the second part of the paper, these insights are applied to a
binary erasure channel (BEC) with an arbitrary erasure probability. An exact
formula for the average error probability of an arbitrary code using maximum
likelihood decoding is derived and shown to be expressible using only the
$r$-wise Hamming distance structure of the code. For a number of codewords
$M\leq4$ and an arbitrary blocklength $n$, the globally optimal codes (in the
sense of minimizing the average error probability) are found. For $M=5,6$ and
an arbitrary blocklength $n$, the optimal codes are conjectured. For larger
$M$, observations regarding the optimal design are presented, e.g., that good
codes have a large $r$-wise Hamming distance structure for all $r$. Numerical
results validate our code design criteria and show the superiority of our best
found nonlinear weak flip codes compared to the best linear codes.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03321</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Separation Principle for Control in the Age of Deep Learning</dc:title>
 <dc:creator>Achille, Alessandro</dc:creator>
 <dc:creator>Soatto, Stefano</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We review the problem of defining and inferring a &quot;state&quot; for a control
system based on complex, high-dimensional, highly uncertain measurement streams
such as videos. Such a state, or representation, should contain all and only
the information needed for control, and discount nuisance variability in the
data. It should also have finite complexity, ideally modulated depending on
available resources. This representation is what we want to store in memory in
lieu of the data, as it &quot;separates&quot; the control task from the measurement
process. For the trivial case with no dynamics, a representation can be
inferred by minimizing the Information Bottleneck Lagrangian in a function
class realized by deep neural networks. The resulting representation has much
higher dimension than the data, already in the millions, but it is smaller in
the sense of information content, retaining only what is needed for the task.
This process also yields representations that are invariant to nuisance factors
and having maximally independent components. We extend these ideas to the
dynamic case, where the representation is the posterior density of the task
variable given the measurements up to the current time, which is in general
much simpler than the prediction density maintained by the classical Bayesian
filter. Again this can be finitely-parametrized using a deep neural network,
and already some applications are beginning to emerge. No explicit assumption
of Markovianity is needed; instead, complexity trades off approximation of an
optimal representation, including the degree of Markovianity.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03327</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Influence Maximization over Markovian Graphs: A Stochastic Optimization
  Approach</dc:title>
 <dc:creator>Nettasinghe, Buddhika</dc:creator>
 <dc:creator>Krishnamurthy, Vikram</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This paper considers the problem of randomized influence maximization over a
Markovian graph process: given a fixed set of nodes whose connectivity graph is
evolving as a Markov chain, estimate the probability distribution (over this
fixed set of nodes) that samples a node which will initiate the largest
information cascade (in expectation). Further, it is assumed that the sampling
process affects the evolution of the graph i.e. the sampling distribution and
the transition probability matrix are functionally dependent. In this setup,
recursive stochastic optimization algorithms are presented to estimate the
optimal sampling distribution for two cases: 1) transition probabilities of the
graph are unknown but, the graph can be observed perfectly 2) transition
probabilities of the graph are known but, the graph is observed in noise. These
algorithms consist of a neighborhood size estimation algorithm combined with a
variance reduction method, a Bayesian filter and a stochastic gradient
algorithm. Convergence of the algorithms are established theoretically and,
numerical results are provided to illustrate how the algorithms work.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03331</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Distribution System Planning for Large-Scale Network
  Integration Studies</dc:title>
 <dc:creator>Scheidler, Alexander</dc:creator>
 <dc:creator>Thurner, Leon</dc:creator>
 <dc:creator>Braun, Martin</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Network integration studies try to assess the impact of future developments,
such as the increase of Renewable Energy Sources or the introduction of Smart
Grid Technologies, on large-scale network areas. Goals can be to support
strategic alignment in the regulatory framework or to adapt the network
planning principles of Distribution System Operators. This study outlines an
approach for the automated distribution system planning that can calculate
network reconfiguration, reinforcement and extension plans in a fully automated
fashion. This allows the estimation of the expected cost in massive
probabilistic simulations of large numbers of real networks and constitutes a
core component of a framework for large-scale network integration studies.
Exemplary case study results are presented that were performed in cooperation
with different major distribution system operators. The case studies cover the
estimation of expected network reinforcement costs, technical and economical
assessment of smart grid technologies and structural network optimisation.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03334</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Orchestrating Complex Application Architectures in Heterogeneous Clouds</dc:title>
 <dc:creator>Caballer, Miguel</dc:creator>
 <dc:creator>Zala, Sahdev</dc:creator>
 <dc:creator>Garc&#xed;a, &#xc1;lvaro L&#xf3;pez</dc:creator>
 <dc:creator>Molt&#xf3;, Germ&#xe1;n</dc:creator>
 <dc:creator>Fern&#xe1;ndez, Pablo Orviz</dc:creator>
 <dc:creator>Velten, Mathieu</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Private cloud infrastructures are now widely deployed and adopted across
technology industries and research institutions. Although cloud computing has
emerged as a reality, it is now known that a single cloud provider cannot fully
satisfy complex user requirements. This has resulted in a growing interest in
developing hybrid cloud solutions that bind together distinct and heterogeneous
cloud infrastructures. In this paper we describe the orchestration approach for
heterogeneous clouds that has been implemented and used within the
INDIGO-DataCloud project. This orchestration model uses existing open-source
software like OpenStack and leverages the OASIS Topology and Specification for
Cloud Applications (TOSCA) open standard as the modeling language. Our approach
uses virtual machines and Docker containers in an homogeneous and transparent
way providing consistent application deployment for the users. This approach is
illustrated by means of two different use cases in different scientific
communities, implemented using the INDIGO-DataCloud solutions.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03334</dc:identifier>
 <dc:identifier>J Grid Computing (2017)</dc:identifier>
 <dc:identifier>doi:10.1007/s10723-017-9418-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03336</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward perfect reads</dc:title>
 <dc:creator>Limasset, Antoine</dc:creator>
 <dc:creator>Flot, Jean-Francois</dc:creator>
 <dc:creator>Peterlongo, Pierre</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  We propose a new method to correct short reads using de Bruijn graphs, and
implement it as a tool called Bcool. As a first step, Bcool constructs a
corrected compacted de Bruijn graph from the reads. This graph is then used as
a reference and the reads are corrected according to their mapping on the
graph. We show that this approach yields a better correction than kmer-spectrum
techniques, while being scalable, making it possible to apply it to human-size
genomic datasets and beyond. The implementation is open source and available at
github.com/Malfoy/BCOOL
</dc:description>
 <dc:description>Comment: RECOMB 2018 Submission</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03343</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Dropout in Online Learning</dc:title>
 <dc:creator>Hara, Kazuyuki</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep learning is the state-of-the-art in fields such as visual object
recognition and speech recognition. This learning uses a large number of layers
and a huge number of units and connections. Therefore, overfitting is a serious
problem with it, and the dropout which is a kind of regularization tool is
used. However, in online learning, the effect of dropout is not well known.
This paper presents our investigation on the effect of dropout in online
learning. We analyzed the effect of dropout on convergence speed near the
singular point. Our results indicated that dropout is effective in online
learning. Dropout tends to avoid the singular point for convergence speed near
that point.
</dc:description>
 <dc:description>Comment: 8 pages, 6 pages</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03343</dc:identifier>
 <dc:identifier>IEICE Technical Report IBIS2017-61</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03345</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Frangi-Net: A Neural Network Approach to Vessel Segmentation</dc:title>
 <dc:creator>Fu, Weilin</dc:creator>
 <dc:creator>Breininger, Katharina</dc:creator>
 <dc:creator>W&#xfc;rfl, Tobias</dc:creator>
 <dc:creator>Ravikumar, Nishant</dc:creator>
 <dc:creator>Schaffert, Roman</dc:creator>
 <dc:creator>Maier, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we reformulate the conventional 2-D Frangi vesselness measure
into a pre-weighted neural network (&quot;Frangi-Net&quot;), and illustrate that the
Frangi-Net is equivalent to the original Frangi filter. Furthermore, we show
that, as a neural network, Frangi-Net is trainable. We evaluate the proposed
method on a set of 45 high resolution fundus images. After fine-tuning, we
observe both qualitative and quantitative improvements in the segmentation
quality compared to the original Frangi measure, with an increase up to $17\%$
in F1 score.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03357</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compact Neural Networks based on the Multiscale Entanglement
  Renormalization Ansatz</dc:title>
 <dc:creator>Hallam, Andrew</dc:creator>
 <dc:creator>Grant, Edward</dc:creator>
 <dc:creator>Stojevic, Vid</dc:creator>
 <dc:creator>Severini, Simone</dc:creator>
 <dc:creator>Green, Andrew G.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  The goal of this paper is to demonstrate a method for tensorizing neural
networks based upon an efficient way of approximating scale invariant quantum
states, the Multi-scale Entanglement Renormalization Ansatz (MERA). We employ
MERA as a replacement for linear layers in a neural network and test this
implementation on the CIFAR-10 dataset. The proposed method outperforms
factorization using tensor trains, providing greater compression for the same
level of accuracy and greater accuracy for the same level of compression. We
demonstrate MERA-layers with 3900 times fewer parameters and a reduction in
accuracy of less than 1% compared to the equivalent fully connected layers.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures. Under review as a conference paper at ICLR 2018</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03359</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Distributed Approximation for TAP and 2-Edge-Connectivity</dc:title>
 <dc:creator>Censor-Hillel, Keren</dc:creator>
 <dc:creator>Dory, Michal</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The tree augmentation problem (TAP) is a fundamental network design problem,
in which the input is a graph $G$ and a spanning tree $T$ for it, and the goal
is to augment $T$ with a minimum set of edges $Aug$ from $G$, such that $T \cup
Aug$ is 2-edge-connected.
  TAP has been widely studied in the sequential setting. The best known
approximation ratio of 2 for the weighted case dates back to the work of
Frederickson and J\'{a}J\'{a}, SICOMP 1981. Recently, a 3/2-approximation was
given for the unweighted case by Kortsarz and Nutov, TALG 2016, and recent
breakthroughs by Adjiashvili, SODA 2017, and by Fiorini et al., 2017, give
approximations better than 2 for bounded weights.
  In this paper, we provide the first fast distributed approximations for TAP.
We present a distributed $2$-approximation for weighted TAP which completes in
$O(h)$ rounds, where $h$ is the height of $T$. When $h$ is large, we show a
much faster 4-approximation algorithm for the unweighted case, completing in
$O(D+\sqrt{n}\log^*{n})$ rounds, where $n$ is the number of vertices and $D$ is
the diameter of $G$.
  Immediate consequences of our results are an $O(D)$-round 2-approximation
algorithm for the minimum size 2-edge-connected spanning subgraph, which
significantly improves upon the running time of previous approximation
algorithms, and an $O(h_{MST}+\sqrt{n}\log^{*}{n})$-round 3-approximation
algorithm for the weighted case, where $h_{MST}$ is the height of the MST of
the graph. Additional applications are algorithms for verifying
2-edge-connectivity and for augmenting the connectivity of any connected
spanning subgraph to 2.
  Finally, we complement our study with proving lower bounds for distributed
approximations of TAP.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03361</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Relevance Transfer Learning</dc:title>
 <dc:creator>Wang, Tianchun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Transfer learning aims to faciliate learning tasks in a label-scarce target
domain by leveraging knowledge from a related source domain with plenty of
labeled data. Often times we may have multiple domains with little or no
labeled data as targets waiting to be solved. Most existing efforts tackle
target domains separately by modeling the `source-target' pairs without
exploring the relatedness between them, which would cause loss of crucial
information, thus failing to achieve optimal capability of knowledge transfer.
In this paper, we propose a novel and effective approach called Multi-Relevance
Transfer Learning (MRTL) for this purpose, which can simultaneously transfer
different knowledge from the source and exploits the shared common latent
factors between target domains. Specifically, we formulate the problem as an
optimization task based on a collective nonnegative matrix tri-factorization
framework. The proposed approach achieves both source-target transfer and
target-target leveraging by sharing multiple decomposed latent subspaces.
Further, an alternative minimization learning algorithm is developed with
convergence guarantee. Empirical study validates the performance and
effectiveness of MRTL compared to the state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03362</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation of optimal encoding ladders for tiled 360{\deg} VR video in
  adaptive streaming systems</dc:title>
 <dc:creator>Ozcinar, Cagri</dc:creator>
 <dc:creator>De Abreu, Ana</dc:creator>
 <dc:creator>Knorr, Sebastian</dc:creator>
 <dc:creator>Smolic, Aljosa</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Given the significant industrial growth of demand for virtual reality (VR),
360{\deg} video streaming is one of the most important VR applications that
require cost-optimal solutions to achieve widespread proliferation of VR
technology. Because of its inherent variability of data-intensive content types
and its tiled-based encoding and streaming, 360{\deg} video requires new
encoding ladders in adaptive streaming systems to achieve cost-optimal and
immersive streaming experiences. In this context, this paper targets both the
provider's and client's perspectives and introduces a new content-aware
encoding ladder estimation method for tiled 360{\deg} VR video in adaptive
streaming systems. The proposed method first categories a given 360{\deg} video
using its features of encoding complexity and estimates the visual distortion
and resource cost of each bitrate level based on the proposed distortion and
resource cost models. An optimal encoding ladder is then formed using the
proposed integer linear programming (ILP) algorithm by considering practical
constraints. Experimental results of the proposed method are compared with the
recommended encoding ladders of professional streaming service providers.
Evaluations show that the proposed encoding ladders deliver better results
compared to the recommended encoding ladders in terms of objective quality for
360{\deg} video, providing optimal encoding ladders using a set of service
provider's constraint parameters.
</dc:description>
 <dc:description>Comment: The 19th IEEE International Symposium on Multimedia (ISM 2017),
  Taichung, Taiwan</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03362</dc:identifier>
 <dc:identifier>The 19th IEEE International Symposium on Multimedia (ISM 2017),
  Taichung, Taiwan</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03363</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Is Decidable about String Constraints with the ReplaceAll Function</dc:title>
 <dc:creator>Chen, Taolue</dc:creator>
 <dc:creator>Chen, Yan</dc:creator>
 <dc:creator>Hague, Matthew</dc:creator>
 <dc:creator>Lin, Anthony W.</dc:creator>
 <dc:creator>Wu, Zhilin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  Recently, it was shown that any theory of strings containing the
string-replace function (even the most restricted version where
pattern/replacement strings are both constant strings) becomes undecidable if
we do not impose some kind of straight-line (aka acyclicity) restriction on the
formulas. Despite this, the straight-line restriction is still practically
sensible since this condition is typically met by string constraints that are
generated by symbolic execution. In this paper, we provide the first systematic
study of straight-line string constraints with the string-replace function and
the regular constraints as the basic operations. We show that a large class of
such constraints (i.e. when only a constant string or a regular expression is
permitted in the pattern) is decidable. We note that the string-replace
function, even under this restriction, is sufficiently powerful for expressing
the concatenation operator and much more (e.g. extensions of regular
expressions with string variables). This gives us the most expressive decidable
logic containing concatenation, replace, and regular constraints under the same
umbrella. Our decision procedure for the straight-line fragment follows an
automata-theoretic approach, and is modular in the sense that the
string-replace terms are removed one by one to generate more and more regular
constraints, which can then be discharged by the state-of-the-art string
constraint solvers. We also show that this fragment is, in a way, a maximal
decidable subclass of the straight-line fragment with string-replace and
regular constraints. To this end, we show undecidability results for the
following two extensions: (1) variables are permitted in the pattern parameter
of the replace function, (2) length constraints are permitted.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03364</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-antenna Interference Management for Coded Caching</dc:title>
 <dc:creator>T&#xf6;lli, Antti</dc:creator>
 <dc:creator>Shariatpanahi, Seyed Pooya</dc:creator>
 <dc:creator>Kaleva, Jarkko</dc:creator>
 <dc:creator>Khalaj, Babak</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A single cell downlink scenario is considered where a multiple-antenna base
station delivers contents to multiple cache-enabled user terminals. Using the
ideas from multi-server coded caching (CC) scheme developed for wired networks,
a joint design of CC and general multicast beamforming is proposed to benefit
from spatial multiplexing gain, improved interference management and the global
CC gain, simultaneously. Utilizing the multiantenna multicasting opportunities
provided by the CC technique, the proposed method is shown to perform well over
the entire SNR region, including the low SNR regime, unlike the existing
schemes based on zero forcing (ZF). Instead of nulling the interference at
users not requiring a specific coded message, general multicast beamforming
strategies are employed, optimally balancing the detrimental impact of both
noise and inter-stream interference from coded messages transmitted in
parallel. The proposed scheme is shown to provide the same degrees-of-freedom
at high SNR as the state-of-art methods and, in general, to perform
significantly better than several base-line schemes including, the joint ZF and
CC, max-min fair multicasting with CC, and basic unicasting with multiuser
beamforming.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03365</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NFV Orchestrator Placement for Geo-Distributed Systems</dc:title>
 <dc:creator>Abu-Lebdeh, Mohammad</dc:creator>
 <dc:creator>Naboulsi, Diala</dc:creator>
 <dc:creator>Glitho, Roch</dc:creator>
 <dc:creator>Tchouati, Constant Wette</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The European Telecommunications Standards Institute (ETSI) developed Network
Functions Virtualization (NFV) Management and Orchestration (MANO) framework.
Within that framework, NFV orchestrator (NFVO) and Virtualized Network Function
(VNF) Manager (VNFM) functional blocks are responsible for managing the
lifecycle of network services and their associated VNFs. However, they face
significant scalability and performance challenges in large-scale and
geo-distributed NFV systems. Their number and location have major implications
for the number of VNFs that can be accommodated and also for the overall system
performance. NFVO and VNFM placement is therefore a key challenge due to its
potential impact on the system scalability and performance. In this paper, we
address the placement of NFVO and VNFM in large-scale and geo-distributed NFV
infrastructure. We provide an integer linear programming formulation of the
problem and propose a two-step placement algorithm to solve it. We also conduct
a set of experiments to evaluate the proposed algorithm.
</dc:description>
 <dc:description>Comment: This paper has been accepted for presentation in 16th IEEE
  International Symposium on Network Computing and Applications (IEEE NCA 2017)</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03368</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One-pass Person Re-identification by Sketch Online Discriminant Analysis</dc:title>
 <dc:creator>Li, Wei-Hong</dc:creator>
 <dc:creator>Zhong, Zhuowei</dc:creator>
 <dc:creator>Zheng, Wei-Shi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Person re-identification (re-id) is to match people across disjoint camera
views in a multi-camera system, and re-id has been an important technology
applied in smart city in recent years. However, the majority of existing person
re-id methods are not designed for processing sequential data in an online way.
This ignores the real-world scenario that person images detected from
multi-cameras system are coming sequentially. While there is a few work on
discussing online re-id, most of them require considerable storage of all
passed data samples that have been ever observed, and this could be unrealistic
for processing data from a large camera network. In this work, we present an
onepass person re-id model that adapts the re-id model based on each newly
observed data and no passed data are directly used for each update. More
specifically, we develop an Sketch online Discriminant Analysis (SoDA) by
embedding sketch processing into Fisher discriminant analysis (FDA). SoDA can
efficiently keep the main data variations of all passed samples in a low rank
matrix when processing sequential data samples, and estimate the approximate
within-class variance (i.e. within-class covariance matrix) from the sketch
data information. We provide theoretical analysis on the effect of the
estimated approximate within-class covariance matrix. In particular, we derive
upper and lower bounds on the Fisher discriminant score (i.e. the quotient
between between-class variation and within-class variation after feature
transformation) in order to investigate how the optimal feature transformation
learned by SoDA sequentially approximates the offline FDA that is learned on
all observed data. Extensive experimental results have shown the effectiveness
of our SoDA and empirically support our theoretical analysis.
</dc:description>
 <dc:description>Comment: Online learning, Person re-identification, Discriminant feature
  extraction</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03373</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SemRe-Rank: Incorporating Semantic Relatedness to Improve Automatic Term
  Extraction Using Personalized PageRank</dc:title>
 <dc:creator>Zhang, Ziqi</dc:creator>
 <dc:creator>Gao, Jie</dc:creator>
 <dc:creator>Ciravegna, Fabio</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Automatic Term Extraction deals with the extraction of terminology from a
domain specific corpus, and has long been an established research area in data
and knowledge acquisition. ATE remains a challenging task as it is known that
no existing methods can consistently outperforms others in all domains. This
work adopts a different strategy towards this problem as we propose to
'enhance' existing ATE methods instead of 'replace' them. We introduce
SemRe-Rank, a generic method based on the concept of incorporating semantic
relatedness - an often overlooked venue - into an existing ATE method to
further improve its performance. SemRe-Rank applies a personalized PageRank
process to a semantic relatedness graph of words to compute their 'semantic
importance' scores, which are then used to revise the scores of term candidates
computed by a base ATE algorithm. Extensively evaluated with 13
state-of-the-art ATE methods on four datasets of diverse nature, it is shown to
have achieved widespread improvement over all methods and across all datasets.
The best performing variants of SemRe-Rank have achieved, on some datasets, an
improvement of 0.15 (on a scale of 0 ~ 1.0) in terms of the precision in the
top ranked K term candidates, and an improvement of 0.28 in terms of overall
F1.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03373</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03381</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking of enriched dialog states for flexible conversational
  information access</dc:title>
 <dc:creator>Dai, Yinpei</dc:creator>
 <dc:creator>Ou, Zhijian</dc:creator>
 <dc:creator>Ren, Dawei</dc:creator>
 <dc:creator>Yu, Pengfei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Dialog state tracking (DST) is a crucial component in a task-oriented dialog
system for conversational information access. A common practice in current
dialog systems is to define the dialog state by a set of slot-value pairs. Such
representation of dialog states and the slot-filling based DST have been widely
employed, but suffer from three drawbacks. (1) The dialog state can contain
only a single value for a slot, and (2) can contain only users' affirmative
preference over the values for a slot. (3) Current task-based dialog systems
mainly focus on the searching task, while the enquiring task is also very
common in practice. The above observations motivate us to enrich current
representation of dialog states and collect a brand new dialog dataset about
movies, based upon which we build a new DST, called enriched DST (EDST), for
flexible accessing movie information. The EDST supports the searching task, the
enquiring task and their mixed task. We show that the new EDST method not only
achieves good results on Iqiyi dataset, but also outperforms other
state-of-the-art DST methods on the traditional dialog datasets, WOZ2.0 and
DSTC2.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03385</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Match Made in Heaven: Practical Compressed Sensing and Network Coding
  for Intelligent Distributed Communication Networks</dc:title>
 <dc:creator>Taghouti, Maroua</dc:creator>
 <dc:creator>Chorppath, Anil Kumar</dc:creator>
 <dc:creator>Waurick, Tobias</dc:creator>
 <dc:creator>Fitzek, Frank H. P.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Based on the impressive features that network coding and compressed sensing
paradigms have separately brought, the idea of bringing them together in
practice will result in major improvements and influence in the upcoming 5G
networks. In this context, this paper aims to evaluate the effectiveness of
these key techniques in a cluster-based wireless sensor network, in the
presence of temporal and spatial correlations. Our goal is to achieve better
compression gains by scaling down the total payload carried by applying
temporal compression as well as reducing the total number of transmissions in
the network using real field network coding. In order to further reduce the
number of transmissions, the cluster-heads perform a low complexity spatial
pre-coding consisting of sending the packets with a certain probability.
Furthermore, we compare our approach with benchmark schemes. As expected, our
numerical results run on NS3 simulator show that on overall our scheme
dramatically drops the number of transmitted packets in the considered cluster
topology with a very high reconstruction SNR.
</dc:description>
 <dc:description>Comment: Submitted to VTC Spring 2018</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03386</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Evaluation of Deep Learning Tools in Docker Containers</dc:title>
 <dc:creator>Xu, Pengfei</dc:creator>
 <dc:creator>Shi, Shaohuai</dc:creator>
 <dc:creator>Chu, Xiaowen</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  With the success of deep learning techniques in a broad range of application
domains, many deep learning software frameworks have been developed and are
being updated frequently to adapt to new hardware features and software
libraries, which bring a big challenge for end users and system administrators.
To address this problem, container techniques are widely used to simplify the
deployment and management of deep learning software. However, it remains
unknown whether container techniques bring any performance penalty to deep
learning applications. The purpose of this work is to systematically evaluate
the impact of docker container on the performance of deep learning
applications. We first benchmark the performance of system components (IO, CPU
and GPU) in a docker container and the host system and compare the results to
see if there's any difference. According to our results, we find that
computational intensive jobs, either running on CPU or GPU, have small overhead
indicating docker containers can be applied to deep learning programs. Then we
evaluate the performance of some popular deep learning tools deployed in a
docker container and the host system. It turns out that the docker container
will not cause noticeable drawbacks while running those deep learning tools. So
encapsulating deep learning tool in a container is a feasible solution.
</dc:description>
 <dc:description>Comment: Conference: BIgCom2017, 9 pages</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03396</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counting hypergraph colorings in the local lemma regime</dc:title>
 <dc:creator>Guo, Heng</dc:creator>
 <dc:creator>Liao, Chao</dc:creator>
 <dc:creator>Lu, Pinyan</dc:creator>
 <dc:creator>Zhang, Chihao</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We give a fully polynomial-time approximation scheme (FPTAS) to count the
number of $q$-colorings for $k$-uniform hypergraphs with maximum degree
$\Delta$ if $k\ge 28$ and $q &gt; 315\Delta^{\frac{14}{k-14}}$. We also obtain a
polynomial-time almost uniform sampler if $q&gt; 798\Delta^{\frac{16}{k-16/3}}$.
These are the first approximate counting and sampling algorithms in the regime
$q\ll\Delta$ (for large $\Delta$ and $k$) without any additional assumptions.
Our method is based on the recent work of Moitra (STOC, 2017). One important
contribution of ours is to remove the dependency of $k$ and $\Delta$ in
Moitra's approach.
</dc:description>
 <dc:description>Comment: v2: improved constants</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03397</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SAIC: Identifying Configuration Files for System Configuration
  Management</dc:title>
 <dc:creator>Huang, Zhen</dc:creator>
 <dc:creator>Lie, David</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.4.3</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:description>  Systems can become misconfigured for a variety of reasons such as operator
errors or buggy patches. When a misconfiguration is discovered, usually the
first order of business is to restore availability, often by undoing the
misconfiguration. To simplify this task, we propose the Statistical Analysis
for Identifying Configuration Files (SAIC), which analyzes how the contents of
a file changes over time to automatically determine which files contain
configuration state. In this way, SAIC reduces the number of files a user must
manually examine during recovery and allows versioning file systems to make
more efficient use of their versioning storage.
  The two key insights that enable SAIC to identify configuration files are
that configuration state must persist across executions of an application and
that configuration state changes at a slower rate than other types of
application state. SAIC applies these insights through a set of filters, which
eliminate non-persistent files from consideration, and a novel similarity
metric, which measures how similar a file's versions are to each other.
Together, these two mechanisms enable SAIC to identify all 72 configuration
files out of 2363 versioned files from 6 common applications in two user
traces, while mistaking only 33 non-configuration files as configuration files,
which allows a versioning file system to eliminate roughly 66% of
non-configuration file versions from its logs, thus reducing the number of file
versions that a user must try to recover from a misconfiguration.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03398</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Fusion and Machine Learning Integration for Transformer Loss of
  Life Estimation</dc:title>
 <dc:creator>Mahoor, Mohsen</dc:creator>
 <dc:creator>Khodaei, Amin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Rapid growth of machine learning methodologies and their applications offer
new opportunity for improved transformer asset management. Accordingly, power
system operators are currently looking for data-driven methods to make
better-informed decisions in terms of network management. In this paper,
machine learning and data fusion techniques are integrated to estimate
transformer loss of life. Using IEEE Std. C57.91-2011, a data synthesis process
is proposed based on hourly transformer loading and ambient temperature values.
This synthesized data is employed to estimate transformer loss of life by using
Adaptive Network-Based Fuzzy Inference System (ANFIS) and Radial Basis Function
(RBF) network, which are further fused together with the objective of improving
the estimation accuracy. Among various data fusion techniques, Ordered Weighted
Averaging (OWA) and sequential Kalman filter are selected to fuse the output
results of the estimated ANFIS and RBF. Simulation results demonstrate the
merit and the effectiveness of the proposed method.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03399</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On First-order Cons-free Term Rewriting and PTIME</dc:title>
 <dc:creator>Kop, Cynthia</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this paper, we prove that (first-order) cons-free term rewriting with a
call-by-value reduction strategy exactly characterises the class of
PTIME-computable functions. We use this to give an alternative proof of the
result by Carvalho and Simonsen which states that cons-free term rewriting with
linearity constraints characterises this class.
</dc:description>
 <dc:description>Comment: workshop proceedings for DICE 2016</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03401</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Yet Another Proof of the Aperiodicity of Robinson Tiles</dc:title>
 <dc:creator>Fernique, Thomas</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Short proof of the aperiodicity of the Robinson tile set.
</dc:description>
 <dc:description>Comment: 2 pages</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03404</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A random matrix analysis and improvement of semi-supervised learning for
  large dimensional data</dc:title>
 <dc:creator>Mai, Xiaoyi</dc:creator>
 <dc:creator>Couillet, Romain</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This article provides an original understanding of the behavior of a class of
graph-oriented semi-supervised learning algorithms in the limit of large and
numerous data. It is demonstrated that the intuition at the root of these
methods collapses in this limit and that, as a result, most of them become
inconsistent. Corrective measures and a new data-driven parametrization scheme
are proposed along with a theoretical analysis of the asymptotic performances
of the resulting approach. A surprisingly close behavior between theoretical
performances on Gaussian mixture models and on real datasets is also
illustrated throughout the article, thereby suggesting the importance of the
proposed analysis for dealing with practical data. As a result, significant
performance gains are observed on practical data classification using the
proposed parametrization.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03406</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning Based Fast Power Integrity Classifier</dc:title>
 <dc:creator>Zhang, HuaChun</dc:creator>
 <dc:creator>Kagan, Lynden</dc:creator>
 <dc:creator>Zheng, Chen</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we proposed a new machine learning based fast power integrity
classifier that quickly flags the EM/IR hotspots. We discussed the features to
extract to describe the power grid, cell power density, routing impact and
controlled collapse chip connection (C4) bumps, etc. The continuous and
discontinuous cases are identified and treated using different machine learning
models. Nearest neighbors, random forest and neural network models are compared
to select the best performance candidates. Experiments are run on open source
benchmark, and result is showing promising prediction accuracy.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, 1 table</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03407</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Higher-order Cons-free Interpreters</dc:title>
 <dc:creator>Kop, Cynthia</dc:creator>
 <dc:creator>Simonsen, Jakob Grue</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Constructor rewriting systems are said to be cons-free if any constructor
term occurring in the rhs of a rule must be a subterm of the lhs of the rule.
Roughly, such systems cannot build new data structures during their evaluation.
In earlier work by several authors, (typed) cons-free systems have been used to
characterise complexity classes such as polynomial or exponential time or space
by varying the type orders, and the recursion forms allowed. This paper
concerns the construction of interpreters for cons-free term rewriting. Due to
their connection with proofs by diagonalisation, interpreters may be of use
when studying separation results between complexity classes in implicit
computational complexity theory. We are interested in interpreters of type
order $k &gt; 1$ that can interpret any term of strictly lower type order; while
this gives us a well-known separation result E$^k$TIME $\subseteq$
E$^{k+1}$TIME, the hope is that more refined interpreters with syntactically
limited constraints can be used to obtain a notion of faux diagonalisation and
be used to attack open problems in complexity theory.
</dc:description>
 <dc:description>Comment: workshop proceedings for HOR 2016</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03410</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Phone Sensors and an Artificial Neural Network to Detect Gait
  Changes During Drinking Episodes in the Natural Environment</dc:title>
 <dc:creator>Suffoletto, Brian</dc:creator>
 <dc:creator>Gharani, Pedram</dc:creator>
 <dc:creator>Chung, Tammy</dc:creator>
 <dc:creator>Karimi, Hassan</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Phone sensors could be useful in assessing changes in gait that occur with
alcohol consumption. This study determined (1) feasibility of collecting
gait-related data during drinking occasions in the natural environment, and (2)
how gait-related features measured by phone sensors relate to estimated blood
alcohol concentration (eBAC). Ten young adult heavy drinkers were prompted to
complete a 5-step gait task every hour from 8pm to 12am over four consecutive
weekends. We collected 3-xis accelerometer, gyroscope, and magnetometer data
from phone sensors, and computed 24 gait-related features using a sliding
window technique. eBAC levels were calculated at each time point based on
Ecological Momentary Assessment (EMA) of alcohol use. We used an artificial
neural network model to analyze associations between sensor features and eBACs
in training (70% of the data) and validation and test (30% of the data)
datasets. We analyzed 128 data points where both eBAC and gait-related sensor
data was captured, either when not drinking (n=60), while eBAC was ascending
(n=55) or eBAC was descending (n=13). 21 data points were captured at times
when the eBAC was greater than the legal limit (0.08 mg/dl). Using a Bayesian
regularized neural network, gait-related phone sensor features showed a high
correlation with eBAC (Pearson's r &gt; 0.9), and &gt;95% of estimated eBAC would
fall between -0.012 and +0.012 of actual eBAC. It is feasible to collect
gait-related data from smartphone sensors during drinking occasions in the
natural environment. Sensor-based features can be used to infer gait changes
associated with elevated blood alcohol content.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03410</dc:identifier>
 <dc:identifier>Gait Posture 60 (2018) 116-12</dc:identifier>
 <dc:identifier>doi:10.1016/j.gaitpost.2017.11.019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03415</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-deterministic Characterisations</dc:title>
 <dc:creator>Kop, Cynthia</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this paper, we extend Jones' result -- that cons-free programming with
$k^{th}$-order data and a call-by-value strategy characterises EXP$^k$TIME --
to a more general setting, including pattern-matching and non-deterministic
choice. We show that the addition of non-determinism is unexpectedly powerful
in the higher-order setting. Nevertheless, we can obtain a non-deterministic
parallel to Jones' hierarchy result by appropriate restricting rule formation.
</dc:description>
 <dc:description>Comment: workshop proceedings for WST 2016</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03417</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Further Analysis of The Role of Heterogeneity in Coevolutionary
  Spatial Games</dc:title>
 <dc:creator>Cardinot, Marcos</dc:creator>
 <dc:creator>Griffith, Josephine</dc:creator>
 <dc:creator>O'Riordan, Colm</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Heterogeneity has been studied as one of the most common explanations of the
puzzle of cooperation in social dilemmas. A large number of papers have been
published discussing the effects of increasing heterogeneity in structured
populations of agents, where it has been established that heterogeneity may
favour cooperative behaviour if it supports agents to locally coordinate their
strategies. In this paper, assuming an existing model of a heterogeneous
weighted network, we aim to further this analysis by exploring the relationship
(if any) between heterogeneity and cooperation. We adopt a weighted network
which is fully populated by agents playing both the Prisoner's Dilemma or the
Optional Prisoner's Dilemma games with coevolutionary rules, i.e., not only the
strategies but also the link weights evolve over time. Surprisingly, results
show that the heterogeneity of link weights (states) on their own does not
always promote cooperation; rather cooperation is actually favoured by the
increase in the number of overlapping states and not by the heterogeneity
itself. We believe that these results can guide further research towards a more
accurate analysis of the role of heterogeneity in social dilemmas.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03417</dc:identifier>
 <dc:identifier>Physica A: Statistical Mechanics and its Applications, Volume 493,
  1 March 2018, Pages 116-124, ISSN 0378-4371</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2017.10.035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03418</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IP Video Conferencing: A Tutorial</dc:title>
 <dc:creator>Sorokin, Roman</dc:creator>
 <dc:creator>Rougier, Jean-Louis</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Video conferencing is a well-established area of communications, which have
been studied for decades. Recently this area has received a new impulse due to
significantly increased bandwidth of Local and Wide area networks, appearance
of low-priced video equipment and development of web based media technologies.
This paper presents the main techniques behind the modern IP-based
videoconferencing services, with a particular focus on codecs, network
protocols, architectures and standardization efforts. Questions of security and
topologies are also tackled. A description of a typical video conference
scenario is provided, demonstrating how the technologies, responsible for
different conference aspects, are working together. Traditional industrial
disposition as well as modern innovative approaches are both addressed. Current
industry trends are highlighted in respect to the topics, described in the
tutorial. Legacy analog/digital technologies, together with the gateways
between the traditional and the IP videoconferencing systems, are not
considered.
</dc:description>
 <dc:description>Comment: Video Conferencing, codec, SVC, MCU, SIP, RTP</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03420</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rigid continuation paths I. Quasilinear average complexity for solving
  polynomial systems</dc:title>
 <dc:creator>Lairez, Pierre</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>68Q25 (Primary), 65H10, 65H20, 65Y20 (Secondary)</dc:subject>
 <dc:description>  How many operations do we need on the average to compute an approximate root
of a random Gaussian polynomial system? Beyond Smale's 17th problem that asked
whether a polynomial bound is possible, we prove a quasi-optimal bound
$\text{(input size)}^{1+o(1)}$. This improves upon the previously known
$\text{(input size)}^{\frac32 +o(1)}$ bound.
  The new algorithm relies on numerical continuation along \emph{rigid
continuation paths}. The central idea is to consider rigid motions of the
equations rather than line segments in the linear space of all polynomial
systems. This leads to a better average condition number and allows for bigger
steps. We show that on the average, we can compute one approximate root of a
random Gaussian polynomial system of~$n$ equations of degree at most $D$ in
$n+1$ homogeneous variables with $O(n^5 D^2)$ continuation steps. This is a
decisive improvement over previous bounds that prove no better than
$\sqrt{2}^{\min(n, D)}$ continuation steps on the average.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03424</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cons-free Programming with Immutable Functions</dc:title>
 <dc:creator>Kop, Cynthia</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We investigate the power of non-determinism in purely functional programming
languages with higher-order types. Specifically, we set out to characterise the
hierarchy NP $\subseteq$ NEXP $\subseteq$ NEXP$^{(2)}$ $\subseteq \cdots
\subseteq$ NEXP$^{(k)}$ $\subseteq \cdots$ solely in terms of higher-typed,
purely functional programs. Although the work is incomplete, we present an
initial approach using cons-free programs with immutable functions.
</dc:description>
 <dc:description>Comment: workshop proceedings for DICE 2017</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03425</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Defining Tourism Domains for Semantic Annotation of Web Content</dc:title>
 <dc:creator>Panasiuk, Oleksandra</dc:creator>
 <dc:creator>K&#xe4;rle, Elias</dc:creator>
 <dc:creator>Simsek, Umutcan</dc:creator>
 <dc:creator>Fensel, Dieter</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Schema.org is an initiative by Bing, Google, Yahoo! and Yandex that publishes
a vocabulary for creating structured data markup on web pages. The use of
schema.org is necessary to increase the visibility of a website, making the
content understandable to different automated agents (e.g. search engines,
chatbots or personal assistant systems). The domain specifications are the
subsets of types from the schema.org vocabulary, each associated with a set of
properties. The challenge is to choose the right classes and properties for an
annotation in a given domain. In this paper we address the problem of finding a
subset of types and properties for complete and correct annotation of different
tourism domains. The approach provides a collection of domain specifications
that were built based on domain analysis and vocabulary selection.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of ENTER 2018</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03430</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Repairing Ontologies via Axiom Weakening</dc:title>
 <dc:creator>Troquard, Nicolas</dc:creator>
 <dc:creator>Confalonieri, Roberto</dc:creator>
 <dc:creator>Galliani, Pietro</dc:creator>
 <dc:creator>Penaloza, Rafael</dc:creator>
 <dc:creator>Porello, Daniele</dc:creator>
 <dc:creator>Kutz, Oliver</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Ontology engineering is a hard and error-prone task, in which small changes
may lead to errors, or even produce an inconsistent ontology. As ontologies
grow in size, the need for automated methods for repairing inconsistencies
while preserving as much of the original knowledge as possible increases. Most
previous approaches to this task are based on removing a few axioms from the
ontology to regain consistency. We propose a new method based on weakening
these axioms to make them less restrictive, employing the use of refinement
operators. We introduce the theoretical framework for weakening DL ontologies,
propose algorithms to repair ontologies based on the framework, and provide an
analysis of the computational complexity. Through an empirical analysis made
over real-life ontologies, we show that our approach preserves significantly
more of the original knowledge of the ontology than removing axioms.
</dc:description>
 <dc:description>Comment: To appear AAAI 2018</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03433</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>h: A Plank for Higher-order Attribute Contraction Schemes</dc:title>
 <dc:creator>Kop, Cynthia</dc:creator>
 <dc:creator>Rose, Kristoffer</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present and formalize h, a core (or &quot;plank&quot;) calculus that can serve as
the foundation for several compiler specification languages, notably CRSX
(Combinatory Reductions Systems with eXtensions), HACS (Higher-order Attribute
Contraction Schemes), and TransScript. We discuss how the h typing and
formation rules introduce the necessary restrictions to ensure that rewriting
is well-defined, even in the presence of h's powerful extensions for
manipulating free variables and environments as first class elements (including
in pattern matching).
</dc:description>
 <dc:description>Comment: workshop proceedings for HOR 2016</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03433</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03436</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eventually Sound Points-To Analysis with Missing Code</dc:title>
 <dc:creator>Bastani, Osbert</dc:creator>
 <dc:creator>Clapp, Lazaro</dc:creator>
 <dc:creator>Anand, Saswat</dc:creator>
 <dc:creator>Sharma, Rahul</dc:creator>
 <dc:creator>Aiken, Alex</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Static analyses make the increasingly tenuous assumption that all source code
is available for analysis; for example, large libraries often call into native
code that cannot be analyzed. We propose a points-to analysis that initially
makes optimistic assumptions about missing code, and then inserts runtime
checks that report counterexamples to these assumptions that occur during
execution. Our approach guarantees eventual soundness, i.e., the static
analysis is sound for the available code after some finite number of
counterexamples. We implement Optix, an eventually sound points-to analysis for
Android apps, where the Android framework is missing. We show that the runtime
checks added by Optix incur low overhead on real programs, and demonstrate how
Optix improves a client information flow analysis for detecting Android
malware.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03438</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Open-World Knowledge Graph Completion</dc:title>
 <dc:creator>Shi, Baoxu</dc:creator>
 <dc:creator>Weninger, Tim</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Knowledge Graphs (KGs) have been applied to many tasks including Web search,
link prediction, recommendation, natural language processing, and entity
linking. However, most KGs are far from complete and are growing at a rapid
pace. To address these problems, Knowledge Graph Completion (KGC) has been
proposed to improve KGs by filling in its missing connections. Unlike existing
methods which hold a closed-world assumption, i.e., where KGs are fixed and new
entities cannot be easily added, in the present work we relax this assumption
and propose a new open-world KGC task. As a first attempt to solve this task we
introduce an open-world KGC model called ConMask. This model learns embeddings
of the entity's name and parts of its text-description to connect unseen
entities to the KG. To mitigate the presence of noisy text descriptions,
ConMask uses a relationship-dependent content masking to extract relevant
snippets and then trains a fully convolutional neural network to fuse the
extracted snippets with entities in the KG. Experiments on large data sets,
both old and new, show that ConMask performs well in the open-world KGC task
and even outperforms existing KGC models on the standard closed-world KGC task.
</dc:description>
 <dc:description>Comment: 8 pages, accepted to AAAI 2018</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03440</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Non-overlapping Convolutional Neural Networks with Multiple
  Kernels</dc:title>
 <dc:creator>Zhong, Kai</dc:creator>
 <dc:creator>Song, Zhao</dc:creator>
 <dc:creator>Dhillon, Inderjit S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we consider parameter recovery for non-overlapping
convolutional neural networks (CNNs) with multiple kernels. We show that when
the inputs follow Gaussian distribution and the sample size is sufficiently
large, the squared loss of such CNNs is $\mathit{~locally~strongly~convex}$ in
a basin of attraction near the global optima for most popular activation
functions, like ReLU, Leaky ReLU, Squared ReLU, Sigmoid and Tanh. The required
sample complexity is proportional to the dimension of the input and polynomial
in the number of kernels and a condition number of the parameters. We also show
that tensor methods are able to initialize the parameters to the local strong
convex region. Hence, for most smooth activations, gradient descent following
tensor initialization is guaranteed to converge to the global optimal with time
that is linear in input dimension, logarithmic in precision and polynomial in
other factors. To the best of our knowledge, this is the first work that
provides recovery guarantees for CNNs with multiple kernels under polynomial
sample and computational complexities.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1706.03175</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03441</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regret Minimization in Behaviorally-Constrained Zero-Sum Games</dc:title>
 <dc:creator>Farina, Gabriele</dc:creator>
 <dc:creator>Kroer, Christian</dc:creator>
 <dc:creator>Sandholm, Tuomas</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  No-regret learning has emerged as a powerful tool for solving extensive-form
games. This was facilitated by the counterfactual-regret minimization (CFR)
framework, which relies on the instantiation of regret minimizers for simplexes
at each information set of the game. We use an instantiation of the CFR
framework to develop algorithms for solving behaviorally-constrained (and, as a
special case, perturbed in the Selten sense) extensive-form games, which allows
us to compute approximate Nash equilibrium refinements. Nash equilibrium
refinements are motivated by a major deficiency in Nash equilibrium: it
provides virtually no guarantees on how it will play in parts of the game tree
that are reached with zero probability. Refinements can mend this issue, but
have not been adopted in practice, mostly due to a lack of scalable algorithms.
We show that, compared to standard algorithms, our method finds solutions that
have substantially better refinement properties, while enjoying a convergence
rate that is comparable to that of state-of-the-art algorithms for Nash
equilibrium computation both in theory and practice.
</dc:description>
 <dc:description>Comment: Published at ICML 17</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03449</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization-Based Collision Avoidance</dc:title>
 <dc:creator>Zhang, Xiaojing</dc:creator>
 <dc:creator>Liniger, Alexander</dc:creator>
 <dc:creator>Borrelli, Francesco</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a novel method for reformulating non-differentiable
collision avoidance constraints into smooth nonlinear constraints using strong
duality of convex optimization. We focus on a controlled object whose goal is
to avoid obstacles while moving in an n-dimensional space. The proposed
reformulation does not introduce approximations, and applies to general
obstacles and controlled objects that can be represented in an n-dimensional
space as the finite union of convex sets. Furthermore, we connect our results
with the notion of signed distance, which is widely used in traditional
trajectory generation algorithms. Our method can be used in generic navigation
and trajectory planning tasks, and the smoothness property allows the use of
general-purpose gradient- and Hessian-based optimization algorithms. Finally,
in case a collision cannot be avoided, our framework allows us to find
&quot;least-intrusive&quot; trajectories, measured in terms of penetration. We
demonstrate the efficacy of our framework on a quadcopter navigation and
automated parking problem, and our numerical experiments suggest that the
proposed methods enable real-time optimization-based trajectory planning
problems in tight environments. Source code of our implementation is provided
at https://github.com/XiaojingGeorgeZhang/OBCA.
</dc:description>
 <dc:description>Comment: 24 pages, 10 figures</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:date>2017-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03466</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Strong Equilibria and Improvement Dynamics in Network Creation Games</dc:title>
 <dc:creator>Janus, Tomasz</dc:creator>
 <dc:creator>de Keijzer, Bart</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study strong equilibria in network creation games. These form a classical
and well-studied class of games where a set of players form a network by buying
edges to their neighbors at a cost of a fixed parameter $\alpha$. The cost of a
player is defined to be the cost of the bought edges plus the sum of distances
to all the players in the resulting graph.
  We identify and characterize various structural properties of strong
equilibria, which lead to a characterization of the set of strong equilibria
for all $\alpha$ in the range $(0,2)$. For $\alpha &gt; 2$, Andelman et al. (2009)
prove that a star graph in which every leaf buys one edge to the center node is
a strong equilibrium, and conjecture that in fact any star is a strong
equilibrium. We resolve this conjecture in the affirmative. Additionally, we
show that when $\alpha$ is large enough ($\geq 2n$) there exist non-star trees
that are strong equilibria. For the strong price of anarchy, we provide precise
expressions when $\alpha$ is in the range $(0,2)$, and we prove a lower bound
of $3/2$ when $\alpha \geq 2$.
  Lastly, we aim to characterize under which conditions (coalitional)
improvement dynamics may converge to a strong equilibrium. To this end, we
study the (coalitional) finite improvement property and (coalitional) weak
acyclicity property. We prove various conditions under which these properties
do and do not hold. Some of these results also hold for the class of pure Nash
equilibria.
</dc:description>
 <dc:description>Comment: 25 pages, 9 figures. A preliminary version of this work appears in
  the proceedings of the 2017 Conference on Web and Internet Economics (WINE)</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03466</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03467</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Worm-level Control through Search-based Reinforcement Learning</dc:title>
 <dc:creator>Lechner, Mathias</dc:creator>
 <dc:creator>Grosu, Radu</dc:creator>
 <dc:creator>Hasani, Ramin M.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Through natural evolution, nervous systems of organisms formed near-optimal
structures to express behavior. Here, we propose an effective way to create
control agents, by \textit{re-purposing} the function of biological neural
circuit models, to govern similar real world applications. We model the
tap-withdrawal (TW) neural circuit of the nematode, \textit{C. elegans}, a
circuit responsible for the worm's reflexive response to external mechanical
touch stimulations, and learn its synaptic and neural parameters as a policy
for controlling the inverted pendulum problem. For reconfiguration of the
purpose of the TW neural circuit, we manipulate a search-based reinforcement
learning. We show that our neural policy performs as good as existing
traditional control theory and machine learning approaches. A video
demonstration of the performance of our method can be accessed at
\url{https://youtu.be/o-Ia5IVyff8}.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03473</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making a long story short: A Multi-Importance Semantic for
  Fast-Forwarding Egocentric Videos</dc:title>
 <dc:creator>Silva, Michel Melo</dc:creator>
 <dc:creator>Ramos, Washington Luis Souza</dc:creator>
 <dc:creator>Chamone, Felipe Cadar</dc:creator>
 <dc:creator>Ferreira, Jo&#xe3;o Pedro Klock</dc:creator>
 <dc:creator>Campos, Mario Fernando Montenegro</dc:creator>
 <dc:creator>Nascimento, Erickson Rangel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The emergence of low-cost, high-quality personal wearable cameras combined
with the increasing storage capacity of video-sharing websites have evoked a
growing interest in first-person videos. Since most videos are composed of
long-running unedited streams which are usually tedious and unpleasant to
watch. State-of-the-art fast-forward methods currently face the challenge of
providing an adequate balance between smoothness in visual flow and the
emphasis on the relevant parts. In this work, we present the Multi-Importance
Semantic Fast-Forward (MISFF), a fully automatic methodology to fast-forward
egocentric videos facing this challenge of balancing. The dilemma of defining
what is the semantic information of a video is addressed by a learning process
based on the preferences of the user. Results show that the proposed method
keeps over 3 times more semantic content than the state-of-the-art semantic
fast-forward. Finally, we discuss the need of a particular video stabilization
techniques for fast-forward egocentric videos.
</dc:description>
 <dc:description>Comment: Submitted to the Journal of Visual Communication and Image
  Representation</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03477</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achievable Rates and Training Overheads for a Measured LOS Massive MIMO
  Channel</dc:title>
 <dc:creator>Harris, Paul</dc:creator>
 <dc:creator>Hasan, Wael Boukley</dc:creator>
 <dc:creator>Liu, Liang</dc:creator>
 <dc:creator>Malkowsky, Steffen</dc:creator>
 <dc:creator>Beach, Mark</dc:creator>
 <dc:creator>Armour, Simon</dc:creator>
 <dc:creator>Tufvesson, Fredrik</dc:creator>
 <dc:creator>Edfors, Ove</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents achievable uplink (UL) sumrate predictions for a measured
line-of-sight (LOS) massive multiple-input, multiple-output (MIMO) (MMIMO)
scenario and illustrates the trade-off between spatial multiplexing performance
and channel de-coherence rate for an increasing number of base station (BS)
antennas. In addition, an orthogonal frequency division multiplexing (OFDM)
case study is formed which considers the 90% coherence time to evaluate the
impact of MMIMO channel training overheads in high-speed LOS scenarios. It is
shown that whilst 25% of the achievable zero-forcing (ZF) sumrate is lost when
the resounding interval is increased by a factor of 4, the OFDM training
overheads for a 100-antenna MMIMO BS using an LTE-like physical layer could be
as low as 2% for a terminal speed of 90m/s.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures. Submitted to IEEE Wireless Communications Letters</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03481</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Log Determinants for Gaussian Process Kernel Learning</dc:title>
 <dc:creator>Dong, Kun</dc:creator>
 <dc:creator>Eriksson, David</dc:creator>
 <dc:creator>Nickisch, Hannes</dc:creator>
 <dc:creator>Bindel, David</dc:creator>
 <dc:creator>Wilson, Andrew Gordon</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  For applications as varied as Bayesian neural networks, determinantal point
processes, elliptical graphical models, and kernel learning for Gaussian
processes (GPs), one must compute a log determinant of an $n \times n$ positive
definite matrix, and its derivatives - leading to prohibitive
$\mathcal{O}(n^3)$ computations. We propose novel $\mathcal{O}(n)$ approaches
to estimating these quantities from only fast matrix vector multiplications
(MVMs). These stochastic approximations are based on Chebyshev, Lanczos, and
surrogate models, and converge quickly even for kernel matrices that have
challenging spectra. We leverage these approximations to develop a scalable
Gaussian process approach to kernel learning. We find that Lanczos is generally
superior to Chebyshev for kernel learning, and that a surrogate approach can be
highly efficient and accurate with popular kernels.
</dc:description>
 <dc:description>Comment: Appears at Advances in Neural Information Processing Systems 30
  (NIPS), 2017</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03481</dc:identifier>
 <dc:identifier>Advances in Neural Information Processing Systems 30 (NIPS), 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03483</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Multi-Modal Word Representation Grounded in Visual Context</dc:title>
 <dc:creator>Zablocki, &#xc9;loi</dc:creator>
 <dc:creator>Piwowarski, Benjamin</dc:creator>
 <dc:creator>Soulier, Laure</dc:creator>
 <dc:creator>Gallinari, Patrick</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Representing the semantics of words is a long-standing problem for the
natural language processing community. Most methods compute word semantics
given their textual context in large corpora. More recently, researchers
attempted to integrate perceptual and visual features. Most of these works
consider the visual appearance of objects to enhance word representations but
they ignore the visual environment and context in which objects appear. We
propose to unify text-based techniques with vision-based techniques by
simultaneously leveraging textual and visual context to learn multimodal word
embeddings. We explore various choices for what can serve as a visual context
and present an end-to-end method to integrate visual context elements in a
multimodal skip-gram model. We provide experiments and extensive analysis of
the obtained results.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03488</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>D3.2: SPEED-5G enhanced functional and system architecture, scenarios
  and performance evaluation metrics</dc:title>
 <dc:creator>Mumtaz, Shahid</dc:creator>
 <dc:creator>Saidul, Kazi</dc:creator>
 <dc:creator>Rodriguez, Huq Jonathan</dc:creator>
 <dc:creator>Marques, Paulo</dc:creator>
 <dc:creator>Radwan, Ayman</dc:creator>
 <dc:creator>BT, Keith Briggs Michael Fitch</dc:creator>
 <dc:creator>Georgakopoulos, Andreas</dc:creator>
 <dc:creator>Belikaidis, Ioannis-Prodromos</dc:creator>
 <dc:creator>Vlacheas, Panagiotis</dc:creator>
 <dc:creator>Kelaidonis, Dimitrios</dc:creator>
 <dc:creator>Kosmatos, Evangelos</dc:creator>
 <dc:creator>Kotrotsos, Serafim</dc:creator>
 <dc:creator>Vassaki, Stavroula</dc:creator>
 <dc:creator>Kritikou, Yiouli</dc:creator>
 <dc:creator>Demestichas, Panagiotis</dc:creator>
 <dc:creator>Tsagkaris, Kostas</dc:creator>
 <dc:creator>Tzifa, Evangelia</dc:creator>
 <dc:creator>Demesticha, Aikaterini</dc:creator>
 <dc:creator>Stavroulaki, Vera</dc:creator>
 <dc:creator>Ropodi, Athina</dc:creator>
 <dc:creator>Argoudelis, Evangelos</dc:creator>
 <dc:creator>Galiatsatos, Marinos</dc:creator>
 <dc:creator>Margaris, Aristotelis</dc:creator>
 <dc:creator>Paitaris, George</dc:creator>
 <dc:creator>Kardaris, Dimitrios</dc:creator>
 <dc:creator>Kaffes, Ioannis</dc:creator>
 <dc:creator>Klaus, Haeyoung Lee</dc:creator>
 <dc:creator>Valerio, Moessner Unis</dc:creator>
 <dc:creator>Bismark, Frascolla</dc:creator>
 <dc:creator>Intel, Okyere</dc:creator>
 <dc:creator>D&#xed;az, Salva</dc:creator>
 <dc:creator>Carrasco, Oscar</dc:creator>
 <dc:creator>Miatton, Federico</dc:creator>
 <dc:creator>Antonio, Sistel</dc:creator>
 <dc:creator>Benoit, Dedomenico</dc:creator>
 <dc:creator>Cea, Miscopein</dc:creator>
 <dc:creator>Oikonomou, Thanasis</dc:creator>
 <dc:creator>Kritharidis, Dimitrios</dc:creator>
 <dc:creator>Weigold, Harald</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This deliverable contains a detailed description of the use cases considered
in SPEED-5G, which will be used as a basis for demonstration in project. These
use cases are Dynamic Channel selection, Load balancing, carrier aggregation.
This deliverable also explains the SPEED-5G architecture design principles,
which is based on software-defined networking and network function
virtualisation. The degree of virtualisation is further illustrated by a number
of novel contributions from involved partners. In the end, KPIs for each use
case are presented, along with the description of how these KPIs can support
5G-PPP KPIs.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03498</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-cell Device-to-Device Communications: A Spectrum Sharing and
  Densification Study</dc:title>
 <dc:creator>Poulakis, Marios I.</dc:creator>
 <dc:creator>Gotsis, Antonis G.</dc:creator>
 <dc:creator>Alexiou, Angeliki</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  One of the most significant 5G technology enablers will be Device-to-Device
(D2D) communications. D2D communications constitute a promising way to improve
spectral, energy and latency performance, exploiting the physical proximity of
communicating devices and increasing resource utilization. Furthermore, network
infrastructure densification has been considered as one of the most substantial
methods to increase system performance, taking advantage of base station
proximity and spatial reuse of system resources. However, could we improve
system performance by leveraging both of these two 5G enabling technologies
together in a multi-cell environment? How does spectrum sharing affect
performance enhancement? This article investigates the implications of
interference, densification and spectrum sharing in D2D performance gain. The
in-band D2D approach, where legacy users coexist with potential D2D pairs, is
considered in a multi-cell system. Overlay and underlay spectrum sharing
approaches are employed in order for the potential D2D pairs to access the
spectrum. Given that two of the most critical problems in the D2D concept are
mode selection and user scheduling, we jointly address them, aiming at
maximizing the total system uplink throughput. Thus, we present a radio
resource management mechanism for intra-cell and cross-cell overlay/underlay
D2D communications enabled in a multi-cell system. System-level simulations are
executed to evaluate the system performance and examine the trends of D2D
communication gain for the different spectrum sharing approaches and various
densification scenarios. Finally, realworld SDR-based experiments are performed
to test and assess D2D communications for overlay and underlay spectrum
sharing.
</dc:description>
 <dc:description>Comment: to appear in IEEE Vehicular Technology Magazine</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03499</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constraints on physical reality arising from a formalization of
  knowledge</dc:title>
 <dc:creator>Wolpert, David</dc:creator>
 <dc:subject>Physics - History and Philosophy of Physics</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  There are (at least) four ways that an agent can acquire information
concerning the state of the universe: via observation, control, prediction, or
via retrodiction, i.e., memory. Each of these four ways of acquiring
information seems to rely on a different kind of physical device (resp., an
observation device, a control device, etc.). However it turns out that certain
mathematical structure is common to those four types of device. Any device that
possesses a certain subset of that structure is known as an &quot;inference device&quot;
(ID).
  Here I review some of the properties of IDs, including their relation with
Turing machines, and (more loosely) quantum mechanics. I also review the bounds
of the joint abilities of any set of IDs to know facts about the physical
universe that contains them. These bounds constrain the possible properties of
any universe that contains agents who can acquire information concerning that
universe.
  I then extend this previous work on IDs, by adding to the definition of IDs
some of the other mathematical structure that is common to the four ways of
acquiring information about the universe but is not captured in the (minimal)
definition of IDs. I discuss these extensions of IDs in the context of
epistemic logic (especially possible worlds formalisms like Kripke structures
and Aumann structures). In particular, I show that these extensions of IDs are
not subject to the problem of logical omniscience that plagues many previously
studied forms of epistemic logic.
</dc:description>
 <dc:description>Comment: 23 pages, 7 figures</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03499</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03503</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Invariant states of linear quantum stochastic systems under Weyl
  perturbations of the Hamiltonian and coupling operators</dc:title>
 <dc:creator>Vladimirov, Igor G.</dc:creator>
 <dc:creator>Petersen, Ian R.</dc:creator>
 <dc:creator>James, Matthew R.</dc:creator>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>81S22, 81S25, 81S30, 81P16, 81S05, 81Q15, 35Q40, 37M25</dc:subject>
 <dc:description>  This paper is concerned with the sensitivity of invariant states in linear
quantum stochastic systems with respect to nonlinear perturbations. The system
variables are governed by a Markovian Hudson-Parthasarathy quantum stochastic
differential equation (QSDE) driven by quantum Wiener processes of external
bosonic fields in the vacuum state. The quadratic system Hamiltonian and the
linear system-field coupling operators, corresponding to a nominal open quantum
harmonic oscillator, are subject to perturbations represented in a Weyl
quantization form. Assuming that the nominal linear QSDE has a Hurwitz dynamics
matrix and using the Wigner-Moyal phase-space framework, we carry out an
infinitesimal perturbation analysis of the quasi-characteristic function for
the invariant quantum state of the nonlinear perturbed system. The resulting
correction of the invariant states in the spatial frequency domain may find
applications to their approximate computation, analysis of relaxation dynamics
and non-Gaussian state generation in nonlinear quantum stochastic systems.
</dc:description>
 <dc:description>Comment: 30 pages, 6 figures</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03512</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Meta-Learning for Adaptive Hierarchical Classifier Design</dc:title>
 <dc:creator>Burg, Gerrit J. J. van den</dc:creator>
 <dc:creator>Hero, Alfred O.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68T05, 62H30, 62C10</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  We propose a new splitting criterion for a meta-learning approach to
multiclass classifier design that adaptively merges the classes into a
tree-structured hierarchy of increasingly difficult binary classification
problems. The classification tree is constructed from empirical estimates of
the Henze-Penrose bounds on the pairwise Bayes misclassification rates that
rank the binary subproblems in terms of difficulty of classification. The
proposed empirical estimates of the Bayes error rate are computed from the
minimal spanning tree (MST) of the samples from each pair of classes. Moreover,
a meta-learning technique is presented for quantifying the one-vs-rest Bayes
error rate for each individual class from a single MST on the entire dataset.
Extensive simulations on benchmark datasets show that the proposed hierarchical
method can often be learned much faster than competing methods, while achieving
competitive accuracy.
</dc:description>
 <dc:description>Comment: Code available at: https://github.com/HeroResearchGroup/SmartSVM</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03515</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hartmann--Tzeng bound and Skew Cyclic Codes of Designed Hamming Distance</dc:title>
 <dc:creator>G&#xf3;mez-Torrecillas, Jos&#xe9;</dc:creator>
 <dc:creator>Navarro, Gabriel</dc:creator>
 <dc:creator>Lobillo, F. J.</dc:creator>
 <dc:creator>Neri, Alessandro</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The use of skew polynomial rings allows to endow linear codes with cyclic
structures which are not cyclic in the classical (commutative) sense. Whenever
these skew cyclic structures are carefully chosen, some control over the
Hamming distance is gained, and it is possible to design efficient decoding
algorithms. In this paper, we give a version of the Hartmann-Tzeng bound that
works for a wide class of skew cyclic codes. We also provide a practical method
for constructing them with designed distance. For skew BCH codes, which are
covered by our constructions, we discuss decoding algorithms. Detailed examples
illustrate both the theory as the constructive methods it supports.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03517</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Submodular Approach for Electricity Distribution Network
  Reconfiguration</dc:title>
 <dc:creator>Khodabakhsh, Ali</dc:creator>
 <dc:creator>Yang, Ger</dc:creator>
 <dc:creator>Basu, Soumya</dc:creator>
 <dc:creator>Nikolova, Evdokia</dc:creator>
 <dc:creator>Caramanis, Michael C.</dc:creator>
 <dc:creator>Lianeas, Thanasis</dc:creator>
 <dc:creator>Pountourakis, Emmanouil</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Distribution network reconfiguration (DNR) is a tool used by operators to
balance line load flows and mitigate losses. As distributed generation and
flexible load adoption increases, the impact of DNR on the security,
efficiency, and reliability of the grid will increase as well. Today,
heuristic-based actions like branch exchange are routinely taken, with no
theoretical guarantee of their optimality. This paper considers loss
minimization via DNR, which changes the on/off status of switches in the
network. The goal is to ensure a radial final configuration (called a spanning
tree in the algorithms literature) that spans all network buses and connects
them to the substation (called the root of the tree) through a single path. We
prove that the associated combinatorial optimization problem is strongly
NP-hard and thus likely cannot be solved efficiently. We formulate the loss
minimization problem as a supermodular function minimization under a single
matroid basis constraint, and use existing algorithms to propose a polynomial
time local search algorithm for the DNR problem at hand and derive performance
bounds. We show that our algorithm is equivalent to the extensively used branch
exchange algorithm, for which, to the best of our knowledge, we pioneer in
proposing a theoretical performance bound. Finally, we use a 33-bus network to
compare our algorithm's performance to several algorithms published in the
literature.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, to appear in 51st Hawaii International
  Conference on System Sciences (HICSS), Hawaii, USA, Jan. 3-6, 2018</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03522</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coordinated AC/DC Microgrid Optimal Scheduling</dc:title>
 <dc:creator>Alanazi, Abdulaziz</dc:creator>
 <dc:creator>Lotfi, Hossein</dc:creator>
 <dc:creator>Khodaei, Amin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper proposes a coordinated optimal scheduling model for hybrid AC/DC
microgrids. The objective of the proposed model is to minimize the total
microgrid operation cost when considering interactions between AC and DC
sub-systems of the microgrid network. Nonlinear power flow equations for AC and
DC networks have been linearized through a proposed model to enable formulating
the problem by mixed integer linear programming (MILP) which expedites the
solution process and ensures better solutions in terms of optimality. The
proposed model is tested on the modified IEEE 33-bus test system. Numerical
simulations exhibit the merits of the proposed coordinated AC/DC optimal
scheduling model and further analyze its sensitivity to various decisive
operational parameters.
</dc:description>
 <dc:description>Comment: 2017 North American Power Symposium (NAPS), Morgantown, WV, Sep 2017</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03525</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving the Redundancy of the Knuth Balancing Scheme for Packet
  Transmission Systems</dc:title>
 <dc:creator>Esenogho, Ebenezer</dc:creator>
 <dc:creator>Mambou, Elie Ngomseu</dc:creator>
 <dc:creator>Ferreira, Hendrik C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A simple scheme was proposed by Knuth to generate balanced codewords from a
random binary in- formation sequence. However, this method presents a
redundancy which is twice that of the full sets of bal- anced codewords, that
is the minimal achievable redun- dancy. The gap between the Knuth's algorithm
gen- erated redundancy and the minimal one is significant and can be reduced.
This paper attempts to achieve this goal through a method based on information
se- quence candidates. The proposed scheme is suitable for various
communication systems as it generates very ef- ?cient and less redundant
balanced codes.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, journal article submitted to telecommunications
  systems journal</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03527</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Depth Estimation Using Mask-Based Lensless Cameras</dc:title>
 <dc:creator>Asif, M. Salman</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, coded masks have been used to demonstrate a thin form-factor
lensless camera, FlatCam, in which a mask is placed immediately on top of a
bare image sensor. In this paper, we present an imaging model and algorithm to
jointly estimate depth and intensity information in the scene from a single or
multiple FlatCams. We use a light field representation to model the mapping of
3D scene onto the sensor in which light rays from different depths yield
different modulation patterns. We present a greedy depth pursuit algorithm to
search the 3D volume and estimate the depth and intensity of each pixel within
the camera field-of-view. We present simulation results to analyze the
performance of our proposed model and algorithm with different FlatCam
settings.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03527</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03532</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Co-Optimization Generation and Distribution Planning in Microgrids</dc:title>
 <dc:creator>Lotfi, Hossein</dc:creator>
 <dc:creator>Khodaei, Amin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper proposes a co-optimization generation and distribution planning
model in microgrids in which simultaneous investment in generation, i.e.,
distributed generation (DG) and distributed energy storage (DES), and
distribution, i.e., upgrading the existing distribution network, is considered.
The objective of the proposed model is to minimize the microgrid total planning
cost which comprises the investment cost of installed generation assets and
lines, the microgrid operation cost, and the cost of unserved energy. The
microgrid planning solution determines the optimal generation size, location,
and mix, as well as required network upgrade. To consider line flow and voltage
limits, a linearized power flow model is proposed and used, allowing further
application of mixed integer linear programming (MILP) in problem modeling. The
proposed model is applied to the IEEE 33-bus standard test system to
demonstrate the acceptable performance and the effectiveness of the proposed
model.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03536</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Picasso, Matisse, or a Fake? Automated Analysis of Drawings at the
  Stroke Level for Attribution and Authentication</dc:title>
 <dc:creator>Elgammal, Ahmed</dc:creator>
 <dc:creator>Kang, Yan</dc:creator>
 <dc:creator>Leeuw, Milko Den</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a computational approach for analysis of strokes in line
drawings by artists. We aim at developing an AI methodology that facilitates
attribution of drawings of unknown authors in a way that is not easy to be
deceived by forged art. The methodology used is based on quantifying the
characteristics of individual strokes in drawings. We propose a novel algorithm
for segmenting individual strokes. We designed and compared different
hand-crafted and learned features for the task of quantifying stroke
characteristics. We also propose and compare different classification methods
at the drawing level. We experimented with a dataset of 300 digitized drawings
with over 80 thousands strokes. The collection mainly consisted of drawings of
Pablo Picasso, Henry Matisse, and Egon Schiele, besides a small number of
representative works of other artists. The experiments shows that the proposed
methodology can classify individual strokes with accuracy 70%-90%, and
aggregate over drawings with accuracy above 80%, while being robust to be
deceived by fakes (with accuracy 100% for detecting fakes in most settings).
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03537</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovery of potential collaboration networks from open knowledge
  sources</dc:title>
 <dc:creator>Piedra, Nelson</dc:creator>
 <dc:creator>Chicaiza, Janneth</dc:creator>
 <dc:creator>Lopez-Vargas, Jorge</dc:creator>
 <dc:creator>Tovar, Edmundo</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Scientific publishing conveys the outputs of an academic or research
activity, in this sense; it also reflects the efforts and issues in which
people engage. To identify potential collaborative networks one of the simplest
approaches is to leverage the co-authorship relations. In this approach,
semantic and hierarchic relationships defined by a Knowledge Organization
System are used in order to improve the system's ability to recommend potential
networks beyond the lexical or syntactic analysis of the topics or concepts
that are of interest to academics.
</dc:description>
 <dc:description>Comment: 2 pages, International Conference on Knowledge Engineering and
  Semantic Web</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03538</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hydra: An Accelerator for Real-Time Edge-Aware Permeability Filtering in
  65nm CMOS</dc:title>
 <dc:creator>Eggimann, Manuel</dc:creator>
 <dc:creator>Gloor, Christelle</dc:creator>
 <dc:creator>Scheidegger, Florian</dc:creator>
 <dc:creator>Cavigelli, Lukas</dc:creator>
 <dc:creator>Schaffner, Michael</dc:creator>
 <dc:creator>Smolic, Aljosa</dc:creator>
 <dc:creator>Benini, Luca</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Many modern video processing pipelines rely on edge-aware (EA) filtering
methods. However, recent high-quality methods are challenging to run in
real-time on embedded hardware due to their computational load. To this end, we
propose an area-efficient and real-time capable hardware implementation of a
high quality EA method. In particular, we focus on the recently proposed
permeability filter (PF) that delivers promising quality and performance in the
domains of HDR tone mapping, disparity and optical flow estimation. We present
an efficient hardware accelerator that implements a tiled variant of the PF
with low on-chip memory requirements and a significantly reduced external
memory bandwidth (6.4x w.r.t. the non-tiled PF). The design has been taped out
in 65 nm CMOS technology, is able to filter 720p grayscale video at 24.8 Hz and
achieves a high compute density of 6.7 GFLOPS/mm2 (12x higher than embedded
GPUs when scaled to the same technology node). The low area and bandwidth
requirements make the accelerator highly suitable for integration into SoCs
where silicon area budget is constrained and external memory is typically a
heavily contended resource.
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03539</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Change-Detection based Framework for Piecewise-stationary Multi-Armed
  Bandit Problem</dc:title>
 <dc:creator>Liu, Fang</dc:creator>
 <dc:creator>Lee, Joohyun</dc:creator>
 <dc:creator>Shroff, Ness</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The multi-armed bandit problem has been extensively studied under the
stationary assumption. However in reality, this assumption often does not hold
because the distributions of rewards themselves may change over time. In this
paper, we propose a change-detection (CD) based framework for multi-armed
bandit problems under the piecewise-stationary setting, and study a class of
change-detection based UCB (Upper Confidence Bound) policies, CD-UCB, that
actively detects change points and restarts the UCB indices. We then develop
CUSUM-UCB and PHT-UCB, that belong to the CD-UCB class and use cumulative sum
(CUSUM) and Page-Hinkley Test (PHT) to detect changes. We show that CUSUM-UCB
obtains the best known regret upper bound under mild assumptions. We also
demonstrate the regret reduction of the CD-UCB policies over arbitrary
Bernoulli rewards and Yahoo! datasets of webpage click-through rates.
</dc:description>
 <dc:description>Comment: accepted by AAAI 2018</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03541</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Language Modeling for Code-Switched Data: Challenges and Approaches</dc:title>
 <dc:creator>Sreeram, Ganji</dc:creator>
 <dc:creator>Sinha, Rohit</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Lately, the problem of code-switching has gained a lot of attention and has
emerged as an active area of research. In bilingual communities, the speakers
commonly embed the words and phrases of a non-native language into the syntax
of a native language in their day-to-day communications. The code-switching is
a global phenomenon among multilingual communities, still very limited acoustic
and linguistic resources are available as yet. For developing effective speech
based applications, the ability of the existing language technologies to deal
with the code-switched data can not be over emphasized. The code-switching is
broadly classified into two modes: inter-sentential and intra-sentential
code-switching. In this work, we have studied the intra-sentential problem in
the context of code-switching language modeling task. The salient contributions
of this paper includes: (i) the creation of Hindi-English code-switching text
corpus by crawling a few blogging sites educating about the usage of the
Internet (ii) the exploration of the parts-of-speech features towards more
effective modeling of Hindi-English code-switched data by the monolingual
language model (LM) trained on native (Hindi) language data, and (iii) the
proposal of a novel textual factor referred to as the code-switch factor
(CS-factor), which allows the LM to predict the code-switching instances. In
the context of recognition of the code-switching data, the substantial
reduction in the PPL is achieved with the use of POS factors and also the
proposed CS-factor provides independent as well as additive gain in the PPL.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03543</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DLPaper2Code: Auto-generation of Code from Deep Learning Research Papers</dc:title>
 <dc:creator>Sethi, Akshay</dc:creator>
 <dc:creator>Sankaran, Anush</dc:creator>
 <dc:creator>Panwar, Naveen</dc:creator>
 <dc:creator>Khare, Shreya</dc:creator>
 <dc:creator>Mani, Senthil</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  With an abundance of research papers in deep learning, reproducibility or
adoption of the existing works becomes a challenge. This is due to the lack of
open source implementations provided by the authors. Further, re-implementing
research papers in a different library is a daunting task. To address these
challenges, we propose a novel extensible approach, DLPaper2Code, to extract
and understand deep learning design flow diagrams and tables available in a
research paper and convert them to an abstract computational graph. The
extracted computational graph is then converted into execution ready source
code in both Keras and Caffe, in real-time. An arXiv-like website is created
where the automatically generated designs is made publicly available for 5,000
research papers. The generated designs could be rated and edited using an
intuitive drag-and-drop UI framework in a crowdsourced manner. To evaluate our
approach, we create a simulated dataset with over 216,000 valid design
visualizations using a manually defined grammar. Experiments on the simulated
dataset show that the proposed framework provide more than $93\%$ accuracy in
flow diagram content extraction.
</dc:description>
 <dc:description>Comment: AAAI2018</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03560</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SHOPPER: A Probabilistic Model of Consumer Choice with Substitutes and
  Complements</dc:title>
 <dc:creator>Ruiz, Francisco J. R.</dc:creator>
 <dc:creator>Athey, Susan</dc:creator>
 <dc:creator>Blei, David M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Economics - Econometrics</dc:subject>
 <dc:description>  We develop SHOPPER, a sequential probabilistic model of market baskets.
SHOPPER uses interpretable components to model the forces that drive how a
customer chooses products; in particular, we designed SHOPPER to capture how
items interact with other items. We develop an efficient posterior inference
algorithm to estimate these forces from large-scale data, and we analyze a
large dataset from a major chain grocery store. We are interested in answering
counterfactual queries about changes in prices. We found that SHOPPER provides
accurate predictions even under price interventions, and that it helps identify
complementary and substitutable pairs of products.
</dc:description>
 <dc:description>Comment: 27 pages, 4 figures, submitted to AOAS</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03564</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting ConvNet Diversity for Flooding Identification</dc:title>
 <dc:creator>Nogueira, Keiller</dc:creator>
 <dc:creator>Fadel, Samuel G.</dc:creator>
 <dc:creator>Dourado, &#xcd;caro C.</dc:creator>
 <dc:creator>Werneck, Rafael de O.</dc:creator>
 <dc:creator>Mu&#xf1;oz, Javier A. V.</dc:creator>
 <dc:creator>Penatti, Ot&#xe1;vio A. B.</dc:creator>
 <dc:creator>Calumby, Rodrigo T.</dc:creator>
 <dc:creator>Li, Lin Tzy</dc:creator>
 <dc:creator>Santos, Jefersson A. dos</dc:creator>
 <dc:creator>Torres, Ricardo da S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Flooding is the world's most costly type of natural disaster in terms of both
economic losses and human causalities. A first and essential procedure towards
flood monitoring is based on identifying the area most vulnerable to flooding,
which gives authorities relevant regions to focus. In this work, we propose
several methods to perform flooding identification in high-resolution remote
sensing images using deep learning. Specifically, some proposed techniques are
based upon unique networks, such as dilated and deconvolutional ones, while
other was conceived to exploit diversity of distinct networks in order to
extract the maximum performance of each classifier. Evaluation of the proposed
algorithms were conducted in a high-resolution remote sensing dataset. Results
show that the proposed algorithms outperformed several state-of-the-art
baselines, providing improvements ranging from 1 to 4% in terms of the Jaccard
Index.
</dc:description>
 <dc:description>Comment: Work winner of the Flood-Detection in Satellite Images, a subtask of
  2017 Multimedia Satellite Task (MediaEval Benchmark)</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03565</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scripted GUI Testing of Android Apps: A Study on Diffusion, Evolution
  and Fragility</dc:title>
 <dc:creator>Coppola, Riccardo</dc:creator>
 <dc:creator>Morisio, Maurizio</dc:creator>
 <dc:creator>Torchiano, Marco</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Background. Evidence suggests that mobile applications are not thoroughly
tested as their desktop counterparts. In particular GUI testing is generally
limited. Like web-based applications, mobile apps suffer from GUI test
fragility, i.e. GUI test classes failing due to minor modifications in the GUI,
without the application functionalities being altered.
  Aims. The objective of our study is to examine the diffusion of GUI testing
on Android, and the amount of changes required to keep test classes up to date,
and in particular the changes due to GUI test fragility. We define metrics to
characterize the modifications and evolution of test classes and test methods,
and proxies to estimate fragility-induced changes.
  Method. To perform our experiments, we selected six widely used open-source
tools for scripted GUI testing of mobile applications previously described in
the literature. We have mined the repositories on GitHub that used those tools,
and computed our set of metrics.
  Results. We found that none of the considered GUI testing frameworks achieved
a major diffusion among the open-source Android projects available on GitHub.
For projects with GUI tests, we found that test suites have to be modified
often, specifically 5\%-10\% of developers' modified LOCs belong to tests, and
that a relevant portion (60\% on average) of such modifications are induced by
fragility.
  Conclusions. Fragility of GUI test classes constitute a relevant concern,
possibly being an obstacle for developers to adopt automated scripted GUI
tests. This first evaluation and measure of fragility of Android scripted GUI
testing can constitute a benchmark for developers, and the basis for the
definition of a taxonomy of fragility causes, and actionable guidelines to
mitigate the issue.
</dc:description>
 <dc:description>Comment: PROMISE'17 Conference, Best Paper Award</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03570</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Colorful Bin Packing Games</dc:title>
 <dc:creator>Bil&#xf2;, Vittorio</dc:creator>
 <dc:creator>Cellinese, Francesco</dc:creator>
 <dc:creator>Melideo, Giovanna</dc:creator>
 <dc:creator>Monaco, Gianpiero</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider colorful bin packing games in which selfish players control a set
of items which are to be packed into a minimum number of unit capacity bins.
Each item has one of $m\geq 2$ colors and cannot be packed next to an item of
the same color. All bins have the same unitary cost which is shared among the
items it contains, so that players are interested in selecting a bin of minimum
shared cost. We adopt two standard cost sharing functions: the egalitarian cost
function which equally shares the cost of a bin among the items it contains,
and the proportional cost function which shares the cost of a bin among the
items it contains proportionally to their sizes. Although, under both cost
functions, colorful bin packing games do not converge in general to a (pure)
Nash equilibrium, we show that Nash equilibria are guaranteed to exist and we
design an algorithm for computing a Nash equilibrium whose running time is
polynomial under the egalitarian cost function and pseudo-polynomial for a
constant number of colors under the proportional one. We also provide a
complete characterization of the efficiency of Nash equilibria under both cost
functions for general games, by showing that the prices of anarchy and
stability are unbounded when $m\geq 3$ while they are equal to 3 for black and
white games, where $m=2$. We finally focus on games with uniform sizes (i.e.,
all items have the same size) for which the two cost functions coincide. We
show again a tight characterization of the efficiency of Nash equilibria and
design an algorithm which returns Nash equilibria with best achievable
performance.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03570</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03573</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Neural Networks for Physics Analysis on low-level whole-detector
  data at the LHC</dc:title>
 <dc:creator>Bhimji, Wahid</dc:creator>
 <dc:creator>Farrell, Steven Andrew</dc:creator>
 <dc:creator>Kurth, Thorsten</dc:creator>
 <dc:creator>Paganini, Michela</dc:creator>
 <dc:creator>Prabhat</dc:creator>
 <dc:creator>Racah, Evan</dc:creator>
 <dc:subject>High Energy Physics - Experiment</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  There has been considerable recent activity applying deep convolutional
neural nets (CNNs) to data from particle physics experiments. Current
approaches on ATLAS/CMS have largely focussed on a subset of the calorimeter,
and for identifying objects or particular particle types. We explore approaches
that use the entire calorimeter, combined with track information, for directly
conducting physics analyses: i.e. classifying events as known-physics
background or new-physics signals.
  We use an existing RPV-Supersymmetry analysis as a case study and explore
CNNs on multi-channel, high-resolution sparse images: applied on GPU and
multi-node CPU architectures (including Knights Landing (KNL) Xeon Phi nodes)
on the Cori supercomputer at NERSC.
</dc:description>
 <dc:description>Comment: Presented at ACAT 2017 Conference, Submitted to J. Phys. Conf. Ser</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03574</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emergence of online communities: Empirical evidence and theory</dc:title>
 <dc:creator>Dover, Yaniv</dc:creator>
 <dc:creator>Kelman, Guy</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Online communities, which have become an integral part of the day-to-day life
of people and organizations, exhibit much diversity in both size and activity
level; some communities grow to a massive scale and thrive, whereas others
remain small, and even wither. In spite of the important role of these
proliferating communities, there is limited empirical evidence that identifies
the dominant factors underlying their dynamics. Using data collected from seven
large online platforms, we observe a universal relationship between online
community size and its activity: First, three distinct activity regimes exist,
one of low-activity and two of high-activity. Further, we find a sharp activity
phase transition at a critical community size that marks the shift between the
first and the second regime. Essentially, it is around this critical size that
sustainable interactive communities emerge. Finally, above a higher
characteristic size, community activity reaches and remains at a constant and
high level to form the third regime. We propose that the sharp activity phase
transition and the regime structure stem from the branching property of online
interactions. Branching results in the emergence of multiplicative growth of
the interactions above certain community sizes.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03576</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance of Source transmit Antenna selection for MIMO cooperative
  communication System Based DF protocol: Symbol Error Rate and Diversity order</dc:title>
 <dc:creator>Bouteggui, Mokhtar</dc:creator>
 <dc:creator>Merazka, Fatiha</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we study the performance of a single relay Multiple Input
Multiple Output (MIMO) cooperative communication system based on Decode and
Forward (DF) relaying protocol for two strategies using transmit antenna
selection at the source. The first strategy uses one antenna between the relay
and the destination, and the second strategy uses Space Time Block Coding
(STBC). All channels follow the Rayleigh fading distribution. We derive the
expression and Upper Bound for Symbol Error Rate (SER) for M-ary Phase Shift
Keying (M-PSK), and the diversity order for both strategies. The analytical
results show that the second strategy performs better than the first one for
the same diversity order and the same Rate R.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03577</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Really is Deep Learning Doing?</dc:title>
 <dc:creator>Xiong, Chuyu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep learning has achieved a great success in many areas, from computer
vision to natural language processing, to game playing, and much more. Yet,
what deep learning is really doing is still an open question. There are a lot
of works in this direction. For example, [5] tried to explain deep learning by
group renormalization, and [6] tried to explain deep learning from the view of
functional approximation. In order to address this very crucial question, here
we see deep learning from perspective of mechanical learning and learning
machine (see [1], [2]). From this particular angle, we can see deep learning
much better and answer with confidence: What deep learning is really doing? why
it works well, how it works, and how much data is necessary for learning. We
also will discuss advantages and disadvantages of deep learning at the end of
this work.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03580</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>First Results from Using Game Refinement Measure and Learning
  Coefficient in Scrabble</dc:title>
 <dc:creator>Suwanviwatana, Kananat</dc:creator>
 <dc:creator>Iida, Hiroyuki</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper explores the entertainment experience and learning experience in
Scrabble. It proposes a new measure from the educational point of view, which
we call learning coefficient, based on the balance between the learner's skill
and the challenge in Scrabble. Scrabble variants, generated using different
size of board and dictionary, are analyzed with two measures of game refinement
and learning coefficient. The results show that 13x13 Scrabble yields the best
entertainment experience and 15x15 (standard) Scrabble with 4% of original
dictionary size yields the most effective environment for language learners.
Moreover, 15x15 Scrabble with 10% of original dictionary size has a good
balance between entertainment and learning experience.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03583</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Nonlinear Model Reduction for Fast Power System Simulation</dc:title>
 <dc:creator>Osipov, Denis</dc:creator>
 <dc:creator>Sun, Kai</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The paper proposes a new adaptive approach to power system model reduction
for fast and accurate time-domain simulation. This new approach is a compromise
between linear model reduction for faster simulation and nonlinear model
reduction for better accuracy. During the simulation period, the approach
adaptively switches among detailed and linearly or nonlinearly reduced models
based on variations of the system state: it employs unreduced models for the
fault-on period, uses weighted column norms of the admittance matrix to decide
which functions to be linearized in power system differential-algebraic
equations for large changes of the state, and adopts a linearly reduced model
for small changes of the state. Two versions of the adaptive model reduction
approach are introduced. The first version uses traditional power system
partitioning where the model reduction is applied to a defined large external
area in a power system and the other area defined as the study area keeps full
detailed models. The second version applies the adaptive model reduction to the
whole system. The paper also conducts comprehensive case studies comparing
simulation results using the proposed adaptively reduced models with the
linearly reduced model on the Northeast Power Coordinating Council 140-bus
48-machine system.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Power Systems</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03585</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometry-constrained Degrees of Freedom Analysis for Imaging Systems:
  Monostatic and Multistatic</dc:title>
 <dc:creator>Mamandipoor, Babak</dc:creator>
 <dc:creator>Arbabian, Amin</dc:creator>
 <dc:creator>Madhow, Upamanyu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we develop a theoretical framework for analyzing the
measurable information content of an unknown scene through an active
electromagnetic imaging array. We consider monostatic and multistatic array
architectures in a one-dimensional setting. Our main results include the
following: (a) we introduce the space-bandwidth product (SBP), and show that,
under the Born approximation, it provides an accurate prediction of the number
of the degrees of freedom (DoF) as constrained by the geometry of the scene and
the imaging system; (b) we show that both monostatic and multistatic
architectures have the same number of DoF; (c) we show that prior DoF analysis
based on the more restrictive Fresnel approximation are obtained by
specializing our results; (d) we investigate matched-filter (back-propagation)
and pseudoinverse image reconstruction schemes, and analyze the achievable
resolution through these methods. Our analytical framework opens up new avenues
to investigate image formation techniques that aim to reconstruct the
reflectivity function of the scene by solving an inverse scattering problem,
and provides insights on achievable resolution. For example, we show that
matched-filter reconstruction leads to a significant resolution loss for
multistatic architectures.
</dc:description>
 <dc:description>Comment: 15 pages, 25 figures, journal paper</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03588</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Proof Rule for Almost-Sure Termination</dc:title>
 <dc:creator>McIver, Annabelle</dc:creator>
 <dc:creator>Morgan, Carroll</dc:creator>
 <dc:creator>Kaminski, Benjamin Lucien</dc:creator>
 <dc:creator>Katoen, Joost-Pieter</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  An important question for a probabilistic program is whether the probability
mass of all its diverging runs is zero, that is that it terminates &quot;almost
surely&quot;. Proving that can be hard, and this paper presents a new method for
doing so; it is expressed in a program logic, and so applies directly to source
code. The programs may contain both probabilistic- and demonic choice, and the
probabilistic choices may depend on the current state.
  As do other researchers, we use variant functions (a.k.a.
&quot;super-martingales&quot;) that are real-valued and probabilistically might decrease
on each loop iteration; but our key innovation is that the amount as well as
the probability of the decrease are parametric.
  We prove the soundness of the new rule, indicate where its applicability goes
beyond existing rules, and explain its connection to classical results on
denumerable (non-demonic) Markov chains.
</dc:description>
 <dc:description>Comment: V1 to appear in PoPL18. This version collects some existing text into
  new example subsection 5.5 and adds a new example 5.6 and makes further
  remarks about uncountable branching. The new example 5.6 relates to work on
  lexicographic termination methods, also to appear in PoPL18 [Agrawal et al,
  2018]</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03588</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03589</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approaches to Stochastic Modeling of Wind Turbines</dc:title>
 <dc:creator>Gevorkyan, M. N.</dc:creator>
 <dc:creator>Demidova, A. V.</dc:creator>
 <dc:creator>Sobolewski, Robert A.</dc:creator>
 <dc:creator>Zaryadov, I. S.</dc:creator>
 <dc:creator>Korolkova, A. V.</dc:creator>
 <dc:creator>Kulyabov, D. S.</dc:creator>
 <dc:creator>Sevastianov, L. A.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Background. This paper study statistical data gathered from wind turbines
located on the territory of the Republic of Poland. The research is aimed to
construct the stochastic model that predicts the change of wind speed with
time. Purpose. The purpose of this work is to find the optimal distribution for
the approximation of available statistical data on wind speed. Methods. We
consider four distributions of a random variable: Log-Normal, Weibull, Gamma
and Beta. In order to evaluate the parameters of distributions we use method of
maximum likelihood. To assess the the results of approximation we use a
quantile-quantile plot. Results. All the considered distributions properly
approximate the available data. The Weibull distribution shows the best results
for the extreme values of the wind speed. Conclusions. The results of the
analysis are consistent with the common practice of using the Weibull
distribution for wind speed modeling. In the future we plan to compare the
results obtained with a much larger data set as well as to build a stochastic
model of the evolution of the wind speed depending on time.
</dc:description>
 <dc:description>Comment: in English; in Russian</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03589</dc:identifier>
 <dc:identifier>doi:10.7148/2017-0622</dc:identifier>
 <dc:language>en</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03590</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast matrix-free evaluation of discontinuous Galerkin finite element
  operators</dc:title>
 <dc:creator>Kronbichler, Martin</dc:creator>
 <dc:creator>Kormann, Katharina</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We present an algorithmic framework for matrix-free evaluation of
discontinuous Galerkin finite element operators based on sum factorization on
quadrilateral and hexahedral meshes. We identify a set of kernels for fast
quadrature on cells and faces targeting a wide class of weak forms originating
from linear and nonlinear partial differential equations. Different algorithms
and data structures for the implementation of operator evaluation are compared
in an in-depth performance analysis. The sum factorization kernels are
optimized by vectorization over several cells and faces and an even-odd
decomposition of the one-dimensional compute kernels. In isolation our
implementation then reaches up to 60\% of arithmetic peak on Intel Haswell and
Broadwell processors and up to 50\% of arithmetic peak on Intel Knights
Landing. The full operator evaluation reaches only about half that throughput
due to memory bandwidth limitations from loading the input and output vectors,
MPI ghost exchange, as well as handling variable coefficients and the geometry.
Our performance analysis shows that the results are often within 10\% of the
available memory bandwidth for the proposed implementation, with the exception
of the Cartesian mesh case where the cost of gather operations and MPI
communication are more substantial.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03591</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient-UCBV: An Almost Optimal Algorithm using Variance Estimates</dc:title>
 <dc:creator>Mukherjee, Subhojyoti</dc:creator>
 <dc:creator>Naveen, K. P.</dc:creator>
 <dc:creator>Sudarsanam, Nandan</dc:creator>
 <dc:creator>Ravindran, Balaraman</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a novel variant of the UCB algorithm (referred to as
Efficient-UCB-Variance (EUCBV)) for minimizing cumulative regret in the
stochastic multi-armed bandit (MAB) setting. EUCBV incorporates the arm
elimination strategy proposed in UCB-Improved \citep{auer2010ucb}, while taking
into account the variance estimates to compute the arms' confidence bounds,
similar to UCBV \citep{audibert2009exploration}. Through a theoretical analysis
we establish that EUCBV incurs a \emph{gap-dependent} regret bound of
{\scriptsize $O\left( \dfrac{K\sigma^2_{\max} \log (T\Delta^2
/K)}{\Delta}\right)$} after $T$ trials, where $\Delta$ is the minimal gap
between optimal and sub-optimal arms; the above bound is an improvement over
that of existing state-of-the-art UCB algorithms (such as UCB1, UCB-Improved,
UCBV, MOSS). Further, EUCBV incurs a \emph{gap-independent} regret bound of
{\scriptsize $O\left(\sqrt{KT}\right)$} which is an improvement over that of
UCB1, UCBV and UCB-Improved, while being comparable with that of MOSS and
OCUCB. Through an extensive numerical study we show that EUCBV significantly
outperforms the popular UCB variants (like MOSS, OCUCB, etc.) as well as
Thompson sampling and Bayes-UCB algorithms.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03599</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Traffic Models of Periodic Event-Triggered Control Systems</dc:title>
 <dc:creator>Fu, Anqi</dc:creator>
 <dc:creator>Mazo, Jr, Manuel</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Periodic event-triggered control (PETC) is a version of event-triggered
control (ETC) that only requires to measure the plant output periodically
instead of continuously. In this work, we present a construction of timing
models for these PETC implementations to capture the dynamics of the traffic
they generate. In the construction, we employ a two-step approach. We first
partition the state space into a finite number of regions. Then in each region,
the event-triggering behavior is analyzed with the help of LMIs. The state
transitions among different regions result from computing the reachable state
set starting from each region within the computed event time intervals.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03602</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Lifted Matrix-Space Model for Semantic Composition</dc:title>
 <dc:creator>Chung, WooJin</dc:creator>
 <dc:creator>Bowman, Samuel R.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent advances in tree structured sentence encoding models have shown that
explicitly modeling syntax can help handle compositionality. More specifically,
recent works by \citetext{Socher2012}, \citetext{Socher2013}, and
\citetext{Chen2013} have shown that using more powerful composition functions
with multiplicative interactions within tree-structured models can yield
significant improvements in model performance. However, existing compositional
approaches which make use of these multiplicative interactions usually have to
learn task-specific matrix-shaped word embeddings or rely on third-order
tensors, which can be very costly. This paper introduces the Lifted
Matrix-Space model which improves on the predecessors on this aspect. The model
learns a global transformation from pre-trained word embeddings into matrices,
which can be composed via matrix multiplication. The upshot is that we can
capture the multiplicative interaction without learning matrix-valued word
representations from scratch. In addition, our composition function effectively
transmits a larger number of activations across layers with comparably few
model parameters. We evaluate our model on the Stanford NLI corpus and the
Multi-Genre NLI corpus and find that the Lifted Matrix-Space model outperforms
the tree-structured long short-term memory networks.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03602</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03605</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stability and Transparency Analysis of a Bilateral Teleoperation in
  Presence of Data Loss</dc:title>
 <dc:creator>Bakhshi, A.</dc:creator>
 <dc:creator>Talebi, H. A.</dc:creator>
 <dc:creator>Suratgar, A. A.</dc:creator>
 <dc:creator>Abdeetedal, M.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a novel approach for stability and transparency analysis
for bilateral teleoperation in the presence of data loss in communication
media. A new model for data loss is proposed based on a set of periodic
continuous pulses and its finite series representation. The passivity of the
overall system is shown using wave variable approach including the newly
defined model for data loss. Simulation results are presented to show the
effectiveness of the proposed approach.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03606</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distribution market as a ramping aggregator for grid flexibility support</dc:title>
 <dc:creator>Majzoobi, Alireza</dc:creator>
 <dc:creator>Mahoor, Mohsen</dc:creator>
 <dc:creator>Khodaei, Amin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The growing proliferation of microgrids and distributed energy resources in
distribution networks has resulted in the development of Distribution Market
Operator (DMO). This new entity will facilitate the management of the
distributed resources and their interactions with upstream network and the
wholesale market. At the same time, DMOs can tap into the flexibility potential
of these distributed resources to address many of the challenges that system
operators are facing. This paper investigates this opportunity and develops a
distribution market scheduling model based on upstream network ramping
flexibility requirements. That is, the distribution network will play the role
of a flexibility resource in the system, with a relatively large size and
potential, to help bulk system operators to address emerging ramping concerns.
Numerical simulations demonstrate the effectiveness of the proposed model on
when tested on a distribution system with several microgrids.
</dc:description>
 <dc:description>Comment: IEEE PES Transmission and Distribution Conference and Exposition
  (T&amp;D), Denver, CO, 16-19 Apr. 2018</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03617</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Yuen's Criticisms on Security of Quantum Key Distribution and Onward</dc:title>
 <dc:creator>Iwakoshi, Takehisa</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Quantum Key Distribution (QKD) has been attracting researchers that it would
provide provable security to distribute secret keys since its birth in 1984.
Since 2005, the trace distance between an ideal quantum state and an actually
distributed state has been employed to evaluate its security level, and the
trace distance was given an interpretation that it would be a maximum failure
probability in distributing perfectly secure keys. However, in 2009, H. P. Yuen
criticized that the trace distance would not have such an interpretation. Since
then, O. Hirota, K. Kato, and T. Iwakoshi have been warning to make people pay
attention to Yuen's criticisms. In 2015, T. Iwakoshi precisely explained why
Yuen has been correct. In 2016, Yuen himself published a paper to explain the
potentially unsolved problems in QKD. This study precisely explains the most
important problems given in Yuen's paper, and gives recent topics around QKD
and other quantum cryptographic protocols.
</dc:description>
 <dc:description>Comment: The part of this unpublished work is now published in SPIE
  Proceedings (Open Access), http://dx.doi.org/10.1117/12.2278625</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03617</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.2.18173.77282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03619</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security of Quantum Key Distribution from Attacker's View</dc:title>
 <dc:creator>Iwakoshi, Takehisa</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In 2005, trace distance between an ideal quantum state to be distributed and
an actual quantum state distributed was introduced as a valid security measure
of Quantum Key Distribution (QKD) by R. Renner et al., then it has been
perceived that the trace can be interpreted as a maximum failure probability of
QKD. While such a perspective has been widely accepted, H. P. Yuen and O.
Hirota have been warning that such an interpretation is not correct since 2009.
The author of this study has been giving questions on the interpretation of the
trace distance based on their criticisms since QIT30 in May 2014, and has been
proposing Yuen's idea to evaluate the security of QKD by the probability for
the attacker to guess the correct key. However, the author could not give the
guessing probability concretely. In this study, the author explains how to
derive the average guessing probability for the attacker, where its result
equals to Yuen's derivation firstly seen in 2010. From this result, one will
see the problems with the maximum failure probability interpretation of the
trace distance clearly. This study also explains the indistinguishability
advantage interpretation is also invalid.
</dc:description>
 <dc:description>Comment: in Japanese and English. The part of this unpublished work is now
  published in SPIE proceedings (Open Access),
  http://dx.doi.org/10.1117/12.2278625</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03619</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.2.12625.74081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03620</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Soft Contract Verification for Higher-Order Stateful Programs</dc:title>
 <dc:creator>Nguyen, Phuc C.</dc:creator>
 <dc:creator>Gilray, Thomas</dc:creator>
 <dc:creator>Tobin-Hochstadt, Sam</dc:creator>
 <dc:creator>Van Horn, David</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Software contracts allow programmers to state rich program properties using
the full expressive power of an object language. However, since they are
enforced at runtime, monitoring contracts imposes significant overhead and
delays error discovery. So contract verification aims to guarantee all or most
of these properties ahead of time, enabling valuable optimizations and yielding
a more general assurance of correctness. Existing methods for static contract
verification satisfy the needs of more restricted target languages, but fail to
address the challenges unique to those conjoining untyped, dynamic programming,
higher-order functions, modularity, and statefulness. Our approach tackles all
these features at once, in the context of the full Racket system---a mature
environment for stateful, higher-order, multi-paradigm programming with or
without types. Evaluating our method using a set of both pure and stateful
benchmarks, we are able to verify 99.94% of checks statically (all but 28 of
49, 861).
  Stateful, higher-order functions pose significant challenges for static
contract verification in particular. In the presence of these features, a
modular analysis must permit code from the current module to escape permanently
to an opaque context (unspecified code from outside the current module) that
may be stateful and therefore store a reference to the escaped closure. Also,
contracts themselves, being predicates wri en in unrestricted Racket, may
exhibit stateful behavior; a sound approach must be robust to contracts which
are arbitrarily expressive and interwoven with the code they monitor. In this
paper, we present and evaluate our solution based on higher-order symbolic
execution, explain the techniques we used to address such thorny issues,
formalize a notion of behavioral approximation, and use it to provide a
mechanized proof of soundness.
</dc:description>
 <dc:description>Comment: ACM SIGPLAN Symposium on Principles of Programming Language (POPL)</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03620</dc:identifier>
 <dc:identifier>Proceedings of the ACM on Programming Languages, Vol. 2, No. POPL,
  Article 51. Publication date: January 2018</dc:identifier>
 <dc:identifier>doi:10.1145/3158139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03634</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alternating minimization for dictionary learning with random
  initialization</dc:title>
 <dc:creator>Chatterji, Niladri S.</dc:creator>
 <dc:creator>Bartlett, Peter L.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present theoretical guarantees for an alternating minimization algorithm
for the dictionary learning/sparse coding problem. The dictionary learning
problem is to factorize vector samples $y^{1},y^{2},\ldots, y^{n}$ into an
appropriate basis (dictionary) $A^*$ and sparse vectors $x^{1*},\ldots,x^{n*}$.
Our algorithm is a simple alternating minimization procedure that switches
between $\ell_1$ minimization and gradient descent in alternate steps.
Dictionary learning and specifically alternating minimization algorithms for
dictionary learning are well studied both theoretically and empirically.
However, in contrast to previous theoretical analyses for this problem, we
replace the condition on the operator norm (that is, the largest magnitude
singular value) of the true underlying dictionary $A^*$ with a condition on the
matrix infinity norm (that is, the largest magnitude term). This not only
allows us to get convergence rates for the error of the estimated dictionary
measured in the matrix infinity norm, but also ensures that a random
initialization will provably converge to the global optimum. Our guarantees are
under a reasonable generative model that allows for dictionaries with growing
operator norms, and can handle an arbitrary level of overcompleteness, while
having sparsity that is information theoretically optimal. We also establish
upper bounds on the sample complexity of our algorithm.
</dc:description>
 <dc:description>Comment: To appear at NIPS 2017</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03636</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ANCHOR: logically-centralized security for Software-Defined Networks</dc:title>
 <dc:creator>Kreutz, Diego</dc:creator>
 <dc:creator>Yu, Jiangshan</dc:creator>
 <dc:creator>Ramos, Fernando M. V.</dc:creator>
 <dc:creator>Esteves-Verissimo, Paulo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  While the logical centralization of functional properties of the network in
Software-Defined Networking (SDN) brought advantages such as a faster pace of
innovation, it also disrupted some of the natural defenses of traditional
architectures against different threats. The literature on SDN has mostly been
concerned with the functional side, despite some specific works concerning
non-functional properties like 'security' or 'dependability'. Though addressing
the latter in an ad-hoc, piecemeal way, may work, it will most likely lead to
efficiency and e effectiveness problems. We claim that the enforcement of
non-functional properties as a pillar of SDN robustness calls for a systemic
approach. We further advocate, for its materialization, the re-iteration of the
successful formula behind SDN - 'logical centralization'. As a general concept,
we propose ANCHOR, a subsystem architecture that promotes the logical
centralization of non-functional properties. To show the effectiveness of the
concept, we focus on 'security' in this paper: we identify the current security
gaps in SDNs and we populate the architecture middleware with the appropriate
security mechanisms, in a global and consistent manner. ANCHOR sets to provide
essential security mechanisms such as strong entropy, secure device
registration, and association, among other crucial services. We claim and
justify in the paper that centralizing such mechanisms is key for their e
ectiveness, by allowing us to: define and enforce global policies for those
properties; ensure higher levels of robustness for critical services; foster
interoperability of the non-functional property enforcement mechanisms; and
finally, better foster the resilience of the architecture itself. We discuss
design and implementation aspects, and we prove and evaluate our algorithms and
mechanisms.
</dc:description>
 <dc:description>Comment: 38 pages, 4 figures, 2 tables, 5 algorithms</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03637</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning and Real-time Classification of Hand-written Digits With
  Spiking Neural Networks</dc:title>
 <dc:creator>Kulkarni, Shruti R.</dc:creator>
 <dc:creator>Alexiades, John M.</dc:creator>
 <dc:creator>Rajendran, Bipin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We describe a novel spiking neural network (SNN) for automated, real-time
handwritten digit classification and its implementation on a GP-GPU platform.
Information processing within the network, from feature extraction to
classification is implemented by mimicking the basic aspects of neuronal spike
initiation and propagation in the brain. The feature extraction layer of the
SNN uses fixed synaptic weight maps to extract the key features of the image
and the classifier layer uses the recently developed NormAD approximate
gradient descent based supervised learning algorithm for spiking neural
networks to adjust the synaptic weights. On the standard MNIST database images
of handwritten digits, our network achieves an accuracy of 99.80% on the
training set and 98.06% on the test set, with nearly 7x fewer parameters
compared to the state-of-the-art spiking networks. We further use this network
in a GPU based user-interface system demonstrating real-time SNN simulation to
infer digits written by different users. On a test set of 500 such images, this
real-time platform achieves an accuracy exceeding 97% while making a prediction
within an SNN emulation time of less than 100ms.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, 1 table, accepted at ICECS 2017</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03638</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Provably Accurate Double-Sparse Coding</dc:title>
 <dc:creator>Nguyen, Thanh V.</dc:creator>
 <dc:creator>Wong, Raymond K. W.</dc:creator>
 <dc:creator>Hegde, Chinmay</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Sparse coding is a crucial subroutine in algorithms for various signal
processing, deep learning, and other machine learning applications. The central
goal is to learn an overcomplete dictionary that can sparsely represent a given
input dataset. However, a key challenge is that storage, transmission, and
processing of the learned dictionary can be untenably high if the data
dimension is high. In this paper, we consider the double-sparsity model
introduced by Rubinstein et al. (2010b) where the dictionary itself is the
product of a fixed, known basis and a data-adaptive sparse component. First, we
introduce a simple algorithm for double-sparse coding that can be amenable to
efficient implementation via neural architectures. Second, we theoretically
analyze its performance and demonstrate asymptotic sample complexity and
running time benefits over existing (provable) approaches for sparse coding. To
our knowledge, our work introduces the first computationally efficient
algorithm for double-sparse coding that enjoys rigorous statistical guarantees.
Finally, we support our analysis via several numerical experiments on simulated
data, confirming that our method can indeed be useful in problem sizes
encountered in practical applications.
</dc:description>
 <dc:description>Comment: 40 pages. An abbreviated conference version appears at AAAI 2018</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03638</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03639</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Small-loss bounds for online learning with partial information</dc:title>
 <dc:creator>Lykouris, Thodoris</dc:creator>
 <dc:creator>Sridharan, Karthik</dc:creator>
 <dc:creator>Tardos, Eva</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the problem of adversarial (non-stochastic) online learning with
partial information feedback, where at each stage, a decision maker picks an
action from a finite set of possible actions. We develop a black-box approach
to solving such problems where the learner observes as feedback only losses of
a subset of the actions that include the selected action. Specifically, when
losses of actions are non-negative, under the graph-based feedback model
introduced by Mannor and Shamir, we offer algorithms that attain the so called
&quot;small-loss&quot; regret bounds with high probability. Prior to our work, there was
no data-dependent guarantee for general feedback graphs even for pseudo-regret
(without dependence on the number of actions, i.e., taking advantage of the
increased information feedback). Addressing this, we provide a high probability
small-loss guarantee. Taking advantage of the black-box nature of our
technique, we show applications to getting high probability small loss
guarantees for semi-bandits (including routing in networks) and contextual
bandits, including possibly infinite comparator class (such as infinite
possible strategies in contextual bandits) as well as learning with slowly
changing (shifting) comparators.
  In the special case of classical bandit and semi-bandit problems, we provide
optimal small-loss, high-probability guarantees of
$\widetilde{O}(\sqrt{dL^{\star}})$ for the actual regret, where $d$ is the
number of arms and $L^{\star}$ is the loss of the best arm or action, answering
open questions of Neu. Previous work for bandits and semi-bandits offered
analogous regret guarantee only for pseudo-regret and only in expectation.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03640</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Deep Learning in Memristive Networks</dc:title>
 <dc:creator>Babu, Anakha V</dc:creator>
 <dc:creator>Rajendran, Bipin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We study the performance of stochastically trained deep neural networks
(DNNs) whose synaptic weights are implemented using emerging memristive devices
that exhibit limited dynamic range, resolution, and variability in their
programming characteristics. We show that a key device parameter to optimize
the learning efficiency of DNNs is the variability in its programming
characteristics. DNNs with such memristive synapses, even with dynamic range as
low as $15$ and only $32$ discrete levels, when trained based on stochastic
updates suffer less than $3\%$ loss in accuracy compared to floating point
software baseline. We also study the performance of stochastic memristive DNNs
when used as inference engines with noise corrupted data and find that if the
device variability can be minimized, the relative degradation in performance
for the Stochastic DNN is better than that of the software baseline. Hence, our
study presents a new optimization corner for memristive devices for building
large noise-immune deep learning systems.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures, accepted at ICECS 2017</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03641</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Comparison of Open-Source Data for Fine-Grain Mapping of
  Land Use</dc:title>
 <dc:creator>Deng, Xueqing</dc:creator>
 <dc:creator>Newsam, Shawn</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This paper performs a quantitative comparison of open-source data available
on the Internet for the fine-grain mapping of land use. Three points of
interest (POI) data sources--Google Places, Bing Maps, and the Yellow
Pages--and one volunteered geographic information data source--Open Street Map
(OSM)--are compared with each other at the parcel level for San Francisco with
respect to a proposed fine-grain land-use taxonomy. The sources are also
compared to coarse-grain authoritative data which we consider to be the ground
truth. Results show limited agreement among the data sources as well as limited
accuracy with respect to the authoritative data even at coarse class
granularity. We conclude that POI and OSM data do not appear to be sufficient
alone for fine-grain land-use mapping.
</dc:description>
 <dc:description>Comment: ACM SIGSPATIAL 2017 Workshop on Urban GIS</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03651</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Long Will My Phone Battery Last?</dc:title>
 <dc:creator>He, Liang</dc:creator>
 <dc:creator>Shin, Kang G.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Mobile devices are only as useful as their battery lasts. Unfortunately, the
operation and life of a mobile device's battery degrade over time and usage.
The state-of-health (SoH) of batteries quantifies their degradation, but mobile
devices are unable to support its accurate estimation -- despite its importance
-- due mainly to their limited hardware and dynamic usage patterns, causing
various problems such as unexpected device shutoffs or even fire/explosion. To
remedy this lack of support, we design, implement and evaluate V-Health, a
low-cost user-level SoH estimation service for mobile devices based only on
their battery voltage, which is commonly available on all commodity mobile
devices. V-Health also enables four novel use-cases that improve mobile users'
experience from different perspectives. The design of V-Health is inspired by
our empirical finding that the relaxing voltages of a device battery
fingerprint its SoH, and is steered by extensive measurements with 15 batteries
used for various commodity mobile devices, such as Nexus 6P, Galaxy S3, iPhone
6 Plus, etc. These measurements consist of 13,377 battery
discharging/charging/resting cycles and have been conducted over 72 months
cumulatively. V-Health has been evaluated via both laboratory experiments and
field tests over 4-6 months, showing &lt;5% error in SoH estimation.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03654</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Poverty Prediction with Public Landsat 7 Satellite Imagery and Machine
  Learning</dc:title>
 <dc:creator>Perez, Anthony</dc:creator>
 <dc:creator>Yeh, Christopher</dc:creator>
 <dc:creator>Azzari, George</dc:creator>
 <dc:creator>Burke, Marshall</dc:creator>
 <dc:creator>Lobell, David</dc:creator>
 <dc:creator>Ermon, Stefano</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Obtaining detailed and reliable data about local economic livelihoods in
developing countries is expensive, and data are consequently scarce. Previous
work has shown that it is possible to measure local-level economic livelihoods
using high-resolution satellite imagery. However, such imagery is relatively
expensive to acquire, often not updated frequently, and is mainly available for
recent years. We train CNN models on free and publicly available multispectral
daytime satellite images of the African continent from the Landsat 7 satellite,
which has collected imagery with global coverage for almost two decades. We
show that despite these images' lower resolution, we can achieve accuracies
that exceed previous benchmarks.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2017 Workshop on Machine Learning for the
  Developing World</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03656</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Traffic Analysis with Deep Learning</dc:title>
 <dc:creator>Oh, Se Eun</dc:creator>
 <dc:creator>Sunkam, Saikrishna</dc:creator>
 <dc:creator>Hopper, Nicholas</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep Neural Networks (DNN) has obtained enormous attention with its
advantageous feature learning and its powerful prediction ability. In this
paper, we broadly study the applicability of deep learning to traffic analysis
and present its effectiveness on the feature extraction for state-of-the-art
machine learning algorithms, website and keyword fingerprinting attacks, and
the prediction on the fingerprintability of websites. To the best of our
knowledge, this is the first extensive work to introduce various applications
using DNN in traffic analysis. With great help of DNN, the quality of cutting
edge website fingerprinting attacks is upgraded while the feature dimension
becomes much lower. As the classifiers, DNN successfully detects which website
the user visited among 100 websites with 91% TPR and 1% FPR against 100,000
background websites, and as the fingerprintability predictors, it almost
perfectly determines the fingerprintability of 4,500 website traffic instances
with 99% of accuracy.
</dc:description>
 <dc:description>Comment: Under submission</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03656</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03660</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TARCO: Two-Stage Auction for D2D Relay Aided Computation Resource
  Allocation in Hetnet</dc:title>
 <dc:creator>Chen, Long</dc:creator>
 <dc:creator>Wu, Jigang</dc:creator>
 <dc:creator>Zhang, Xinxiang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In heterogeneous cellular network, task scheduling for computation offloading
is one of the biggest challenges. Most works focus on alleviating heavy burden
of macro base stations by moving the computation tasks on macro-cell user
equipment (MUE) to remote cloud or small-cell base stations. But the
selfishness of network users is seldom considered. Motivated by the cloud edge
computing, this paper provides incentive for task transfer from macro cell
users to small cell base stations. The proposed incentive scheme utilizes small
cell user equipment to provide relay service. The problem of computation
offloading is modelled as a two-stage auction, in which the remote MUEs with
common social character can form a group and then buy the computation resource
of small-cell base stations with the relay of small cell user equipment. A
two-stage auction scheme named TARCO is contributed to maximize utilities for
both sellers and buyers in the network. The truthful, individual rationality
and budget balance of the TARCO are also proved in this paper. In addition, two
algorithms are proposed to further refine TARCO on the social welfare of the
network. Extensive simulation results demonstrate that, TARCO is better than
random algorithm by about 104.90% in terms of average utility of MUEs, while
the performance of TARCO is further improved up to 28.75% and 17.06% by the
proposed two algorithms, respectively.
</dc:description>
 <dc:description>Comment: 22 pages, 9 figures, Working paper, SUBMITTED to IEEE TRANSACTIONS ON
  SERVICES COMPUTING</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03660</dc:identifier>
 <dc:identifier>IEEE Transactions on Services Computing, 2018</dc:identifier>
 <dc:identifier>doi:10.1109/TSC.2018.2792024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03665</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning of Geometry with Edge-aware Depth-Normal
  Consistency</dc:title>
 <dc:creator>Yang, Zhenheng</dc:creator>
 <dc:creator>Wang, Peng</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:creator>Zhao, Liang</dc:creator>
 <dc:creator>Nevatia, Ramakant</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning to reconstruct depths in a single image by watching unlabeled videos
via deep convolutional network (DCN) is attracting significant attention in
recent years. In this paper, we introduce a surface normal representation for
unsupervised depth estimation framework. Our estimated depths are constrained
to be compatible with predicted normals, yielding more robust geometry results.
Specifically, we formulate an edge-aware depth-normal consistency term, and
solve it by constructing a depth-to-normal layer and a normal-to-depth layer
inside of the DCN. The depth-to-normal layer takes estimated depths as input,
and computes normal directions using cross production based on neighboring
pixels. Then given the estimated normals, the normal-to-depth layer outputs a
regularized depth map through local planar smoothness. Both layers are computed
with awareness of edges inside the image to help address the issue of
depth/normal discontinuity and preserve sharp edges. Finally, to train the
network, we apply the photometric error and gradient smoothness for both depth
and normal predictions. We conducted experiments on both outdoor (KITTI) and
indoor (NYUv2) datasets, and show that our algorithm vastly outperforms state
of the art, which demonstrates the benefits from our approach.
</dc:description>
 <dc:description>Comment: Accepted at AAAI 2018</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03674</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Breast density classification with deep convolutional neural networks</dc:title>
 <dc:creator>Wu, Nan</dc:creator>
 <dc:creator>Geras, Krzysztof J.</dc:creator>
 <dc:creator>Shen, Yiqiu</dc:creator>
 <dc:creator>Su, Jingyi</dc:creator>
 <dc:creator>Kim, S. Gene</dc:creator>
 <dc:creator>Kim, Eric</dc:creator>
 <dc:creator>Wolfson, Stacey</dc:creator>
 <dc:creator>Moy, Linda</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Breast density classification is an essential part of breast cancer
screening. Although a lot of prior work considered this problem as a task for
learning algorithms, to our knowledge, all of them used small and not
clinically realistic data both for training and evaluation of their models. In
this work, we explore the limits of this task with a data set coming from over
200,000 breast cancer screening exams. We use this data to train and evaluate a
strong convolutional neural network classifier. In a reader study, we find that
our model can perform this task comparably to a human expert.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03676</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communicative Capital for Prosthetic Agents</dc:title>
 <dc:creator>Pilarski, Patrick M.</dc:creator>
 <dc:creator>Sutton, Richard S.</dc:creator>
 <dc:creator>Mathewson, Kory W.</dc:creator>
 <dc:creator>Sherstan, Craig</dc:creator>
 <dc:creator>Parker, Adam S. R.</dc:creator>
 <dc:creator>Edwards, Ann L.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This work presents an overarching perspective on the role that machine
intelligence can play in enhancing human abilities, especially those that have
been diminished due to injury or illness. As a primary contribution, we develop
the hypothesis that assistive devices, and specifically artificial arms and
hands, can and should be viewed as agents in order for us to most effectively
improve their collaboration with their human users. We believe that increased
agency will enable more powerful interactions between human users and next
generation prosthetic devices, especially when the sensorimotor space of the
prosthetic technology greatly exceeds the conventional control and
communication channels available to a prosthetic user. To more concretely
examine an agency-based view on prosthetic devices, we propose a new schema for
interpreting the capacity of a human-machine collaboration as a function of
both the human's and machine's degrees of agency. We then introduce the idea of
communicative capital as a way of thinking about the communication resources
developed by a human and a machine during their ongoing interaction. Using this
schema of agency and capacity, we examine the benefits and disadvantages of
increasing the agency of a prosthetic limb. To do so, we present an analysis of
examples from the literature where building communicative capital has enabled a
progression of fruitful, task-directed interactions between prostheses and
their human users. We then describe further work that is needed to concretely
evaluate the hypothesis that prostheses are best thought of as agents. The
agent-based viewpoint developed in this article significantly extends current
thinking on how best to support the natural, functional use of increasingly
complex prosthetic enhancements, and opens the door for more powerful
interactions between humans and their assistive technologies.
</dc:description>
 <dc:description>Comment: 33 pages, 10 figures; unpublished technical report undergoing peer
  review</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03677</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Egocentric Hand Detection Via Dynamic Region Growing</dc:title>
 <dc:creator>Huang, Shao</dc:creator>
 <dc:creator>Wang, Weiqiang</dc:creator>
 <dc:creator>He, Shengfeng</dc:creator>
 <dc:creator>Lau, Rynson W. H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Egocentric videos, which mainly record the activities carried out by the
users of the wearable cameras, have drawn much research attentions in recent
years. Due to its lengthy content, a large number of ego-related applications
have been developed to abstract the captured videos. As the users are
accustomed to interacting with the target objects using their own hands while
their hands usually appear within their visual fields during the interaction,
an egocentric hand detection step is involved in tasks like gesture
recognition, action recognition and social interaction understanding. In this
work, we propose a dynamic region growing approach for hand region detection in
egocentric videos, by jointly considering hand-related motion and egocentric
cues. We first determine seed regions that most likely belong to the hand, by
analyzing the motion patterns across successive frames. The hand regions can
then be located by extending from the seed regions, according to the scores
computed for the adjacent superpixels. These scores are derived from four
egocentric cues: contrast, location, position consistency and appearance
continuity. We discuss how to apply the proposed method in real-life scenarios,
where multiple hands irregularly appear and disappear from the videos.
Experimental results on public datasets show that the proposed method achieves
superior performance compared with the state-of-the-art methods, especially in
complicated scenarios.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03678</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Supervised Intrinsic Image Decomposition</dc:title>
 <dc:creator>Janner, Michael</dc:creator>
 <dc:creator>Wu, Jiajun</dc:creator>
 <dc:creator>Kulkarni, Tejas D.</dc:creator>
 <dc:creator>Yildirim, Ilker</dc:creator>
 <dc:creator>Tenenbaum, Joshua B.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Intrinsic decomposition from a single image is a highly challenging task, due
to its inherent ambiguity and the scarcity of training data. In contrast to
traditional fully supervised learning approaches, in this paper we propose
learning intrinsic image decomposition by explaining the input image. Our
model, the Rendered Intrinsics Network (RIN), joins together an image
decomposition pipeline, which predicts reflectance, shape, and lighting
conditions given a single image, with a recombination function, a learned
shading model used to recompose the original input based off of intrinsic image
predictions. Our network can then use unsupervised reconstruction error as an
additional signal to improve its intermediate representations. This allows
large-scale unlabeled data to be useful during training, and also enables
transferring learned knowledge to images of unseen object categories, lighting
conditions, and shapes. Extensive experiments demonstrate that our method
performs well on both intrinsic image decomposition and knowledge transfer.
</dc:description>
 <dc:description>Comment: NIPS 2017, project page: http://rin.csail.mit.edu/</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03684</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Covert Communications with A Full-Duplex Receiver over Wireless Fading
  Channels</dc:title>
 <dc:creator>Hu, Jinsong</dc:creator>
 <dc:creator>Shahzad, Khurram</dc:creator>
 <dc:creator>Yan, Shihao</dc:creator>
 <dc:creator>Zhou, Xiangyun</dc:creator>
 <dc:creator>Shu, Feng</dc:creator>
 <dc:creator>Li, Jun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we propose a covert communication scheme where the transmitter
attempts to hide its transmission to a full-duplex receiver, from a warden that
is to detect this covert transmission using a radiometer. Specifically, we
first derive the detection error rate at the warden, based on which the optimal
detection threshold for its radiometer is analytically determined and its
expected detection error rate over wireless fading channels is achieved in a
closed-form expression. Our analysis indicates that the artificial noise
deliberately produced by the receiver with a random transmit power, although
causes self-interference, offers the capability of achieving a positive
effective covert rate for any transmit power (can be infinity) subject to any
given covertness requirement on the expected detection error rate. This work is
the first study on the use of the full-duplex receiver with controlled
artificial noise for achieving covert communications and invites further
investigation in this regard.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03688</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Document Context Neural Machine Translation with Memory Networks</dc:title>
 <dc:creator>Maruf, Sameen</dc:creator>
 <dc:creator>Haffari, Gholamreza</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a document-level neural machine translation model which takes both
the source and target document contexts into account using memory networks. We
model the problem as a structured prediction problem with interdependencies
among the observed and hidden variables, i.e., the source sentences and their
unobserved target translations in the document. The resulting structured
prediction problem is tackled with a neural translation model equipped with two
memory components, one each for the source and target, to capture the
documental interdependencies. We train the model end-to-end and propose an
iterative decoding algorithm based on the block-coordinate descent.
Experimental results and analysis on translating French, German, and Estonian
documents to English show that our model is effective in exploiting both source
and target document contexts to generate improved translations.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03689</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning of Speech Recognition System Based on Policy
  Gradient and Hypothesis Selection</dc:title>
 <dc:creator>Kato, Taku</dc:creator>
 <dc:creator>Shinozaki, Takahiro</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Speech recognition systems have achieved high recognition performance for
several tasks. However, the performance of such systems is dependent on the
tremendously costly development work of preparing vast amounts of task-matched
transcribed speech data for supervised training. The key problem here is the
cost of transcribing speech data. The cost is repeatedly required to support
new languages and new tasks. Assuming broad network services for transcribing
speech data for many users, a system would become more self-sufficient and more
useful if it possessed the ability to learn from very light feedback from the
users without annoying them. In this paper, we propose a general reinforcement
learning framework for speech recognition systems based on the policy gradient
method. As a particular instance of the framework, we also propose a hypothesis
selection-based reinforcement learning method. The proposed framework provides
a new view for several existing training and adaptation methods. The
experimental results show that the proposed method improves the recognition
performance compared to unsupervised adaptation.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03694</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fully Convolutional Tri-branch Network (FCTN) for Domain Adaptation</dc:title>
 <dc:creator>Zhang, Junting</dc:creator>
 <dc:creator>Liang, Chen</dc:creator>
 <dc:creator>Kuo, C. -C. Jay</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A domain adaptation method for urban scene segmentation is proposed in this
work. We develop a fully convolutional tri-branch network, where two branches
assign pseudo labels to images in the unlabeled target domain while the third
branch is trained with supervision based on images in the pseudo-labeled target
domain. The re-labeling and re-training processes alternate. With this design,
the tri-branch network learns target-specific discriminative representations
progressively and, as a result, the cross-domain capability of the segmenter
improves. We evaluate the proposed network on large-scale domain adaptation
experiments using both synthetic (GTA) and real (Cityscapes) images. It is
shown that our solution achieves the state-of-the-art performance and it
outperforms previous methods by a significant margin.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03697</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating User and Agent Models: A Deep Task-Oriented Dialogue System</dc:title>
 <dc:creator>Wang, Weiyan</dc:creator>
 <dc:creator>WU, Yuxiang</dc:creator>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Lu, Zhongqi</dc:creator>
 <dc:creator>Mo, Kaixiang</dc:creator>
 <dc:creator>Yang, Qiang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Task-oriented dialogue systems can efficiently serve a large number of
customers and relieve people from tedious works. However, existing
task-oriented dialogue systems depend on handcrafted actions and states or
extra semantic labels, which sometimes degrades user experience despite the
intensive human intervention. Moreover, current user simulators have limited
expressive ability so that deep reinforcement Seq2Seq models have to rely on
selfplay and only work in some special cases. To address those problems, we
propose a uSer and Agent Model IntegrAtion (SAMIA) framework inspired by an
observation that the roles of the user and agent models are asymmetric.
Firstly, this SAMIA framework model the user model as a Seq2Seq learning
problem instead of ranking or designing rules. Then the built user model is
used as a leverage to train the agent model by deep reinforcement learning. In
the test phase, the output of the agent model is filtered by the user model to
enhance the stability and robustness. Experiments on a real-world coffee
ordering dataset verify the effectiveness of the proposed SAMIA framework.
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures, it's a revised version of our previously
  attempted submission to IJCAI 2017</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03705</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Deep Learning: Learning Deep Neural Networks on the Fly</dc:title>
 <dc:creator>Sahoo, Doyen</dc:creator>
 <dc:creator>Pham, Quang</dc:creator>
 <dc:creator>Lu, Jing</dc:creator>
 <dc:creator>Hoi, Steven C. H.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep Neural Networks (DNNs) are typically trained by backpropagation in a
batch learning setting, which requires the entire training data to be made
available prior to the learning task. This is not scalable for many real-world
scenarios where new data arrives sequentially in a stream form. We aim to
address an open challenge of &quot;Online Deep Learning&quot; (ODL) for learning DNNs on
the fly in an online setting. Unlike traditional online learning that often
optimizes some convex objective function with respect to a shallow model (e.g.,
a linear/kernel-based hypothesis), ODL is significantly more challenging since
the optimization of the DNN objective function is non-convex, and regular
backpropagation does not work well in practice, especially for online learning
settings. In this paper, we present a new online deep learning framework that
attempts to tackle the challenges by learning DNN models of adaptive depth from
a sequence of training data in an online learning setting. In particular, we
propose a novel Hedge Backpropagation (HBP) method for online updating the
parameters of DNN effectively, and validate the efficacy of our method on
large-scale data sets, including both stationary and concept drifting
scenarios.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03707</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning under $p$-Tampering Attacks</dc:title>
 <dc:creator>Mahloujifar, Saeed</dc:creator>
 <dc:creator>Diochnos, Dimitrios I.</dc:creator>
 <dc:creator>Mahmoody, Mohammad</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Mahloujifar and Mahmoody (TCC'17) studied attacks against learning algorithms
using a special case of Valiant's malicious noise, called $p$-tampering, in
which the adversary could change training examples with independent probability
$p$ but only using correct labels. They showed the power of such attacks by
increasing the error probability in the so called `targeted' poisoning model in
which the adversary's goal is to increase the loss of the generated hypothesis
over a particular test example. At the heart of their attack was an efficient
algorithm to bias the average output of any bounded real-valued function
through $p$-tampering.
  In this work, we present new attacks for biasing the average output of
bounded real-valued functions, improving upon the biasing attacks of MM16. Our
improved biasing attacks, directly imply improved $p$-tampering attacks against
learners in the targeted poisoning model. As a bonus, our attacks come with
considerably simpler analysis compared to previous attacks.
  We also study the possibility of PAC learning under $p$-tampering attacks in
the \emph{non-targeted} (aka indiscriminate) setting where the adversary's goal
is to increase the risk of the generated hypothesis (for a random test
example). We show that PAC learning is \emph{possible} under $p$-tampering
poisoning attacks essentially whenever it is possible in the realizable setting
without the attacks. We further show that PAC learning under `no-mistake'
adversarial noise is \emph{not} possible, if the adversary could choose the
(still limited to only $p$ fraction of) tampered examples that she substitutes
with adversarially chosen ones. Our formal model for such `bounded-budget'
tampering attackers is inspired by the notions of (strong) adaptive corruption
in secure multi-party computation.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03707</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03709</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Bounds on Optimal Caching with Variable Object Sizes</dc:title>
 <dc:creator>Berger, Daniel S.</dc:creator>
 <dc:creator>Beckmann, Nathan</dc:creator>
 <dc:creator>Harchol-Balter, Mor</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Many recent caching systems aim to improve hit ratios, but there is no good
sense among practitioners of how much further hit ratios can be improved. In
other words, should the systems community continue working on this problem?
Currently, there is no principled answer to this question. Most prior work
assumes that objects have the same size, but in practice object sizes often
vary by several orders of magnitude. The few known results for variable object
sizes provide very weak guarantees and are impractical to compute on traces of
realistic length. We propose a new method to compute the offline optimal hit
ratio under variable object sizes. Our key insight is to represent caching as a
min-cost flow problem, hence we call our method the flow-based offline optimal
(FOO). We show that, under simple independence assumptions and Zipf
popularities, FOO's bounds become tight as the number of objects goes to
infinity. From FOO we develop fast, practical methods to compute nearly tight
bounds for the optimal hit ratio, which we call practical flow-based offline
optimal (P-FOO). P-FOO enables the first analysis of optimal caching on
realistic traces with hundreds of millions of requests. We evaluate P-FOO on
several production traces, where results show that recent caching systems are
still far from optimal.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03711</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synchronization of Kuramoto Oscillators via Cutset Projections</dc:title>
 <dc:creator>Jafarpour, Saber</dc:creator>
 <dc:creator>Bullo, Francesco</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Synchronization in coupled oscillators networks is a remarkable phenomenon of
relevance in numerous fields. For Kuramoto oscillators the loss of
synchronization is determined by a trade-off between coupling strength and
oscillator heterogeneity. Despite extensive prior work, the existing sufficient
conditions for synchronization are either very conservative or heuristic and
approximate. Using an oblique projection operator, called the cutset
projection, we propose a novel family of sufficient synchronization conditions;
these conditions rigorously identify the correct functional form of the
trade-off between coupling strength and oscillator heterogeneity. To overcome
the need to solve a nonconvex optimization problem, we then provide two
explicit bounding methods, thereby obtaining (i) the best-known sufficient
condition based on the 2-norm, and (ii) the first-known generally-applicable
sufficient condition based on the $\infty$-norm. We conclude with a comparative
study of the novel conditions for specific topologies and IEEE test cases; for
most IEEE test cases our new sufficient conditions are one to two orders of
magnitude more accurate than previous rigorous tests.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03712</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantized Memory-Augmented Neural Networks</dc:title>
 <dc:creator>Park, Seongsik</dc:creator>
 <dc:creator>Kim, Seijoon</dc:creator>
 <dc:creator>Lee, Seil</dc:creator>
 <dc:creator>Bae, Ho</dc:creator>
 <dc:creator>Yoon, Sungroh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Memory-augmented neural networks (MANNs) refer to a class of neural network
models equipped with external memory (such as neural Turing machines and memory
networks). These neural networks outperform conventional recurrent neural
networks (RNNs) in terms of learning long-term dependency, allowing them to
solve intriguing AI tasks that would otherwise be hard to address. This paper
concerns the problem of quantizing MANNs. Quantization is known to be effective
when we deploy deep models on embedded systems with limited resources.
Furthermore, quantization can substantially reduce the energy consumption of
the inference procedure. These benefits justify recent developments of
quantized multi layer perceptrons, convolutional networks, and RNNs. However,
no prior work has reported the successful quantization of MANNs. The in-depth
analysis presented here reveals various challenges that do not appear in the
quantization of the other networks. Without addressing them properly, quantized
MANNs would normally suffer from excessive quantization error which leads to
degraded performance. In this paper, we identify memory addressing
(specifically, content-based addressing) as the main reason for the performance
degradation and propose a robust quantization method for MANNs to address the
challenge. In our experiments, we achieved a computation-energy gain of 22x
with 8-bit fixed-point and binary quantization compared to the floating-point
implementation. Measured on the bAbI dataset, the resulting model, named the
quantized MANN (Q-MANN), improved the error rate by 46% and 30% with 8-bit
fixed-point and binary quantization, respectively, compared to the MANN
quantized using conventional techniques.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03720</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scheduling with regular performance measures and optional job rejection
  on a single machine</dc:title>
 <dc:creator>Mor, Baruch</dc:creator>
 <dc:creator>Shapira, Dana</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  We address single machine problems with optional job rejection, studied
lately in Zhang et al. (2010) and Cao et al. (2006). In these papers, the
authors focus on minimizing regular performance measures, i.e., functions that
are non decreasing in the jobs completion time, subject to the constraint that
the total rejection cost cannot exceed a predefined upper bound. The authors
prove that the considered problems are ordinary NP hard and provide pseudo
polynomial time Dynamic Programming (DP) solutions. In this paper, we focus on
three of these problems: makespan with release dates; total completion times;
and total weighted completion, and present enhanced DPs for these problems. The
resulting computational complexity achieved is O(nU), where n is the number of
jobs and U is the upper bound on the total rejection cost. Moreover, the
extensive numerical study we executed proves that all updated DP algorithms are
extremely efficient, even for large size problem instances.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03726</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Saliency Prediction for Mobile User Interfaces</dc:title>
 <dc:creator>Gupta, Prakhar</dc:creator>
 <dc:creator>Gupta, Shubh</dc:creator>
 <dc:creator>Jayagopal, Ajaykrishnan</dc:creator>
 <dc:creator>Pal, Sourav</dc:creator>
 <dc:creator>Sinha, Ritwik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce models for saliency prediction for mobile user interfaces. A
mobile interface may include elements like buttons, text, etc. in addition to
natural images which enable performing a variety of tasks. Saliency in natural
images is a well studied area. However, given the difference in what
constitutes a mobile interface, and the usage context of these devices, we
postulate that saliency prediction for mobile interface images requires a fresh
approach. Mobile interface design involves operating on elements, the building
blocks of the interface. We first collected eye-gaze data from mobile devices
for free viewing task. Using this data, we develop a novel autoencoder based
multi-scale deep learning model that provides saliency prediction at the mobile
interface element level. Compared to saliency prediction approaches developed
for natural images, we show that our approach performs significantly better on
a range of established metrics.
</dc:description>
 <dc:description>Comment: Paper accepted at WACV 2018</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03736</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Sentiment/Topic Modeling on Text Data Using Boosted Restricted
  Boltzmann Machine</dc:title>
 <dc:creator>Fatemi, Masoud</dc:creator>
 <dc:creator>Safayani, Mehran</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recently by the development of the Internet and the Web, different types of
social media such as web blogs become an immense source of text data. Through
the processing of these data, it is possible to discover practical information
about different topics, individuals opinions and a thorough understanding of
the society. Therefore, applying models which can automatically extract the
subjective information from the documents would be efficient and helpful. Topic
modeling methods, also sentiment analysis are the most raised topics in the
natural language processing and text mining fields. In this paper a new
structure for joint sentiment-topic modeling based on Restricted Boltzmann
Machine (RBM) which is a type of neural networks is proposed. By modifying the
structure of RBM as well as appending a layer which is analogous to sentiment
of text data to it, we propose a generative structure for joint sentiment topic
modeling based on neutral networks. The proposed method is supervised and
trained by the Contrastive Divergence algorithm. The new attached layer in the
proposed model is a layer with the multinomial probability distribution which
can be used in text data sentiment classification or any other supervised
application. The proposed model is compared with existing models in the
experiments such as evaluating as a generative model, sentiment classification,
information retrieval and the corresponding results demonstrate the efficiency
of the method.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03742</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Judgment aggregation in non-classical logics</dc:title>
 <dc:creator>Porello, Daniele</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This work contributes to the theory of judgment aggregation by discussing a
number of significant non-classical logics. After adapting the standard
framework of judgment aggregation to cope with non-classical logics, we discuss
in particular results for the case of Intuitionistic Logic, the Lambek
calculus, Linear Logic and Relevant Logics. The motivation for studying
judgment aggregation in non-classical logics is that they offer a number of
modelling choices to represent agents' reasoning in aggregation problems. By
studying judgment aggregation in logics that are weaker than classical logic,
we investigate whether some well-known impossibility results, that were
tailored for classical logic, still apply to those weak systems.
</dc:description>
 <dc:description>Comment: To appear in Journal of Applied Non-Classical Logics</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03745</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Logics for modelling collective attitudes</dc:title>
 <dc:creator>Porello, Daniele</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We introduce a number of logics to reason about collective propositional
attitudes that are defined by means of the majority rule. It is well known that
majoritarian aggregation is subject to irrationality, as the results in social
choice theory and judgment aggregation show. The proposed logics for modelling
collective attitudes are based on a substructural propositional logic that
allows for circumventing inconsistent outcomes. Individual and collective
propositional attitudes, such as beliefs, desires, obligations, are then
modelled by means of minimal modalities to ensure a number of basic principles.
In this way, a viable consistent modelling of collective attitudes is obtained.
</dc:description>
 <dc:description>Comment: To appear in Fundamenta Informaticae</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03752</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lattice embeddings between types of fuzzy sets. Closed-valued fuzzy sets</dc:title>
 <dc:creator>Lobillo, F. J.</dc:creator>
 <dc:creator>Merino, Luis</dc:creator>
 <dc:creator>Navarro, Gabriel</dc:creator>
 <dc:creator>Santos, Evangelina</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03E72, 16D25</dc:subject>
 <dc:description>  In this paper we deal with the problem of extending Zadeh's operators on
fuzzy sets (FSs) to interval-valued (IVFSs), set-valued (SVFSs) and type-2
(T2FSs) fuzzy sets. Namely, it is known that seeing FSs as SVFSs, or T2FSs,
whose membership degrees are singletons is not order-preserving. We then
describe a family of lattice embeddings from FSs to SVFSs. Alternatively, if
the former singleton viewpoint is required, we reformulate the intersection on
hesitant fuzzy sets and introduce what we have called closed-valued fuzzy sets.
This new type of fuzzy sets extends standard union and intersection on FSs. In
addition, it allows handling together membership degrees of different nature
as, for instance, closed intervals and finite sets. Finally, all these
constructions are viewed as T2FSs forming a chain of lattices.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03754</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Skill Transfer from Supervised Language Tasks to Reading
  Comprehension</dc:title>
 <dc:creator>Mihaylov, Todor</dc:creator>
 <dc:creator>Kozareva, Zornitsa</dc:creator>
 <dc:creator>Frank, Anette</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Reading comprehension is a challenging task in natural language processing
and requires a set of skills to be solved. While current approaches focus on
solving the task as a whole, in this paper, we propose to use a neural network
`skill' transfer approach. We transfer knowledge from several lower-level
language tasks (skills) including textual entailment, named entity recognition,
paraphrase detection and question type classification into the reading
comprehension model.
  We conduct an empirical evaluation and show that transferring language skill
knowledge leads to significant improvements for the task with much fewer steps
compared to the baseline model. We also show that the skill transfer approach
is effective even with small amounts of training data. Another finding of this
work is that using token-wise deep label supervision for text classification
improves the performance of transfer learning.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03759</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>YEDDA: A Lightweight Collaborative Text Span Annotation Tool</dc:title>
 <dc:creator>Yang, Jie</dc:creator>
 <dc:creator>Zhang, Yue</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we introduce YEDDA, a lightweight but efficient open-source
tool for text span annotation. YEDDA provides a systematic solution for text
span annotation, ranging from collaborative user annotation to administrator
evaluation and analysis. It overcomes the low efficiency of traditional text
annotation tools by annotating entities through both command line and shortcut
keys, which are configurable with custom labels. YEDDA also gives intelligent
recommendations by training a predictive model using the up-to-date annotated
text. An administrator client is developed to evaluate annotation quality of
multiple annotators and generate detailed comparison report for each annotator
pair. YEDDA is developed based on Tkinter and is compatible with all major
operating systems.
</dc:description>
 <dc:description>Comment: In submission LREC 2018</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03771</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cloud vs Edge Computing for Mobile Services: Delay-aware Decision Making
  to Minimize Energy Consumption</dc:title>
 <dc:creator>Masoudi, Meysam</dc:creator>
 <dc:creator>Cavdar, Cicek</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A promising technique to provide mobile applications with high computation
resources is to offload the processing task to the cloud. Mobile cloud
computing enables mobile devices with limited batteries to run resource hungry
applications with the help of abundant processing capabilities of the clouds
and to save power. However, it is not always true that cloud computing consumes
less energy compared to mobile edge computing. It may take more energy for the
mobile device to transmit a file to the cloud than running the task itself at
the edge. This paper investigates the power minimization problem for the mobile
devices by data offloading in multi-cell multi-user OFDMA mobile cloud
computing networks. We consider the maximum acceptable delay and tolerable
interference as QoS metrics to be satisfied in our network. We formulate the
problem as a mixed integer nonlinear problem which is converted into a convex
form using D.C. approximation. To solve the optimization problem, we have
proposed centralized and distributed algorithms for joint power allocation and
channel assignment together with decision making. Our simulation results
illustrate that by utilizing the proposed algorithms, considerable power saving
could be achieved e.g. about 60 % for short delays and large bitstream sizes in
comparison with the baselines.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03774</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Sad State of Entrepreneurship in America: What Educators Can Do
  About It</dc:title>
 <dc:creator>Phillips, Fred</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The entrepreneurial scene suffers from a sick venture capital industry, a
number of imponderable illogics, and, maybe, misplaced adulation from students
and the public. The paper details these problems, finds root causes, and
prescribes action for higher education professionals and institutions.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03774</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03784</identifier>
 <datestamp>2018-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Z2Z4-Additive Cyclic Codes: Kernel and Rank</dc:title>
 <dc:creator>Borges, J.</dc:creator>
 <dc:creator>Dougherty, S. T.</dc:creator>
 <dc:creator>Fern&#xe1;ndez-C&#xf3;rdoba, C.</dc:creator>
 <dc:creator>Ten-Valls, R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A Z2Z4-additive code C subset of Z_2^alpha x Z_4^beta is called cyclic if the
set of coordinates can be partitioned into two subsets, the set of Z_2 and the
set of Z_4 coordinates, such that any cyclic shift of the coordinates of both
subsets leaves the code invariant. Let Phi(C) be the binary Gray image of C. We
study the rank and the dimension of the kernel of a Z2Z4-additive cyclic code
C, that is, the dimensions of the binary linear codes &lt;Phi(C)&gt; and ker(Phi(C)).
We give upper and lower bounds for these parameters. It is known that the codes
&lt;Phi(C)&gt; and ker(Phi(C)) are binary images of Z2Z4-additive codes R(C) and
K(C), respectively. Moreover, we show that R(C) and K(C) are also cyclic and we
determine the generator polynomials of these codes in terms of the generator
polynomials of the code C.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1707.03214</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03784</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03795</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-Windowed Contiguous Hotspot Queries</dc:title>
 <dc:creator>Rudi, Ali Gholami</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>68U05</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  A hotspot of a moving entity is a region in which it spends a significant
amount of time. Given the location of a moving object through a certain time
interval, i.e. its trajectory, our goal is to find its hotspots. We consider
axis-parallel square hotspots of fixed side length, which contain the longest
contiguous portion of the trajectory. Gudmundsson, van Kreveld, and Staals
(2013) presented an algorithm to find a hotspot of a trajectory in $O(n \log
n)$, in which $n$ is the number of vertices of the trajectory. We present an
algorithm for answering \emph{time-windowed} hotspot queries, to find a hotspot
in any given time interval. The algorithm has an approximation factor of $1/2$
and answers each query with the time complexity $O(\log^2 n)$. The time
complexity of the preprocessing step of the algorithm is $O(n)$. When the query
contains the whole trajectory, it implies an $O(n)$ algorithm for finding
approximate contiguous hotspots.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03798</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Centralized Coded Caching of Correlated Contents</dc:title>
 <dc:creator>Yang, Qianqian</dc:creator>
 <dc:creator>G&#xfc;nd&#xfc;z, Deniz</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Coded caching and delivery is studied taking into account the correlations
among the contents in the library. Correlations are modeled as common parts
shared by multiple contents; that is, each file in the database is composed of
a group of subfiles, where each subfile is shared by a different subset of
files. The number of files that include a certain subfile is defined as the
level of commonness of this subfile. First, a correlation-aware uncoded caching
scheme is proposed, and it is shown that the optimal placement for this scheme
gives priority to the subfiles with the highest levels of commonness. Then a
correlation-aware coded caching scheme is presented, and the cache capacity
allocated to subfiles with different levels of commonness is optimized in order
to minimize the delivery rate. The proposed correlation-aware coded caching
scheme is shown to remarkably outperform state-of-the-art correlation-ignorant
solutions, indicating the benefits of exploiting content correlations in coded
caching and delivery in networks.
</dc:description>
 <dc:description>Comment: 6 pages 2 figures</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03799</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking Multiple Vehicles Using a Variational Radar Model</dc:title>
 <dc:creator>Scheel, Alexander</dc:creator>
 <dc:creator>Dietmayer, Klaus</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  High-resolution radar sensors are able to resolve multiple measurements per
object and therefore provide valuable information for vehicle environment
perception. For instance, multiple measurements allow to infer the size of an
object or to more precisely measure the object's motion. Yet, the increased
amount of data raises the demands on tracking modules: measurement models that
are able to process multiple measurements for an object are necessary and
measurement-to-object associations become more complex. This paper presents a
new variational radar model for vehicles and demonstrates how this model can be
incorporated in a Random-Finite-Set-based multi-object tracker. The measurement
model is learned from actual data using variational Gaussian mixtures and
avoids excessive manual engineering. In combination with the multi-object
tracker, the entire process chain from the raw measurements to the resulting
tracks is formulated probabilistically. The presented approach is evaluated on
experimental data and it is demonstrated that data-driven measurement model
outperforms a manually designed model.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03800</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object Referring in Visual Scene with Spoken Language</dc:title>
 <dc:creator>Vasudevan, Arun Balajee</dc:creator>
 <dc:creator>Dai, Dengxin</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Object referring has important applications, especially for human-machine
interaction. While having received great attention, the task is mainly attacked
with written language (text) as input rather than spoken language (speech),
which is more natural. This paper investigates Object Referring with Spoken
Language (ORSpoken) by presenting two datasets and one novel approach. Objects
are annotated with their locations in images, text descriptions and speech
descriptions. This makes the datasets ideal for multi-modality learning. The
approach is developed by carefully taking down ORSpoken problem into three
sub-problems and introducing task-specific vision-language interactions at the
corresponding levels. Experiments show that our method outperforms competing
methods consistently and significantly. The approach is also evaluated in the
presence of audio noise, showing the efficacy of the proposed vision-language
interaction methods in counteracting background noise.
</dc:description>
 <dc:description>Comment: 10 pages, Submitted to WACV 2018</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03806</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Providing Physical Layer Security for Mission Critical Machine Type
  Communication</dc:title>
 <dc:creator>Weinand, Andreas</dc:creator>
 <dc:creator>Ambekar, Abhijit</dc:creator>
 <dc:creator>Karrenbauer, Michael</dc:creator>
 <dc:creator>Schotten, Hans D.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The design of wireless systems for Mission Critical Machine Type
Communication (MC-MTC) is currently a hot research topic. Wireless systems are
considered to provide numerous advantages over wired systems in industrial
applications for example. However, due to the broadcast nature of the wireless
channel, such systems are prone to a wide range of cyber attacks. These range
from passive eavesdropping attacks to active attacks like data manipulation or
masquerade attacks. Therefore it is necessary to provide reliable and efficient
security mechanisms. One of the most important security issue in such a system
is to ensure integrity as well as authenticity of exchanged messages over the
air between communicating devices in order to prohibit active attacks. In the
present work, an approach on how to achieve this goal in MC-MTC systems based
on Physical Layer Security (PHYSEC), especially a new method based on keeping
track of channel variations, will be presented and a proof-of-concept
evaluation is given.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03808</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An experimental mechatronic design and control of a 5 DOF Robotic arm
  for identification and sorting of different sized objects</dc:title>
 <dc:creator>Tolis, Christos</dc:creator>
 <dc:creator>Fragulis, George F.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The purpose of this paper is to present the construction and programming of a
five degrees of freedom robotic arm which interacts with an infrared sensor for
the identification and sorting of different sized objects. The main axis of the
construction design will be up to the three main branches of science that make
up the Mechatronics: Mechanical Engineering, Electronic-Electrical Engineering
and Computer Engineering. The methods that have been used for the construction
are presented as well as the methods for the programming of the arm in
cooperation with the sensor. The aim is to present the manual and automatic
control of the arm for the recognition and the installation of the objects
through a simple (in operation) and low in cost sensor like the one that was
used by this paper. Furthermore, this paper presents the significance of this
robotic arm design and its further applications in contemporary industrial
forms of production.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03810</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robotic Tactile Perception of Object Properties: A Review</dc:title>
 <dc:creator>Luo, Shan</dc:creator>
 <dc:creator>Bimbo, Joao</dc:creator>
 <dc:creator>Dahiya, Ravinder</dc:creator>
 <dc:creator>Liu, Hongbin</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Touch sensing can help robots understand their sur- rounding environment, and
in particular the objects they interact with. To this end, roboticists have, in
the last few decades, developed several tactile sensing solutions, extensively
reported in the literature. Research into interpreting the conveyed tactile
information has also started to attract increasing attention in recent years.
However, a comprehensive study on this topic is yet to be reported. In an
effort to collect and summarize the major scientific achievements in the area,
this survey extensively reviews current trends in robot tactile perception of
object properties. Available tactile sensing technologies are briefly presented
before an extensive review on tactile recognition of object properties. The
object properties that are targeted by this review are shape, surface material
and object pose. The role of touch sensing in combination with other sensing
sources is also discussed. In this review, open issues are identified and
future directions for applying tactile sensing in different tasks are
suggested.
</dc:description>
 <dc:description>Comment: 17 pages, 3 figures, 5 tables</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03817</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning with Options that Terminate Off-Policy</dc:title>
 <dc:creator>Harutyunyan, Anna</dc:creator>
 <dc:creator>Vrancx, Peter</dc:creator>
 <dc:creator>Bacon, Pierre-Luc</dc:creator>
 <dc:creator>Precup, Doina</dc:creator>
 <dc:creator>Nowe, Ann</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A temporally abstract action, or an option, is specified by a policy and a
termination condition: the policy guides option behavior, and the termination
condition roughly determines its length. Generally, learning with longer
options (like learning with multi-step returns) is known to be more efficient.
However, if the option set for the task is not ideal, and cannot express the
primitive optimal policy exactly, shorter options offer more flexibility and
can yield a better solution. Thus, the termination condition puts learning
efficiency at odds with solution quality. We propose to resolve this dilemma by
decoupling the behavior and target terminations, just like it is done with
policies in off-policy learning. To this end, we give a new algorithm,
Q(\beta), that learns the solution with respect to any termination condition,
regardless of how the options actually terminate. We derive Q(\beta) by casting
learning with options into a common framework with well-studied multi-step
off-policy learning. We validate our algorithm empirically, and show that it
holds up to its motivating claims.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03819</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperative control of multi-agent systems to locate source of an odor</dc:title>
 <dc:creator>Sinha, Abhinav</dc:creator>
 <dc:creator>Kaur, Rishemjit</dc:creator>
 <dc:creator>Kumar, Ritesh</dc:creator>
 <dc:creator>Bhondekar, Amol P.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This work targets the problem of odor source localization by multi-agent
systems. A hierarchical cooperative control has been put forward to solve the
problem of locating source of an odor by driving the agents in consensus when
at least one agent obtains information about location of the source. Synthesis
of the proposed controller has been carried out in a hierarchical manner of
group decision making, path planning and control. Decision making utilizes
information of the agents using conventional Particle Swarm Algorithm and
information of the movement of filaments to predict the location of the odor
source. The predicted source location in the decision level is then utilized to
map a trajectory and pass that information to the control level. The
distributed control layer uses sliding mode controllers known for their
inherent robustness and the ability to reject matched disturbances completely.
Two cases of movement of agents towards the source, i.e., under consensus and
formation have been discussed herein. Finally, numerical simulations
demonstrate the efficacy of the proposed hierarchical distributed control.
</dc:description>
 <dc:description>Comment: 8 pages, initial results on our work</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03822</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LSTM Networks for Data-Aware Remaining Time Prediction of Business
  Process Instances</dc:title>
 <dc:creator>Navarin, Nicol&#xf2;</dc:creator>
 <dc:creator>Vincenzi, Beatrice</dc:creator>
 <dc:creator>Polato, Mirko</dc:creator>
 <dc:creator>Sperduti, Alessandro</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Predicting the completion time of business process instances would be a very
helpful aid when managing processes under service level agreement constraints.
The ability to know in advance the trend of running process instances would
allow business managers to react in time, in order to prevent delays or
undesirable situations. However, making such accurate forecasts is not easy:
many factors may influence the required time to complete a process instance. In
this paper, we propose an approach based on deep Recurrent Neural Networks
(specifically LSTMs) that is able to exploit arbitrary information associated
to single events, in order to produce an as-accurate-as-possible prediction of
the completion time of running instances. Experiments on real-world datasets
confirm the quality of our proposal.
</dc:description>
 <dc:description>Comment: Article accepted for publication in 2017 IEEE Symposium on Deep
  Learning (IEEE DL'17) @ SSCI</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03826</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model Checking Markov Population Models by Stochastic Approximations</dc:title>
 <dc:creator>Bortolussi, Luca</dc:creator>
 <dc:creator>Lanciani, Roberta</dc:creator>
 <dc:creator>Nenzi, Laura</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Many complex systems can be described by population models, in which a pool
of agents interacts and produces complex collective behaviours. We consider the
problem of verifying formal properties of the underlying mathematical
representation of these models, which is a Continuous Time Markov Chain, often
with a huge state space. To circumvent the state space explosion, we rely on
stochastic approximation techniques, which replace the large model by a simpler
one, guaranteed to be probabilistically consistent. We show how to efficiently
and accurately verify properties of random individual agents, specified by
Continuous Stochastic Logic extended with Timed Automata (CSL-TA), and how to
lift these specifications to the collective level, approximating the number of
agents satisfying them using second or higher order stochastic approximation
techniques.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03829</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time Stream-based Monitoring</dc:title>
 <dc:creator>Faymonville, Peter</dc:creator>
 <dc:creator>Finkbeiner, Bernd</dc:creator>
 <dc:creator>Schwenger, Maximilian</dc:creator>
 <dc:creator>Torfah, Hazem</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We introduce RTLola, a new stream-based specification language for the
description of real-time properties of reactive systems. In real-time
applications, data arrives at varying rates and in most cases it is hard to
predict the input rate. The integration of sliding windows over real-time
intervals with aggregation functions into RTLola allows us to detach fixed-rate
output streams from the varying rate input streams. However, the number of
input values within a single window instance can grow arbitrarily large
disallowing any guarantees on the expected memory consumption. A feature of
RTLola is that it allows for an automatic memory analysis that guides the user
in identifying the computationally expensive specifications. For specifications
using only certain classes of aggregation functions, we can give a precise
memory bound. Furthermore, assuming a fixed monitor output rate, we can provide
memory guarantees which can be computed statically. To demonstrate the features
of RTLola, we evaluate the language and the implementation experimentally.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03832</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Time-of-Arrival Estimation in NB-IoT Systems</dc:title>
 <dc:creator>Hu, Sha</dc:creator>
 <dc:creator>Li, Xuhong</dc:creator>
 <dc:creator>Rusek, Fredrik</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider time-of-arrival (ToA) estimation of a first arrival-path for a
device working in narrowband Internet-of-Things (NB-IoT) systems. Due to a
limited 180 KHz bandwidth used in NB-IoT, the time-domain auto-correlation
function (ACF) of transmitted NB positioning reference signal (NPRS) has a wide
main lobe. Without considering that, the performance of ToA estimation can be
degraded for two reasons. Firstly, under multiple-path channel environments,
the NPRS corresponding to different received paths are superimposed on each
other, and so are the cross-correlations corresponding to them. Secondly, the
measured peak-to-average-power-ratio (PAPR) used for detecting the presence of
NPRS is inaccurate. Therefore, in this paper we propose a space-alternating
generalized expectation-maximization (SAGE) based method to jointly estimate
the number of channel taps, the channel coefficients and the corresponding
delays in NB-IoT systems, with considering the imperfect ACF of NPRS. Such a
proposed method only uses the time-domain cross-correlations between the
received signal and the transmitted NPRS, and has a low complexity. We show
through simulations that, the ToA estimation of the proposed method performs
close to the maximum likelihood (ML) estimation for a single-path channel, and
significantly outperforms a traditional ToA estimator that uses signal-to-noise
(SNR) or power thresholds based estimation.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03842</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Refinement Reflection: Complete Verification with SMT</dc:title>
 <dc:creator>Vazou, Niki</dc:creator>
 <dc:creator>Tondwalkar, Anish</dc:creator>
 <dc:creator>Choudhury, Vikraman</dc:creator>
 <dc:creator>Scott, Ryan G.</dc:creator>
 <dc:creator>Newton, Ryan R.</dc:creator>
 <dc:creator>Wadler, Philip</dc:creator>
 <dc:creator>Jhala, Ranjit</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We introduce Refinement Reflection, a new framework for building SMT-based
deductive verifiers. The key idea is to reflect the code implementing a
user-defined function into the function's (output) refinement type. As a
consequence, at uses of the function, the function definition is instantiated
in the SMT logic in a precise fashion that permits decidable verification.
Reflection allows the user to write equational proofs of programs just by
writing other programs using pattern-matching and recursion to perform
case-splitting and induction. Thus, via the propositions-as-types principle, we
show that reflection permits the specification of arbitrary functional
correctness properties. Finally, we introduce a proof-search algorithm called
Proof by Logical Evaluation that uses techniques from model checking and
abstract interpretation, to completely automate equational reasoning. We have
implemented reflection in Liquid Haskell and used it to verify that the widely
used instances of the Monoid, Applicative, Functor, and Monad typeclasses
actually satisfy key algebraic laws required to make the clients safe, and have
used reflection to build the first library that actually verifies assumptions
about associativity and ordering that are crucial for safe deterministic
parallelism.
</dc:description>
 <dc:description>Comment: 29 pages plus appendices, to appear in POPL 2018. arXiv admin note:
  text overlap with arXiv:1610.04641</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03846</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Dave...I can assure you...that it's going to be all right...&quot; -- A
  definition, case for, and survey of algorithmic assurances in human-autonomy
  trust relationships</dc:title>
 <dc:creator>Israelsen, Brett W</dc:creator>
 <dc:creator>Ahmed, Nisar R</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  As technology becomes more advanced, those who design, use and are otherwise
affected by it want to know that it will perform correctly, and understand why
it does what it does, and how to use it appropriately. In essence they want to
be able to trust the systems that are being designed. In this survey we present
assurances that are the method by which users can understand how to trust
autonomous systems. Trust between humans and autonomy is reviewed, and the
implications for the design of assurances are highlighted. A survey of existing
research related to assurances is presented. Much of the surveyed research
originates from fields such as interpretable, comprehensible, transparent, and
explainable machine learning, as well as human-computer interaction,
human-robot interaction, and e-commerce. Several key ideas are extracted from
this work in order to refine the definition of assurances. The design of
assurances is found to be highly dependent not only on the capabilities of the
autonomous system, but on the characteristics of the human user, and the
appropriate trust-related behaviors. Several directions for future research are
identified and discussed.
</dc:description>
 <dc:description>Comment: page count reduction. arXiv admin note: substantial text overlap with
  arXiv:1708.00495</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03859</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards the Use of Deep Reinforcement Learning with Global Policy For
  Query-based Extractive Summarisation</dc:title>
 <dc:creator>Molla, Diego</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Supervised approaches for text summarisation suffer from the problem of
mismatch between the target labels/scores of individual sentences and the
evaluation score of the final summary. Reinforcement learning can solve this
problem by providing a learning mechanism that uses the score of the final
summary as a guide to determine the decisions made at the time of selection of
each sentence. In this paper we present a proof-of-concept approach that
applies a policy-gradient algorithm to learn a stochastic policy using an
undiscounted reward. The method has been applied to a policy consisting of a
simple neural network and simple features. The resulting deep reinforcement
learning system is able to learn a global policy and obtain encouraging
results.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, 1 algorithm. As submitted for camera ready for
  the 2017 Australasian Language Technology Association Workshop (ALTA 2017)</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03859</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03860</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Size bounds and query plans for relational joins</dc:title>
 <dc:creator>Atserias, Albert</dc:creator>
 <dc:creator>Grohe, Martin</dc:creator>
 <dc:creator>Marx, D&#xe1;niel</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Relational joins are at the core of relational algebra, which in turn is the
core of the standard database query language SQL. As their evaluation is
expensive and very often dominated by the output size, it is an important task
for database query optimisers to compute estimates on the size of joins and to
find good execution plans for sequences of joins. We study these problems from
a theoretical perspective, both in the worst-case model, and in an average-case
model where the database is chosen according to a known probability
distribution. In the former case, our first key observation is that the
worst-case size of a query is characterised by the fractional edge cover number
of its underlying hypergraph, a combinatorial parameter previously known to
provide an upper bound. We complete the picture by proving a matching lower
bound, and by showing that there exist queries for which the join-project plan
suggested by the fractional edge cover approach may be substantially better
than any join plan that does not use intermediate projections. On the other
hand, we show that in the average-case model, every join-project plan can be
turned into a plan containing no projections in such a way that the expected
time to evaluate the plan increases only by a constant factor independent of
the size of the database. Not surprisingly, the key combinatorial parameter in
this context is the maximum density of the underlying hypergraph. We show how
to make effective use of this parameter to eliminate the projections.
</dc:description>
 <dc:description>Comment: Conference version in FOCS 2008</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03871</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FunTAL: Reasonably Mixing a Functional Language with Assembly</dc:title>
 <dc:creator>Patterson, Daniel</dc:creator>
 <dc:creator>Perconti, Jamie</dc:creator>
 <dc:creator>Dimoulas, Christos</dc:creator>
 <dc:creator>Ahmed, Amal</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present FunTAL, the first multi-language system to formalize safe
interoperability between a high-level functional language and low-level
assembly code while supporting compositional reasoning about the mix. A central
challenge in developing such a multi-language is bridging the gap between
assembly, which is staged into jumps to continuations, and high-level code,
where subterms return a result. We present a compositional stack-based typed
assembly language that supports components, comprised of one or more basic
blocks, that may be embedded in high-level contexts. We also present a logical
relation for FunTAL that supports reasoning about equivalence of high-level
components and their assembly replacements, mixed-language programs with
callbacks between languages, and assembly components comprised of different
numbers of basic blocks.
</dc:description>
 <dc:description>Comment: 15 pages; implementation at https://dbp.io/artifacts/funtal/;
  published in PLDI '17, Proceedings of the 38th ACM SIGPLAN Conference on
  Programming Language Design and Implementation, June 18 - 23, 2017,
  Barcelona, Spain</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03871</dc:identifier>
 <dc:identifier>doi:10.1145/3140587.3062347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03874</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Material Classification in the Wild: Do Synthesized Training Data
  Generalise Better than Real-World Training Data?</dc:title>
 <dc:creator>Kalliatakis, Grigorios</dc:creator>
 <dc:creator>Sticlaru, Anca</dc:creator>
 <dc:creator>Stamatiadis, George</dc:creator>
 <dc:creator>Ehsan, Shoaib</dc:creator>
 <dc:creator>Leonardis, Ales</dc:creator>
 <dc:creator>Gall, Juergen</dc:creator>
 <dc:creator>McDonald-Maier, Klaus D.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We question the dominant role of real-world training images in the field of
material classification by investigating whether synthesized data can
generalise more effectively than real-world data. Experimental results on three
challenging real-world material databases show that the best performing
pre-trained convolutional neural network (CNN) architectures can achieve up to
91.03% mean average precision when classifying materials in cross-dataset
scenarios. We demonstrate that synthesized data achieve an improvement on mean
average precision when used as training data and in conjunction with
pre-trained CNN architectures, which spans from ~ 5% to ~ 19% across three
widely used material databases of real-world images.
</dc:description>
 <dc:description>Comment: accepted for publication in VISAPP 2018. arXiv admin note: text
  overlap with arXiv:1703.04101</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03876</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Proof of Stavi's Theorem</dc:title>
 <dc:creator>Rabinovich, Alexander</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Kamp's theorem established the expressive equivalence of the temporal logic
with Until and Since and the First-Order Monadic Logic of Order (FOMLO) over
the Dedekind-complete time flows. However, this temporal logic is not
expressively complete for FOMLO over the rationals. Stavi introduced two
additional modalities and proved that the temporal logic with Until, Since and
Stavi's modalities is expressively equivalent to FOMLO over all linear orders.
We present a simple proof of Stavi's theorem.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1401.2580</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03876</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03885</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clustering with Local Restrictions</dc:title>
 <dc:creator>Lokshtanov, Daniel</dc:creator>
 <dc:creator>Marx, D&#xe1;niel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study a family of graph clustering problems where each cluster has to
satisfy a certain local requirement. Formally, let $\mu$ be a function on the
subsets of vertices of a graph $G$. In the $(\mu,p,q)$-PARTITION problem, the
task is to find a partition of the vertices into clusters where each cluster
$C$ satisfies the requirements that (1) at most $q$ edges leave $C$ and (2)
$\mu(C)\le p$. Our first result shows that if $\mu$ is an {\em arbitrary}
polynomial-time computable monotone function, then $(\mu,p,q)$-PARTITION can be
solved in time $n^{O(q)}$, i.e., it is polynomial-time solvable {\em for every
fixed $q$}. We study in detail three concrete functions $\mu$ (the number of
vertices in the cluster, number of nonedges in the cluster, maximum number of
non-neighbors a vertex has in the cluster), which correspond to natural
clustering problems. For these functions, we show that $(\mu,p,q)$-PARTITION
can be solved in time $2^{O(p)}\cdot n^{O(1)}$ and in time $2^{O(q)}\cdot
n^{O(1)}$ on $n$-vertex graphs, i.e., the problem is fixed-parameter tractable
parameterized by $p$ or by $q$.
</dc:description>
 <dc:description>Comment: Conference version in ICALP 2011</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03885</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03886</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Completely inapproximable monotone and antimonotone parameterized
  problems</dc:title>
 <dc:creator>Marx, D&#xe1;niel</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We prove that weighted circuit satisfiability for monotone or antimonotone
circuits has no fixed-parameter tractable approximation algorithm with any
approximation ratio function $\rho$, unless $FPT\neq W[1]$. In particular, not
having such an fpt-approximation algorithm implies that these problems have no
polynomial-time approximation algorithms with ratio $\rho(OPT)$ for any
nontrivial function $\rho$.
</dc:description>
 <dc:description>Comment: Conference version in CCC 2010</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03887</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hamming distance completeness and sparse matrix multiplication</dc:title>
 <dc:creator>Graf, Daniel</dc:creator>
 <dc:creator>Labib, Karim</dc:creator>
 <dc:creator>Uzna&#x144;ski, Przemys&#x142;aw</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We investigate relations between $(+,\diamond)$ vector products for binary
integer functions $\diamond$. We show that there exists a broad class of
products equivalent under one-to-polylog reductions to the computation of the
Hamming distance. Examples include: the dominance product, the threshold
product and $\ell_{2p+1}$ distances for constant $p$. Our result has the
following consequences:
  The following All Pairs- problems are of the same complexity (up to polylog
factors) for $n$ vectors in $Z^d$: computing Hamming Distance, $\ell_{2p+1}$
Distance, Threshold Products and Dominance Products. As a consequence,
Yuster's~(SODA'09) algorithm improves not only Matou\v{s}ek's (IPL'91), but
also the results of Indyk, Lewenstein, Lipsky and Porat (ICALP'04) and Min, Kao
and Zhu (COCOON'09). Obtain by reduction algorithms for All Pairs
$\ell_3,\ell_5,\dots$ Distances are new.
  The following Pattern Matching problems are of the same complexity (up to
polylog factors) for a text of length $n$ and a pattern of length $m$: Hamming
Distance, Less-than, Threshold and $\ell_{2p+1}$. For all of them the current
best upper bounds are $\mathcal{O}(n\sqrt{m \log m})$ time due to results of
Abrahamson (SICOMP'87), Amir and Farach (Ann.~Math.~Artif.~Intell.'91), Atallah
and Duket (IPL'11), Clifford, Clifford and Iliopoulous (CPM'05) and Amir,
Lipsky, Porat and Umanski (CPM'05). The obtained algorithms for
$\ell_3,\ell_5,\dots$ Pattern Matchings are new.
  We also show that the complexity of All Pairs Hamming Distances is within a
polylog factor from $sparse(n,d^2,n;nd,nd)$, where $sparse(a,b,c;m_1,m_2)$ is
the time of multiplying sparse matrices of size $a\times b$ and $b\times c$,
with $m_1$ and $m_2$ nonzero entries. This means that the current upperbounds
by Yuster cannot be improved without improving the sparse matrix multiplication
algorithm by Yuster and Zwick~(ACM TALG'05) and vice versa.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03888</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In-Depth Exploration of Single-Snapshot Lossy Compression Techniques for
  N-Body Simulations</dc:title>
 <dc:creator>Tao, Dingwen</dc:creator>
 <dc:creator>Di, Sheng</dc:creator>
 <dc:creator>Chen, Zizhong</dc:creator>
 <dc:creator>Cappello, Franck</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In situ lossy compression allowing user-controlled data loss can
significantly reduce the I/O burden. For large-scale N-body simulations where
only one snapshot can be compressed at a time, the lossy compression ratio is
very limited because of the fairly low spatial coherence of the particle data.
In this work, we assess the state-of-the-art single-snapshot lossy compression
techniques of two common N-body simulation models: cosmology and molecular
dynamics. We design a series of novel optimization techniques based on the two
representative real-world N-body simulation codes. For molecular dynamics
simulation, we propose three compression modes (i.e., best speed, best
tradeoff, best compression mode) that can refine the tradeoff between the
compression rate (a.k.a., speed/throughput) and ratio. For cosmology
simulation, we identify that our improved SZ is the best lossy compressor with
respect to both compression ratio and rate. Its compression ratio is higher
than the second-best compressor by 11% with comparable compression rate.
Experiments with up to 1024 cores on the Blues supercomputer at Argonne show
that our proposed lossy compression method can reduce I/O time by 80% compared
with writing data directly to a parallel file system and outperforms the
second-best solution by 60%. Moreover, our proposed lossy compression methods
have the best rate-distortion with reasonable compression errors on the tested
N-body simulation data compared with state-of-the-art compressors.
</dc:description>
 <dc:description>Comment: Accepted by IEEE BigData 2017</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03889</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhanced Movie Content Similarity Based on Textual, Auditory and Visual
  Information</dc:title>
 <dc:creator>Bougiatiotis, Konstantinos</dc:creator>
 <dc:creator>Giannakopoulos, Theodore</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In this paper we examine the ability of low-level multimodal features to
extract movie similarity, in the context of a content-based movie
recommendation approach. In particular, we demonstrate the extraction of
multimodal representation models of movies, based on textual information from
subtitles, as well as cues from the audio and visual channels. With regards to
the textual domain, we emphasize our research in topic modeling of movies based
on their subtitles, in order to extract topics that discriminate between
movies. Regarding the visual domain, we focus on the extraction of semantically
useful features that model camera movements, colors and faces, while for the
audio domain we adopt simple classification aggregates based on pretrained
models. The three domains are combined with static metadata (e.g. directors,
actors) to prove that the content-based movie similarity procedure can be
enhanced with low-level multimodal information. In order to demonstrate the
proposed content representation approach, we have built a small dataset of 160
widely known movies. We assert movie similarities, as propagated by the
individual modalities and fusion models, in the form of recommendation
rankings. Extensive experimentation proves that all three low-level modalities
(text, audio and visual) boost the performance of a content-based
recommendation system, compared to the typical metadata-based content
representation, by more than $50\%$ relative increase. To our knowledge, this
is the first approach that utilizes a wide range of features from all involved
modalities, in order to enhance the performance of the content similarity
estimation, compared to the metadata-based approaches.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03892</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Arrhythmia Classification from the Abductive Interpretation of Short
  Single-Lead ECG Records</dc:title>
 <dc:creator>Teijeiro, Tom&#xe1;s</dc:creator>
 <dc:creator>Garc&#xed;a, Constantino A.</dc:creator>
 <dc:creator>Castro, Daniel</dc:creator>
 <dc:creator>F&#xe9;lix, Paulo</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68T10</dc:subject>
 <dc:description>  In this work we propose a new method for the rhythm classification of short
single-lead ECG records, using a set of high-level and clinically meaningful
features provided by the abductive interpretation of the records. These
features include morphological and rhythm-related features that are used to
build two classifiers: one that evaluates the record globally, using aggregated
values for each feature; and another one that evaluates the record as a
sequence, using a Recurrent Neural Network fed with the individual features for
each detected heartbeat. The two classifiers are finally combined using the
stacking technique, providing an answer by means of four target classes: Normal
sinus rhythm, Atrial fibrillation, Other anomaly, and Noisy. The approach has
been validated against the 2017 Physionet/CinC Challenge dataset, obtaining a
final score of 0.83 and ranking first in the competition.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures. Presented in the Computing in Cardiology 2017
  conference</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03894</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the hardness of losing weight</dc:title>
 <dc:creator>Krokhin, Andrei</dc:creator>
 <dc:creator>Marx, D&#xe1;niel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study the complexity of local search for the Boolean constraint
satisfaction problem (CSP), in the following form: given a CSP instance, that
is, a collection of constraints, and a solution to it, the question is whether
there is a better (lighter, i.e., having strictly less Hamming weight) solution
within a given distance from the initial solution. We classify the complexity,
both classical and parameterized, of such problems by a Schaefer-style
dichotomy result, that is, with a restricted set of allowed types of
constraints. Our results show that there is a considerable amount of such
problems that are NP-hard, but fixed-parameter tractable when parameterized by
the distance.
</dc:description>
 <dc:description>Comment: Conference version in ICALP 2008</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03895</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group Connectivity: $\mathbb Z_4$ v. $\mathbb Z_2^2$</dc:title>
 <dc:creator>Hu&#x161;ek, Radek</dc:creator>
 <dc:creator>Moheln&#xed;kov&#xe1;, Lucie</dc:creator>
 <dc:creator>&#x160;&#xe1;mal, Robert</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We answer a question on group connectivity suggested by Jaeger et al. [Group
connectivity of graphs -- A nonhomogeneous analogue of nowhere-zero flow
properties, JCTB 1992]: we find that $\mathbb Z_2^2$-connectivity does not
imply $\mathbb Z_4$-connectivity, neither vice versa. We use a computer to find
the graphs certifying this and to verify their properties using non-trivial
enumerative algorithm. While the graphs are small (the largest has 15 vertices
and 21 edges), a computer-free approach remains elusive.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03896</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Observability in Inertial Parameter Identification</dc:title>
 <dc:creator>Wensing, Patrick M.</dc:creator>
 <dc:creator>Niemeyer, G&#xfc;nter</dc:creator>
 <dc:creator>Slotine, Jean-Jacques E.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present an algorithm to characterize the space of identifiable inertial
parameters in system identification of an articulated robot. This problem has
been considered in the literature for decades; however, existing methods suffer
from common drawbacks. Methods either rely on symbolic techniques that do not
scale, or rely on numerical techniques that are sensitive to the choice of an
input motion. The contribution of this work is to propose a recursive algorithm
for this problem that requires only the structural parameters of a mechanism as
its input. This Recursive Parameter Nullspace Algorithm (RPNA) can be applied
to general open-chain kinematic trees, and does not rely on symbolic
techniques. Drawing on the exponential parameterization of rigid-body
kinematics, classical linear controllability and observability results can be
directly applied to inertial parameter identifiability. The high-level
operation of the RPNA is based on a key observation -- undetectable changes in
inertial parameters can be interpreted as sequences of inertial transfers
across the joints. This observation can be applied recursively, and lends an
overall complexity of O(N) to determine the minimal parameters for a system of
N bodies. Matlab source code for the new algorithm is provided.
</dc:description>
 <dc:description>Comment: Pre-submission notes</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03902</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural-Symbolic Learning and Reasoning: A Survey and Interpretation</dc:title>
 <dc:creator>Besold, Tarek R.</dc:creator>
 <dc:creator>Garcez, Artur d'Avila</dc:creator>
 <dc:creator>Bader, Sebastian</dc:creator>
 <dc:creator>Bowman, Howard</dc:creator>
 <dc:creator>Domingos, Pedro</dc:creator>
 <dc:creator>Hitzler, Pascal</dc:creator>
 <dc:creator>Kuehnberger, Kai-Uwe</dc:creator>
 <dc:creator>Lamb, Luis C.</dc:creator>
 <dc:creator>Lowd, Daniel</dc:creator>
 <dc:creator>Lima, Priscila Machado Vieira</dc:creator>
 <dc:creator>de Penning, Leo</dc:creator>
 <dc:creator>Pinkas, Gadi</dc:creator>
 <dc:creator>Poon, Hoifung</dc:creator>
 <dc:creator>Zaverucha, Gerson</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The study and understanding of human behaviour is relevant to computer
science, artificial intelligence, neural computation, cognitive science,
philosophy, psychology, and several other areas. Presupposing cognition as
basis of behaviour, among the most prominent tools in the modelling of
behaviour are computational-logic systems, connectionist models of cognition,
and models of uncertainty. Recent studies in cognitive science, artificial
intelligence, and psychology have produced a number of cognitive models of
reasoning, learning, and language that are underpinned by computation. In
addition, efforts in computer science research have led to the development of
cognitive computational systems integrating machine learning and automated
reasoning. Such systems have shown promise in a range of applications,
including computational biology, fault diagnosis, training and assessment in
simulators, and software verification. This joint survey reviews the personal
ideas and views of several researchers on neural-symbolic learning and
reasoning. The article is organised in three parts: Firstly, we frame the scope
and goals of neural-symbolic computation and have a look at the theoretical
foundations. We then proceed to describe the realisations of neural-symbolic
computation, systems, and applications. Finally we present the challenges
facing the area and avenues for further research.
</dc:description>
 <dc:description>Comment: 58 pages, work in progress</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03905</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attend and Diagnose: Clinical Time Series Analysis using Attention
  Models</dc:title>
 <dc:creator>Song, Huan</dc:creator>
 <dc:creator>Rajan, Deepta</dc:creator>
 <dc:creator>Thiagarajan, Jayaraman J.</dc:creator>
 <dc:creator>Spanias, Andreas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  With widespread adoption of electronic health records, there is an increased
emphasis for predictive models that can effectively deal with clinical
time-series data. Powered by Recurrent Neural Network (RNN) architectures with
Long Short-Term Memory (LSTM) units, deep neural networks have achieved
state-of-the-art results in several clinical prediction tasks. Despite the
success of RNNs, its sequential nature prohibits parallelized computing, thus
making it inefficient particularly when processing long sequences. Recently,
architectures which are based solely on attention mechanisms have shown
remarkable success in transduction tasks in NLP, while being computationally
superior. In this paper, for the first time, we utilize attention models for
clinical time-series modeling, thereby dispensing recurrence entirely. We
develop the \textit{SAnD} (Simply Attend and Diagnose) architecture, which
employs a masked, self-attention mechanism, and uses positional encoding and
dense interpolation strategies for incorporating temporal order. Furthermore,
we develop a multi-task variant of \textit{SAnD} to jointly infer models with
multiple diagnosis tasks. Using the recent MIMIC-III benchmark datasets, we
demonstrate that the proposed approach achieves state-of-the-art performance in
all tasks, outperforming LSTM models and classical baselines with
hand-engineered features.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03906</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>D-SLATS: Distributed Simultaneous Localization and Time Synchronization</dc:title>
 <dc:creator>Alanwar, Amr</dc:creator>
 <dc:creator>Ferraz, Henrique</dc:creator>
 <dc:creator>Hsieh, Kevin</dc:creator>
 <dc:creator>Thazhath, Rohit</dc:creator>
 <dc:creator>Martin, Paul</dc:creator>
 <dc:creator>Hespanha, Joao</dc:creator>
 <dc:creator>Srivastava, Mani</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Through the last decade, we have witnessed a surge of Internet of Things
(IoT) devices, and with that a greater need to choreograph their actions across
both time and space. Although these two problems, namely time synchronization
and localization, share many aspects in common, they are traditionally treated
separately or combined on centralized approaches that results in an ineffcient
use of resources, or in solutions that are not scalable in terms of the number
of IoT devices. Therefore, we propose D-SLATS, a framework comprised of three
different and independent algorithms to jointly solve time synchronization and
localization problems in a distributed fashion. The First two algorithms are
based mainly on the distributed Extended Kalman Filter (EKF) whereas the third
one uses optimization techniques. No fusion center is required, and the devices
only communicate with their neighbors. The proposed methods are evaluated on
custom Ultra-Wideband communication Testbed and a quadrotor, representing a
network of both static and mobile nodes. Our algorithms achieve up to three
microseconds time synchronization accuracy and 30 cm localization error.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03906</dc:identifier>
 <dc:identifier>doi:10.1145/3084041.3084049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03908</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite Sample Differentially Private Confidence Intervals</dc:title>
 <dc:creator>Karwa, Vishesh</dc:creator>
 <dc:creator>Vadhan, Salil</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We study the problem of estimating finite sample confidence intervals of the
mean of a normal population under the constraint of differential privacy. We
consider both the known and unknown variance cases and construct differentially
private algorithms to estimate confidence intervals. Crucially, our algorithms
guarantee a finite sample coverage, as opposed to an asymptotic coverage.
Unlike most previous differentially private algorithms, we do not require the
domain of the samples to be bounded. We also prove lower bounds on the expected
size of any differentially private confidence set showing that our the
parameters are optimal up to polylogarithmic factors.
</dc:description>
 <dc:description>Comment: Presented at TPDP 2017 and a shorter version to appear at ITCS 2018</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03910</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LDPC-Based Code Hopping for Gaussian Wiretap Channel With Limited
  Feedback</dc:title>
 <dc:creator>Chen, Zhao</dc:creator>
 <dc:creator>Yin, Liuguo</dc:creator>
 <dc:creator>Lu, Jianhua</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents a scheme named code hopping (CodeHop) for gaussian
wiretap channels based on nonsystematic low-density parity-check (LDPC) codes.
Different from traditional communications, in the CodeHop scheme, the
legitimate receiver (Bob) rapidly switches the parity-check matrix upon each
correctly received source message block. Given an authenticated public feedback
channel, the transmitter's (Alice) parity-check matrix can also be synchronized
with the receiver's. As a result, once an eavesdropper (Eve) erroneously
decodes a message block, she may not be able to follow the update of subsequent
parity-check matrices. Thus, the average BER of Eve will be very close to $0.5$
if the transmitted number of message blocks is large enough. Focused on the
measure of security gap defined as the difference of channel quality between
Bob and Eve, numerical results show that the CodeHop scheme outperforms other
solutions by sufficiently reducing the security gap without sacrificing the
error-correcting performance of Bob.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03933</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous Integration: The Silver Bullet?</dc:title>
 <dc:creator>Rahman, Akond</dc:creator>
 <dc:creator>Agrawal, Amritanshu</dc:creator>
 <dc:creator>Krishna, Rahul</dc:creator>
 <dc:creator>Sobran, Alexander</dc:creator>
 <dc:creator>Menzies, Tim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Continuous integration (CI) tools integrate code changes by automatically
compiling, building, and executing test cases upon submission of code changes.
Use of CI tools is getting increasingly popular, yet how proprietary projects
reap the benefits of CI remains unknown. To investigate the influence of CI on
software development, we mine 661 open source software (OSS) projects, and 171
proprietary projects. For OSS projects, we observe the expected benefits after
CI adoption, i.e. more bugs are resolved, and more issues are resolved.
However, for the proprietary projects, we cannot make similar observations.
Therefore, we cannot claim that CI is the `silver bullet' for software
development.
  Why is this so? Our findings indicate that only adoption of CI might not be
enough to improve software development. CI can be effective for software
development if practitioners use CI's feedback mechanism efficiently, by
applying the practice of making frequent commits. For proprietary projects we
observe practitioners to commit less frequently, and hence not use CI
effectively, for obtaining feedback on the submitted code changes. We recommend
practitioners to (i) apply the CI best practices along with adoption of CI
tools, (ii) consider their team's development context before adopting CI tools,
and (iii) after adoption of CI, investigate if CI satisfies their needs by
applying software analytics.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03936</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consensus in the Age of Blockchains</dc:title>
 <dc:creator>Bano, Shehar</dc:creator>
 <dc:creator>Sonnino, Alberto</dc:creator>
 <dc:creator>Al-Bassam, Mustafa</dc:creator>
 <dc:creator>Azouvi, Sarah</dc:creator>
 <dc:creator>McCorry, Patrick</dc:creator>
 <dc:creator>Meiklejohn, Sarah</dc:creator>
 <dc:creator>Danezis, George</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The blockchain initially gained traction in 2008 as the technology underlying
bitcoin, but now has been employed in a diverse range of applications and
created a global market worth over $150B as of 2017. What distinguishes
blockchains from traditional distributed databases is the ability to operate in
a decentralized setting without relying on a trusted third party. As such their
core technical component is consensus: how to reach agreement among a group of
nodes. This has been extensively studied already in the distributed systems
community for closed systems, but its application to open blockchains has
revitalized the field and led to a plethora of new designs.
  The inherent complexity of consensus protocols and their rapid and dramatic
evolution makes it hard to contextualize the design landscape. We address this
challenge by conducting a systematic and comprehensive study of blockchain
consensus protocols. After first discussing key themes in classical consensus
protocols, we describe: first protocols based on proof-of-work (PoW), second
proof-of-X (PoX) protocols that replace PoW with more energy-efficient
alternatives, and third hybrid protocols that are compositions or variations of
classical consensus protocols. We develop a framework to evaluate their
performance, security and design properties, and use it to systematize key
themes in the protocol categories described above. This evaluation leads us to
identify research gaps and challenges for the community to consider in future
research endeavours.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03937</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerated Method for Stochastic Composition Optimization with
  Nonsmooth Regularization</dc:title>
 <dc:creator>Huo, Zhouyuan</dc:creator>
 <dc:creator>Gu, Bin</dc:creator>
 <dc:creator>Liu, Ji</dc:creator>
 <dc:creator>Huang, Heng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Stochastic composition optimization draws much attention recently and has
been successful in many emerging applications of machine learning, statistical
analysis, and reinforcement learning. In this paper, we focus on the
composition problem with nonsmooth regularization penalty. Previous works
either have slow convergence rate or do not provide complete convergence
analysis for the general problem. In this paper, we tackle these two issues by
proposing a new stochastic composition optimization method for composition
problem with nonsmooth regularization penalty. In our method, we apply variance
reduction technique to accelerate the speed of convergence. To the best of our
knowledge, our method admits the fastest convergence rate for stochastic
composition optimization: for strongly convex composition problem, our
algorithm is proved to admit linear convergence; for general composition
problem, our algorithm significantly improves the state-of-the-art convergence
rate from $O(T^{-1/2})$ to $O((n_1+n_2)^{{2}/{3}}T^{-1})$. Finally, we apply
our proposed algorithm to portfolio management and policy evaluation in
reinforcement learning. Experimental results verify our theoretical analysis.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03937</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03938</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CARLA: An Open Urban Driving Simulator</dc:title>
 <dc:creator>Dosovitskiy, Alexey</dc:creator>
 <dc:creator>Ros, German</dc:creator>
 <dc:creator>Codevilla, Felipe</dc:creator>
 <dc:creator>Lopez, Antonio</dc:creator>
 <dc:creator>Koltun, Vladlen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We introduce CARLA, an open-source simulator for autonomous driving research.
CARLA has been developed from the ground up to support development, training,
and validation of autonomous urban driving systems. In addition to open-source
code and protocols, CARLA provides open digital assets (urban layouts,
buildings, vehicles) that were created for this purpose and can be used freely.
The simulation platform supports flexible specification of sensor suites and
environmental conditions. We use CARLA to study the performance of three
approaches to autonomous driving: a classic modular pipeline, an end-to-end
model trained via imitation learning, and an end-to-end model trained via
reinforcement learning. The approaches are evaluated in controlled scenarios of
increasing difficulty, and their performance is examined via metrics provided
by CARLA, illustrating the platform's utility for autonomous driving research.
The supplementary video can be viewed at https://youtu.be/Hp8Dz-Zek2E
</dc:description>
 <dc:description>Comment: Published at the 1st Conference on Robot Learning (CoRL)</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03941</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What, When and Where to Cache: A Unified Optimization Approach</dc:title>
 <dc:creator>Panigrahy, Nitish K.</dc:creator>
 <dc:creator>Li, Jian</dc:creator>
 <dc:creator>Zafari, Faheem</dc:creator>
 <dc:creator>Towsley, Don</dc:creator>
 <dc:creator>Yu, Paul</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Caching algorithms are usually described by the eviction method and analyzed
using a metric of hit probability. Since contents have different importance
(e.g. popularity), the utility of a high hit probability, and the cost of
transmission can vary across contents. In this paper, we consider timer-based
(TTL) policies across a cache network, where contents have differentiated
timers over which we optimize. Each content is associated with a utility
measured in terms of the corresponding hit probability. We start our analysis
from a linear cache network: we propose a utility maximization problem where
the objective is to maximize the sum of utilities and a cost minimization
problem where the objective is to minimize the content transmission cost across
the network. These frameworks enable us to design online algorithms for cache
management, for which we prove achieving optimal performance. Informed by the
results of our analysis, we formulate a non-convex optimization problem for a
general cache network. We show that the duality gap is zero, hence we can
develop a distributed iterative primal-dual algorithm for content management in
the network. Finally, we consider two applications of our cache network model:
(i) directly mapping to content distribution and (ii) generalization to
wireless sensor network by jointly considering content caching and content
compression. We characterize the tradeoff among caching, compression and
communication via a nonlinear non-convex optimization problem. We show that it
can be transformed into an equivalent convex problem. The obtained numerical
results provide us with insights into how to optimize the performance.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03946</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Paragraph Vectors</dc:title>
 <dc:creator>Ji, Geng</dc:creator>
 <dc:creator>Bamler, Robert</dc:creator>
 <dc:creator>Sudderth, Erik B.</dc:creator>
 <dc:creator>Mandt, Stephan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Word2vec (Mikolov et al., 2013) has proven to be successful in natural
language processing by capturing the semantic relationships between different
words. Built on top of single-word embeddings, paragraph vectors (Le and
Mikolov, 2014) find fixed-length representations for pieces of text with
arbitrary lengths, such as documents, paragraphs, and sentences. In this work,
we propose a novel interpretation for neural-network-based paragraph vectors by
developing an unsupervised generative model whose maximum likelihood solution
corresponds to traditional paragraph vectors. This probabilistic formulation
allows us to go beyond point estimates of parameters and to perform Bayesian
posterior inference. We find that the entropy of paragraph vectors decreases
with the length of documents, and that information about posterior uncertainty
improves performance in supervised learning tasks such as sentiment analysis
and paraphrase detection.
</dc:description>
 <dc:description>Comment: Presented at the NIPS 2017 workshop &quot;Advances in Approximate Bayesian
  Inference&quot;</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03947</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Analysis of Executables to Detect and Characterize Malware</dc:title>
 <dc:creator>Smith, Michael R.</dc:creator>
 <dc:creator>Ingram, Joe B.</dc:creator>
 <dc:creator>Lamb, Christopher C.</dc:creator>
 <dc:creator>Draelos, Timothy J.</dc:creator>
 <dc:creator>Doak, Justin E.</dc:creator>
 <dc:creator>Aimone, James B.</dc:creator>
 <dc:creator>James, Conrad D.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  It is needed to ensure the integrity of systems that process sensitive
information and control many aspects of everyday life. We examine the use of
machine learning algorithms to detect malware using the system calls generated
by executables-alleviating attempts at obfuscation as the behavior is monitored
rather than the bytes of an executable. We examine several machine learning
techniques for detecting malware including random forests, deep learning
techniques, and liquid state machines. The experiments examine the effects of
concept drift on each algorithm to understand how well the algorithms
generalize to novel malware samples by testing them on data that was collected
after the training data. The results suggest that each of the examined machine
learning algorithms is a viable solution to detect malware-achieving between
90% and 95% class-averaged accuracy (CAA). In real-world scenarios, the
performance evaluation on an operational network may not match the performance
achieved in training. Namely, the CAA may be about the same, but the values for
precision and recall over the malware can change significantly. We structure
experiments to highlight these caveats and offer insights into expected
performance in operational environments. In addition, we use the induced models
to gain a better understanding about what differentiates the malware samples
from the goodware, which can further be used as a forensics tool to understand
what the malware (or goodware) was doing to provide directions for
investigation and remediation.
</dc:description>
 <dc:description>Comment: 9 pages, 6 Tables, 4 Figures</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03948</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Manipulative Elicitation -- A New Attack on Elections with Incomplete
  Preferences</dc:title>
 <dc:creator>Dey, Palash</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Lu and Boutilier proposed a novel approach based on &quot;minimax regret&quot; to use
classical score based voting rules in the setting where preferences can be any
partial (instead of complete) orders over the set of alternatives. We show here
that such an approach is vulnerable to a new kind of manipulation which was not
present in the classical (where preferences are complete orders) world of
voting. We call this attack &quot;manipulative elicitation.&quot; More specifically, it
may be possible to (partially) elicit the preferences of the agents in a way
that makes some distinguished alternative win the election who may not be a
winner if we elicit every preference completely. More alarmingly, we show that
the related computational task is polynomial time solvable for a large class of
voting rules which includes all scoring rules, maximin, Copeland$^\alpha$ for
every $\alpha\in[0,1]$, simplified Bucklin voting rules, etc. We then show that
introducing a parameter per pair of alternatives which specifies the minimum
number of partial preferences where this pair of alternatives must be
comparable makes the related computational task of manipulative elicitation
\NPC for all common voting rules including a class of scoring rules which
includes the plurality, $k$-approval, $k$-veto, veto, and Borda voting rules,
maximin, Copeland$^\alpha$ for every $\alpha\in[0,1]$, and simplified Bucklin
voting rules. Hence, in this work, we discover a fundamental vulnerability in
using minimax regret based approach in partial preferential setting and propose
a novel way to tackle it.
</dc:description>
 <dc:description>Comment: To appear in AAAI 2018</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03951</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Chroma from Luma in AV1</dc:title>
 <dc:creator>Trudeau, Luc N.</dc:creator>
 <dc:creator>Egge, Nathan E.</dc:creator>
 <dc:creator>Barr, David</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Chroma from luma (CfL) prediction is a new and promising chroma-only intra
predictor that models chroma pixels as a linear function of the coincident
reconstructed luma pixels. In this paper, we present the CfL predictor adopted
in Alliance Video 1 (AV1), a royalty-free video codec developed by the Alliance
for Open Media (AOM). The proposed CfL distinguishes itself from prior art not
only by reducing decoder complexity, but also by producing more accurate
predictions. On average, CfL reduces the BD-rate, when measured with CIEDE2000,
by 5% for still images and 2% for video sequences.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03952</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verifiable Light-Weight Monitoring for Certificate Transparency Logs</dc:title>
 <dc:creator>Dahlberg, Rasmus</dc:creator>
 <dc:creator>Pulls, Tobias</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Trust in publicly verifiable Certificate Transparency (CT) logs is reduced
through cryptography, gossip, auditing, and monitoring. The role of a monitor
is to observe each and every log entry, looking for suspicious certificates
that interest the entity running the monitor. While anyone can run a monitor,
it requires continuous operation and copies of the logs to be inspected. This
has lead to the emergence of monitoring-as-a-service: a trusted party runs the
monitor and provides registered subjects with selective certificate
notifications, e.g., &quot;notify me of all foo.com certificates&quot;. We present a
CT/bis extension for verifiable light-weight monitoring that enables subjects
to verify the correctness of such notifications, reducing the trust that is
placed in these monitors. Our extension supports verifiable monitoring of
wild-card domains and piggybacks on CT's existing gossip-audit security model.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03953</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Breaking the Softmax Bottleneck: A High-Rank RNN Language Model</dc:title>
 <dc:creator>Yang, Zhilin</dc:creator>
 <dc:creator>Dai, Zihang</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:creator>Cohen, William W.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We formulate language modeling as a matrix factorization problem, and show
that the expressiveness of Softmax-based models (including the majority of
neural language models) is limited by a Softmax bottleneck. Given that natural
language is highly context-dependent, this further implies that in practice
Softmax with distributed word embeddings does not have enough capacity to model
natural language. We propose a simple and effective method to address this
issue, and improve the state-of-the-art perplexities on Penn Treebank and
WikiText-2 to 47.69 and 40.68 respectively.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03954</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EddyNet: A Deep Neural Network For Pixel-Wise Classification of Oceanic
  Eddies</dc:title>
 <dc:creator>Lguensat, Redouane</dc:creator>
 <dc:creator>Sun, Miao</dc:creator>
 <dc:creator>Fablet, Ronan</dc:creator>
 <dc:creator>Mason, Evan</dc:creator>
 <dc:creator>Tandeo, Pierre</dc:creator>
 <dc:creator>Chen, Ge</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Atmospheric and Oceanic Physics</dc:subject>
 <dc:description>  This work presents EddyNet, a deep learning based architecture for automated
eddy detection and classification from Sea Surface Height (SSH) maps provided
by the Copernicus Marine and Environment Monitoring Service (CMEMS). EddyNet is
a U-Net like network that consists of a convolutional encoder-decoder followed
by a pixel-wise classification layer. The output is a map with the same size of
the input where pixels have the following labels \{'0': Non eddy, '1':
anticyclonic eddy, '2': cyclonic eddy\}. We investigate the use of SELU
activation function instead of the classical ReLU+BN and we use an overlap
based loss function instead of the cross entropy loss. Keras Python code, the
training datasets and EddyNet weights files are open-source and freely
available on https://github.com/redouanelg/EddyNet.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03955</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>StreetX: Spatio-Temporal Access Control Model for Data</dc:title>
 <dc:creator>Sandha, Sandeep Singh</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Cities are a big source of spatio-temporal data that is shared across
entities to drive potential use cases. Many of the Spatio-temporal datasets are
confidential and are selectively shared. To allow selective sharing, several
access control models exist, however user cannot express arbitrary space and
time constraints on data attributes using them. In this paper we focus on
spatio-temporal access control model. We show that location and time attributes
of data may decide its confidentiality via a motivating example and thus can
affect user's access control policy. In this paper, we present StreetX which
enables user to represent constraints on multiple arbitrary space regions and
time windows using a simple abstract language. StreetX is scalable and is
designed to handle large amount of spatio-temporal data from multiple users.
Multiple space and time constraints can affect performance of the query and may
also result in conflicts. StreetX automatically resolve conflicts and optimizes
the query evaluation with access control to improve performance. We implemented
and tested prototype of StreetX using space constraints by defining region
having 1749 polygon coordinates on 10 million data records. Our testing shows
that StreetX extends the current access control with spatio-temporal
capabilities.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03961</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Efficiency and Asymptotic Performance Evaluation of Beamforming
  Structures in Doubly Massive MIMO mmWave Systems</dc:title>
 <dc:creator>Buzzi, Stefano</dc:creator>
 <dc:creator>D'Andrea, Carmen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Future cellular systems based on the use of millimeter waves will heavily
rely on the use of antenna arrays both at the transmitter and at the receiver.
For complexity reasons and energy consumption issues, fully digital precoding
and postcoding structures may turn out to be unfeasible, and thus suboptimal
structures, making use of simplified hardware and a limited number of RF
chains, have been investigated. This paper considers and makes a comparative
assessment, both from a spectral efficiency and energy efficiency point of
view, of several suboptimal precoding and postcoding beamforming structures for
a cellular multiuser MIMO (MU-MIMO) system with large number of antennas.
Analytical formulas for the asymptotic achievable spectral efficiency and for
the global energy efficiency of several beamforming structures are derived in
the large number of antennas regime. Using the most recently available data for
the energy consumption of phase shifters and switches, we show that
fully-digital beamformers may actually achieve a larger energy efficiency than
lower-complexity solutions, as well as that low-complexity beam-steering purely
analog beamforming may in some cases represent a good performance-complexity
trade-off solution.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Green Communications and Networking</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03966</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-agent based IoT smart waste monitoring and collection architecture</dc:title>
 <dc:creator>Likotiko, Eunice David</dc:creator>
 <dc:creator>Nyambo, Devotha</dc:creator>
 <dc:creator>Mwangoka, Joseph</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Solid waste management is one of the existing challenges in urban areas and
it is becoming a critical issue due to rapid increase in population.
Appropriate solid waste management systems are important for improving the
environment and the well being of residents. In this paper, an Internet of
Things (IoT) architecture for real time waste monitoring and collection has
been proposed; able to improve and optimize solid waste collection in a city.
Netlogo Multiagent platform has been used to simulate real time monitoring and
smart decisions on waste management. Waste filling level in bins and truck
collection process are abstracted to a multiagent model and citizen are
involved by paying the price for waste collection services. Furthermore, waste
level data are updated and recorded continuously and are provided to decision
algorithms to determine the vehicle optimal route for waste collection to the
distributed bins in the city. Several simulation cases executed and results
validated. The presented solution gives substantial benefits to all waste
stakeholders by enabling the waste collection process to be more efficient.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03985</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applications of Deep Learning and Reinforcement Learning to Biological
  Data</dc:title>
 <dc:creator>Mahmud, Mufti</dc:creator>
 <dc:creator>Kaiser, M. Shamim</dc:creator>
 <dc:creator>Hussain, Amir</dc:creator>
 <dc:creator>Vassanelli, Stefano</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>A.1, I.2, I.5, J.3</dc:subject>
 <dc:description>  Rapid advances of hardware-based technologies during the past decades have
opened up new possibilities for Life scientists to gather multimodal data in
various application domains (e.g., Omics, Bioimaging, Medical Imaging, and
[Brain/Body]-Machine Interfaces), thus generating novel opportunities for
development of dedicated data intensive machine learning techniques. Overall,
recent research in Deep learning (DL), Reinforcement learning (RL), and their
combination (Deep RL) promise to revolutionize Artificial Intelligence. The
growth in computational power accompanied by faster and increased data storage
and declining computing costs have already allowed scientists in various fields
to apply these techniques on datasets that were previously intractable for
their size and complexity. This review article provides a comprehensive survey
on the application of DL, RL, and Deep RL techniques in mining Biological data.
In addition, we compare performances of DL techniques when applied to different
datasets across various application domains. Finally, we outline open issues in
this challenging research area and discuss future development perspectives.
</dc:description>
 <dc:description>Comment: 33 pages, 5 figures, 1 table, survey paper, IEEE Trans. Neural Netw.
  Learn. Syst., 2018</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03985</dc:identifier>
 <dc:identifier>doi:10.1109/TNNLS.2018.2790388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03987</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimised Maintenance of Datalog Materialisations</dc:title>
 <dc:creator>Hu, Pan</dc:creator>
 <dc:creator>Motik, Boris</dc:creator>
 <dc:creator>Horrocks, Ian</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  To efficiently answer queries, datalog systems often materialise all
consequences of a datalog program, so the materialisation must be updated
whenever the input facts change. Several solutions to the materialisation
update problem have been proposed. The Delete/Rederive (DRed) and the
Backward/Forward (B/F) algorithms solve this problem for general datalog, but
both contain steps that evaluate rules 'backwards' by matching their heads to a
fact and evaluating the partially instantiated rule bodies as queries. We show
that this can be a considerable source of overhead even on very small updates.
In contrast, the Counting algorithm does not evaluate the rules 'backwards',
but it can handle only nonrecursive rules. We present two hybrid approaches
that combine DRed and B/F with Counting so as to reduce or even eliminate
'backward' rule evaluation while still handling arbitrary datalog programs. We
show empirically that our hybrid algorithms are usually significantly faster
than existing approaches, sometimes by orders of magnitude.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03989</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Characterization of Mobility Management in User-centric Networks</dc:title>
 <dc:creator>Nascimento, Andrea</dc:creator>
 <dc:creator>Sofia, Rute</dc:creator>
 <dc:creator>Condeixa, Tiago</dc:creator>
 <dc:creator>Sargento, Susana</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Mobility management is a key aspect to consider in future Internet
architectures, as these architectures include a highly nomadic end-user which
often relies on services provided by multi-access networks. In contrast,
today's mobility management solutions were designed having in mind simpler
scenarios and requirements from the network and where roaming could often be
taken care of with previously established agreements. With a more dynamic
behavior in the network, and also with a more prominent role from the end-user,
mobility management has to deal with additional requirements derived from new
Internet paradigms. To assist in understanding such requirements and also how
to deal with them, this paper proposes a starting point to dismantle current
mobility management notions. Our contribution is an initial proposal on
defining mobility management in concrete functional blocks, their interaction,
as well as a potential grouping which later can assist in deriving novel and
more flexible mobility management architectures.
</dc:description>
 <dc:description>Comment: New2AN 2011</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03989</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-642-22875-9_29</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03990</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Longitudinal Study of Child Face Recognition</dc:title>
 <dc:creator>Deb, Debayan</dc:creator>
 <dc:creator>Nain, Neeta</dc:creator>
 <dc:creator>Jain, Anil K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a longitudinal study of face recognition performance on Children
Longitudinal Face (CLF) dataset containing 3,682 face images of 919 subjects,
in the age group [2, 18] years. Each subject has at least four face images
acquired over a time span of up to six years. Face comparison scores are
obtained from (i) a state-of-the-art COTS matcher (COTS-A), (ii) an open-source
matcher (FaceNet), and (iii) a simple sum fusion of scores obtained from COTS-A
and FaceNet matchers. To improve the performance of the open-source FaceNet
matcher for child face recognition, we were able to fine-tune it on an
independent training set of 3,294 face images of 1,119 children in the age
group [3, 18] years. Multilevel statistical models are fit to genuine
comparison scores from the CLF dataset to determine the decrease in face
recognition accuracy over time. Additionally, we analyze both the verification
and open-set identification accuracies in order to evaluate state-of-the-art
face recognition technology for tracing and identifying children lost at a
young age as victims of child trafficking or abduction.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03993</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A superpolynomial lower bound for the size of non-deterministic
  complement of an unambiguous automaton</dc:title>
 <dc:creator>Raskin, Michael</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Unambiguous non-deterministic finite automata have intermediate expressive
power and succinctness between deterministic and non-deterministic automata.
  It has been conjectured that every unambiguous non-deterministic one-way
finite automaton (1UFA) recognizing some language L can be converted into a
1UFA recognizing the complement of the original language L with polynomial
increase in the number of states.
  We disprove this conjecture by presenting a family of 1UFAs on a
single-letter alphabet such that recognizing the complements of the
corresponding languages requires superpolynomial increase in the number of
states even for generic non-deterministic one-way finite automata.
  We also note that both the languages and their complements can be recognized
by sweeping deterministic automata with a linear increase in the number of
states.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.03993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04001</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Migration of Hierarchical Data to Relational Tables using
  Programming-by-Example</dc:title>
 <dc:creator>Yaghmazadeh, Navid</dc:creator>
 <dc:creator>Wang, Xinyu</dc:creator>
 <dc:creator>Dillig, Isil</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  While many applications export data in hierarchical formats like XML and
JSON, it is often necessary to convert such hierarchical documents to a
relational representation. This paper presents a novel programming-by-example
approach, and its implementation in a tool called Mitra, for automatically
migrating tree-structured documents to relational tables. We have evaluated the
proposed technique using two sets of experiments. In the first experiment, we
used Mitra to automate 98 data transformation tasks collected from
StackOverflow. Our method can generate the desired program for 94% of these
benchmarks with an average synthesis time of 3.8 seconds. In the second
experiment, we used Mitra to generate programs that can convert real-world XML
and JSON datasets to full-fledged relational databases. Our evaluation shows
that Mitra can automate the desired transformation for all datasets.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04013</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stream Reasoning in Temporal Datalog</dc:title>
 <dc:creator>Ronca, Alessandro</dc:creator>
 <dc:creator>Kaminski, Mark</dc:creator>
 <dc:creator>Grau, Bernardo Cuenca</dc:creator>
 <dc:creator>Motik, Boris</dc:creator>
 <dc:creator>Horrocks, Ian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  In recent years, there has been an increasing interest in extending
traditional stream processing engines with logical, rule-based, reasoning
capabilities. This poses significant theoretical and practical challenges since
rules can derive new information and propagate it both towards past and future
time points; as a result, streamed query answers can depend on data that has
not yet been received, as well as on data that arrived far in the past. Stream
reasoning algorithms, however, must be able to stream out query answers as soon
as possible, and can only keep a limited number of previous input facts in
memory. In this paper, we propose novel reasoning problems to deal with these
challenges, and study their computational properties on Datalog extended with a
temporal sort and the successor function (a core rule-based language for stream
reasoning applications).
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04015</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WMRB: Learning to Rank in a Scalable Batch Training Approach</dc:title>
 <dc:creator>Liu, Kuan</dc:creator>
 <dc:creator>Natarajan, Prem</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a new learning to rank algorithm, named Weighted Margin-Rank Batch
loss (WMRB), to extend the popular Weighted Approximate-Rank Pairwise loss
(WARP). WMRB uses a new rank estimator and an efficient batch training
algorithm. The approach allows more accurate item rank approximation and
explicit utilization of parallel computation to accelerate training. In three
item recommendation tasks, WMRB consistently outperforms WARP and other
baselines. Moreover, WMRB shows clear time efficiency advantages as data scale
increases.
</dc:description>
 <dc:description>Comment: RecSys 2017 Poster Proceedings, August 27-31, Como, Italy</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04019</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Batch Learning Framework for Scalable Personalized Ranking</dc:title>
 <dc:creator>Liu, Kuan</dc:creator>
 <dc:creator>Natarajan, Prem</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In designing personalized ranking algorithms, it is desirable to encourage a
high precision at the top of the ranked list. Existing methods either seek a
smooth convex surrogate for a non-smooth ranking metric or directly modify
updating procedures to encourage top accuracy. In this work we point out that
these methods do not scale well to a large-scale setting, and this is partly
due to the inaccurate pointwise or pairwise rank estimation. We propose a new
framework for personalized ranking. It uses batch-based rank estimators and
smooth rank-sensitive loss functions. This new batch learning framework leads
to more stable and accurate rank approximations compared to previous work.
Moreover, it enables explicit use of parallel computation to speed up training.
We conduct empirical evaluation on three item recommendation tasks. Our method
shows consistent accuracy improvements over state-of-the-art methods.
Additionally, we observe time efficiency advantages when data scale increases.
</dc:description>
 <dc:description>Comment: AAAI 2018, Feb 2-7, New Orleans, USA</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04022</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Within-Class Covariance Analysis for Acoustic Scene Classification</dc:title>
 <dc:creator>Eghbal-zadeh, Hamid</dc:creator>
 <dc:creator>Dorfer, Matthias</dc:creator>
 <dc:creator>Widmer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Within-Class Covariance Normalization (WCCN) is a powerful post-processing
method for normalizing the within-class covariance of a set of data points.
WCCN projects the observations into a linear sub-space where the within-class
variability is reduced. This property has proven to be beneficial in subsequent
recognition tasks. The central idea of this paper is to reformulate the classic
WCCN as a Deep Neural Network (DNN) compatible version. We propose the Deep
WithinClass Covariance Analysis (DWCCA) which can be incorporated in a DNN
architecture. This formulation enables us to exploit the beneficial properties
of WCCN, and still allows for training with Stochastic Gradient Descent (SGD)
in an end-to-end fashion. We investigate the advantages of DWCCA on deep neural
networks with convolutional layers for supervised learning. Our results on
Acoustic Scene Classification show that via DWCCA we can achieves equal or
superior performance in a VGG-style deep neural network.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04024</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How fragile are information cascades?</dc:title>
 <dc:creator>Peres, Yuval</dc:creator>
 <dc:creator>Racz, Miklos Z.</dc:creator>
 <dc:creator>Sly, Allan</dc:creator>
 <dc:creator>Stuhl, Izabella</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Economics - Econometrics</dc:subject>
 <dc:description>  It is well known that sequential decision making may lead to information
cascades. That is, when agents make decisions based on their private
information, as well as observing the actions of those before them, then it
might be rational to ignore their private signal and imitate the action of
previous individuals. If the individuals are choosing between a right and a
wrong state, and the initial actions are wrong, then the whole cascade will be
wrong. This issue is due to the fact that cascades can be based on very little
information.
  We show that if agents occasionally disregard the actions of others and base
their action only on their private information, then wrong cascades can be
avoided. Moreover, we study the optimal asymptotic rate at which the error
probability at time $t$ can go to zero. The optimal policy is for the player at
time $t$ to follow their private information with probability $p_{t} = c/t$,
leading to a learning rate of $c'/t$, where the constants $c$ and $c'$ are
explicit.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04025</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cloud Computing and Content Management Systems: A Case Study in
  Macedonian Education</dc:title>
 <dc:creator>Jankulovski, Jove</dc:creator>
 <dc:creator>Mitrevski, Pece</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Technologies have become inseparable of our lives, economy, and the society
as a whole. For example, clouds provide numerous computing resources that can
facilitate our lives, whereas the Content Management Systems (CMSs) can provide
the right content for the right user. Thus, education must embrace these
emerging technologies in order to prepare citizens for the 21st century. The
research explored 'if' and 'how' Cloud Computing influences the application of
CMSs, and 'if' and 'how' it fosters the usage of mobile technologies to access
cloud resources. The analyses revealed that some of the respondents have sound
experience in using clouds and in using CMSs. Nevertheless, it was evident that
significant number of respondents have limited or no experience in cloud
computing concepts, cloud security and CMSs, as well. Institutions of the
system should update educational policies in order to enable education
innovation, provide means and support, and continuously update/upgrade
educational infrastructure.
</dc:description>
 <dc:description>Comment: 13 pages, 5 figures, 10 tables</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04025</dc:identifier>
 <dc:identifier>International Journal on Cloud Computing: Services and
  Architecture (IJCCSA) Vol. 7, No. 5, October 2017</dc:identifier>
 <dc:identifier>doi:10.5121/ijccsa.2017.7501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04029</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing TCP Goodput and Delay in next generation IEEE 802.11 (ax)
  devices</dc:title>
 <dc:creator>Sharon, Oran</dc:creator>
 <dc:creator>Alpert, Yaron</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper we suggest three scheduling strategies for the IEEE 802.11ax
transmis- sion of DL unidirectional TCP data from the Access Point to stations.
Two strategies are based on the Single User operation mode and one is based on
the Multi User operation mode, using Multi User Multiple-Input-Multiple-Output
(MU-MIMO) and OFDMA. We measure the Goodput of the system as a function of the
time intervals over which these Goodputs are received in all three strategies.
For up to 8 stations the MU strategy outperforms the SU. For 16 and 32 stations
it is not clear whether MU outperforms SU or vice versa. For 64 stations the SU
strategies outperform the MU significantly. We also checked the influence of
the Delayed Acks feature on the received Goodputs and found that this feature
has significance only when the TCP data segments are relatively short.
</dc:description>
 <dc:description>Comment: 37 pages, 9 figures</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04030</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ocasta: Clustering Configuration Settings For Error Recovery</dc:title>
 <dc:creator>Huang, Zhen</dc:creator>
 <dc:creator>Lie, David</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:subject>B.8.1</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:description>  Effective machine-aided diagnosis and repair of configuration errors
continues to elude computer systems designers. Most of the literature targets
errors that can be attributed to a single erroneous configuration setting.
However, a recent study found that a significant amount of configuration errors
require fixing more than one setting together. To address this limitation,
Ocasta statistically clusters dependent configuration settings based on the
application's accesses to its configuration settings and utilizes the extracted
clustering of configuration settings to fix configuration errors involving more
than one configuration settings. Ocasta treats applications as black-boxes and
only relies on the ability to observe application accesses to their
configuration settings.
  We collected traces of real application usage from 24 Linux and 5 Windows
desktops computers and found that Ocasta is able to correctly identify clusters
with 88.6% accuracy. To demonstrate the effectiveness of Ocasta, we evaluated
it on 16 real-world configuration errors of 11 Linux and Windows applications.
Ocasta is able to successfully repair all evaluated configuration errors in 11
minutes on average and only requires the user to examine an average of 3
screenshots of the output of the application to confirm that the error is
repaired. A user study we conducted shows that Ocasta is easy to use by both
expert and non-expert users and is more efficient than manual configuration
error troubleshooting.
</dc:description>
 <dc:description>Comment: Published in Proceedings of the 44th Annual IEEE/IFIP International
  Conference on Dependable Systems and Networks (DSN 2014)</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04030</dc:identifier>
 <dc:identifier>44th Annual IEEE/IFIP International Conference on Dependable
  Systems and Networks, 2014, pages={479-490}</dc:identifier>
 <dc:identifier>doi:10.1109/DSN.2014.51</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04036</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Physiological and behavioral profiling for nociceptive pain estimation
  using personalized multitask learning</dc:title>
 <dc:creator>Lopez-Martinez, Daniel</dc:creator>
 <dc:creator>Rudovic, Ognjen</dc:creator>
 <dc:creator>Picard, Rosalind</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Pain is a subjective experience commonly measured through patient's self
report. While there exist numerous situations in which automatic pain
estimation methods may be preferred, inter-subject variability in physiological
and behavioral pain responses has hindered the development of such methods. In
this work, we address this problem by introducing a novel personalized
multitask machine learning method for pain estimation based on individual
physiological and behavioral pain response profiles, and show its advantages in
a dataset containing multimodal responses to nociceptive heat pain.
</dc:description>
 <dc:description>Comment: NIPS Machine Learning for Health 2017</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04040</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anytime Motion Planning on Large Dense Roadmaps with Expensive Edge
  Evaluations</dc:title>
 <dc:creator>Choudhury, Shushman</dc:creator>
 <dc:creator>Salzman, Oren</dc:creator>
 <dc:creator>Choudhury, Sanjiban</dc:creator>
 <dc:creator>Dellin, Christopher M.</dc:creator>
 <dc:creator>Srinivasa, Siddhartha S.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We propose an algorithmic framework for efficient anytime motion planning on
large dense geometric roadmaps, in domains where collision checks and therefore
edge evaluations are computationally expensive. A large dense roadmap (graph)
can typically ensure the existence of high quality solutions for most
motion-planning problems, but the size of the roadmap, particularly in
high-dimensional spaces, makes existing search-based planning algorithms
computationally expensive. We deal with the challenges of expensive search and
collision checking in two ways. First, we frame the problem of anytime motion
planning on roadmaps as searching for the shortest path over a sequence of
subgraphs of the entire roadmap graph, generated by some densification
strategy. This lets us achieve bounded sub-optimality with bounded worst-case
planning effort. Second, for searching each subgraph, we develop an anytime
planning algorithm which uses a belief model to compute the collision
probability of unknown configurations and searches for paths that are
Pareto-optimal in path length and collision probability. This algorithm is
efficient with respect to collision checks as it searches for successively
shorter paths. We theoretically analyze both our ideas and evaluate them
individually on high-dimensional motion-planning problems. Finally, we apply
both of these ideas together in our algorithmic framework for anytime motion
planning, and show that it outperforms BIT* on high-dimensional hypercube
problems.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04043</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Few-Shot Learning with Graph Neural Networks</dc:title>
 <dc:creator>Garcia, Victor</dc:creator>
 <dc:creator>Bruna, Joan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose to study the problem of few-shot learning with the prism of
inference on a partially observed graphical model, constructed from a
collection of input images whose label can be either observed or not. By
assimilating generic message-passing inference algorithms with their
neural-network counterparts, we define a graph neural network architecture that
generalizes several of the recently proposed few-shot learning models. Besides
providing improved numerical performance, our framework is easily extended to
variants of few-shot learning, such as semi-supervised or active learning,
demonstrating the ability of graph-based models to operate well on 'relational'
tasks.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04044</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Representation for Natural Language Processing via Kernelized
  Hashcodes</dc:title>
 <dc:creator>Garg, Sahil</dc:creator>
 <dc:creator>Galstyan, Aram</dc:creator>
 <dc:creator>Rish, Irina</dc:creator>
 <dc:creator>Cecchi, Guillermo</dc:creator>
 <dc:creator>Gao, Shuyang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Kernel similarity functions have been successfully applied in classification
models such as Support Vector Machines, Gaussian Processes and k-Nearest
Neighbors (kNN), but found to be computationally expensive for Natural Language
Processing (NLP) tasks due to the cost of computing kernel similarities between
discrete natural language structures. A well-known technique, Kernelized
Locality Sensitive Hashing (KLSH), allows for an approximate computation of kNN
graphs and significantly reduces the number of kernel computations; however,
applying KLSH to other classifiers have not been explored. In this paper, we
propose to use random subspaces of KLSH codes for constructing an efficient
representation that preserves fine-grained structure of the data and is
suitable for general classification methods. Further, we proposed an approach
for optimizing KLSH model for supervised classification problems, by maximizing
a variational lower bound on the mutual information between the KLSH codes
(feature vectors) and the class labels.We apply the proposed approach to the
task of extracting information about bio-molecular interactions from the
semantic parsing of scientific papers. Our empirical results on a variety of
datasets demonstrate significant improvements over the state of the art.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04047</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepKSPD: Learning Kernel-matrix-based SPD Representation for
  Fine-grained Image Recognition</dc:title>
 <dc:creator>Engin, Melih</dc:creator>
 <dc:creator>Wang, Lei</dc:creator>
 <dc:creator>Zhou, Luping</dc:creator>
 <dc:creator>Liu, Xinwang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Being symmetric positive-definite (SPD), covariance matrix has traditionally
been used to represent a set of local descriptors in visual recognition. Recent
study shows that kernel matrix can give considerably better representation by
modelling the nonlinearity in the local descriptor set. Nevertheless, neither
the descriptors nor the kernel matrix is deeply learned. Worse, they are
considered separately, hindering the pursuit of an optimal SPD representation.
This work proposes a deep network that jointly learns local descriptors,
kernel-matrix-based SPD representation, and the classifier via an end-to-end
training process. We derive the derivatives for the mapping from a local
descriptor set to the SPD representation to carry out backpropagation. Also, we
exploit the Daleckii-Krein formula in operator theory to give a concise and
unified result on differentiating SPD matrix functions, including the matrix
logarithm to handle the Riemannian geometry of kernel matrix. Experiments not
only show the superiority of kernel-matrix-based SPD representation with deep
local descriptors, but also verify the advantage of the proposed deep network
in pursuing better SPD representations for fine-grained image recognition
tasks.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04048</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CT-SRCNN: Cascade Trained and Trimmed Deep Convolutional Neural Networks
  for Image Super Resolution</dc:title>
 <dc:creator>Ren, Haoyu</dc:creator>
 <dc:creator>El-Khamy, Mostafa</dc:creator>
 <dc:creator>Lee, Jungwon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose methodologies to train highly accurate and efficient deep
convolutional neural networks (CNNs) for image super resolution (SR). A cascade
training approach to deep learning is proposed to improve the accuracy of the
neural networks while gradually increasing the number of network layers. Next,
we explore how to improve the SR efficiency by making the network slimmer. Two
methodologies, the one-shot trimming and the cascade trimming, are proposed.
With the cascade trimming, the network's size is gradually reduced layer by
layer, without significant loss on its discriminative ability. Experiments on
benchmark image datasets show that our proposed SR network achieves the
state-of-the-art super resolution accuracy, while being more than 4 times
faster compared to existing deep super resolution networks.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Winter Conf. on Applications of Computer Vision
  (WACV) 2018, Lake Tahoe, USA</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04049</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One-Bit ExpanderSketch for One-Bit Compressed Sensing</dc:title>
 <dc:creator>Nakos, Vasileios</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Is it possible to obliviously construct a set of hyperplanes H such that you
can approximate a unit vector x when you are given the side on which the vector
lies with respect to every h in H? In the sparse recovery literature, where x
is approximately k-sparse, this problem is called one- bit compressed sensing
and has received a fair amount of attention the last decade. In this paper we
obtain the first scheme that achieves almost optimal measurements and sublinear
decoding time for one-bit compressed sensing in the non-uniform case. For a
large range of parameters, we improve the state of the art in both the number
of measurements and the decoding time.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04061</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Going Further with Point Pair Features</dc:title>
 <dc:creator>Hinterstoisser, Stefan</dc:creator>
 <dc:creator>Lepetit, Vincent</dc:creator>
 <dc:creator>Rajkumar, Naresh</dc:creator>
 <dc:creator>Konolige, Kurt</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Point Pair Features is a widely used method to detect 3D objects in point
clouds, however they are prone to fail in presence of sensor noise and
background clutter. We introduce novel sampling and voting schemes that
significantly reduces the influence of clutter and sensor noise. Our
experiments show that with our improvements, PPFs become competitive against
state-of-the-art methods as it outperforms them on several objects from
challenging benchmarks, at a low computational cost.
</dc:description>
 <dc:description>Comment: Corrected post-print of manuscript accepted to the European
  Conference on Computer Vision (ECCV) 2016;
  https://link.springer.com/chapter/10.1007/978-3-319-46487-9_51</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04061</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-46487-9_51</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04062</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mathematics of Isogeny Based Cryptography</dc:title>
 <dc:creator>De Feo, Luca</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  These lectures notes were written for a summer school on Mathematics for
post-quantum cryptography in Thi\`es, Senegal. They try to provide a guide for
Masters' students to get through the vast literature on elliptic curves,
without getting lost on their way to learning isogeny based cryptography. They
are by no means a reference text on the theory of elliptic curves, nor on
cryptography; students are encouraged to complement these notes with some of
the books recommended in the bibliography.
  The presentation is divided in three parts, roughly corresponding to the
three lectures given. In an effort to keep the reader interested, each part
alternates between the fundamental theory of elliptic curves, and applications
in cryptography. We often prefer to have the main ideas flow smoothly, rather
than having a rigorous presentation as one would have in a more classical book.
The reader will excuse us for the inaccuracies and the omissions.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04063</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Planning and Control of Hybrid Systems with Limit Cycle using
  LQR Trees</dc:title>
 <dc:creator>Natarajan, Ramkumar</dc:creator>
 <dc:creator>Rajasekaran, Siddharthan</dc:creator>
 <dc:creator>Taylor, Jonathan D.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a multi-query recovery policy for a hybrid system with goal limit
cycle. The sample trajectories and the hybrid limit cycle of the dynamical
system are stabilized using locally valid Time Varying LQR controller policies
which probabilistically cover a bounded region of state space. The original LQR
Tree algorithm builds such trees for non-linear static and non-hybrid systems
like a pendulum or a cart-pole. We leverage the idea of LQR trees to plan with
a continuous control set, unlike methods that rely on discretization like
dynamic programming to plan for hybrid dynamical systems where it is hard to
capture the exact event of discrete transition. We test the algorithm on a
compass gait model by stabilizing a dynamic walking hybrid limit cycle with
point foot contact from random initial conditions. We show results from the
simulation where the system comes back to a stable behavior with initial
position or velocity perturbation and noise.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, 1 table, To appear in: Intelligent Robots and
  Systems (IROS), 2017 IEEE/RSJ International Conference on</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04066</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication Complexity of Discrete Fair Division</dc:title>
 <dc:creator>Plaut, Benjamin</dc:creator>
 <dc:creator>Roughgarden, Tim</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We initiate the study of the communication complexity of fair division with
indivisible goods. We focus on the most well-studied fairness notions
(envy-freeness, proportionality, and approximations thereof) and valuation
classes (submodular, subadditive and unrestricted). Our results completely
resolve whether the communication complexity of computing a fair allocation (or
determining that none exist) is polynomial or exponential (in the number of
goods), for every combination of fairness notion, valuation class, and number
of players, for both deterministic and randomized protocols.
</dc:description>
 <dc:description>Comment: Working paper</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04068</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reuters Tracer: Toward Automated News Production Using Large Scale
  Social Media Data</dc:title>
 <dc:creator>Liu, Xiaomo</dc:creator>
 <dc:creator>Nourbakhsh, Armineh</dc:creator>
 <dc:creator>Li, Quanzhi</dc:creator>
 <dc:creator>Shah, Sameena</dc:creator>
 <dc:creator>Martin, Robert</dc:creator>
 <dc:creator>Duprey, John</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  To deal with the sheer volume of information and gain competitive advantage,
the news industry has started to explore and invest in news automation. In this
paper, we present Reuters Tracer, a system that automates end-to-end news
production using Twitter data. It is capable of detecting, classifying,
annotating, and disseminating news in real time for Reuters journalists without
manual intervention. In contrast to other similar systems, Tracer is topic and
domain agnostic. It has a bottom-up approach to news detection, and does not
rely on a predefined set of sources or subjects. Instead, it identifies
emerging conversations from 12+ million tweets per day and selects those that
are news-like. Then, it contextualizes each story by adding a summary and a
topic to it, estimating its newsworthiness, veracity, novelty, and scope, and
geotags it. Designing algorithms to generate news that meets the standards of
Reuters journalists in accuracy and timeliness is quite challenging. But Tracer
is able to achieve competitive precision, recall, timeliness, and veracity on
news detection and delivery. In this paper, we reveal our key algorithm designs
and evaluations that helped us achieve this goal, and lessons learned along the
way.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Big Data 2017</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04069</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards ECDSA key derivation from deep embeddings for novel Blockchain
  applications</dc:title>
 <dc:creator>Perone, Christian S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this work, we propose a straightforward method to derive Elliptic Curve
Digital Signature Algorithm (ECDSA) key pairs from embeddings created using
Deep Learning and Metric Learning approaches. We also show that these keys
allows the derivation of cryptocurrencies (such as Bitcoin) addresses that can
be used to transfer and receive funds, allowing novel Blockchain-based
applications that can be used to transfer funds or data directly to domains
such as image, text, sound or any other domain where Deep Learning can extract
high-quality embeddings; providing thus a novel integration between the
properties of the Blockchain-based technologies such as trust minimization and
decentralization together with the high-quality learned representations from
Deep Learning techniques.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04071</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>KBGAN: Adversarial Learning for Knowledge Graph Embeddings</dc:title>
 <dc:creator>Cai, Liwei</dc:creator>
 <dc:creator>Wang, William Yang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce an adversarial learning framework, which we named KBGAN, to
improve the performances of a wide range of existing knowledge graph embedding
models. Because knowledge graph datasets typically only contain positive facts,
sampling useful negative training examples is a non-trivial task. Replacing the
head or tail entity of a fact with a uniformly randomly selected entity is a
conventional method for generating negative facts used by many previous works,
but the majority of negative facts generated in this way can be easily
discriminated from positive facts, and will contribute little towards the
training. Inspired by generative adversarial networks (GANs), we use one
knowledge graph embedding model as a negative sample generator to assist the
training of our desired model, which acts as the discriminator in GANs. The
objective of the generator is to generate difficult negative samples that can
maximize their likeliness determined by the discriminator, while the
discriminator minimizes its training loss. This framework is independent of the
concrete form of generator and discriminator, and therefore can utilize a wide
variety of knowledge graph embedding models as its building blocks. In
experiments, we adversarially train two translation-based models, TransE and
TransD, each with assistance from one of the two probability-based models,
DistMult and ComplEx. We evaluate the performances of KBGAN on the link
prediction task, using three knowledge base completion datasets: FB15k-237,
WN18 and WN18RR. Experimental results show that adversarial training
substantially improves the performances of target embedding models under
various settings.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04075</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Automated ICD Coding Using Deep Learning</dc:title>
 <dc:creator>Shi, Haoran</dc:creator>
 <dc:creator>Xie, Pengtao</dc:creator>
 <dc:creator>Hu, Zhiting</dc:creator>
 <dc:creator>Zhang, Ming</dc:creator>
 <dc:creator>Xing, Eric P.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  International Classification of Diseases(ICD) is an authoritative health care
classification system of different diseases and conditions for clinical and
management purposes. Considering the complicated and dedicated process to
assign correct codes to each patient admission based on overall diagnosis, we
propose a hierarchical deep learning model with attention mechanism which can
automatically assign ICD diagnostic codes given written diagnosis. We utilize
character-aware neural language models to generate hidden representations of
written diagnosis descriptions and ICD codes, and design an attention mechanism
to address the mismatch between the numbers of descriptions and corresponding
codes. Our experimental results show the strong potential of automated ICD
coding from diagnosis descriptions. Our best model achieves 0.53 and 0.90 of F1
score and area under curve of receiver operating characteristic respectively.
The result outperforms those achieved using character-unaware encoding method
or without attention mechanism. It indicates that our proposed deep learning
model can code automatically in a reasonable way and provide a framework for
computer-auxiliary ICD coding.
</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04076</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differential Performance Debugging with Discriminant Regression Trees</dc:title>
 <dc:creator>Tizpaz-Niari, Saeid</dc:creator>
 <dc:creator>Cerny, Pavol</dc:creator>
 <dc:creator>Chang, Bor-Yuh Evan</dc:creator>
 <dc:creator>Trivedi, Ashutosh</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Differential performance debugging is a technique to find performance
problems. It applies in situations where the performance of a program is
(unexpectedly) different for different classes of inputs. The task is to
explain the differences in asymptotic performance among various input classes
in terms of program internals. We propose a data-driven technique based on
discriminant regression tree (DRT) learning problem where the goal is to
discriminate among different classes of inputs. We propose a new algorithm for
DRT learning that first clusters the data into functional clusters, capturing
different asymptotic performance classes, and then invokes off-the-shelf
decision tree learning algorithms to explain these clusters. We focus on linear
functional clusters and adapt classical clustering algorithms (K-means and
spectral) to produce them. For the K-means algorithm, we generalize the notion
of the cluster centroid from a point to a linear function. We adapt spectral
clustering by defining a novel kernel function to capture the notion of linear
similarity between two data points. We evaluate our approach on benchmarks
consisting of Java programs where we are interested in debugging performance.
We show that our algorithm significantly outperforms other well-known
regression tree learning algorithms in terms of running time and accuracy of
classification.
</dc:description>
 <dc:description>Comment: To Appear in AAAI 2018</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04078</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parkinson's Disease Digital Biomarker Discovery with Optimized
  Transitions and Inferred Markov Emissions</dc:title>
 <dc:creator>Bukkittu, Avinash</dc:creator>
 <dc:creator>Lin, Baihan</dc:creator>
 <dc:creator>Vu, Trung</dc:creator>
 <dc:creator>Pe'er, Itsik</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We search for digital biomarkers from Parkinson's Disease by observing
approximate repetitive patterns matching hypothesized step and stride periodic
cycles. These observations were modeled as a cycle of hidden states with
randomness allowing deviation from a canonical pattern of transitions and
emissions, under the hypothesis that the averaged features of hidden states
would serve to informatively characterize classes of patients/controls. We
propose a Hidden Semi-Markov Model (HSMM), a latent-state model, emitting
3D-acceleration vectors. Transitions and emissions are inferred from data. We
fit separate models per unique device and training label. Hidden Markov Models
(HMM) force geometric distributions of the duration spent at each state before
transition to a new state. Instead, our HSMM allows us to specify the
distribution of state duration. This modified version is more effective because
we are interested more in each state's duration than the sequence of distinct
states, allowing inclusion of these durations the feature vector.
</dc:description>
 <dc:description>Comment: 10th RECOMB/ISCB Conference on Regulatory &amp; Systems Genomics with
  DREAM Challenges</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04079</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine Grained Knowledge Transfer for Personalized Task-oriented Dialogue
  Systems</dc:title>
 <dc:creator>Mo, Kaixiang</dc:creator>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Yang, Qiang</dc:creator>
 <dc:creator>Fung, Pascale</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Training a personalized dialogue system requires a lot of data, and the data
collected for a single user is usually insufficient. One common practice for
this problem is to share training dialogues between different users and train
multiple sequence-to-sequence dialogue models together with transfer learning.
However, current sequence-to-sequence transfer learning models operate on the
entire sentence, which might cause negative transfer if different personal
information from different users is mixed up. We propose a personalized decoder
model to transfer finer granularity phrase-level knowledge between different
users while keeping personal preferences of each user intact. A novel personal
control gate is introduced, enabling the personalized decoder to switch between
generating personalized phrases and shared phrases. The proposed personalized
decoder model can be easily combined with various deep models and can be
trained with reinforcement learning. Real-world experimental results
demonstrate that the phrase-level personalized decoder improves the BLEU over
multiple sentence-level transfer baseline models by as much as 7.5%.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04090</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MojiTalk: Generating Emotional Responses at Scale</dc:title>
 <dc:creator>Zhou, Xianda</dc:creator>
 <dc:creator>Wang, William Yang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Generating emotional language is a key step towards building empathetic
natural language processing agents. However, a major challenge for this line of
research is the lack of large-scale labeled training data, and previous studies
are limited to only small sets of human annotated sentiment labels.
Additionally, explicitly controlling the emotion and sentiment of generated
text is also difficult. In this paper, we take a more radical approach: we
exploit the idea of leveraging Twitter data that are naturally labeled with
emojis. More specifically, we collect a large corpus of Twitter conversations
that include emojis in the response, and assume the emojis convey the
underlying emotions of the sentence. We then introduce a reinforced conditional
variational encoder approach to train a deep generative model on these
conversations, which allows us to use emojis to control the emotion of the
generated text. Experimentally, we show in our quantitative and qualitative
analyses that the proposed models can successfully generate high-quality
abstractive conversation responses in accordance with designated emotions.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04094</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Neural Graph Embedding with Matrix Factorization</dc:title>
 <dc:creator>Guo, Junliang</dc:creator>
 <dc:creator>Xu, Linli</dc:creator>
 <dc:creator>Huang, Xunpeng</dc:creator>
 <dc:creator>Chen, Enhong</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent advances in language modeling such as word2vec motivate a number of
graph embedding approaches by treating random walk sequences as sentences to
encode structural proximity in a graph. However, most of the existing
principles of neural graph embedding do not incorporate auxiliary information
such as node content flexibly. In this paper we take a matrix factorization
perspective of graph embedding which generalizes to structural embedding as
well as content embedding in a natural way. For structure embedding, we
validate that the matrix we construct and factorize preserves the high-order
proximities of the graph. Label information can be further integrated into the
matrix via the process of random walk sampling to enhance the quality of
embedding. In addition, we generalize the Skip-Gram Negative Sampling model to
integrate the content of the graph in a matrix factorization framework. As a
consequence, graph embedding can be learned in a unified framework integrating
graph structure and node content as well as label information simultaneously.
We demonstrate the efficacy of the proposed model with the tasks of
semi-supervised node classification and link prediction on a variety of
real-world benchmark network datasets.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04094</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04096</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial Interference Aided Physical Layer Security in Cache-enabled
  Heterogeneous Networks</dc:title>
 <dc:creator>Zhao, Wu</dc:creator>
 <dc:creator>Chen, Zhiyong</dc:creator>
 <dc:creator>Li, Kuikui</dc:creator>
 <dc:creator>Xia, Bin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Caching popular contents is a promising way to offload the mobile data
traffic in wireless networks, but so far the potential advantage of caching in
improving physical layer security (PLS) is rarely considered. In this paper, we
contribute to the design and theoretical understanding of exploiting the
caching ability of users to improve the PLS in a wireless heterogeneous network
(HetNet). In such network, the base station (BS) ensures the secrecy of
communication by utilizing some of the available power to transmit a pre-cached
file, such that only the eavesdropper's channel is degraded. Accordingly, the
node locations of BSs, users and eavesdroppers are first modeled as mutually
independent poisson point processes (PPPs) and the corresponding file access
protocol is developed. We then derive analytical expressions of two metrics,
average secrecy rate and secrecy coverage probability, for the proposed system.
Numerical results are provided to show the significant security advantages of
the proposed network and to characterize the impact of network resource on the
secrecy metrics.
</dc:description>
 <dc:description>Comment: submitted to IEEE ICC 2018</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04101</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recommender Systems with Random Walks: A Survey</dc:title>
 <dc:creator>Semage, Laknath</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Recommender engines have become an integral component in today's e-commerce
systems. From recommending books in Amazon to finding friends in social
networks such as Facebook, they have become omnipresent.
  Generally, recommender systems can be classified into two main categories:
content based and collaborative filtering based models. Both these models build
relationships between users and items to provide recommendations. Content based
systems achieve this task by utilizing features extracted from the context
available, whereas collaborative systems use shared interests between user-item
subsets.
  There is another relatively unexplored approach for providing recommendations
that utilizes a stochastic process named random walks. This study is a survey
exploring use cases of random walks in recommender systems and an attempt at
classifying them.
</dc:description>
 <dc:description>Comment: 15 pages, a survey paper</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04109</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Natural exact covering systems and the reversion of the M\&quot;obius series</dc:title>
 <dc:creator>Goulden, I. P.</dc:creator>
 <dc:creator>Granville, Andrew</dc:creator>
 <dc:creator>Richmond, L. Bruce</dc:creator>
 <dc:creator>Shallit, Jeffrey</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05A15, 11A07, 11A25, 05A16, 11N37, 68R15</dc:subject>
 <dc:description>  We prove that the number of natural exact covering systems of cardinality $k$
is equal to the coefficient of $x^k$ in the reversion of the power series
$\sum_{k \ge 1} \mu (k) x^k$, where $\mu(k)$ is the usual number-theoretic
M\&quot;obius function. Using this result, we deduce an asymptotic expression for
the number of such systems.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04114</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile Sensing of Two-Dimensional Bandlimited Fields on Random Paths</dc:title>
 <dc:creator>Rastogi, Charvi</dc:creator>
 <dc:creator>Kumar, Animesh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Mobile sensing has been recently proposed for sampling spatial fields, where
mobile sensors record the field along various paths for reconstruction.
Classical and contemporary sampling typically assumes that the sampling
locations are approximately known. This work explores multiple sampling
strategies along random paths to sample and reconstruct a two dimensional
bandlimited field. Extensive simulations are carried out, with insights from
sensing matrices and their properties, to evaluate the sampling strategies.
Their performance is measured by evaluating the stability of field
reconstruction from field samples. The effect of location unawareness on some
sampling strategies is also evaluated by simulations.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures; submitted to ICASSP 2018</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04115</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering conversational topics and emotions associated with
  Demonetization tweets in India</dc:title>
 <dc:creator>Niyogi, Mitodru</dc:creator>
 <dc:creator>Pal, Asim K.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Social media platforms contain great wealth of information which provides us
opportunities explore hidden patterns or unknown correlations, and understand
people's satisfaction with what they are discussing. As one showcase, in this
paper, we summarize the data set of Twitter messages related to recent
demonetization of all Rs. 500 and Rs. 1000 notes in India and explore insights
from Twitter's data. Our proposed system automatically extracts the popular
latent topics in conversations regarding demonetization discussed in Twitter
via the Latent Dirichlet Allocation (LDA) based topic model and also identifies
the correlated topics across different categories. Additionally, it also
discovers people's opinions expressed through their tweets related to the event
under consideration via the emotion analyzer. The system also employs an
intuitive and informative visualization to show the uncovered insight.
Furthermore, we use an evaluation measure, Normalized Mutual Information (NMI),
to select the best LDA models. The obtained LDA results show that the tool can
be effectively used to extract discussion topics and summarize them for further
manual analysis.
</dc:description>
 <dc:description>Comment: 6 pages, 11 figures. arXiv admin note: substantial text overlap with
  arXiv:1608.02519 by other authors; text overlap with arXiv:1705.08094 by
  other authors</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04118</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software for full-color 3D reconstruction of the biological tissues
  internal structure</dc:title>
 <dc:creator>Khoperskov, A. V.</dc:creator>
 <dc:creator>Kovalev, M. E.</dc:creator>
 <dc:creator>Astakhov, A. S.</dc:creator>
 <dc:creator>Novochadov, V. V.</dc:creator>
 <dc:creator>Terpilovskiy, A. A.</dc:creator>
 <dc:creator>Tiras, K. P.</dc:creator>
 <dc:creator>Malanin, D. A.</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  A software for processing sets of full-color images of biological tissue
histological sections is developed. We used histological sections obtained by
the method of high-precision layer-by-layer grinding of frozen biological
tissues. The software allows restoring the image of the tissue for an arbitrary
cross-section of the tissue sample. Thus, our method is designed to create a
full-color 3D reconstruction of the biological tissue structure. The resolution
of 3D reconstruction is determined by the quality of the initial histological
sections. The newly developed technology available to us provides a resolution
of up to 5 - 10 {\mu}m in three dimensions.
</dc:description>
 <dc:description>Comment: 11 pages, 8 figures</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04118</dc:identifier>
 <dc:identifier>Lecture Notes in Computer Science, 2017, v.10594, p.1-10</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-69182-4_1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04121</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Audio Source Separation via Spectrum Energy Preserved
  Wasserstein Learning</dc:title>
 <dc:creator>Zhang, Ning</dc:creator>
 <dc:creator>Yan, Junchi</dc:creator>
 <dc:creator>Zhou, Yuchen</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Separating audio mixtures into individual tracks has been a long standing
challenging task. We introduce a novel unsupervised audio source separation
approach based on deep adversarial learning. Specifically, our loss function
adopts the Wasserstein distance which directly measures the distribution
distance between the separated sources and the real sources for each individual
source. Moreover, a global regularization term is added to fulfill the spectrum
energy preservation property regarding separation. Unlike state-of-the-art
unsupervised models which often involve deliberately devised constraints or
careful model selection, our approach need little prior model specification on
the data, and can be straightforwardly learned in an end-to-end fashion. We
show that the proposed method performs competitively on public benchmark
against state-of-the-art unsupervised methods.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04125</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stability and Stabilization of Fractional-order Systems with Different
  Derivative Orders: An LMI Approach</dc:title>
 <dc:creator>Badri, Pouya</dc:creator>
 <dc:creator>Sojoodi, Mahdi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Stability and stabilization analysis of fractional-order linear
time-invariant (FO-LTI) systems with different derivative orders is studied in
this paper. First, by using an appropriate linear matrix function, a
single-order equivalent system for the given different-order system is
introduced by which a new stability condition is obtained that is easier to
check in practice than the conditions known up to now. Then the stabilization
problem of fractional-order linear systems with different fractional orders via
a dynamic output feedback controller with a predetermined order is
investigated, utilizing the proposed stability criterion. The linear matrix
inequality based procedure of developing stabilizing output feedback control is
preserved in spite of the complexity of assuming the most complete linear
controller model, with direct feedthrough parameter. The proposed stability and
stabilization theorems are applicable to FO-LTI systems with different
fractional orders in one or both of and intervals. Eventually, some numerical
examples are presented to confirm the obtained analytical results.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04126</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disease Prediction from Electronic Health Records Using Generative
  Adversarial Networks</dc:title>
 <dc:creator>Hwang, Uiwon</dc:creator>
 <dc:creator>Choi, Sungwoon</dc:creator>
 <dc:creator>Yoon, Sungroh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Electronic health records (EHRs) have contributed to the computerization of
patient records so that they can be used not only for efficient and systematic
medical services, but also for research on data science. In this paper, we
compared the disease prediction performance of generative adversarial networks
(GANs) and conventional learning algorithms in combination with missing value
prediction methods. As a result, the highest accuracy of 98.05% was obtained
using a stacked autoencoder as the missing value prediction method and an
auxiliary classifier GANs (AC-GANs) as the disease predicting method. Our
results show that the combination of the stacked autoencoder and the AC-GANs
significantly outperforms existing algorithms for the problem of disease
prediction in which missing values and class imbalance exist.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04126</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04141</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Truncated Polynomial Expansion Downlink Precoders and Uplink Detectors
  for Massive MIMO</dc:title>
 <dc:creator>Benzin, Andreas</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:creator>Shadmi, Yonatan</dc:creator>
 <dc:creator>Tulino, Antonia</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In TDD reciprocity-based massive MIMO it is essential to be able to compute
the downlink precoding matrix over all OFDM resource blocks within a small
fraction of the uplink-downlink slot duration. Early implementation of massive
MIMO are limited to the simple Conjugate Beamforming (ConjBF) precoding method,
because of such computation latency limitation. However, it has been widely
demonstrated by theoretical analysis and system simulation that Regularized
Zero-Forcing (RZF) precoding is generally much more effective than ConjBF for a
large but practical number of transmit antennas. In order to recover a
significant fraction of the gap between ConjBF and RZF and yet meeting the very
strict computation latency constraints, truncated polynomial expansion (TPE)
methods have been proposed. In this paper we present a novel TPE method that
outperforms all previously proposed methods in the general non-symmetric case
of users with arbitrary antenna correlation. In addition, the proposed method
is significantly simpler and more flexible than previously proposed methods
based on deterministic equivalents and free probability in large random matrix
theory. We consider power allocation with our TPE approach, and show that
classical system optimization problems such as min-sum power and max-min rate
can be easily solved. Furthermore, we provide a detailed computation latency
analysis specifically targeted to a highly parallel FPGA hardware architecture.
</dc:description>
 <dc:description>Comment: A shorter version of this paper without the tutorial-like appendices
  has been submitted to IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04147</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Residual Text Detection Network for Scene Text</dc:title>
 <dc:creator>Zhu, Xiangyu</dc:creator>
 <dc:creator>Jiang, Yingying</dc:creator>
 <dc:creator>Yang, Shuli</dc:creator>
 <dc:creator>Wang, Xiaobing</dc:creator>
 <dc:creator>Li, Wei</dc:creator>
 <dc:creator>Fu, Pei</dc:creator>
 <dc:creator>Wang, Hua</dc:creator>
 <dc:creator>Luo, Zhenbo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Scene text detection is a challenging problem in computer vision. In this
paper, we propose a novel text detection network based on prevalent object
detection frameworks. In order to obtain stronger semantic feature, we adopt
ResNet as feature extraction layers and exploit multi-level feature by
combining hierarchical convolutional networks. A vertical proposal mechanism is
utilized to avoid proposal classification, while regression layer remains
working to improve localization accuracy. Our approach evaluated on ICDAR2013
dataset achieves F-measure of 0.91, which outperforms previous state-of-the-art
results in scene text detection.
</dc:description>
 <dc:description>Comment: IAPR International Conference on Document Analysis and Recognition
  (ICDAR) 2017</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04149</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Broadcast in radio networks: time vs. energy tradeoffs</dc:title>
 <dc:creator>Klonowski, Marek</dc:creator>
 <dc:creator>Paj&#x105;k, Dominik</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In wireless networks, consisting of battery-powered devices, energy is a
costly resource and most of it is spent on transmitting and receiving messages.
Broadcast is a problem where a message needs to be transmitted from one node to
all other nodes of the network. We study algorithms that can work under limited
energy measured as the maximum number of transmissions by a single station. The
goal of the paper is to study tradeoffs between time and energy complexity of
broadcast problem in multi-hop radio networks. We consider a model where the
topology of the network is unknown and if two neighbors of a station are
transmitting in the same discrete time slot, then the signals collide and the
receiver cannot distinguish the collided signals from silence.
  We observe that existing, time efficient, algorithms are not optimized with
respect to energy expenditure. We then propose and analyse two new randomized
energy-efficient algorithms. Our first algorithm works in time
$O((D+\varphi)\cdot n^{1/\varphi}\cdot \varphi)$ with high probability and uses
$O(\varphi)$ energy per station for any $\varphi \leq \log n/(2\log\log n)$ for
any graph with $n$ nodes and diameter $D$. Our second algorithm works in time
$O((D+\log n)\log n)$ with high probability and uses $O(\log n/\log\log n)$
energy.
  We prove that our algorithms are almost time-optimal for given energy limits
for graphs with constant diameters by constructing lower bound on time of
$\Omega(n^{1/\varphi} \cdot \varphi)$. The lower bound shows also that any
algorithm working in polylogaritmic time in $n$ for all graphs needs energy
$\Omega(\log n/\log\log n)$.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04150</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>STWalk: Learning Trajectory Representations in Temporal Graphs</dc:title>
 <dc:creator>Pandhre, Supriya</dc:creator>
 <dc:creator>Mittal, Himangi</dc:creator>
 <dc:creator>Gupta, Manish</dc:creator>
 <dc:creator>Balasubramanian, Vineeth N</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Analyzing the temporal behavior of nodes in time-varying graphs is useful for
many applications such as targeted advertising, community evolution and outlier
detection. In this paper, we present a novel approach, STWalk, for learning
trajectory representations of nodes in temporal graphs. The proposed framework
makes use of structural properties of graphs at current and previous time-steps
to learn effective node trajectory representations. STWalk performs random
walks on a graph at a given time step (called space-walk) as well as on graphs
from past time-steps (called time-walk) to capture the spatio-temporal behavior
of nodes. We propose two variants of STWalk to learn trajectory
representations. In one algorithm, we perform space-walk and time-walk as part
of a single step. In the other variant, we perform space-walk and time-walk
separately and combine the learned representations to get the final trajectory
embedding. Extensive experiments on three real-world temporal graph datasets
validate the effectiveness of the learned representations when compared to
three baseline methods. We also show the goodness of the learned trajectory
embeddings for change point detection, as well as demonstrate that arithmetic
operations on these trajectory representations yield interesting and
interpretable results.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures, 2 tables</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04150</dc:identifier>
 <dc:identifier>doi:10.1145/3152494.3152512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04154</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable probabilistic embeddings: bridging the gap between topic
  models and neural networks</dc:title>
 <dc:creator>Potapenko, Anna</dc:creator>
 <dc:creator>Popov, Artem</dc:creator>
 <dc:creator>Vorontsov, Konstantin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We consider probabilistic topic models and more recent word embedding
techniques from a perspective of learning hidden semantic representations.
Inspired by a striking similarity of the two approaches, we merge them and
learn probabilistic embeddings with online EM-algorithm on word co-occurrence
data. The resulting embeddings perform on par with Skip-Gram Negative Sampling
(SGNS) on word similarity tasks and benefit in the interpretability of the
components. Next, we learn probabilistic document embeddings that outperform
paragraph2vec on a document similarity task and require less memory and time
for training. Finally, we employ multimodal Additive Regularization of Topic
Models (ARTM) to obtain a high sparsity and learn embeddings for other
modalities, such as timestamps and categories. We observe further improvement
of word similarity performance and meaningful inter-modality similarities.
</dc:description>
 <dc:description>Comment: Appeared in AINL-2017</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04161</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end Video-level Representation Learning for Action Recognition</dc:title>
 <dc:creator>Zhu, Jiagang</dc:creator>
 <dc:creator>Zou, Wei</dc:creator>
 <dc:creator>Zhu, Zheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  From the frame/clip-level feature learning to the video-level representation
building, deep learning methods in action recognition have developed rapidly in
recent years. However, current methods suffer from the confusion caused by
partial observation training, or without end-to-end learning, or restricted to
single temporal scale modeling and so on. In this paper, we build upon
two-stream ConvNets and propose Deep networks with Temporal Pyramid Pooling
(DTPP), an end-to-end video-level representation learning approach, to address
these problems. Specifically, at first, RGB images and optical flow stacks are
sparsely sampled across the whole video. Then a temporal pyramid pooling layer
is used to aggregate the frame-level features which consist of spatial and
temporal cues. Lastly, the trained model has compact video-level representation
with multiple temporal scales, which is both global and sequence-aware.
Experimental results show that DTPP achieves the state-of-the-art performance
on two challenging video action datasets: UCF101 and HMDB51, either by ImageNet
pre-training or Kinetics pre-training.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, 6 tables. The explanation for the batch size is
  added</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04162</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Sparse Graph-Structured Lasso Mixed Model for Genetic Association with
  Confounding Correction</dc:title>
 <dc:creator>Ye, Wenting</dc:creator>
 <dc:creator>Liu, Xiang</dc:creator>
 <dc:creator>Wang, Haohan</dc:creator>
 <dc:creator>Xing, Eric P.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  While linear mixed model (LMM) has shown a competitive performance in
correcting spurious associations raised by population stratification, family
structures, and cryptic relatedness, more challenges are still to be addressed
regarding the complex structure of genotypic and phenotypic data. For example,
geneticists have discovered that some clusters of phenotypes are more
co-expressed than others. Hence, a joint analysis that can utilize such
relatedness information in a heterogeneous data set is crucial for genetic
modeling.
  We proposed the sparse graph-structured linear mixed model (sGLMM) that can
incorporate the relatedness information from traits in a dataset with
confounding correction. Our method is capable of uncovering the genetic
associations of a large number of phenotypes together while considering the
relatedness of these phenotypes. Through extensive simulation experiments, we
show that the proposed model outperforms other existing approaches and can
model correlation from both population structure and shared signals. Further,
we validate the effectiveness of sGLMM in the real-world genomic dataset on two
different species from plants and humans. In Arabidopsis thaliana data, sGLMM
behaves better than all other baseline models for 63.4% traits. We also discuss
the potential causal genetic variation of Human Alzheimer's disease discovered
by our model and justify some of the most important genetic loci.
</dc:description>
 <dc:description>Comment: Code available at https://github.com/YeWenting/sGLMM</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04168</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Document Embeddings With CNNs</dc:title>
 <dc:creator>Liu, Chundi</dc:creator>
 <dc:creator>Zhao, Shunan</dc:creator>
 <dc:creator>Volkovs, Maksims</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new model for unsupervised document embedding. Existing
approaches either require complex inference or use recurrent neural networks
that are difficult to parallelize. We take a different route and use recent
advances in language modelling to develop a convolutional neural network
embedding model. This allows us to train deeper architectures that are fully
parallelizable. Stacking layers together increases the receptive field allowing
each successive layer to model increasingly longer range semantic dependencies
within the document. Empirically, we demonstrate superior results on two
publicly available benchmarks.
</dc:description>
 <dc:description>Comment: Corrected typos</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04170</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Randomized Connection Network with Graph-based Label Inference</dc:title>
 <dc:creator>Bao, Siqi</dc:creator>
 <dc:creator>Wang, Pei</dc:creator>
 <dc:creator>Mok, Tony C. W.</dc:creator>
 <dc:creator>Chung, Albert C. S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, a novel 3D deep learning network is proposed for brain MR
image segmentation with randomized connection, which can decrease the
dependency between layers and increase the network capacity. The convolutional
LSTM and 3D convolution are employed as network units to capture the long-term
and short-term 3D properties respectively. To assemble these two kinds of
spatial-temporal information and refine the deep learning outcomes, we further
introduce an efficient graph-based node selection and label inference method.
Experiments have been carried out on two publicly available databases and
results demonstrate that the proposed method can obtain competitive
performances as compared with other state-of-the-art methods.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04170</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04172</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Depth First Always On Routing Trace Algorithm</dc:title>
 <dc:creator>Kim, Anthony</dc:creator>
 <dc:creator>Chen, Sung Hyun</dc:creator>
 <dc:creator>Zheng, Chen</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  In this paper, we discussed current limitation in the
electronic-design-automotation (EDA) tool on tracing the always on routing. We
developed an algorithm to efficiently track the secondary power routing and
accurately estimate the routing quality using approximate voltage drop as the
criteria. The fast check can identify potential hotspot issues without going
through sign-off checks. It helps designers to capture issues at early stages
and fix the issues with less design effort. We also discussed some limitations
to our algorithm.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures, 1 table</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04175</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Subhourly Electricity Resource Dispatch Under Multiple Price
  Signals With High Renewable Generation Availability</dc:title>
 <dc:creator>Chassin, David P.</dc:creator>
 <dc:creator>Behboodi, Sahand</dc:creator>
 <dc:creator>Djilali, Ned</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper proposes a system-wide optimal resource dispatch strategy that
enables a shift from a primarily energy cost-based approach, to a strategy
using simultaneous price signals for energy, power and ramping behavior. A
formal method to compute the optimal sub-hourly power trajectory is derived for
a system when the price of energy and ramping are both significant. Optimal
control functions are obtained in both time and frequency domains, and a
discrete-time solution suitable for periodic feedback control systems is
presented. The method is applied to North America Western Interconnection for
the planning year 2024, and it is shown that an optimal dispatch strategy that
simultaneously considers both the cost of energy and the cost of ramping leads
to significant cost savings in systems with high levels of renewable
generation: the savings exceed 25% of the total system operating cost for a 50%
renewables scenario.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04178</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CUR Decompositions, Similarity Matrices, and Subspace Clustering</dc:title>
 <dc:creator>Aldroubi, Akram</dc:creator>
 <dc:creator>Hamm, Keaton</dc:creator>
 <dc:creator>Koku, Ahmet Bugra</dc:creator>
 <dc:creator>Sekmen, Ali</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A general framework for solving the subspace clustering problem using the CUR
decomposition is presented. The CUR decomposition provides a natural way to
construct similarity matrices for data that come from a union of unknown
subspaces $\mathscr{U}=\underset{i=1}{\overset{M}\bigcup}S_i$. The similarity
matrices thus constructed give the exact clustering in the noise-free case. A
simple adaptation of the technique also allows clustering of noisy data. Two
known methods for subspace clustering can be derived from the CUR technique.
Experiments on synthetic and real data are presented to test the method.
</dc:description>
 <dc:description>Comment: Approximately 22 Pages</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04181</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Selection based on the Local Lift Dependence Scale</dc:title>
 <dc:creator>Marcondes, Diego</dc:creator>
 <dc:creator>Simonis, Adilson</dc:creator>
 <dc:creator>Barrera, Junior</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper uses a classical approach to feature selection: minimization of a
cost function applied on estimated joint distributions. However, the search
space in which such minimization is performed is extended. In the original
formulation, the search space is the Boolean lattice of features sets (BLFS),
while, in the present formulation, it is a collection of Boolean lattices of
ordered pairs (features, associated value) (CBLOP), indexed by the elements of
the BLFS. In this approach, we may not only select the features that are most
related to a variable Y, but also select the values of the features that most
influence the variable or that are most prone to have a specific value of Y. A
local formulation of Shanon's mutual information is applied on a CBLOP to
select features, namely, the Local Lift Dependence Scale, an scale for
measuring variable dependence in multiple resolutions. The main contribution of
this paper is to define and apply this local measure, which permits to analyse
local properties of joint distributions that are neglected by the classical
Shanon's global measure. The proposed approach is applied to a dataset
consisting of student performances on a university entrance exam, as well as on
undergraduate courses. The approach is also applied to two datasets of the UCI
Machine Learning Repository.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04184</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-number Computability from the Perspective of Computer Assisted
  Proofs in Analysis</dc:title>
 <dc:creator>Moczurad, Ma&#x142;gorzata</dc:creator>
 <dc:creator>Zgliczy&#x144;ski, Piotr</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We present an interval approach to real-number computations. In some aspects
it is similar to existing ones. However, those aspects in which our attitude
differs give it several advantages. First, we do not need any oracles and
impractical or non-realistic structures; we carry out calculations in a way it
is done in real-life practice (e.g.\ in computer assisted proofs in analysis).
Second, the interval point of view allows us to consider various kinds of
global information. Apparently, the latter has not been treated in the
literature.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04184</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04185</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytic Model for Network Resource Management between ISPs and Users</dc:title>
 <dc:creator>Lolaee, Hossein</dc:creator>
 <dc:creator>Akhaee, Mohammad Ali</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Fixed Communication Provider (FCP) is a consortium of Internet Service
Providers (ISPs) which users can switch easily and freely between their ISPs.
In order to increase the QoS of the ISPs, we propose a two class service model
as the following. ISPs divide their available bandwidth into two parts to
provide their end users with optimal services. One dedicated to primary users,
and the other for secondary users. Primary users are those who pay more and
thus, expect dedicated bandwidth that is always available. Secondary services
are provided by ISPs for the other users who cannot afford the dedicated
bandwidth. In this study, by defining the utility functions for both user
types, we aim at dividing the ISP bandwidth between these two services such
that the utility function of the users is maximized. Since the primary users do
not always use the maximum bandwidth, an algorithm is proposed for ISPs to
estimate the primary users required bandwidth in each time segment based on the
previous segments. Based on this estimate, the expected bandwidth is dedicated
to the primary users, and the remaining bandwidth is devoted to the secondary
users to improve the Quality of Service (QoS). On the other hand, an ISP is
penalized if it fails to provide the primary users with the required bandwidth
mentioned in their contract. Therefore, there exists a trade-off between the
conservative estimation of the primary users rate, QoS of the secondary users
and the achieved utility of the ISPs.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures, Journal of IET Networks</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04185</dc:identifier>
 <dc:identifier>IET Networks, vol. 6, no. 2, pp. 32 to 38, Mar. 2017</dc:identifier>
 <dc:identifier>doi:10.1049/iet-net.2016.0060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04188</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assessing Agile Transformation Success Factors</dc:title>
 <dc:creator>Campanelli, Amadeu Silveira</dc:creator>
 <dc:creator>Neto, Florindo Silote</dc:creator>
 <dc:creator>Parreiras, Fernando Silva</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Research on success factors involved in the agile transformation process is
not conclusive and there is still need for guidelines to help in the
transformation process considering the organizational context (culture, values,
needs, reality and goals). The usage of success factors as a tool to help agile
adoption raises the following research question: What are the success factors
for an organization and their teams in preparation for the agile transformation
process? This research presents an assessment of the organizational environment
including the company's goals and the perception of the team members to provide
awareness of how the organization should prepare for the next steps in the
agile transformation. The findings show that a company based in Chicago, USA,
succeeded implementing customer involvement and self-organized teams but faces
challenges with measurement models and training. The main contribution of the
research is understand which success factors exist in their environment and how
they can be used during agile adoption.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04189</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A distributed system for SearchOnMath based on the Microsoft BizSpark
  program</dc:title>
 <dc:creator>Oliveira, Ricardo M.</dc:creator>
 <dc:creator>Gonzaga, Flavio B.</dc:creator>
 <dc:creator>Barbosa, Valmir C.</dc:creator>
 <dc:creator>Xex&#xe9;o, Geraldo B.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Mathematical information retrieval is a relatively new area, so the first
search tools capable of retrieving mathematical formulas began to appear only a
few years ago. The proposals made public so far mostly implement searches on
internal university databases, small sets of scientific papers, or Wikipedia in
English. As such, only modest computing power is required. In this context,
SearchOnMath has emerged as a pioneering tool in that it indexes several
different databases and is compatible with several mathematical representation
languages. Given the significantly greater number of formulas it handles, a
distributed system becomes necessary to support it. The present study is based
on the Microsoft BizSpark program and has aimed, for 38 different
distributed-system scenarios, to pinpoint the one affording the best response
times when searching the SearchOnMath databases for a collection of 120
formulas.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04192</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Latent Constrained Correlation Filter</dc:title>
 <dc:creator>Zhang, Baochang</dc:creator>
 <dc:creator>Luan, Shangzhen</dc:creator>
 <dc:creator>Chen, Chen</dc:creator>
 <dc:creator>Han, Jungong</dc:creator>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:creator>Perina, Alessandro</dc:creator>
 <dc:creator>Shao, Ling</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Correlation filters are special classifiers designed for shift-invariant
object recognition, which are robust to pattern distortions. The recent
literature shows that combining a set of sub-filters trained based on a single
or a small group of images obtains the best performance. The idea is equivalent
to estimating variable distribution based on the data sampling (bagging), which
can be interpreted as finding solutions (variable distribution approximation)
directly from sampled data space. However, this methodology fails to account
for the variations existed in the data. In this paper, we introduce an
intermediate step -- solution sampling -- after the data sampling step to form
a subspace, in which an optimal solution can be estimated. More specifically,
we propose a new method, named latent constrained correlation filters (LCCF),
by mapping the correlation filters to a given latent subspace, and develop a
new learning framework in the latent subspace that embeds distribution-related
constraints into the original problem. To solve the optimization problem, we
introduce a subspace based alternating direction method of multipliers (SADMM),
which is proven to converge at the saddle point. Our approach is successfully
applied to three different tasks, including eye localization, car detection and
object tracking. Extensive experiments demonstrate that LCCF outperforms the
state-of-the-art methods. The source code will be publicly available.
https://github.com/bczhangbczhang/.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04194</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full-Body Locomotion Reconstruction of Virtual Characters Using a Single
  IMU</dc:title>
 <dc:creator>Mousas, Christos</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  This paper presents a method of reconstructing full-body locomotion sequences
for virtual characters in real-time, using data from a single inertial
measurement unit (IMU). This process can be characterized by its difficulty
because of the need to reconstruct a high number of degrees of freedom (DOFs)
from a very low number of DOFs. To solve such a complex problem, the presented
method is divided into several steps. The user's full-body locomotion and the
IMU's data are recorded simultaneously. Then, the data is preprocessed in such
a way that would be handled more efficiently. By developing a hierarchical
multivariate hidden Markov model with reactive interpolation functionality the
system learns the structure of the motion sequences. Specifically, the phases
of the locomotion sequence are assigned in the higher hierarchical level, and
the frame structure of the motion sequences are assigned at the lower
hierarchical level. During the runtime of the method, the forward algorithm is
used for reconstructing the full-body motion of a virtual character. Firstly,
the method predicts the phase where the input motion belongs (higher
hierarchical level). Secondly, the method predicts the closest trajectories and
their progression and interpolates the most probable of them to reconstruct the
virtual character's full-body motion (lower hierarchical level). Evaluating the
proposed method shows that it works on reasonable framerates and minimizes the
reconstruction errors compared with previous approaches.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04203</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building machines that adapt and compute like brains</dc:title>
 <dc:creator>Kriegeskorte, Nikolaus</dc:creator>
 <dc:creator>Mok, Robert M.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Building machines that learn and think like humans is essential not only for
cognitive science, but also for computational neuroscience, whose ultimate goal
is to understand how cognition is implemented in biological brains. A new
cognitive computational neuroscience should build cognitive-level and neural-
level models, understand their relationships, and test both types of models
with both brain and behavioral data.
</dc:description>
 <dc:description>Comment: Commentary on: Lake BM, Ullman TD, Tenenbaum JB, Gershman SJ. (2017)
  Building machines that learn and think like people. Behavioral and Brain
  Sciences, 40</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04204</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Commonsense LocatedNear Relation Extraction</dc:title>
 <dc:creator>Xu, Frank F.</dc:creator>
 <dc:creator>Lin, Bill Y.</dc:creator>
 <dc:creator>Zhu, Kenny Q.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  LocatedNear relation describes two typically co-located objects, which is a
type of useful commonsense knowledge for computer vision, natural language
understanding, machine comprehension, etc. We propose to automatically extract
such relationship through a sentence-level classifier and aggregating the
scores of entity pairs detected from a large number of sentences. To enable the
research of these tasks, we release two benchmark datasets, one containing
5,000 sentences annotated with whether a mentioned entity pair has LocatedNear
relation in the given sentence or not; the other containing 500 pairs of
physical objects and whether they are commonly located nearby. We also propose
some baseline methods for the tasks and compare the results with a
state-of-the-art general-purpose relation classifier.
</dc:description>
 <dc:description>Comment: 6 pages + 2 pages of reference. Accepted by AKBC@NIPS'17</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04207</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Channel Covariance Estimation for the Hybrid MIMO Architecture:
  A Compressive Sensing Based Approach</dc:title>
 <dc:creator>Park, Sungwoo</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Spatial channel covariance information can replace full knowledge of the
entire channel matrix for designing analog precoders in hybrid
multiple-input-multiple-output (MIMO) architecture. Spatial channel covariance
estimation, however, is challenging for the hybrid MIMO architecture because
the estimator operating at baseband can only obtain a lower dimensional
pre-combined signal through fewer radio frequency (RF) chains than antennas. In
this paper, we propose two approaches for covariance estimation based on
compressive sensing techniques. One is to apply a time-varying sensing matrix,
and the other is to exploit the prior knowledge that the covariance matrix is
Hermitian. We present the rationale of the two ideas and validate the
superiority of the proposed methods by theoretical analysis and numerical
simulations. We conclude the paper by extending the proposed algorithms from
narrowband massive MIMO systems with a single receive antenna to wideband
systems with multiple receive antennas.
</dc:description>
 <dc:description>Comment: submitted to IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04208</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Scalability for Stackelberg Security Games</dc:title>
 <dc:creator>Sinha, Arunesh</dc:creator>
 <dc:creator>Schlenker, Aaron</dc:creator>
 <dc:creator>Dmello, Donnabell</dc:creator>
 <dc:creator>Tambe, Milind</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Stackelberg Security Games (SSGs) have been adopted widely for modeling
adversarial interactions. With increasing size of the applications of SSGs,
scalability of equilibrium computation is an important research problem. While
prior research has made progress with regards to scalability, many real world
problems cannot be solved satisfactorily yet as per current requirements; these
include the deployed federal air marshals (FAMS) application and the threat
screening (TSG) problem at airports. Further, these problem domains are
inherently limited by NP hardness shown in prior literature. We initiate a
principled study of approximations in zero-sum SSGs. Our contribution includes
the following: (1) a unified model of SSGs called adversarial randomized
allocation (ARA) games that allows studying most SSGs in one model, (2)
hardness of approximation results for zero-sum ARA, as well as for the
sub-problem of allocating federal air marshal (FAMS) and threat screening
problem (TSG) at airports, (3) an approximation framework for zero-sum ARA with
provable approximation guarantees and (4) experiments demonstrating the
significant scalability of up to 1000x improvement in runtime with an
acceptable 5% solution quality loss.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04211</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence of Hierarchical Clustering and Persistent Homology Methods
  on Directed Networks</dc:title>
 <dc:creator>Chowdhury, Samir</dc:creator>
 <dc:creator>M&#xe9;moli, Facundo</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  While there has been much interest in adapting conventional clustering
procedures---and in higher dimensions, persistent homology methods---to
directed networks, little is known about the convergence of such methods. In
order to even formulate the problem of convergence for such methods, one needs
to stipulate a reasonable model for a directed network together with a flexible
sampling theory for such a model. In this paper we propose and study a
particular model of directed networks, and use this model to study the
convergence of certain hierarchical clustering and persistent homology methods
that accept any matrix of (possibly asymmetric) pairwise relations as input and
produce dendrograms and persistence barcodes as outputs. We show that as points
are sampled from some probability distribution, the output of each method
converges almost surely to a dendrogram/barcode depending on the structure of
the distribution.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04213</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skyline Identification in Multi-Armed Bandits</dc:title>
 <dc:creator>Cheu, Albert</dc:creator>
 <dc:creator>Sundaram, Ravi</dc:creator>
 <dc:creator>Ullman, Jonathan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a variant of the classical PAC multi-armed bandit problem. There
is an ordered set of $n$ arms $A[1],\dots,A[n]$, each with some stochastic
reward drawn from some unknown bounded distribution. The goal is to identify
the $skyline$ of the set $A$, consisting of all arms $A[i]$ such that $A[i]$
has larger expected reward than all lower-numbered arms $A[1],\dots,A[i-1]$. We
define a natural notion of an $\varepsilon$-approximate skyline and prove
matching upper and lower bounds for identifying an $\varepsilon$-skyline.
Specifically, we show that in order to identify an $\varepsilon$-skyline from
among $n$ arms with probability $1-\delta$, $$
\Theta\bigg(\frac{n}{\varepsilon^2} \cdot \min\bigg\{
\log\bigg(\frac{1}{\varepsilon \delta}\bigg), \log\bigg(\frac{n}{\delta}\bigg)
\bigg\} \bigg) $$ samples are necessary and sufficient. When $\varepsilon \gg
1/n$, our results improve over the naive algorithm, which draws enough samples
to approximate the expected reward of every arm; the algorithm of (Auer et al.,
AISTATS'16) for Pareto-optimal arm identification is likewise superseded. Our
results show that the sample complexity of the skyline problem lies strictly in
between that of best arm identification (Even-Dar et al., COLT'02) and that of
approximating the expected reward of every arm.
</dc:description>
 <dc:description>Comment: 18 pages, 2 Figures; an ALT'18/ISIT'18 submission</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04214</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BP-STDP: Approximating Backpropagation using Spike Timing Dependent
  Plasticity</dc:title>
 <dc:creator>Tavanaei, Amirhossein</dc:creator>
 <dc:creator>Maida, Anthony S.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The problem of training spiking neural networks (SNNs) is a necessary
precondition to understanding computations within the brain, a field still in
its infancy. Previous work has shown that supervised learning in multi-layer
SNNs enables bio-inspired networks to recognize patterns of stimuli through
hierarchical feature acquisition. Although gradient descent has shown
impressive performance in multi-layer (and deep) SNNs, it is generally not
considered biologically plausible and is also computationally expensive. This
paper proposes a novel supervised learning approach based on an event-based
spike-timing-dependent plasticity (STDP) rule embedded in a network of
integrate-and-fire (IF) neurons. The proposed temporally local learning rule
follows the backpropagation weight change updates applied at each time step.
This approach enjoys benefits of both accurate gradient descent and temporally
local, efficient STDP. Thus, this method is able to address some open questions
regarding accurate and efficient computations that occur in the brain. The
experimental results on the XOR problem, the Iris data, and the MNIST dataset
demonstrate that the proposed SNN performs as successfully as the traditional
NNs. Our approach also compares favorably with the state-of-the-art multi-layer
SNNs.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04216</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coordination Technology for Active Support Networks: Context,
  Needfinding, and Design</dc:title>
 <dc:creator>Rosenschein, Stanley J.</dc:creator>
 <dc:creator>Davies, Todd</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Coordination is a key problem for addressing goal-action gaps in many human
endeavors. We define interpersonal coordination as a type of communicative
action characterized by low interpersonal belief and goal conflict. Such
situations are particularly well described as having collectively
&quot;intelligent&quot;, &quot;common good&quot; solutions, viz., ones that almost everyone would
agree constitute social improvements. Coordination is useful across the
spectrum of interpersonal communication -- from isolated individuals to
organizational teams. Much attention has been paid to coordination in teams and
organizations. In this paper we focus on the looser interpersonal structures we
call active support networks (ASNs), and on technology that meets their needs.
We describe two needfinding investigations focused on social support, which
examined (a) four application areas for improving coordination in ASNs: (i)
academic coaching, (ii) vocational training, (iii) early learning intervention,
and (iv) volunteer coordination; and (b) existing technology relevant to ASNs.
We find a thus-far unmet need for personal task management software that allows
smooth integration with an individual's active support network. Based on
identified needs, we then describe an open architecture for coordination that
has been developed into working software. The design includes a set of
capabilities we call &quot;social prompting,&quot; as well as templates for accomplishing
multi-task goals, and an engine that controls coordination in the network. The
resulting tool is currently available and in continuing development. We explain
its use in ASNs with an example. Follow-up studies are underway in which the
technology is being applied in existing support networks.
</dc:description>
 <dc:description>Comment: 16 pages, 4 figures, Scheduled to appear in AI &amp; Society, 33(1), 2018</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04226</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Arbitrarily-Oriented Text Recognition</dc:title>
 <dc:creator>Cheng, Zhanzhan</dc:creator>
 <dc:creator>Liu, Xuyang</dc:creator>
 <dc:creator>Bai, Fan</dc:creator>
 <dc:creator>Niu, Yi</dc:creator>
 <dc:creator>Pu, Shiliang</dc:creator>
 <dc:creator>Zhou, Shuigeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recognizing text from natural images is still a hot research topic in
computer vision due to its various applications. Despite the enduring research
of several decades on optical character recognition (OCR), recognizing texts
from natural images is still a challenging task. This is because scene texts
are often in irregular arrangements (curved, arbitrarily-oriented or seriously
distorted), which have not yet been well addressed in the literature. Existing
methods on text recognition mainly work with regular (horizontal and frontal)
texts and cannot be trivially generalized to handle irregular texts. In this
paper, we develop the arbitrary orientation network (AON) to capture the deep
features of irregular texts (e.g. arbitrarily-oriented, perspective or curved),
which are combined into an attention-based decoder to generate character
sequence. The whole network can be trained end-to-end by using only images and
word-level labels. Extensive experiments on various benchmarks, including the
CUTE80, SVT-Perspective, IIIT5k, SVT and ICDAR datasets, show that the proposed
AON-based method substantially outperforms the existing methods.
</dc:description>
 <dc:description>Comment: A method used in ICDAR 2017 word recognition competitions</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04231</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Syntax-Directed Attention for Neural Machine Translation</dc:title>
 <dc:creator>Chen, Kehai</dc:creator>
 <dc:creator>Wang, Rui</dc:creator>
 <dc:creator>Utiyama, Masao</dc:creator>
 <dc:creator>Sumita, Eiichiro</dc:creator>
 <dc:creator>Zhao, Tiejun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Attention mechanism, including global attention and local attention, plays a
key role in neural machine translation (NMT). Global attention attends to all
source words for word prediction. In comparison, local attention selectively
looks at fixed-window source words. However, alignment weights for the current
target word often decrease to the left and right by linear distance centering
on the aligned source position and neglect syntax-directed distance
constraints. In this paper, we extend local attention with syntax-distance
constraint, to focus on syntactically related source words with the predicted
target word, thus learning a more effective context vector for word prediction.
Moreover, we further propose a double context NMT architecture, which consists
of a global context vector and a syntax-directed context vector over the global
attention, to provide more translation performance for NMT from source
representation. The experiments on the large-scale Chinese-to-English and
English-to-Germen translation tasks show that the proposed approach achieves a
substantial and significant improvement over the baseline system.
</dc:description>
 <dc:description>Comment: This paper has been accepted by the AAAI-2018</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04235</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bitcoin and quantum computing</dc:title>
 <dc:creator>Tessler, Louis</dc:creator>
 <dc:creator>Byrnes, Tim</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Bitcoin is a digital currency and payment system based on classical
cryptographic technologies which works without a central administrator such as
in traditional currencies. It has long been questioned what the impact of
quantum computing would be on Bitcoin, and cryptocurrencies in general. Here,
we analyse three primary directions that quantum computers might have an impact
in: mining, security, and forks. We find that in the near-term the impact of
quantum computers appear to be rather small for all three directions. The
impact of quantum computers would require considerably larger number of qubits
and breakthroughs in quantum algorithms to reverse existing hash functions.
</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04237</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>D-PCN: Parallel Convolutional Neural Networks for Image Recognition in
  Reverse Adversarial Style</dc:title>
 <dc:creator>Yang, Shiqi</dc:creator>
 <dc:creator>Peng, Gang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, a recognition framework named D-PCN using a discriminator is
proposed, which can intensify the feature extracting ability of convolutional
neural networks. The framework contains two parallel convolutional neural
networks, and a discriminator, which is introduced from the Generative
Adversarial Nets and can improve the performance of parallel networks. The two
nets are devised side by side, and the discriminator takes in the features from
parallel networks as input, aiming to guide the two nets to learn features of
different details in a reverse adversarial style. After that, the feature maps
from two nets get aggregated, then an extra overall classifier is added and
will output the final prediction employing the fused features. The training
strategy of the D-PCN is also introduced which ensures the utilization of the
discriminator. We experiment the D-PCN with several CNN models including NIN,
ResNet, ResNeXt and DenseNet using single NVIDIA TITAN Xp, on the two benchmark
datasets: CIFAR-100 and downsampled ImageNet-1k, the D-PCN enhances all models
on CIFAR-100 and also reinforces the performance of ResNet on downsampled
ImageNet-1k explicitly. In particular, it yields state-of-the-art
classification performance on CIFAR-100 with compared to relative works.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04238</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Kullback-Leibler Divergence and Universal Hypothesis Testing for
  Continuous Distributions</dc:title>
 <dc:creator>Yang, Pengfei</dc:creator>
 <dc:creator>Chen, Biao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Universal hypothesis testing refers to the problem of deciding whether
samples come from a nominal distribution or an unknown distribution that is
different from the nominal distribution. Hoeffding's test, whose test statistic
is equivalent to the empirical Kullback-Leibler divergence (KLD), is known to
be asymptotically optimal for distributions defined on finite alphabets. With
continuous observations, however, the discontinuity of the KLD in the
distribution functions results in significant complications for universal
hypothesis testing. This paper introduces a robust version of the classical
KLD, defined as the KLD from a distribution to the L'evy ball of a known
distribution. This robust KLD is shown to be continuous in the underlying
distribution function with respect to the weak convergence. The continuity
property enables the development of a universal hypothesis test for continuous
observations that is shown to be asymptotically optimal for continuous
distributions in the same sense as that of the Hoeffding's test for discrete
distributions.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Trans. Information Theory</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04240</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensuring Liveness Properties of Distributed Systems (A Research Agenda)</dc:title>
 <dc:creator>van Glabbeek, Rob</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  Often fairness assumptions need to be made in order to establish liveness
properties of distributed systems, but in many situations these lead to false
conclusions.
  This document presents a research agenda aiming at laying the foundations of
a theory of concurrency that is equipped to ensure liveness properties of
distributed systems without making fairness assumptions. This theory will
encompass process algebra, temporal logic and semantic models, as well as
treatments of real-time. The agenda also includes developing a methodology that
allows successful application of this theory to the specification, analysis and
verification of realistic distributed systems, including routing protocols for
wireless networks.
  Contemporary process algebras and temporal logics fail to make distinctions
between systems of which one has a crucial liveness property and the other does
not, at least when assuming justness, a strong progress property, but not
assuming fairness. Setting up an alternative framework involves giving up on
identifying strongly bisimilar systems, inventing new induction principles,
developing new axiomatic bases for process algebras and new congruence formats
for operational semantics, and creating new treatments of time and probability.
  Even simple systems like fair schedulers or mutual exclusion protocols cannot
be accurately specified in standard process algebras (or Petri nets) in the
absence of fairness assumptions. Hence the work involves the study of adequate
language or model extensions, and their expressive power.
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04243</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strongly Secure and Efficient Data Shuffle On Hardware Enclaves</dc:title>
 <dc:creator>Chen, Ju</dc:creator>
 <dc:creator>Tang, Yuzhe</dc:creator>
 <dc:creator>Zhou, Hao</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Mitigating memory-access attacks on the Intel SGX architecture is an
important and open research problem. A natural notion of the mitigation is
cache-miss obliviousness which requires the cache-misses emitted during an
enclave execution are oblivious to sensitive data. This work realizes the
cache-miss obliviousness for the computation of data shuffling. The proposed
approach is to software-engineer the oblivious algorithm of Melbourne shuffle
on the Intel SGX/TSX architecture, where the Transaction Synchronization
eXtension (TSX) is (ab)used to detect the occurrence of cache misses. In the
system building, we propose software techniques to prefetch memory data prior
to the TSX transaction to defend the physical bus-tapping attacks. Our
evaluation based on real implementation shows that our system achieves superior
performance and lower transaction abort rate than the related work in the
existing literature.
</dc:description>
 <dc:description>Comment: Systex'17</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04247</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Image Registration via Empirical Mode Decomposition</dc:title>
 <dc:creator>Abbasi-Asl, Reza</dc:creator>
 <dc:creator>Ghaffari, Aboozar</dc:creator>
 <dc:creator>Fatemizadeh, Emad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Spatially varying intensity noise is a common source of distortion in images.
Bias field noise is one example of such distortion that is often present in the
magnetic resonance (MR) images. In this paper, we first show that empirical
mode decomposition (EMD) can considerably reduce the bias field noise in the MR
images. Then, we propose two hierarchical multi-resolution EMD-based algorithms
for robust registration of images in the presence of spatially varying noise.
One algorithm (LR-EMD) is based on registering EMD feature-maps of both
floating and reference images in various resolution levels. In the second
algorithm (AFR-EMD), we first extract an average feature-map based on EMD from
both floating and reference images. Then, we use a simple hierarchical
multi-resolution algorithm based on downsampling to register the average
feature-maps. Both algorithms achieve lower error rate and higher convergence
percentage compared to the intensity-based hierarchical registration.
Specifically, using mutual information as the similarity measure, AFR-EMD
achieves 42% lower error rate in intensity and 52% lower error rate in
transformation compared to intensity-based hierarchical registration. For
LR-EMD, the error rate is 32% lower for the intensity and 41% lower for the
transformation.
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04248</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linking Sequences of Events with Sparse or No Common Occurrence across
  Data Sets</dc:title>
 <dc:creator>Kim, Yunsung</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Data of practical interest - such as personal records, transaction logs, and
medical histories - are sequential collections of events relevant to a
particular source entity. Recent studies have attempted to link sequences that
represent a common entity across data sets to allow more comprehensive
statistical analyses and to identify potential privacy failures. Yet, current
approaches remain tailored to their specific domains of application, and they
fail when co-referent sequences in different data sets contain sparse or no
common events, which occurs frequently in many cases.
  To address this, we formalize the general problem of &quot;sequence linkage&quot; and
describe &quot;LDA-Link,&quot; a generic solution that is applicable even when
co-referent event sequences contain no common items at all. LDA-Link is built
upon &quot;Split-Document&quot; model, a new mixed-membership probabilistic model for the
generation of event sequence collections. It detects the latent similarity of
sequences and thus achieves robustness particularly when co-referent sequences
share sparse or no event overlap. We apply LDA-Link in the context of social
media profile reconciliation where users make no common posts across platforms,
comparing to the state-of-the-art generic solution to sequence linkage.
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04249</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Enhancement Network: A Refined Scene Text Detector</dc:title>
 <dc:creator>Zhang, Sheng</dc:creator>
 <dc:creator>Liu, Yuliang</dc:creator>
 <dc:creator>Jin, Lianwen</dc:creator>
 <dc:creator>Luo, Canjie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a refined scene text detector with a \textit{novel}
Feature Enhancement Network (FEN) for Region Proposal and Text Detection
Refinement. Retrospectively, both region proposal with \textit{only} $3\times
3$ sliding-window feature and text detection refinement with \textit{single
scale} high level feature are insufficient, especially for smaller scene text.
Therefore, we design a new FEN network with \textit{task-specific},
\textit{low} and \textit{high} level semantic features fusion to improve the
performance of text detection. Besides, since \textit{unitary}
position-sensitive RoI pooling in general object detection is unreasonable for
variable text regions, an \textit{adaptively weighted} position-sensitive RoI
pooling layer is devised for further enhancing the detecting accuracy. To
tackle the \textit{sample-imbalance} problem during the refinement stage, we
also propose an effective \textit{positives mining} strategy for efficiently
training our network. Experiments on ICDAR 2011 and 2013 robust text detection
benchmarks demonstrate that our method can achieve state-of-the-art results,
outperforming all reported methods in terms of F-measure.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, 2 tables. This paper is accepted to appear in
  AAAI 2018</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04258</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unified Spectral Clustering with Optimal Graph</dc:title>
 <dc:creator>Kang, Zhao</dc:creator>
 <dc:creator>Peng, Chong</dc:creator>
 <dc:creator>Cheng, Qiang</dc:creator>
 <dc:creator>Xu, Zenglin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Spectral clustering has found extensive use in many areas. Most traditional
spectral clustering algorithms work in three separate steps: similarity graph
construction; continuous labels learning; discretizing the learned labels by
k-means clustering. Such common practice has two potential flaws, which may
lead to severe information loss and performance degradation. First, predefined
similarity graph might not be optimal for subsequent clustering. It is
well-accepted that similarity graph highly affects the clustering results. To
this end, we propose to automatically learn similarity information from data
and simultaneously consider the constraint that the similarity matrix has exact
c connected components if there are c clusters. Second, the discrete solution
may deviate from the spectral solution since k-means method is well-known as
sensitive to the initialization of cluster centers. In this work, we transform
the candidate solution into a new one that better approximates the discrete
one. Finally, those three subtasks are integrated into a unified framework,
with each subtask iteratively boosted by using the results of the others
towards an overall optimal solution. It is known that the performance of a
kernel method is largely determined by the choice of kernels. To tackle this
practical problem of how to select the most suitable kernel for a particular
data set, we further extend our model to incorporate multiple kernel learning
ability. Extensive experiments demonstrate the superiority of our proposed
method as compared to existing clustering approaches.
</dc:description>
 <dc:description>Comment: Accepted by AAAI 2018</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04259</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Synthesis of Guaranteed-Quality Plans for Robot Fleets in
  Logistics Scenarios via Optimization Modulo Theories</dc:title>
 <dc:creator>Leofante, Francesco</dc:creator>
 <dc:creator>&#xc1;brah&#xe1;m, Erika</dc:creator>
 <dc:creator>Niemueller, Tim</dc:creator>
 <dc:creator>Lakemeyer, Gerhard</dc:creator>
 <dc:creator>Tacchella, Armando</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In manufacturing, the increasing involvement of autonomous robots in
production processes poses new challenges on the production management. In this
paper we report on the usage of Optimization Modulo Theories (OMT) to solve
certain multi-robot scheduling problems in this area. Whereas currently
existing methods are heuristic, our approach guarantees optimality for the
computed solution. We do not only present our final method but also its
chronological development, and draw some general observations for the
development of OMT-based approaches.
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04260</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of trackers for Pan-Tilt-Zoom Scenarios</dc:title>
 <dc:creator>Tang, Yucao</dc:creator>
 <dc:creator>Bilodeau, Guillaume-Alexandre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Tracking with a Pan-Tilt-Zoom (PTZ) camera has been a research topic in
computer vision for many years. Compared to tracking with a still camera, the
images captured with a PTZ camera are highly dynamic in nature because the
camera can perform large motion resulting in quickly changing capture
conditions. Furthermore, tracking with a PTZ camera involves camera control to
position the camera on the target. For successful tracking and camera control,
the tracker must be fast enough, or has to be able to predict accurately the
next position of the target. Therefore, standard benchmarks do not allow to
assess properly the quality of a tracker for the PTZ scenario. In this work, we
use a virtual PTZ framework to evaluate different tracking algorithms and
compare their performances. We also extend the framework to add target position
prediction for the next frame, accounting for camera motion and processing
delays. By doing this, we can assess if predicting can make long-term tracking
more robust as it may help slower algorithms for keeping the target in the
field of view of the camera. Results confirm that both speed and robustness are
required for tracking under the PTZ scenario.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures, International Conference on Pattern Recognition
  and Artificial Intelligence 2018</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04260</dc:identifier>
 <dc:identifier>ICPRAI (2018) 3-9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04268</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quickest Detection of Markov Networks</dc:title>
 <dc:creator>Heydari, Javad</dc:creator>
 <dc:creator>Tajer, Ali</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Detecting correlation structures in large networks arises in many domains.
Such detection problems are often studied independently of the underlying data
acquisition process, rendering settings in which data acquisition policies
(e.g., the sample-size) are pre-specified. Motivated by the advantages of
data-adaptive sampling, this paper treats the inherently coupled problems of
data acquisition and decision-making for correlation detection. Specifically,
this paper considers a Markov network of agents generating random variables,
and designs a quickest sequential strategy for discerning the correlation model
governing the Markov network. By abstracting the Markov network as an
undirected graph,designing the quickest sampling strategy becomes equivalent to
sequentially and data-adaptively identifying and sampling a sequence of
vertices in the graph. The existing data-adaptive approaches fail to solve this
problem since the node selection actions are dependent. Hence, a novel sampling
strategy is proposed to incorporate the correlation structures into the
decision rules for minimizing the average delay in forming a confident
decision. The proposed procedure involves searching over all possible future
decisions which becomes computationally prohibitive for large networks.
However, by leveraging the Markov properties it is shown that the search
horizon can be reduced to the neighbors of each node in the dependency graph
without compromising the performance. Performance analyses and numerical
evaluations demonstrate the gains of the proposed sequential approach over the
existing ones.
</dc:description>
 <dc:description>Comment: 41 pages, 10 figures</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04289</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Natural Language Inference with External Knowledge</dc:title>
 <dc:creator>Chen, Qian</dc:creator>
 <dc:creator>Zhu, Xiaodan</dc:creator>
 <dc:creator>Ling, Zhen-Hua</dc:creator>
 <dc:creator>Inkpen, Diana</dc:creator>
 <dc:creator>Wei, Si</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Modeling informal inference in natural language is very challenging. With the
recent availability of large annotated data, it has become feasible to train
complex models such as neural networks to perform natural language inference
(NLI), which have achieved state-of-the-art performance. Although there exist
relatively large annotated data, can machines learn all knowledge needed to
perform NLI from the data? If not, how can NLI models benefit from external
knowledge and how to build NLI models to leverage it? In this paper, we aim to
answer these questions by enriching the state-of-the-art neural natural
language inference models with external knowledge. We demonstrate that the
proposed models with external knowledge further improve the state of the art on
the Stanford Natural Language Inference (SNLI) dataset.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2018</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04291</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scale out for large minibatch SGD: Residual network training on
  ImageNet-1K with improved accuracy and reduced time to train</dc:title>
 <dc:creator>Codreanu, Valeriu</dc:creator>
 <dc:creator>Podareanu, Damian</dc:creator>
 <dc:creator>Saletore, Vikram</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  For the past 5 years, the ILSVRC competition and the ImageNet dataset have
attracted a lot of interest from the Computer Vision community, allowing for
state-of-the-art accuracy to grow tremendously. This should be credited to the
use of deep artificial neural network designs. As these became more complex,
the storage, bandwidth, and compute requirements increased. This means that
with a non-distributed approach, even when using the most high-density server
available, the training process may take weeks, making it prohibitive.
Furthermore, as datasets grow, the representation learning potential of deep
networks grows as well by using more complex models. This synchronicity
triggers a sharp increase in the computational requirements and motivates us to
explore the scaling behaviour on petaflop scale supercomputers. In this paper
we will describe the challenges and novel solutions needed in order to train
ResNet-50 in this large scale environment. We demonstrate above 90\% scaling
efficiency and a training time of 28 minutes using up to 104K x86 cores. This
is supported by software tools from Intel's ecosystem. Moreover, we show that
with regular 90 - 120 epoch train runs we can achieve a top-1 accuracy as high
as 77\% for the unmodified ResNet-50 topology. We also introduce the novel
Collapsed Ensemble (CE) technique that allows us to obtain a 77.5\% top-1
accuracy, similar to that of a ResNet-152, while training a unmodified
ResNet-50 topology for the same fixed training budget. All ResNet-50 models as
well as the scripts needed to replicate them will be posted shortly.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures, 13 tables</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04293</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hand Gesture Recognition with Leap Motion</dc:title>
 <dc:creator>Du, Youchen</dc:creator>
 <dc:creator>Liu, Shenglan</dc:creator>
 <dc:creator>Feng, Lin</dc:creator>
 <dc:creator>Chen, Menghui</dc:creator>
 <dc:creator>Wu, Jie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The recent introduction of depth cameras like Leap Motion Controller allows
researchers to exploit the depth information to recognize hand gesture more
robustly. This paper proposes a novel hand gesture recognition system with Leap
Motion Controller. A series of features are extracted from Leap Motion tracking
data, we feed these features along with HOG feature extracted from sensor
images into a multi-class SVM classifier to recognize performed gesture,
dimension reduction and feature weighted fusion are also discussed. Our results
show that our model is much more accurate than previous work.
</dc:description>
 <dc:description>Comment: 6 pages, 10 figures</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04293</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04295</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond-CMOS Device Benchmarking for Boolean and Non-Boolean Logic
  Applications</dc:title>
 <dc:creator>Pan, Chenyun</dc:creator>
 <dc:creator>Naeemi, Azad</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  The latest results of benchmarking research are presented for a variety of
beyond-CMOS charge- and spin-based devices. In addition to improving the
device-level models, several new device proposals and a few majorly modified
devices are investigated. Deep pipelining circuits are employed to boost the
throughput of low-power devices. Furthermore, the benchmarking methodology is
extended to interconnect-centric analyses and non-Boolean logic applications.
In contrast to Boolean circuits, non-Boolean circuits based on the cellular
neural network demonstrate that spintronic devices can potentially outperform
conventional CMOS devices.
</dc:description>
 <dc:description>Comment: 9 pages, 10 figures</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04297</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the ERM Principle with Networked Data</dc:title>
 <dc:creator>Wang, Yuanhong</dc:creator>
 <dc:creator>Wang, Yuyi</dc:creator>
 <dc:creator>Liu, Xingwu</dc:creator>
 <dc:creator>Pu, Juhua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Networked data, in which every training example involves two objects and may
share some common objects with others, is used in many machine learning tasks
such as learning to rank and link prediction. A challenge of learning from
networked examples is that target values are not known for some pairs of
objects. In this case, neither the classical i.i.d.\ assumption nor techniques
based on complete U-statistics can be used. Most existing theoretical results
of this problem only deal with the classical empirical risk minimization (ERM)
principle that always weights every example equally, but this strategy leads to
unsatisfactory bounds. We consider general weighted ERM and show new universal
risk bounds for this problem. These new bounds naturally define an optimization
problem which leads to appropriate weights for networked examples. Though this
optimization problem is not convex in general, we devise a new fully
polynomial-time approximation scheme (FPTAS) to solve it.
</dc:description>
 <dc:description>Comment: accepted by AAAI. arXiv admin note: substantial text overlap with
  arXiv:math/0702683 by other authors</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04305</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Latent Dirichlet Allocation (LDA) and Topic modeling: models,
  applications, a survey</dc:title>
 <dc:creator>Jelodar, Hamed</dc:creator>
 <dc:creator>Wang, Yongli</dc:creator>
 <dc:creator>Yuan, Chi</dc:creator>
 <dc:creator>Feng, Xia</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Topic modeling is one of the most powerful techniques in text mining for data
mining, latent data discovery, and finding relationships among data, text
documents. Researchers have published many articles in the field of topic
modeling and applied in various fields such as software engineering, political
science, medical and linguistic science, etc. There are various methods for
topic modeling, which Latent Dirichlet allocation (LDA) is one of the most
popular methods in this field. Researchers have proposed various models based
on the LDA in topic modeling. According to previous work, this paper can be
very useful and valuable for introducing LDA approaches in topic modeling. In
this paper, we investigated scholarly articles highly (between 2003 to 2016)
related to Topic Modeling based on LDA to discover the research development,
current trends and intellectual structure of topic modeling. Also, we summarize
challenges and introduce famous tools and datasets in topic modeling based on
LDA.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1505.07302 by other authors</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04309</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Regulating Artificial General Intelligence</dc:title>
 <dc:creator>Gans, Joshua S.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Here we examine the paperclip apocalypse concern for artificial general
intelligence (or AGI) whereby a superintelligent AI with a simple goal (ie.,
producing paperclips) accumulates power so that all resources are devoted
towards that simple goal and are unavailable for any other use. We provide
conditions under which a paper apocalypse can arise but also show that, under
certain architectures for recursive self-improvement of AIs, that a paperclip
AI may refrain from allowing power capabilities to be developed. The reason is
that such developments pose the same control problem for the AI as they do for
humans (over AIs) and hence, threaten to deprive it of resources for its
primary goal.
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04313</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-Supervised Learning via New Deep Network Inversion</dc:title>
 <dc:creator>Balestriero, Randall</dc:creator>
 <dc:creator>Roger, Vincent</dc:creator>
 <dc:creator>Glotin, Herve G.</dc:creator>
 <dc:creator>Baraniuk, Richard G.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We exploit a recently derived inversion scheme for arbitrary deep neural
networks to develop a new semi-supervised learning framework that applies to a
wide range of systems and problems. The approach outperforms current
state-of-the-art methods on MNIST reaching $99.14\%$ of test set accuracy while
using $5$ labeled examples per class. Experiments with one-dimensional signals
highlight the generality of the method. Importantly, our approach is simple,
efficient, and requires no change in the deep network architecture.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1710.09302</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04315</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A machine learning approach for efficient uncertainty quantification
  using multiscale methods</dc:title>
 <dc:creator>Chan, Shing</dc:creator>
 <dc:creator>Elsheikh, Ahmed H.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Several multiscale methods account for sub-grid scale features using coarse
scale basis functions. For example, in the Multiscale Finite Volume method the
coarse scale basis functions are obtained by solving a set of local problems
over dual-grid cells. We introduce a data-driven approach for the estimation of
these coarse scale basis functions. Specifically, we employ a neural network
predictor fitted using a set of solution samples from which it learns to
generate subsequent basis functions at a lower computational cost than solving
the local problems. The computational advantage of this approach is realized
for uncertainty quantification tasks where a large number of realizations has
to be evaluated. We attribute the ability to learn these basis functions to the
modularity of the local problems and the redundancy of the permeability patches
between samples. The proposed method is evaluated on elliptic problems yielding
very promising results.
</dc:description>
 <dc:description>Comment: Journal of Computational Physics (2017)</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04315</dc:identifier>
 <dc:identifier>doi:10.1016/j.jcp.2017.10.034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04322</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gender recognition and biometric identification using a large dataset of
  hand images</dc:title>
 <dc:creator>Afifi, Mahmoud</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The human hand possesses distinctive features which can reveal gender
information. In addition, the hand is considered one of the primary biometric
traits used to identify a person. In this work, we propose a large dataset of
human hand images with detailed ground-truth information for gender recognition
and biometric identification. The proposed dataset comprises of 11,076 hand
images (dorsal and palmar sides), from 190 subjects of different ages under the
same lighting conditions. Using this dataset, a convolutional neural network
(CNN) can be trained effectively for the gender recognition task. Based on
this, we design a two-stream CNN to tackle the gender recognition problem. This
trained model is then used as a feature extractor to feed a set of support
vector machine classifiers for the biometric identification task. To facilitate
access to the proposed dataset and replication of our experiments, the dataset,
trained CNN models, and Matlab source code are available at
(https://goo.gl/rQJndd).
</dc:description>
 <dc:description>Comment: 17 pages, 4 figures, 5 tables. Under consideration of PRL</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04323</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Order Attention Models for Visual Question Answering</dc:title>
 <dc:creator>Schwartz, Idan</dc:creator>
 <dc:creator>Schwing, Alexander G.</dc:creator>
 <dc:creator>Hazan, Tamir</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The quest for algorithms that enable cognitive abilities is an important part
of machine learning. A common trait in many recently investigated
cognitive-like tasks is that they take into account different data modalities,
such as visual and textual input. In this paper we propose a novel and
generally applicable form of attention mechanism that learns high-order
correlations between various data modalities. We show that high-order
correlations effectively direct the appropriate attention to the relevant
elements in the different data modalities that are required to solve the joint
task. We demonstrate the effectiveness of our high-order attention mechanism on
the task of visual question answering (VQA), where we achieve state-of-the-art
performance on the standard VQA dataset.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures, NIPS 2017</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04325</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extremely Large Minibatch SGD: Training ResNet-50 on ImageNet in 15
  Minutes</dc:title>
 <dc:creator>Akiba, Takuya</dc:creator>
 <dc:creator>Suzuki, Shuji</dc:creator>
 <dc:creator>Fukuda, Keisuke</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We demonstrate that training ResNet-50 on ImageNet for 90 epochs can be
achieved in 15 minutes with 1024 Tesla P100 GPUs. This was made possible by
using a large minibatch size of 32k. To maintain accuracy with this large
minibatch size, we employed several techniques such as RMSprop warm-up, batch
normalization without moving averages, and a slow-start learning rate schedule.
This paper also describes the details of the hardware and software of the
system used to achieve the above performance.
</dc:description>
 <dc:description>Comment: NIPS'17 Workshop: Deep Learning at Supercomputer Scale</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04326</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An efficient algorithm computing composition factors of $T(V)^{\otimes
  n}$</dc:title>
 <dc:creator>Saied, Amin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present an algorithm that computes the composition factors of the n-th
tensor power of the free associative algebra on a vector space. The composition
factors admit a description in terms of certain coefficients $c_{\lambda\mu}$
determining their irreducible structure. By reinterpreting these coefficients
as counting the number of ways to solve certain `decomposition-puzzles' we are
able to design an efficient algorithm extending the range of computation by a
factor of over 750. Furthermore, by visualising the data appropriately, we gain
insights into the nature of the coefficients leading to the development of a
new representation theoretic framework called PD-modules.
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04329</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Medical Diagnosis From Laboratory Tests by Combining Generative and
  Discriminative Learning</dc:title>
 <dc:creator>Zhang, Shiyue</dc:creator>
 <dc:creator>Xie, Pengtao</dc:creator>
 <dc:creator>Wang, Dong</dc:creator>
 <dc:creator>Xing, Eric P.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A primary goal of computational phenotype research is to conduct medical
diagnosis. In hospital, physicians rely on massive clinical data to make
diagnosis decisions, among which laboratory tests are one of the most important
resources. However, the longitudinal and incomplete nature of laboratory test
data casts a significant challenge on its interpretation and usage, which may
result in harmful decisions by both human physicians and automatic diagnosis
systems. In this work, we take advantage of deep generative models to deal with
the complex laboratory tests. Specifically, we propose an end-to-end
architecture that involves a deep generative variational recurrent neural
networks (VRNN) to learn robust and generalizable features, and a
discriminative neural network (NN) model to learn diagnosis decision making,
and the two models are trained jointly. Our experiments are conducted on a
dataset involving 46,252 patients, and the 50 most frequent tests are used to
predict the 50 most common diagnoses. The results show that our model, VRNN+NN,
significantly (p&lt;0.001) outperforms other baseline models. Moreover, we
demonstrate that the representations learned by the joint training are more
informative than those learned by pure generative models. Finally, we find that
our model offers a surprisingly good imputation for missing values.
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04340</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Augmentation Generative Adversarial Networks</dc:title>
 <dc:creator>Antoniou, Antreas</dc:creator>
 <dc:creator>Storkey, Amos</dc:creator>
 <dc:creator>Edwards, Harrison</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Effective training of neural networks requires much data. In the low-data
regime, parameters are underdetermined, and learnt networks generalise poorly.
Data Augmentation \cite{krizhevsky2012imagenet} alleviates this by using
existing data more effectively. However standard data augmentation produces
only limited plausible alternative data. Given there is potential to generate a
much broader set of augmentations, we design and train a generative model to do
data augmentation. The model, based on image conditional Generative Adversarial
Networks, takes data from a source domain and learns to take any data item and
generalise it to generate other within-class data items. As this generative
process does not depend on the classes themselves, it can be applied to novel
unseen classes of data. We show that a Data Augmentation Generative Adversarial
Network (DAGAN) augments standard vanilla classifiers well. We also show a
DAGAN can enhance few-shot learning systems such as Matching Networks. We
demonstrate these approaches on Omniglot, on EMNIST having learnt the DAGAN on
Omniglot, and VGG-Face data. In our experiments we can see over 13\% increase
in accuracy in the low-data regime experiments in Omniglot (from 69\% to 82\%),
EMNIST (73.9\% to 76\%) and VGG-Face (4.5\% to 12\%); in Matching Networks for
Omniglot we observe an increase of 0.5\% (from 96.9\% to 97.4\%) and an
increase of 1.8\% in EMNIST (from 59.5\% to 61.3\%).
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04345</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alpha-Divergences in Variational Dropout</dc:title>
 <dc:creator>Mazoure, Bogdan</dc:creator>
 <dc:creator>Islam, Riashat</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We investigate the use of alternative divergences to Kullback-Leibler (KL) in
variational inference(VI), based on the Variational Dropout \cite{kingma2015}.
Stochastic gradient variational Bayes (SGVB) \cite{aevb} is a general framework
for estimating the evidence lower bound (ELBO) in Variational Bayes. In this
work, we extend the SGVB estimator with using Alpha-Divergences, which are
alternative to divergences to VI' KL objective. The Gaussian dropout can be
seen as a local reparametrization trick of the SGVB objective. We extend the
Variational Dropout to use alpha divergences for variational inference. Our
results compare $\alpha$-divergence variational dropout with standard
variational dropout with correlated and uncorrelated weight noise. We show that
the $\alpha$-divergence with $\alpha \rightarrow 1$ (or KL divergence) is still
a good measure for use in variational inference, in spite of the efficient use
of Alpha-divergences for Dropout VI \cite{Li17}. $\alpha \rightarrow 1$ can
yield the lowest training error, and optimizes a good lower bound for the
evidence lower bound (ELBO) among all values of the parameter $\alpha \in
[0,\infty)$.
</dc:description>
 <dc:description>Comment: Bogdan Mazoure and Riashat Islam contributed equally</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04347</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Networks tag the location of bird vocalisations on audio
  spectrograms</dc:title>
 <dc:creator>Fanioudakis, Lefteris</dc:creator>
 <dc:creator>Potamitis, Ilyas</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This work focuses on reliable detection and segmentation of bird
vocalizations as recorded in the open field. Acoustic detection of avian sounds
can be used for the automatized monitoring of multiple bird taxa and querying
in long-term recordings for species of interest. These tasks are tackled in
this work, by suggesting two approaches: A) First, DenseNets are applied to
weekly labeled data to infer the attention map of the dataset (i.e. Salience
and CAM). We push further this idea by directing attention maps to the YOLO v2
Deepnet-based, detection framework to localize bird vocalizations. B) A deep
autoencoder, namely the U-net, maps the audio spectrogram of bird vocalizations
to its corresponding binary mask that encircles the spectral blobs of
vocalizations while suppressing other audio sources. We focus solely on
procedures requiring minimum human attendance, suitable to scan massive volumes
of data, in order to analyze them, evaluate insights and hypotheses and
identify patterns of bird activity. Hopefully, this approach will be valuable
to researchers, conservation practitioners, and decision makers that need to
design policies on biodiversity issues.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1609.08408</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04351</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic detection of alarm sounds in a noisy hospital environment
  using model and non-model based approaches</dc:title>
 <dc:creator>Raboshchuk, Ganna</dc:creator>
 <dc:creator>Quintana, Sergi G&#xf3;mez</dc:creator>
 <dc:creator>Lilja, Alex Peir&#xf3;</dc:creator>
 <dc:creator>Nadeu, Climent</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  In the noisy acoustic environment of a Neonatal Intensive Care Unit (NICU)
there is a variety of alarms, which are frequently triggered by the biomedical
equipment. In this paper different approaches for automatic detection of those
sound alarms are presented and compared: 1) a non-model-based approach that
employs signal processing techniques; 2) a model-based approach based on neural
networks; and 3) an approach that combines both non-model and model-based
approaches. The performance of the developed detection systems that follow each
of those approaches is assessed, analysed and compared both at the frame level
and at the event level by using an audio database recorded in a real-world
hospital environment.
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04352</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Reading Comprehension with ConvNets</dc:title>
 <dc:creator>Wu, Felix</dc:creator>
 <dc:creator>Lao, Ni</dc:creator>
 <dc:creator>Blitzer, John</dc:creator>
 <dc:creator>Yang, Guandao</dc:creator>
 <dc:creator>Weinberger, Kilian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  State-of-the-art deep reading comprehension models are dominated by recurrent
neural nets. Their sequential nature is a natural fit for language, but it also
precludes parallelization within an instances and often becomes the bottleneck
for deploying such models to latency critical scenarios. This is particularly
problematic for longer texts. Here we present a convolutional architecture as
an alternative to these recurrent architectures. Using simple dilated
convolutional units in place of recurrent ones, we achieve results comparable
to the state of the art on two question answering tasks, while at the same time
achieving up to two orders of magnitude speedups for question answering.
</dc:description>
 <dc:description>Comment: 15 pages, 10 figures, submitted to ICLR 2018</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04355</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Algorithms for Graph Coloring</dc:title>
 <dc:creator>Bhattacharya, Sayan</dc:creator>
 <dc:creator>Chakrabarty, Deeparnab</dc:creator>
 <dc:creator>Henzinger, Monika</dc:creator>
 <dc:creator>Nanongkai, Danupon</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We design fast dynamic algorithms for proper vertex and edge colorings in a
graph undergoing edge insertions and deletions. In the static setting, there
are simple linear time algorithms for $(\Delta+1)$- vertex coloring and
$(2\Delta-1)$-edge coloring in a graph with maximum degree $\Delta$. It is
natural to ask if we can efficiently maintain such colorings in the dynamic
setting as well. We get the following three results. (1) We present a
randomized algorithm which maintains a $(\Delta+1)$-vertex coloring with
$O(\log \Delta)$ expected amortized update time. (2) We present a deterministic
algorithm which maintains a $(1+o(1))\Delta$-vertex coloring with
$O(\text{poly} \log \Delta)$ amortized update time. (3) We present a simple,
deterministic algorithm which maintains a $(2\Delta-1)$-edge coloring with
$O(\log \Delta)$ worst-case update time. This improves the recent
$O(\Delta)$-edge coloring algorithm with $\tilde{O}(\sqrt{\Delta})$ worst-case
update time by Barenboim and Maimon.
</dc:description>
 <dc:description>Comment: To appear in SODA 2018</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04366</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parameter Estimation in Finite Mixture Models by Regularized Optimal
  Transport: A Unified Framework for Hard and Soft Clustering</dc:title>
 <dc:creator>Dessein, Arnaud</dc:creator>
 <dc:creator>Papadakis, Nicolas</dc:creator>
 <dc:creator>Deledalle, Charles-Alban</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this short paper, we formulate parameter estimation for finite mixture
models in the context of discrete optimal transportation with convex
regularization. The proposed framework unifies hard and soft clustering methods
for general mixture models. It also generalizes the celebrated
$k$\nobreakdash-means and expectation-maximization algorithms in relation to
associated Bregman divergences when applied to exponential family mixture
models.
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04367</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Longest Alignment with Edits in Data Streams</dc:title>
 <dc:creator>Grigorescu, Elena</dc:creator>
 <dc:creator>Azer, Erfan Sadeqi</dc:creator>
 <dc:creator>Zhou, Samson</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Analyzing patterns in data streams generated by network traffic, sensor
networks, or satellite feeds is a challenge for systems in which the available
storage is limited. In addition, real data is noisy, which makes designing data
stream algorithms even more challenging.
  Motivated by such challenges, we study algorithms for detecting the
similarity of two data streams that can be read in sync. Two strings $S, T\in
\Sigma^n$ form a $d$-near-alignment if the distance between them in some given
metric is at most $d$. We study the problem of identifying a longest substring
of $S$ and $T$ that forms a $d$-near-alignment under the edit distance, in the
simultaneous streaming model. In this model, symbols of strings $S$ and $T$ are
streamed at the same time, and the amount of available processing space is
sublinear in the length of the strings.
  We give several algorithms, including an exact one-pass algorithm that uses
$\mathcal{O}(d^2+d\log n)$ bits of space. We couple these results with
comparable lower bounds.
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04368</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine vs Machine: Minimax-Optimal Defense Against Adversarial Examples</dc:title>
 <dc:creator>Hamm, Jihun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recently, researchers have discovered that the state-of-the-art object
classifiers can be fooled easily by small perturbations in the input
unnoticeable to human eyes. It is known that an attacker can generate strong
adversarial examples if she knows the classifier parameters. Conversely, a
defender can robustify the classifier by retraining if she has the adversarial
examples. The cat-and-mouse game nature of attacks and defenses raises the
question of the presence of equilibria in the dynamics. In this paper, we
present a neural-network based attack class to approximate a larger but
intractable class of attacks, and formulate the attacker-defender interaction
as a zero-sum leader-follower game. We present sensitivity-penalized
optimization algorithms to find minimax solutions, which are the best
worst-case defenses against whitebox attacks. Advantages of the learning-based
attacks and defenses compared to gradient-based attacks and defenses are
demonstrated with MNIST and CIFAR-10.
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:date>2017-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04387</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity of UAV-Enabled Multicast Channel: Joint Trajectory Design and
  Power Allocation</dc:title>
 <dc:creator>Wu, Yundi</dc:creator>
 <dc:creator>Xu, Jie</dc:creator>
 <dc:creator>Qiu, Ling</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies an unmanned aerial vehicle (UAV)-enabled multicast
channel, in which a UAV serves as a mobile transmitter to deliver common
information to a set of $K$ ground users. We aim to characterize the capacity
of this channel over a finite UAV communication period, subject to its maximum
speed constraint and an average transmit power constraint. To achieve the
capacity, the UAV should use a sufficiently long code that spans over its whole
communication period. Accordingly, the multicast channel capacity is achieved
via maximizing the minimum achievable time-averaged rates of the $K$ users, by
jointly optimizing the UAV's trajectory and transmit power allocation over
time. However, this problem is non-convex and difficult to be solved optimally.
To tackle this problem, we first consider a relaxed problem by ignoring the
maximum UAV speed constraint, and obtain its globally optimal solution via the
Lagrange dual method. The optimal solution reveals that the UAV should hover
above a finite number of ground locations, with the optimal hovering duration
and transmit power at each location. Next, based on such a
multi-location-hovering solution, we present a successive hover-and-fly
trajectory design and obtain the corresponding optimal transmit power
allocation for the case with the maximum UAV speed constraint. Numerical
results show that our proposed joint UAV trajectory and transmit power
optimization significantly improves the achievable rate of the UAV-enabled
multicast channel, and also greatly outperforms the conventional multicast
channel with a fixed-location transmitter.
</dc:description>
 <dc:description>Comment: Submitted for possible publication</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04387</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04411</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Neural Network with Word Embeddings for Chinese Word
  Segmentation</dc:title>
 <dc:creator>Wang, Chunqi</dc:creator>
 <dc:creator>Xu, Bo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Character-based sequence labeling framework is flexible and efficient for
Chinese word segmentation (CWS). Recently, many character-based neural models
have been applied to CWS. While they obtain good performance, they have two
obvious weaknesses. The first is that they heavily rely on manually designed
bigram feature, i.e. they are not good at capturing n-gram features
automatically. The second is that they make no use of full word information.
For the first weakness, we propose a convolutional neural model, which is able
to capture rich n-gram features without any feature engineering. For the second
one, we propose an effective approach to integrate the proposed model with word
embeddings. We evaluate the model on two benchmark datasets: PKU and MSR.
Without any feature engineering, the model obtains competitive performance --
95.7% on PKU and 97.3% on MSR. Armed with word embeddings, the model achieves
state-of-the-art performance on both datasets -- 96.5% on PKU and 98.0% on MSR,
without using any external labeled resource.
</dc:description>
 <dc:description>Comment: will be published by IJCNLP2017</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04412</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Refutation of Guinea's &quot;Understanding SAT is in P&quot;</dc:title>
 <dc:creator>Abascal, Jackson</dc:creator>
 <dc:creator>Maimon, Shir</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this work, we summarize and critique the paper &quot;Understanding SAT is in P&quot;
by Alejandro S\'anchez Guinea [arXiv:1504.00337]. The paper claims to present a
polynomial-time solution for the NP-complete language 3-SAT. We show that
Guinea's algorithm is flawed and does not prove 3-SAT is in P.
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04419</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overlaying Quantitative Measurement on Networks: An Evaluation of Three
  Positioning and Nine Visual Marker Techniques</dc:title>
 <dc:creator>Zhang, Guohao</dc:creator>
 <dc:creator>Auchus, Alexander P.</dc:creator>
 <dc:creator>Kochunov, Peter</dc:creator>
 <dc:creator>Elmqvist, Niklas</dc:creator>
 <dc:creator>Chen, Jian</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We report results from an experiment on ranking visual markers and node
positioning techniques for network visualizations. Inspired by prior ranking
studies, we rethink the ranking when the dataset size increases and when the
markers are distributed in space. Centrality indices are visualized as node
attributes. Our experiment studies nine visual markers and three positioning
methods. Our results suggest that direct encoding of quantities improves
accuracy by about 20% compared to previous results. Of the three positioning
techniques, circular was always in the top group, and matrix and projection
switch orders depending on two factors: whether or not the tasks demand
symmetry, or the nodes are within closely proximity. Among the most interesting
results of ranking the visual markers for comparison tasks are that hue and
area fall into the top groups for nearly all multi-scale comparison tasks;
Shape (ordered by curvature) is perhaps not as scalable as we have thought and
can support more accurate answers only when two quantities are compared;
Lightness and slope are least accurate for quantitative comparisons regardless
of scale of the comparison tasks. Our experiment is among the first to acquire
a complete picture of ranking visual markers in different scales for comparison
tasks.
</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04422</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Souper: A Synthesizing Superoptimizer</dc:title>
 <dc:creator>Sasnauskas, Raimondas</dc:creator>
 <dc:creator>Chen, Yang</dc:creator>
 <dc:creator>Collingbourne, Peter</dc:creator>
 <dc:creator>Ketema, Jeroen</dc:creator>
 <dc:creator>Taneja, Jubi</dc:creator>
 <dc:creator>Regehr, John</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  If we can automatically derive compiler optimizations, we might be able to
sidestep some of the substantial engineering challenges involved in creating
and maintaining a high-quality compiler. We developed Souper, a synthesizing
superoptimizer, to see how far these ideas might be pushed in the context of
LLVM. Along the way, we discovered that Souper's intermediate representation
was sufficiently similar to the one in Microsoft Visual C++ that we applied
Souper to that compiler as well. Shipping, or about-to-ship, versions of both
compilers contain optimizations suggested by Souper but implemented by hand.
Alternately, when Souper is used as a fully automated optimization pass it
compiles a Clang compiler binary that is about 3 MB (4.4%) smaller than the one
compiled by LLVM.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04427</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grothendieck constant is norm of Strassen matrix multiplication tensor</dc:title>
 <dc:creator>Zhang, Jinjie</dc:creator>
 <dc:creator>Lim, Lek-Heng</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We show that two important quantities from two disparate areas of complexity
theory --- Strassen's exponent of matrix multiplication $\omega$ and
Grothendieck's constant $K_G$ --- are intimately related. They are different
measures of size for the same underlying object --- the matrix multiplication
tensor, i.e., the $3$-tensor or bilinear operator $\mu_{l,m,n} : \mathbb{F}^{l
\times m} \times \mathbb{F}^{m \times n} \to \mathbb{F}^{l \times n}$, $(A,B)
\mapsto AB$ defined by matrix-matrix product over $\mathbb{F} = \mathbb{R}$ or
$\mathbb{C}$. It is well-known that Strassen's exponent of matrix
multiplication is the greatest lower bound on (the log of) a tensor rank of
$\mu_{l,m,n}$. We will show that Grothendieck's constant is the least upper
bound on a tensor norm of $\mu_{l,m,n}$, taken over all $l, m, n \in
\mathbb{N}$. Aside from relating the two celebrated quantities, this insight
allows us to rewrite Grothendieck's inequality as a norm inequality \[
\lVert\mu_{l,m,n}\rVert_{1,2,\infty}
=\max_{X,Y,M\neq0}\frac{|\operatorname{tr}(XMY)|}{\lVert X\rVert_{1,2}\lVert
Y\rVert_{2,\infty}\lVert M\rVert_{\infty,1}}\leq K_G, \] and thereby allows a
natural generalization to arbitrary $p,q, r$, $1\le p,q,r\le \infty$. We show
that the following generalization is locally sharp: \[
\lVert\mu_{l,m,n}\rVert_{p,q,r}=\max_{X,Y,M\neq0}\frac{|\operatorname{tr}(XMY)|}{\|X\|_{p,q}\|Y\|_{q,r}\|M\|_{r,p}}\leq
K_G \cdot l^{|1/q-1/2|} \cdot m^{1-1/p} \cdot n^{1/r}, \] and conjecture that
Grothendieck's inequality is unique: $(p,q,r )=(1,2,\infty)$ is the only choice
for which $\lVert\mu_{l,m,n}\rVert_{p,q,r}$ is uniformly bounded by a constant.
We establish two-thirds of this conjecture: uniform boundedness of
$\lVert\mu_{l,m,n}\rVert_{p,q,r}$ over all $l,m,n$ necessarily implies that
$\min \{p,q,r\}=1$ and $\max \{p,q,r\}=\infty$.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04433</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crowd counting via scale-adaptive convolutional neural network</dc:title>
 <dc:creator>Zhang, Lu</dc:creator>
 <dc:creator>Shi, Miaojing</dc:creator>
 <dc:creator>Chen, Qiaobo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The task of crowd counting is to automatically estimate the pedestrian number
in crowd images. To cope with the scale and perspective changes that commonly
exist in crowd images, state-of-the-art approaches employ multi-column CNN
architectures to regress density maps of crowd images. Multiple columns have
different receptive fields corresponding to pedestrians (heads) of different
scales. We instead propose a scale-adaptive CNN (SaCNN) architecture with a
backbone of fixed small receptive fields. We extract feature maps from multiple
layers and adapt them to have the same output size; we combine them to produce
the final density map. The number of people is computed by integrating the
density map. We also introduce a relative count loss along with the density map
loss to improve the network generalization on crowd scenes with few
pedestrians, where most representative approaches perform poorly on. We conduct
extensive experiments on the ShanghaiTech, UCF_CC_50 and WorldExpo datasets as
well as a new dataset SmartCity that we collect for crowd scenes with few
people. The results demonstrate significant improvements of SaCNN over the
state-of-the-art.
</dc:description>
 <dc:description>Comment: IEEE Winter Conf. on Applications of Computer Vision (WACV'18)</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04433</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04434</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faithful to the Original: Fact Aware Neural Abstractive Summarization</dc:title>
 <dc:creator>Cao, Ziqiang</dc:creator>
 <dc:creator>Wei, Furu</dc:creator>
 <dc:creator>Li, Wenjie</dc:creator>
 <dc:creator>Li, Sujian</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Unlike extractive summarization, abstractive summarization has to fuse
different parts of the source text, which inclines to create fake facts. Our
preliminary study reveals nearly 30% of the outputs from a state-of-the-art
neural summarization system suffer from this problem. While previous
abstractive summarization approaches usually focus on the improvement of
informativeness, we argue that faithfulness is also a vital prerequisite for a
practical abstractive summarization system. To avoid generating fake facts in a
summary, we leverage open information extraction and dependency parse
technologies to extract actual fact descriptions from the source text. The
dual-attention sequence-to-sequence framework is then proposed to force the
generation conditioned on both the source text and the extracted fact
descriptions. Experiments on the Gigaword benchmark dataset demonstrate that
our model can greatly reduce fake summaries by 80%. Notably, the fact
descriptions also bring significant improvement on informativeness since they
often condense the meaning of the source text.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures, AAAI 2018</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04436</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SQLNet: Generating Structured Queries From Natural Language Without
  Reinforcement Learning</dc:title>
 <dc:creator>Xu, Xiaojun</dc:creator>
 <dc:creator>Liu, Chang</dc:creator>
 <dc:creator>Song, Dawn</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Synthesizing SQL queries from natural language is a long-standing open
problem and has been attracting considerable interest recently. Toward solving
the problem, the de facto approach is to employ a sequence-to-sequence-style
model. Such an approach will necessarily require the SQL queries to be
serialized. Since the same SQL query may have multiple equivalent
serializations, training a sequence-to-sequence-style model is sensitive to the
choice from one of them. This phenomenon is documented as the &quot;order-matters&quot;
problem. Existing state-of-the-art approaches rely on reinforcement learning to
reward the decoder when it generates any of the equivalent serializations.
However, we observe that the improvement from reinforcement learning is
limited.
  In this paper, we propose a novel approach, i.e., SQLNet, to fundamentally
solve this problem by avoiding the sequence-to-sequence structure when the
order does not matter. In particular, we employ a sketch-based approach where
the sketch contains a dependency graph so that one prediction can be done by
taking into consideration only the previous predictions that it depends on. In
addition, we propose a sequence-to-set model as well as the column attention
mechanism to synthesize the query based on the sketch. By combining all these
novel techniques, we show that SQLNet can outperform the prior art by 9% to 13%
on the WikiSQL task.
</dc:description>
 <dc:description>Comment: Submitting to ICLR 2018</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04438</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Abduction under Partial Observability</dc:title>
 <dc:creator>Juba, Brendan</dc:creator>
 <dc:creator>Li, Zongyi</dc:creator>
 <dc:creator>Miller, Evan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Juba recently proposed a formulation of learning abductive reasoning from
examples, in which both the relative plausibility of various explanations, as
well as which explanations are valid, are learned directly from data. The main
shortcoming of this formulation of the task is that it assumes access to
full-information (i.e., fully specified) examples; relatedly, it offers no role
for declarative background knowledge, as such knowledge is rendered redundant
in the abduction task by complete information. In this work, we extend the
formulation to utilize such partially specified examples, along with
declarative background knowledge about the missing data. We show that it is
possible to use implicitly learned rules together with the explicitly given
declarative knowledge to support hypotheses in the course of abduction. We
observe that when a small explanation exists, it is possible to obtain a
much-improved guarantee in the challenging exception-tolerant setting. Such
small, human-understandable explanations are of particular interest for
potential applications of the task.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2017-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04449</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General Framework for Covariance Matrix Optimization in MIMO Systems</dc:title>
 <dc:creator>Xing, Chengwen</dc:creator>
 <dc:creator>Jing, Yindi</dc:creator>
 <dc:creator>Wang, Shuai</dc:creator>
 <dc:creator>Wang, Jiaheng</dc:creator>
 <dc:creator>An, Jianping</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For multi-input multi-output (MIMO) systems, many transceiver design problems
involve the optimization of the covariance matrices of the transmitted signals.
Karush-Kuhn-Tucker (KKT) conditions based derivations are the most popular
method, and many derivations and results have been reported for different
scenarios of MIMO systems. We propose a unified framework in formulating the
KKT conditions for general MIMO systems. Based on this framework, the optimal
water-filling structure of the transmission covariance matrices are derived
rigorously, which is applicable to a wide range of MIMO systems. Our results
show that for MIMO systems with various power constraint formulations and
objective functions, both the derivation logics and water-filling structures
for the optimal covariance matrix solutions are fundamentally the same. Thus,
our unified framework and solution reveal the underlying relationships among
the different water-filling structures of the covariance matrices. Furthermore,
our results provide new solutions to the covariance matrix optimization of many
complicated MIMO systems with multiple users and imperfect channel state
information (CSI) which were unknown before.
</dc:description>
 <dc:description>Comment: 43 Pages, 4 Figures, IEEE Communications</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04450</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>All-Transfer Learning for Deep Neural Networks and its Application to
  Sepsis Classification</dc:title>
 <dc:creator>Sawada, Yoshihide</dc:creator>
 <dc:creator>Sato, Yoshikuni</dc:creator>
 <dc:creator>Nakada, Toru</dc:creator>
 <dc:creator>Ujimoto, Kei</dc:creator>
 <dc:creator>Hayashi, Nobuhiro</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this article, we propose a transfer learning method for deep neural
networks (DNNs). Deep learning has been widely used in many applications.
However, applying deep learning is problematic when a large amount of training
data are not available. One of the conventional methods for solving this
problem is transfer learning for DNNs. In the field of image recognition,
state-of-the-art transfer learning methods for DNNs re-use parameters trained
on source domain data except for the output layer. However, this method may
result in poor classification performance when the amount of target domain data
is significantly small. To address this problem, we propose a method called
All-Transfer Deep Learning, which enables the transfer of all parameters of a
DNN. With this method, we can compute the relationship between the source and
target labels by the source domain knowledge. We applied our method to actual
two-dimensional electrophoresis image~(2-DE image) classification for
determining if an individual suffers from sepsis; the first attempt to apply a
classification approach to 2-DE images for proteomics, which has attracted
considerable attention as an extension beyond genomics. The results suggest
that our proposed method outperforms conventional transfer learning methods for
DNNs.
</dc:description>
 <dc:description>Comment: Long version of article published at ECAI 2016 (9 pages, 13 figures,
  8 tables)</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04451</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Concepts and Compositional Voting</dc:title>
 <dc:creator>Wang, Jianyu</dc:creator>
 <dc:creator>Zhang, Zhishuai</dc:creator>
 <dc:creator>Xie, Cihang</dc:creator>
 <dc:creator>Zhou, Yuyin</dc:creator>
 <dc:creator>Premachandran, Vittal</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:creator>Xie, Lingxi</dc:creator>
 <dc:creator>Yuille, Alan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  It is very attractive to formulate vision in terms of pattern theory
\cite{Mumford2010pattern}, where patterns are defined hierarchically by
compositions of elementary building blocks. But applying pattern theory to real
world images is currently less successful than discriminative methods such as
deep networks. Deep networks, however, are black-boxes which are hard to
interpret and can easily be fooled by adding occluding objects. It is natural
to wonder whether by better understanding deep networks we can extract building
blocks which can be used to develop pattern theoretic models. This motivates us
to study the internal representations of a deep network using vehicle images
from the PASCAL3D+ dataset. We use clustering algorithms to study the
population activities of the features and extract a set of visual concepts
which we show are visually tight and correspond to semantic parts of vehicles.
To analyze this we annotate these vehicles by their semantic parts to create a
new dataset, VehicleSemanticParts, and evaluate visual concepts as unsupervised
part detectors. We show that visual concepts perform fairly well but are
outperformed by supervised discriminative methods such as Support Vector
Machines (SVM). We next give a more detailed analysis of visual concepts and
how they relate to semantic parts. Following this, we use the visual concepts
as building blocks for a simple pattern theoretical model, which we call
compositional voting. In this model several visual concepts combine to detect
semantic parts. We show that this approach is significantly better than
discriminative methods like SVM and deep networks trained specifically for
semantic part detection. Finally, we return to studying occlusion by creating
an annotated dataset with occlusion, called VehicleOcclusion, and show that
compositional voting outperforms even deep networks when the amount of
occlusion becomes large.
</dc:description>
 <dc:description>Comment: It is accepted by Annals of Mathematical Sciences and Applications</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04451</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04452</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Digitising Cultural Complexity: Representing Rich Cultural Data in a Big
  Data environment</dc:title>
 <dc:creator>Edmond, Jennifer</dc:creator>
 <dc:creator>Folan, Georgina Nugent</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  One of the major terminological forces driving ICT integration in research
today is that of &quot;big data.&quot; While the phrase sounds inclusive and integrative,
&quot;big data&quot; approaches are highly selective, excluding input that cannot be
effectively structured, represented, or digitised. Data of this complex sort is
precisely the kind that human activity produces, but the technological
imperative to enhance signal through the reduction of noise does not
accommodate this richness. Data and the computational approaches that
facilitate &quot;big data&quot; have acquired a perceived objectivity that belies their
curated, malleable, reactive, and performative nature. In an input environment
where anything can &quot;be data&quot; once it is entered into the system as &quot;data,&quot; data
cleaning and processing, together with the metadata and information
architectures that structure and facilitate our cultural archives acquire a
capacity to delimit what data are. This engenders a process of simplification
that has major implications for the potential for future innovation within
research environments that depend on rich material yet are increasingly
mediated by digital technologies. This paper presents the preliminary findings
of the European-funded KPLEX (Knowledge Complexity) project which investigates
the delimiting effect digital mediation and datafication has on rich, complex
cultural data. The paper presents a systematic review of existing implicit
definitions of data, elaborating on the implications of these definitions and
highlighting the ways in which metadata and computational technologies can
restrict the interpretative potential of data. It sheds light on the gap
between analogue or augmented digital practices and fully computational ones,
and the strategies researchers have developed to deal with this gap. The paper
proposes a reconceptualisation of data as it is functionally employed within
digitally-mediated research so as to incorporate and acknowledge the richness
and complexity of our source materials.
</dc:description>
 <dc:description>Comment: Ways of Being in a Digital Age - A Review Conference, Oct 2017,
  Liverpool, United Kingdom. 2017</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04453</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparsification of the Alignment Path Search Space in Dynamic Time
  Warping</dc:title>
 <dc:creator>Soheily-Khah, Saeid</dc:creator>
 <dc:creator>Marteau, Pierre-Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Temporal data are naturally everywhere, especially in the digital era that
sees the advent of big data and internet of things. One major challenge that
arises during temporal data analysis and mining is the comparison of time
series or sequences, which requires to determine a proper distance or
(dis)similarity measure. In this context, the Dynamic Time Warping (DTW) has
enjoyed success in many domains, due to its 'temporal elasticity', a property
particularly useful when matching temporal data. Unfortunately this
dissimilarity measure suffers from a quadratic computational cost, which
prohibits its use for large scale applications. This work addresses the
sparsification of the alignment path search space for DTW-like measures,
essentially to lower their computational cost without loosing on the quality of
the measure. As a result of our sparsification approach, two new
(dis)similarity measures, namely SP-DTW (Sparsified-Paths search space DTW) and
its kernelization SP-K rdtw (Sparsified-Paths search space K rdtw kernel) are
proposed for time series comparison. A wide range of public datasets is used to
evaluate the efficiency (estimated in term of speed-up ratio and classification
accuracy) of the proposed (dis)similarity measures on the 1-Nearest Neighbor
(1-NN) and the Support Vector Machine (SVM) classification algorithms. Our
experiment shows that our proposed measures provide a significant speed-up
without loosing on accuracy. Furthermore, at the cost of a slight reduction of
the speedup they significantly outperform on the accuracy criteria the old but
well known Sakoe-Chiba approach that reduces the DTW path search space using a
symmetric corridor.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04457</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Word, Subword or Character? An Empirical Study of Granularity in
  Chinese-English NMT</dc:title>
 <dc:creator>Wang, Yining</dc:creator>
 <dc:creator>Zhou, Long</dc:creator>
 <dc:creator>Zhang, Jiajun</dc:creator>
 <dc:creator>Zong, Chengqing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Neural machine translation (NMT), a new approach to machine translation, has
been proved to outperform conventional statistical machine translation (SMT)
across a variety of language pairs. Translation is an open-vocabulary problem,
but most existing NMT systems operate with a fixed vocabulary, which causes the
incapability of translating rare words. This problem can be alleviated by using
different translation granularities, such as character, subword and hybrid
word-character. Translation involving Chinese is one of the most difficult
tasks in machine translation, however, to the best of our knowledge, there has
not been any other work exploring which translation granularity is most
suitable for Chinese in NMT. In this paper, we conduct an extensive comparison
using Chinese-English NMT as a case study. Furthermore, we discuss the
advantages and disadvantages of various translation granularities in detail.
Our experiments show that subword model performs best for Chinese-to-English
translation with the vocabulary which is not so big while hybrid word-character
model is most suitable for English-to-Chinese translation. Moreover,
experiments of different granularities show that Hybrid_BPE method can achieve
best result on Chinese-to-English translation task.
</dc:description>
 <dc:description>Comment: 15 pages,3 figures,CWMT2017. arXiv admin note: text overlap with
  arXiv:1609.08144 by other authors</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04459</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilayer Nonlinear Processing for Information Privacy in Sensor
  Networks</dc:title>
 <dc:creator>He, Xin</dc:creator>
 <dc:creator>Sun, Meng</dc:creator>
 <dc:creator>Tay, Wee Peng</dc:creator>
 <dc:creator>Gong, Yi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  A sensor network wishes to transmit information to a fusion center to allow
it to detect a public hypothesis, but at the same time prevent it from
inferring a private hypothesis. We propose a multilayer nonlinear processing
procedure at each sensor to distort the sensor's data before it is sent to the
fusion center. In our proposed framework, sensors are grouped into clusters,
and each sensor first applies a nonlinear fusion function on the information it
receives from sensors in the same cluster and in a previous layer. A linear
weighting matrix is then used to distort the information it sends to sensors in
the next layer. We adopt a nonparametric approach and develop a modified mirror
descent algorithm to optimize the weighting matrices so as to ensure that the
regularized empirical risk of detecting the private hypothesis is above a given
privacy threshold, while minimizing the regularized empirical risk of detecting
the public hypothesis. Experiments on empirical datasets demonstrate that our
approach is able to achieve a good trade-off between the error rates of the
public and private hypothesis.
</dc:description>
 <dc:description>Comment: 13 pages, 17 figures, submitted to IEEE Transactions on Information
  Forensics and Security</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04460</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blind Source Separation Using Mixtures of Alpha-Stable Distributions</dc:title>
 <dc:creator>Keriven, Nicolas</dc:creator>
 <dc:creator>Deleforge, Antoine</dc:creator>
 <dc:creator>Liutkus, Antoine</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  We propose a new blind source separation algorithm based on mixtures of
alpha-stable distributions. Complex symmetric alpha-stable distributions have
been recently showed to better model audio signals in the time-frequency domain
than classical Gaussian distributions thanks to their larger dynamic range.
However, inference of these models is notoriously hard to perform because their
probability density functions do not have a closed-form expression in general.
Here, we introduce a novel method for estimating mixture of alpha-stable
distributions based on random moment matching. We apply this to the blind
estimation of binary masks in individual frequency bands from multichannel
convolutive audio mixes. We show that the proposed method yields better
separation performance than Gaussian-based binary-masking methods.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04467</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Cell Probe Bounds for Succinct Boolean Matrix-Vector
  Multiplication</dc:title>
 <dc:creator>Chakraborty, Diptarka</dc:creator>
 <dc:creator>Kamma, Lior</dc:creator>
 <dc:creator>Larsen, Kasper Green</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The conjectured hardness of Boolean matrix-vector multiplication has been
used with great success to prove conditional lower bounds for numerous
important data structure problems, see Henzinger et al. [STOC'15]. In recent
work, Larsen and Williams [SODA'17] attacked the problem from the upper bound
side and gave a surprising cell probe data structure (that is, we only charge
for memory accesses, while computation is free). Their cell probe data
structure answers queries in $\tilde{O}(n^{7/4})$ time and is succinct in the
sense that it stores the input matrix in read-only memory, plus an additional
$\tilde{O}(n^{7/4})$ bits on the side. In this paper, we essentially settle the
cell probe complexity of succinct Boolean matrix-vector multiplication. We
present a new cell probe data structure with query time $\tilde{O}(n^{3/2})$
storing just $\tilde{O}(n^{3/2})$ bits on the side. We then complement our data
structure with a lower bound showing that any data structure storing $r$ bits
on the side, with $n &lt; r &lt; n^2$ must have query time $t$ satisfying $t r =
\tilde{\Omega}(n^3)$. For $r \leq n$, any data structure must have $t =
\tilde{\Omega}(n^2)$. Since lower bounds in the cell probe model also apply to
classic word-RAM data structures, the lower bounds naturally carry over. We
also prove similar lower bounds for matrix-vector multiplication over
$\mathbb{F}_2$.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04471</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domain-Specific Acceleration and Auto-Parallelization of Legacy
  Scientific Code in FORTRAN 77 using Source-to-Source Compilation</dc:title>
 <dc:creator>Vanderbauwhede, Wim</dc:creator>
 <dc:creator>Davidson, Gavin</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Massively parallel accelerators such as GPGPUs, manycores and FPGAs represent
a powerful and affordable tool for scientists who look to speed up simulations
of complex systems. However, porting code to such devices requires a detailed
understanding of heterogeneous programming tools and effective strategies for
parallelization. In this paper we present a source to source compilation
approach with whole-program analysis to automatically transform single-threaded
FORTRAN 77 legacy code into OpenCL-accelerated programs with parallelized
kernels.
  The main contributions of our work are: (1) whole-source refactoring to allow
any subroutine in the code to be offloaded to an accelerator. (2) Minimization
of the data transfer between the host and the accelerator by eliminating
redundant transfers. (3) Pragmatic auto-parallelization of the code to be
offloaded to the accelerator by identification of parallelizable maps and
reductions.
  We have validated the code transformation performance of the compiler on the
NIST FORTRAN 78 test suite and several real-world codes: the Large Eddy
Simulator for Urban Flows, a high-resolution turbulent flow model; the shallow
water component of the ocean model Gmodel; the Linear Baroclinic Model, an
atmospheric climate model and Flexpart-WRF, a particle dispersion simulator.
  The automatic parallelization component has been tested on as 2-D Shallow
Water model (2DSW) and on the Large Eddy Simulator for Urban Flows (UFLES) and
produces a complete OpenCL-enabled code base. The fully OpenCL-accelerated
versions of the 2DSW and the UFLES are resp. 9x and 20x faster on GPU than the
original code on CPU, in both cases this is the same performance as manually
ported code.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures, submitted to &quot;Computers and Fluids&quot; as full
  paper from ParCFD conference entry</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04473</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sixteen space-filling curves and traversals for d-dimensional cubes and
  simplices</dc:title>
 <dc:creator>Haverkort, Herman</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  This article describes sixteen different ways to traverse d-dimensional space
recursively in a way that is well-defined for any number of dimensions. Each of
these traversals has distinct properties that may be beneficial for certain
applications. Some of the traversals are novel, some have been known in
principle but had not been described adequately for any number of dimensions,
some of the traversals have been known. This article is the first to present
them all in a consistent notation system. Furthermore, with this article, tools
are provided to enumerate points in a regular grid in the order in which they
are visited by each traversal. In particular, we cover: five discontinuous
traversals based on subdividing cubes into 2^d subcubes: Z-traversal (Morton
indexing), U-traversal, Gray-code traversal, Double-Gray-code traversal, and
Inside-out traversal; two discontinuous traversals based on subdividing
simplices into 2^d subsimplices: the Hill-Z traversal and the Maehara-reflected
traversal; five continuous traversals based on subdividing cubes into 2^d
subcubes: the Base-camp Hilbert curve, the Harmonious Hilbert curve, the Alfa
Hilbert curve, the Beta Hilbert curve, and the Butz-Hilbert curve; four
continuous traversals based on subdividing cubes into 3^d subcubes: the Peano
curve, the Coil curve, the Half-coil curve, and the Meurthe curve. All of these
traversals are self-similar in the sense that the traversal in each of the
subcubes or subsimplices of a cube or simplex, on any level of recursive
subdivision, can be obtained by scaling, translating, rotating, reflecting
and/or reversing the traversal of the complete unit cube or simplex.
</dc:description>
 <dc:description>Comment: 28 pages, 12 figures</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04474</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Persuasion with limited communication capacity</dc:title>
 <dc:creator>Treust, Ma&#xeb;l Le</dc:creator>
 <dc:creator>Tomala, Tristan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We consider a Bayesian persuasion problem where the persuader and the
decision maker communicate through an imperfect channel which has a fixed and
limited number of messages and is subject to exogenous noise. Imperfect
communication entails a loss of payoff for the persuader. We establish an upper
bound on the payoffs the persuader can secure by communicating through the
channel. We also show that the bound is tight: if the persuasion problem
consists of a large number of independent copies of the same base problem, then
the persuader can achieve this bound arbitrarily closely by using strategies
which tie all the problems together. We characterize this optimal payoff as a
function of the information-theoretic capacity of the communication channel.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04480</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Audio-to-score alignment of piano music using RNN-based automatic music
  transcription</dc:title>
 <dc:creator>Kwon, Taegyun</dc:creator>
 <dc:creator>Jeong, Dasaem</dc:creator>
 <dc:creator>Nam, Juhan</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  We propose a framework for audio-to-score alignment on piano performance that
employs automatic music transcription (AMT) using neural networks. Even though
the AMT result may contain some errors, the note prediction output can be
regarded as a learned feature representation that is directly comparable to
MIDI note or chroma representation. To this end, we employ two recurrent neural
networks that work as the AMT-based feature extractors to the alignment
algorithm. One predicts the presence of 88 notes or 12 chroma in frame-level
and the other detects note onsets in 12 chroma. We combine the two types of
learned features for the audio-to-score alignment. For comparability, we apply
dynamic time warping as an alignment algorithm without any additional
post-processing. We evaluate the proposed framework on the MAPS dataset and
compare it to previous work. The result shows that the alignment framework with
the learned features significantly improves the accuracy, achieving less than
10 ms in mean onset error.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, The paper was published in SMC 2017 proceedings,
  Proceedings of 14th Sound and Music Computing Conference (SMC). 2017</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04481</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Automatic Diagnosis Method of Facial Acne Vulgaris Based on
  Convolutional Neural Network</dc:title>
 <dc:creator>Shen, Xiaolei</dc:creator>
 <dc:creator>Zhang, Jiachi</dc:creator>
 <dc:creator>Yan, Chenjun</dc:creator>
 <dc:creator>Zhou, Hong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present a new automatic diagnosis method of facial acne
vulgaris based on convolutional neural network. This method is proposed to
overcome the shortcoming of classification types in previous methods. The core
of our method is to extract features of images based on convolutional neural
network and achieve classification by classifier. We design a binary classifier
of skin-and-non-skin to detect skin area and a seven-classifier to achieve the
classification of facial acne vulgaris and healthy skin. In the experiment, we
compared the effectiveness of our convolutional neural network and the
pre-trained VGG16 neural network on the ImageNet dataset. And we use the ROC
curve and normal confusion matrix to evaluate the performance of the binary
classifier and the seven-classifier. The results of our experiment show that
the pre-trained VGG16 neural network is more effective in extracting image
features. The classifiers based on the pre-trained VGG16 neural network achieve
the skin detection and acne classification and have good robustness.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures, 5 tables</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04483</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional Random Field and Deep Feature Learning for Hyperspectral
  Image Segmentation</dc:title>
 <dc:creator>Alam, Fahim Irfan</dc:creator>
 <dc:creator>Zhou, Jun</dc:creator>
 <dc:creator>Liew, Alan Wee-Chung</dc:creator>
 <dc:creator>Jia, Xiuping</dc:creator>
 <dc:creator>Chanussot, Jocelyn</dc:creator>
 <dc:creator>Gao, Yongsheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image segmentation is considered to be one of the critical tasks in
hyperspectral remote sensing image processing. Recently, convolutional neural
network (CNN) has established itself as a powerful model in segmentation and
classification by demonstrating excellent performances. The use of a graphical
model such as a conditional random field (CRF) contributes further in capturing
contextual information and thus improving the segmentation performance. In this
paper, we propose a method to segment hyperspectral images by considering both
spectral and spatial information via a combined framework consisting of CNN and
CRF. We use multiple spectral cubes to learn deep features using CNN, and then
formulate deep CRF with CNN-based unary and pairwise potential functions to
effectively extract the semantic correlations between patches consisting of
three-dimensional data cubes. Effective piecewise training is applied in order
to avoid the computationally expensive iterative CRF inference. Furthermore, we
introduce a deep deconvolution network that improves the segmentation masks. We
also introduce a new dataset and experimented our proposed method on it along
with several widely adopted benchmark datasets to evaluate the effectiveness of
our method. By comparing our results with those from several state-of-the-art
models, we show the promising potential of our method.
</dc:description>
 <dc:description>Comment: Submitted for Journal (Version 2)</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04484</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stable project allocation under distributional constraints</dc:title>
 <dc:creator>&#xc1;goston, Kolos Csaba</dc:creator>
 <dc:creator>Bir&#xf3;, P&#xe9;ter</dc:creator>
 <dc:creator>Sz&#xe1;nt&#xf3;, Rich&#xe1;rd</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In a two-sided matching market when agents on both sides have preferences the
stability of the solution is typically the most important requirement. However,
we may also face some distributional constraints with regard to the minimum
number of assignees or the distribution of the assignees according to their
types. These two requirements can be challenging to reconcile in practice. In
this paper we describe two real applications, a project allocation problem and
a workshop assignment problem, both involving some distributional constraints.
We used integer programming techniques to find reasonably good solutions with
regard to the stability and the distributional constraints. Our approach can be
useful in a variety of different applications, such as resident allocation with
lower quotas, controlled school choice or college admissions with affirmative
action.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04489</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Parallel Best-Response Algorithm with Exact Line Search for Nonconvex
  Sparsity-Regularized Rank Minimization</dc:title>
 <dc:creator>Yang, Yang</dc:creator>
 <dc:creator>Pesavento, Marius</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose a convergent parallel best-response algorithm with
the exact line search for the nondifferentiable nonconvex sparsity-regularized
rank minimization problem. On the one hand, it exhibits a faster convergence
than subgradient algorithms and block coordinate descent algorithms. On the
other hand, its convergence to a stationary point is guaranteed, while ADMM
algorithms only converge for convex problems. Furthermore, the exact line
search procedure in the proposed algorithm is performed efficiently in
closed-form to avoid the meticulous choice of stepsizes, which is however a
common bottleneck in subgradient algorithms and successive convex approximation
algorithms. Finally, the proposed algorithm is numerically tested.
</dc:description>
 <dc:description>Comment: Submitted to IEEE ICASSP 2017</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04492</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Design for Strategic Coordination of Autonomous Devices with
  Non-Aligned Utilities</dc:title>
 <dc:creator>Treust, Ma&#xeb;l Le</dc:creator>
 <dc:creator>Tomala, Tristan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we investigate the coordination of autonomous devices with
non-aligned utility functions. Both encoder and decoder are considered as
players, that choose the encoding and the decoding in order to maximize their
long-run utility functions. The topology of the point-to-point network under
investigation, suggests that the decoder implements a strategy, knowing in
advance the strategy of the encoder. We characterize the encoding and decoding
functions that form an equilibrium, by using empirical coordination. The
equilibrium solution is related to an auxiliary game in which both players
choose some conditional distributions in order to maximize their expected
utilities. This problem is closely related to the literature on &quot;Information
Design&quot; in Game Theory. We also characterize the set of posterior distributions
that are compatible with a rate-limited channel between the encoder and the
decoder. Finally, we provide an example of non-aligned utility functions
corresponding to parallel fading multiple access channels.
</dc:description>
 <dc:description>Comment: IEEE Proc. of the Fifty-fourth Annual Allerton Conference Allerton
  House, UIUC, Illinois, USA September 27 - 30, 2016</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04496</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear-Time Algorithms for Maximum-Weight Induced Matchings and Minimum
  Chain Covers in Convex Bipartite Graphs</dc:title>
 <dc:creator>Klemz, Boris</dc:creator>
 <dc:creator>Rote, G&#xfc;nter</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A bipartite graph $G=(U,V,E)$ is convex if the vertices in $V$ can be
linearly ordered such that for each vertex $u\in U$, the neighbors of $u$ are
consecutive in the ordering of $V$. An induced matching $H$ of $G$ is a
matching such that no edge of $E$ connects endpoints of two different edges of
$H$. We show that in a convex bipartite graph with $n$ vertices and $m$
weighted edges, an induced matching of maximum total weight can be computed in
$O(n+m)$ time. An unweighted convex bipartite graph has a representation of
size $O(n)$ that records for each vertex $u\in U$ the first and last neighbor
in the ordering of $V$. Given such a compact representation, we compute an
induced matching of maximum cardinality in $O(n)$ time.
  In convex bipartite graphs, maximum-cardinality induced matchings are dual to
minimum chain covers. A chain cover is a covering of the edge set by chain
subgraphs, that is, subgraphs that do not contain induced matchings of more
than one edge. Given a compact representation, we compute a representation of a
minimum chain cover in $O(n)$ time. If no compact representation is given, the
cover can be computed in $O(n+m)$ time.
  All of our algorithms achieve optimal running time for the respective problem
and model. Previous algorithms considered only the unweighted case, and the
best algorithm for computing a maximum-cardinality induced matching or a
minimum chain cover in a convex bipartite graph had a running time of $O(n^2)$.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04498</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Targeted Advertising Based on Browsing History</dc:title>
 <dc:creator>Zhang, Yong</dc:creator>
 <dc:creator>Zhou, Hongming</dc:creator>
 <dc:creator>Tan, Nganmeng</dc:creator>
 <dc:creator>Bagheri, Saeed</dc:creator>
 <dc:creator>Er, Meng Joo</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Audience interest, demography, purchase behavior and other possible
classifications are ex- tremely important factors to be carefully studied in a
targeting campaign. This information can help advertisers and publishers
deliver advertisements to the right audience group. How- ever, it is not easy
to collect such information, especially for the online audience with whom we
have limited interaction and minimum deterministic knowledge. In this paper, we
pro- pose a predictive framework that can estimate online audience demographic
attributes based on their browsing histories. Under the proposed framework,
first, we retrieve the content of the websites visited by audience, and
represent the content as website feature vectors; second, we aggregate the
vectors of websites that audience have visited and arrive at feature vectors
representing the users; finally, the support vector machine is exploited to
predict the audience demographic attributes. The key to achieving good
prediction performance is preparing representative features of the audience.
Word Embedding, a widely used tech- nique in natural language processing tasks,
together with term frequency-inverse document frequency weighting scheme is
used in the proposed method. This new representation ap- proach is unsupervised
and very easy to implement. The experimental results demonstrate that the new
audience feature representation method is more powerful than existing baseline
methods, leading to a great improvement in prediction accuracy.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04500</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Case Study of the 2016 Korean Cyber Command Compromise</dc:title>
 <dc:creator>Park, Kyong Jae</dc:creator>
 <dc:creator>Park, Sung Mi</dc:creator>
 <dc:creator>James, Joshua I.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  On October 2016 the South Korean cyber military unit was the victim of a
successful cyber attack that allowed access to internal networks. Per usual
with large scale attacks against South Korean entities, the hack was
immediately attributed to North Korea. Also, per other large-scale cyber
security incidents, the same types of 'evidence' were used for attribution
purposes. Disclosed methods of attribution provide weak evidence, and the
procedure Korean organizations tend to use for information disclosure lead many
to question any conclusions. We will analyze and discuss a number of issues
with the current way that South Korean organizations disclose cyber attack
information to the public. A time line of events and disclosures will be
constructed and analyzed in the context of appropriate measures for cyber
warfare. Finally, we will examine the South Korean cyber military attack in
terms previously proposed cyber warfare response guidelines. Specifically,
whether any of the guidelines can be applied to this real-world case, and if
so, is South Korea justified in declaring war based on the most recent cyber
attack.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04500</dc:identifier>
 <dc:identifier>European Conference on Information Warfare and Security, ECCWS.
  p.315-321 (2017)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04502</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>United Nations Digital Blue Helmets as a Starting Point for Cyber
  Peacekeeping</dc:title>
 <dc:creator>Akatyev, Nikolay</dc:creator>
 <dc:creator>James, Joshua I.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Prior works, such as the Tallinn manual on the international law applicable
to cyber warfare, focus on the circumstances of cyber warfare. Many
organizations are considering how to conduct cyber warfare, but few have
discussed methods to reduce, or even prevent, cyber conflict. A recent series
of publications started developing the framework of Cyber Peacekeeping (CPK)
and its legal requirements. These works assessed the current state of
organizations such as ITU IMPACT, NATO CCDCOE and Shanghai Cooperation
Organization, and found that they did not satisfy requirements to effectively
host CPK activities. An assessment of organizations currently working in the
areas related to CPK found that the United Nations (UN) has mandates and
organizational structures that appear to somewhat overlap the needs of CPK.
However, the UN's current approach to Peacekeeping cannot be directly mapped to
cyberspace. In this research we analyze the development of traditional
Peacekeeping in the United Nations, and current initiatives in cyberspace.
Specifically, we will compare the proposed CPK framework with the recent
initiative of the United Nations named the 'Digital Blue Helmets' as well as
with other projects in the UN which helps to predict and mitigate conflicts.
Our goal is to find practical recommendations for the implementation of the CPK
framework in the United Nations, and to examine how responsibilities defined in
the CPK framework overlap with those of the 'Digital Blue Helmets' and the
Global Pulse program.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04502</dc:identifier>
 <dc:identifier>European Conference on Information Warfare and Security, ECCWS.
  p.8-16 (2017)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04503</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consensus Halving is PPA-Complete</dc:title>
 <dc:creator>Filos-Ratsikas, Aris</dc:creator>
 <dc:creator>Goldberg, Paul W.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We show that the computational problem CONSENSUS-HALVING is PPA-complete, the
first PPA-completeness result for a problem whose definition does not involve
an explicit circuit. We also show that an approximate version of this problem
is polynomial-time equivalent to NECKLACE SPLITTING, which establishes
PPAD-hardness for NECKLACE SPLITTING, and suggests that it is also
PPA-complete.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04504</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tilings with noncongruent triangles</dc:title>
 <dc:creator>Kupavskii, Andrey</dc:creator>
 <dc:creator>Pach, J&#xe1;nos</dc:creator>
 <dc:creator>Tardos, G&#xe1;bor</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  We solve a problem of R. Nandakumar by proving that there is no tiling of the
plane with pairwise noncongruent triangles of equal area and equal perimeter.
We also show that no convex polygon with more than three sides can be tiled
with finitely many triangles such that no pair of them share a full side.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04506</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constraint Solving via Fractional Edge Covers</dc:title>
 <dc:creator>Grohe, Martin</dc:creator>
 <dc:creator>Marx, D&#xe1;niel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Many important combinatorial problems can be modeled as constraint
satisfaction problems. Hence identifying polynomial-time solvable classes of
constraint satisfaction problems has received a lot of attention. In this
paper, we are interested in structural properties that can make the problem
tractable. So far, the largest structural class that is known to be
polynomial-time solvable is the class of bounded hypertree width instances
introduced by Gottlob et al. Here we identify a new class of polynomial-time
solvable instances: those having bounded fractional edge cover number.
  Combining hypertree width and fractional edge cover number, we then introduce
the notion of fractional hypertree width. We prove that constraint satisfaction
problems with bounded fractional hypertree width can be solved in polynomial
time (provided that a the tree decomposition is given in the input). Together
with a recent approximation algorithm for finding such decompositions by Marx,
it follows that bounded fractional hypertree width is now the most general
known structural property that guarantees polynomial-time solvability.
</dc:description>
 <dc:description>Comment: Conference version in SODA 2006</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04506</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04513</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>COMBINE: a novel drug discovery platform designed to capture insight and
  experience of users</dc:title>
 <dc:creator>Cho, Sung Jin</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The insight and experience gained by a researcher are often lost because the
current productive and analytics software are inherently data-centric,
disconnected, and scattered. The connected nature of insight and experience can
be captured if the applications themselves are connected. How connected
applications concept is implemented in COnstruct cheMical and BIological
NEtwork (COMBINE), a novel user-centric drug discovery platform, is described.
Using publicly available data, how COMBINE users capture insight and experience
is explained, and how COMBINE users perform data organization, data sharing,
data analysis, and data visualization is illustrated.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04518</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Supervised Learning Concept for Reducing User Interaction in Passenger
  Cars</dc:title>
 <dc:creator>St&#xe4;rk, Marius</dc:creator>
 <dc:creator>Backes, Damian</dc:creator>
 <dc:creator>Kehl, Christian</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this article an automation system for human-machine-interfaces (HMI) for
setpoint adjustment using supervised learning is presented. We use HMIs of
multi-modal thermal conditioning systems in passenger cars as example for a
complex setpoint selection system. The goal is the reduction of interaction
complexity up to full automation. The approach is not limited to climate
control applications but can be extended to other setpoint-based HMIs.
</dc:description>
 <dc:description>Comment: 4 pages, 9 figures, concept only</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04520</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fair Knapsack</dc:title>
 <dc:creator>Fluschnik, Till</dc:creator>
 <dc:creator>Skowron, Piotr</dc:creator>
 <dc:creator>Triphaus, Mervin</dc:creator>
 <dc:creator>Wilker, Kai</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the following multiagent variant of the knapsack problem. We are
given a set of items, a set of voters, and a value of the budget; each item is
endowed with a cost and each voter assigns to each item a certain value. The
goal is to select a subset of items with the total cost not exceeding the
budget, in a way that is consistent with the voters' preferences. Since the
preferences of the voters over the items can vary significantly, we need a way
of aggregating these preferences, in order to select the socially most
preferred valid knapsack. We study three approaches to aggregating voters
preferences, which are motivated by the literature on multiwinner elections and
fair allocation. This way we introduce the concepts of individually best,
diverse, and fair knapsack. We study computational complexity (including
parameterized complexity, and complexity under restricted domains) of computing
the aforementioned concepts of multiagent knapsacks.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04528</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple And Efficient Architecture Search for Convolutional Neural
  Networks</dc:title>
 <dc:creator>Elsken, Thomas</dc:creator>
 <dc:creator>Metzen, Jan-Hendrik</dc:creator>
 <dc:creator>Hutter, Frank</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Neural networks have recently had a lot of success for many tasks. However,
neural network architectures that perform well are still typically designed
manually by experts in a cumbersome trial-and-error process. We propose a new
method to automatically search for well-performing CNN architectures based on a
simple hill climbing procedure whose operators apply network morphisms,
followed by short optimization runs by cosine annealing. Surprisingly, this
simple method yields competitive results, despite only requiring resources in
the same order of magnitude as training a single network. E.g., on CIFAR-10,
our method designs and trains networks with an error rate below 6% in only 12
hours on a single GPU; training for one day reduces this error further, to
almost 5%.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2018</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04532</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards an interdisciplinary, socio-technical analysis of software
  ecosystem health</dc:title>
 <dc:creator>Mens, Tom</dc:creator>
 <dc:creator>Adams, Bram</dc:creator>
 <dc:creator>Marsan, Josianne</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This extended abstract presents the research goals and preliminary research
results of the interdisciplinary research project SECOHealth, an ongoing
collaboration between research teams of Polytechnique Montreal (Canada), the
University of Mons (Belgium) and Laval University (Canada). SECOHealth aims to
contribute to research and practice in software engineering by delivering a
validated interdisciplinary scientific methodology and a catalog of guidelines
and recommendation tools for improving software ecosystem health.
</dc:description>
 <dc:description>Comment: 3 pages; presented at BENEVOL 2017, the BElgian-NEtherlands software
  eVOLution symposium, December 2017, Antwerp, Belgium</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04548</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Cloud-Based Service for Maintaining and Analyzing Data About
  Scientific Events</dc:title>
 <dc:creator>Behrend, Andreas</dc:creator>
 <dc:creator>Vahdati, Sahar</dc:creator>
 <dc:creator>Lange, Christoph</dc:creator>
 <dc:creator>Engels, Christiane</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  We propose the new cloud-based service OpenResearch for managing and
analyzing data about scientific events such as conferences and workshops in a
persistent and reliable way. This includes data about scientific articles,
participants, acceptance rates, submission numbers, impact values as well as
organizational details such as program committees, chairs, fees and sponsors.
OpenResearch is a centralized repository for scientific events and supports
researchers in collecting, organizing, sharing and disseminating information
about scientific events in a structured way. An additional feature currently
under development is the possibility to archive web pages along with the
extracted semantic data in order to lift the burden of maintaining new and old
conference web sites from public research institutions. However, the main
advantage is that this cloud-based repository enables a comprehensive analysis
of conference data. Based on extracted semantic data, it is possible to
determine quality estimations, scientific communities, research trends as well
the development of acceptance rates, fees, and number of participants in a
continuous way complemented by projections into the future. Furthermore, data
about research articles can be systematically explored using a content-based
analysis as well as citation linkage. All data maintained in this
crowd-sourcing platform is made freely available through an open SPARQL
endpoint, which allows for analytical queries in a flexible and user-defined
way.
</dc:description>
 <dc:description>Comment: A completed version of this paper had been accepted in SAVE-SD
  workshop 2017 at WWW conference</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04556</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving the Resource Constrained Project Scheduling Problem Using the
  Parallel Tabu Search Designed for the CUDA Platform</dc:title>
 <dc:creator>Bukata, Libor</dc:creator>
 <dc:creator>Sucha, Premysl</dc:creator>
 <dc:creator>Hanzalek, Zdenek</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In the paper, a parallel Tabu Search algorithm for the Resource Constrained
Project Scheduling Problem is proposed. To deal with this NP-hard combinatorial
problem many optimizations have been performed. For example, a resource
evaluation algorithm is selected by a heuristic and an effective Tabu List was
designed. In addition to that, a capacity-indexed resource evaluation algorithm
was proposed and the GPU (Graphics Processing Unit) version uses a homogeneous
model to reduce the required communication bandwidth. According to the
experiments, the GPU version outperforms the optimized parallel CPU version
with respect to the computational time and the quality of solutions. In
comparison with other existing heuristics, the proposed solution often gives
better quality solutions.
</dc:description>
 <dc:description>Comment: Published in Journal of Parallel and Distributed Computing</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04556</dc:identifier>
 <dc:identifier>Journal of Parallel and Distributed Computing, 77 (2015), 58-68</dc:identifier>
 <dc:identifier>doi:10.1016/j.jpdc.2014.11.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04559</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linking Types for Multi-Language Software: Have Your Cake and Eat It Too</dc:title>
 <dc:creator>Patterson, Daniel</dc:creator>
 <dc:creator>Ahmed, Amal</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Software developers compose systems from components written in many different
languages. A business-logic component may be written in Java or OCaml, a
resource-intensive component in C or Rust, and a high-assurance component in
Coq. In this multi-language world, program execution sends values from one
linguistic context to another. This boundary-crossing exposes values to
contexts with unforeseen behavior---that is, behavior that could not arise in
the source language of the value. For example, a Rust function may end up being
applied in an ML context that violates the memory usage policy enforced by
Rust's type system. This leads to the question of how developers ought to
reason about code in such a multi-language world where behavior inexpressible
in one language is easily realized in another.
  This paper proposes the novel idea of linking types to address the problem of
reasoning about single-language components in a multi-lingual setting.
Specifically, linking types allow programmers to annotate where in a program
they can link with components inexpressible in their unadulterated language.
This enables developers to reason about (behavioral) equality using only their
own language and the annotations, even though their code may be linked with
code written in a language with more expressive power.
</dc:description>
 <dc:description>Comment: 14 pages; published in SNAPL '17, 2nd Summit on Advances in
  Programming Languages, May 7-10, 2017, Pacific Grove, California</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04559</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.SNAPL.2017.12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04564</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phonemic and Graphemic Multilingual CTC Based Speech Recognition</dc:title>
 <dc:creator>M&#xfc;ller, Markus</dc:creator>
 <dc:creator>St&#xfc;ker, Sebastian</dc:creator>
 <dc:creator>Waibel, Alex</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Training automatic speech recognition (ASR) systems requires large amounts of
data in the target language in order to achieve good performance. Whereas large
training corpora are readily available for languages like English, there exists
a long tail of languages which do suffer from a lack of resources. One method
to handle data sparsity is to use data from additional source languages and
build a multilingual system. Recently, ASR systems based on recurrent neural
networks (RNNs) trained with connectionist temporal classification (CTC) have
gained substantial research interest. In this work, we extended our previous
approach towards training CTC-based systems multilingually. Our systems feature
a global phone set, based on the joint phone sets of each source language. We
evaluated the use of different language combinations as well as the addition of
Language Feature Vectors (LFVs). As contrastive experiment, we built systems
based on graphemes as well. Systems having a multilingual phone set are known
to suffer in performance compared to their monolingual counterparts. With our
proposed approach, we could reduce the gap between these mono- and multilingual
setups, using either graphemes or phonemes.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04569</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilingual Adaptation of RNN Based ASR Systems</dc:title>
 <dc:creator>M&#xfc;ller, Markus</dc:creator>
 <dc:creator>St&#xfc;ker, Sebastian</dc:creator>
 <dc:creator>Waibel, Alex</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A large amount of data is required for automatic speech recognition (ASR)
systems achieving good performance. While such data is readily available for
languages like English, there exists a long tail of languages with only limited
language resources. By using data from additional source languages, this
problem can be mitigated. In this work, we focus on multilingual systems based
on recurrent neural networks (RNNs), trained using the Connectionist Temporal
Classification (CTC) loss function. Using a multilingual set of acoustic units
to train systems jointly on multiple languages poses difficulties: While the
same phones share the same symbols across languages, they are pronounced
slightly different because of, e.g., small shifts in tongue positions. To
address this issue, we proposed Language Feature Vectors (LFVs) to train
language adaptive multilingual systems. In this work, we extended this approach
by introducing a novel technique which we call &quot;modulation&quot; to add LFVs . We
evaluated our approach in multiple conditions, showing improvements in both
full and low resource conditions as well as for grapheme and phone based
systems.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04574</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Explanatory Rules from Noisy Data</dc:title>
 <dc:creator>Evans, Richard</dc:creator>
 <dc:creator>Grefenstette, Edward</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  Artificial Neural Networks are powerful function approximators capable of
modelling solutions to a wide variety of problems, both supervised and
unsupervised. As their size and expressivity increases, so too does the
variance of the model, yielding a nearly ubiquitous overfitting problem.
Although mitigated by a variety of model regularisation methods, the common
cure is to seek large amounts of training data---which is not necessarily
easily obtained---that sufficiently approximates the data distribution of the
domain we wish to test on. In contrast, logic programming methods such as
Inductive Logic Programming offer an extremely data-efficient process by which
models can be trained to reason on symbolic domains. However, these methods are
unable to deal with the variety of domains neural networks can be applied to:
they are not robust to noise in or mislabelling of inputs, and perhaps more
importantly, cannot be applied to non-symbolic domains where the data is
ambiguous, such as operating on raw pixels. In this paper, we propose a
Differentiable Inductive Logic framework, which can not only solve tasks which
traditional ILP systems are suited for, but shows a robustness to noise and
error in the training data which ILP cannot cope with. Furthermore, as it is
trained by backpropagation against a likelihood objective, it can be hybridised
by connecting it with neural networks over ambiguous data in order to be
applied to domains which ILP cannot address, while providing data efficiency
and generalisation beyond what neural networks on their own can achieve.
</dc:description>
 <dc:description>Comment: 64 pages, to appear in Journal of Artificial Intelligence Research
  (Special Track on Deep Learning, Knowledge Representation, and Reasoning)</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04591</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond the Hype: On Using Blockchains in Trust Management for
  Authentication</dc:title>
 <dc:creator>Alexopoulos, Nikolaos</dc:creator>
 <dc:creator>Daubert, J&#xf6;rg</dc:creator>
 <dc:creator>M&#xfc;hlh&#xe4;user, Max</dc:creator>
 <dc:creator>Habib, Sheikh Mahbub</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Trust Management (TM) systems for authentication are vital to the security of
online interactions, which are ubiquitous in our everyday lives. Various
systems, like the Web PKI (X.509) and PGP's Web of Trust are used to manage
trust in this setting. In recent years, blockchain technology has been
introduced as a panacea to our security problems, including that of
authentication, without sufficient reasoning, as to its merits.In this work, we
investigate the merits of using open distributed ledgers (ODLs), such as the
one implemented by blockchain technology, for securing TM systems for
authentication. We formally model such systems, and explore how blockchain can
help mitigate attacks against them. After formal argumentation, we conclude
that in the context of Trust Management for authentication, blockchain
technology, and ODLs in general, can offer considerable advantages compared to
previous approaches. Our analysis is, to the best of our knowledge, the first
to formally model and argue about the security of TM systems for
authentication, based on blockchain technology. To achieve this result, we
first provide an abstract model for TM systems for authentication. Then, we
show how this model can be conceptually encoded in a blockchain, by expressing
it as a series of state transitions. As a next step, we examine five prevalent
attacks on TM systems, and provide evidence that blockchain-based solutions can
be beneficial to the security of such systems, by mitigating, or completely
negating such attacks.
</dc:description>
 <dc:description>Comment: A version of this paper was published in IEEE Trustcom.
  http://ieeexplore.ieee.org/document/8029486/</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04592</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vertebral body segmentation with GrowCut: Initial experience, workflow
  and practical application</dc:title>
 <dc:creator>Egger, Jan</dc:creator>
 <dc:creator>Nimsky, Christopher</dc:creator>
 <dc:creator>Chen, Xiaojun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  In this contribution, we used the GrowCut segmentation algorithm publicly
available in three-dimensional Slicer for three-dimensional segmentation of
vertebral bodies. To the best of our knowledge, this is the first time that the
GrowCut method has been studied for the usage of vertebral body segmentation.
In brief, we found that the GrowCut segmentation times were consistently less
than the manual segmentation times. Hence, GrowCut provides an alternative to a
manual slice-by-slice segmentation process.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04592</dc:identifier>
 <dc:identifier>SAGE Open Medicine, Volume 5, pp. 1-10, Nov. 2017</dc:identifier>
 <dc:identifier>doi:10.1177/2050312117740984</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04595</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Destination Prediction Based on Route Choices with Transition
  Matrix Optimization</dc:title>
 <dc:creator>Sun, Heli</dc:creator>
 <dc:creator>Yang, Zhou</dc:creator>
 <dc:creator>Huang, Jianbin</dc:creator>
 <dc:creator>Jia, Xiaolin</dc:creator>
 <dc:creator>Guan, Ziyu</dc:creator>
 <dc:creator>Zhao, Zhongmeng</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Destination prediction is an essential task in a variety of mobile
applications. In this paper, we optimize the matrix operation and adapt a
semi-lazy framework to improve the prediction accuracy and efficiency of a
state-of-the-art approach. To this end, we employ efficient dynamic-programming
by devising several data constructs including Efficient Transition Probability
and Transition Probabilities with Detours that are capable of pinpointing the
minimum amount of computation. We prove that our method achieves one order of
cut in both time and space complexity. The experimental results on real-world
and synthetic datasets have shown that our solution consistently outperforms
its state-of-the-art counterparts in terms of both efficiency (approximately
over 100 times faster) and accuracy (above 30% increase).
</dc:description>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04595</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04596</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Not all bytes are equal: Neural byte sieve for fuzzing</dc:title>
 <dc:creator>Rajpal, Mohit</dc:creator>
 <dc:creator>Blum, William</dc:creator>
 <dc:creator>Singh, Rishabh</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Fuzzing is a popular dynamic program analysis technique used to find
vulnerabilities in complex software. Fuzzing involves presenting a target
program with crafted malicious input designed to cause crashes, buffer
overflows, memory errors, and exceptions. Crafting malicious inputs in an
efficient manner is a difficult open problem and often the best approach to
generating such inputs is through applying uniform random mutations to
pre-existing valid inputs (seed files). We present a learning technique that
uses neural networks to learn patterns in the input files from past fuzzing
explorations to guide future fuzzing explorations. In particular, the neural
models learn a function to predict good (and bad) locations in input files to
perform fuzzing mutations based on the past mutations and corresponding code
coverage information. We implement several neural models including LSTMs and
sequence-to-sequence models that can encode variable length input files. We
incorporate our models in the state-of-the-art AFL (American Fuzzy Lop) fuzzer
and show significant improvements in terms of code coverage, unique code paths,
and crashes for various input formats including ELF, PNG, PDF, and XML.
</dc:description>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04598</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional neural networks pretrained on large face recognition
  datasets for emotion classification from video</dc:title>
 <dc:creator>Knyazev, Boris</dc:creator>
 <dc:creator>Shvetsov, Roman</dc:creator>
 <dc:creator>Efremova, Natalia</dc:creator>
 <dc:creator>Kuharenko, Artem</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we describe a solution to our entry for the emotion recognition
challenge EmotiW 2017. We propose an ensemble of several models, which capture
spatial and audio features from videos. Spatial features are captured by
convolutional neural networks, pretrained on large face recognition datasets.
We show that usage of strong industry-level face recognition networks increases
the accuracy of emotion recognition. Using our ensemble we improve on the
previous best result on the test set by about 1 %, achieving a 60.03 %
classification accuracy without any use of visual temporal information.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04604</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smaller parameters for vertex cover kernelization</dc:title>
 <dc:creator>Hols, Eva-Maria C.</dc:creator>
 <dc:creator>Kratsch, Stefan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We revisit the topic of polynomial kernels for Vertex Cover relative to
structural parameters. Our starting point is a recent paper due to Fomin and
Str{\o}mme [WG 2016] who gave a kernel with $\mathcal{O}(|X|^{12})$ vertices
when $X$ is a vertex set such that each connected component of $G-X$ contains
at most one cycle, i.e., $X$ is a modulator to a pseudoforest. We strongly
generalize this result by using modulators to $d$-quasi-forests, i.e., graphs
where each connected component has a feedback vertex set of size at most $d$,
and obtain kernels with $\mathcal{O}(|X|^{3d+9})$ vertices. Our result relies
on proving that minimal blocking sets in a $d$-quasi-forest have size at most
$d+2$. This bound is tight and there is a related lower bound of
$\mathcal{O}(|X|^{d+2-\epsilon})$ on the bit size of kernels.
  In fact, we also get bounds for minimal blocking sets of more general graph
classes: For $d$-quasi-bipartite graphs, where each connected component can be
made bipartite by deleting at most $d$ vertices, we get the same tight bound of
$d+2$ vertices. For graphs whose connected components each have a vertex cover
of cost at most $d$ more than the best fractional vertex cover, which we call
$d$-quasi-integral, we show that minimal blocking sets have size at most
$2d+2$, which is also tight. Combined with existing randomized polynomial
kernelizations this leads to randomized polynomial kernelizations for
modulators to $d$-quasi-bipartite and $d$-quasi-integral graphs. There are
lower bounds of $\mathcal{O}(|X|^{d+2-\epsilon})$ and
$\mathcal{O}(|X|^{2d+2-\epsilon})$ for the bit size of such kernels.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04606</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Provably efficient neural network representation for image
  classification</dc:title>
 <dc:creator>Huang, Yichen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The state-of-the-art approaches for image classification are based on neural
networks. Mathematically, the task of classifying images is equivalent to
finding the function that maps an image to the label it is associated with. To
rigorously establish the success of neural network methods, we should first
prove that the function has an efficient neural network representation, and
then design provably efficient training algorithms to find such a
representation. Here, we achieve the first goal based on a set of assumptions
about the patterns in the images. The validity of these assumptions is very
intuitive in many image classification problems, including but not limited to,
recognizing handwritten digits.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04609</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Text Mining Descriptions Of Dreams: aesthetic and clinical efforts</dc:title>
 <dc:creator>Fabbri, Renato</dc:creator>
 <dc:creator>Borges, Fabiane M.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Dreams are highly valued in both Freudian psychoanalysis and less
conservative clinical traditions. Text mining enables the extraction of meaning
from writings in powerful and unexpected ways. In this work, we report methods,
uses and results obtained by mining descriptions of dreams. The texts were
collected as part of a course in Schizoanalysis (Clinical Psychology) from
dozens of participants. They were subsequently mined using various techniques
for the achievement of poems and summaries, which were then used in clinical
sessions by means of music and declamation. The results were found
aesthetically appealing and effective to engage the audience. The expansion of
the corpus, mining methods and strategies for using the derivatives for art and
therapy are considered for future work.
</dc:description>
 <dc:description>Comment: Scripts and corpus in https://github.com/ttm/sonhos, Anais do XX ENMC
  - Encontro Nacional de Modelagem Computacional e VIII ECTM - Encontro de
  Ci\^encias e Tecnologia de Materiais, Nova Friburgo, RJ - 16 a 19 Outubro
  2017</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04611</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Joint Encryption-Encoding Scheme Using QC-LDPC Codes Based on Finite
  Geometry</dc:title>
 <dc:creator>Khayami, Hossein</dc:creator>
 <dc:creator>Eghlidos, Taraneh</dc:creator>
 <dc:creator>Aref, Mohammad Reza</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Joint encryption-encoding schemes has been released to fulfill both
reliability and security desires in a single step. Using Low Density Parity
Check (LDPC) codes in joint encryption-encoding schemes, as an alternative to
classical linear codes, would shorten the key size as well as improving error
correction capability. In this article, we present a joint encryption-encoding
scheme using Quasi Cyclic-Low Density Parity Check (QC-LDPC) codes based on
finite geometry. We observed that our proposed scheme not only outperforms in
its key size and transmission rate, but also remains secure against all known
cryptanalyses of code-based secret key cryptosystems. We subsequently show that
our scheme benefits from low computational complexity. In our proposed joint
encryption-encoding scheme, by taking the advantage of QC-LDPC codes based on
finite geometries, the key size decreases to 1/5 of that of the so far best
similar system. In addition, using our proposed scheme a plenty of different
desirable transmission rates is achievable. The wide variety of codes proposed
here makes our cryptosystem applicable on a number of different communication
and cryptographic standards.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04612</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Algorithmic-Autoregulation (AA) Methodology and Software: a
  collective focus on self-transparency</dc:title>
 <dc:creator>Fabbri, Renato</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  There are numerous efforts to achieve a lightweight and systematic account of
what is done by a group and its individuals. The Algorithmic-Autoregulation
(AA) is a special case, in which a technical community embraced the challenge
of registering their own dedication for sharing processes, self-transparency,
and documenting the efforts. AA is used since June/2011 by dozens of
researchers and software developers, with the support of different software
gadgets and for distinct tasks. This article describes these implementations
and statistics of their usage including expected natural properties and
ontological formalisms which eases comparative analysis and furthers
integration.
</dc:description>
 <dc:description>Comment: Scripts and data in https://github.com/ttm/ensaaio</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04612</dc:identifier>
 <dc:identifier>Anais do XX ENMC - Encontro Nacional de Modelagem Computacional e
  VIII ECTM - Encontro de Ci\^encias e Tecnologia de Materiais, Nova Friburgo,
  RJ - 16 a 19 Outubro 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04614</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preserving Reliability to Heterogeneous Ultra-Dense Distributed Networks
  in Unlicensed Spectrum</dc:title>
 <dc:creator>Cui, Qimei</dc:creator>
 <dc:creator>Gu, Yu</dc:creator>
 <dc:creator>Ni, Wei</dc:creator>
 <dc:creator>Zhang, Xuefei</dc:creator>
 <dc:creator>Tao, Xiaofeng</dc:creator>
 <dc:creator>Zhang, Ping</dc:creator>
 <dc:creator>Liu, Ren Ping</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This article investigates the prominent dilemma between capacity and
reliability in heterogeneous ultra-dense distributed networks, and advocates a
new measure of effective capacity to quantify the maximum sustainable data rate
of a link while preserving the quality-of-service (QoS) of the link in such
networks. Recent breakthroughs are brought forth in developing the theory of
the effective capacity in heterogeneous ultra-dense distributed networks.
Potential applications of the effective capacity are demonstrated on the
admission control, power control and resource allocation of such networks, with
substantial gains revealed over existing technologies. This new measure is of
particular interest to ultra-dense deployment of the emerging fifth-generation
(5G) wireless networks in the unlicensed spectrum, leveraging the capacity gain
brought by the use of the unlicensed band and the stringent reliability
sustained by 5G in future heterogeneous network environments.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04614</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04618</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impartial redistricting: a Markov chain approach to the &quot;Gerrymandering
  problem&quot;</dc:title>
 <dc:creator>Dou, Jason</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  After every U.S. national census, a state legislature is required to redraw
the boundaries of congressional districts in order to account for changes in
population. At the moment this is done in a highly partisan way, with
districting done in order to maximize the benefits to the party in power. This
is a threat to U.S's democracy. There have been proposals to take the
re-districting out of the hands of political parties and give to an
&quot;independent&quot; commission. Independence is hard to come by and in this thesis we
want to explore the possibility of computer generated districts that as far as
possible to avoid partisan &quot;gerrymandering&quot;. The idea we have is to treat every
possible redistricting as a state in a Markov Chain: every state is obtained by
its former state in random way. With some technical conditions, we will get a
near uniform member of the states after running sufficiently long time (the
mixing time). Then we can say the uniform member is an impartial distribution.
Based on the geographical and statistical data of Pennsylvania, I have achieved
the Markov Chain algorithm with several constraints, done optimization
experiments and a web interface is going to be made to show the results.
</dc:description>
 <dc:description>Comment: Bachelor's thesis, Beijing Univ (2014)</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04623</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Three Factors Influencing Minima in SGD</dc:title>
 <dc:creator>Jastrz&#x119;bski, Stanis&#x142;aw</dc:creator>
 <dc:creator>Kenton, Zachary</dc:creator>
 <dc:creator>Arpit, Devansh</dc:creator>
 <dc:creator>Ballas, Nicolas</dc:creator>
 <dc:creator>Fischer, Asja</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:creator>Storkey, Amos</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the properties of the endpoint of stochastic gradient descent (SGD).
By approximating SGD as a stochastic differential equation (SDE) we consider
the Boltzmann-Gibbs equilibrium distribution of that SDE under the assumption
of isotropic variance in loss gradients. Through this analysis, we find that
three factors - learning rate, batch size and the variance of the loss
gradients - control the trade-off between the depth and width of the minima
found by SGD, with wider minima favoured by a higher ratio of learning rate to
batch size. We have direct control over the learning rate and batch size, while
the variance is determined by the choice of model architecture, model
parameterization and dataset. In the equilibrium distribution only the ratio of
learning rate to batch size appears, implying that the equilibrium distribution
is invariant under a simultaneous rescaling of learning rate and batch size by
the same amount. We then explore experimentally how learning rate and batch
size affect SGD from two perspectives: the endpoint of SGD and the dynamics
that lead up to it. For the endpoint, the experiments suggest the endpoint of
SGD is invariant under simultaneous rescaling of batch size and learning rate,
and also that a higher ratio leads to flatter minima, both findings are
consistent with our theoretical analysis. We note experimentally that the
dynamics also seem to be invariant under the same rescaling of learning rate
and batch size, which we explore showing that one can exchange batch size and
learning rate for cyclical learning rate schedule. Next, we illustrate how
noise affects memorization, showing that high noise levels lead to better
generalization. Finally, we find experimentally that the invariance under
simultaneous rescaling of learning rate and batch size breaks down if the
learning rate gets too large or the batch size gets too small.
</dc:description>
 <dc:description>Comment: First two authors contributed equally</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04626</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The effect of website attributes and mental involvement online impulse
  purchases</dc:title>
 <dc:creator>Saadatmand, Seyedeh Samira</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This research aimed at investigating the impact of website features and
involvement on immediate online shopping. The research is applied in terms of
type and it is causative in terms of methodology. The statistical population
consisted of all citizens of Tabriz, who have purchased clothes online at least
once and 260 individuals were chosen randomly and the questionnaires were
collected according to this sample size. The data were collected by
questionnaire. For analysis of the data, software SPSS and for test of the
model hypotheses, SEM was used by confirmatory factor analysis. The results
showed that the website benefit-oriented features have a positive impact on
immediate online shopping and website benefit-oriented features have no
significant impact on immediate online shopping.
</dc:description>
 <dc:description>Comment: 24 pages, in Persian</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04627</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bypass Fraud Detection: Artificial Intelligence Approach</dc:title>
 <dc:creator>Ighneiwa, Ibrahim</dc:creator>
 <dc:creator>Mohamed, Hussamedin</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Telecom companies are severely damaged by bypass fraud or SIM boxing.
However, there is a shortage of published research to tackle this problem. The
traditional method of Test Call Generating is easily overcome by fraudsters and
the need for more sophisticated ways is inevitable. In this work, we are
developing intelligent algorithms that mine a huge amount of mobile operator's
data and detect the SIMs that are used to bypass international calls. This
method will make it hard for fraudsters to generate revenue and hinder their
work. Also by reducing fraudulent activities, quality of service can be
increased as well as customer satisfaction. Our technique has been evaluated
and tested on real world mobile operator data, and proved to be very efficient.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04628</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Designing a Generic Framework for Cloud-based Big Data Analytics</dc:title>
 <dc:creator>Khan, Samiya</dc:creator>
 <dc:creator>Alam, Mansaf</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Big data analytics has gathered immense research attention lately because of
its ability to harness useful information from heaps of data. Cloud computing
has been adjudged as one of the best infrastructural solutions for
implementation of big data analytics. This research paper proposes a five-layer
model for cloud-based big data analytics that uses dew computing and edge
computing concepts. Besides this, the paper also presents an approach for
creation of custom big data stack by selecting technologies on the basis of
identified data and computing models for the application
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04640</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gerrymandering and Computational Redistricting</dc:title>
 <dc:creator>Guest, Olivia</dc:creator>
 <dc:creator>Kanayet, Frank J.</dc:creator>
 <dc:creator>Love, Bradley C.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Partisan gerrymandering poses a threat to democracy. Moreover, the complexity
of the districting task may exceed human capacities. One potential solution is
using computational models to automate the districting process by optimising
objective and open criteria, such as how spatially compact districts are. We
formulated one such model that minimised pairwise distance between voters
within a district. Using US Census Bureau data, we confirmed our prediction
that the difference in compactness between the computed and actual districts
would be greatest for states that are large and therefore difficult for humans
to properly district given their limited capacities. The computed solutions
highlighted differences in how humans and machines solve this task with machine
solutions more fully optimised and displaying emergent properties not evident
in human solutions. These results suggest a division of labour in which humans
debate and formulate districting criteria whereas machines optimise the
criteria to draw the district boundaries.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04642</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cryptanalysis of Merkle-Hellman cipher using parallel genetic algorithm</dc:title>
 <dc:creator>Kantour, Nedjmeeddine</dc:creator>
 <dc:creator>Bouroubi, Sadek</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A60, 68T20</dc:subject>
 <dc:description>  In 1976, Whitfield Diffie and Martin Hellman introduced the public key
cryptography or asymmetric cryptography standards. Two years later, an
asymmetric cryptosystem was published by Ralph Merkle and Martin Hellman called
MH, based on a variant of knapsack problem known as the subset-sum problem
which is proven to be NP-hard. Furthermore, over the last four decades,
Metaheuristics have achieved a remarkable progress in solving NP-hard
optimization problems. However, the conception of these methods raises several
challenges, mainly the adaptation and the parameters setting. In this paper, we
propose a Parallel Genetic Algorithm (PGA) adapted to explore effectively the
search space of considerable size in order to break the MH cipher. Experimental
study is included, showing the performance of the proposed attacking scheme and
finally concluding with a comparison with the LLL algorithm attack.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04661</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UCT: Learning Unified Convolutional Networks for Real-time Visual
  Tracking</dc:title>
 <dc:creator>Zhu, Zheng</dc:creator>
 <dc:creator>Huang, Guan</dc:creator>
 <dc:creator>Zou, Wei</dc:creator>
 <dc:creator>Du, Dalong</dc:creator>
 <dc:creator>Huang, Chang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks (CNN) based tracking approaches have shown
favorable performance in recent benchmarks. Nonetheless, the chosen CNN
features are always pre-trained in different task and individual components in
tracking systems are learned separately, thus the achieved tracking performance
may be suboptimal. Besides, most of these trackers are not designed towards
real-time applications because of their time-consuming feature extraction and
complex optimization details.In this paper, we propose an end-to-end framework
to learn the convolutional features and perform the tracking process
simultaneously, namely, a unified convolutional tracker (UCT). Specifically,
The UCT treats feature extractor and tracking process both as convolution
operation and trains them jointly, enabling learned CNN features are tightly
coupled to tracking process. In online tracking, an efficient updating method
is proposed by introducing peak-versus-noise ratio (PNR) criterion, and scale
changes are handled efficiently by incorporating a scale branch into network.
The proposed approach results in superior tracking performance, while
maintaining real-time speed. The standard UCT and UCT-Lite can track generic
objects at 41 FPS and 154 FPS without further optimization, respectively.
Experiments are performed on four challenging benchmark tracking datasets:
OTB2013, OTB2015, VOT2014 and VOT2015, and our method achieves state-of-the-art
results on these benchmarks compared with other real-time trackers.
</dc:description>
 <dc:description>Comment: ICCV2017 Workshops. arXiv admin note: text overlap with
  arXiv:1711.01124</dc:description>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04677</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private Function Retrieval</dc:title>
 <dc:creator>Mirmohseni, Mahtab</dc:creator>
 <dc:creator>Maddah-Ali, Mohammad Ali</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The widespread use of cloud computing services raises the question of how one
can delegate the processing tasks to the untrusted distributed parties without
breeching the privacy of its data and algorithms. Motivated by the algorithm
privacy concerns in a distributed computing system, in this paper, we introduce
the private function retrieval (PFR) problem, where a user wishes to
efficiently retrieve a linear function of $K$ messages from $N$
non-communicating replicated servers while keeping the function hidden from
each individual server. The goal is to find a scheme with minimum communication
cost. To characterize the fundamental limits of the communication cost, we
define the capacity of PFR problem as the size of the message that can be
privately retrieved (which is the size of one file) normalized to the required
downloaded information bits. We first show that for the PFR problem with $K$
messages, $N=2$ servers and a linear function with binary coefficients the
capacity is $C=\frac{1}{2}\Big(1-\frac{1}{2^K}\Big)^{-1}$. Interestingly, this
is the capacity of retrieving one of $K$ messages from $N=2$ servers while
keeping the index of the requested message hidden from each individual server,
the problem known as private information retrieval (PIR). Then, we extend the
proposed achievable scheme to the case of arbitrary number of servers and
coefficients in the field $GF(q)$ with arbitrary $q$ and obtain
$R=\Big(1-\frac{1}{N}\Big)\Big(1+\frac{\frac{1}{N-1}}{(\frac{q^K-1}{q-1})^{N-1}}\Big)$.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04678</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuum Deformation of a Multiple Quadcopter Payload Delivery Team
  without Inter-Agent Communication</dc:title>
 <dc:creator>Rastgoftar, Hossein</dc:creator>
 <dc:creator>Atkins, Ella M.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper proposes continuum deformation as a strategy for controlling the
collective motion of a multiple quadcopter system (MQS) carrying a common
payload. Continuum deformation allows expansion and contraction of inter-agent
distances in a 2D motion plane to follow desired motions of three team leaders.
The remaining quadcopter followers establish the desired continuum deformation
only by knowing leaders positions at desired sample time waypoints without the
need for inter-agent communication over the intermediate intervals. Each
quadcopter applies a linear-quadratic-Gaussian (LQG) controller to track the
desired trajectory given by the continuum deformation in the presence of
disturbance and measurement noise. Results of simulated cooperative aerial
payload transport in the presence of uncertainty illustrate the application of
continuum deformation for coordinated transport through a narrow channel.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04679</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attention-based Information Fusion using Multi-Encoder-Decoder Recurrent
  Neural Networks</dc:title>
 <dc:creator>Baier, Stephan</dc:creator>
 <dc:creator>Spieckermann, Sigurd</dc:creator>
 <dc:creator>Tresp, Volker</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  With the rising number of interconnected devices and sensors, modeling
distributed sensor networks is of increasing interest. Recurrent neural
networks (RNN) are considered particularly well suited for modeling sensory and
streaming data. When predicting future behavior, incorporating information from
neighboring sensor stations is often beneficial. We propose a new RNN based
architecture for context specific information fusion across multiple spatially
distributed sensor stations. Hereby, latent representations of multiple local
models, each modeling one sensor station, are jointed and weighted, according
to their importance for the prediction. The particular importance is assessed
depending on the current context using a separate attention function. We
demonstrate the effectiveness of our model on three different real-world sensor
network datasets.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04679</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04683</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor Decompositions for Modeling Inverse Dynamics</dc:title>
 <dc:creator>Baier, Stephan</dc:creator>
 <dc:creator>Tresp, Volker</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Modeling inverse dynamics is crucial for accurate feedforward robot control.
The model computes the necessary joint torques, to perform a desired movement.
The highly non-linear inverse function of the dynamical system can be
approximated using regression techniques. We propose as regression method a
tensor decomposition model that exploits the inherent three-way interaction of
positions x velocities x accelerations. Most work in tensor factorization has
addressed the decomposition of dense tensors. In this paper, we build upon the
decomposition of sparse tensors, with only small amounts of nonzero entries.
The decomposition of sparse tensors has successfully been used in relational
learning, e.g., the modeling of large knowledge graphs. Recently, the approach
has been extended to multi-class classification with discrete input variables.
Representing the data in high dimensional sparse tensors enables the
approximation of complex highly non-linear functions. In this paper we show how
the decomposition of sparse tensors can be applied to regression problems.
Furthermore, we extend the method to continuous inputs, by learning a mapping
from the continuous inputs to the latent representations of the tensor
decomposition, using basis functions. We evaluate our proposed model on a
dataset with trajectories from a seven degrees of freedom SARCOS robot arm. Our
experimental results show superior performance of the proposed functional
tensor model, compared to challenging state-of-the art methods.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04686</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weightless: Lossy Weight Encoding For Deep Neural Network Compression</dc:title>
 <dc:creator>Reagen, Brandon</dc:creator>
 <dc:creator>Gupta, Udit</dc:creator>
 <dc:creator>Adolf, Robert</dc:creator>
 <dc:creator>Mitzenmacher, Michael M.</dc:creator>
 <dc:creator>Rush, Alexander M.</dc:creator>
 <dc:creator>Wei, Gu-Yeon</dc:creator>
 <dc:creator>Brooks, David</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The large memory requirements of deep neural networks limit their deployment
and adoption on many devices. Model compression methods effectively reduce the
memory requirements of these models, usually through applying transformations
such as weight pruning or quantization. In this paper, we present a novel
scheme for lossy weight encoding which complements conventional compression
techniques. The encoding is based on the Bloomier filter, a probabilistic data
structure that can save space at the cost of introducing random errors.
Leveraging the ability of neural networks to tolerate these imperfections and
by re-training around the errors, the proposed technique, Weightless, can
compress DNN weights by up to 496x with the same model accuracy. This results
in up to a 1.51x improvement over the state-of-the-art.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04689</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Person Recognition using Smartphones' Accelerometer Data</dc:title>
 <dc:creator>Singha, Thingom Bishal</dc:creator>
 <dc:creator>Nath, Rajsekhar Kumar</dc:creator>
 <dc:creator>Narsimhadhan, A. V.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Smartphones have become quite pervasive in various aspects of our daily
lives. They have become important links to a host of important data and
applications, which if compromised, can lead to disastrous results. Due to
this, today's smartphones are equipped with multiple layers of authentication
modules. However, there still lies the need for a viable and unobtrusive layer
of security which can perform the task of user authentication using resources
which are cost-efficient and widely available on smartphones. In this work, we
propose a method to recognize users using data from a phone's embedded
accelerometer sensors. Features encapsulating information from both time and
frequency domains are extracted from walking data samples, and are used to
build a Random Forest ensemble classification model. Based on the experimental
results, the resultant model delivers an accuracy of 0.9679 and Area under
Curve (AUC) of 0.9822.
</dc:description>
 <dc:description>Comment: Currently under review at IEEE National Conference on Communications
  2018</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04695</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Sensing of Floods in the UK</dc:title>
 <dc:creator>Arthur, Rudy</dc:creator>
 <dc:creator>Boulton, Chris A.</dc:creator>
 <dc:creator>Shotton, Humphrey</dc:creator>
 <dc:creator>Williams, Hywel T. P.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  &quot;Social sensing&quot; is a form of crowd-sourcing that involves systematic
analysis of digital communications to detect real-world events. Here we
consider the use of social sensing for observing natural hazards. In
particular, we present a case study that uses data from a popular social media
platform (Twitter) to detect and locate flood events in the UK. In order to
improve data quality we apply a number of filters (timezone, simple text
filters and a naive Bayes `relevance' filter) to the data. We then use place
names in the user profile and message text to infer the location of the tweets.
These two steps remove most of the irrelevant tweets and yield orders of
magnitude more located tweets than we have by relying on geo-tagged data. We
demonstrate that high resolution social sensing of floods is feasible and we
can produce high-quality historical and real-time maps of floods using Twitter.
</dc:description>
 <dc:description>Comment: 24 pages, 6 figures</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04697</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controlling complex policy problems: a multimethodological approach
  using system dynamics and network controllability</dc:title>
 <dc:creator>Schoenenberger, Lukas</dc:creator>
 <dc:creator>Tanase, Radu</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Notwithstanding the usefulness of system dynamics in analyzing complex policy
problems, policy design is far from straightforward and in many instances
trial-and-error driven. To address this challenge, we propose to combine system
dynamics with network controllability, an emerging field in network science, to
facilitate the detection of effective leverage points in system dynamics models
and thus to support the design of influential policies. We illustrate our
approach by analyzing a classic system dynamics model: the World Dynamics
model. We show that it is enough to control only 53% of the variables to steer
the entire system to an arbitrary final state. We further rank all variables
according to their importance in controlling the system and we validate our
approach by showing that high ranked variables have a significantly larger
impact on the system behavior compared to low ranked variables.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04697</dc:identifier>
 <dc:identifier>Journal of Simulation (2017): 1-9</dc:identifier>
 <dc:identifier>doi:10.1080/17477778.2017.1387335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04705</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Near Duplicates in Software Documentation</dc:title>
 <dc:creator>Luciv, D. V.</dc:creator>
 <dc:creator>Koznov, D. V.</dc:creator>
 <dc:creator>Chernishev, G. A.</dc:creator>
 <dc:creator>Terekhov, A. N.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Contemporary software documentation is as complicated as the software itself.
During its lifecycle, the documentation accumulates a lot of near duplicate
fragments, i.e. chunks of text that were copied from a single source and were
later modified in different ways. Such near duplicates decrease documentation
quality and thus hamper its further utilization. At the same time, they are
hard to detect manually due to their fuzzy nature. In this paper we give a
formal definition of near duplicates and present an algorithm for their
detection in software documents. This algorithm is based on the exact software
clone detection approach: the software clone detection tool Clone Miner was
adapted to detect exact duplicates in documents. Then, our algorithm uses these
exact duplicates to construct near ones. We evaluate the proposed algorithm
using the documentation of 19 open source and commercial projects. Our
evaluation is very comprehensive - it covers various documentation types:
design and requirement specifications, programming guides and API
documentation, user manuals. Overall, the evaluation shows that all kinds of
software documentation contain a significant number of both exact and near
duplicates. Next, we report on the performed manual analysis of the detected
near duplicates for the Linux Kernel Documentation. We present both quantative
and qualitative results of this analysis, demonstrate algorithm strengths and
weaknesses, and discuss the benefits of duplicate management in software
documents.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04708</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning for the Geosciences: Challenges and Opportunities</dc:title>
 <dc:creator>Karpatne, Anuj</dc:creator>
 <dc:creator>Ebert-Uphoff, Imme</dc:creator>
 <dc:creator>Ravela, Sai</dc:creator>
 <dc:creator>Babaie, Hassan Ali</dc:creator>
 <dc:creator>Kumar, Vipin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Geophysics</dc:subject>
 <dc:description>  Geosciences is a field of great societal relevance that requires solutions to
several urgent problems facing our humanity and the planet. As geosciences
enters the era of big data, machine learning (ML) -- that has been widely
successful in commercial domains -- offers immense potential to contribute to
problems in geosciences. However, problems in geosciences have several unique
challenges that are seldom found in traditional applications, requiring novel
problem formulations and methodologies in machine learning. This article
introduces researchers in the machine learning (ML) community to these
challenges offered by geoscience problems and the opportunities that exist for
advancing both machine learning and geosciences. We first highlight typical
sources of geoscience data and describe their properties that make it
challenging to use traditional machine learning techniques. We then describe
some of the common categories of geoscience problems where machine learning can
play a role, and discuss some of the existing efforts and promising directions
for methodological development in machine learning. We conclude by discussing
some of the emerging research themes in machine learning that are applicable
across all problems in the geosciences, and the importance of a deep
collaboration between machine learning and geosciences for synergistic
advancements in both disciplines.
</dc:description>
 <dc:description>Comment: Under review at IEEE Transactions on Knowledge and Data Engineering</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04709</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stampery Blockchain Timestamping Architecture (BTA) - Version 6</dc:title>
 <dc:creator>Crespo, Ad&#xe1;n S&#xe1;nchez de Pedro</dc:creator>
 <dc:creator>Garc&#xed;a, Luis Iv&#xe1;n Cuende</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W15 (Primary), 68M12, 68M14 (Secondary)</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>I.7.4</dc:subject>
 <dc:subject>J.1</dc:subject>
 <dc:description>  A method for timestamping, anchoring and certification of a virtually
unlimited amount of data in one or more blockchains, focusing on scalability
and cost-effectiveness while ensuring existence, integrity and ownership by
using cryptographic proofs that are independently verifiable by anyone in the
world without disclosure of the original data and without the intervention of
the certifying party.
</dc:description>
 <dc:description>Comment: 21 pages, 16 figures</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04709</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.2.17223.80805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04710</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-Temporal Data Mining: A Survey of Problems and Methods</dc:title>
 <dc:creator>Atluri, Gowtham</dc:creator>
 <dc:creator>Karpatne, Anuj</dc:creator>
 <dc:creator>Kumar, Vipin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Large volumes of spatio-temporal data are increasingly collected and studied
in diverse domains including, climate science, social sciences, neuroscience,
epidemiology, transportation, mobile health, and Earth sciences.
Spatio-temporal data differs from relational data for which computational
approaches are developed in the data mining community for multiple decades, in
that both spatial and temporal attributes are available in addition to the
actual measurements/attributes. The presence of these attributes introduces
additional challenges that needs to be dealt with. Approaches for mining
spatio-temporal data have been studied for over a decade in the data mining
community. In this article we present a broad survey of this relatively young
field of spatio-temporal data mining. We discuss different types of
spatio-temporal data and the relevant data mining questions that arise in the
context of analyzing each of these datasets. Based on the nature of the data
mining problem studied, we classify literature on spatio-temporal data mining
into six major categories: clustering, predictive learning, change detection,
frequent pattern mining, anomaly detection, and relationship mining. We discuss
the various forms of spatio-temporal data mining problems in each of these
categories.
</dc:description>
 <dc:description>Comment: Accepted for publication at ACM Computing Surveys</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04712</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized Near Neighbor Graphs, Giant Components, and Applications in
  Data Science</dc:title>
 <dc:creator>Linderman, George C.</dc:creator>
 <dc:creator>Mishne, Gal</dc:creator>
 <dc:creator>Kluger, Yuval</dc:creator>
 <dc:creator>Steinerberger, Stefan</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  If we pick $n$ random points uniformly in $[0,1]^d$ and connect each point to
its $k-$nearest neighbors, then it is well known that there exists a giant
connected component with high probability. We prove that in $[0,1]^d$ it
suffices to connect every point to $ c_{d,1} \log{\log{n}}$ points chosen
randomly among its $ c_{d,2} \log{n}-$nearest neighbors to ensure a giant
component of size $n - o(n)$ with high probability. This construction yields a
much sparser random graph with $\sim n \log\log{n}$ instead of $\sim n \log{n}$
edges that has comparable connectivity properties. This result has nontrivial
implications for problems in data science where an affinity matrix is
constructed: instead of picking the $k-$nearest neighbors, one can often pick
$k' \ll k$ random points out of the $k-$nearest neighbors without sacrificing
efficiency. This can massively simplify and accelerate computation, we
illustrate this with several numerical examples.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04713</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ADaPTION: Toolbox and Benchmark for Training Convolutional Neural
  Networks with Reduced Numerical Precision Weights and Activation</dc:title>
 <dc:creator>Milde, Moritz B.</dc:creator>
 <dc:creator>Neil, Daniel</dc:creator>
 <dc:creator>Aimar, Alessandro</dc:creator>
 <dc:creator>Delbruck, Tobi</dc:creator>
 <dc:creator>Indiveri, Giacomo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs) are
useful for many practical tasks in machine learning. Synaptic weights, as well
as neuron activation functions within the deep network are typically stored
with high-precision formats, e.g. 32 bit floating point. However, since storage
capacity is limited and each memory access consumes power, both storage
capacity and memory access are two crucial factors in these networks. Here we
present a method and present the ADaPTION toolbox to extend the popular deep
learning library Caffe to support training of deep CNNs with reduced numerical
precision of weights and activations using fixed point notation. ADaPTION
includes tools to measure the dynamic range of weights and activations. Using
the ADaPTION tools, we quantized several CNNs including VGG16 down to 16-bit
weights and activations with only 0.8% drop in Top-1 accuracy. The
quantization, especially of the activations, leads to increase of up to 50% of
sparsity especially in early and intermediate layers, which we exploit to skip
multiplications with zero, thus performing faster and computationally cheaper
inference.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04714</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Converse for the Nearest Lattice Point Problem</dc:title>
 <dc:creator>Vaishampayan, Vinay A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Upper bounds on the communication complexity of finding the nearest lattice
point in a given lattice $\Lambda \subset \mathbb{R}^2$ was considered in
earlier works~\cite{VB:2017}, for a two party, interactive communication model.
Here we derive a lower bound on the communication complexity of a key step in
that procedure. Specifically, the problem considered is that of interactively
finding $\min(X_1,X_2)$, when $(X_1,X_2)$ is uniformly distributed on the unit
square. A lower bound is derived on the single-shot interactive communication
complexity and shown to be tight. This is accomplished by characterizing the
constraints placed on the partition generated by an interactive code and
exploiting a self similarity property of an optimal solution.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:1701.08458</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04718</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Type Checking Algorithm for Higher-rank, Impredicative and
  Second-order Types</dc:title>
 <dc:creator>Fu, Peng</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We study a type checking algorithm that is able to type check a nontrivial
subclass of functional programs that use features such as higher-rank,
impredicative and second-order types. The only place the algorithm requires
type annotation is before each function declaration. We prove the soundness of
the type checking algorithm with respect to System $\mathbf{F}_{\omega}$, i.e.
if the program is type checked, then the type checker will produce a well-typed
annotated System $\mathbf{F}_{\omega}$ term. We extend the basic algorithm to
handle pattern matching and let-bindings. We implement a prototype type checker
and test it on a variety of functional programs.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04725</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Attentive Session-based Recommendation</dc:title>
 <dc:creator>Li, Jing</dc:creator>
 <dc:creator>Ren, Pengjie</dc:creator>
 <dc:creator>Chen, Zhumin</dc:creator>
 <dc:creator>Ren, Zhaochun</dc:creator>
 <dc:creator>Ma, Jun</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Given e-commerce scenarios that user profiles are invisible, session-based
recommendation is proposed to generate recommendation results from short
sessions. Previous work only considers the user's sequential behavior in the
current session, whereas the user's main purpose in the current session is not
emphasized. In this paper, we propose a novel neural networks framework, i.e.,
Neural Attentive Recommendation Machine (NARM), to tackle this problem.
Specifically, we explore a hybrid encoder with an attention mechanism to model
the user's sequential behavior and capture the user's main purpose in the
current session, which are combined as a unified session representation later.
We then compute the recommendation scores for each candidate item with a
bi-linear matching scheme based on this unified session representation. We
train NARM by jointly learning the item and session representations as well as
their matchings. We carried out extensive experiments on two benchmark
datasets. Our experimental results show that NARM outperforms state-of-the-art
baselines on both datasets. Furthermore, we also find that NARM achieves a
significant improvement on long sessions, which demonstrates its advantages in
modeling the user's sequential behavior and main purpose simultaneously.
</dc:description>
 <dc:description>Comment: Proceedings of the 2017 ACM on Conference on Information and
  Knowledge Management. arXiv admin note: text overlap with arXiv:1511.06939,
  arXiv:1606.08117 by other authors</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04728</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cheating by Duplication: Equilibrium Requires Global Knowledge</dc:title>
 <dc:creator>Afek, Yehuda</dc:creator>
 <dc:creator>Rafaeli, Shaked</dc:creator>
 <dc:creator>Sulamy, Moshe</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Distributed algorithms with rational agents have always assumed the size of
the network is known to the participants before the algorithm starts. Here we
address the following question: what global information must agents know
a-priori about the network in order for equilibrium to be possible? We start
this investigation by considering different distributed computing problems and
showing how much each agent must a-priori know about $n$, the number of agents
in the network, in order for distributed algorithms to be equilibria.
  We prove that when $n$ is not a-priori known, equilibrium for both knowledge
sharing and coloring is impossible. We provide new algorithms for both problems
when $n$ is a-priori known to all agents. We further show that when agents are
given a range in which the actual value of $n$ may be, different distributed
problems require different such ranges in order for equilibrium to be possible.
By providing algorithms that are equilibrium on the one hand and impossibility
results on the other, we provide the tight range in which equilibrium is
possible but beyond which there exist no equilibrium for the following common
distributed problems: Leader Election, Knowledge Sharing, Coloring, Partition
and Orientation.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04731</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-Shot Style Transfer in Text Using Recurrent Neural Networks</dc:title>
 <dc:creator>Carlson, Keith</dc:creator>
 <dc:creator>Riddell, Allen</dc:creator>
 <dc:creator>Rockmore, Daniel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Zero-shot translation is the task of translating between a language pair
where no aligned data for the pair is provided during training. In this work we
employ a model that creates paraphrases which are written in the style of
another existing text. Since we provide the model with no paired examples from
the source style to the target style during training, we call this task
zero-shot style transfer. Herein, we identify a high-quality source of aligned,
stylistically distinct text in Bible versions and use this data to train an
encoder/decoder recurrent neural model. We also train a statistical machine
translation system, Moses, for comparison. We find that the neural network
outperforms Moses on the established BLEU and PINC metrics for evaluating
paraphrase quality. This technique can be widely applied due to the broad
definition of style which is used. For example, tasks like text simplification
can easily be viewed as style transfer. The corpus itself is highly parallel
with 33 distinct Bible Versions used, and human-aligned due to the presence of
chapter and verse numbers within the text. This makes the data a rich source of
study for other natural language tasks.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04735</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resurrecting the sigmoid in deep learning through dynamical isometry:
  theory and practice</dc:title>
 <dc:creator>Pennington, Jeffrey</dc:creator>
 <dc:creator>Schoenholz, Samuel S.</dc:creator>
 <dc:creator>Ganguli, Surya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  It is well known that the initialization of weights in deep neural networks
can have a dramatic impact on learning speed. For example, ensuring the mean
squared singular value of a network's input-output Jacobian is $O(1)$ is
essential for avoiding the exponential vanishing or explosion of gradients. The
stronger condition that all singular values of the Jacobian concentrate near
$1$ is a property known as dynamical isometry. For deep linear networks,
dynamical isometry can be achieved through orthogonal weight initialization and
has been shown to dramatically speed up learning; however, it has remained
unclear how to extend these results to the nonlinear setting. We address this
question by employing powerful tools from free probability theory to compute
analytically the entire singular value distribution of a deep network's
input-output Jacobian. We explore the dependence of the singular value
distribution on the depth of the network, the weight initialization, and the
choice of nonlinearity. Intriguingly, we find that ReLU networks are incapable
of dynamical isometry. On the other hand, sigmoidal networks can achieve
isometry, but only with orthogonal weight initialization. Moreover, we
demonstrate empirically that deep nonlinear networks achieving dynamical
isometry learn orders of magnitude faster than networks that do not. Indeed, we
show that properly-initialized deep sigmoidal networks consistently outperform
deep ReLU networks. Overall, our analysis reveals that controlling the entire
distribution of Jacobian singular values is an important design consideration
in deep learning.
</dc:description>
 <dc:description>Comment: 13 pages, 6 figures. Appearing at the 31st Conference on Neural
  Information Processing Systems (NIPS 2017)</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04740</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heavy Hitters and the Structure of Local Privacy</dc:title>
 <dc:creator>Bun, Mark</dc:creator>
 <dc:creator>Nelson, Jelani</dc:creator>
 <dc:creator>Stemmer, Uri</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a new locally differentially private algorithm for the heavy
hitters problem which achieves optimal worst-case error as a function of all
standardly considered parameters. Prior work obtained error rates which depend
optimally on the number of users, the size of the domain, and the privacy
parameter, but depend sub-optimally on the failure probability.
  We strengthen existing lower bounds on the error to incorporate the failure
probability, and show that our new upper bound is tight with respect to this
parameter as well. Our lower bound is based on a new understanding of the
structure of locally private protocols. We further develop these ideas to
obtain the following general results beyond heavy hitters.
  $\bullet$ Advanced Grouposition: In the local model, group privacy for $k$
users degrades proportionally to $\approx \sqrt{k}$, instead of linearly in $k$
as in the central model. Stronger group privacy yields improved max-information
guarantees, as well as stronger lower bounds (via &quot;packing arguments&quot;), over
the central model.
  $\bullet$ Building on a transformation of Bassily and Smith (STOC 2015), we
give a generic transformation from any non-interactive approximate-private
local protocol into a pure-private local protocol. Again in contrast with the
central model, this shows that we cannot obtain more accurate algorithms by
moving from pure to approximate local privacy.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04755</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ACtuAL: Actor-Critic Under Adversarial Learning</dc:title>
 <dc:creator>Goyal, Anirudh</dc:creator>
 <dc:creator>Ke, Nan Rosemary</dc:creator>
 <dc:creator>Lamb, Alex</dc:creator>
 <dc:creator>Hjelm, R Devon</dc:creator>
 <dc:creator>Pal, Chris</dc:creator>
 <dc:creator>Pineau, Joelle</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative Adversarial Networks (GANs) are a powerful framework for deep
generative modeling. Posed as a two-player minimax problem, GANs are typically
trained end-to-end on real-valued data and can be used to train a generator of
high-dimensional and realistic images. However, a major limitation of GANs is
that training relies on passing gradients from the discriminator through the
generator via back-propagation. This makes it fundamentally difficult to train
GANs with discrete data, as generation in this case typically involves a
non-differentiable function. These difficulties extend to the reinforcement
learning setting when the action space is composed of discrete decisions. We
address these issues by reframing the GAN framework so that the generator is no
longer trained using gradients through the discriminator, but is instead
trained using a learned critic in the actor-critic framework with a Temporal
Difference (TD) objective. This is a natural fit for sequence modeling and we
use it to achieve improvements on language modeling tasks over the standard
Teacher-Forcing methods.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04759</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Networks Architecture Evaluation in a Quantum Computer</dc:title>
 <dc:creator>da Silva, Adenilton Jos&#xe9;</dc:creator>
 <dc:creator>de Oliveira, Rodolfo Luan F.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this work, we propose a quantum algorithm to evaluate neural networks
architectures named Quantum Neural Network Architecture Evaluation (QNNAE). The
proposed algorithm is based on a quantum associative memory and the learning
algorithm for artificial neural networks. Unlike conventional algorithms for
evaluating neural network architectures, QNNAE does not depend on
initialization of weights. The proposed algorithm has a binary output and
results in 0 with probability proportional to the performance of the network.
And its computational cost is equal to the computational cost to train a neural
network.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04759</dc:identifier>
 <dc:identifier>doi:10.1109/BRACIS.2017.33</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04805</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QuickEdit: Editing Text &amp; Translations via Simple Delete Actions</dc:title>
 <dc:creator>Grangier, David</dc:creator>
 <dc:creator>Auli, Michael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose a framework for computer-assisted text editing. It applies to
translation post-editing and to paraphrasing and relies on very simple
interactions: a human editor modifies a sentence by marking tokens they would
like the system to change. Our model then generates a new sentence which
reformulates the initial sentence by avoiding the words from the marked tokens.
Our approach builds upon neural sequence-to-sequence modeling and introduces a
neural network which takes as input a sentence along with deleted token
markers. Our model is trained on translation bi-text by simulating post-edits.
Our results on post-editing for machine translation and paraphrasing evaluate
the performance of our approach. We show +11.4 BLEU with limited post-editing
effort on the WMT-14 English-German translation task (25.2 to 36.6), which
represents +5.9 BLEU over the post-editing baseline (30.7 to 36.6).
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04808</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Design-Space Exploration for Allocating Security Tasks in Multicore
  Real-Time Systems</dc:title>
 <dc:creator>Hasan, Monowar</dc:creator>
 <dc:creator>Mohan, Sibin</dc:creator>
 <dc:creator>Pellizzoni, Rodolfo</dc:creator>
 <dc:creator>Bobba, Rakesh B.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  The increased capabilities of modern real-time systems (RTS) expose them to
various security threats. Recently, frameworks that integrate security tasks
without perturbing the real-time tasks have been proposed, but they only target
single core systems. However, modern RTS are migrating towards multicore
platforms. This makes the problem of integrating security mechanisms more
complex, as designers now have multiple choices for where to allocate the
security tasks. In this paper we propose HYDRA, a design space exploration
algorithm that finds an allocation of security tasks for multicore RTS using
the concept of opportunistic execution. HYDRA allows security tasks to operate
with existing real-time tasks without perturbing system parameters or normal
execution patterns, while still meeting the desired monitoring frequency for
intrusion detection. Our evaluation uses a representative real-time control
system (along with synthetic task sets for a broader exploration) to illustrate
the efficacy of HYDRA.
</dc:description>
 <dc:description>Comment: Accepted for publication, 21st DATE (Design, Automation &amp; Test in
  Europe) conference, 2018</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04810</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Found in Translation&quot;: Predicting Outcomes of Complex Organic Chemistry
  Reactions using Neural Sequence-to-Sequence Models</dc:title>
 <dc:creator>Schwaller, Philippe</dc:creator>
 <dc:creator>Gaudin, Theophile</dc:creator>
 <dc:creator>Lanyi, David</dc:creator>
 <dc:creator>Bekas, Costas</dc:creator>
 <dc:creator>Laino, Teodoro</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  There is an intuitive analogy of an organic chemist's understanding of a
compound and a language speaker's understanding of a word. Consequently, it is
possible to introduce the basic concepts and analyze potential impacts of
linguistic analysis to the world of organic chemistry. In this work, we cast
the reaction prediction task as a translation problem by introducing a
template-free sequence-to-sequence model, trained end-to-end and fully
data-driven. We propose a novel way of tokenization, which is arbitrarily
extensible with reaction information. With this approach, we demonstrate
results superior to the state-of-the-art solution by a significant margin on
the top-1 accuracy. Specifically, our approach achieves an accuracy of 80.1%
without relying on auxiliary knowledge such as reaction templates. Also, 66.4%
accuracy is reached on a larger and noisier dataset.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04818</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncertainty quantification for radio interferometric imaging: I.
  proximal MCMC methods</dc:title>
 <dc:creator>Cai, Xiaohao</dc:creator>
 <dc:creator>Pereyra, Marcelo</dc:creator>
 <dc:creator>McEwen, Jason D.</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Uncertainty quantification is a critical missing component in radio
interferometric imaging that will only become increasingly important as the
big-data era of radio interferometry emerges. Since radio interferometric
imaging requires solving a high-dimensional, ill-posed inverse problem,
uncertainty quantification is difficult but also critical to the accurate
scientific interpretation of radio observations. Statistical sampling
approaches to perform Bayesian inference, like Markov Chain Monte Carlo (MCMC)
sampling, can in principle recover the full posterior distribution of the
image, from which uncertainties can then be quantified. However, traditional
high-dimensional sampling methods are generally limited to smooth (e.g.
Gaussian) priors and cannot be used with sparsity-promoting priors. Sparse
priors, motivated by the theory of compressive sensing, have been shown to be
highly effective for radio interferometric imaging. In this article proximal
MCMC methods are developed for radio interferometric imaging, leveraging
proximal calculus to support non-differential priors, such as sparse priors, in
a Bayesian framework. Furthermore, three strategies to quantify uncertainties
using the recovered posterior distribution are developed: (i) local
(pixel-wise) credible intervals to provide error bars for each individual
pixel; (ii) highest posterior density credible regions; and (iii) hypothesis
testing of image structure. These forms of uncertainty quantification provide
rich information for analysing radio interferometric observations in a
statistically robust manner.
</dc:description>
 <dc:description>Comment: 16 pages, 7 figures, see companion article in this arXiv listing</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04819</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncertainty quantification for radio interferometric imaging: II. MAP
  estimation</dc:title>
 <dc:creator>Cai, Xiaohao</dc:creator>
 <dc:creator>Pereyra, Marcelo</dc:creator>
 <dc:creator>McEwen, Jason D.</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Uncertainty quantification is a critical missing component in radio
interferometric imaging that will only become increasingly important as the
big-data era of radio interferometry emerges. Statistical sampling approaches
to perform Bayesian inference, like Markov Chain Monte Carlo (MCMC) sampling,
can in principle recover the full posterior distribution of the image, from
which uncertainties can then be quantified. However, for massive data sizes,
like those anticipated from the Square Kilometre Array (SKA), it will be
difficult if not impossible to apply any MCMC technique due to its inherent
computational cost. We formulate Bayesian inference problems with
sparsity-promoting priors (motivated by compressive sensing), for which we
recover maximum a posteriori (MAP) point estimators of radio interferometric
images by convex optimisation. Exploiting recent developments in the theory of
probability concentration, we quantify uncertainties by post-processing the
recovered MAP estimate. Three strategies to quantify uncertainties are
developed: (i) highest posterior density credible regions; (ii) local credible
intervals (cf. error bars) for individual pixels and superpixels; and (iii)
hypothesis testing of image structure. These forms of uncertainty
quantification provide rich information for analysing radio interferometric
observations in a statistically robust manner. Our MAP-based methods are
approximately $10^5$ times faster computationally than state-of-the-art MCMC
methods and, in addition, support highly distributed and parallelised
algorithmic structures. For the first time, our MAP-based techniques provide a
means of quantifying uncertainties for radio interferometric imaging for
realistic data volumes and practical use, and scale to the emerging big-data
era of radio astronomy.
</dc:description>
 <dc:description>Comment: 13 pages, 9 figures, see companion article in this arXiv listing</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04822</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vulnerabilities of Electric Vehicle Battery Packs to Cyberattacks on
  Auxiliary Components</dc:title>
 <dc:creator>Sripad, Shashank</dc:creator>
 <dc:creator>Kulandaivel, Sekar</dc:creator>
 <dc:creator>Pande, Vikram</dc:creator>
 <dc:creator>Sekar, Vyas</dc:creator>
 <dc:creator>Viswanathan, Venkatasubramanian</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Modern automobiles are entirely controlled by electronic circuits and
programs which undoubtedly exposes them to the threat of cyberattacks.
Alongside, there is a potential for massive growth in electric vehicle (EV)
adoption. The cyber vulnerabilities are magnified with electric vehicles
because of the unique and critical risks that entail most EV batteries. EV
battery packs provide 'limited driving range' and have 'finite lifetime', and
there is widespread anxiety regarding range and life. In this study, we develop
a systematic framework to model cyberattacks on auxiliary components and
identify the consequent impact on EV batteries. We model the possible
cyberattacks on auxiliary components by engaging them in various 'modes' and
analyze the impact on battery packs described through a physics-driven
experimentally-validated model that accurately captures battery dynamics and
degradation. In the short-term, cyberattacks could deplete a battery pack by up
to 20% per hour and completely drain the available range. The EV battery pack
is most vulnerable to cyberattacks when it is fully charged due to the
influence of state-of-charge (SOC) on the battery health. For long-term impact,
we explore the location effect of attack and identify that cyberattacks could
cause a 3-fold increase in the internal resistance (an indicator of cycle life)
in cold regions versus hot regions. We believe that the methodology and the
approach presented will help in building the foundational principles for
cyber-security in the context of electric vehicles; a very nascent but
crucially important topic in the coming years.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, Supporting Information</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04837</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Factor-Based Quantitative Investing by Forecasting Company
  Fundamentals</dc:title>
 <dc:creator>Alberg, John</dc:creator>
 <dc:creator>Lipton, Zachary C.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  On a periodic basis, publicly traded companies are required to report
fundamentals: financial data such as revenue, operating income, debt, among
others. These data points provide some insight into the financial health of a
company. Academic research has identified some factors, i.e. computed features
of the reported data, that are known through retrospective analysis to
outperform the market average. Two popular factors are the book value
normalized by market capitalization (book-to-market) and the operating income
normalized by the enterprise value (EBIT/EV). In this paper: we first show
through simulation that if we could (clairvoyantly) select stocks using factors
calculated on future fundamentals (via oracle), then our portfolios would far
outperform a standard factor approach. Motivated by this analysis, we train
deep neural networks to forecast future fundamentals based on a trailing
5-years window. Quantitative analysis demonstrates a significant improvement in
MSE over a naive strategy. Moreover, in retrospective analysis using an
industry-grade stock portfolio simulator (backtester), we show an improvement
in compounded annual return to 17.1% (MLP) vs 14.4% for a standard factor
model.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04845</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Invariances and Data Augmentation for Supervised Music Transcription</dc:title>
 <dc:creator>Thickstun, John</dc:creator>
 <dc:creator>Harchaoui, Zaid</dc:creator>
 <dc:creator>Foster, Dean</dc:creator>
 <dc:creator>Kakade, Sham M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  This paper explores a variety of models for frame-based music transcription,
with an emphasis on the methods needed to reach state-of-the-art on human
recordings. The translation-invariant network discussed in this paper, which
combines a traditional filterbank with a convolutional neural network, was the
top-performing model in the 2017 MIREX Multiple Fundamental Frequency
Estimation evaluation. This class of models shares parameters in the
log-frequency domain, which exploits the frequency invariance of music to
reduce the number of model parameters and avoid overfitting to the training
data. All models in this paper were trained with supervision by labeled data
from the MusicNet dataset, augmented by random label-preserving pitch-shift
transformations.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04848</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reliability and Sharpness in Border Crossing Traffic Interval Prediction</dc:title>
 <dc:creator>Lin, Lei</dc:creator>
 <dc:creator>Handley, John</dc:creator>
 <dc:creator>Sadek, Adel</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Short-term traffic volume prediction models have been extensively studied in
the past few decades. However, most of the previous studies only focus on
single-value prediction. Considering the uncertain and chaotic nature of the
transportation system, an accurate and reliable prediction interval with upper
and lower bounds may be better than a single point value for transportation
management. In this paper, we introduce a neural network model called Extreme
Learning Machine (ELM) for interval prediction of short-term traffic volume and
improve it with the heuristic particle swarm optimization algorithm (PSO). The
hybrid PSO-ELM model can generate the prediction intervals under different
confidence levels and guarantee the quality by minimizing a multi-objective
function which considers two criteria reliability and interval sharpness. The
PSO-ELM models are built based on an hourly traffic dataset and compared with
ARMA and Kalman Filter models. The results show that ARMA models are the worst
for all confidence levels, and the PSO-ELM models are comparable with Kalman
Filter from the aspects of reliability and narrowness of the intervals,
although the parameters of PSO-ELM are fixed once the training is done while
Kalman Filter is updated in an online approach. Additionally, only the PSO-ELMs
are able to produce intervals with coverage probabilities higher than or equal
to the confidence levels. For the points outside of the prediction levels given
by PSO-ELMs, they lie very close to the bounds.
</dc:description>
 <dc:description>Comment: Presented at 2017 TRB Annual Meeting</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04851</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning and Visualizing Localized Geometric Features Using 3D-CNN: An
  Application to Manufacturability Analysis of Drilled Holes</dc:title>
 <dc:creator>Ghadai, Sambit</dc:creator>
 <dc:creator>Balu, Aditya</dc:creator>
 <dc:creator>Krishnamurthy, Adarsh</dc:creator>
 <dc:creator>Sarkar, Soumik</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  3D Convolutional Neural Networks (3D-CNN) have been used for object
recognition based on the voxelized shape of an object. However, interpreting
the decision making process of these 3D-CNNs is still an infeasible task. In
this paper, we present a unique 3D-CNN based Gradient-weighted Class Activation
Mapping method (3D-GradCAM) for visual explanations of the distinct local
geometric features of interest within an object. To enable efficient learning
of 3D geometries, we augment the voxel data with surface normals of the object
boundary. We then train a 3D-CNN with this augmented data and identify the
local features critical for decision-making using 3D GradCAM. An application of
this feature identification framework is to recognize difficult-to-manufacture
drilled hole features in a complex CAD geometry. The framework can be extended
to identify difficult-to-manufacture features at multiple spatial scales
leading to a real-time design for manufacturability decision support system.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2017 Symposium on Interpretable Machine Learning</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04851</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04853</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Denoising Imaging Polarimetry by an Adapted BM3D Method</dc:title>
 <dc:creator>Tibbs, Alexander B.</dc:creator>
 <dc:creator>Daly, Ilse M.</dc:creator>
 <dc:creator>Roberts, Nicholas W.</dc:creator>
 <dc:creator>Bull, David R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Imaging polarimetry allows more information to be extracted from a scene than
conventional intensity or colour imaging. However, a major challenge of imaging
polarimetry is image degradation due to noise. This paper investigates the
mitigation of noise through denoising algorithms and compares existing
denoising algorithms with a new method, based on BM3D. This algorithm, PBM3D,
gives visual quality superior to the state of the art across all images and
noise standard deviations tested. We show that denoising polarization images
using PBM3D allows the degree of polarization to be more accurately calculated
by comparing it to spectroscopy methods.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04855</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Human Categorization of Natural Images Using Deep Feature
  Representations</dc:title>
 <dc:creator>Battleday, Ruairidh M.</dc:creator>
 <dc:creator>Peterson, Joshua C.</dc:creator>
 <dc:creator>Griffiths, Thomas L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Over the last few decades, psychologists have developed sophisticated formal
models of human categorization using simple artificial stimuli. In this paper,
we use modern machine learning methods to extend this work into the realm of
naturalistic stimuli, enabling human categorization to be studied over the
complex visual domain in which it evolved and developed. We show that
representations derived from a convolutional neural network can be used to
model behavior over a database of &gt;300,000 human natural image classifications,
and find that a group of models based on these representations perform well,
near the reliability of human judgments. Interestingly, this group includes
both exemplar and prototype models, contrasting with the dominance of exemplar
models in previous work. We are able to improve the performance of the
remaining models by preprocessing neural network representations to more
closely capture human similarity judgments.
</dc:description>
 <dc:description>Comment: 13 pages, 7 figures, 6 tables. Preliminary work presented at CogSci
  2017</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04870</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Game Theory for Real-Time Behavioral Dynamics in Microscopic
  Populations with Noisy Signaling</dc:title>
 <dc:creator>Noel, Adam</dc:creator>
 <dc:creator>Fang, Yuting</dc:creator>
 <dc:creator>Yang, Nan</dc:creator>
 <dc:creator>Makrakis, Dimitrios</dc:creator>
 <dc:creator>Eckford, Andrew W.</dc:creator>
 <dc:subject>Quantitative Biology - Cell Behavior</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  This article introduces the application of game theory to understand noisy
real-time signaling and the resulting behavioral dynamics in microscopic
populations such as bacteria and other cells. It presents a bridge between the
fields of molecular communication and microscopic game theory. Molecular
communication uses conventional communication engineering theory and techniques
to study and design systems that use chemical molecules as information
carriers. Microscopic game theory models interactions within and between
populations of cells and microorganisms. Integrating these two fields provides
unique opportunities to understand and control microscopic populations that
have imperfect signal propagation. Two case studies, namely bacteria resource
sharing and tumor cell signaling, are presented as examples to demonstrate the
potential of this approach.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, 1 box. Submitted for publication</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04875</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Shape Classification Using Collaborative Representation based
  Projections</dc:title>
 <dc:creator>Fotopoulou, F.</dc:creator>
 <dc:creator>Oikonomou, S.</dc:creator>
 <dc:creator>Papathanasiou, A.</dc:creator>
 <dc:creator>Economou, G.</dc:creator>
 <dc:creator>Fotopoulos, S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A novel 3D shape classification scheme, based on collaborative representation
learning, is investigated in this work. A data-driven feature-extraction
procedure, taking the form of a simple projection operator, is in the core of
our methodology. Provided a shape database, a graph encapsulating the
structural relationships among all the available shapes, is first constructed
and then employed in defining low-dimensional sparse projections. The recently
introduced method of CRPs (collaborative representation based projections),
which is based on L2-Graph, is the first variant that is included towards this
end. A second algorithm, that particularizes the CRPs to shape descriptors that
are inherently nonnegative, is also introduced as potential alternative. In
both cases, the weights in the graph reflecting the database structure are
calculated so as to approximate each shape as a sparse linear combination of
the remaining dataset objects. By way of solving a generalized eigenanalysis
problem, a linear matrix operator is designed that will act as the feature
extractor. Two popular, inherently high dimensional descriptors, namely
ShapeDNA and Global Point Signature (GPS), are employed in our experimentations
with SHREC10, SHREC11 and SCHREC 15 datasets, where shape recognition is cast
as a multi-class classification problem that is tackled by means of an SVM
(support vector machine) acting within the reduced dimensional space of the
crafted projections. The results are very promising and outperform state of the
art methods, providing evidence about the highly discriminative nature of the
introduced 3D shape representations.
</dc:description>
 <dc:description>Comment: 16 pages, 6 Figures, 3 Tables Statement including that an updated
  version of this manuscript is under condiseration at Pattern Recognition
  Letters, is added</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2017-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04875</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04881</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Graph Parameters from Random Order Streams</dc:title>
 <dc:creator>Peng, Pan</dc:creator>
 <dc:creator>Sohler, Christian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We develop a new algorithmic technique that allows to transfer some constant
time approximation algorithms for general graphs into random order streaming
algorithms. We illustrate our technique by proving that in random order streams
with probability at least $2/3$,
  $\bullet$ the number of connected components of $G$ can be approximated up to
an additive error of $\varepsilon n$ using
$(\frac{1}{\varepsilon})^{O(1/\varepsilon^3)}$ space,
  $\bullet$ the weight of a minimum spanning tree of a connected input graph
with integer edges weights from $\{1,\dots,W\}$ can be approximated within a
multiplicative factor of $1+\varepsilon$ using
$\big(\frac{1}{\varepsilon}\big)^{\tilde O(W^3/\varepsilon^3)}$ space,
  $\bullet$ the size of a maximum independent set in planar graphs can be
approximated within a multiplicative factor of $1+\varepsilon$ using space
$2^{(1/\varepsilon)^{(1/\varepsilon)^{\log^{O(1)} (1/\varepsilon)}}}$.
</dc:description>
 <dc:description>Comment: SODA 2018</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04882</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Partial Covering For Geometric Set Systems</dc:title>
 <dc:creator>Inamdar, Tanmay</dc:creator>
 <dc:creator>Varadarajan, Kasturi</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study a generalization of the Set Cover problem called the \emph{Partial
Set Cover} in the context of geometric set systems. The input to this problem
is a set system $(X, \mathcal{S})$, where $X$ is a set of elements and
$\mathcal{S}$ is a collection of subsets of $X$, and an integer $k \le |X|$.
The goal is to cover at least $k$ elements of $X$ by using a minimum-weight
collection of sets from $\mathcal{S}$. The main result of this article is an LP
rounding scheme which shows that the integrality gap of the Partial Set Cover
LP is at most a constant times that of the Set Cover LP for a certain
projection of the set system $(X, \mathcal{S})$. As a corollary of this result,
we get improved approximation guarantees for the Partial Set Cover problem for
a large class of geometric set systems.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04883</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating HPC codes on Intel(R) Omni-Path Architecture networks: From
  particle physics to Machine Learning</dc:title>
 <dc:creator>Boyle, Peter</dc:creator>
 <dc:creator>Chuvelev, Michael</dc:creator>
 <dc:creator>Cossu, Guido</dc:creator>
 <dc:creator>Kelly, Christopher</dc:creator>
 <dc:creator>Lehner, Christoph</dc:creator>
 <dc:creator>Meadows, Lawrence</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>High Energy Physics - Lattice</dc:subject>
 <dc:description>  We discuss practical methods to ensure near wirespeed performance from
clusters with either one or two Intel(R) Omni-Path host fabric interfaces (HFI)
per node, and Intel(R) Xeon Phi(TM) 72xx (Knight's Landing) processors, and
using the Linux operating system.
  The study evaluates the performance improvements achievable and the required
programming approaches in two distinct example problems: firstly in Cartesian
communicator halo exchange problems, appropriate for structured grid PDE
solvers that arise in quantum chromodynamics simulations of particle physics,
and secondly in gradient reduction appropriate to synchronous stochastic
gradient descent for machine learning. As an example, we accelerate a published
Baidu Research reduction code and obtain a factor of ten speedup over the
original code using the techniques discussed in this paper. This displays how a
factor of ten speedup in strongly scaled distributed machine learning could be
achieved when synchronous stochastic gradient descent is massively parallelised
with a fixed mini-batch size.
  We find a significant improvement in performance robustness when memory is
obtained using carefully allocated 2MB &quot;huge&quot; virtual memory pages, implying
that either non-standard allocation routines should be used for communication
buffers. These can be accessed via a LD\_PRELOAD override in the manner
suggested by libhugetlbfs. We make use of a the Intel(R) MPI 2019 library
&quot;Technology Preview&quot; and underlying software to enable thread concurrency
throughout the communication software stake via multiple PSM2 endpoints per
process and use of multiple independent MPI communicators. When using a single
MPI process per node, we find that this greatly accelerates delivered bandwidth
in many core Intel(R) Xeon Phi processors.
</dc:description>
 <dc:description>Comment: 17 pages, 5 figures</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04884</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear piecewise-deterministic Markov processes with families of random
  discrete events</dc:title>
 <dc:creator>Soltani, Mohammad</dc:creator>
 <dc:creator>Singh, Abhyudai</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider a class of piecewise-deterministic Markov processes where the
state evolves according to a linear dynamical system. This continuous time
evolution is interspersed by discrete events that occur at random times and
change (reset) the state based on a linear affine map. In particular, we
consider two families of discrete events, with the first family of resets
occurring at exponentially-distributed times. The second family of resets is
generally-distributed, in the sense that, the time intervals between events are
independent and identically distributed random variables that follow an
arbitrary continuous positively-valued probability density function. For this
class of stochastic systems, we provide explicit conditions that lead to finite
stationary moments, and the corresponding exact closed-form moment formulas.
These results are illustrated on an example drawn from systems biology, where a
protein is expressed in bursts at exponentially-distributed time intervals,
decays within the cell-cycle, and is randomly divided among daughter cells when
generally-distributed cell-division events occur. Our analysis leads to novel
results for the mean and noise levels in protein copy numbers, and we decompose
the noise levels into components arising from stochastic expression, random
cell-cycle times, and partitioning. Interestingly, these individual noise
contributions behave differently as cell division times become more random. In
summary, the paper expands the class of stochastic hybrid systems for which
statistical moments can be derived exactly without any approximations, and
these results have applications for studying random phenomena in diverse areas.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04886</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IP Session continuity in heterogeneous mobile networks using Software
  Defined Networking</dc:title>
 <dc:creator>Bojovi&#x107;, Petar D.</dc:creator>
 <dc:creator>Bojovi&#x107;, &#x17d;ivko</dc:creator>
 <dc:creator>Baji&#x107;, Dragana</dc:creator>
 <dc:creator>&#x160;enk, Vojin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Smart environment requires uninterrupted connection when moving from one
network to another. This is best accomplished at the network level (L3). Full
interoperability and integration of heterogeneous networks is necessary for
communication session continuity. Software Defined Networking (SDN) with
virtual IP addresses solves the problem. Implementing a homogeneous SDN is
expensive, given the enormous investments in existing networks. To solve this
second problem, we deploy the least set of SDN features to provide full L3
mobility. We use a common controller to manage the IP address translations.
</dc:description>
 <dc:description>Comment: Accepted for publishing at Journal of Communications and Networks,
  Special issue on Wireless SDN</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04886</dc:identifier>
 <dc:identifier>Journal of Communications and Networks 19(6):563-568, December
  2017</dc:identifier>
 <dc:identifier>doi:10.1109/JCN.2017.000096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04887</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>STARK: Structured Dictionary Learning Through Rank-one Tensor Recovery</dc:title>
 <dc:creator>Ghassemi, Mohsen</dc:creator>
 <dc:creator>Shakeri, Zahra</dc:creator>
 <dc:creator>Sarwate, Anand D.</dc:creator>
 <dc:creator>Bajwa, Waheed U.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In recent years, a class of dictionaries have been proposed for
multidimensional (tensor) data representation that exploit the structure of
tensor data by imposing a Kronecker structure on the dictionary underlying the
data. In this work, a novel algorithm called &quot;STARK&quot; is provided to learn
Kronecker structured dictionaries that can represent tensors of any order. By
establishing that the Kronecker product of any number of matrices can be
rearranged to form a rank-1 tensor, we show that Kronecker structure can be
enforced on the dictionary by solving a rank-1 tensor recovery problem. Because
rank-1 tensor recovery is a challenging nonconvex problem, we resort to solving
a convex relaxation of this problem. Empirical experiments on synthetic and
real data show promising results for our proposed algorithm.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04889</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Annealing Applied to De-Conflicting Optimal Trajectories for Air
  Traffic Management</dc:title>
 <dc:creator>Stollenwerk, Tobias</dc:creator>
 <dc:creator>O'Gorman, Bryan</dc:creator>
 <dc:creator>Venturelli, Davide</dc:creator>
 <dc:creator>Mandr&#xe0;, Salvatore</dc:creator>
 <dc:creator>Rodionova, Olga</dc:creator>
 <dc:creator>Ng, Hok K.</dc:creator>
 <dc:creator>Sridhar, Banavar</dc:creator>
 <dc:creator>Rieffel, Eleanor G.</dc:creator>
 <dc:creator>Biswas, Rupak</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present the mapping of a class of simplified air traffic management (ATM)
problems (strategic conflict resolution) to quadratic unconstrained boolean
optimization (QUBO) problems. The mapping is performed through an original
representation of the conflict-resolution problem in terms of a conflict graph,
where nodes of the graph represent flights and edges represent a potential
conflict between flights. The representation allows a natural decomposition of
a real world instance related to wind- optimal trajectories over the Atlantic
ocean into smaller subproblems, that can be discretized and are amenable to be
programmed in quantum annealers. In the study, we tested the new programming
techniques and we benchmark the hardness of the instances using both classical
solvers and the D-Wave 2X and D-Wave 2000Q quantum chip. The preliminary
results show that for reasonable modeling choices the most challenging
subproblems which are programmable in the current devices are solved to
optimality with 99% of probability within a second of annealing time.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04892</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eigendecomposition-Based Partial FFT Demodulation for Differential OFDM
  in Underwater Acoustic Communications</dc:title>
 <dc:creator>Han, Jing</dc:creator>
 <dc:creator>Zhang, Lingling</dc:creator>
 <dc:creator>Zhang, Qunfei</dc:creator>
 <dc:creator>Leus, Geert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Differential orthogonal frequency division multiplexing (OFDM) is practically
attractive for underwater acoustic communications since it has the potential to
obviate channel estimation. However, similar to coherent OFDM, it may suffer
from severe inter-carrier interference over time-varying channels. To alleviate
the induced performance degradation, we adopt the newly-emerging partial FFT
demodulation technique in this paper and propose an eigendecomposition-based
algorithm to compute the combining weights. Compared to existing adaptive
methods, the new algorithm can avoid error propagation and eliminate the need
for parameter tuning. Moreover, it guarantees global optimality under the
narrowband Doppler assumption, with the optimal weight vector of partial FFT
demodulation achieved by the eigenvector associated with the smallest
eigenvalue of the pilot detection error matrix. Finally, the algorithm can also
be extended straightforwardly to perform subband-wise computation to counteract
wideband Doppler effects.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Vehicular Technology, Nov. 2017</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04894</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sobolev GAN</dc:title>
 <dc:creator>Mroueh, Youssef</dc:creator>
 <dc:creator>Li, Chun-Liang</dc:creator>
 <dc:creator>Sercu, Tom</dc:creator>
 <dc:creator>Raj, Anant</dc:creator>
 <dc:creator>Cheng, Yu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new Integral Probability Metric (IPM) between distributions: the
Sobolev IPM. The Sobolev IPM compares the mean discrepancy of two distributions
for functions (critic) restricted to a Sobolev ball defined with respect to a
dominant measure $\mu$. We show that the Sobolev IPM compares two distributions
in high dimensions based on weighted conditional Cumulative Distribution
Functions (CDF) of each coordinate on a leave one out basis. The Dominant
measure $\mu$ plays a crucial role as it defines the support on which
conditional CDFs are compared. Sobolev IPM can be seen as an extension of the
one dimensional Von-Mises Cram\'er statistics to high dimensional
distributions. We show how Sobolev IPM can be used to train Generative
Adversarial Networks (GANs). We then exploit the intrinsic conditioning implied
by Sobolev IPM in text generation. Finally we show that a variant of Sobolev
GAN achieves competitive results in semi-supervised learning on CIFAR-10,
thanks to the smoothness enforced on the critic by Sobolev GAN which relates to
Laplacian regularization.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04895</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differential-Flatness and Control of Quadrotor(s) with a Payload
  Suspended through Flexible Cable(s)</dc:title>
 <dc:creator>Kotaru, Prasanth</dc:creator>
 <dc:creator>Wu, Guofan</dc:creator>
 <dc:creator>Sreenath, Koushil</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We present the coordinate-free dynamics of three different quadrotor systems
: (a) single quadrotor with a point-mass payload suspended through a flexible
cable; (b) multiple quadrotors with a shared point-mass payload suspended
through flexible cables; and (c) multiple quadrotors with a shared rigid-body
payload suspended through flexible cables. We model the flexible cable(s) as a
finite series of links with spherical joints with mass concentrated at the end
of each link. The resulting systems are thus high-dimensional with high
degree-of-underactuation. For each of these systems, we show that the dynamics
are differentially-flat, enabling planning of dynamically feasible
trajectories. For the single quadrotor with a point-mass payload suspended
through a flexible cable with five links (16 degrees-of-freedom and 12
degrees-of-underactuation), we use the coordinate-free dynamics to develop a
geometric variation-based linearized equations of motion about a desired
trajectory. We show that a finite-horizon linear quadratic regulator can be
used to track a desired trajectory with a relatively large region of
attraction.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04898</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effect of enhanced dissipation by shear flows on transient relaxation
  and probability density function in two dimensions</dc:title>
 <dc:creator>Kim, Eun-jin</dc:creator>
 <dc:creator>Movahedi, Ismail</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:subject>Physics - Plasma Physics</dc:subject>
 <dc:subject>60 Probability theory and stochastic processes</dc:subject>
 <dc:description>  We report a non-perturbative study of the effects of shear flows on
turbulence reduction in a decaying turbulence in two dimensions. By considering
different initial power spectra and shear flows (zonal flows, combined zonal
flows and streamers), we demonstrate how shear flows rapidly generate small
scales, leading to a fast damping of turbulence amplitude. In particular, a
double exponential decrease in turbulence amplitude is shown to occur due to an
exponential increase in wavenumber. The scaling of the effective dissipation
time scale $\tau_{e}$, previously taken to be a hybrid time scale $\tau_{e}
\propto \tau_{\Omega}^{{2/3}} \tau_{\eta}$, is shown to depend on types of
depend on the type of shear flow as well as the initial power spectrum. Here,
$\tau_{\Omega}$ and $\tau_{\eta}$ are shearing and molecular diffusion times,
respectively. Furthermore, we present time-dependent Probability Density
Functions (PDFs) and discuss the effect of enhanced dissipation on PDFs and a
dynamical time scale $\tau(t)$, which represents the time scale over which a
system passes through statistically different states.
</dc:description>
 <dc:description>Comment: 26 pages, 5 figures</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04898</dc:identifier>
 <dc:identifier>doi:10.1063/1.5003014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04901</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Target Recognition of Aircraft using Inverse Synthetic
  Aperture Radar</dc:title>
 <dc:creator>Pena-Caballero, Carlos</dc:creator>
 <dc:creator>Cantu, Elifaleth</dc:creator>
 <dc:creator>Rodriguez, Jesus</dc:creator>
 <dc:creator>Gonzales, Adolfo</dc:creator>
 <dc:creator>Castellanos, Osvaldo</dc:creator>
 <dc:creator>Cantu, Angel</dc:creator>
 <dc:creator>Strait, Megan</dc:creator>
 <dc:creator>Son, Jae</dc:creator>
 <dc:creator>Kim, Dongchul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Along with the improvement of radar technologies, Automatic Target
Recognition (ATR) using Synthetic Aperture Radar (SAR) and Inverse SAR (ISAR)
has come to be an active research area. SAR/ISAR are radar techniques to
generate a two-dimensional high-resolution image of a target. Unlike other
similar experiments using Convolutional Neural Networks (CNN) to solve this
problem, we utilize an unusual approach that leads to better performance and
faster training times. Our CNN uses complex values generated by a simulation to
train the network; additionally, we utilize a multi-radar approach to increase
the accuracy of the training and testing processes, thus resulting in higher
accuracies than the other papers working on SAR/ISAR ATR. We generated our
dataset with 7 different aircraft models with a radar simulator we developed
called RadarPixel; it is a Windows GUI program implemented using Matlab and
Java programming, the simulator is capable of accurately replicating a real
SAR/ISAR configurations. Our objective is to utilize our multi-radar technique
and determine the optimal number of radars needed to detect and classify
targets.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04902</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PassBio: Privacy-Preserving User-Centric Biometric Authentication</dc:title>
 <dc:creator>Zhou, Kai</dc:creator>
 <dc:creator>Ren, Jian</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The proliferation of online biometric authentication has necessitated
security requirements of biometric templates. The existing secure biometric
authentication schemes feature a server-centric model, where a service provider
maintains a biometric database and is fully responsible for the security of the
templates. The end-users have to fully trust the server in storing, processing
and managing their private templates. As a result, the end-users' templates
could be compromised by outside attackers or even the service provider itself.
In this paper, we propose a user-centric biometric authentication scheme
(PassBio) that enables end-users to encrypt their own templates with our
proposed light-weighted encryption scheme. During authentication, all the
templates remain encrypted such that the server will never see them directly.
However, the server is able to determine whether the distance of two encrypted
templates is within a pre-defined threshold. Our security analysis shows that
no critical information of the templates can be revealed under both passive and
active attacks. PassBio follows a &quot;compute-then-compare&quot; computational model
over encrypted data. More specifically, our proposed Threshold Predicate
Encryption (TPE) scheme can encrypt two vectors x and y in such a manner that
the inner product of x and y can be evaluated and compared to a pre-defined
threshold. TPE guarantees that only the comparison result is revealed and no
key information about x and y can be learned. Furthermore, we show that TPE can
be utilized as a flexible building block to evaluate different distance metrics
such as Hamming distance and Euclidean distance over encrypted data. Such a
compute-then-compare computational model, enabled by TPE, can be widely applied
in many interesting applications such as searching over encrypted data while
ensuring data security and privacy.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04903</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Multilingual Part-of-Speech Tagging via Adversarial Training</dc:title>
 <dc:creator>Yasunaga, Michihiro</dc:creator>
 <dc:creator>Kasai, Jungo</dc:creator>
 <dc:creator>Radev, Dragomir</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Adversarial training (AT) is a powerful regularization method for neural
networks, aiming to achieve robustness to input perturbations. Yet, the
specific effects of the robustness obtained by AT are still unclear in the
context of natural language processing. In this paper, we propose and analyze a
neural POS tagging model that exploits adversarial training (AT). In our
experiments on the Penn Treebank WSJ corpus and the Universal Dependencies (UD)
dataset (28 languages), we find that AT not only improves the overall tagging
accuracy, but also 1) largely prevents overfitting in low resource languages
and 2) boosts tagging accuracy for rare / unseen words. The proposed POS tagger
achieves state-of-the-art performance on nearly all of the languages in UD
v1.2. We also demonstrate that 3) the improved tagging performance by AT
contributes to the downstream task of dependency parsing, and that 4) AT helps
the model to learn cleaner word and internal representations. These positive
results motivate further use of AT for natural language tasks.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04907</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Family of Constrained Adaptive filtering Algorithms Based on
  Logarithmic Cost</dc:title>
 <dc:creator>Gogineni, Vinay Chakravarthi</dc:creator>
 <dc:creator>Mula, Subrahmanyam</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper introduces a novel constraint adaptive filtering algorithm based
on a relative logarithmic cost function which is termed as Constrained Least
Mean Logarithmic Square (CLMLS). The proposed CLMLS algorithm elegantly adjusts
the cost function based on the amount of error thereby achieves better
performance compared to the conventional Constrained LMS (CLMS) algorithm. With
no assumption on input, the mean square stability analysis of the proposed
CLMLS algorithm is presented using the energy conservation approach. The
analytical expressions for the transient and steady state MSD are derived and
these analytical results are validated through extensive simulations. The
proposed CLMLS algorithm is extended to the sparse case by incorporating the
$\ell_1$-norm penalty into the CLMLS cost function. detailed Simulations
confirms the superiority of the sparse CLMLS over the state-of-the-art.
</dc:description>
 <dc:description>Comment: 14 pages, 3 figures under communication</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04913</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>pyLEMMINGS: Large Margin Multiple Instance Classification and Ranking
  for Bioinformatics Applications</dc:title>
 <dc:creator>Asif, Amina</dc:creator>
 <dc:creator>Abbasi, Wajid Arshad</dc:creator>
 <dc:creator>Munir, Farzeen</dc:creator>
 <dc:creator>Ben-Hur, Asa</dc:creator>
 <dc:creator>Minhas, Fayyaz ul Amir Afsar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Motivation: A major challenge in the development of machine learning based
methods in computational biology is that data may not be accurately labeled due
to the time and resources required for experimentally annotating properties of
proteins and DNA sequences. Standard supervised learning algorithms assume
accurate instance-level labeling of training data. Multiple instance learning
is a paradigm for handling such labeling ambiguities. However, the widely used
large-margin classification methods for multiple instance learning are
heuristic in nature with high computational requirements. In this paper, we
present stochastic sub-gradient optimization large margin algorithms for
multiple instance classification and ranking, and provide them in a software
suite called pyLEMMINGS.
  Results: We have tested pyLEMMINGS on a number of bioinformatics problems as
well as benchmark datasets. pyLEMMINGS has successfully been able to identify
functionally important segments of proteins: binding sites in Calmodulin
binding proteins, prion forming regions, and amyloid cores. pyLEMMINGS achieves
state-of-the-art performance in all these tasks, demonstrating the value of
multiple instance learning. Furthermore, our method has shown more than
100-fold improvement in terms of running time as compared to heuristic
solutions with improved accuracy over benchmark datasets.
  Availability and Implementation: pyLEMMINGS python package is available for
download at: http://faculty.pieas.edu.pk/fayyaz/software.html#pylemmings.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04915</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Symmetric Variational Autoencoder</dc:title>
 <dc:creator>Pu, Yunchen</dc:creator>
 <dc:creator>Wang, Weiyao</dc:creator>
 <dc:creator>Henao, Ricardo</dc:creator>
 <dc:creator>Chen, Liqun</dc:creator>
 <dc:creator>Gan, Zhe</dc:creator>
 <dc:creator>Li, Chunyuan</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A new form of variational autoencoder (VAE) is developed, in which the joint
distribution of data and codes is considered in two (symmetric) forms: ($i$)
from observed data fed through the encoder to yield codes, and ($ii$) from
latent codes drawn from a simple prior and propagated through the decoder to
manifest data. Lower bounds are learned for marginal log-likelihood fits
observed data and latent codes. When learning with the variational bound, one
seeks to minimize the symmetric Kullback-Leibler divergence of joint density
functions from ($i$) and ($ii$), while simultaneously seeking to maximize the
two marginal log-likelihoods. To facilitate learning, a new form of adversarial
training is developed. An extensive set of experiments is performed, in which
we demonstrate state-of-the-art data reconstruction and generation on several
image benchmark datasets.
</dc:description>
 <dc:description>Comment: Accepted to NIPS 2017</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2017-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04916</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Steganography with Kerckhoffs' Principle based on Generative
  Adversarial Networks</dc:title>
 <dc:creator>Ke, Yan</dc:creator>
 <dc:creator>Zhang, Minqing</dc:creator>
 <dc:creator>Liu, Jia</dc:creator>
 <dc:creator>Su, Tingting</dc:creator>
 <dc:creator>Yang, Xiaoyuan</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The distortion in steganography that usually comes from the modification or
recoding on the cover image during the embedding process leaves the
steganalyzer with possibility of discriminating. Faced with such a risk, we
propose generative steganography with Kerckhoffs' principle (GSK) in this
letter. In GSK, the secret messages are generated by a cover image using a
generator rather than embedded into the cover, thus resulting in no
modifications in the cover. To ensure the security, the generators are trained
to meet Kerckhoffs' principle based on generative adversarial networks (GAN).
Everything about the GSK system, except the extraction key, is public knowledge
for the receivers. The secret messages can be outputted by the generator if and
only if the extraction key and the cover image are both inputted. In the
generator training procedures, there are two GANs, Message- GAN and Cover-GAN,
designed to work jointly making the generated results under the control of the
extraction key and the cover image. We provide experimental results on the
training process and give an example of the working process by adopting a
generator trained on MNIST, which demonstrate that GSK can use a cover image
without any modification to generate messages, and without the extraction key
or the cover image, only meaningless results would be obtained.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04934</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistically Optimal and Computationally Efficient Low Rank Tensor
  Completion from Noisy Entries</dc:title>
 <dc:creator>Xia, Dong</dc:creator>
 <dc:creator>Yuan, Ming</dc:creator>
 <dc:creator>Zhang, Cun-Hui</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  In this article, we develop methods for estimating a low rank tensor from
noisy observations on a subset of its entries to achieve both statistical and
computational efficiencies. There have been a lot of recent interests in this
problem of noisy tensor completion. Much of the attention has been focused on
the fundamental computational challenges often associated with problems
involving higher order tensors, yet very little is known about their
statistical performance. To fill in this void, in this article, we characterize
the fundamental statistical limits of noisy tensor completion by establishing
minimax optimal rates of convergence for estimating a $k$th order low rank
tensor under the general $\ell_p$ ($1\le p\le 2$) norm which suggest
significant room for improvement over the existing approaches. Furthermore, we
propose a polynomial-time computable estimating procedure based upon power
iteration and a second-order spectral initialization that achieves the optimal
rates of convergence. Our method is fairly easy to implement and numerical
experiments are presented to further demonstrate the practical merits of our
estimator.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04945</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capturing Localized Image Artifacts through a CNN-based Hyper-image
  Representation</dc:title>
 <dc:creator>Chandakkar, Parag Shridhar</dc:creator>
 <dc:creator>Li, Baoxin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Training deep CNNs to capture localized image artifacts on a relatively small
dataset is a challenging task. With enough images at hand, one can hope that a
deep CNN characterizes localized artifacts over the entire data and their
effect on the output. However, on smaller datasets, such deep CNNs may overfit
and shallow ones find it hard to capture local artifacts. Thus some image-based
small-data applications first train their framework on a collection of patches
(instead of the entire image) to better learn the representation of localized
artifacts. Then the output is obtained by averaging the patch-level results.
Such an approach ignores the spatial correlation among patches and how various
patch locations affect the output. It also fails in cases where few patches
mainly contribute to the image label. To combat these scenarios, we develop the
notion of hyper-image representations. Our CNN has two stages. The first stage
is trained on patches. The second stage utilizes the last layer representation
developed in the first stage to form a hyper-image, which is used to train the
second stage. We show that this approach is able to develop a better mapping
between the image and its output. We analyze additional properties of our
approach and show its effectiveness on one synthetic and two real-world vision
tasks - no-reference image quality estimation and image tampering detection -
by its performance improvement over existing strong baselines.
</dc:description>
 <dc:description>Comment: Our work on No-reference Image Quality Estimation (NR-IQA) using deep
  neural networks</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04951</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Word Segmentation to POS Tagging for Vietnamese</dc:title>
 <dc:creator>Nguyen, Dat Quoc</dc:creator>
 <dc:creator>Vu, Thanh</dc:creator>
 <dc:creator>Nguyen, Dai Quoc</dc:creator>
 <dc:creator>Dras, Mark</dc:creator>
 <dc:creator>Johnson, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents an empirical comparison of two strategies for Vietnamese
Part-of-Speech (POS) tagging from unsegmented text: (i) a pipeline strategy
where we consider the output of a word segmenter as the input of a POS tagger,
and (ii) a joint strategy where we predict a combined segmentation and POS tag
for each syllable. We also make a comparison between state-of-the-art (SOTA)
feature-based and neural network-based models. On the benchmark Vietnamese
treebank (Nguyen et al., 2009), experimental results show that the pipeline
strategy produces better scores of POS tagging from unsegmented text than the
joint strategy, and the highest accuracy is obtained by using a feature-based
model.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of the 15th Annual Workshop of the
  Australasian Language Technology Association, ALTA 2017</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04955</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Strictly Contractive Peaceman-Rachford Splitting Method</dc:title>
 <dc:creator>Na, Sen</dc:creator>
 <dc:creator>Ma, Mingyuan</dc:creator>
 <dc:creator>Ma, Shuming</dc:creator>
 <dc:creator>Peng, Guangju</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we propose a couple of new Stochastic Strictly Contractive
Peaceman-Rachford Splitting Method (SCPRSM), called Stochastic SCPRSM (SS-PRSM)
and Stochastic Conjugate Gradient SCPRSM (SCG-PRSM) for large-scale
optimization problems. The two types of Stochastic PRSM algorithms respectively
incorporate stochastic variance reduced gradient (SVRG) and conjugate gradient
method. Stochastic PRSM methods and most stochastic ADMM algorithms can only
achieve a $O(1/\sqrt{t})$ convergence rate on general convex problems, while
our SS-PRSM has a $O(1/t)$ convergence rate in general convexity case which
matches the convergence rate of the batch ADMM and SCPRSM algorithms. Besides
our methods has faster convergence rate and lower memory cost. SCG-PRSM is the
first to improve the performance by incorporating conjugate gradient and using
the Armijo line search method. Experiments shows that the proposed algorithms
are faster than stochastic and batch ADMM algorithms. The numerical experiments
show SCG-PRSM achieve the state-of-the-art performance on our benchmark
datasets.
</dc:description>
 <dc:description>Comment: submit to NIPS 2017</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04956</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classical Structured Prediction Losses for Sequence to Sequence Learning</dc:title>
 <dc:creator>Edunov, Sergey</dc:creator>
 <dc:creator>Ott, Myle</dc:creator>
 <dc:creator>Auli, Michael</dc:creator>
 <dc:creator>Grangier, David</dc:creator>
 <dc:creator>Ranzato, Marc'Aurelio</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  There has been much recent work on training neural attention models at the
sequence-level using either reinforcement learning-style methods or by
optimizing the beam. In this paper, we survey a range of classical objective
functions that have been widely used to train linear models for structured
prediction and apply them to neural sequence to sequence models. Our
experiments show that these losses can perform surprisingly well by slightly
outperforming beam search optimization in a like for like setup. We also report
new state of the art results on both IWSLT 2014 German-English translation as
well as Gigaword abstractive summarization.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04964</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Human-level Machine Reading Comprehension: Reasoning and
  Inference with Multiple Strategies</dc:title>
 <dc:creator>Xu, Yichong</dc:creator>
 <dc:creator>Liu, Jingjing</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Shen, Yelong</dc:creator>
 <dc:creator>Liu, Xiaodong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents a new MRC model that is capable of three key
comprehension skills: 1) handling rich variations in question types; 2)
understanding potential answer choices; and 3) drawing inference through
multiple sentences. The model is based on the proposed MUlti-Strategy Inference
for Comprehension (MUSIC) architecture, which is able to dynamically apply
different attention strategies to different types of questions on the fly. By
incorporating a multi-step inference engine analogous to ReasoNet (Shen et al.,
2017), MUSIC can also effectively perform multi-sentence inference in
generating answers. Evaluation on the RACE dataset shows that the proposed
method significantly outperforms previous state-of-the-art models by 7.5% in
relative accuracy.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04965</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-optimal sample complexity for convex tensor completion</dc:title>
 <dc:creator>Ghadermarzy, Navid</dc:creator>
 <dc:creator>Plan, Yaniv</dc:creator>
 <dc:creator>Y&#x131;lmaz, &#xd6;zg&#xfc;r</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>62H12, 94A15, 15A69</dc:subject>
 <dc:description>  We analyze low rank tensor completion (TC) using noisy measurements of a
subset of the tensor. Assuming a rank-$r$, order-$d$, $N \times N \times \cdots
\times N$ tensor where $r=O(1)$, the best sampling complexity that was achieved
is $O(N^{\frac{d}{2}})$, which is obtained by solving a tensor nuclear-norm
minimization problem. However, this bound is significantly larger than the
number of free variables in a low rank tensor which is $O(dN)$. In this paper,
we show that by using an atomic-norm whose atoms are rank-$1$ sign tensors, one
can obtain a sample complexity of $O(dN)$. Moreover, we generalize the matrix
max-norm definition to tensors, which results in a max-quasi-norm (max-qnorm)
whose unit ball has small Rademacher complexity. We prove that solving a
constrained least squares estimation using either the convex atomic-norm or the
nonconvex max-qnorm results in optimal sample complexity for the problem of
low-rank tensor completion. Furthermore, we show that these bounds are nearly
minimax rate-optimal. We also provide promising numerical results for max-qnorm
constrained tensor completion, showing improved recovery results compared to
matricization and alternating least squares.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04969</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Straggler Mitigation in Distributed Optimization Through Data Encoding</dc:title>
 <dc:creator>Karakus, Can</dc:creator>
 <dc:creator>Sun, Yifan</dc:creator>
 <dc:creator>Diggavi, Suhas</dc:creator>
 <dc:creator>Yin, Wotao</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Slow running or straggler tasks can significantly reduce computation speed in
distributed computation. Recently, coding-theory-inspired approaches have been
applied to mitigate the effect of straggling, through embedding redundancy in
certain linear computational steps of the optimization algorithm, thus
completing the computation without waiting for the stragglers. In this paper,
we propose an alternate approach where we embed the redundancy directly in the
data itself, and allow the computation to proceed completely oblivious to
encoding. We propose several encoding schemes, and demonstrate that popular
batch algorithms, such as gradient descent and L-BFGS, applied in a
coding-oblivious manner, deterministically achieve sample path linear
convergence to an approximate solution of the original problem, using an
arbitrarily varying subset of the nodes at each iteration. Moreover, this
approximation can be controlled by the amount of redundancy and the number of
nodes used in each iteration. We provide experimental results demonstrating the
advantage of the approach over uncoded and data replication strategies.
</dc:description>
 <dc:description>Comment: appeared at NIPS 2017</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04971</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DataVizard: Recommending Visual Presentations for Structured Data</dc:title>
 <dc:creator>Ananthanarayanan, Rema</dc:creator>
 <dc:creator>Lohia, Pranay Kr.</dc:creator>
 <dc:creator>Bedathur, Srikanta</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Selecting the appropriate visual presentation of the data such that it
preserves the semantics of the underlying data and at the same time provides an
intuitive summary of the data is an important, often the final step of data
analytics. Unfortunately, this is also a step involving significant human
effort starting from selection of groups of columns in the structured results
from analytics stages, to the selection of right visualization by experimenting
with various alternatives. In this paper, we describe our \emph{DataVizard}
system aimed at reducing this overhead by automatically recommending the most
appropriate visual presentation for the structured result. Specifically, we
consider the following two scenarios: first, when one needs to visualize the
results of a structured query such as SQL; and the second, when one has
acquired a data table with an associated short description (e.g., tables from
the Web). Using a corpus of real-world database queries (and their results) and
a number of statistical tables crawled from the Web, we show that DataVizard is
capable of recommending visual presentations with high accuracy. We also
present the results of a user survey that we conducted in order to assess user
views of the suitability of the presented charts vis-a-vis the plain text
captions of the data.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04973</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Robust Variable Step Size Fractional Least Mean Square (RVSS-FLMS)
  Algorithm</dc:title>
 <dc:creator>Khan, Shujaat</dc:creator>
 <dc:creator>Usman, Muhammad</dc:creator>
 <dc:creator>Naseem, Imran</dc:creator>
 <dc:creator>Togneri, Roberto</dc:creator>
 <dc:creator>Bennamoun, Mohammed</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  In this paper, we propose an adaptive framework for the variable step size of
the fractional least mean square (FLMS) algorithm. The proposed algorithm named
the robust variable step size-FLMS (RVSS-FLMS), dynamically updates the step
size of the FLMS to achieve high convergence rate with low steady state error.
For the evaluation purpose, the problem of system identification is considered.
The experiments clearly show that the proposed approach achieves better
convergence rate compared to the FLMS and adaptive step-size modified FLMS
(AMFLMS).
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures, 13th IEEE Colloquium on Signal Processing &amp; its
  Applications (CSPA 2017)</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04973</dc:identifier>
 <dc:identifier>2017 IEEE 13th International Colloquium on Signal Processing &amp; its
  Applications (CSPA), Batu Ferringhi, 2017, pp. 1-6</dc:identifier>
 <dc:identifier>doi:10.1109/CSPA.2017.8064914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04974</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling and Performance Comparison of Privacy Approaches for Location
  Based Services</dc:title>
 <dc:creator>Biswas, Pratima</dc:creator>
 <dc:creator>Sairam, Ashok Singh</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In pervasive computing environment, Location Based Services (LBSs) are
getting popularity among users because of their usefulness in day-to-day life.
LBSs are information services that use geospatial data of mobile device and
smart phone users to provide information, entertainment and security in real
time. A key concern in such pervasive computing environment is the need to
reveal the user's exact location which may allow an adversary to infer private
information about the user. To address the privacy concerns of LBS users, a
large number of security approaches have been proposed based on the concept of
k-anonymity. The central idea in location k-anonymity is to find a set of k-1
users confined in a given geographical area of the actual user, such that the
location of these k users are indistinguishable from one another, thus
protecting the identity of the user. Although a number of performance
parameters like success rate, amount of privacy achieved are used to measure
the performance of the k-anonymity approaches, they make the implicit,
unrealistic assumption that the k-1 users are readily available. As such these
approaches ignore the turnaround time to process a user request, which is
crucial for a real-time application like LBS. In this work, we model the
k-anonymity approaches using queuing theory to compute the average sojourn time
of users and queue length of the system. To demonstrate that queuing theory can
be used to model all k-anonymity approaches, we consider graph-based
k-anonymity approaches. The proposed analytical model is further validated with
experimental results.
</dc:description>
 <dc:description>Comment: 18 pages and 11 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04978</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Online Speed Scaling With Deadline Uncertainty</dc:title>
 <dc:creator>Reddy, Goonwanth</dc:creator>
 <dc:creator>Vaze, Rahul</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A speed scaling problem is considered, where time is divided into slots, and
jobs with payoff $v$ arrive at the beginning of the slot with associated
deadlines $d$. Each job takes one slot to be processed, and multiple jobs can
be processed by the server in each slot with energy cost $g(k)$ for processing
$k$ jobs in one slot. The payoff is accrued by the algorithm only if the job is
processed by its deadline. We consider a robust version of this speed scaling
problem, where a job on its arrival reveals its payoff $v$, however, the
deadline is hidden to the online algorithm, which could potentially be chosen
adversarially and known to the optimal offline algorithm. The objective is to
derive a robust (to deadlines) and optimal online algorithm that achieves the
best competitive ratio. We propose an algorithm (called min-LCR) and show that
it is an optimal online algorithm for any convex energy cost function $g(.)$.
We do so without actually evaluating the optimal competitive ratio, and give a
general proof that works for any convex $g$, which is rather novel. For the
popular choice of energy cost function $g(k) = k^\alpha, \alpha \ge 2$, we give
concrete bounds on the competitive ratio of the algorithm, which ranges between
$2.618$ and $3$ depending on the value of $\alpha$. The best known online
algorithm for the same problem, but where deadlines are revealed to the online
algorithm has competitive ratio of $2$ and a lower bound of $\sqrt{2}$. Thus,
importantly, lack of deadline knowledge does not make the problem degenerate,
and the effect of deadline information on the optimal competitive ratio is
limited.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04978</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04979</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum transport senses community structure in networks</dc:title>
 <dc:creator>Zhao, Chenchao</dc:creator>
 <dc:creator>Song, Jun S.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Condensed Matter - Other Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Quantum time evolution exhibits rich physics, attributable to the interplay
between the density and phase of a wave function. However, unlike classical
heat diffusion, the wave nature of quantum mechanics has not yet been
extensively explored in modern data analysis. We propose that the Laplace
transform of quantum transport (QT) can be used to construct an ensemble of
maps from a given complex network to a circle $S^1$, such that closely-related
nodes on the network are grouped into sharply concentrated clusters on $S^1$.
The resulting QT clustering (QTC) algorithm is as powerful as the
state-of-the-art spectral clustering in discerning complex geometric patterns
and more robust when clusters show strong density variations or heterogeneity
in size. The observed phenomenon of QTC can be interpreted as a collective
behavior of the microscopic nodes that evolve as macroscopic cluster orbitals
in an effective tight-binding model recapitulating the network. Python source
code implementing the algorithm and examples are available at
https://github.com/jssong-lab/QTC.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04981</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SkipFlow: Incorporating Neural Coherence Features for End-to-End
  Automatic Text Scoring</dc:title>
 <dc:creator>Tay, Yi</dc:creator>
 <dc:creator>Phan, Minh C.</dc:creator>
 <dc:creator>Tuan, Luu Anh</dc:creator>
 <dc:creator>Hui, Siu Cheung</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Deep learning has demonstrated tremendous potential for Automatic Text
Scoring (ATS) tasks. In this paper, we describe a new neural architecture that
enhances vanilla neural network models with auxiliary neural coherence
features. Our new method proposes a new \textsc{SkipFlow} mechanism that models
relationships between snapshots of the hidden representations of a long
short-term memory (LSTM) network as it reads. Subsequently, the semantic
relationships between multiple snapshots are used as auxiliary features for
prediction. This has two main benefits. Firstly, essays are typically long
sequences and therefore the memorization capability of the LSTM network may be
insufficient. Implicit access to multiple snapshots can alleviate this problem
by acting as a protection against vanishing gradients. The parameters of the
\textsc{SkipFlow} mechanism also acts as an auxiliary memory. Secondly,
modeling relationships between multiple positions allows our model to learn
features that represent and approximate textual coherence. In our model, we
call this \textit{neural coherence} features. Overall, we present a unified
deep learning architecture that generates neural coherence features as it reads
in an end-to-end fashion. Our approach demonstrates state-of-the-art
performance on the benchmark ASAP dataset, outperforming not only feature
engineering baselines but also other deep learning models.
</dc:description>
 <dc:description>Comment: Accepted to AAAI 2018</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04987</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unified Pragmatic Models for Generating and Following Instructions</dc:title>
 <dc:creator>Fried, Daniel</dc:creator>
 <dc:creator>Andreas, Jacob</dc:creator>
 <dc:creator>Klein, Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We extend models for both following and generating natural language
instructions by adding an explicit pragmatic layer. These pragmatics-enabled
models explicitly reason about why speakers produce certain instructions, and
about how listeners will react upon hearing them. Given learned base listener
and speaker models, we build a pragmatic listener that uses the base speaker to
reason counterfactually about alternative action descriptions, and a pragmatic
speaker that uses the base listener to simulate the interpretation of candidate
instruction sequences. Evaluation of language generation and interpretation in
the SAIL navigation and SCONE instruction following datasets shows that the
pragmatic inference procedure improves state-of-the-art listener models (at
correctly interpreting human instructions) and speaker models (at producing
instructions correctly interpretable by humans) in diverse settings.
</dc:description>
 <dc:description>Comment: Fixed comparison in Table 2</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04988</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concurrent Pump Scheduling and Storage Level Optimization Using
  Meta-Models and Evolutionary Algorithms</dc:title>
 <dc:creator>Behandish, Morad</dc:creator>
 <dc:creator>Wu, Zheng Yi</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In spite of the growing computational power offered by the commodity
hardware, fast pump scheduling of complex water distribution systems is still a
challenge. In this paper, the Artificial Neural Network (ANN) meta-modeling
technique has been employed with a Genetic Algorithm (GA) for simultaneously
optimizing the pump operation and the tank levels at the ends of the cycle. The
generalized GA+ANN algorithm has been tested on a real system in the UK.
Comparing to the existing operation, the daily cost is reduced by about 10-15%,
while the number of pump switches are kept below 4 switches-per-day. In
addition, tank levels are optimized ensure a periodic behavior, which results
in a predictable and stable performance over repeated cycles.
</dc:description>
 <dc:description>Comment: 12th International Conference on Computing and Control for the Water
  Industry (CCWI'2013)</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04988</dc:identifier>
 <dc:identifier>Procedia Engineering, 70, pp.103-112, 2014</dc:identifier>
 <dc:identifier>doi:10.1016/j.proeng.2014.02.013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04992</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature importance scores and lossless feature pruning using Banzhaf
  power indices</dc:title>
 <dc:creator>Kulynych, Bogdan</dc:creator>
 <dc:creator>Troncoso, Carmela</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Understanding the influence of features in machine learning is crucial to
interpreting models and selecting the best features for classification. In this
work we propose the use of principles from coalitional game theory to reason
about importance of features. In particular, we propose the use of the Banzhaf
power index as a measure of influence of features on the outcome of a
classifier. We show that features having Banzhaf power index of zero can be
losslessly pruned without damage to classifier accuracy. Computing the power
indices does not require having access to data samples. However, if samples are
available, the indices can be empirically estimated. We compute Banzhaf power
indices for a neural network classifier on real-life data, and compare the
results with gradient-based feature saliency, and coefficients of a logistic
regression model with $L_1$ regularization.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2017 Symposium on Interpretable Machine Learning</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04993</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistent distributed state estimation with global observability over
  sensor network</dc:title>
 <dc:creator>He, Xingkang</dc:creator>
 <dc:creator>Xue, Wenchao</dc:creator>
 <dc:creator>Fang, Haitao</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper studies the distributed state estimation problem for a class of
discrete time-varying systems over sensor networks. Firstly, it is shown that a
networked Kalman filter with optimal gain parameter is actually a centralized
filter, since it requires each sensor to have global information which is
usually forbidden in large networks. Then, a sub-optimal distributed Kalman
filter (DKF) is proposed by employing the covariance intersection (CI) fusion
strategy. It is proven that the proposed DKF is of consistency, that is, the
upper bound of error covariance matrix can be provided by the filter in real
time. The consistency also enables the design of adaptive CI weights for better
filter precision. Furthermore, the boundedness of covariance matrix and the
convergence of the proposed filter are proven based on the strong connectivity
of directed network topology and the global observability which permits the
sub-system with local sensor's measurements to be unobservable. Meanwhile, to
keep the covariance of the estimation error bounded, the proposed DKF does not
require the system matrix to be nonsingular at each moment, which seems to be a
necessary condition in the main DKF designs under global observability.
Finally, simulation results of two examples show the effectiveness of the
algorithm in the considered scenarios.
</dc:description>
 <dc:description>Comment: 11 pages, 9 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04994</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction Under Uncertainty with Error-Encoding Networks</dc:title>
 <dc:creator>Henaff, Mikael</dc:creator>
 <dc:creator>Zhao, Junbo</dc:creator>
 <dc:creator>LeCun, Yann</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this work we introduce a new framework for performing temporal predictions
in the presence of uncertainty. It is based on a simple idea of disentangling
components of the future state which are predictable from those which are
inherently unpredictable, and encoding the unpredictable components into a
low-dimensional latent variable which is fed into a forward model. Our method
uses a supervised training objective which is fast and easy to train. We
evaluate it in the context of video prediction on multiple datasets and show
that it is able to consistently generate diverse predictions without the need
for alternating minimization over a latent space or adversarial training.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.04994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05010</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Kalman Filters with State Equality Constraints: Time-based
  and Event-triggered Communications</dc:title>
 <dc:creator>He, Xingkang</dc:creator>
 <dc:creator>Hu, Chen</dc:creator>
 <dc:creator>Hong, Yiguang</dc:creator>
 <dc:creator>Shi, Ling</dc:creator>
 <dc:creator>Fang, Haitao</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we investigate a distributed estimation problem for
multi-agent systems with state equality constraints (SECs). We propose a
distributed Kalman filter design based on a covariance intersection approach by
combining a filtering structure and a fusion-projection scheme for time-varying
dynamics, in order to overcome the strong correlation between the estimates of
agents and timely provide an upper bound of the error covariance matrix of each
agent.It is shown that all SECs will be satisfied as the fusion-projection
number goes to infinity. Further, given a finite fusion-projection number, the
SECs will be satisfied as time goes to infinity. Based on the extended
collective observability, we prove the Gaussianity, consistency, upper
boundedness of the covariance matrix and convergence of the proposed
distributed time-based filter, and show how the SEC improves the estimation
performance and relaxes the observability condition. Moreover, to reduce the
communication cost, we propose a distributed event-triggered filter with SECs
for time-invariant dynamics, and provide the Gaussianity, consistency and upper
boundedness of the covariance matrix for the proposed filter under the extended
collective observability. We also show that a smaller triggering threshold
leads to a smaller upper bound of the covariance matrix. Finally, we study the
distributed tracking on a land-based vehicle for illustration. The simulation
results demonstrate the effectiveness of the proposed algorithms.
</dc:description>
 <dc:description>Comment: 16 pages, 11 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05016</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Peg-in-Hole Revisited: A Generic Force Model for Haptic Assembly</dc:title>
 <dc:creator>Behandish, Morad</dc:creator>
 <dc:creator>Ilies, Horea T.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The development of a generic and effective force model for semi-automatic or
manual virtual assembly with haptic support is not a trivial task, especially
when the assembly constraints involve complex features of arbitrary shape. The
primary challenge lies in a proper formulation of the guidance forces and
torques that effectively assist the user in the exploration of the virtual
environment (VE), from repulsing collisions to attracting proper contact. The
secondary difficulty is that of efficient implementation that maintains the
standard 1 kHz haptic refresh rate. We propose a purely geometric model for an
artificial energy field that favors spatial relations leading to proper
assembly, differentiated to obtain forces and torques for general motions. The
energy function is expressed in terms of a cross-correlation of shape-dependent
affinity fields, precomputed offline separately for each object. We test the
effectiveness of the method using familiar peg-in-hole examples. We show that
the proposed technique unifies the two phases of free motion and precise
insertion into a single interaction mode and provides a generic model to
replace the ad hoc mating constraints or virtual fixtures, with no restrictive
assumption on the types of the involved assembly features.
</dc:description>
 <dc:description>Comment: A shorter version was presented in ASME Computers and Information in
  Engineering Conference (CIE'2014) (Best Paper Award)</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05016</dc:identifier>
 <dc:identifier>ASME Transactions, Journal of ASME Transactions, Journal of
  Computing and Information Science in Engineering, 15(4), p.041004, 2015</dc:identifier>
 <dc:identifier>doi:10.1115/1.4030749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05017</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Haptic Assembly Using Skeletal Densities and Fourier Transforms</dc:title>
 <dc:creator>Behandish, Morad</dc:creator>
 <dc:creator>Ilies, Horea T.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Haptic-assisted virtual assembly and prototyping has seen significant
attention over the past two decades. However, in spite of the appealing
prospects, its adoption has been slower than expected. We identify the main
roadblocks as the inherent geometric complexities faced when assembling objects
of arbitrary shape, and the computation time limitation imposed by the
notorious 1 kHz haptic refresh rate. We addressed the first problem in a recent
work by introducing a generic energy model for geometric guidance and
constraints between features of arbitrary shape. In the present work, we
address the second challenge by leveraging Fourier transforms to compute the
constraint forces and torques. Our new concept of 'geometric energy' field is
computed automatically from a cross-correlation of 'skeletal densities' in the
frequency domain, and serves as a generalization of the manually specified
virtual fixtures or heuristically identified mating constraints proposed in the
literature. The formulation of the energy field as a convolution enables
efficient computation using fast Fourier transforms (FFT) on the graphics
processing unit (GPU). We show that our method is effective for low-clearance
assembly of objects of arbitrary geometric and syntactic complexity.
</dc:description>
 <dc:description>Comment: A shorter version was presented in ASME Computers and Information in
  Engineering Conference (CIE'2015) (Best Paper Award)</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05017</dc:identifier>
 <dc:identifier>ASME Transactions, Journal of ASME Transactions, Journal of
  Computing and Information Science in Engineering, 16(2), p.021002, 2016</dc:identifier>
 <dc:identifier>doi:10.1115/1.4032696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05019</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparing Bug Finding Tools with Reviews and Tests</dc:title>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:creator>J&#xfc;rjens, Jan</dc:creator>
 <dc:creator>Koller, Claudia</dc:creator>
 <dc:creator>Trischberger, Peter</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Bug finding tools can find defects in software source code us- ing an
automated static analysis. This automation may be able to reduce the time spent
for other testing and review activities. For this we need to have a clear
understanding of how the defects found by bug finding tools relate to the
defects found by other techniques. This paper describes a case study using
several projects mainly from an industrial environment that were used to
analyse the interrelationships. The main finding is that the bug finding tools
predominantly find different defects than testing but a subset of defects found
by reviews. However, the types that can be detected are analysed more
thoroughly. Therefore, a combination is most advisable if the high number of
false positives of the tools can be tolerated.
</dc:description>
 <dc:description>Comment: 16 pages, 1 figure</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05019</dc:identifier>
 <dc:identifier>Khendek F., Dssouli R. (eds) Testing of Communicating Systems.
  TestCom 2005. Lecture Notes in Computer Science, vol 3502. Springer, Berlin,
  Heidelberg</dc:identifier>
 <dc:identifier>doi:10.1007/11430230_4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05028</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Large Deviation principle for empirical measures of the d-regular
  random graphs</dc:title>
 <dc:creator>Ibrahim, U.</dc:creator>
 <dc:creator>Lotsi, A.</dc:creator>
 <dc:creator>Doku-Amponsah, K.</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>60F10, 05C80</dc:subject>
 <dc:description>  For a $d-$regular random model, we assign to vertices $q-$state spins. From
this model, we define the \emph{empirical co-operate measure}, which enumerates
the number of co-operation between a given couple of spins, and \emph{
empirical spin measure}, which enumerates the number of sites having a given
spin on the $d-$regular random graph model. For these empirical measures we
obtain large deviation principle(LDP) in the weak topology.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05032</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Delay-Distortion Problem</dc:title>
 <dc:creator>Vaze, Rahul</dc:creator>
 <dc:creator>Chaudhari, Shreyas</dc:creator>
 <dc:creator>Choube, Akshat</dc:creator>
 <dc:creator>Aggarwal, Nitin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  An energy-limited source trying to transmit multiple packets to a destination
with possibly different sizes is considered. With limited energy, the source
cannot potentially transmit all bits of all packets. In addition, there is a
delay cost associated with each packet. Thus, the source has to choose, how
many bits to transmit for each packet, and the order in which to transmit these
bits, to minimize the cost of distortion (introduced by transmitting lower
number of bits) and queueing plus transmission delay, across all packets.
Assuming an exponential metric for distortion loss and linear delay cost, we
show that the optimization problem is jointly convex. Hence, the problem can be
exactly solved using convex solvers, however, because of the complicated
expression derived from the KKT conditions, no closed form solution can be
found even with the simplest cost function choice made in the paper, also the
optimal order in which packets should be transmitted needs to be found via
brute force. To facilitate a more structured solution, a discretized version of
the problem is also considered, where time and energy are divided in discrete
amounts. In any time slot (fixed length), bits belonging to any one packet can
be transmitted, while any discrete number of energy quanta can be used in any
slot corresponding to any one packet, such that the total energy constraint is
satisfied. The discretized problem is a special case of a multi-partitioning
problem, where each packet's utility is super-modular and the proposed greedy
solution is shown to incur cost that is at most $2$-times of the optimal cost.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05036</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Publish/subscribe-enabled software defined networking for efficient and
  scalable IoT communications</dc:title>
 <dc:creator>Hakiri, Akram</dc:creator>
 <dc:creator>Berthou, Pascal</dc:creator>
 <dc:creator>Gokhale, Aniruddha</dc:creator>
 <dc:creator>Abdellatif, Slim</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  - The Internet of Things (IoT) is the result of many different enabling
technologies such as embedded systems, wireless sensor networks, cloud
computing, big-data, etc. used to gather, process, infer, and transmit data.
Integrating all these technologies requires a comprehensive and holistic
research effort to address all the challenges imposed by these technologies,
especially for sensing and delivering information from physical world to
cloud-hosted services. In this paper, we outline the most important issues
related to standardization efforts, mobility of objects, networking and gateway
access, and QoS support. In particular, we describe a novel IoT network
architecture that integrates Software Defined Networking (SDN) and the Object
Management Group's Data Distribution Service (DDS) middleware. The proposed
architecture will improve service delivery of IoT system and will bring
flexibility to the network.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05036</dc:identifier>
 <dc:identifier>IEEE Communications Magazine, Institute of Electrical and
  Electronics Engineers, 2015, 53 (9), pp.48 - 54.
  \&amp;\#x3008;10.1109/MCOM.2015.7263372\&amp;\#x3009</dc:identifier>
 <dc:identifier>doi:10.1109/MCOM.2015.7263372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05037</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple-Source Adaptation for Regression Problems</dc:title>
 <dc:creator>Hoffman, Judy</dc:creator>
 <dc:creator>Mohri, Mehryar</dc:creator>
 <dc:creator>Zhang, Ningshan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a detailed theoretical analysis of the problem of multiple-source
adaptation in the general stochastic scenario, extending known results that
assume a single target labeling function. Our results cover a more realistic
scenario and show the existence of a single robust predictor accurate for
\emph{any} target mixture of the source distributions. Moreover, we present an
efficient and practical optimization solution to determine the robust predictor
in the important case of squared loss, by casting the problem as an instance of
DC-programming. We report the results of experiments with both an artificial
task and a sentiment analysis task. We find that our algorithm outperforms
competing approaches by producing a single robust model that performs well on
any target mixture distribution.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05044</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achieve Sustainable Ultra-Dense Heterogeneous Networks for 5G</dc:title>
 <dc:creator>An, Jianping</dc:creator>
 <dc:creator>Yang, Kai</dc:creator>
 <dc:creator>Wu, Jinsong</dc:creator>
 <dc:creator>Ye, Neng</dc:creator>
 <dc:creator>Guo, Song</dc:creator>
 <dc:creator>Liao, Zhifang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Due to the exponentially increased demands of mobile data traffic, e.g., a
1000-fold increase in traffic demand from 4G to 5G, network densification is
considered as a key mechanism in the evolution of cellular networks, and
ultra-dense heterogeneous network (UDHN) is a promising technique to meet the
requirements of explosive data traffic in 5G networks. In the UDHN, base
station is brought closer and closer to users through densely deploying small
cells, which would result in extremely high spectral efficiency and energy
efficiency. In this article, we first present a potential network architecture
for the UDHN, and then propose a generalized orthogonal/non-orthogonal random
access scheme to improve the network efficiency while reducing the signaling
overhead. Simulation results demonstrate the effectiveness of the proposed
scheme. Finally, we present some of the key challenges of the UDHN.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05060</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Principal Projection for Cost-Sensitive Online Multi-Label
  Classification</dc:title>
 <dc:creator>Chu, Hong-Min</dc:creator>
 <dc:creator>Huang, Kuan-Hao</dc:creator>
 <dc:creator>Lin, Hsuan-Tien</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study multi-label classification (MLC) with three important real-world
issues: online updating, label space dimensional reduction (LSDR), and
cost-sensitivity. Current MLC algorithms have not been designed to address
these three issues simultaneously. In this paper, we propose a novel algorithm,
cost-sensitive dynamic principal projection (CS-DPP) that resolves all three
issues. The foundation of CS-DPP is an online LSDR framework derived from a
leading LSDR algorithm. In particular, CS-DPP is equipped with an efficient
online dimension reducer motivated by matrix stochastic gradient, and
establishes its theoretical backbone when coupled with a carefully-designed
online regression learner. In addition, CS-DPP embeds the cost information into
label weights to achieve cost-sensitivity along with theoretical guarantees.
Experimental results verify that CS-DPP achieves better practical performance
than current MLC algorithms across different evaluation criteria, and
demonstrate the importance of resolving the three issues simultaneously.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05065</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Influence of a range of interaction among agents on efficiency and
  effectiveness of knowledge transfer within an organisation</dc:title>
 <dc:creator>Paradowski, Kamil</dc:creator>
 <dc:creator>Kowalska-Stycze&#x144;, Agnieszka</dc:creator>
 <dc:creator>Malarz, Krzysztof</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:description>  In this study we examined how the size of non-formal groups between
organization members affect the transfer of knowledge in the context of the
efficiency and effectiveness of this process. To analyse the dynamics of the
transfer of knowledge the cellular automata model was used. The model is based
on local interactions between members of the organization, that take place in
the nearest neighbourhood. These groups of close neighbours are represented by
von Neumann's neighbourhood (four nearest-neighbours) and Moore's neighbourhood
(four nearest-neighbours and four next-nearest neighbours) and complex
neighbourhood (four nearest neighbours, four next-nearest neighbours and four
next-next-neighbours). The results of the simulation show the influence of the
size of the neighbourhood on the efficiency of knowledge transfer.
</dc:description>
 <dc:description>Comment: presented during 13th Econophysics Colloquium &amp; 9th Polish Symposium
  on Physics in Economy and Social Sciences, Jul. 5-7, 2017, Warszawa (PL)</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05066</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning an Executable Neural Semantic Parser</dc:title>
 <dc:creator>Cheng, Jianpeng</dc:creator>
 <dc:creator>Reddy, Siva</dc:creator>
 <dc:creator>Saraswat, Vijay</dc:creator>
 <dc:creator>Lapata, Mirella</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper describes a neural semantic parser that maps natural language
utterances onto logical forms which can be executed against a task-specific
environment, such as a knowledge base or a database, to produce a response. The
parser generates tree-structured logical forms with a transition-based approach
which combines a generic tree-generation algorithm with domain-general
operations defined by the logical language. The generation process is modeled
by structured recurrent neural networks, which provide a rich encoding of the
sentential context and generation history for making predictions. To tackle
mismatches between natural language and logical form tokens, various attention
mechanisms are explored. Finally, we consider different training settings for
the neural semantic parser, including a fully supervised training where
annotated logical forms are given, weakly-supervised training where denotations
are provided, and distant supervision where only unlabeled sentences and a
knowledge base are available. Experiments across a wide range of datasets
demonstrate the effectiveness of our parser.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05068</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Matrix Elastic Net based Canonical Correlation Analysis: An
  Effective Algorithm for Multi-View Unsupervised Learning</dc:title>
 <dc:creator>Zhang, Peng-Bo</dc:creator>
 <dc:creator>Yang, Zhi-Xin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents a robust matrix elastic net based canonical correlation
analysis (RMEN-CCA) for multiple view unsupervised learning problems, which
emphasizes the combination of CCA and the robust matrix elastic net (RMEN) used
as coupled feature selection. The RMEN-CCA leverages the strength of the RMEN
to distill naturally meaningful features without any prior assumption and to
measure effectively correlations between different 'views'. We can further
employ directly the kernel trick to extend the RMEN-CCA to the kernel scenario
with theoretical guarantees, which takes advantage of the kernel trick for
highly complicated nonlinear feature learning. Rather than simply incorporating
existing regularization minimization terms into CCA, this paper provides a new
learning paradigm for CCA and is the first to derive a coupled feature
selection based CCA algorithm that guarantees convergence. More significantly,
for CCA, the newly-derived RMEN-CCA bridges the gap between measurement of
relevance and coupled feature selection. Moreover, it is nontrivial to tackle
directly the RMEN-CCA by previous optimization approaches derived from its
sophisticated model architecture. Therefore, this paper further offers a bridge
between a new optimization problem and an existing efficient iterative
approach. As a consequence, the RMEN-CCA can overcome the limitation of CCA and
address large-scale and streaming data problems. Experimental results on four
popular competing datasets illustrate that the RMEN-CCA performs more
effectively and efficiently than do state-of-the-art approaches.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05073</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DuReader: a Chinese Machine Reading Comprehension Dataset from
  Real-world Applications</dc:title>
 <dc:creator>He, Wei</dc:creator>
 <dc:creator>Liu, Kai</dc:creator>
 <dc:creator>Lyu, Yajuan</dc:creator>
 <dc:creator>Zhao, Shiqi</dc:creator>
 <dc:creator>Xiao, Xinyan</dc:creator>
 <dc:creator>Liu, Yuan</dc:creator>
 <dc:creator>Wang, Yizhong</dc:creator>
 <dc:creator>Wu, Hua</dc:creator>
 <dc:creator>She, Qiaoqiao</dc:creator>
 <dc:creator>Liu, Xuan</dc:creator>
 <dc:creator>Wu, Tian</dc:creator>
 <dc:creator>Wang, Haifeng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we introduce DuReader, a new large-scale, open-domain Chinese
machine reading comprehension (MRC) dataset, aiming to tackle real-world MRC
problems. In comparison to prior datasets, DuReader has the following
characteristics: (a) the questions and the documents are all extracted from
real application data, and the answers are human generated; (b) it provides
rich annotations for question types, especially yes-no and opinion questions,
which take a large proportion in real users' questions but have not been well
studied before; (c) it provides multiple answers for each question. The first
release of DuReader contains 200k questions, 1,000k documents, and 420k
answers, which, to the best of our knowledge, is the largest Chinese MRC
dataset so far. Experimental results show there exists big gap between the
state-of-the-art baseline systems and human performance, which indicates
DuReader is a challenging dataset that deserves future study. The dataset and
the code of the baseline systems are publicly available now.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05074</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symmetric Decomposition of Asymmetric Games</dc:title>
 <dc:creator>Tuyls, Karl</dc:creator>
 <dc:creator>Perolat, Julien</dc:creator>
 <dc:creator>Lanctot, Marc</dc:creator>
 <dc:creator>Ostrovski, Georg</dc:creator>
 <dc:creator>Savani, Rahul</dc:creator>
 <dc:creator>Leibo, Joel</dc:creator>
 <dc:creator>Ord, Toby</dc:creator>
 <dc:creator>Graepel, Thore</dc:creator>
 <dc:creator>Legg, Shane</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  We introduce new theoretical insights into two-population asymmetric games
allowing for an elegant symmetric decomposition into two single population
symmetric games. Specifically, we show how an asymmetric bimatrix game (A,B)
can be decomposed into its symmetric counterparts by envisioning and
investigating the payoff tables (A and B) that constitute the asymmetric game,
as two independent, single population, symmetric games. We reveal several
surprising formal relationships between an asymmetric two-population game and
its symmetric single population counterparts, which facilitate a convenient
analysis of the original asymmetric game due to the dimensionality reduction of
the decomposition. The main finding reveals that if (x,y) is a Nash equilibrium
of an asymmetric game (A,B), this implies that y is a Nash equilibrium of the
symmetric counterpart game determined by payoff table A, and x is a Nash
equilibrium of the symmetric counterpart game determined by payoff table B.
Also the reverse holds and combinations of Nash equilibria of the counterpart
games form Nash equilibria of the asymmetric game. We illustrate how these
formal relationships aid in identifying and analysing the Nash structure of
asymmetric games, by examining the evolutionary dynamics of the simpler
counterpart games in several canonical examples.
</dc:description>
 <dc:description>Comment: Paper is published in Scientific Reports;
  https://www.nature.com/articles/s41598-018-19194-4, 2018</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05075</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytic Methods for Geometric Modeling via Spherical Decomposition</dc:title>
 <dc:creator>Behandish, Morad</dc:creator>
 <dc:creator>Ilies, Horea T.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Analytic methods are emerging in solid and configuration modeling, while
providing new insights into a variety of shape and motion related problems by
exploiting tools from group morphology, convolution algebras, and harmonic
analysis. However, most convolution-based methods have used uniform grid-based
sampling to take advantage of the fast Fourier transform (FFT) algorithm. We
propose a new paradigm for more efficient computation of analytic correlations
that relies on a grid-free discretization of arbitrary shapes as countable
unions of balls, in turn described as sublevel sets of summations of smooth
radial kernels at adaptively sampled 'knots'. Using a simple geometric lifting
trick, we interpret this combination as a convolution of an impulsive skeletal
density and primitive kernels with conical support, which faithfully embeds
into the convolution formulation of interactions across different objects. Our
approach enables fusion of search-efficient combinatorial data structures
prevalent in time-critical collision and proximity queries with analytic
methods popular in path planning and protein docking, and outperforms uniform
grid-based FFT methods by leveraging nonequispaced FFTs. We provide example
applications in formulating holonomic collision constraints, shape
complementarity metrics, and morphological operations, unified within a single
analytic framework.
</dc:description>
 <dc:description>Comment: Special Issue on SIAM/ACM symposium on Solid and Physical Modeling
  (SPM'2015) (Best Paper Award, 2nd Place)</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05075</dc:identifier>
 <dc:identifier>Journal of Computer-Aided Design, 70, pp.100-115, 2016</dc:identifier>
 <dc:identifier>doi:10.1016/j.cad.2015.06.016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05076</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The return to higher education: evidence from Romania</dc:title>
 <dc:creator>Oancea, Bogdan</dc:creator>
 <dc:creator>Pospisil, Richard</dc:creator>
 <dc:creator>Dragoescu, Raluca Mariana</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Education is one of the most important components of the human capital, and
an important determinant of the personal income. Estimating the rate of return
to education is a main topic of economic research. In this paper we analyzed
the rate of return to higher education in Romania using the well-known Mincer
equation. Besides the educational level and the number of years of experience
on the labor market we also used a series of socio-demographic variables such
as gender, civil status, the area of residence. We were interested mainly in
calculating the rate of return to higher education, therefore we computed this
rate for bachelor, master and doctoral degrees separately. We also investigated
the rate of return to higher education on technical, science, economics, law,
medicine, and arts fields. Our results showed that the rate of return to higher
education has a greater value than most of the developed countries of EU and
the field of higher education that brings the highest rate of return is
medicine
</dc:description>
 <dc:description>Comment: Proceedings of the Knowledge for Market Use Conference, 6-7
  September, 2017</dc:description>
 <dc:date>2017-09-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05078</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A unified decision making framework for supply and demand management in
  microgrid networks</dc:title>
 <dc:creator>Diddigi, Raghuram Bharadwaj</dc:creator>
 <dc:creator>Danda, Sai Koti Reddy</dc:creator>
 <dc:creator>Narayanam, Krishnasuri</dc:creator>
 <dc:creator>Bhatnagar, Shalabh</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper considers two important problems - on the supply-side and
demand-side respectively and studies both in a unified framework. On the supply
side, we study the problem of energy sharing among microgrids with the goal of
maximizing profit obtained from selling power while meeting customer demand. On
the other hand, under shortage of power, this problem becomes one of deciding
the amount of power to be bought with dynamically varying prices. On the demand
side, we consider the problem of optimally scheduling the time-adjustable
demand - i.e., of loads with flexible time windows in which they can be
scheduled. While previous works have treated these two problems in isolation,
we combine these problems together and provide for the first time in the
literature, a unified Markov decision process (MDP) framework for these
problems. We then apply the Q-learning algorithm, a popular model-free
reinforcement learning technique, to obtain the optimal policy. Through
simulations, we show that our model outperforms the traditional power sharing
models.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05082</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparative Case Study on the Impact of Test-Driven Development on
  Program Design and Test Coverage</dc:title>
 <dc:creator>Siniaalto, Maria</dc:creator>
 <dc:creator>Abrahamsson, Pekka</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Test-driven development (TDD) is a programming technique in which the tests
are written prior to the source code. It is proposed that TDD is one of the
most fundamental practices enabling the development of software in an agile and
iterative manner. Both the literature and practice suggest that TDD practice
yields several benefits. Essentially, it is claimed that TDD leads to an
improved software design, which has a dramatic impact on the maintainability
and further development of the system. The impact of TDD on program design has
seldom come under the researchers' focus. This paper reports the results from a
comparative case study of three software development projects where the effect
of TDD on program design was measured using object-oriented metrics. The
results show that the effect of TDD on program design was not as evident as
expected, but the test coverage was significantly superior to iterative
test-last development.
</dc:description>
 <dc:description>Comment: This is author's version of the published paper. The copyright
  holder's version is accessible at
  http://ieeexplore.ieee.org/abstract/document/4343755/</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05082</dc:identifier>
 <dc:identifier>Empirical Software Engineering and Measurement, 2007. ESEM 2007.
  First International Symposium on (pp. 275-284). IEEE</dc:identifier>
 <dc:identifier>doi:10.1109/ESEM.2007.35</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05084</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TripletGAN: Training Generative Model with Triplet Loss</dc:title>
 <dc:creator>Cao, Gongze</dc:creator>
 <dc:creator>Yang, Yezhou</dc:creator>
 <dc:creator>Lei, Jie</dc:creator>
 <dc:creator>Jin, Cheng</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Song, Mingli</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  As an effective way of metric learning, triplet loss has been widely used in
many deep learning tasks, including face recognition and person-ReID, leading
to many states of the arts. The main innovation of triplet loss is using
feature map to replace softmax in the classification task. Inspired by this
concept, we propose here a new adversarial modeling method by substituting the
classification loss of discriminator with triplet loss. Theoretical proof based
on IPM (Integral probability metric) demonstrates that such setting will help
the generator converge to the given distribution theoretically under some
conditions. Moreover, since triplet loss requires the generator to maximize
distance within a class, we justify tripletGAN is also helpful to prevent mode
collapse through both theory and experiment.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05088</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of Machine Learning for Channel based Message Authentication
  in Mission Critical Machine Type Communication</dc:title>
 <dc:creator>Weinand, Andreas</dc:creator>
 <dc:creator>Karrenbauer, Michael</dc:creator>
 <dc:creator>Sattiraju, Raja</dc:creator>
 <dc:creator>Schotten, Hans D.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  The design of robust wireless communication systems for industrial
applications such as closed loop control processes has been considered manifold
recently. Additionally, the ongoing advances in the area of connected mobility
have similar or even higher requirements regarding system reliability and
availability. Beside unfulfilled reliability requirements, the availability of
a system can further be reduced, if it is under attack in the sense of
violation of information security goals such as data authenticity or integrity.
In order to guarantee the safe operation of an application, a system has at
least to be able to detect these attacks. Though there are numerous techniques
in the sense of conventional cryptography in order to achieve that goal, these
are not always suited for the requirements of the applications mentioned due to
resource inefficiency. In the present work, we show how the goal of message
authenticity based on physical layer security (PHYSEC) can be achieved. The
main idea for such techniques is to exploit user specific characteristics of
the wireless channel, especially in spatial domain. Additionally, we show the
performance of our machine learning based approach and compare it with other
existing approaches.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05090</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficiency Analysis of ASP Encodings for Sequential Pattern Mining Tasks</dc:title>
 <dc:creator>Guyet, Thomas</dc:creator>
 <dc:creator>Moinard, Yves</dc:creator>
 <dc:creator>Quiniou, Ren&#xe9;</dc:creator>
 <dc:creator>Schaub, Torsten</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This article presents the use of Answer Set Programming (ASP) to mine
sequential patterns. ASP is a high-level declarative logic programming paradigm
for high level encoding combinatorial and optimization problem solving as well
as knowledge representation and reasoning. Thus, ASP is a good candidate for
implementing pattern mining with background knowledge, which has been a data
mining issue for a long time. We propose encodings of the classical sequential
pattern mining tasks within two representations of embeddings (fill-gaps vs
skip-gaps) and for various kinds of patterns: frequent, constrained and
condensed. We compare the computational performance of these encodings with
each other to get a good insight into the efficiency of ASP encodings. The
results show that the fill-gaps strategy is better on real problems due to
lower memory consumption. Finally, compared to a constraint programming
approach (CPSM), another declarative programming paradigm, our proposal showed
comparable performance.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05090</dc:identifier>
 <dc:identifier>Bruno Pinaud; Fabrice Guillet; Bruno Cremilleux; Cyril de Runz.
  Advances in Knowledge Discovery and Management, 7, Springer, pp.41--81, 2017,
  978-3-319-65405-8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05091</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequences of radius $k$ for complete bipartite graphs</dc:title>
 <dc:creator>D&#x119;bski, Micha&#x142;</dc:creator>
 <dc:creator>Lonc, Zbigniew</dc:creator>
 <dc:creator>Rz&#x105;&#x17c;ewski, Pawe&#x142;</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A \emph{$k$-radius sequence} for a graph $G$ is a sequence of vertices of $G$
(typically with repetitions) such that for every edge $uv$ of $G$ vertices $u$
and $v$ appear at least once within distance $k$ in the sequence. The length of
a shortest $k$-radius sequence for $G$ is denoted by $f_k(G)$. We give an
asymptotically tight estimation on $f_k(G)$ for complete bipartite graphs
{which matches a lower bound, valid for all bipartite graphs}. We also show
that determining $f_k(G)$ for an arbitrary graph $G$ is NP-hard for every
constant $k&gt;1$.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05091</dc:identifier>
 <dc:identifier>Discrete Applied Mathematics 225, pp. 51--63. 2017</dc:identifier>
 <dc:identifier>doi:10.1016/j.dam.2017.03.017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05092</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How long is a piece of string? An exploration of multi-winner approval
  voting and ballot-length restrictions</dc:title>
 <dc:creator>Lee, Barton E.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Multi-winner approval elections are seen in a variety of settings ranging
from academic societies and associations to public elections. In such
elections, it is often the case that ballot-length restrictions are enforced;
that is, where voters have a limit on the number of candidates which they can
vote for. Despite this common feature, there does not seem to be any
theoretical justification for ballot-length restrictions (Laslier and Van der
Straeten, 2016).
  This work endogenously derives the set of voter best-response ballot lengths
under complete information and with general assumptions on voter utilities and
voting rules. These results provide justification for some ballot-length
restrictions observed in practice, however when considering equilibrium
outcomes our analysis shows that this justification is no longer valid.
Equilibrium analysis is considered for voters with lazy and truth-bias
second-order tendencies and the equilibrium solution concept is pure-Nash
equilibria.
  The key insights show that ballot-length restrictions or institutional
features which make voting costly may lead to instability in election outcomes
when voters have diverse preferences, via the non-existence of equilibria. On
the other hand, when equilibria do exist they satisfy desirable properties
which are not guaranteed by equilibria attained under costless voting and in
the absence of ballot-length restrictions. In summary our results highlight a
stark trade-off between stable and desirable election outcomes.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05096</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On edge intersection graphs of paths with 2 bends</dc:title>
 <dc:creator>Pergel, Martin</dc:creator>
 <dc:creator>Rz&#x105;&#x17c;ewski, Pawe&#x142;</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  An EPG-representation of a graph $G$ is a collection of paths in a plane
square grid, each corresponding to a single vertex of $G$, so that two vertices
are adjacent if and only if their corresponding paths share infinitely many
points. In this paper we focus on graphs admitting EPG-representations by paths
with at most 2 bends. We show hardness of the recognition problem for this
class of graphs, along with some subclasses.
  We also initiate the study of graphs representable by unaligned polylines,
and by polylines, whose every segment is parallel to one of prescribed slopes.
We show hardness of recognition and explore the trade-off between the number of
bends and the number of slopes.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05096</dc:identifier>
 <dc:identifier>Discrete Applied Mathematics 226, pp. 106--116. 2017</dc:identifier>
 <dc:identifier>doi:10.1016/j.dam.2017.04.023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05098</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Web Robot Detection in Academic Publishing</dc:title>
 <dc:creator>Lagopoulos, Athanasios</dc:creator>
 <dc:creator>Tsoumakas, Grigorios</dc:creator>
 <dc:creator>Papadopoulos, Georgios</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Recent industry reports assure the rise of web robots which comprise more
than half of the total web traffic. They not only threaten the security,
privacy and efficiency of the web but they also distort analytics and metrics,
doubting the veracity of the information being promoted. In the academic
publishing domain, this can cause articles to be faulty presented as prominent
and influential. In this paper, we present our approach on detecting web robots
in academic publishing websites. We use different supervised learning
algorithms with a variety of characteristics deriving from both the log files
of the server and the content served by the website. Our approach relies on the
assumption that human users will be interested in specific domains or articles,
while web robots crawl a web library incoherently. We experiment with features
adopted in previous studies with the addition of novel semantic characteristics
which derive after performing a semantic analysis using the Latent Dirichlet
Allocation (LDA) algorithm. Our real-world case study shows promising results,
pinpointing the significance of semantic features in the web robot detection
problem.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05099</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overcoming data scarcity with transfer learning</dc:title>
 <dc:creator>Hutchinson, Maxwell L.</dc:creator>
 <dc:creator>Antono, Erin</dc:creator>
 <dc:creator>Gibbons, Brenna M.</dc:creator>
 <dc:creator>Paradiso, Sean</dc:creator>
 <dc:creator>Ling, Julia</dc:creator>
 <dc:creator>Meredig, Bryce</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Despite increasing focus on data publication and discovery in materials
science and related fields, the global view of materials data is highly sparse.
This sparsity encourages training models on the union of multiple datasets, but
simple unions can prove problematic as (ostensibly) equivalent properties may
be measured or computed differently depending on the data source. These hidden
contextual differences introduce irreducible errors into analyses,
fundamentally limiting their accuracy. Transfer learning, where information
from one dataset is used to inform a model on another, can be an effective tool
for bridging sparse data while preserving the contextual differences in the
underlying measurements. Here, we describe and compare three techniques for
transfer learning: multi-task, difference, and explicit latent variable
architectures. We show that difference architectures are most accurate in the
multi-fidelity case of mixed DFT and experimental band gaps, while multi-task
most improves classification performance of color with band gaps. For
activation energies of steps in NO reduction, the explicit latent variable
method is not only the most accurate, but also enjoys cancellation of errors in
functions that depend on multiple tasks. These results motivate the publication
of high quality materials datasets that encode transferable information,
independent of industrial or academic interest in the particular labels, and
encourage further development and application of transfer learning methods to
materials informatics problems.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05101</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fixing Weight Decay Regularization in Adam</dc:title>
 <dc:creator>Loshchilov, Ilya</dc:creator>
 <dc:creator>Hutter, Frank</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We note that common implementations of adaptive gradient algorithms, such as
Adam, limit the potential benefit of weight decay regularization, because the
weights do not decay multiplicatively (as would be expected for standard weight
decay) but by an additive constant factor. We propose a simple way to resolve
this issue by decoupling weight decay and the optimization steps taken w.r.t.
the loss function. We provide empirical evidence that our proposed modification
(i) decouples the optimal choice of weight decay factor from the setting of the
learning rate for both standard SGD and Adam, and (ii) substantially improves
Adam's generalization performance, allowing it to compete with SGD with
momentum on image classification datasets (on which it was previously typically
outperformed by the latter). We also demonstrate that longer optimization runs
require smaller weight decay values for optimal results and introduce a
normalized variant of weight decay to reduce this dependence. Finally, we
propose a version of Adam with warm restarts (AdamWR) that has strong anytime
performance while achieving state-of-the-art results on CIFAR-10 and
ImageNet32x32. Our source code is available at
https://github.com/loshchil/AdamW-and-SGDW
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05102</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Multi-layer Information Bottleneck Problem</dc:title>
 <dc:creator>Yang, Qianqian</dc:creator>
 <dc:creator>Piantanida, Pablo</dc:creator>
 <dc:creator>G&#xfc;nd&#xfc;z, Deniz</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The muti-layer information bottleneck (IB) problem, where information is
propagated (or successively refined) from layer to layer, is considered. Based
on information forwarded by the preceding layer, each stage of the network is
required to preserve a certain level of relevance with regards to a specific
hidden variable, quantified by the mutual information. The hidden variables and
the source can be arbitrarily correlated. The optimal trade-off between rates
of relevance and compression (or complexity) is obtained through a
single-letter characterization, referred to as the rate-relevance region.
Conditions of successive refinabilty are given. Binary source with BSC hidden
variables and binary source with BSC/BEC mixed hidden variables are both proved
to be successively refinable. We further extend our result to Guassian models.
A counterexample of successive refinability is also provided.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05104</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An optimized shape descriptor based on structural properties of networks</dc:title>
 <dc:creator>Miranda, Gisele H. B.</dc:creator>
 <dc:creator>Machicao, Jeaneth</dc:creator>
 <dc:creator>Bruno, Odemir M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  The structural analysis of shape boundaries leads to the characterization of
objects as well as to the understanding of shape properties. The literature on
graphs and networks have contributed to the structural characterization of
shapes with different theoretical approaches. We performed a study on the
relationship between the shape architecture and the network topology
constructed over the shape boundary. For that, we used a method for network
modeling proposed in 2009. Firstly, together with curvature analysis, we
evaluated the proposed approach for regular polygons. This way, it was possible
to investigate how the network measurements vary according to some specific
shape properties. Secondly, we evaluated the performance of the proposed shape
descriptor in classification tasks for three datasets, accounting for both
real-world and synthetic shapes. We demonstrated that not only degree related
measurements are capable of distinguishing classes of objects. Yet, when using
measurements that account for distinct properties of the network structure, the
construction of the shape descriptor becomes more computationally efficient.
Given the fact the network is dynamically constructed, the number of iterations
can be reduced. The proposed approach accounts for a more robust set of
structural measurements, that improved the discriminant power of the shape
descriptors.
</dc:description>
 <dc:description>Comment: 19 pages, 13 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05105</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Study of the Effects of Spurious Transitions on
  Abstraction-based Heuristics</dc:title>
 <dc:creator>Sadeqi, Mehdi</dc:creator>
 <dc:creator>Holte, Robert C.</dc:creator>
 <dc:creator>Zilles, Sandra</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The efficient solution of state space search problems is often attempted by
guiding search algorithms with heuristics (estimates of the distance from any
state to the goal). A popular way for creating heuristic functions is by using
an abstract version of the state space. However, the quality of
abstraction-based heuristic functions, and thus the speed of search, can suffer
from spurious transitions, i.e., state transitions in the abstract state space
for which no corresponding transitions in the reachable component of the
original state space exist. Our first contribution is a quantitative study
demonstrating that the harmful effects of spurious transitions on heuristic
functions can be substantial, in terms of both the increase in the number of
abstract states and the decrease in the heuristic values, which may slow down
search. Our second contribution is an empirical study on the benefits of
removing a certain kind of spurious transition, namely those that involve
states with a pair of mutually exclusive (mutex) variablevalue assignments. In
the context of state space planning, a mutex pair is a pair of variable-value
assignments that does not occur in any reachable state. Detecting mutex pairs
is a problem that has been addressed frequently in the planning literature. Our
study shows that there are cases in which mutex detection helps to eliminate
harmful spurious transitions to a large extent and thus to speed up search
substantially.
</dc:description>
 <dc:description>Comment: 38 pages, 9 figures, appendix with 5 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05114</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hierarchical Contextual Attention-based GRU Network for Sequential
  Recommendation</dc:title>
 <dc:creator>Cui, Qiang</dc:creator>
 <dc:creator>Wu, Shu</dc:creator>
 <dc:creator>Huang, Yan</dc:creator>
 <dc:creator>Wang, Liang</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Sequential recommendation is one of fundamental tasks for Web applications.
Previous methods are mostly based on Markov chains with a strong Markov
assumption. Recently, recurrent neural networks (RNNs) are getting more and
more popular and has demonstrated its effectiveness in many tasks. The last
hidden state is usually applied as the sequence's representation to make
recommendation. Benefit from the natural characteristics of RNN, the hidden
state is a combination of long-term dependency and short-term interest to some
degrees. However, the monotonic temporal dependency of RNN impairs the user's
short-term interest. Consequently, the hidden state is not sufficient to
reflect the user's final interest. In this work, to deal with this problem, we
propose a Hierarchical Contextual Attention-based GRU (HCA-GRU) network. The
first level of HCA-GRU is conducted on the input. We construct a contextual
input by using several recent inputs based on the attention mechanism. This can
model the complicated correlations among recent items and strengthen the hidden
state. The second level is executed on the hidden state. We fuse the current
hidden state and a contextual hidden state built by the attention mechanism,
which leads to a more suitable user's overall interest. Experiments on two
real-world datasets show that HCA-GRU can effectively generate the personalized
ranking list and achieve significant improvement.
</dc:description>
 <dc:description>Comment: I will upload a new version of a new task later</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05116</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evidence Aggregation for Answer Re-Ranking in Open-Domain Question
  Answering</dc:title>
 <dc:creator>Wang, Shuohang</dc:creator>
 <dc:creator>Yu, Mo</dc:creator>
 <dc:creator>Jiang, Jing</dc:creator>
 <dc:creator>Zhang, Wei</dc:creator>
 <dc:creator>Guo, Xiaoxiao</dc:creator>
 <dc:creator>Chang, Shiyu</dc:creator>
 <dc:creator>Wang, Zhiguo</dc:creator>
 <dc:creator>Klinger, Tim</dc:creator>
 <dc:creator>Tesauro, Gerald</dc:creator>
 <dc:creator>Campbell, Murray</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A popular recent approach to answering open-domain questions is to first
search for question-related passages and then apply reading comprehension
models to extract answers. Existing methods usually extract answers from single
passages independently. But some questions require a combination of evidence
from across different sources to answer correctly. In this paper, we propose
two models which make use of multiple passages to generate their answers. Both
use an answer-reranking approach which reorders the answer candidates generated
by an existing state-of-the-art QA model. We propose two methods, namely,
strength-based re-ranking and coverage-based re-ranking, to make use of the
aggregated evidence from different passages to better determine the answer. Our
models have achieved state-of-the-art results on three public open-domain QA
datasets: Quasar-T, SearchQA and the open-domain version of TriviaQA, with
about 8 percentage points of improvement over the former two datasets.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05128</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grab, Pay and Eat: Semantic Food Detection for Smart Restaurants</dc:title>
 <dc:creator>Aguilar, Eduardo</dc:creator>
 <dc:creator>Remeseiro, Beatriz</dc:creator>
 <dc:creator>Bola&#xf1;os, Marc</dc:creator>
 <dc:creator>Radeva, Petia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The increase in awareness of people towards their nutritional habits has
drawn considerable attention to the field of automatic food analysis. Focusing
on self-service restaurants environment, automatic food analysis is not only
useful for extracting nutritional information from foods selected by customers,
it is also of high interest to speed up the service solving the bottleneck
produced at the cashiers in times of high demand. In this paper, we address the
problem of automatic food tray analysis in canteens and restaurants
environment, which consists in predicting multiple foods placed on a tray
image. We propose a new approach for food analysis based on convolutional
neural networks, we name Semantic Food Detection, which integrates in the same
framework food localization, recognition and segmentation. We demonstrate that
our method improves the state of the art food detection by a considerable
margin on the public dataset UNIMIB2016 achieving about 90% in terms of
F-measure, and thus provides a significant technological advance towards the
automatic billing in restaurant environments.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05133</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning in a large scale photonic Recurrent Neural
  Network</dc:title>
 <dc:creator>Bueno, Julian</dc:creator>
 <dc:creator>Maktoobi, Sheler</dc:creator>
 <dc:creator>Froehly, Luc</dc:creator>
 <dc:creator>Fischer, Ingo</dc:creator>
 <dc:creator>Jacquot, Maxime</dc:creator>
 <dc:creator>Larger, Laurent</dc:creator>
 <dc:creator>Brunner, Daniel</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  Photonic Neural Network implementations have been gaining considerable
attention as a potentially disruptive future technology. Demonstrating learning
in large scale neural networks is essential to establish photonic machine
learning substrates as viable information processing systems. Realizing
photonic Neural Networks with numerous nonlinear nodes in a fully parallel and
efficient learning hardware was lacking so far. We demonstrate a network of up
to 2500 diffractively coupled photonic nodes, forming a large scale Recurrent
Neural Network. Using a Digital Micro Mirror Device, we realize reinforcement
learning. Our scheme is fully parallel, and the passive weights maximize energy
efficiency and bandwidth. The computational output efficiently converges and we
achieve very good performance.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05135</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Similarity-Aware Spectral Sparsification by Edge Filtering</dc:title>
 <dc:creator>Feng, Zhuo</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In recent years, spectral graph sparsification techniques that can compute
ultra-sparse graph proxies have been extensively studied for accelerating
various numerical and graph-related applications. Prior nearly-linear-time
spectral sparsification methods first extract low-stretch spanning tree of the
original graph to form the backbone of the sparsifier, and then recover small
portions of spectrally-critical off-tree edges to the spanning to significantly
improve the approximation quality. However, it is not clear how many off-tree
edges should be recovered for achieving a desired spectral similarity level
within the sparsifier. Motivated by recent graph signal processing techniques,
this paper proposes a similarity-aware spectral graph sparsification framework
that leverages an efficient off-tree edge filtering scheme to construct
spectral sparsifiers with guaranteed spectral similarity (relative condition
number) level. An iterative graph densification framework and a generalized
eigenvalue stability checking scheme are introduced to facilitate efficient and
effective filtering of off-tree edges even for highly ill-conditioned problems.
The proposed method has been validated using various kinds of graphs obtained
from public domain sparse matrix collections relevant to VLSI CAD, finite
element analysis, as well as social and data networks frequently studied in
many machine learning and data mining applications.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05136</identifier>
 <datestamp>2017-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Rewiring: Training very sparse deep networks</dc:title>
 <dc:creator>Bellec, Guillaume</dc:creator>
 <dc:creator>Kappel, David</dc:creator>
 <dc:creator>Maass, Wolfgang</dc:creator>
 <dc:creator>Legenstein, Robert</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neuromorphic hardware tends to pose limits on the connectivity of deep
networks that one can run on them. But also generic hardware and software
implementations of deep learning run more efficiently on sparse networks.
Several methods exist for pruning connections of a neural network after it was
trained without connectivity constraints. We present an algorithm, DEEP R, that
enables us to train directly a sparsely connected neural network. DEEP R
automatically rewires the network during supervised training so that
connections are there where they are most needed for the task, while its total
number is all the time strictly bounded. We demonstrate that DEEP R can be used
to train very sparse feedforward and recurrent neural networks on standard
benchmark tasks with just a minor loss in performance. DEEP R is based on a
rigorous theoretical foundation that views rewiring as stochastic sampling of
network configurations from a posterior.
</dc:description>
 <dc:description>Comment: 10 pages (12 with references, 24 with appendix), 4 Figures in the
  main text</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05139</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>XGAN: Unsupervised Image-to-Image Translation for Many-to-Many Mappings</dc:title>
 <dc:creator>Royer, Am&#xe9;lie</dc:creator>
 <dc:creator>Bousmalis, Konstantinos</dc:creator>
 <dc:creator>Gouws, Stephan</dc:creator>
 <dc:creator>Bertsch, Fred</dc:creator>
 <dc:creator>Mosseri, Inbar</dc:creator>
 <dc:creator>Cole, Forrester</dc:creator>
 <dc:creator>Murphy, Kevin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Style transfer usually refers to the task of applying color and texture
information from a specific style image to a given content image while
preserving the structure of the latter. Here we tackle the more generic problem
of semantic style transfer: given two unpaired collections of images, we aim to
learn a mapping between the corpus-level style of each collection, while
preserving semantic content shared across the two domains. We introduce XGAN
(&quot;Cross-GAN&quot;), a dual adversarial autoencoder, which captures a shared
representation of the common domain semantic content in an unsupervised way,
while jointly learning the domain-to-domain image translations in both
directions. We exploit ideas from the domain adaptation literature and define a
semantic consistency loss which encourages the model to preserve semantics in
the learned embedding space. We report promising qualitative results for the
task of face-to-cartoon translation. The cartoon dataset we collected for this
purpose is in the process of being released as a new benchmark for semantic
style transfer.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2018</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05144</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup
  Fairness</dc:title>
 <dc:creator>Kearns, Michael</dc:creator>
 <dc:creator>Neel, Seth</dc:creator>
 <dc:creator>Roth, Aaron</dc:creator>
 <dc:creator>Wu, Zhiwei Steven</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The most prevalent notions of fairness in machine learning are statistical
definitions: they fix a small collection of pre-defined groups, and then ask
for parity of some statistic of the classifier across these groups. Constraints
of this form are susceptible to intentional or inadvertent &quot;fairness
gerrymandering&quot;, in which a classifier appears to be fair on each individual
group, but badly violates the fairness constraint on one or more structured
subgroups defined over the protected attributes. We propose instead to demand
statistical notions of fairness across exponentially (or infinitely) many
subgroups, defined by a structured class of functions over the protected
attributes. This interpolates between statistical definitions of fairness and
recently proposed individual notions of fairness, but raises several
computational challenges. It is no longer clear how to audit a fixed classifier
to see if it satisfies such a strong definition of fairness. We prove that the
computational problem of auditing subgroup fairness for both equality of false
positive rates and statistical parity is equivalent to the problem of weak
agnostic learning, which means it is computationally hard in the worst case,
even for simple structured subclasses.
  We then derive two algorithms that provably converge to the best fair
classifier, given access to oracles which can solve the agnostic learning
problem. The algorithms are based on a formulation of subgroup fairness as a
two-player zero-sum game between a Learner and an Auditor. Our first algorithm
provably converges in a polynomial number of steps. Our second algorithm enjoys
only provably asymptotic convergence, but has the merit of simplicity and
faster per-step computation. We implement the simpler algorithm using linear
regression as a heuristic oracle, and show that we can effectively both audit
and learn fair classifiers on real datasets.
</dc:description>
 <dc:description>Comment: Added Follow-the-Perturbed-Leader based algorithm with polynomial
  round convergence</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05147</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Restoration by Compression</dc:title>
 <dc:creator>Dar, Yehuda</dc:creator>
 <dc:creator>Elad, Michael</dc:creator>
 <dc:creator>Bruckstein, Alfred M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we study the topic of signal restoration using complexity
regularization, quantifying the compression bit-cost of the signal estimate.
While complexity-regularized restoration is an established concept, solid
practical methods were suggested only for the Gaussian denoising task, leaving
more complicated restoration problems without a generally constructive
approach. Here we present practical methods for complexity-regularized
restoration of signals, accommodating deteriorations caused by a known linear
degradation operator of an arbitrary form. Our iterative procedure, obtained
using the Half Quadratic Splitting approach, addresses the restoration task as
a sequence of simpler problems involving $ \ell_2$-regularized estimations and
rate-distortion optimizations (considering the squared-error criterion).
Further, we replace the rate-distortion optimizations with an arbitrary
standardized compression technique and thereby restore the signal by leveraging
underlying models designed for compression. Additionally, we propose a
shift-invariant complexity regularizer, measuring the bit-cost of all the
shifted forms of the estimate, extending our method to use averaging of
decompressed outputs gathered from compression of shifted signals. On the
theoretical side, we present an analysis of complexity-regularized restoration
of a cyclo-stationary Gaussian signal from deterioration by a linear
shift-invariant operator and an additive white Gaussian noise. The theory shows
that optimal complexity-regularized restoration relies on an elementary
restoration filter and compression spreading reconstruction quality unevenly
based on the energy distribution of the degradation filter. Nicely, these ideas
are realized also in the proposed practical methods. Finally, we present
experiments showing good results for image deblurring and inpainting using the
HEVC compression standard.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05157</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on the complexity of Feedback Vertex Set parameterized by
  mim-width</dc:title>
 <dc:creator>Jaffke, Lars</dc:creator>
 <dc:creator>Kwon, O-joung</dc:creator>
 <dc:creator>Telle, Jan Arne</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>05C85</dc:subject>
 <dc:description>  We complement the recent algorithmic result that Feedback Vertex Set is
XP-time solvable parameterized by the mim-width of a given branch decomposition
of the input graph [3] by showing that the problem is W[1]-hard in this
parameterization. The hardness holds even for linear mim-width, as well as for
H-graphs, where the parameter is the number of edges in H. To obtain this
result, we adapt a reduction due to Fomin, Golovach and Raymond [2], following
the same line of reasoning but adding a new gadget.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05157</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05159</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classical Control, Quantum Circuits and Linear Logic in Enriched
  Category Theory</dc:title>
 <dc:creator>Rennela, Mathys</dc:creator>
 <dc:creator>Staton, Sam</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>Mathematics - Operator Algebras</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  We describe categorical models of a circuit-based (quantum) functional pro-
gramming language. We show that enriched categories play a crucial role.
Following earlier work on QWire by Paykin et al., we consider both a simple
first-order linear language for circuits, and a more powerful host language,
such that the circuit language is embedded inside the host language. Our
categorical semantics for the host language is standard, and involves cartesian
closed categories and monads. We interpret the circuit language not in an
ordinary category, but in a category that is enriched in the host category. We
show that this structure is also related to linear/non-linear models. As an
extended example, we recall an earlier result that the category of W*-algebras
is dcpo-enriched, and we use this model to extend the circuit language with
some recursive types.
</dc:description>
 <dc:description>Comment: 28 pages, 3 figures; Mathematical Foundations of Program Semantics
  XXXIII</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05165</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Saliency-based Sequential Image Attention with Multiset Prediction</dc:title>
 <dc:creator>Welleck, Sean</dc:creator>
 <dc:creator>Mao, Jialin</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:creator>Zhang, Zheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Humans process visual scenes selectively and sequentially using attention.
Central to models of human visual attention is the saliency map. We propose a
hierarchical visual architecture that operates on a saliency map and uses a
novel attention mechanism to sequentially focus on salient regions and take
additional glimpses within those regions. The architecture is motivated by
human visual attention, and is used for multi-label image classification on a
novel multiset task, demonstrating that it achieves high precision and recall
while localizing objects with its attention. Unlike conventional multi-label
image classification models, the model supports multiset prediction due to a
reinforcement-learning based training process that allows for arbitrary label
permutation and multiple instances per label.
</dc:description>
 <dc:description>Comment: To appear in Advances in Neural Information Processing Systems 30
  (NIPS 2017)</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05166</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Keyframe-based Dense SLAM with an RGB-D Camera</dc:title>
 <dc:creator>Liu, Haomin</dc:creator>
 <dc:creator>Li, Chen</dc:creator>
 <dc:creator>Chen, Guojun</dc:creator>
 <dc:creator>Zhang, Guofeng</dc:creator>
 <dc:creator>Kaess, Michael</dc:creator>
 <dc:creator>Bao, Hujun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present RKD-SLAM, a robust keyframe-based dense SLAM
approach for an RGB-D camera that can robustly handle fast motion and dense
loop closure, and run without time limitation in a moderate size scene. It not
only can be used to scan high-quality 3D models, but also can satisfy the
demand of VR and AR applications. First, we combine color and depth information
to construct a very fast keyframe-based tracking method on a CPU, which can
work robustly in challenging cases (e.g.~fast camera motion and complex loops).
For reducing accumulation error, we also introduce a very efficient incremental
bundle adjustment (BA) algorithm, which can greatly save unnecessary
computation and perform local and global BA in a unified optimization
framework. An efficient keyframe-based depth representation and fusion method
is proposed to generate and timely update the dense 3D surface with online
correction according to the refined camera poses of keyframes through BA. The
experimental results and comparisons on a variety of challenging datasets and
TUM RGB-D benchmark demonstrate the effectiveness of the proposed system.
</dc:description>
 <dc:description>Comment: 12 pages, 9 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05166</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05170</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Extending Neural Networks with Loss Ensembles for Text Classification</dc:title>
 <dc:creator>Hajiabadi, Hamideh</dc:creator>
 <dc:creator>Molla-Aliod, Diego</dc:creator>
 <dc:creator>Monsefi, Reza</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Ensemble techniques are powerful approaches that combine several weak
learners to build a stronger one. As a meta learning framework, ensemble
techniques can easily be applied to many machine learning techniques. In this
paper we propose a neural network extended with an ensemble loss function for
text classification. The weight of each weak loss function is tuned within the
training phase through the gradient propagation optimization method of the
neural network. The approach is evaluated on several text classification
datasets. We also evaluate its performance in various environments with several
degrees of label noise. Experimental results indicate an improvement of the
results and strong resilience against label noise in comparison with other
methods.
</dc:description>
 <dc:description>Comment: 5 pages, 5 tables, 1 figure. Camera-ready submitted to The 2017
  Australasian Language Technology Association Workshop (ALTA 2017)</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05170</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05174</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Optimal Discrete Optimization for Experimental Design: A Regret
  Minimization Approach</dc:title>
 <dc:creator>Allen-Zhu, Zeyuan</dc:creator>
 <dc:creator>Li, Yuanzhi</dc:creator>
 <dc:creator>Singh, Aarti</dc:creator>
 <dc:creator>Wang, Yining</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  The experimental design problem concerns the selection of k points from a
potentially large design pool of p-dimensional vectors, so as to maximize the
statistical efficiency regressed on the selected k design points. Statistical
efficiency is measured by optimality criteria, including A(verage),
D(eterminant), T(race), E(igen), V(ariance) and G-optimality. Except for the
T-optimality, exact optimization is NP-hard.
  We propose a polynomial-time regret minimization framework to achieve a
$(1+\varepsilon)$ approximation with only $O(p/\varepsilon^2)$ design points,
for all the optimality criteria above.
  In contrast, to the best of our knowledge, before our work, no
polynomial-time algorithm achieves $(1+\varepsilon)$ approximations for
D/E/G-optimality, and the best poly-time algorithm achieving
$(1+\varepsilon)$-approximation for A/V-optimality requires $k =
\Omega(p^2/\varepsilon)$ design points.
</dc:description>
 <dc:description>Comment: 33 pages, 4 tables. A preliminary version of this paper titled
  &quot;Near-Optimal Experimental Design via Regret Minimization&quot; with weaker
  results appeared in the Proceedings of the 34th International Conference on
  Machine Learning (ICML 2017), Sydney</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05175</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional Autoencoders with Adversarial Information Factorization</dc:title>
 <dc:creator>Creswell, Antonia</dc:creator>
 <dc:creator>Bharath, Anil A</dc:creator>
 <dc:creator>Sengupta, Biswa</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Generative models, such as variational auto-encoders (VAE) and generative
adversarial networks (GAN), have been immensely successful in approximating
image statistics in computer vision. VAEs are useful for unsupervised feature
learning, while GANs alleviate supervision by penalizing inaccurate samples
using an adversarial game. In order to utilize benefits of these two
approaches, we combine the VAE under an adversarial setup with auxiliary label
information. We show that factorizing the latent space to separate the
information needed for reconstruction (a continuous space) from the information
needed for image attribute classification (a discrete space), enables the
capability to edit specific attributes of an image.
</dc:description>
 <dc:description>Comment: Under review for CVPR 2018</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05186</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>False Positive and Cross-relation Signals in Distant Supervision Data</dc:title>
 <dc:creator>Dumitrache, Anca</dc:creator>
 <dc:creator>Aroyo, Lora</dc:creator>
 <dc:creator>Welty, Chris</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Distant supervision (DS) is a well-established method for relation extraction
from text, based on the assumption that when a knowledge-base contains a
relation between a term pair, then sentences that contain that pair are likely
to express the relation. In this paper, we use the results of a crowdsourcing
relation extraction task to identify two problems with DS data quality: the
widely varying degree of false positives across different relations, and the
observed causal connection between relations that are not considered by the DS
method. The crowdsourcing data aggregation is performed using ambiguity-aware
CrowdTruth metrics, that are used to capture and interpret inter-annotator
disagreement. We also present preliminary results of using the crowd to enhance
DS training data for a relation classification model, without requiring the
crowd to annotate the entire set.
</dc:description>
 <dc:description>Comment: in proceedings of the 6th Workshop on Automated Knowledge Base
  Construction (AKBC) at NIPS 2017</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05187</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Zoom-in Network for Fast Object Detection in Large Images</dc:title>
 <dc:creator>Gao, Mingfei</dc:creator>
 <dc:creator>Yu, Ruichi</dc:creator>
 <dc:creator>Li, Ang</dc:creator>
 <dc:creator>Morariu, Vlad I.</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a generic framework that reduces the computational cost of
object detection while retaining accuracy for scenarios where objects with
varied sizes appear in high resolution images. Detection progresses in a
coarse-to-fine manner, first on a down-sampled version of the image and then on
a sequence of higher resolution regions identified as likely to improve the
detection accuracy. Built upon reinforcement learning, our approach consists of
a model (R-net) that uses coarse detection results to predict the potential
accuracy gain for analyzing a region at a higher resolution and another model
(Q-net) that sequentially selects regions to zoom in. Experiments on the
Caltech Pedestrians dataset show that our approach reduces the number of
processed pixels by over 50% without a drop in detection accuracy. The merits
of our approach become more significant on a high resolution test set collected
from YFCC100M dataset where our approach maintains high detection performance
while reducing the number of processed pixels by about 70% and the detection
time by over 50%.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05189</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CryptoDL: Deep Neural Networks over Encrypted Data</dc:title>
 <dc:creator>Hesamifard, Ehsan</dc:creator>
 <dc:creator>Takabi, Hassan</dc:creator>
 <dc:creator>Ghasemi, Mehdi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Machine learning algorithms based on deep neural networks have achieved
remarkable results and are being extensively used in different domains.
However, the machine learning algorithms requires access to raw data which is
often privacy sensitive. To address this issue, we develop new techniques to
provide solutions for running deep neural networks over encrypted data. In this
paper, we develop new techniques to adopt deep neural networks within the
practical limitation of current homomorphic encryption schemes. More
specifically, we focus on classification of the well-known convolutional neural
networks (CNN). First, we design methods for approximation of the activation
functions commonly used in CNNs (i.e. ReLU, Sigmoid, and Tanh) with low degree
polynomials which is essential for efficient homomorphic encryption schemes.
Then, we train convolutional neural networks with the approximation polynomials
instead of original activation functions and analyze the performance of the
models. Finally, we implement convolutional neural networks over encrypted data
and measure performance of the models. Our experimental results validate the
soundness of our approach with several convolutional neural networks with
varying number of layers and structures. When applied to the MNIST optical
character recognition tasks, our approach achieves 99.52\% accuracy which
significantly outperforms the state-of-the-art solutions and is very close to
the accuracy of the best non-private version, 99.77\%. Also, it can make close
to 164000 predictions per hour. We also applied our approach to CIFAR-10, which
is much more complex compared to MNIST, and were able to achieve 91.5\%
accuracy with approximation polynomials used as activation functions. These
results show that CryptoDL provides efficient, accurate and scalable
privacy-preserving predictions.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05195</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A learning problem that is independent of the set theory ZFC axioms</dc:title>
 <dc:creator>Ben-David, Shai</dc:creator>
 <dc:creator>Hrubes, Pavel</dc:creator>
 <dc:creator>Moran, Shay</dc:creator>
 <dc:creator>Shpilka, Amir</dc:creator>
 <dc:creator>Yehudayoff, Amir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the following statistical estimation problem: given a family F of
real valued functions over some domain X and an i.i.d. sample drawn from an
unknown distribution P over X, find h in F such that the expectation of h
w.r.t. P is probably approximately equal to the supremum over expectations on
members of F. This Expectation Maximization (EMX) problem captures many well
studied learning problems; in fact, it is equivalent to Vapnik's general
setting of learning.
  Surprisingly, we show that the EMX learnability, as well as the learning
rates of some basic class F, depend on the cardinality of the continuum and is
therefore independent of the set theory ZFC axioms (that are widely accepted as
a formalization of the notion of a mathematical proof).
  We focus on the case where the functions in F are Boolean, which generalizes
classification problems. We study the interaction between the statistical
sample complexity of F and its combinatorial structure. We introduce a new
version of sample compression schemes and show that it characterizes EMX
learnability for a wide family of classes. However, we show that for the class
of finite subsets of the real line, the existence of such compression schemes
is independent of set theory. We conclude that the learnability of that class
with respect to the family of probability distributions of countable support is
independent of the set theory ZFC axioms.
  We also explore the existence of a &quot;VC-dimension-like&quot; parameter that
captures learnability in this setting. Our results imply that that there exist
no &quot;finitary&quot; combinatorial parameter that characterizes EMX learnability in a
way similar to the VC-dimension based characterization of binary valued
classification problems.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05197</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Gaussian Processes for Biophysical Parameter Retrieval</dc:title>
 <dc:creator>Svendsen, Daniel Heestermans</dc:creator>
 <dc:creator>Martino, Luca</dc:creator>
 <dc:creator>Campos-Taberner, Manuel</dc:creator>
 <dc:creator>Garc&#xed;a-Haro, Francisco Javier</dc:creator>
 <dc:creator>Camps-Valls, Gustau</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Solving inverse problems is central to geosciences and remote sensing.
Radiative transfer models (RTMs) represent mathematically the physical laws
which govern the phenomena in remote sensing applications (forward models). The
numerical inversion of the RTM equations is a challenging and computationally
demanding problem, and for this reason, often the application of a nonlinear
statistical regression is preferred. In general, regression models predict the
biophysical parameter of interest from the corresponding received radiance.
However, this approach does not employ the physical information encoded in the
RTMs. An alternative strategy, which attempts to include the physical
knowledge, consists in learning a regression model trained using data simulated
by an RTM code. In this work, we introduce a nonlinear nonparametric regression
model which combines the benefits of the two aforementioned approaches. The
inversion is performed taking into account jointly both real observations and
RTM-simulated data. The proposed Joint Gaussian Process (JGP) provides a solid
framework for exploiting the regularities between the two types of data. The
JGP automatically detects the relative quality of the simulated and real data,
and combines them accordingly. This occurs by learning an additional
hyper-parameter w.r.t. a standard GP model, and fitting parameters through
maximizing the pseudo-likelihood of the real observations. The resulting scheme
is both simple and robust, i.e., capable of adapting to different scenarios.
The advantages of the JGP method compared to benchmark strategies are shown
considering RTM-simulated and real observations in different experiments.
Specifically, we consider leaf area index (LAI) retrieval from Landsat data
combined with simulated data generated by the PROSAIL model.
</dc:description>
 <dc:description>Comment: 21 pages single column, Accepted for publication in IEEE Transactions
  on Geoscience and Remote Sensing</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05197</dc:identifier>
 <dc:identifier>doi:10.1109/TGRS.2017.2767205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05198</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised patient representations from clinical notes with
  interpretable classification decisions</dc:title>
 <dc:creator>Sushil, Madhumita</dc:creator>
 <dc:creator>&#x160;uster, Simon</dc:creator>
 <dc:creator>Luyckx, Kim</dc:creator>
 <dc:creator>Daelemans, Walter</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We have two main contributions in this work: 1. We explore the usage of a
stacked denoising autoencoder, and a paragraph vector model to learn
task-independent dense patient representations directly from clinical notes. We
evaluate these representations by using them as features in multiple supervised
setups, and compare their performance with those of sparse representations. 2.
To understand and interpret the representations, we explore the best encoded
features within the patient representations obtained from the autoencoder
model. Further, we calculate the significance of the input features of the
trained classifiers when we use these pretrained representations as input.
</dc:description>
 <dc:description>Comment: Accepted poster at NIPS 2017 Workshop on Machine Learning for Health
  (https://ml4health.github.io/2017/)</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05216</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tree Projections and Constraint Optimization Problems: Fixed-Parameter
  Tractability and Parallel Algorithms</dc:title>
 <dc:creator>Gottlob, Georg</dc:creator>
 <dc:creator>Greco, Gianlugi</dc:creator>
 <dc:creator>Scarcello, Francesco</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>H.2</dc:subject>
 <dc:description>  Tree projections provide a unifying framework to deal with most structural
decomposition methods of constraint satisfaction problems (CSPs). Within this
framework, a CSP instance is decomposed into a number of sub-problems, called
views, whose solutions are either already available or can be computed
efficiently. The goal is to arrange portions of these views in a tree-like
structure, called tree projection, which determines an efficiently solvable CSP
instance equivalent to the original one. Deciding whether a tree projection
exists is NP-hard. Solution methods have therefore been proposed in the
literature that do not require a tree projection to be given, and that either
correctly decide whether the given CSP instance is satisfiable, or return that
a tree projection actually does not exist. These approaches had not been
generalized so far on CSP extensions for optimization problems, where the goal
is to compute a solution of maximum value/minimum cost. The paper fills the
gap, by exhibiting a fixed-parameter polynomial-time algorithm that either
disproves the existence of tree projections or computes an optimal solution,
with the parameter being the size of the expression of the objective function
to be optimized over all possible solutions (and not the size of the whole
constraint formula, used in related works). Tractability results are also
established for the problem of returning the best K solutions. Finally,
parallel algorithms for such optimization problems are proposed and analyzed.
Given that the classes of acyclic hypergraphs, hypergraphs of bounded
treewidth, and hypergraphs of bounded generalized hypertree width are all
covered as special cases of the tree projection framework, the results in this
paper directly apply to these classes. These classes are extensively considered
in the CSP setting, as well as in conjunctive database query evaluation and
optimization.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05217</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controllable Abstractive Summarization</dc:title>
 <dc:creator>Fan, Angela</dc:creator>
 <dc:creator>Grangier, David</dc:creator>
 <dc:creator>Auli, Michael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Current models for document summarization ignore user preferences such as the
desired length, style or entities that the user has a preference for. We
present a neural summarization model that enables users to specify such high
level attributes in order to control the shape of the final summaries to better
suit their needs. With user input, we show that our system can produce high
quality summaries that are true to user preference. Without user input, we can
set the control variables automatically and outperform comparable state of the
art summarization systems despite the relative simplicity of our model.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05219</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LAA LTE and WiFi based Smart Grid Metering Infrastructure in 3.5 GHz
  Band</dc:title>
 <dc:creator>Parvez, Imtiaz</dc:creator>
 <dc:creator>Khan, Tanwir</dc:creator>
 <dc:creator>Sarwat, Arif</dc:creator>
 <dc:creator>Parvez, Zakaria</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Advanced metering infrastructure (AMI) of smart grid requires bidirectional
communication for transferring data to billing center, for which WiFi is an
attractive choice. However, WiFi operates in the unlicensed bands and LTE needs
to offload data in the same unlicensed band. Recent release of 3.5 GHz (also
termed as citizen broadband radio service (CBRS)) can be an attractive shared
band where LTE and WiFi can coexist. In our study, we propose a fixed duty
cycled LTE-U and WiFi based smart grid metering infrastructure where smart
meter uses WiFi and data collector (termed as Access Point (AP)) of smart
meters uses LTE for transferring data. We investigate the coexistence
performance of LTE-WiFi in the 3.5 GHz band using a time division duplexing
(TDD) LTE confederated by WiFi along with FTP traffic model for system level
simulation. The simulation results demonstrate a good neighboring coexistence
between LTE and WiFi resulting a candidate AMI architecture for smart grid in
the 3.5 GHz band.
</dc:description>
 <dc:description>Comment: Accepted in IEEE R10HTC conference</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05220</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Dual-functional Radar-Communication Systems: Optimal Waveform
  Design</dc:title>
 <dc:creator>Liu, Fan</dc:creator>
 <dc:creator>Zhou, Longfei</dc:creator>
 <dc:creator>Masouros, Christos</dc:creator>
 <dc:creator>Li, Ang</dc:creator>
 <dc:creator>Luo, Wu</dc:creator>
 <dc:creator>Petropulu, Athina</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We focus on a dual-functional multi-input-multi-output (MIMO)
radar-communication (RadCom) system, where a single transmitter communicates
with downlink cellular users and detects radar targets simultaneously. Several
design criteria are considered for minimizing the downlink multi-user
interference. First, we consider both the omnidirectional and directional
beampattern design problems, where the closed-form globally optimal solutions
are obtained. Based on these waveforms, we further consider a weighted
optimization to enable a flexible trade-off between radar and communications
performance and introduce a low-complexity algorithm. The computational costs
of the above three designs are shown to be similar to the conventional
zero-forcing (ZF) precoding. Moreover, to address the more practical constant
modulus waveform design problem, we propose a branch-and-bound algorithm that
obtains a globally optimal solution and derive its worst-case complexity as a
function of the maximum iteration number. Finally, we assess the effectiveness
of the proposed waveform design approaches by numerical results.
</dc:description>
 <dc:description>Comment: 13 pages, 10 figures. This work has been submitted to the IEEE for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05225</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep
  Learning</dc:title>
 <dc:creator>Rajpurkar, Pranav</dc:creator>
 <dc:creator>Irvin, Jeremy</dc:creator>
 <dc:creator>Zhu, Kaylie</dc:creator>
 <dc:creator>Yang, Brandon</dc:creator>
 <dc:creator>Mehta, Hershel</dc:creator>
 <dc:creator>Duan, Tony</dc:creator>
 <dc:creator>Ding, Daisy</dc:creator>
 <dc:creator>Bagul, Aarti</dc:creator>
 <dc:creator>Langlotz, Curtis</dc:creator>
 <dc:creator>Shpanskaya, Katie</dc:creator>
 <dc:creator>Lungren, Matthew P.</dc:creator>
 <dc:creator>Ng, Andrew Y.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We develop an algorithm that can detect pneumonia from chest X-rays at a
level exceeding practicing radiologists. Our algorithm, CheXNet, is a 121-layer
convolutional neural network trained on ChestX-ray14, currently the largest
publicly available chest X-ray dataset, containing over 100,000 frontal-view
X-ray images with 14 diseases. Four practicing academic radiologists annotate a
test set, on which we compare the performance of CheXNet to that of
radiologists. We find that CheXNet exceeds average radiologist performance on
the F1 metric. We extend CheXNet to detect all 14 diseases in ChestX-ray14 and
achieve state of the art results on all 14 diseases.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05226</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable R-CNN</dc:title>
 <dc:creator>Wu, Tianfu</dc:creator>
 <dc:creator>Li, Xilai</dc:creator>
 <dc:creator>Song, Xi</dc:creator>
 <dc:creator>Sun, Wei</dc:creator>
 <dc:creator>Dong, Liang</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a method of learning qualitatively interpretable models
in object detection using popular two-stage region-based ConvNet detection
systems (i.e., R-CNN). R-CNN consists of a region proposal network and a RoI
(Region-of-Interest) prediction network.By interpretable models, we focus on
weakly-supervised extractive rationale generation, that is learning to unfold
latent discriminative part configurations of object instances automatically and
simultaneously in detection without using any supervision for part
configurations. We utilize a top-down hierarchical and compositional grammar
model embedded in a directed acyclic AND-OR Graph (AOG) to explore and unfold
the space of latent part configurations of RoIs. We propose an AOGParsing
operator to substitute the RoIPooling operator widely used in R-CNN, so the
proposed method is applicable to many state-of-the-art ConvNet based detection
systems. The AOGParsing operator aims to harness both the explainable rigor of
top-down hierarchical and compositional grammar models and the discriminative
power of bottom-up deep neural networks through end-to-end training. In
detection, a bounding box is interpreted by the best parse tree derived from
the AOG on-the-fly, which is treated as the extractive rationale generated for
interpreting detection. In learning, we propose a folding-unfolding method to
train the AOG and ConvNet end-to-end. In experiments, we build on top of the
R-FCN and test the proposed method on the PASCAL VOC 2007 and 2012 datasets
with performance comparable to state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05227</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Goal-Driven Query Answering for Existential Rules with Equality</dc:title>
 <dc:creator>Benedikt, Michael</dc:creator>
 <dc:creator>Motik, Boris</dc:creator>
 <dc:creator>Tsamoura, Efthymia</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Inspired by the magic sets for Datalog, we present a novel goal-driven
approach for answering queries over terminating existential rules with equality
(aka TGDs and EGDs). Our technique improves the performance of query answering
by pruning the consequences that are not relevant for the query. This is
challenging in our setting because equalities can potentially affect all
predicates in a dataset. We address this problem by combining the existing
singularization technique with two new ingredients: an algorithm for
identifying the rules relevant to a query and a new magic sets algorithm. We
show empirically that our technique can significantly improve the performance
of query answering, and that it can mean the difference between answering a
query in a few seconds or not being able to process the query at all.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05233</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A visual search engine for Bangladeshi laws</dc:title>
 <dc:creator>Mandal, Manash Kumar</dc:creator>
 <dc:creator>Nath, Pinku Deb</dc:creator>
 <dc:creator>Mizan, Arpeeta Shams</dc:creator>
 <dc:creator>Saquib, Nazmus</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Browsing and finding relevant information for Bangladeshi laws is a challenge
faced by all law students and researchers in Bangladesh, and by citizens who
want to learn about any legal procedure. Some law archives in Bangladesh are
digitized, but lack proper tools to organize the data meaningfully. We present
a text visualization tool that utilizes machine learning techniques to make the
searching of laws quicker and easier. Using Doc2Vec to layout law article
nodes, link mining techniques to visualize relevant citation networks, and
named entity recognition to quickly find relevant sections in long law
articles, our tool provides a faster and better search experience to the users.
Qualitative feedback from law researchers, students, and government officials
show promise for visually intuitive search tools in the context of
governmental, legal, and constitutional data in developing countries, where
digitized data does not necessarily pave the way towards an easy access to
information.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2017 Workshop on Machine Learning for the
  Developing World. Corresponding author: Nazmus Saquib</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05237</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Considering Durations and Replays to Improve Music Recommender Systems</dc:title>
 <dc:creator>Hanna, Pierre</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The consumption of music has its specificities in comparison with other
media, especially in relation to listening durations and replays. Music
recommendation can take these properties into account in order to predict the
behaviours of the users. Their impact is investigated in this paper. A large
database was thus created using logs collected on a streaming platform, notably
collecting the listening times. The proposed study shows that a high proportion
of the listening events implies a skip action, which may indicate that the user
did not appreciate the track listened. Implicit like and dislike can be deduced
from this information of durations and replays and can be taken into account
for music recommendation and for the evaluation of music recommendation
engines. A quantitative study as usually found in the literature confirms that
neighborhood-based systems considering binary data give the best results in
terms of MAP@k. However, a more qualitative evaluation of the recommended
tracks shows that many tracks recommended, usually evaluated in a positive way,
lead to skips or thus are actually not appreciated. We propose the
consideration of implicit like/dislike as recommendation engine inputs.
Evaluations show that neighbourhood-based engines remain the most precise, but
filtering inputs according to durations and/or replays have a significant
positive impact on the objective of the recommendation engine. The
recommendation process can thus be improved by taking account of listening
durations and replays. We also study the possibility of post-filtering a list
of recommended tracks so as to limit the number of tracks that will be
unpleasantly listened (skip and implicit dislike) and to increase the
proportion of tracks appreciated (implicit like). Several simple algorithms
show that this post-filtering operation leads to an improvement of the quality
of the music recommendations.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05240</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly-supervised Semantic Parsing with Abstract Examples</dc:title>
 <dc:creator>Goldman, Omer</dc:creator>
 <dc:creator>Latcinnik, Veronica</dc:creator>
 <dc:creator>Naveh, Udi</dc:creator>
 <dc:creator>Globerson, Amir</dc:creator>
 <dc:creator>Berant, Jonathan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Semantic parsers translate language utterances to programs, but are often
trained from utterance-denotation pairs only. Consequently, parsers must
overcome the problem of spuriousness at training time, where an incorrect
program found at search time accidentally leads to a correct denotation. We
propose that in small well-typed domains, we can semi-automatically generate an
abstract representation for examples that facilitates information sharing
across examples. This alleviates spuriousness, as the probability of randomly
obtaining a correct answer from a program decreases across multiple examples.
We test our approach on CNLVR, a challenging visual reasoning dataset, where
spuriousness is central because denotations are either TRUE or FALSE, and thus
random programs have high probability of leading to a correct denotation. We
develop the first semantic parser for this task and reach 83.5% accuracy, a
15.7% absolute accuracy improvement compared to the best reported accuracy so
far.
</dc:description>
 <dc:description>Comment: CNLVR,NLVR</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05244</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private Information Retrieval from Storage Constrained Databases --
  Coded Caching meets PIR</dc:title>
 <dc:creator>Abdul-Wahid, Maryam</dc:creator>
 <dc:creator>Almoualem, Firas</dc:creator>
 <dc:creator>Kumar, Deepak</dc:creator>
 <dc:creator>Tandon, Ravi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Private information retrieval (PIR) allows a user to retrieve a desired
message out of $K$ possible messages from $N$ databases without revealing the
identity of the desired message. Majority of existing works on PIR assume the
presence of replicated databases, each storing all the $K$ messages. In this
work, we consider the problem of PIR from storage constrained databases. Each
database has a storage capacity of $\mu KL$ bits, where $K$ is the number of
messages, $L$ is the size of each message in bits, and $\mu \in [1/N, 1]$ is
the normalized storage. In the storage constrained PIR problem, there are two
key design questions: a) how to store content across each database under
storage constraints; and b) construction of schemes that allow efficient PIR
through storage constrained databases. The main contribution of this work is a
general achievable scheme for PIR from storage constrained databases for any
value of storage. In particular, for any $(N,K)$, with normalized storage $\mu=
t/N$, where the parameter $t$ can take integer values $t \in \{1, 2, \ldots,
N\}$, we show that our proposed PIR scheme achieves a download cost of
$\left(1+ \frac{1}{t}+ \frac{1}{t^{2}}+ \cdots + \frac{1}{t^{K-1}}\right)$. The
extreme case when $\mu=1$ (i.e., $t=N$) corresponds to the setting of
replicated databases with full storage. For this extremal setting, our scheme
recovers the information-theoretically optimal download cost characterized by
Sun and Jafar as $\left(1+ \frac{1}{N}+ \cdots + \frac{1}{N^{K-1}}\right)$. For
the other extreme, when $\mu= 1/N$ (i.e., $t=1$), the proposed scheme achieves
a download cost of $K$. The interesting aspect of the result is that for
intermediate values of storage, i.e., $1/N &lt; \mu &lt;1$, the proposed scheme can
strictly outperform memory-sharing between extreme values of storage.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05246</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Loss Functions for Multiset Prediction</dc:title>
 <dc:creator>Welleck, Sean</dc:creator>
 <dc:creator>Yao, Zixin</dc:creator>
 <dc:creator>Gai, Yu</dc:creator>
 <dc:creator>Mao, Jialin</dc:creator>
 <dc:creator>Zhang, Zheng</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the problem of multiset prediction. The goal of multiset prediction
is to train a predictor that maps an input to a multiset consisting of multiple
items. Unlike existing problems in supervised learning, such as classification,
ranking and sequence generation, there is no known order among items in a
target multiset, and each item in the multiset may appear more than once,
making this problem extremely challenging. In this paper, we propose a novel
multiset loss function by viewing this problem from the perspective of
sequential decision making. The proposed multiset loss function is empirically
evaluated on two families of datasets, one synthetic and the other real, with
varying levels of difficulty, against various baseline loss functions including
reinforcement learning, sequence, and aggregated distribution matching loss
functions. The experiments reveal the effectiveness of the proposed loss
function over the others.
</dc:description>
 <dc:description>Comment: Submitted as a conference paper to ICLR 2018</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05251</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>War and Peace: The Peculiarities of Ukrainian-Russian Scientific
  Cooperation Dynamics Against the Background of Russian Military Aggression in
  Ukraine, in 2014-2016</dc:title>
 <dc:creator>Nazarovets, Serhii</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The paper presents the results of bibliometric analysis of publications that
were co-written by authors affiliated with Ukrainian and Russian institutions
in 2007-2016 according to Scopus. Results of the study show that Ukrainian and
Russian scientists have not refused to carry out joint research in major
international projects, but a decrease in the number of works, written by
Ukrainian and Russian scientific institutions staff members in 2016, provides
evidence on the threat and negative impact the Russian military intervention
brings to cooperation in science. The findings are important for generating the
science development programs in Ukraine.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05251</dc:identifier>
 <dc:identifier>Nauka innov. 2017, 13(5):38-43</dc:identifier>
 <dc:identifier>doi:10.15407/scin13.05.038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05253</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Network Dynamics Models for Control of Under-actuated Legged
  Millirobots</dc:title>
 <dc:creator>Nagabandi, Anusha</dc:creator>
 <dc:creator>Yang, Guangzhao</dc:creator>
 <dc:creator>Asmar, Thomas</dc:creator>
 <dc:creator>Kahn, Gregory</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:creator>Fearing, Ronald S.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Millirobots are a promising robotic platform for many applications due to
their small size and low manufacturing costs. However, controlling these
millirobots is difficult due to their underactuation, power constraints, and
size. While hand-engineered controllers can sometimes control these
millirobots, they often have difficulties with highly dynamic maneuvers and
complex terrains. We present a learning based approach in which a model of the
dynamics is learned from data gathered by the millirobot, and that data is then
leveraged by an MPC controller. We show that with 17 minutes of random data
collected with the VelociRoACH millirobot, the VelociRoACH can accurately
follow trajectories at higher speeds and on more difficult terrains than a
differential drive controller. Experiment videos can be found at
https://youtu.be/1Wx3xTHy938
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05254</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Research on two-dimensional traffic flow model based on psychological
  field theory</dc:title>
 <dc:creator>Li, Wenhao</dc:creator>
 <dc:creator>Nie, Yu</dc:creator>
 <dc:creator>Yang, Zhongyao</dc:creator>
 <dc:creator>Zheng, Shaochun</dc:creator>
 <dc:creator>Wang, Dehui</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, the influence of fan-shaped buffer zone on the performance of
the toll plaza is researched. A two-dimensional traffic flow model and a
comprehensive evaluation model based on mechanical model and psychological
field are established. The traffic flow model is simulated by creating
coordinate system.
  We first establish queue theory model to analyze vehicles when entering toll
plaza. Then, a two-dimensional steadily car-following model is established
based on psychological field for the analysis of vehicles when leaving toll
plaza. According to psychological field theory, we analyze the force condition
of each vehicle. The force of each vehicle is contributed by the vehicles in
its observation area and obstacles. By projecting these vehicles and obstacles
via the equipotential line in the psychological field, the influence on the
value and direction acceleration of following vehicles is obtained.
Consequently, the changes of each vehicle's speed and position are obtained as
well. Next, we establish simulation based on the states of vehicles and make
the rules of vehicle state-changing. By simulating the system, we obtain the
throughput of the toll plaza's input and output. Then we obtained the bearing
pressure on the road by the max throughput and the demand of the roads. Using
the number of cars in per unit area as the safety factor. Then a comprehensive
evaluation model is established based on bearing pressure on the road, cost and
safety factor.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05255</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep-ESN: A Multiple Projection-encoding Hierarchical Reservoir
  Computing Framework</dc:title>
 <dc:creator>Ma, Qianli</dc:creator>
 <dc:creator>Shen, Lifeng</dc:creator>
 <dc:creator>Cottrell, Garrison W.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  As an efficient recurrent neural network (RNN) model, reservoir computing
(RC) models, such as Echo State Networks, have attracted widespread attention
in the last decade. However, while they have had great success with time series
data [1], [2], many time series have a multiscale structure, which a
single-hidden-layer RC model may have difficulty capturing. In this paper, we
propose a novel hierarchical reservoir computing framework we call Deep Echo
State Networks (Deep-ESNs). The most distinctive feature of a Deep-ESN is its
ability to deal with time series through hierarchical projections.
Specifically, when an input time series is projected into the high-dimensional
echo-state space of a reservoir, a subsequent encoding layer (e.g., a PCA,
autoencoder, or a random projection) can project the echo-state representations
into a lower-dimensional space. These low-dimensional representations can then
be processed by another ESN. By using projection layers and encoding layers
alternately in the hierarchical framework, a Deep-ESN can not only attenuate
the effects of the collinearity problem in ESNs, but also fully take advantage
of the temporal kernel property of ESNs to explore multiscale dynamics of time
series. To fuse the multiscale representations obtained by each reservoir, we
add connections from each encoding layer to the last output layer. Theoretical
analyses prove that stability of a Deep-ESN is guaranteed by the echo state
property (ESP), and the time complexity is equivalent to a conventional ESN.
Experimental results on some artificial and real world time series demonstrate
that Deep-ESNs can capture multiscale dynamics, and outperform both standard
ESNs and previous hierarchical ESN-based models.
</dc:description>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05260</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Tuning of Two-Dimensional Keyboards</dc:title>
 <dc:creator>Bannerman, Aricca</dc:creator>
 <dc:creator>Emington, James</dc:creator>
 <dc:creator>Venkatesh, Anil</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>00A65</dc:subject>
 <dc:description>  We give a new analysis of a tuning problem in music theory, pertaining
specifically to the approximation of harmonics on a two-dimensional keyboard.
We formulate the question as a linear programming problem on families of
constraints and provide exact solutions for many new keyboard dimensions. We
also show that an optimal tuning for harmonic approximation can be obtained for
any keyboard of given width, provided sufficiently many rows of octaves.
</dc:description>
 <dc:description>Comment: 14 page, 3 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05282</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>C-WSL: Count-guided Weakly Supervised Localization</dc:title>
 <dc:creator>Gao, Mingfei</dc:creator>
 <dc:creator>Li, Ang</dc:creator>
 <dc:creator>Yu, Ruichi</dc:creator>
 <dc:creator>Morariu, Vlad I.</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a count-guided weakly supervised localization (C-WSL) framework
with per-class object count as an additional form of image-level supervision to
improve weakly supervised localization (WSL). C-WSL uses a simple count-based
region selection algorithm to select high quality regions, each of which covers
a single object instance at training time, and improves WSL by training with
the selected regions. To demonstrate the effectiveness of C-WSL, we integrate
object count supervision into two WSL architectures and conduct extensive
experiments on Pascal VOC2007 and VOC2012. Experimental results show that C-WSL
leads to large improvements in WSL detection performance and that the proposed
approach significantly outperforms the state-of-the-art methods.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05284</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Obfuscating the Interconnects: Low-Cost and Resilient Full-Chip Layout
  Camouflaging</dc:title>
 <dc:creator>Patnaik, Satwik</dc:creator>
 <dc:creator>Ashraf, Mohammed</dc:creator>
 <dc:creator>Knechtel, Johann</dc:creator>
 <dc:creator>Sinanoglu, Ozgur</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Layout camouflaging (LC) is a promising technique to protect chip design
intellectual property (IP) from reverse engineers. Most prior art, however,
cannot leverage the full potential of LC due to excessive overheads and/or
their limited scope on an FEOL-centric and accordingly customized manufacturing
process. If at all, most existing techniques can be reasonably applied only to
selected parts of a chip---we argue that such &quot;small-scale or custom
camouflaging&quot; will eventually be circumvented, irrespective of the underlying
technique. In this work, we propose a novel LC scheme which is low-cost and
generic---full-chip LC can finally be realized without any reservation. Our
scheme is based on obfuscating the interconnects (BEOL); it can be readily
applied to any design without modifications in the device layer (FEOL). Applied
with split manufacturing in conjunction, our approach is the first in the
literature to cope with both the FEOL fab and the end-user being untrustworthy.
We implement and evaluate our primitives at the (DRC-clean) layout level; our
scheme incurs significantly lower cost than most of the previous works. When
comparing fully camouflaged to original layouts (i.e., for 100% LC), we observe
on average power, performance, and area overheads of 12%, 30%, and 48%,
respectively. Here we also show empirically that most existing LC techniques
(as well as ours) can only provide proper resilience against powerful SAT
attacks once at least 50% of the layout is camouflaged---only large-scale LC is
practically secure. As indicated, our approach can deliver even 100% LC at
acceptable cost. Finally, we also make our flow publicly available, enabling
the community to protect their sensitive designs.
</dc:description>
 <dc:description>Comment: Published in Proc. International Conference On Computer Aided Design
  (ICCAD) 2017; [v2] added DOI to PDF header</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05284</dc:identifier>
 <dc:identifier>doi:10.1109/ICCAD.2017.8203758</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05294</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Semantic Relatedness using Global Relation Vectors</dc:title>
 <dc:creator>Jameel, Shoaib</dc:creator>
 <dc:creator>Bouraoui, Zied</dc:creator>
 <dc:creator>Schockaert, Steven</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Word embedding models such as GloVe rely on co-occurrence statistics from a
large corpus to learn vector representations of word meaning. These vectors
have proven to capture surprisingly fine-grained semantic and syntactic
information. While we may similarly expect that co-occurrence statistics can be
used to capture rich information about the relationships between different
words, existing approaches for modeling such relationships have mostly relied
on manipulating pre-trained word vectors. In this paper, we introduce a novel
method which directly learns relation vectors from co-occurrence statistics. To
this end, we first introduce a variant of GloVe, in which there is an explicit
connection between word vectors and PMI weighted co-occurrence vectors. We then
show how relation vectors can be naturally embedded into the resulting vector
space.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05295</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved quantum backtracking algorithms through effective resistance
  estimates</dc:title>
 <dc:creator>Jarret, Michael</dc:creator>
 <dc:creator>Wan, Kianna</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We investigate quantum backtracking algorithms of a type previously
introduced by Montanaro (arXiv:1509.02374). These algorithms explore trees of
unknown structure, and in certain cases exponentially outperform classical
procedures (such as DPLL). Some of the previous work focused on obtaining a
quantum advantage for trees in which a unique marked vertex is promised to
exist. We remove this restriction and re-characterise the problem in terms of
the effective resistance of the search space. To this end, we present a
generalisation of one of Montanaro's algorithms to trees containing $k \geq 1$
marked vertices, where $k$ is not necessarily known \textit{a priori}.
  Our approach involves using amplitude estimation to determine a near-optimal
weighting of a diffusion operator, which can then be applied to prepare a
superposition state that has support only on marked vertices and ancestors
thereof. By repeatedly sampling this state and updating the input vertex, a
marked vertex is reached in a logarithmic number of steps. The algorithm
thereby achieves the conjectured bound of
$\widetilde{\mathcal{O}}(\sqrt{TR_{\mathrm{max}}})$ for finding a single marked
vertex and $\widetilde{\mathcal{O}}\left(k\sqrt{T R_{\mathrm{max}}}\right)$ for
finding all $k$ marked vertices, where $T$ is an upper bound on the tree size
and $R_{\mathrm{max}}$ is the maximum effective resistance encountered by the
algorithm. This constitutes a speedup over Montanaro's original procedure in
both the case of finding one and finding multiple marked vertices in an
arbitrary tree. If there are no marked vertices, the effective resistance
becomes infinite, and we recover the scaling of Montanaro's existence
algorithm.
</dc:description>
 <dc:description>Comment: 27 pages</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05296</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Whole-System Provenance Capture</dc:title>
 <dc:creator>Pasquier, Thomas</dc:creator>
 <dc:creator>Han, Xueyuan</dc:creator>
 <dc:creator>Goldstein, Mark</dc:creator>
 <dc:creator>Moyer, Thomas</dc:creator>
 <dc:creator>Eyers, David</dc:creator>
 <dc:creator>Seltzer, Margo</dc:creator>
 <dc:creator>Bacon, Jean</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Data provenance describes how data came to be in its present form. It
includes data sources and the transformations that have been applied to them.
Data provenance has many uses, from forensics and security to aiding the
reproducibility of scientific experiments. We present CamFlow, a whole-system
provenance capture mechanism that integrates easily into a PaaS offering. While
there have been several prior whole-system provenance systems that captured a
comprehensive, systemic and ubiquitous record of a system's behavior, none have
been widely adopted. They either A) impose too much overhead, B) are designed
for long-outdated kernel releases and are hard to port to current systems, C)
generate too much data, or D) are designed for a single system. CamFlow
addresses these shortcoming by: 1) leveraging the latest kernel design advances
to achieve efficiency; 2) using a self-contained, easily maintainable
implementation relying on a Linux Security Module, NetFilter, and other
existing kernel facilities; 3) providing a mechanism to tailor the captured
provenance data to the needs of the application; and 4) making it easy to
integrate provenance across distributed systems. The provenance we capture is
streamed and consumed by tenant-built auditor applications. We illustrate the
usability of our implementation by describing three such applications:
demonstrating compliance with data regulations; performing fault/intrusion
detection; and implementing data loss prevention. We also show how CamFlow can
be leveraged to capture meaningful provenance without modifying existing
applications.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05296</dc:identifier>
 <dc:identifier>SoCC '17 Proceedings of the 2017 Symposium on Cloud Computing</dc:identifier>
 <dc:identifier>doi:10.1145/3127479.3129249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05303</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Political Discourse in the Trump Era</dc:title>
 <dc:creator>Nithyanand, Rishab</dc:creator>
 <dc:creator>Schaffner, Brian</dc:creator>
 <dc:creator>Gill, Phillipa</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We identify general trends in the (in)civility and complexity of political
discussions occurring on Reddit between January 2007 and May 2017 -- a period
spanning both terms of Barack Obama's presidency and the first 100 days of
Donald Trump's presidency. We then investigate four factors that are frequently
hypothesized as having contributed to the declining quality of American
political discourse -- (1) the rising popularity of Donald Trump, (2)
increasing polarization and negative partisanship, (3) the democratization of
news media and the rise of fake news, and (4) merging of fringe groups into
mainstream political discussions.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05305</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Accelerated Communication-Efficient Primal-Dual Optimization
  Framework for Structured Machine Learning</dc:title>
 <dc:creator>Ma, Chenxin</dc:creator>
 <dc:creator>Jaggi, Martin</dc:creator>
 <dc:creator>Curtis, Frank E.</dc:creator>
 <dc:creator>Srebro, Nathan</dc:creator>
 <dc:creator>Tak&#xe1;&#x10d;, Martin</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Distributed optimization algorithms are essential for training machine
learning models on very large-scale datasets. However, they often suffer from
communication bottlenecks. Confronting this issue, a communication-efficient
primal-dual coordinate ascent framework (CoCoA) and its improved variant CoCoA+
have been proposed, achieving a convergence rate of $\mathcal{O}(1/t)$ for
solving empirical risk minimization problems with Lipschitz continuous losses.
In this paper, an accelerated variant of CoCoA+ is proposed and shown to
possess a convergence rate of $\mathcal{O}(1/t^2)$ in terms of reducing
suboptimality. The analysis of this rate is also notable in that the
convergence rate bounds involve constants that, except in extreme cases, are
significantly reduced compared to those previously provided for CoCoA+. The
results of numerical experiments are provided to show that acceleration can
lead to significant performance gains.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05313</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulating Action Dynamics with Neural Process Networks</dc:title>
 <dc:creator>Bosselut, Antoine</dc:creator>
 <dc:creator>Levy, Omer</dc:creator>
 <dc:creator>Holtzman, Ari</dc:creator>
 <dc:creator>Ennis, Corin</dc:creator>
 <dc:creator>Fox, Dieter</dc:creator>
 <dc:creator>Choi, Yejin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Understanding procedural language requires anticipating the causal effects of
actions, even when they are not explicitly stated. In this work, we introduce
Neural Process Networks to understand procedural text through (neural)
simulation of action dynamics. Our model complements existing memory
architectures with dynamic entity tracking by explicitly modeling actions as
state transformers. The model updates the states of the entities by executing
learned action operators. Empirical results demonstrate that our proposed model
can reason about the unstated causal effects of actions, allowing it to provide
more accurate contextual information for understanding and generating
procedural text, all while offering more interpretable internal representations
than existing alternatives.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05315</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ranking of nodes of networks taking into account the power function of
  its weight of connections</dc:title>
 <dc:creator>Soboliev, A. M.</dc:creator>
 <dc:creator>Lande, D. V.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  To rank nodes in quasi-hierarchical networks of social nature, it is
necessary to carry out a detailed analysis of the network and evaluate the
results obtained according to all the given criteria and identify the most
influential nodes. Existing ranking algorithms in the overwhelming majority
estimate such networks in general, which does not allow to clearly determine
the influence of nodes among themselves. In the course of the study, an
analysis of the results of known algorithms for ranking the nodes of HITS,
PageRank and compares the obtained data with the expert evaluation of the
network. For the effective analysis of quasi-hierarchical networks, the basic
algorithm of HITS is modified, which allows to evaluate and rank nodes
according to the given criteria (the number of input and output links among
themselves), which corresponds to the results of expert evaluation. It is shown
that the received method in some cases provides results that correspond to the
real social relation, and the indexes of the authorship of the nodes -
pre-assigned social roles.
</dc:description>
 <dc:description>Comment: 11 pages, 2 fig</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05319</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Cost Coefficient Identification for Planning Optimal Operation
  in Mobile Robot based Internal Transportation</dc:title>
 <dc:creator>Das, Pragna</dc:creator>
 <dc:creator>Ribas-Xirgo, Lluis</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Decisions in automated logistic systems can be improved based on knowledge of
real-time state of individual parts and also environmental factors. These
knowledge can be obtained through travel time of edges by individual robots
which represents the utility based costs in the system. Our work focuses on
identifying \textbf{cost coefficients} in an autonomous multi-robot system used
for internal transportation. With suitable predictions of these travel times
the current status of cost involved in traversing from one node to another can
be known. Thus suitable state-space model is formulated and Kalman filtering is
used to estimate these travel time to use as weights for cost efficient route
planning. Experiments show that paths obtained using online \textbf{travel
times} as weights have total traversing cost reduces by 15\% on average.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05323</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Optimal Generalizability in Parametric Learning</dc:title>
 <dc:creator>Beirami, Ahmad</dc:creator>
 <dc:creator>Razaviyayn, Meisam</dc:creator>
 <dc:creator>Shahrampour, Shahin</dc:creator>
 <dc:creator>Tarokh, Vahid</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the parametric learning problem, where the objective of the
learner is determined by a parametric loss function. Employing empirical risk
minimization with possibly regularization, the inferred parameter vector will
be biased toward the training samples. Such bias is measured by the cross
validation procedure in practice where the data set is partitioned into a
training set used for training and a validation set, which is not used in
training and is left to measure the out-of-sample performance. A classical
cross validation strategy is the leave-one-out cross validation (LOOCV) where
one sample is left out for validation and training is done on the rest of the
samples that are presented to the learner, and this process is repeated on all
of the samples. LOOCV is rarely used in practice due to the high computational
complexity. In this paper, we first develop a computationally efficient
approximate LOOCV (ALOOCV) and provide theoretical guarantees for its
performance. Then we use ALOOCV to provide an optimization algorithm for
finding the regularizer in the empirical risk minimization framework. In our
numerical experiments, we illustrate the accuracy and efficiency of ALOOCV as
well as our proposed framework for the optimization of the regularizer.
</dc:description>
 <dc:description>Comment: Proc. of 2017 Advances in Neural Information Processing Systems (NIPS
  2017)</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05324</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Value of Communication in Designing Robust Distributed Controllers</dc:title>
 <dc:creator>Furieri, Luca</dc:creator>
 <dc:creator>Kamgarpour, Maryam</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider computation of optimal distributed controllers with constraints
on states and inputs. The problem of distributed control arises in several
large-scale systems, such as transportation networks and power grid systems.
Well-established results highlight the intractability of the corresponding
optimization problem for many cases of interest. In particular, convex
computation of controllers having a fixed sparsity pattern is not possible for
any system whose dynamics propagate according to a strongly connected topology.
Such limitation is due to the fact that given enough time, the decisions of
each controller spread to all system states and thus affect the future
decisions of every other controller. Based on this insight, we propose
designing communication links between controllers to propagate relevant output
information quickly enough for convexity. We show that communication links can
be used to restore convexity for strongly connected systems without the need of
full information. The resulting distributed control policy is optimal and
satisfies state and input constraints robustly. Additionally, we propose novel
graph theoretic interpretations of the result.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05332</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Barrel Shifter Physical Unclonable Function Based Encryption</dc:title>
 <dc:creator>Guo, Yunxi</dc:creator>
 <dc:creator>Dee, Timothy</dc:creator>
 <dc:creator>Tyagi, Akhilesh</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Physical Unclonable Functions (PUFs) are circuits designed to extract
physical randomness from the underlying circuit. This randomness depends on the
manufacturing process. It differs for each device enabling chip-level
authentication and key generation applications. We present a protocol utilizing
a PUF for secure data transmission. Parties each have a PUF used for encryption
and decryption; this is facilitated by constraining the PUF to be commutative.
This framework is evaluated with a primitive permutation network - a barrel
shifter. Physical randomness is derived from the delay of different shift
paths. Barrel shifter (BS) PUF captures the delay of different shift paths.
This delay is entangled with message bits before they are sent across an
insecure channel. BS-PUF is implemented using transmission gates; their
characteristics ensure same-chip reproducibility, a necessary property of PUFs.
Post-layout simulations of a common centroid layout 8-level barrel shifter in
0.13 {\mu}m technology assess uniqueness, stability and randomness properties.
BS-PUFs pass all selected NIST statistical randomness tests. Stability similar
to Ring Oscillator (RO) PUFs under environment variation is shown. Logistic
regression of 100,000 plaintext-ciphertext pairs (PCPs) failed to successfully
model BS- PUF behavior.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05332</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05340</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting Automatic Commit Classification Into Maintenance Activities By
  Utilizing Source Code Changes</dc:title>
 <dc:creator>Levin, Stanislav</dc:creator>
 <dc:creator>Yehudai, Amiram</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Background: Understanding maintenance activities performed in a source code
repository could help practitioners reduce uncertainty and improve
cost-effectiveness by planning ahead and pre-allocating resources towards
source code maintenance. The research community uses 3 main classification
categories for maintenance activities: Corrective: fault fixing; Perfective:
system improvements; Adaptive: new feature introduction. Previous work in this
area has mostly concentrated on evaluating commit classification (into
maintenance activities) models in the scope of a single software project. Aims:
In this work we seek to design a commit classification model capable of
providing high accuracy and Kappa across different projects. In addition, we
wish to compare the accuracy and kappa characteristics of classification models
that utilize word frequency analysis, source code changes, and combination
thereof. Method: We suggest a novel method for automatically classifying
commits into maintenance activities by utilizing source code changes (e.g,
statement added, method removed, etc.). The results we report are based on
studying 11 popular open source projects from various professional domains from
which we had manually classified 1151 commits, over 100 from each of the
studied projects. Our models were trained using 85% of the dataset, while the
remaining 15% were used as a test set. Results: Our method shows a promising
accuracy of 76% and Cohen's kappa of 63% (considered &quot;Good&quot; in this context)
for the test dataset, an improvement of over 20 percentage points, and a
relative boost of ~40% in the context of cross-project classification.
Conclusions: We show that by using source code changes in combination with
commit message word frequency analysis we are able to considerably boost
classification quality in a project agnostic manner.
</dc:description>
 <dc:description>Comment: postprint, PROMISE 2017</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05341</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust and High Fidelity Mesh Denoising</dc:title>
 <dc:creator>Yadav, Sunil Kumar</dc:creator>
 <dc:creator>Reitebuch, Ulrich</dc:creator>
 <dc:creator>Polthier, Konrad</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  This paper presents a simple and effective two-stage mesh denoising
algorithm, where in the first stage, the face normal filtering is done by using
the bilateral normal filtering in the robust statistics framework. Tukey's
bi-weight function is used as similarity function in the bilateral weighting,
which is a robust estimator and stops the diffusion at sharp edges to retain
features and removes noise from flat regions effectively. In the second stage,
an edge weighted Laplace operator is introduced to compute a differential
coordinate. This differential coordinate helps the algorithm to produce a
high-quality mesh without any face normal flips and makes the method robust
against high-intensity noise.
</dc:description>
 <dc:description>Comment: Revised Version</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05345</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supervised and Unsupervised Transfer Learning for Question Answering</dc:title>
 <dc:creator>Chung, Yu-An</dc:creator>
 <dc:creator>Lee, Hung-Yi</dc:creator>
 <dc:creator>Glass, James</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Although transfer learning has been shown to be successful for tasks like
object and speech recognition, its applicability to question answering (QA) has
yet to be well-studied. In this paper, we conduct extensive experiments to
investigate the transferability of knowledge learned from a source QA dataset
to a target dataset using two QA models. The performance of both models on a
TOEFL listening comprehension test (Tseng et al., 2016) and MCTest (Richardson
et al., 2013) is significantly improved via a simple transfer learning
technique from MovieQA (Tapaswi et al., 2016). In particular, one of the models
achieves the state-of-the-art on all target datasets; for the TOEFL listening
comprehension test, it outperforms the previous best model by 7%. Finally, we
show that transfer learning is helpful even in unsupervised scenarios when
correct answers for target QA dataset examples are not available.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05348</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Navigation without localisation: reliable teach and repeat based on the
  convergence theorem</dc:title>
 <dc:creator>Krajnik, Tomas</dc:creator>
 <dc:creator>Majer, Filip</dc:creator>
 <dc:creator>Halodova, Lucie</dc:creator>
 <dc:creator>Bayer, Jan</dc:creator>
 <dc:creator>Vintr, Tomas</dc:creator>
 <dc:creator>Faigl, Jan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a novel concept for teach-and-repeat visual navigation. The
proposed concept is based on a mathematical model, which indicates that in
teach-and-repeat navigation scenarios, mobile robots do not need to perform
explicit localisation. Rather than that, a mobile robot which repeats a
previously taught path can simply &quot;replay&quot; the learned velocities, while using
its camera information only to correct its heading relatively to the intended
path. To support our claim, we establish a position error model of a robot,
which traverses a taught path by only correcting its heading. Then, we outline
a mathematical proof which shows that this position error does not diverge over
time. Based on the insights from the model, we present a simple monocular
teach-and-repeat navigation method. The method is computationally efficient, it
does not require camera calibration and it can learn and autonomously traverse
arbitrarily-shaped paths. In a series of experiments, we demonstrate that the
method can reliably guide mobile robots in realistic indoor and outdoor
conditions, and can cope with imperfect odometry, landmark deficiency,
illumination variations and naturally-occurring environment changes.
Furthermore, we provide the navigation system and the datasets gathered at
\url{www.github.com/gestom/stroll_bearnav}.
</dc:description>
 <dc:description>Comment: The paper was rejected from IEEE RAL ICRA 2018 issue. Please check
  the reviews in the paper's appendix</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05350</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Learning Approach for Expert Identification in Question Answering
  Communities</dc:title>
 <dc:creator>Zheng, Chen</dc:creator>
 <dc:creator>Zhai, Shuangfei</dc:creator>
 <dc:creator>Zhang, Zhongfei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we describe an effective convolutional neural network
framework for identifying the expert in question answering community. This
approach uses the convolutional neural network and combines user feature
representations with question feature representations to compute scores that
the user who gets the highest score is the expert on this question. Unlike
prior work, this method does not measure expert based on measure answer content
quality to identify the expert but only require question sentence and user
embedding feature to identify the expert. Remarkably, Our model can be applied
to different languages and different domains. The proposed framework is trained
on two datasets, The first dataset is Stack Overflow and the second one is
Zhihu. The Top-1 accuracy results of our experiments show that our framework
outperforms the best baseline framework for expert identification.
</dc:description>
 <dc:description>Comment: 7 pages. arXiv admin note: text overlap with arXiv:1403.6652 by other
  authors</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05354</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Numerical Solution of Fourth-Order Linear Two-Point Boundary
  Value Problems</dc:title>
 <dc:creator>Leeb, William</dc:creator>
 <dc:creator>Rokhlin, Vladimir</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  This paper introduces a fast and numerically stable algorithm for the
solution of fourth-order linear boundary value problems on an interval. This
type of equation arises in a variety of settings in physics and signal
processing. However, current methods of solution involve discretizing the
differential equation directly by finite elements or finite differences, and
consequently suffer from the poor conditioning introduced by such schemes. Our
new method instead reformulates the equation as a collection of second-kind
integral equations defined on local subdomains. Each such equation can be
stably discretized. The boundary values of these local solutions are matched by
solving a banded linear system. The method of iterative refinement is then used
to increase the accuracy of the scheme. Iterative refinement requires applying
the differential operator to a function on the entire domain, for which we
provide an algorithm with linear cost. We illustrate the performance of our
method on several numerical examples.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05355</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Conflict Detection in Police Body-Worn Video</dc:title>
 <dc:creator>Letcher, Alistair</dc:creator>
 <dc:creator>Tri&#x161;ovi&#x107;, Jelena</dc:creator>
 <dc:creator>Cademartori, Collin</dc:creator>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Xu, Jason</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Automatic conflict detection has grown in relevance with the advent of
body-worn technology, but existing metrics such as turn-taking and overlap are
poor indicators of conflict in police-public interactions. Moreover, standard
techniques to compute them fall short when applied to such diversified and
noisy contexts. We develop a pipeline catered to this task combining adaptive
noise removal, non-speech filtering and new measures of conflict based on the
repetition and intensity of phrases in speech. We demonstrate the effectiveness
of our approach on body-worn audio data collected by the Los Angeles Police
Department.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, 1 table</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05356</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Construction of Rate-Compatible Punctured Polar (RCPP)
  Codes Using Hierarchical Puncturing</dc:title>
 <dc:creator>Hong, Song-Nam</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we present an efficient method to construct a good
rate-compatible punctured polar (RCPP) code. One of the major challenges on the
construction of a RCPP code is to design a common information set which is good
for all the codes in the family. In the proposed construction, a common
information set is simply optimized for the highest-rate punctured polar code
in the family and then, this set is updated for each other code by satisfying
the condition that information bits are unchanged during retransmissions. This
is enabled by presenting a novel hierarchical puncturing and information-copy
technique. To be specific, some information bits are copied to frozen-bit
channels, which yields an information-dependent frozen vector. Then, the
updated information sets are obtained by appropriately combining the common
information set and an information-dependent frozen vector. Moreover, the
impact of unknown frozen bits are resolved using the proposed hierarchical
puncturing. Simulation results demonstrate that the proposed RCPP code attains
a significant performance gain (about 2dB) over a benchmark RCPP code where
both codes use the same puncturing patterns but the latter uses the
conventional all-zero frozen vector. Therefore, the proposed method would be
crucial to construct a good RCPP code.
</dc:description>
 <dc:description>Comment: submitted to IEEE WCNC Polar Coding Workshop</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05365</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LIUBoost : Locality Informed Underboosting for Imbalanced Data
  Classification</dc:title>
 <dc:creator>Ahmed, Sajid</dc:creator>
 <dc:creator>Rayhan, Farshid</dc:creator>
 <dc:creator>Mahbub, Asif</dc:creator>
 <dc:creator>Jani, Md. Rafsan</dc:creator>
 <dc:creator>Shatabda, Swakkhar</dc:creator>
 <dc:creator>Farid, Dewan Md.</dc:creator>
 <dc:creator>Rahman, Chowdhury Mofizur</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The problem of class imbalance along with class-overlapping has become a
major issue in the domain of supervised learning. Most supervised learning
algorithms assume equal cardinality of the classes under consideration while
optimizing the cost function and this assumption does not hold true for
imbalanced datasets which results in sub-optimal classification. Therefore,
various approaches, such as undersampling, oversampling, cost-sensitive
learning and ensemble based methods have been proposed for dealing with
imbalanced datasets. However, undersampling suffers from information loss,
oversampling suffers from increased runtime and potential overfitting while
cost-sensitive methods suffer due to inadequately defined cost assignment
schemes. In this paper, we propose a novel boosting based method called
LIUBoost. LIUBoost uses under sampling for balancing the datasets in every
boosting iteration like RUSBoost while incorporating a cost term for every
instance based on their hardness into the weight update formula minimizing the
information loss introduced by undersampling. LIUBoost has been extensively
evaluated on 18 imbalanced datasets and the results indicate significant
improvement over existing best performing method RUSBoost.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05366</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Velocity variations at Columbia Glacier captured by particle filtering
  of oblique time-lapse images</dc:title>
 <dc:creator>Brinkerhoff, Douglas</dc:creator>
 <dc:creator>O'Neel, Shad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  We develop a probabilistic method for tracking glacier surface motion based
on time-lapse imagery, which works by sequentially resampling a stochastic
state-space model according to a likelihood determined through correlation
between reference and test images. The method is robust due to its natural
handling of periodic occlusion and its capacity to follow multiple hypothesis
displacements between images, and can improve estimates of velocity magnitude
and direction through the inclusion of observations from an arbitrary number of
cameras. We apply the method to an annual record of images from two cameras
near the terminus of Columbia Glacier. While the method produces velocities at
daily resolution, we verify our results by comparing eleven-day means to
TerraSar-X. We find that Columbia Glacier transitions between a winter state
characterized by moderate velocities and little temporal variability, to an
early summer speed-up in which velocities are sensitive to increases in melt-
and rainwater, to a fall slowdown, where velocities drop to below their winter
mean and become insensitive to external forcing, a pattern consistent with the
development and collapse of efficient and inefficient subglacial hydrologic
networks throughout the year.
</dc:description>
 <dc:description>Comment: 24 pages, 8 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05368</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel SDASS Descriptor for Fully Encoding the Information of 3D Local
  Surface</dc:title>
 <dc:creator>Zhao, Bao</dc:creator>
 <dc:creator>Le, Xinyi</dc:creator>
 <dc:creator>Xi, Juntong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Local feature description is a fundamental yet challenging task in 3D
computer vision. This paper proposes a novel descriptor, named Statistic of
Deviation Angles on Subdivided Space (SDASS), for comprehensive encoding
geometrical and spatial in-formation of local surface on Local Reference Axis
(LRA). The SDASS descriptor is generated by one geometrical feature and two
spatial features. Considering that surface normals, which are usually used for
encoding geometrical information of local surface, are vulnerable to various
nuisances, we propose a robust geometrical attribute, called Local Principal
Axis (LPA), to replace the normals for generating the geometrical feature of
our SDASS descriptor. For accurately encoding spatial information, we use two
spatial features for fully encoding the spatial information of a local surface
based on LRA. Besides, an improved LRA is proposed for increasing the
robustness of our SDASS to noise and varying mesh resolutions. The performance
of the SDASS descriptor is rigorously tested on several popular datasets.
Results show that our descriptor has a high descriptiveness and strong
robustness, and its performance outperform existing algorithms by a large
margin. Finally, the proposed descriptor is applied to 3D registration. The
accurate result further confirms the effectiveness of the SDASS method.
</dc:description>
 <dc:description>Comment: 14 pages, 13 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05374</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Kernel Machines using Deep Learning</dc:title>
 <dc:creator>Song, Huan</dc:creator>
 <dc:creator>Thiagarajan, Jayaraman J.</dc:creator>
 <dc:creator>Sattigeri, Prasanna</dc:creator>
 <dc:creator>Spanias, Andreas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Building highly non-linear and non-parametric models is central to several
state-of-the-art machine learning systems. Kernel methods form an important
class of techniques that induce a reproducing kernel Hilbert space (RKHS) for
inferring non-linear models through the construction of similarity functions
from data. These methods are particularly preferred in cases where the training
data sizes are limited and when prior knowledge of the data similarities is
available. Despite their usefulness, they are limited by the computational
complexity and their inability to support end-to-end learning with a
task-specific objective. On the other hand, deep neural networks have become
the de facto solution for end-to-end inference in several learning paradigms.
In this article, we explore the idea of using deep architectures to perform
kernel machine optimization, for both computational efficiency and end-to-end
inferencing. To this end, we develop the DKMO (Deep Kernel Machine
Optimization) framework, that creates an ensemble of dense embeddings using
Nystrom kernel approximations and utilizes deep learning to generate
task-specific representations through the fusion of the embeddings.
Intuitively, the filters of the network are trained to fuse information from an
ensemble of linear subspaces in the RKHS. Furthermore, we introduce the kernel
dropout regularization to enable improved training convergence. Finally, we
extend this framework to the multiple kernel case, by coupling a global fusion
layer with pre-trained deep kernel machines for each of the constituent
kernels. Using case studies with limited training data, and lack of explicit
feature sources, we demonstrate the effectiveness of our framework over
conventional model inferencing techniques.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05376</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sliced Wasserstein Distance for Learning Gaussian Mixture Models</dc:title>
 <dc:creator>Kolouri, Soheil</dc:creator>
 <dc:creator>Rohde, Gustavo K.</dc:creator>
 <dc:creator>Hoffmann, Heiko</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Gaussian mixture models (GMM) are powerful parametric tools with many
applications in machine learning and computer vision. Expectation maximization
(EM) is the most popular algorithm for estimating the GMM parameters. However,
EM guarantees only convergence to a stationary point of the log-likelihood
function, which could be arbitrarily worse than the optimal solution. Inspired
by the relationship between the negative log-likelihood function and the
Kullback-Leibler (KL) divergence, we propose an alternative formulation for
estimating the GMM parameters using the sliced Wasserstein distance, which
gives rise to a new algorithm. Specifically, we propose minimizing the
sliced-Wasserstein distance between the mixture model and the data distribution
with respect to the GMM parameters. In contrast to the KL-divergence, the
energy landscape for the sliced-Wasserstein distance is more well-behaved and
therefore more suitable for a stochastic gradient descent scheme to obtain the
optimal GMM parameters. We show that our formulation results in parameter
estimates that are more robust to random initializations and demonstrate that
it can estimate high-dimensional data distributions more faithfully than the EM
algorithm.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05379</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Systematic Literature Review of Experiments in Socially Assistive
  Robotics using Humanoid Robots</dc:title>
 <dc:creator>Erich, Floris</dc:creator>
 <dc:creator>Hirokawa, Masakazu</dc:creator>
 <dc:creator>Suzuki, Kenji</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We perform a Systematic Literature Review to discover how Humanoid robots are
being applied in Socially Assistive Robotics experiments. Our search returned
24 papers, from which 16 were included for closer analysis. To do this analysis
we used a conceptual framework inspired by Behavior-based Robotics. We were
interested in finding out which robot was used (most use the robot NAO), what
the goals of the application were (teaching, assisting, playing, instructing),
how the robot was controlled (manually in most of the experiments), what kind
of behaviors the robot exhibited (reacting to touch, pointing at body parts,
singing a song, dancing, among others), what kind of actuators the robot used
(always motors, sometimes speakers, hardly ever any other type of actuator) and
what kind of sensors the robot used (in many studies the robot did not use any
sensors at all, in others the robot frequently used camera and/or microphone).
The results of this study can be used for designing software frameworks
targeting Humanoid Socially Assistive Robotics, especially in the context of
Software Product Line Engineering projects.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05380</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bridging Source and Target Word Embeddings for Neural Machine
  Translation</dc:title>
 <dc:creator>Kuang, Shaohui</dc:creator>
 <dc:creator>Li, Junhui</dc:creator>
 <dc:creator>Xiong, Deyi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Neural machine translation systems encode a source sequence into a vector
from which a target sequence is generated via a decoder. Different from the
traditional statistical machine translation, source and target words are not
directly mapped to each other in translation rules. They are at the two ends of
a long information channel in the encoder-decoder neural network, separated by
source and target hidden states. This may lead to translations with
inconceivable word alignments. In this paper, we try to bridge source and
target word embeddings so as to shorten their distance. We propose three
strategies to bridge them: 1) a source state bridging model that moves source
word embeddings one step closer to their counterparts, 2) a target state
bridging model that explores relevant source word embeddings for target state
prediction, and 3) a direct link bridging model that directly connects source
and target word embeddings so as to minimize their discrepancy. Experiments and
analysis demonstrate that the proposed bridging models are able to
significantly improve quality of both translation and word alignments.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05391</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semiblind subgraph reconstruction in Gaussian graphical models</dc:title>
 <dc:creator>Xie, Tianpei</dc:creator>
 <dc:creator>Liu, Sijia</dc:creator>
 <dc:creator>Hero III, Alfred O.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Consider a social network where only a few nodes (agents) have meaningful
interactions in the sense that the conditional dependency graph over node
attribute variables (behaviors) is sparse. A company that can only observe the
interactions between its own customers will generally not be able to accurately
estimate its customers' dependency subgraph: it is blinded to any external
interactions of its customers and this blindness creates false edges in its
subgraph. In this paper we address the semiblind scenario where the company has
access to a noisy summary of the complementary subgraph connecting external
agents, e.g., provided by a consolidator. The proposed framework applies to
other applications as well, including field estimation from a network of awake
and sleeping sensors and privacy-constrained information sharing over social
subnetworks. We propose a penalized likelihood approach in the context of a
graph signal obeying a Gaussian graphical models (GGM). We use a convex-concave
iterative optimization algorithm to maximize the penalized likelihood.
</dc:description>
 <dc:description>Comment: 7 pages; 5 figures; 2017 5th IEEE Global Conference on Signal and
  Information Processing</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05397</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Epitome for Unravelling Generalized Hamming Network: A Fuzzy Logic
  Interpretation of Deep Learning</dc:title>
 <dc:creator>Fan, Lixin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper gives a rigorous analysis of trained Generalized Hamming
Networks(GHN) proposed by Fan (2017) and discloses an interesting finding about
GHNs, i.e., stacked convolution layers in a GHN is equivalent to a single yet
wide convolution layer. The revealed equivalence, on the theoretical side, can
be regarded as a constructive manifestation of the universal approximation
theorem Cybenko(1989); Hornik (1991). In practice, it has profound and
multi-fold implications. For network visualization, the constructed deep
epitomes at each layer provide a visualization of network internal
representation that does not rely on the input data. Moreover, deep epitomes
allows the direct extraction of features in just one step, without resorting to
regularized optimizations used in existing visualization tools.
</dc:description>
 <dc:description>Comment: 25 pages, 14 figures</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05400</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear system security -- detection and correction of adversarial
  attacks in the noise-free case</dc:title>
 <dc:creator>Tang, Zhanghan</dc:creator>
 <dc:creator>Kuijper, Margreta</dc:creator>
 <dc:creator>Chong, Michelle</dc:creator>
 <dc:creator>Mareels, Iven</dc:creator>
 <dc:creator>Leckie, Chris</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We address the problem of attack detection and attack correction for
multi-output discrete-time linear time-invariant systems under sensor attack.
More specifically, we focus on the situation where adversarial attack signals
are added to some of the system's output signals. A 'security index' is defined
to characterize the vulnerability of a system against such sensor attacks.
Methods to compute the security index are presented as are algorithms to detect
and correct for sensor attacks. The results are illustrated by examples
involving multiple sensors.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures; this paper also submitted to Automatica in Nov
  2017</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05401</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting Simple Neural Networks for Learning Representations of
  Knowledge Graphs</dc:title>
 <dc:creator>Ravishankar, Srinivas</dc:creator>
 <dc:creator>Chandrahas</dc:creator>
 <dc:creator>Talukdar, Partha Pratim</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We address the problem of learning vector representations for entities and
relations in Knowledge Graphs (KGs) for Knowledge Base Completion (KBC). This
problem has received significant attention in the past few years and multiple
methods have been proposed. Most of the existing methods in the literature use
a predefined characteristic scoring function for evaluating the correctness of
KG triples. These scoring functions distinguish correct triples (high score)
from incorrect ones (low score). However, their performance vary across
different datasets. In this work, we demonstrate that a simple neural network
based score function can consistently achieve near start-of-the-art performance
on multiple datasets. We also quantitatively demonstrate biases in standard
benchmark datasets, and highlight the need to perform evaluation spanning
various datasets.
</dc:description>
 <dc:description>Comment: 7 pages, submitted to and accepted in Automated Knowledge Base
  Construction (AKBC) Workshop 2017, at NIPS 2017</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05403</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Combinatorial Group Testing for Low-Energy Massive Random Access</dc:title>
 <dc:creator>Inan, Huseyin A.</dc:creator>
 <dc:creator>Kairouz, Peter</dc:creator>
 <dc:creator>Ozgur, Ayfer</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present random access schemes for machine-type communication where a
massive number of low-energy wireless devices want to occasionally transmit
short information packets. We focus on the device discovery problem, with
extensions to joint discovery and data transmission as well as data
transmission without communicating device identities. We formulate this problem
as a combinatorial group testing one, where the goal is to exactly identify the
set of at most $d$ defective items from a pool of $n$ items. We translate the
energy constraint at the physical layer to a constraint on the number of tests
each item can participate in, and study the resulting &quot;sparse&quot; combinatorial
group testing problem.
  In our sparse setting, we restrict the number of tests each item can
participate in by $w_{\max}$. It is easy to observe that if $w_{\max} \leq d$,
then we must have $t=n$; i.e., testing every item individually is optimal. We
show that if $w_{\max}=d+1$, the number of tests decreases suddenly from $t=n$
to $t = (d+1)\sqrt{n}$. More generally, if $w_{\max}=ld+1$ for any positive
integer $l$ such that $ld+1 \leq \sqrt[l+1]{n}$, we can achieve
$t=(ld+1)n^{1/(l+1)}$ using Kautz and Singleton's construction with a
particular choice of field size. We also prove a nearly matching lower bound
which shows that $t = \Omega(d^{2/l+1}n^{1/(l+1)})$. This shows that in the
sparse setting $t$ is a fractional power of $n$, rather than logarithmic in $n$
as in the classical setting.
  Since encoding and decoding efficiency can be just as important as energy
efficiency, we demonstrate that our construction can be decoded in (poly$(d) +
O(t)$)-time and each entry in any codeword can be computed in space poly$(\log
n)$. This shows that our construction not only (nearly) achieves the
fundamental lower bound, but also does that with a favorable encoding and
decoding complexity.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05406</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fast and Robust TSVM for Pattern Classification</dc:title>
 <dc:creator>Gao, Bin-Bin</dc:creator>
 <dc:creator>Wang, Jian-Jun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Twin support vector machine~(TSVM) is a powerful learning algorithm by
solving a pair of smaller SVM-type problems. However, there are still some
specific issues waiting to be solved when it faces with some real applications,
\emph{e.g}, low efficiency and noise data. In this paper, we propose a Fast and
Robust TSVM~(FR-TSVM) to deal with these issues above. In FR-TSVM, we propose
an effective fuzzy membership function to ease the effects of noisy inputs. We
apply the fuzzy membership to each input instance and reformulate the TSVMs
such that different input instances can make different contributions to the
learning of the separating hyperplanes. To further speed up the training
procedure, we develop an efficient coordinate descent algorithm with shirking
to solve the involved a pair of quadratic programming problems (QPPs) of
FR-TSVM. Moreover, theoretical foundations of the proposed model are analyzed
in details. The experimental results on several artificial and benchmark
datasets indicate that the FR-TSVM not only obtains the fast learning speed but
also shows the robust classification performance.
</dc:description>
 <dc:description>Comment: 14 pages, Under Review</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05407</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Influential Sample Selection: A Graph Signal Processing Approach</dc:title>
 <dc:creator>Anirudh, Rushil</dc:creator>
 <dc:creator>Thiagarajan, Jayaraman J.</dc:creator>
 <dc:creator>Sridhar, Rahul</dc:creator>
 <dc:creator>Bremer, Timo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  With the growing complexity of machine learning techniques, understanding the
functioning of black-box models is more important than ever. A recently popular
strategy towards interpretability is to generate explanations based on examples
-- called influential samples -- that have the largest influence on the model's
observed behavior. However, for such an analysis, we are confronted with a
plethora of influence metrics. While each of these metrics provide varying
levels of representativeness and diversity, existing approaches implicitly
couple the definition of influence to their sample selection algorithm, thereby
making it challenging to generalize to specific analysis needs. In this paper,
we propose a generic approach to influential sample selection, which analyzes
the influence metric as a function on a graph constructed using the samples. We
show that samples which are critical to recovering the high-frequency content
of the function correspond to the most influential samples. Our approach
decouples the influence metric from the actual sample selection technique, and
hence can be used with any type of task-specific influence. Using experiments
in prototype selection, and semi-supervised classification, we show that, even
with popularly used influence metrics, our approach can produce superior
results in comparison to state-of-the-art approaches. Furthermore, we
demonstrate how a novel influence metric can be used to recover the influence
structure in characterizing the decision surface, and recovering corrupted
labels efficiently.
</dc:description>
 <dc:description>Comment: Technical Report</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05408</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Neural Networks as Weighted Language Recognizers</dc:title>
 <dc:creator>Chen, Yining</dc:creator>
 <dc:creator>Gilroy, Sorcha</dc:creator>
 <dc:creator>Knight, Kevin</dc:creator>
 <dc:creator>May, Jonathan</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We investigate computational complexity of questions of various problems for
simple recurrent neural networks (RNNs) as formal models for recognizing
weighted languages. We focus on the single-layer, ReLU-activation,
rational-weight RNNs with softmax, which are commonly used in natural language
processing applications. We show that most problems for such RNNs are
undecidable, including consistency, equivalence, minimization, and finding the
highest-weighted string. However, for consistent RNNs the last problem becomes
decidable, although the solution can be exponentially long. If additionally the
string is limited to polynomial length, the problem becomes NP-complete and
APX-hard. In summary, this shows that approximations and heuristic algorithms
are necessary in practical applications of those RNNs. We also consider RNNs as
unweighted language recognizers and situate RNNs between Turing Machines and
Random-Access Machines regarding their real-time recognition powers.
</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05408</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05410</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Programming Bots by Synthesizing Natural Language Expressions into API
  Invocations</dc:title>
 <dc:creator>Zamanirad, Shayan</dc:creator>
 <dc:creator>Benatallah, Boualem</dc:creator>
 <dc:creator>Barukh, Moshe Chai</dc:creator>
 <dc:creator>Casati, Fabio</dc:creator>
 <dc:creator>Rodriguez, Carlos</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  At present, bots are still in their preliminary stages of development. Many
are relatively simple, or developed ad-hoc for a very specific use-case. For
this reason, they are typically programmed manually, or utilize
machine-learning classifiers to interpret a fixed set of user utterances. In
reality, real world conversations with humans require support for dynamically
capturing users expressions. Moreover, bots will derive immeasurable value by
programming them to invoke APIs for their results. Today, within the Web and
Mobile development community, complex applications are being stringed together
with a few lines of code -- all made possible by APIs. Yet, developers today
are not as empowered to program bots in much the same way. To overcome this, we
introduce BotBase, a bot programming platform that dynamically synthesizes
natural language user expressions into API invocations. Our solution is two
faceted: Firstly, we construct an API knowledge graph to encode and evolve
APIs; secondly, leveraging the above we apply techniques in NLP, ML and Entity
Recognition to perform the required synthesis from natural language user
expressions into API calls.
</dc:description>
 <dc:description>Comment: The paper is published at ASE 2017 (The 32nd IEEE/ACM International
  Conference on Automated Software Engineering)</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05410</dc:identifier>
 <dc:identifier>Proceedings of the 32nd IEEE/ACM International Conference on
  Automated Software Engineering (ASE), 2017, 832-837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05411</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Z-Forcing: Training Stochastic Recurrent Networks</dc:title>
 <dc:creator>Goyal, Anirudh</dc:creator>
 <dc:creator>Sordoni, Alessandro</dc:creator>
 <dc:creator>C&#xf4;t&#xe9;, Marc-Alexandre</dc:creator>
 <dc:creator>Ke, Nan Rosemary</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many efforts have been devoted to training generative latent variable models
with autoregressive decoders, such as recurrent neural networks (RNN).
Stochastic recurrent models have been successful in capturing the variability
observed in natural sequential data such as speech. We unify successful ideas
from recently proposed architectures into a stochastic recurrent model: each
step in the sequence is associated with a latent variable that is used to
condition the recurrent dynamics for future steps. Training is performed with
amortized variational inference where the approximate posterior is augmented
with a RNN that runs backward through the sequence. In addition to maximizing
the variational lower bound, we ease training of the latent variables by adding
an auxiliary cost which forces them to reconstruct the state of the backward
recurrent network. This provides the latent variables with a task-independent
objective that enhances the performance of the overall model. We found this
strategy to perform better than alternative approaches such as KL annealing.
Although being conceptually simple, our model achieves state-of-the-art results
on standard speech benchmarks such as TIMIT and Blizzard and competitive
performance on sequential MNIST. Finally, we apply our model to language
modeling on the IMDB dataset where the auxiliary cost helps in learning
interpretable latent variables. Source Code:
\url{https://github.com/anirudh9119/zforcing_nips17}
</dc:description>
 <dc:description>Comment: To appear in NIPS'17</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05412</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IKBT: solving closed-form Inverse Kinematics with Behavior Tree</dc:title>
 <dc:creator>Zhang, Dianmu</dc:creator>
 <dc:creator>Hannaford, Blake</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Serial robot arms have complicated kinematic equations which must be solved
to write effective arm planning and control software (the Inverse Kinematics
Problem). Existing software packages for inverse kinematics often rely on
numerical methods which have significant shortcomings. Here we report a new
symbolic inverse kinematics solver which overcomes the limitations of numerical
methods, and the shortcomings of previous symbolic software packages. We
integrate Behavior Trees, an execution planning framework previously used for
controlling intelligent robot behavior, to organize the equation solving
process, and a modular architecture for each solution technique. The system
successfully solved, generated a LaTex report, and generated a Python code
template for 18 out of 19 example robots of 4-6 DOF. The system is readily
extensible, maintainable, and multi-platform with few dependencies. The
complete package is available with a Modified BSD license on Github.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05415</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DNA-GAN: Learning Disentangled Representations from Multi-Attribute
  Images</dc:title>
 <dc:creator>Xiao, Taihong</dc:creator>
 <dc:creator>Hong, Jiapeng</dc:creator>
 <dc:creator>Ma, Jinwen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Disentangling factors of variation has always been a challenging problem in
representation learning. Existing algorithms suffer from many limitations, such
as unpredictable disentangling factors, bad quality of generated images from
encodings, lack of identity information, etc. In this paper, we propose a
supervised algorithm called DNA-GAN trying to disentangle different attributes
of images. The latent representations of images are DNA-like, in which each
individual piece represents an independent factor of variation. By annihilating
the recessive piece and swapping a certain piece of two latent representations,
we obtain another two different representations which could be decoded into
images. In order to obtain realistic images and also disentangled
representations, we introduce the discriminator for adversarial training.
Experiments on Multi-PIE and CelebA datasets demonstrate the effectiveness of
our method and the advantage of overcoming limitations existing in other
methods.
</dc:description>
 <dc:description>Comment: submitted to ICLR 2018</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05417</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Anti-Jamming Performance of the NR-DCSK System</dc:title>
 <dc:creator>Van Nguyen, Binh</dc:creator>
 <dc:creator>Jung, Hyoyoung</dc:creator>
 <dc:creator>Kim, Kiseon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the anti-jamming performance of the NR-DCSK system.
We consider several practical jamming environments including broad-band jamming
(BBJ), partial-time jamming (PTJ), tone jamming (TJ) consisting of both
single-tone and multi-tone, and sweep jamming (SWJ). We first analytically
derived the bit error rates of the considered system under the BBJ and the PTJ
environments in closed-form expressions. Our derived results show that the
system performances under these two jamming environments are enhanced as $P$
increases, where $P$ is the parameter of the NR-DCSK modulation scheme denoting
the number of times a chaotic sample is repeated. In addition, our results
demonstrate that for the PTJ, the optimal value of the jamming factor is close
to zero when the jamming power is small, however, it increases and approaches
one as the jamming power enlarges. We then investigate the performance of the
considered system under the TJ and the SWJ environments via Monte-Carlo
simulations. Our simulations show that single-tone jamming causes a more
significant performance degradation than that provided by multi-tone jamming
counterparts. Moreover, we point out that the system performance is
significantly degraded when the starting frequency of the sweep jammer is close
to the carrier frequency of the transmitted chaotic signals, the sweep
bandwidth is small, and the sweep time is half of the transmitted bit duration.
</dc:description>
 <dc:description>Comment: 7 pages, 8 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05421</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Physical Layer Security Schemes for Full-Duplex Cooperative Systems:
  State of the Art and Beyond</dc:title>
 <dc:creator>Van Nguyen, Binh</dc:creator>
 <dc:creator>Jung, Hyoyoung</dc:creator>
 <dc:creator>Kim, Kiseon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Due to the broadcast nature of wireless medium, wireless communication is
highly vulnerable to eavesdropping attack. Traditionally, secure wireless data
transmission has relied on cryptographic techniques at the network layer which
incur high computational power and complexity. As an alternative, physical
layer security (PLS) is emerging as a promising paradigm to protect wireless
systems by exploiting the physical characteristics of the wireless channels.
Among various PLS approaches, the one based on cooperative communication is
favorable and has got a lot of interest from the research community. Although
PLS schemes with half-duplex relays have been extensively discovered, the issue
of PLS in cooperative systems with full-duplex (FD) relays is far from being
comprehensively understood. In this paper, we first present the state of the
art on PLS approaches proposed for FD cooperative systems. We then provide a
case study in which a source-based jamming scheme is proposed to enhance the
secrecy performance of a cooperative system with an untrusted FD relay.
Finally, we outline several interesting yet challenging future research
problems in this topic.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, 1 table</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05429</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modular Resource Centric Learning for Workflow Performance Prediction</dc:title>
 <dc:creator>Singh, Alok</dc:creator>
 <dc:creator>Nguyen, Mai</dc:creator>
 <dc:creator>Purawat, Shweta</dc:creator>
 <dc:creator>Crawl, Daniel</dc:creator>
 <dc:creator>Altintas, Ilkay</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Workflows provide an expressive programming model for fine-grained control of
large-scale applications in distributed computing environments. Accurate
estimates of complex workflow execution metrics on large-scale machines have
several key advantages. The performance of scheduling algorithms that rely on
estimates of execution metrics degrades when the accuracy of predicted
execution metrics decreases. This in-progress paper presents a technique being
developed to improve the accuracy of predicted performance metrics of
large-scale workflows on distributed platforms. The central idea of this work
is to train resource-centric machine learning agents to capture complex
relationships between a set of program instructions and their performance
metrics when executed on a specific resource. This resource-centric view of a
workflow exploits the fact that predicting execution times of sub-modules of a
workflow requires monitoring and modeling of a few dynamic and static features.
We transform the input workflow that is essentially a directed acyclic graph of
actions into a Physical Resource Execution Plan (PREP). This transformation
enables us to model an arbitrarily complex workflow as a set of simpler
programs running on physical nodes. We delegate a machine learning model to
capture performance metrics for each resource type when it executes different
program instructions under varying degrees of resource contention. Our
algorithm takes the prediction metrics from each resource agent and composes
the overall workflow performance metrics by utilizing the structure of the
corresponding Physical Resource Execution Plan.
</dc:description>
 <dc:description>Comment: This paper was presented at: 6th Workshop on Big Data Analytics:
  Challenges, and Opportunities (BDAC) at the 27th IEEE/ACM International
  Conference for High Performance Computing, Networking, Storage, and Analysis
  (SC 2015)</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05431</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Inception-Residual Laplacian Pyramid Networks for Accurate Single
  Image Super-Resolution</dc:title>
 <dc:creator>Tang, Yongliang</dc:creator>
 <dc:creator>Gong, Weiguo</dc:creator>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Li, Weihong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With exploiting contextual information over large image regions in an
efficient way, the deep convolutional neural network has shown an impressive
performance for single image super-resolution (SR). In this paper, we propose a
deep convolutional network by cascading the well-designed inception-residual
blocks within the deep Laplacian pyramid framework to progressively restore the
missing high-frequency details of high-resolution (HR) images. By optimizing
our network structure, the trainable depth of the proposed network gains a
significant improvement, which in turn improves super-resolving accuracy. With
our network depth increasing, however, the saturation and degradation of
training accuracy continues to be a critical problem. As regard to this, we
propose an effective two-stage training strategy, in which we firstly use
images downsampled from the ground-truth HR images as the optimal objective to
train the inception-residual blocks in each pyramid level with an extremely
high learning rate enabled by gradient clipping, and then the ground-truth HR
images are used to fine-tune all the pre-trained inception-residual blocks for
obtaining the final SR model. Furthermore, we present a new loss function
operating in both image space and local rank space to optimize our network for
exploiting the contextual information among different output components.
Extensive experiments on benchmark datasets validate that the proposed method
outperforms existing state-of-the-art SR methods in terms of the objective
evaluation as well as the visual quality.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05433</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Sequential Neural Encoder with Latent Structured Description for
  Modeling Sentences</dc:title>
 <dc:creator>Ruan, Yu-Ping</dc:creator>
 <dc:creator>Chen, Qian</dc:creator>
 <dc:creator>Ling, Zhen-Hua</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we propose a sequential neural encoder with latent structured
description (SNELSD) for modeling sentences. This model introduces latent
chunk-level representations into conventional sequential neural encoders, i.e.,
recurrent neural networks (RNNs) with long short-term memory (LSTM) units, to
consider the compositionality of languages in semantic modeling. An SNELSD
model has a hierarchical structure that includes a detection layer and a
description layer. The detection layer predicts the boundaries of latent word
chunks in an input sentence and derives a chunk-level vector for each word. The
description layer utilizes modified LSTM units to process these chunk-level
vectors in a recurrent manner and produces sequential encoding outputs. These
output vectors are further concatenated with word vectors or the outputs of a
chain LSTM encoder to obtain the final sentence representation. All the model
parameters are learned in an end-to-end manner without a dependency on
additional text chunking or syntax parsing. A natural language inference (NLI)
task and a sentiment analysis (SA) task are adopted to evaluate the performance
of our proposed model. The experimental results demonstrate the effectiveness
of the proposed SNELSD model on exploring task-dependent chunking patterns
during the semantic modeling of sentences. Furthermore, the proposed method
achieves better performance than conventional chain LSTMs and tree-structured
LSTMs on both tasks.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Audio, Speech, and Language
  Processing</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05433</dc:identifier>
 <dc:identifier>doi:10.1109/TASLP.2017.2773198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05435</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TorusE: Knowledge Graph Embedding on a Lie Group</dc:title>
 <dc:creator>Ebisu, Takuma</dc:creator>
 <dc:creator>Ichise, Ryutaro</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Knowledge graphs are useful for many artificial intelligence (AI) tasks.
However, knowledge graphs often have missing facts. To populate the graphs,
knowledge graph embedding models have been developed. Knowledge graph embedding
models map entities and relations in a knowledge graph to a vector space and
predict unknown triples by scoring candidate triples. TransE is the first
translation-based method and it is well known because of its simplicity and
efficiency for knowledge graph completion. It employs the principle that the
differences between entity embeddings represent their relations. The principle
seems very simple, but it can effectively capture the rules of a knowledge
graph. However, TransE has a problem with its regularization. TransE forces
entity embeddings to be on a sphere in the embedding vector space. This
regularization warps the embeddings and makes it difficult for them to fulfill
the abovementioned principle. The regularization also affects adversely the
accuracies of the link predictions. On the other hand, regularization is
important because entity embeddings diverge by negative sampling without it.
This paper proposes a novel embedding model, TorusE, to solve the
regularization problem. The principle of TransE can be defined on any Lie
group. A torus, which is one of the compact Lie groups, can be chosen for the
embedding space to avoid regularization. To the best of our knowledge, TorusE
is the first model that embeds objects on other than a real or complex vector
space, and this paper is the first to formally discuss the problem of
regularization of TransE. Our approach outperforms other state-of-the-art
approaches such as TransE, DistMult and ComplEx on a standard link prediction
task. We show that TorusE is scalable to large-size knowledge graphs and is
faster than the original TransE.
</dc:description>
 <dc:description>Comment: accepted for AAAI-18</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05441</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CTRL+Z: Recovering Anonymized Social Graphs</dc:title>
 <dc:creator>Zhang, Yang</dc:creator>
 <dc:creator>Humbert, Mathias</dc:creator>
 <dc:creator>Surma, Bartlomiej</dc:creator>
 <dc:creator>Manoharan, Praveen</dc:creator>
 <dc:creator>Vreeken, Jilles</dc:creator>
 <dc:creator>Backes, Michael</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Social graphs derived from online social interactions contain a wealth of
information that is nowadays extensively used by both industry and academia.
However, due to the sensitivity of information contained in such social graphs,
they need to be properly anonymized before release. Most of the graph
anonymization techniques that have been proposed to sanitize social graph data
rely on the perturbation of the original graph's structure, more specifically
of its edge set. In this paper, we identify a fundamental weakness of these
edge-based anonymization mechanisms and exploit it to recover most of the
original graph structure.
  First, we propose a method to quantify an edge's plausibility in a given
graph by relying on graph embedding. Our experiments on three real-life social
network datasets under two widely known graph anonymization mechanisms
demonstrate that this method can very effectively detect fake edges with AUC
values above 0.95 in most cases. Second, by relying on Gaussian mixture models
and maximum a posteriori probability estimation, we derive an optimal decision
rule to detect whether an edge is fake based on the observed graph data. We
further demonstrate that this approach concretely jeopardizes the privacy
guarantees provided by the considered graph anonymization mechanisms. To
mitigate this vulnerability, we propose a method to generate fake edges as
plausible as possible given the graph structure and incorporate it into the
existing anonymization mechanisms. Our evaluation demonstrates that the
enhanced mechanisms not only decrease the chances of graph recovery (with AUC
dropping by up to 35%), but also provide even better graph utility than
existing anonymization methods.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05443</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human and Machine Speaker Recognition Based on Short Trivial Events</dc:title>
 <dc:creator>Zhang, Miao</dc:creator>
 <dc:creator>Kang, Xiaofei</dc:creator>
 <dc:creator>Wang, Yanqing</dc:creator>
 <dc:creator>Li, Lantian</dc:creator>
 <dc:creator>Tang, Zhiyuan</dc:creator>
 <dc:creator>Dai, Haisheng</dc:creator>
 <dc:creator>Wang, Dong</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Trivial events are ubiquitous in human to human conversations, e.g., cough,
laugh and sniff. Compared to regular speech, these trivial events are usually
short and unclear, thus generally regarded as not speaker discriminative and so
are largely ignored by present speaker recognition research. However, these
trivial events are highly valuable in some particular circumstances such as
forensic examination, as they are less subjected to intentional change, so can
be used to discover the genuine speaker from disguised speech. In this paper,
we collect a trivial event speech database that involves 75 speakers and 6
types of events, and report preliminary speaker recognition results on this
database, by both human listeners and machines. Particularly, the deep feature
learning technique recently proposed by our group is utilized to analyze and
recognize the trivial events, which leads to acceptable equal error rates
(EERs) despite the extremely short durations (0.2-0.5 seconds) of these events.
Comparing different types of events, 'hmm' seems more speaker discriminative.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2018-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05444</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Real-Time Multi-View Eye Tracking</dc:title>
 <dc:creator>Arar, Nuri Murat</dc:creator>
 <dc:creator>Thiran, Jean-Philippe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Despite significant advances in improving the gaze tracking accuracy under
controlled conditions, the tracking robustness under real-world conditions,
such as large head pose and movements, use of eyeglasses, illumination and eye
type variations, remains a major challenge in eye tracking. In this paper, we
revisit this challenge and introduce a real-time multi-camera eye tracking
framework to improve the tracking robustness. First, differently from previous
work, we design a multi-view tracking setup that allows for acquiring multiple
eye appearances simultaneously. Leveraging multi-view appearances enables to
more reliably detect gaze features under challenging conditions, particularly
when they are obstructed in conventional single-view appearance due to large
head movements or eyewear effects. The features extracted on various
appearances are then used for estimating multiple gaze outputs. Second, we
propose to combine estimated gaze outputs through an adaptive fusion mechanism
to compute user's overall point of regard. The proposed mechanism firstly
determines the estimation reliability of each gaze output according to user's
momentary head pose and predicted gazing behavior, and then performs a
reliability-based weighted fusion. We demonstrate the efficacy of our framework
with extensive simulations and user experiments on a collected dataset
featuring 20 subjects. Our results show that in comparison with
state-of-the-art eye trackers, the proposed framework provides not only a
significant enhancement in accuracy but also a notable robustness. Our
prototype system runs at 30 frames-per-second (fps) and achieves 1 degree
accuracy under challenging experimental scenarios, which makes it suitable for
applications demanding high accuracy and robustness.
</dc:description>
 <dc:description>Comment: Organisational changes in the main msp and supplementary info.
  Results unchanged. Main msp: 14 pages, 15 figures. Supplementary: 2 tables, 1
  figure. Under review for an IEEE transactions publication</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05447</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emotional End-to-End Neural Speech Synthesizer</dc:title>
 <dc:creator>Lee, Younggun</dc:creator>
 <dc:creator>Rabiee, Azam</dc:creator>
 <dc:creator>Lee, Soo-Young</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  In this paper, we introduce an emotional speech synthesizer based on the
recent end-to-end neural model, named Tacotron. Despite its benefits, we found
that the original Tacotron suffers from the exposure bias problem and
irregularity of the attention alignment. Later, we address the problem by
utilization of context vector and residual connection at recurrent neural
networks (RNNs). Our experiments showed that the model could successfully train
and generate speech for given emotion labels.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05448</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lattice Rescoring Strategies for Long Short Term Memory Language Models
  in Speech Recognition</dc:title>
 <dc:creator>Kumar, Shankar</dc:creator>
 <dc:creator>Nirschl, Michael</dc:creator>
 <dc:creator>Holtmann-Rice, Daniel</dc:creator>
 <dc:creator>Liao, Hank</dc:creator>
 <dc:creator>Suresh, Ananda Theertha</dc:creator>
 <dc:creator>Yu, Felix</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent neural network (RNN) language models (LMs) and Long Short Term
Memory (LSTM) LMs, a variant of RNN LMs, have been shown to outperform
traditional N-gram LMs on speech recognition tasks. However, these models are
computationally more expensive than N-gram LMs for decoding, and thus,
challenging to integrate into speech recognizers. Recent research has proposed
the use of lattice-rescoring algorithms using RNNLMs and LSTMLMs as an
efficient strategy to integrate these models into a speech recognition system.
In this paper, we evaluate existing lattice rescoring algorithms along with new
variants on a YouTube speech recognition task. Lattice rescoring using LSTMLMs
reduces the word error rate (WER) for this task by 8\% relative to the WER
obtained using an N-gram LM.
</dc:description>
 <dc:description>Comment: Accepted at ASRU 2017</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05448</dc:identifier>
 <dc:identifier>Proceedings of ASRU 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05456</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Approaches for Initial Access in mmWave 5G Systems</dc:title>
 <dc:creator>Soleimani, Hossein</dc:creator>
 <dc:creator>Parada, Ra&#xf9;l</dc:creator>
 <dc:creator>Tomasin, Stefano</dc:creator>
 <dc:creator>Zorzi, Michele</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  mmWave communication systems overcome high attenuation by using multiple
antennas at both the transmitter and the receiver to perform beamforming. Upon
entrance of a user equipment (UE) into a cell a scanning procedure must be
performed by the base station in order to find the UE, in what is known as
initial access (IA) procedure. In this paper we start from the observation that
UEs are more likely to enter from some directions than from others, as they
typically move along streets, while other movements are impossible due to the
presence of obstacles. Moreover, users are entering with a given time
statistics, for example described by inter-arrival times. In this context we
propose scanning strategies for IA that take into account the entrance
statistics. In particular, we propose two approaches: a memory-less random
illumination (MLRI) algorithm and a statistic and memory-based illumination
(SMBI) algorithm. The MLRI algorithm scans a random sector in each slot, based
on the statistics of sector entrance, without memory. The SMBI algorithm
instead scans sectors in a deterministic sequence selected according to the
statistics of sector entrance and time of entrance, and taking into account the
fact that the user has not yet been discovered (thus including memory). We
assess the performance of the proposed methods in terms of average discovery
time.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05457</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hibikino-Musashi@Home 2017 Team Description Paper</dc:title>
 <dc:creator>Hori, Sansei</dc:creator>
 <dc:creator>Ishida, Yutaro</dc:creator>
 <dc:creator>Kiyama, Yuta</dc:creator>
 <dc:creator>Tanaka, Yuichiro</dc:creator>
 <dc:creator>Kuroda, Yuki</dc:creator>
 <dc:creator>Hisano, Masataka</dc:creator>
 <dc:creator>Imamura, Yuto</dc:creator>
 <dc:creator>Himaki, Tomotaka</dc:creator>
 <dc:creator>Yoshimoto, Yuma</dc:creator>
 <dc:creator>Aratani, Yoshiya</dc:creator>
 <dc:creator>Hashimoto, Kouhei</dc:creator>
 <dc:creator>Iwamoto, Gouki</dc:creator>
 <dc:creator>Fujita, Hiroto</dc:creator>
 <dc:creator>Morie, Takashi</dc:creator>
 <dc:creator>Tamukoh, Hakaru</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Our team Hibikino-Musashi@Home was founded in 2010. It is based in Kitakyushu
Science and Research Park, Japan. Since 2010, we have participated in the
RoboCup@Home Japan open competition open-platform league every year. Currently,
the Hibikino-Musashi@Home team has 24 members from seven different laboratories
based in the Kyushu Institute of Technology. Our home-service robots are used
as platforms for both education and implementation of our research outcomes. In
this paper, we introduce our team and the technologies that we have implemented
in our robots.
</dc:description>
 <dc:description>Comment: 8 pages; RoboCup 2017 @Home Open Platform League team description
  paper</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05458</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Public Image Database for Benchmark of Plant Seedling Classification
  Algorithms</dc:title>
 <dc:creator>Giselsson, Thomas Mosgaard</dc:creator>
 <dc:creator>J&#xf8;rgensen, Rasmus Nyholm</dc:creator>
 <dc:creator>Jensen, Peter Kryger</dc:creator>
 <dc:creator>Dyrmann, Mads</dc:creator>
 <dc:creator>Midtiby, Henrik Skov</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A database of images of approximately 960 unique plants belonging to 12
species at several growth stages is made publicly available. It comprises
annotated RGB images with a physical resolution of roughly 10 pixels per mm. To
standardise the evaluation of classification results obtained with the
database, a benchmark based on $f_{1}$ scores is proposed. The dataset is
available at https://vision.eng.au.dk/plant-seedlings-dataset
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05462</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Machine Learning Approach to Modeling Human Migration</dc:title>
 <dc:creator>Robinson, Caleb</dc:creator>
 <dc:creator>Dilkina, Bistra</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Human migration is a type of human mobility, where a trip involves a person
moving with the intention of changing their home location. Predicting human
migration as accurately as possible is important in city planning applications,
international trade, spread of infectious diseases, conservation planning, and
public policy development. Traditional human mobility models, such as gravity
models or the more recent radiation model, predict human mobility flows based
on population and distance features only. These models have been validated on
commuting flows, a different type of human mobility, and are mainly used in
modeling scenarios where large amounts of prior ground truth mobility data are
not available. One downside of these models is that they have a fixed form and
are therefore not able to capture more complicated migration dynamics. We
propose machine learning models that are able to incorporate any number of
exogenous features, to predict origin/destination human migration flows. Our
machine learning models outperform traditional human mobility models on a
variety of evaluation metrics, both in the task of predicting migrations
between US counties as well as international migrations. In general, predictive
machine learning models of human migration will provide a flexible base with
which to model human migration under different what-if conditions, such as
potential sea level rise or population growth scenarios.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05467</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aicyber's System for NLPCC 2017 Shared Task 2: Voting of Baselines</dc:title>
 <dc:creator>Steven, Du</dc:creator>
 <dc:creator>Zhang, Xi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents Aicyber's system for NLPCC 2017 shared task 2. It is
formed by a voting of three deep learning based system trained on
character-enhanced word vectors and a well known bag-of-word model.
</dc:description>
 <dc:description>Comment: 6 pages, 2 tables</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05468</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking Typological Traits of Uralic Languages in Distributed Language
  Representations</dc:title>
 <dc:creator>Bjerva, Johannes</dc:creator>
 <dc:creator>Augenstein, Isabelle</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Although linguistic typology has a long history, computational approaches
have only recently gained popularity. The use of distributed representations in
computational linguistics has also become increasingly popular. A recent
development is to learn distributed representations of language, such that
typologically similar languages are spatially close to one another. Although
empirical successes have been shown for such language representations, they
have not been subjected to much typological probing. In this paper, we first
look at whether this type of language representations are empirically useful
for model transfer between Uralic languages in deep neural networks. We then
investigate which typological features are encoded in these representations by
attempting to predict features in the World Atlas of Language Structures, at
various stages of fine-tuning of the representations. We focus on Uralic
languages, and find that some typological traits can be automatically inferred
with accuracies well above a strong baseline.
</dc:description>
 <dc:description>Comment: Finnish abstract included in the paper</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05469</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic Distributed Edge-Coloring with Fewer Colors</dc:title>
 <dc:creator>Ghaffari, Mohsen</dc:creator>
 <dc:creator>Kuhn, Fabian</dc:creator>
 <dc:creator>Maus, Yannic</dc:creator>
 <dc:creator>Uitto, Jara</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present a deterministic distributed algorithm, in the LOCAL model, that
computes a $(1+o(1))\Delta$-edge-coloring in polylogarithmic-time, so long as
the maximum degree $\Delta=\tilde{\Omega}(\log n)$. For smaller $\Delta$, we
give a polylogarithmic-time $3\Delta/2$-edge-coloring. These are the first
deterministic algorithms to go below the natural barrier of $2\Delta-1$ colors,
and they improve significantly on the recent polylogarithmic-time
$(2\Delta-1)(1+o(1))$-edge-coloring of Ghaffari and Su [SODA'17] and the
$(2\Delta-1)$-edge-coloring of Fischer, Ghaffari, and Kuhn [FOCS'17],
positively answering the main open question of the latter. The key technical
ingredient of our algorithm is a simple and novel gradual packing of
judiciously chosen near-maximum matchings, each of which becomes one of the
color classes.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05471</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Utility of Context (or the Lack Thereof) for Object Detection</dc:title>
 <dc:creator>Barnea, Ehud</dc:creator>
 <dc:creator>Ben-Shahar, Ohad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The recurring context in which objects appear holds valuable information that
can be employed to predict their existence. This intuitive observation indeed
led many researchers to endow appearance-based detectors with explicit
reasoning about context. The underlying thesis suggests that with stronger
contextual relations, the better improvement in detection capacity one can
expect from such a combined approach. In practice, however, the observed
improvement in many case is modest at best, and often only marginal. In this
work we seek to understand this phenomenon better, in part by pursuing an
opposite approach. Instead of going from context to detection score, we
formulate the score as a function of standard detector results and contextual
relations, an approach that allows to treat the utility of context as an
optimization problem in order to obtain the largest gain possible from
considering context in the first place. Analyzing different contextual
relations reveals the most helpful ones and shows that in many cases including
context can help while in other cases a significant improvement is simply
impossible or impractical. To better understand these results we then analyze
the ability of context to handle different types of false detections, revealing
that contextual information cannot ameliorate localization errors, which in
turn also diminish the observed improvement obtained by correcting other types
of errors. These insights provide further explanations and better understanding
regarding the success or failure of utilizing context for object detection.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05472</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can clone detection support quality assessments of requirements
  specifications?</dc:title>
 <dc:creator>Juergens, Elmar</dc:creator>
 <dc:creator>Deissenboeck, Florian</dc:creator>
 <dc:creator>Feilkas, Martin</dc:creator>
 <dc:creator>Hummel, Benjamin</dc:creator>
 <dc:creator>Schaetz, Bernhard</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:creator>Domann, Christoph</dc:creator>
 <dc:creator>Streit, Jonathan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Due to their pivotal role in software engineering, considerable effort is
spent on the quality assurance of software requirements specifications. As they
are mainly described in natural language, relatively few means of automated
quality assessment exist. However, we found that clone detection, a technique
widely applied to source code, is promising to assess one important quality
aspect in an automated way, namely redundancy that stems from copy&amp;paste
operations. This paper describes a large-scale case study that applied clone
detection to 28 requirements specifications with a total of 8,667 pages. We
report on the amount of redundancy found in real-world specifications, discuss
its nature as well as its consequences and evaluate in how far existing code
clone detection approaches can be applied to assess the quality of requirements
specifications in practice.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05472</dc:identifier>
 <dc:identifier>Proceedings of the 32nd ACM/IEEE International Conference on
  Software Engineering - Volume 2. Pages 79-88. ACM, 2010</dc:identifier>
 <dc:identifier>doi:10.1145/1810295.1810308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05473</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coloring intersection hypergraphs of pseudo-disks</dc:title>
 <dc:creator>Keszegh, Bal&#xe1;zs</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We prove that the intersection hypergraph of a family of $n$ pseudo-disks
with respect to another family of pseudo-disks admits a proper coloring with
$4$ colors and a conflict-free coloring with $O(\log n)$ colors. Along the way
we prove that the respective Delaunay-graph is planar. We also prove that the
intersection hypergraph of a family of $n$ regions with linear union complexity
with respect to a family of pseudo-disks admits a proper coloring with constant
many colors and a conflict-free coloring with $O(\log n)$ colors. Our results
serve as a common generalization and strengthening of many earlier results,
including ones about proper and conflict-free coloring points with respect to
pseudo-disks, coloring regions of linear union complexity with respect to
points and coloring disks with respect to disks.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05475</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The best defense is a good offense: Countering black box attacks by
  predicting slightly wrong labels</dc:title>
 <dc:creator>Kilcher, Yannic</dc:creator>
 <dc:creator>Hofmann, Thomas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Black-Box attacks on machine learning models occur when an attacker, despite
having no access to the inner workings of a model, can successfully craft an
attack by means of model theft. The attacker will train an own substitute model
that mimics the model to be attacked. The substitute can then be used to design
attacks against the original model, for example by means of adversarial
samples. We put ourselves in the shoes of the defender and present a method
that can successfully avoid model theft by mounting a counter-attack.
Specifically, to any incoming query, we slightly perturb our output label
distribution in a way that makes substitute training infeasible. We demonstrate
that the perturbation does not affect the ordinary use of our model, but
results in an effective defense against attacks based on model theft.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05477</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Convex Parametrization of a New Class of Universal Kernel Functions
  for use in Kernel Learning</dc:title>
 <dc:creator>Colbert, Brendon K.</dc:creator>
 <dc:creator>Peet, Matthew M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a new class of universal kernel functions which admit a linear
parametrization using positive semidefinite matrices. These kernels are
generalizations of the Sobolev kernel and are defined by piecewise-polynomial
functions. The class of kernels is termed &quot;tessellated&quot; as the resulting
discriminant is defined piecewise with hyper-rectangular domains whose corners
are determined by the training data. The kernels have scalable complexity, but
each instance is universal in the sense that its hypothesis space is dense in
$L_2$. Using numerical testing, we show that for the soft margin SVM, this
class can eliminate the need for Gaussian kernels. Furthermore, we demonstrate
that when the ratio of the number of training data to features is high, this
method will significantly outperform other kernel learning algorithms. Finally,
to reduce the complexity associated with SDP-based kernel learning methods, we
use a randomized basis for the positive matrices to integrate with existing
multiple kernel learning algorithms such as SimpleMKL.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05480</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>No Reference Stereoscopic Video Quality Assessment Using Joint Motion
  and Depth Statistics</dc:title>
 <dc:creator>Balasubramanyam, Appina</dc:creator>
 <dc:creator>Akshith, Jalli</dc:creator>
 <dc:creator>Srinivas, Battula Shanmukh</dc:creator>
 <dc:creator>Sumohana, Channappayya S</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  We present a no reference (NR) quality assessment algorithm for assessing the
perceptual quality of natural stereoscopic 3D (S3D) videos. This work is
inspired by our finding that the joint statistics of the subband coefficients
of motion (optical flow or motion vector magnitude) and depth (disparity map)
of natural S3D videos possess a unique signature. Specifically, we empirically
show that the joint statistics of the motion and depth subband coefficients of
S3D video frames can be modeled accurately using a Bivariate Generalized
Gaussian Distribution (BGGD). We then demonstrate that the parameters of the
BGGD model possess the ability to discern quality variations in S3D videos.
Therefore, the BGGD model parameters are employed as motion and depth quality
features. In addition to these features, we rely on a frame level spatial
quality feature that is computed using a robust off the shelf NR image quality
assessment (IQA) algorithm. These frame level motion, depth and spatial
features are consolidated and used with the corresponding S3D video's
difference mean opinion score (DMOS) labels for supervised learning using
support vector regression (SVR). The overall quality of an S3D video is
computed by averaging the frame level quality predictions of the constituent
video frames. The proposed algorithm, dubbed Video QUality Evaluation using
MOtion and DEpth Statistics (VQUEMODES) is shown to outperform the state of the
art methods when evaluated over the IRCCYN and LFOVIA S3D subjective quality
assessment databases.
</dc:description>
 <dc:description>Comment: 13 PAGES, 7 FIGURES, 7 TABLES</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05482</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Estimation of Generalization Error and Bias-Variance
  Components of Ensembles</dc:title>
 <dc:creator>Mahajan, Dhruv</dc:creator>
 <dc:creator>Gupta, Vivek</dc:creator>
 <dc:creator>Keerthi, S Sathiya</dc:creator>
 <dc:creator>Sundararajan, Sellamanickam</dc:creator>
 <dc:creator>Narayanamurthy, Shravan</dc:creator>
 <dc:creator>Kidambi, Rahul</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  For many applications, an ensemble of base classifiers is an effective
solution. The tuning of its parameters(number of classes, amount of data on
which each classifier is to be trained on, etc.) requires G, the generalization
error of a given ensemble. The efficient estimation of G is the focus of this
paper. The key idea is to approximate the variance of the class
scores/probabilities of the base classifiers over the randomness imposed by the
training subset by normal/beta distribution at each point x in the input
feature space. We estimate the parameters of the distribution using a small set
of randomly chosen base classifiers and use those parameters to give efficient
estimation schemes for G. We give empirical evidence for the quality of the
various estimators. We also demonstrate their usefulness in making design
choices such as the number of classifiers in the ensemble and the size of a
subset of data used for training that is needed to achieve a certain value of
generalization error. Our approach also has great potential for designing
distributed ensemble classifiers.
</dc:description>
 <dc:description>Comment: 12 Pages, 4 Figures, 12 Pages, Under Review in SDM 2018</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05486</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Lie bracket approximation approach to distributed optimization over
  directed graphs</dc:title>
 <dc:creator>Michalowsky, Simon</dc:creator>
 <dc:creator>Gharesifard, Bahman</dc:creator>
 <dc:creator>Ebenbauer, Christian</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider a group of computation units trying to cooperatively solve a
distributed optimization problem with shared linear equality and inequality
constraints. Assuming that the computation units are communicating over a
network whose topology is described by a time-invariant directed graph, by
combining saddle-point dynamics with Lie bracket approximation techniques we
derive a methodology that allows to design distributed continuous-time
optimization algorithms that solve this problem under minimal assumptions on
the graph topology as well as on the structure of the constraints. We discuss
several extensions as well as special cases in which the proposed procedure
becomes particularly simple.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05487</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis and Optimization of Sparse Matrix-Vector
  Multiplication on Modern Multi- and Many-Core Processors</dc:title>
 <dc:creator>Elafrou, Athena</dc:creator>
 <dc:creator>Goumas, Georgios</dc:creator>
 <dc:creator>Koziris, Nektarios</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  This paper presents a low-overhead optimizer for the ubiquitous sparse
matrix-vector multiplication (SpMV) kernel. Architectural diversity among
different processors together with structural diversity among different sparse
matrices lead to bottleneck diversity. This justifies an SpMV optimizer that is
both matrix- and architecture-adaptive through runtime specialization. To this
direction, we present an approach that first identifies the performance
bottlenecks of SpMV for a given sparse matrix on the target platform either
through profiling or by matrix property inspection, and then selects suitable
optimizations to tackle those bottlenecks. Our optimization pool is based on
the widely used Compressed Sparse Row (CSR) sparse matrix storage format and
has low preprocessing overheads, making our overall approach practical even in
cases where fast decision making and optimization setup is required. We
evaluate our optimizer on three x86-based computing platforms and demonstrate
that it is able to distinguish and appropriately optimize SpMV for the majority
of matrices in a representative test suite, leading to significant speedups
over the CSR and Inspector-Executor CSR SpMV kernels available in the latest
release of the Intel MKL library.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures, ICPP 2017</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05487</dc:identifier>
 <dc:identifier>doi:10.1109/ICPP.2017.38</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05491</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Squeeze-SegNet: A new fast Deep Convolutional Neural Network for
  Semantic Segmentation</dc:title>
 <dc:creator>Nanfack, Geraldin</dc:creator>
 <dc:creator>Elhassouny, Azeddine</dc:creator>
 <dc:creator>Thami, Rachid Oulad Haj</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The recent researches in Deep Convolutional Neural Network have focused their
attention on improving accuracy that provide significant advances. However, if
they were limited to classification tasks, nowadays with contributions from
Scientific Communities who are embarking in this field, they have become very
useful in higher level tasks such as object detection and pixel-wise semantic
segmentation. Thus, brilliant ideas in the field of semantic segmentation with
deep learning have completed the state of the art of accuracy, however this
architectures become very difficult to apply in embedded systems as is the case
for autonomous driving. We present a new Deep fully Convolutional Neural
Network for pixel-wise semantic segmentation which we call Squeeze-SegNet. The
architecture is based on Encoder-Decoder style. We use a SqueezeNet-like
encoder and a decoder formed by our proposed squeeze-decoder module and
upsample layer using downsample indices like in SegNet and we add a
deconvolution layer to provide final multi-channel feature map. On datasets
like Camvid or City-states, our net gets SegNet-level accuracy with less than
10 times fewer parameters than SegNet.
</dc:description>
 <dc:description>Comment: The 10th International Conference on Machine Vision (ICMV 2017).
  arXiv admin note: text overlap with arXiv:1704.06857 by other authors</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05496</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rumor Source Detection under Querying with Untruthful Answers</dc:title>
 <dc:creator>Choi, Jaeyoung</dc:creator>
 <dc:creator>Moon, Sangwoo</dc:creator>
 <dc:creator>Woo, Jiin</dc:creator>
 <dc:creator>Son, Kyunghwan</dc:creator>
 <dc:creator>Shin, Jinwoo</dc:creator>
 <dc:creator>Yi, Yung</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Social networks are the major routes for most individuals to exchange their
opinions about new products, social trends and political issues via their
interactions. It is often of significant importance to figure out who initially
diffuses the information, ie, finding a rumor source or a trend setter. It is
known that such a task is highly challenging and the source detection
probability cannot be beyond 31 percent for regular trees, if we just estimate
the source from a given diffusion snapshot. In practice, finding the source
often entails the process of querying that asks &quot;Are you the rumor source?&quot; or
&quot;Who tells you the rumor?&quot; that would increase the chance of detecting the
source. In this paper, we consider two kinds of querying: (a) simple batch
querying and (b) interactive querying with direction under the assumption that
queries can be untruthful with some probability. We propose estimation
algorithms for those queries, and quantify their detection performance and the
amount of extra budget due to untruthfulness, analytically showing that
querying significantly improves the detection performance. We perform extensive
simulations to validate our theoretical findings over synthetic and real-world
social network topologies.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05497</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statman's Hierarchy Theorem</dc:title>
 <dc:creator>Westerbaan, Bram</dc:creator>
 <dc:creator>Westerbaan, Bas</dc:creator>
 <dc:creator>Kuyper, Rutger</dc:creator>
 <dc:creator>Tankink, Carst</dc:creator>
 <dc:creator>Viehoff, Remy</dc:creator>
 <dc:creator>Barendregt, Henk</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In the Simply Typed $\lambda$-calculus Statman investigates the reducibility
relation $\leq_{\beta\eta}$ between types: for $A,B \in \mathbb{T}^0$, types
freely generated using $\rightarrow$ and a single ground type $0$, define $A
\leq_{\beta\eta} B$ if there exists a $\lambda$-definable injection from the
closed terms of type $A$ into those of type $B$. Unexpectedly, the induced
partial order is the (linear) well-ordering (of order type) $\omega + 4$.
  In the proof a finer relation $\leq_{h}$ is used, where the above injection
is required to be a B\&quot;ohm transformation, and an (a posteriori) coarser
relation $\leq_{h^+}$, requiring a finite family of B\&quot;ohm transformations that
is jointly injective.
  We present this result in a self-contained, syntactic, constructive and
simplified manner. En route similar results for $\leq_h$ (order type $\omega +
5$) and $\leq_{h^+}$ (order type $8$) are obtained. Five of the equivalence
classes of $\leq_{h^+}$ correspond to canonical term models of Statman, one to
the trivial term model collapsing all elements of the same type, and one does
not even form a model by the lack of closed terms of many types.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05497</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 4 (November
  27, 2017) lmcs:4089</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-13(4:19)2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05508</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generally Applicable, Highly Scalable Measurement Computation and
  Optimization Approach to Sequential Model-Based Diagnosis</dc:title>
 <dc:creator>Rodler, Patrick</dc:creator>
 <dc:creator>Schmid, Wolfgang</dc:creator>
 <dc:creator>Schekotihin, Konstantin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Model-Based Diagnosis deals with the identification of the real cause of a
system's malfunction based on a formal system model and observations of the
system behavior. When a malfunction is detected, there is usually not enough
information available to pinpoint the real cause and one needs to discriminate
between multiple fault hypotheses (called diagnoses). To this end, Sequential
Diagnosis approaches ask an oracle for additional system measurements.
  This work presents strategies for (optimal) measurement selection in
model-based sequential diagnosis. In particular, assuming a set of leading
diagnoses being given, we show how queries (sets of measurements) can be
computed and optimized along two dimensions: expected number of queries and
cost per query. By means of a suitable decoupling of two optimizations and a
clever search space reduction the computations are done without any inference
engine calls. For the full search space, we give a method requiring only a
polynomial number of inferences and show how query properties can be guaranteed
which existing methods do not provide. Evaluation results using real-world
problems indicate that the new method computes (virtually) optimal queries
instantly independently of the size and complexity of the considered diagnosis
problems and outperforms equally general methods not exploiting the proposed
theory by orders of magnitude.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05508</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05509</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Note on Representing attribute reduction and concepts in concepts
  lattice using graphs</dc:title>
 <dc:creator>Konecny, Jan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Mao H. (2017, Representing attribute reduction and concepts in concept
lattice using graphs. Soft Computing 21(24):7293--7311) claims to make
contributions to the study of reduction of attributes in concept lattices by
using graph theory. We show that her results are either trivial or already
well-known and all three algorithms proposed in the paper are incorrect.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05512</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Neural Networks and Data Augmentation for Spectral-Spatial
  Classification of Hyperspectral Images</dc:title>
 <dc:creator>Acquarelli, Jacopo</dc:creator>
 <dc:creator>Marchiori, Elena</dc:creator>
 <dc:creator>Buydens, Lutgarde M. C.</dc:creator>
 <dc:creator>Tran, Thanh</dc:creator>
 <dc:creator>van Laarhoven, Twan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Spectral-spatial classification of remotely sensed hyperspectral images has
been the subject of many studies in recent years. Current methods achieve
excellent performance on benchmark hyperspectral image labeling tasks when a
sufficient number of labeled pixels is available. However, in the presence of
only very few labeled pixels, such classification becomes a challenging
problem.
  In this paper we propose to tackle this problem using convolutional neural
networks (CNNs) and data augmentation. Our newly developed method relies on the
assumption of spectral-spatial locality: nearby pixels in a hyperspectral image
are related, in the sense that their spectra and their labels are likely to be
similar. We exploit this assumption to develop 1) a new data augmentation
procedure which adds new samples to the train set and 2) a tailored loss
function which penalize differences among weights of the network corresponding
to nearby wavelengths of the spectra. We train a simple single layer
convolutional neural network with this loss function and augmented train set
and use it to classify all unlabeled pixels of the given image.
  To assess the efficacy of our method, we used five publicly available
hyperspectral images: Pavia Center, Pavia University, KSC, Indian Pines and
Salina. On these images our method significantly outperforms other baselines.
Notably, with just 1% of labeled pixels per class, on these dataset our method
achieves an accuracy of 99.5%, etc. Furthermore we show that our method
improves over other baselines also in a supervised setting, when no overlap
between train and test pixels is allowed.
  Overall our investigation demonstrates that spectral-spatial locality can be
easily embedded in a simple convolutional neural network through data
augmentation and a tailored loss function.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05516</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating Inner Properties of Multimodal Representation and Semantic
  Compositionality with Brain-based Componential Semantics</dc:title>
 <dc:creator>Wang, Shaonan</dc:creator>
 <dc:creator>Zhang, Jiajun</dc:creator>
 <dc:creator>Lin, Nan</dc:creator>
 <dc:creator>Zong, Chengqing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Multimodal models have been proven to outperform text-based approaches on
learning semantic representations. However, it still remains unclear what
properties are encoded in multimodal representations, in what aspects do they
outperform the single-modality representations, and what happened in the
process of semantic compositionality in different input modalities. Considering
that multimodal models are originally motivated by human concept
representations, we assume that correlating multimodal representations with
brain-based semantics would interpret their inner properties to answer the
above questions. To that end, we propose simple interpretation methods based on
brain-based componential semantics. First we investigate the inner properties
of multimodal representations by correlating them with corresponding
brain-based property vectors. Then we map the distributed vector space to the
interpretable brain-based componential space to explore the inner properties of
semantic compositionality. Ultimately, the present paper sheds light on the
fundamental questions of natural language understanding, such as how to
represent the meaning of words and how to combine word meanings into larger
units.
</dc:description>
 <dc:description>Comment: To appear in AAAI-18</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05518</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MAMoC: Multisite Adaptive Offloading Framework for Mobile Cloud
  Applications</dc:title>
 <dc:creator>Sulaiman, Dawand</dc:creator>
 <dc:creator>Barker, Adam</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper presents MAMoC, a framework which brings together a diverse range
of infrastructure types including mobile devices, cloudlets, and remote cloud
resources under one unified API. MAMoC allows mobile applications to leverage
the power of multiple offloading destinations. MAMoC's intelligent offloading
decision engine adapts to the contextual changes in this heterogeneous
environment, in order to reduce the overall runtime for both single-site and
multi-site offloading scenarios. MAMoC is evaluated through a set of offloading
experiments, which evaluate the performance of our offloading decision engine.
The results show that offloading computation using our framework can reduce the
overall task completion time for both single-site and multi-site offloading
scenarios.
</dc:description>
 <dc:description>Comment: 8 pages, CloudCom 2017 Conference</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05519</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerated Alternating Projections for Robust Principal Component
  Analysis</dc:title>
 <dc:creator>Cai, HanQin</dc:creator>
 <dc:creator>Cai, Jian-Feng</dc:creator>
 <dc:creator>Wei, Ke</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We study robust PCA for the fully observed setting, which is about separating
a low rank matrix $\boldsymbol{L}$ and a sparse matrix $\boldsymbol{S}$ from
their sum $\boldsymbol{D}=\boldsymbol{L}+\boldsymbol{S}$. In this paper, a new
algorithm, dubbed accelerated alternating projections, is introduced for robust
PCA which significantly improves the computational efficiency of the existing
alternating projections proposed in [Netrapalli, Praneeth, et al., 2014] when
updating the low rank factor. The acceleration is achieved by first projecting
a matrix onto some low dimensional subspace before obtaining a new estimate of
the low rank matrix via truncated SVD. Exact recovery guarantee has been
established which shows linear convergence of the proposed algorithm. Empirical
performance evaluations establish the advantage of our algorithm over other
state-of-the-art algorithms for robust PCA.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05523</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Correlation Based Feature Representation for First-Person Activity
  Recognition</dc:title>
 <dc:creator>Kahani, Reza</dc:creator>
 <dc:creator>Talebpour, Alireza</dc:creator>
 <dc:creator>Mahmoudi-Aznaveh, Ahmad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, a simple yet efficient feature encoding for first-person video
is introduced. The proposed method is appropriate for representation of
high-dimensional features such as those extracted from convolutional neural
networks (CNNs). The per-frame extracted features are considered as a set of
time series, and inter and intra-time series relations are employed to
represent the video descriptors. To find the inter-time relations, the series
are grouped and the linear correlation between each pair of groups is
calculated. The relations between them can represent the scene dynamics and
local motions. The introduced grouping strategy helps to considerably reduce
the computational cost. Furthermore, we split the series in temporal direction
in order to better focus on each local time window. In order to extract the
cyclic motion patterns, which can be considered as primary components of
various activities, intra-time series correlations are exploited. The
representation method results in highly discriminative features which can be
simply classified by a linear SVM. The experiments show that our method
outperforms the previous encoding methods, such as bag of visual word (BoVW),
improved Fisher vector (IFV), Fourier temporal pyramid (FTP), and recently
proposed pooled time series (PoT) on three public first-person datasets. The
experimental results also confirm that the proposed method has a superior
performance over the state-of-the-art methods on recognizing first-person
activities
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05525</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the insertion of n-powers</dc:title>
 <dc:creator>Almeida, J.</dc:creator>
 <dc:creator>Kl&#xed;ma, O.</dc:creator>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  In algebraic terms, the insertion of $n$-powers in words may be modelled at
the language level by considering the pseudovariety of ordered monoids defined
by the inequality $1\le x^n$. We compare this pseudovariety with several other
natural pseudovarieties of ordered monoids and of monoids associated with the
Burnside pseudovariety of groups defined by the identity $x^n=1$. In
particular, we are interested in determining the pseudovariety of monoids that
it generates, which can be viewed as the problem of determining the Boolean
closure of the class of regular languages closed under $n$-power insertions. We
exhibit a simple upper bound and show that it satisfies all pseudoidentities
which are provable from $1\le x^n$ in which both sides are regular elements
with respect to the upper bound.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05535</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual-Path Convolutional Image-Text Embedding</dc:title>
 <dc:creator>Zheng, Zhedong</dc:creator>
 <dc:creator>Zheng, Liang</dc:creator>
 <dc:creator>Garrett, Michael</dc:creator>
 <dc:creator>Yang, Yi</dc:creator>
 <dc:creator>Shen, Yi-Dong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  This paper considers the task of matching images and sentences. The challenge
consists in discriminatively embedding the two modalities onto a shared
visual-textual space. Existing work in this field largely uses Recurrent Neural
Networks (RNN) for text feature learning and employs off-the-shelf
Convolutional Neural Networks (CNN) for image feature extraction. Our system,
in comparison, differs in two key aspects. Firstly, we build a convolutional
network amenable for fine-tuning the visual and textual representations, where
the entire network only contains four components, i.e., convolution layer,
pooling layer, rectified linear unit function (ReLU), and batch normalisation.
End-to-end learning allows the system to directly learn from the data and fully
utilise the supervisions. Secondly, we propose instance loss according to
viewing each multimodal data pair as a class. This works with a large margin
objective to learn the inter-modal correspondence between images and their
textual descriptions. Experiments on two generic retrieval datasets (Flickr30k
and MSCOCO) demonstrate that our method yields competitive accuracy compared to
state-of-the-art methods. Moreover, in language person retrieval, we improve
the state of the art by a large margin. Code is available at https://github.
com/layumi/Image-Text-Embedding
</dc:description>
 <dc:description>Comment: 12pages, 13 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05535</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05538</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting and assessing contextual change in diachronic text documents
  using context volatility</dc:title>
 <dc:creator>Kahmann, Christian</dc:creator>
 <dc:creator>Niekler, Andreas</dc:creator>
 <dc:creator>Heyer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Terms in diachronic text corpora may exhibit a high degree of semantic
dynamics that is only partially captured by the common notion of semantic
change. The new measure of context volatility that we propose models the degree
by which terms change context in a text collection over time. The computation
of context volatility for a word relies on the significance-values of its
co-occurrent terms and the corresponding co-occurrence ranks in sequential time
spans. We define a baseline and present an efficient computational approach in
order to overcome problems related to computational issues in the data
structure. Results are evaluated both, on synthetic documents that are used to
simulate contextual changes, and a real example based on British newspaper
texts.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05541</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Good and safe uses of AI Oracles</dc:title>
 <dc:creator>Armstrong, Stuart</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  An Oracle is a design for potentially high power artificial intelligences
(AIs), where the AI is made safe by restricting it to only answer questions.
Unfortunately most designs cause the Oracle to be motivated to manipulate
humans with the contents of their answers, and Oracles of potentially high
intelligence might be very successful at this. Solving the problem, without
compromising the accuracy of the answer, is tricky. This paper reduces the
issue to a cryptographic-style problem of Alice ensuring that her Oracle
answers her questions while not providing key information to an eavesdropping
Eve. Two Oracle designs solve this problem, one counterfactual (the Oracle
answers as if it expected its answer to never be read) and one on-policy
(limited by the quantity of information it can transmit).
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05551</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sound Event Detection in Synthetic Audio: Analysis of the DCASE 2016
  Task Results</dc:title>
 <dc:creator>Lafay, Gr&#xe9;goire</dc:creator>
 <dc:creator>Benetos, Emmanouil</dc:creator>
 <dc:creator>Lagrange, Mathieu</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  As part of the 2016 public evaluation challenge on Detection and
Classification of Acoustic Scenes and Events (DCASE 2016), the second task
focused on evaluating sound event detection systems using synthetic mixtures of
office sounds. This task, which follows the `Event Detection - Office
Synthetic' task of DCASE 2013, studies the behaviour of tested algorithms when
facing controlled levels of audio complexity with respect to background noise
and polyphony/density, with the added benefit of a very accurate ground truth.
This paper presents the task formulation, evaluation metrics, submitted
systems, and provides a statistical analysis of the results achieved, with
respect to various aspects of the evaluation dataset.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05551</dc:identifier>
 <dc:identifier>IEEE Workshop on Applications of Signal Processing to Audio and
  Acoustics (WASPAA 2017), Sep 2017, Mohonk, United States</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05557</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phrase-based Image Captioning with Hierarchical LSTM Model</dc:title>
 <dc:creator>Tan, Ying Hua</dc:creator>
 <dc:creator>Chan, Chee Seng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Automatic generation of caption to describe the content of an image has been
gaining a lot of research interests recently, where most of the existing works
treat the image caption as pure sequential data. Natural language, however
possess a temporal hierarchy structure, with complex dependencies between each
subsequence. In this paper, we propose a phrase-based hierarchical Long
Short-Term Memory (phi-LSTM) model to generate image description. In contrast
to the conventional solutions that generate caption in a pure sequential
manner, our proposed model decodes image caption from phrase to sentence. It
consists of a phrase decoder at the bottom hierarchy to decode noun phrases of
variable length, and an abbreviated sentence decoder at the upper hierarchy to
decode an abbreviated form of the image description. A complete image caption
is formed by combining the generated phrases with sentence during the inference
stage. Empirically, our proposed model shows a better or competitive result on
the Flickr8k, Flickr30k and MS-COCO datasets in comparison to the state-of-the
art models. We also show that our proposed model is able to generate more novel
captions (not seen in the training data) which are richer in word contents in
all these three datasets.
</dc:description>
 <dc:description>Comment: 17 pages, 12 figures, ACCV2016 extension, phrase-based image
  captioning</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05560</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Adaptive-Newton Method for Explorative Learning</dc:title>
 <dc:creator>Khan, Mohammad Emtiyaz</dc:creator>
 <dc:creator>Lin, Wu</dc:creator>
 <dc:creator>Tangkaratt, Voot</dc:creator>
 <dc:creator>Liu, Zuozhu</dc:creator>
 <dc:creator>Nielsen, Didrik</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present the Variational Adaptive Newton (VAN) method which is a black-box
optimization method especially suitable for explorative-learning tasks such as
active learning and reinforcement learning. Similar to Bayesian methods, VAN
estimates a distribution that can be used for exploration, but requires
computations that are similar to continuous optimization methods. Our
theoretical contribution reveals that VAN is a second-order method that unifies
existing methods in distinct fields of continuous optimization, variational
inference, and evolution strategies. Our experimental results show that VAN
performs well on a wide-variety of learning tasks. This work presents a
general-purpose explorative-learning method that has the potential to improve
learning in areas such as active learning and reinforcement learning.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05561</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Stochastic Resource-Sharing Network for Electric Vehicle Charging</dc:title>
 <dc:creator>Aveklouris, Angelos</dc:creator>
 <dc:creator>Vlasiou, Maria</dc:creator>
 <dc:creator>Zwart, Bert</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We consider a distribution grid used to charge electric vehicles such that
voltage drops stay bounded. We model this as a class of resource-sharing
networks, known as bandwidth-sharing networks in the communication network
literature. We focus on resource-sharing networks that are driven by a class of
greedy control rules that can be implemented in a decentralized fashion. For a
large number of such control rules, we can characterize the performance of the
system by a fluid approximation. This leads to a set of dynamic equations that
take into account the stochastic behavior of EVs. We show that the invariant
point of these equations is unique and can be computed by solving a specific
ACOPF problem, which admits an exact convex relaxation. For the class of
weighted proportional fairness control, we show additional appealing properties
under the linearized Distflow model, such as fairness and a product-form
property of the stochastic model.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05568</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dialogue Act Recognition via CRF-Attentive Structured Network</dc:title>
 <dc:creator>Chen, Zheqian</dc:creator>
 <dc:creator>Yang, Rongqin</dc:creator>
 <dc:creator>Zhao, Zhou</dc:creator>
 <dc:creator>Cai, Deng</dc:creator>
 <dc:creator>He, Xiaofei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Dialogue Act Recognition (DAR) is a challenging problem in dialogue
interpretation, which aims to attach semantic labels to utterances and
characterize the speaker's intention. Currently, many existing approaches
formulate the DAR problem ranging from multi-classification to structured
prediction, which suffer from handcrafted feature extensions and attentive
contextual structural dependencies. In this paper, we consider the problem of
DAR from the viewpoint of extending richer Conditional Random Field (CRF)
structural dependencies without abandoning end-to-end training. We incorporate
hierarchical semantic inference with memory mechanism on the utterance
modeling. We then extend structured attention network to the linear-chain
conditional random field layer which takes into account both contextual
utterances and corresponding dialogue acts. The extensive experiments on two
major benchmark datasets Switchboard Dialogue Act (SWDA) and Meeting Recorder
Dialogue Act (MRDA) datasets show that our method achieves better performance
than other state-of-the-art solutions to the problem. It is a remarkable fact
that our method is nearly close to the human annotator's performance on SWDA
within 2% gap.
</dc:description>
 <dc:description>Comment: 10 pages, 4figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05572</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mitigating Clipping Effects on Error Floors under Belief Propagation
  Decoding of Polar Codes</dc:title>
 <dc:creator>Elkelesh, Ahmed</dc:creator>
 <dc:creator>Cammerer, Sebastian</dc:creator>
 <dc:creator>Ebada, Moustafa</dc:creator>
 <dc:creator>Brink, Stephan ten</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we show that polar belief propagation (BP) decoding exhibits an
error floor behavior which is caused by clipping of the log-likelihood ratios
(LLR). The error floor becomes more pronounced for clipping to smaller
LLR-values. We introduce a single-value measure quantifying a &quot;relative error
floor&quot;, showing, by exhaustive simulations for different lengths, that the
error floor is mainly caused by inadequate clipping values. We propose four
modifications to the conventional BP decoding algorithm to mitigate this error
floor behavior, demonstrating that the error floor is a decoder property, and
not a code property. The results agree with the fact that polar codes are
theoretically proven to not suffer from error floors. Finally, we show that
another cause of error floors can be an improper selection of frozen bit
positions.
</dc:description>
 <dc:description>Comment: ISWCS2017</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05573</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PlinyCompute: A Platform for High-Performance, Distributed,
  Data-Intensive Tool Development</dc:title>
 <dc:creator>Zou, Jia</dc:creator>
 <dc:creator>Barnett, R. Matthew</dc:creator>
 <dc:creator>Lorido-Botran, Tania</dc:creator>
 <dc:creator>Luo, Shangyu</dc:creator>
 <dc:creator>Monroy, Carlos</dc:creator>
 <dc:creator>Sikdar, Sourav</dc:creator>
 <dc:creator>Teymourian, Kia</dc:creator>
 <dc:creator>Yuan, Binhang</dc:creator>
 <dc:creator>Jermaine, Chris</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper describes PlinyCompute, a system for development of
high-performance, data-intensive, distributed computing tools and libraries. In
the large, PlinyCompute presents the programmer with a very high-level,
declarative interface, relying on automatic, relational-database style
optimization to figure out how to stage distributed computations. However, in
the small, PlinyCompute presents the capable systems programmer with a
persistent object data model and API (the &quot;PC object model&quot;) and associated
memory management system that has been designed from the ground-up for high
performance, distributed, data-intensive computing. This contrasts with most
other Big Data systems, which are constructed on top of the Java Virtual
Machine (JVM), and hence must at least partially cede performance-critical
concerns such as memory management (including layout and de/allocation) and
virtual method/function dispatch to the JVM. This hybrid approach---declarative
in the large, trusting the programmer's ability to utilize PC object model
efficiently in the small---results in a system that is ideal for the
development of reusable, data-intensive tools and libraries. Through extensive
benchmarking, we show that implementing complex objects manipulation and
non-trivial, library-style computations on top of PlinyCompute can result in a
speedup of 2x to more than 50x or more compared to equivalent implementations
on Spark.
</dc:description>
 <dc:description>Comment: 48 pages, including references and Appendix</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05581</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TTW: A Time-Triggered-Wireless Design for CPS [ Extended version ]</dc:title>
 <dc:creator>Jacob, Romain</dc:creator>
 <dc:creator>Zhang, Licong</dc:creator>
 <dc:creator>Zimmerling, Marco</dc:creator>
 <dc:creator>Beutel, Jan</dc:creator>
 <dc:creator>Chakraborty, Samarjit</dc:creator>
 <dc:creator>Thiele, Lothar</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Wired field buses have proved their effectiveness to support Cyber-Physical
Systems (CPS). However, in avionics, for ease of deployment, or for new
functionality featuring mobile devices, there is a strong interest for wireless
solutions. Low-power wireless protocols have been proposed, but requirements of
a large class of CPS applications can still not be satisfied. This paper
presents Time-Triggered-Wireless (TTW), a distributed low-power wireless system
design that minimizes energy consumption and offers end-to-end timing
predictability, adaptability, reliability, low latency. Our evaluation shows a
reduction of communication latency by a factor 2x and of energy consumption by
33-40% compared to state-of-the-art approaches. This validates the suitability
of TTW for wireless CPS applications and opens the way for implementation and
real-world experience with industry partners.
</dc:description>
 <dc:description>Comment: 13 pages, 8 figures. Extended version of the same paper, to be
  published in the proceedings of DATE 2018</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05586</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>People, Penguins and Petri Dishes: Adapting Object Counting Models To
  New Visual Domains And Object Types Without Forgetting</dc:title>
 <dc:creator>Marsden, Mark</dc:creator>
 <dc:creator>McGuinness, Kevin</dc:creator>
 <dc:creator>Little, Suzanne</dc:creator>
 <dc:creator>Keogh, Ciara E.</dc:creator>
 <dc:creator>O'Connor, Noel E.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we propose a technique to adapt a convolutional neural network
(CNN) based object counter to additional visual domains and object types while
still preserving the original counting function. Domain-specific normalisation
and scaling operators are trained to allow the model to adjust to the
statistical distributions of the various visual domains. The developed
adaptation technique is used to produce a singular patch-based counting
regressor capable of counting various object types including people, vehicles,
cell nuclei and wildlife. As part of this study a challenging new cell counting
dataset in the context of tissue culture and patient diagnosis is constructed.
This new collection, referred to as the Dublin Cell Counting (DCC) dataset, is
the first of its kind to be made available to the wider computer vision
community. State-of-the-art object counting performance is achieved in both the
Shanghaitech (parts A and B) and Penguins datasets while competitive
performance is observed on the TRANCOS and Modified Bone Marrow (MBM) datasets,
all using a shared counting model.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05597</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Advances in Variational Inference</dc:title>
 <dc:creator>Zhang, Cheng</dc:creator>
 <dc:creator>Butepage, Judith</dc:creator>
 <dc:creator>Kjellstrom, Hedvig</dc:creator>
 <dc:creator>Mandt, Stephan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many modern unsupervised or semi-supervised machine learning algorithms rely
on Bayesian probabilistic models. These models are usually intractable and thus
require approximate inference. Variational inference (VI) lets us approximate a
high-dimensional Bayesian posterior with a simpler variational distribution by
solving an optimization problem. This approach has been successfully used in
various models and large-scale applications. In this review, we give an
overview of recent trends in variational inference. We first introduce standard
mean field variational inference, then review recent advances focusing on the
following aspects: (a) scalable VI, which includes stochastic approximations,
(b) generic VI, which extends the applicability of VI to a large class of
otherwise intractable models, such as non-conjugate models, (c) accurate VI,
which includes variational models beyond the mean field approximation or with
atypical divergences, and (d) amortized VI, which implements the inference over
local latent variables with inference networks. Finally, we provide a summary
of promising future research directions.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05603</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Words are Malleable: Computing Semantic Shifts in Political and Media
  Discourse</dc:title>
 <dc:creator>Azarbonyad, Hosein</dc:creator>
 <dc:creator>Dehghani, Mostafa</dc:creator>
 <dc:creator>Beelen, Kaspar</dc:creator>
 <dc:creator>Arkut, Alexandra</dc:creator>
 <dc:creator>Marx, Maarten</dc:creator>
 <dc:creator>Kamps, Jaap</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recently, researchers started to pay attention to the detection of temporal
shifts in the meaning of words. However, most (if not all) of these approaches
restricted their efforts to uncovering change over time, thus neglecting other
valuable dimensions such as social or political variability. We propose an
approach for detecting semantic shifts between different viewpoints--broadly
defined as a set of texts that share a specific metadata feature, which can be
a time-period, but also a social entity such as a political party. For each
viewpoint, we learn a semantic space in which each word is represented as a low
dimensional neural embedded vector. The challenge is to compare the meaning of
a word in one space to its meaning in another space and measure the size of the
semantic shifts. We compare the effectiveness of a measure based on optimal
transformations between the two spaces with a measure based on the similarity
of the neighbors of the word in the respective spaces. Our experiments
demonstrate that the combination of these two performs best. We show that the
semantic shifts not only occur over time, but also along different viewpoints
in a short period of time. For evaluation, we demonstrate how this approach
captures meaningful semantic shifts and can help improve other tasks such as
the contrastive viewpoint summarization and ideology detection (measured as
classification accuracy) in political texts. We also show that the two laws of
semantic change which were empirically shown to hold for temporal shifts also
hold for shifts across viewpoints. These laws state that frequent words are
less likely to shift meaning while words with many senses are more likely to do
so.
</dc:description>
 <dc:description>Comment: In Proceedings of the 26th ACM International on Conference on
  Information and Knowledge Management (CIKM2017)</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05606</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A bijective proof of the enumeration of maps in higher genus</dc:title>
 <dc:creator>Lepoutre, Mathias</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Bender and Canfield proved in 1991 that the generating series of maps in
higher genus is a rational function of the generating series of planar maps. In
this paper, we give the first bijective proof of this result. Our approach
starts with the introduction of a canonical orientation that enables us to
construct a bijection between $4$-valent bicolorable maps and a family of
unicellular blossoming maps.
</dc:description>
 <dc:description>Comment: Submitted to FPSAC2018. 10 pages, 6 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05611</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpreting Deep Visual Representations via Network Dissection</dc:title>
 <dc:creator>Zhou, Bolei</dc:creator>
 <dc:creator>Bau, David</dc:creator>
 <dc:creator>Oliva, Aude</dc:creator>
 <dc:creator>Torralba, Antonio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:description>  The success of recent deep convolutional neural networks (CNNs) depends on
learning hidden representations that can summarize the important factors of
variation behind the data. However, CNNs often criticized as being black boxes
that lack interpretability, since they have millions of unexplained model
parameters. In this work, we describe Network Dissection, a method that
interprets networks by providing labels for the units of their deep visual
representations. The proposed method quantifies the interpretability of CNN
representations by evaluating the alignment between individual hidden units and
a set of visual semantic concepts. By identifying the best alignments, units
are given human interpretable labels across a range of objects, parts, scenes,
textures, materials, and colors. The method reveals that deep representations
are more transparent and interpretable than expected: we find that
representations are significantly more interpretable than they would be under a
random equivalently powerful basis. We apply the method to interpret and
compare the latent representations of various network architectures trained to
solve different supervised and self-supervised training tasks. We then examine
factors affecting the network interpretability such as the number of the
training iterations, regularizations, different initializations, and the
network depth and width. Finally we show that the interpreted units can be used
to provide explicit explanations of a prediction given by a CNN for an image.
Our results highlight that interpretability is an important property of deep
neural networks that provides new insights into their hierarchical structure.
</dc:description>
 <dc:description>Comment: *B. Zhou and D. Bau contributed equally to this work. 15 pages, 27
  figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05624</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian width bounds with applications to arithmetic progressions in
  random settings</dc:title>
 <dc:creator>Bri&#xeb;t, Jop</dc:creator>
 <dc:creator>Gopi, Sivakanth</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Motivated by two problems on arithmetic progressions (APs)---concerning large
deviations for AP counts in random sets and random differences in Szemer\'edi's
theorem---we prove upper bounds on the Gaussian width of the image of the
$n$-dimensional Boolean hypercube under a mapping
$\psi:\mathbb{R}^n\to\mathbb{R}^k$, where each coordinate is a constant-degree
multilinear polynomial with $0/1$ coefficients. We show the following
applications of our bounds. Let $[\mathbb{Z}/N\mathbb{Z}]_p$ be the random
subset of $\mathbb{Z}/N\mathbb{Z}$ containing each element independently with
probability $p$.
  - Let $X_k$ be the number of $k$-term APs in $[\mathbb{Z}/N\mathbb{Z}]_p$. We
show that a precise estimate on the large deviation rate $\log\Pr[X_k \geq
(1+\delta)\mathbb{E}X_k]$ due to Bhattacharya, Ganguly, Shao and Zhao is valid
if $p \geq \omega(N^{-c_k}\log N)$ for $c_k = (6k\lceil(k-1)/2\rceil)^{-1}$,
which slightly improves their bound of $c_k = (6k(k-1))^{-1}$ for $k \geq 5$
(and matching their $c_3$ and $c_4$).
  - A set $D\subseteq \mathbb{Z}/N\mathbb{Z}$ is $\ell$-intersective if every
dense subset of $\mathbb{Z}/N\mathbb{Z}$ contains a non-trivial $(\ell+1)$-term
AP with common difference in $D$. We show that $[\mathbb{Z}/N\mathbb{Z}]_p$ is
$\ell$-intersective with probability $1 - o_N(1)$ provided $p \geq
\omega(N^{-\beta_\ell}\log N)$ for $\beta_\ell =
(\lceil(\ell+1)/2\rceil)^{-1}$, improving the bound $\beta_\ell =(\ell+1)^{-1}$
due to Frantzikinakis, Lesigne and Wierdl for $\ell \geq 2$ and reproving more
directly the same result shown recently by the authors and Dvir.
  In addition, we discuss some intriguing connections with special kinds of
error correcting codes (locally decodable codes) and the Banach-space notion of
type for injective tensor products of $\ell_p$-spaces.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05626</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Temporal-Recurrent-Replicated-Softmax for Topical Trends over Time</dc:title>
 <dc:creator>Gupta, Pankaj</dc:creator>
 <dc:creator>Rajaram, Subburam</dc:creator>
 <dc:creator>Sch&#xfc;tze, Hinrich</dc:creator>
 <dc:creator>Andrassy, Bernt</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Dynamic topic modeling facilitates the identification of topical trends over
time in temporal collections of unstructured documents. We introduce a novel
unsupervised neural dynamic topic model known as Recurrent Neural
Network-Replicated Softmax Model (RNNRSM), where the discovered topics at each
time influence the topic discovery in the subsequent time steps. We account for
the temporal ordering of documents by explicitly modeling a joint distribution
of latent topical dependencies over time, using distributional estimators with
temporal recurrent connections. Applying RNN-RSM to 19 years of articles on NLP
research, we demonstrate that compared to state-of-the art topic models,
RNN-RSM shows better generalization, topic interpretation, evolution and
trends. We also propose to quantify the capability of dynamic topic model to
capture word evolution in topics over time.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05627</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Layerwise Convexity of Rectifier Networks with Sign
  Constrained Weights</dc:title>
 <dc:creator>An, Senjian</dc:creator>
 <dc:creator>Boussaid, Farid</dc:creator>
 <dc:creator>Bennamoun, Mohammed</dc:creator>
 <dc:creator>Sohel, Ferdous</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  By introducing sign constraints on the weights, this paper proposes sign
constrained rectifier networks (SCRNs), whose training can be solved
efficiently by the well known majorization-minimization (MM) algorithms. We
prove that the proposed two-hidden-layer SCRNs, which exhibit negative weights
in the second hidden layer and negative weights in the output layer, are
capable of separating any two (or more) disjoint pattern sets. Furthermore, the
proposed two-hidden-layer SCRNs can decompose the patterns of each class into
several clusters so that each cluster is convexly separable from all the
patterns from the other classes. This provides a means to learn the pattern
structures and analyse the discriminant factors between different classes of
patterns.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05635</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An example of how false conclusions could be made with personalized
  health tracking and suggestions for avoiding similar situations</dc:title>
 <dc:creator>DeMasi, Orianna</dc:creator>
 <dc:creator>Recht, Benjamin</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Personalizing interventions and treatments is a necessity for optimal medical
care. Recent advances in computing, such as personal electronic devices, have
made it easier than ever to collect and utilize vast amounts of personal data
on individuals. This data could support personalized medicine; however, there
are pitfalls that must be avoided. We discuss an example, longitudinal medical
tracking, in which traditional methods of evaluating machine learning
algorithms fail and present the opportunity for false conclusions. We then pose
three suggestions for avoiding such opportunities for misleading results in
medical applications, where reliability is essential.
</dc:description>
 <dc:description>Comment: Presented at the Data For Good Exchange 2017</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05635</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05640</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contraction-based Observers using non-Euclidean Norms with an
  Application to Traffic Networks</dc:title>
 <dc:creator>Coogan, Samuel</dc:creator>
 <dc:creator>Arcak, Murat</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this note, we study Luenberger-type full-state observers for nonlinear
systems using contraction theory. We show that if the matrix measure of a
suitably defined Jacobian matrix constructed from the dynamics of the
system-observer interconnection is uniformly negative, then the state estimate
converges exponentially to the actual state. This sufficient condition for
convergence establishes that the distance between the estimate and state is
infinitesimally contracting with respect to some norm on the state-space. In
contrast to existing results for contraction-based observer design, we allow
for contraction with respect to non-Euclidean norms. Such norms have proven
useful in applications. To demonstrate our results, we study the problem of
observing vehicular traffic density along a freeway modeled as interconnected,
spatially homogenous compartments, and our approach relies on establishing
contraction of the system-observer interconnection with respect to the
one-norm.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05642</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Benchmarks and New Directions for Noise Power Estimation
  Methods in ISM Radio Environment</dc:title>
 <dc:creator>Nikonowicz, Jakub</dc:creator>
 <dc:creator>Mahmood, Aamir</dc:creator>
 <dc:creator>Sisinni, Emiliano</dc:creator>
 <dc:creator>Gidlund, Mikael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Noise power estimation is a key issue in modern wireless communication
systems. It allows resource allocation by detecting white spectral spaces
effectively, and gives control over the communication process by adjusting
transmission power. Thus far, the proposed estimation methods in the literature
are based on spectral averaging, eigenvalues of sample covariance matrix,
information theory, and statistical signal analysis. Each method is
characterized by certain stability, accuracy and complexity. However, the
existing literature does not provide an appropriate comparison. In this paper,
we evaluate the performance of the existing estimation techniques intensively
in terms of stability and accuracy, followed by detailed complexity analysis.
The basis for comparison is signal-to-noise ratio (SNR) estimation in simulated
industrial, scientific and medical (ISM) band transmission. The source of used
background distortions is complex noise measurement, recorded by USRP-2932 in
an industrial production area. Based on the examined solutions, we also analyze
the influence of noise samples separation techniques on the estimation process.
As a response to the defects in the used methods, we propose a novel noise
samples separation algorithm based on the adaptation of rank order filtering
(ROF). In addition to simple implementation, the proposed method has a very
good 0.5 dB root-mean-squared error (RMSE) and smaller than 0.1 dB resolution,
thus achieving a performance that is comparable with the methods exploiting
information theory concepts.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05649</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assessing the Usability of a Novel System for Programming Education</dc:title>
 <dc:creator>Vincenti, Giovanni</dc:creator>
 <dc:creator>Hilberg, Scott</dc:creator>
 <dc:creator>Braman, James</dc:creator>
 <dc:creator>Satzinger, Michael</dc:creator>
 <dc:creator>Cao, Lily</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The authors present the results of a simple usability test performed on
line_explorer, an innovative tool aimed at letting students explore
programming. The system offers an interactive environment where students can
learn, review, and practice programming independently or through step-by-step
instruction. Students in Information Technology, Computer Science, and
Information Systems were surveyed. The findings show that students have
interest in this tool, whereas some groups find this tool more interesting and
useful. The findings will help refine the user interface for the next phase of
testing which include changes for simplicity, usability and expanded topic
content. Overall the survey on line_explorer in its current design phase seem
more useful for IT and CS majors, however significant changes are still needed.
</dc:description>
 <dc:description>Comment: Presented at Systems, Programming, Languages and Applications:
  Software for Humanity - Education (SPLASH-E) 2017</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05649</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05650</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tractable Product Channel Model for Line-of-Sight Scenarios</dc:title>
 <dc:creator>Fernandez-Plazaola, Unai</dc:creator>
 <dc:creator>Moreno-Pozas, Laureano</dc:creator>
 <dc:creator>Lopez-Martinez, F. Javier</dc:creator>
 <dc:creator>Paris, Jos&#xe9; F.</dc:creator>
 <dc:creator>Martos-Naya, Eduardo</dc:creator>
 <dc:creator>Romero-Jerez, Juan M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We here present a general and tractable model for line-of-sight (LOS)
scenarios, which is based on the product of two independent and non-identically
distributed $\kappa$-$\mu$ shadowed random variables. Simple closed-form
expressions for the probability density function, cumulative distribution
function and moment-generating function are derived, which are as tractable as
the corresponding expressions derived from a product of Nakagami-$m$ random
variables. This model simplifies the challenging characterization of LOS
product channels, as well as combinations of LOS with non-LOS ones. It also
shows a higher flexibility when fitting measurements with respect to exact
approaches based on the Rician distribution.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05650</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05667</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Friendly Smoothed Analysis of the Simplex Method</dc:title>
 <dc:creator>Dadush, Daniel</dc:creator>
 <dc:creator>Huiberts, Sophie</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Explaining the excellent practical performance of the simplex method for
linear programming has been a major topic of research for over 50 years. One of
the most successful frameworks for understanding the simplex method was given
by Spielman and Teng (JACM `04), who the developed the notion of smoothed
analysis. Starting from an arbitrary linear program with $d$ variables and $n$
constraints, Spielman and Teng analyzed the expected runtime over random
perturbations of the LP (smoothed LP), where variance $\sigma^2$ Gaussian noise
is added to the LP data. In particular, they gave a two-stage shadow vertex
simplex algorithm which uses an expected $\widetilde{O}(d^{55} n^{86}
\sigma^{-30})$ number of simplex pivots to solve the smoothed LP. Their
analysis and runtime was substantially improved by Deshpande and Spielman (FOCS
`05) and later Vershynin (SICOMP `09). The fastest current algorithm, due to
Vershynin, solves the smoothed LP using an expected $O(d^3 \log^7 n \sigma^{-4}
+ d^9\log^7 n)$ number of pivots, improving the dependence on $n$ from
polynomial to logarithmic.
  While the original proof of Spielman and Teng has now been substantially
simplified, the resulting analyses are still quite long and complex and the
parameter dependencies far from optimal. In this work, we make substantial
progress on this front, providing an improved and simpler analysis of shadow
simplex methods, where our main algorithm requires an expected \[ O(d^2
\sqrt{\log n} \sigma^{-2} + d^5 \log^{3/2} n) \] number of simplex pivots. We
obtain our results via an improved \emph{shadow bound}, key to earlier analyses
as well, combined with algorithmic techniques of Borgwardt (ZOR `82) and
Vershynin. As an added bonus, our analysis is completely \emph{modular},
allowing us to obtain non-trivial bounds for perturbations beyond Gaussians,
such as Laplace perturbations.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05667</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05677</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PQSER: A Matlab package for spectral seriation</dc:title>
 <dc:creator>Concas, Anna</dc:creator>
 <dc:creator>Fenu, Caterina</dc:creator>
 <dc:creator>Rodriguez, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>65F15, 65F50, 05C82, 91D30</dc:subject>
 <dc:description>  The seriation problem is an important ordering issue which consists of
finding the best ordering of a set of units whose interrelationship is defined
by a bipartite graph. It has important applications in, e.g., archaeology,
anthropology, psychology, and biology. This paper presents a Matlab
implementation of an algorithm for spectral seriation by Atkins et al., based
on the use of the Fiedler vector of the Laplacian matrix associated to the
problem, which encodes the set of admissible solutions into a PQ-tree. We
introduce some numerical technicalities in the original algorithm to improve
its performance, and point out that the presence of a multiple Fiedler value
may have a substantial influence on the computation of an approximated
solution, in the presence of inconsistent data sets. Practical examples and
numerical experiments show how to use the toolbox to process data sets deriving
from real-world applications.
</dc:description>
 <dc:description>Comment: 20 pages, 9 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05678</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Morphological Expansion of Small Datasets for Improving
  Word Embeddings</dc:title>
 <dc:creator>Akhtar, Syed Sarfaraz</dc:creator>
 <dc:creator>Gupta, Arihant</dc:creator>
 <dc:creator>Vajpayee, Avijit</dc:creator>
 <dc:creator>Srivastava, Arjit</dc:creator>
 <dc:creator>Shrivastava, Manish</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a language independent, unsupervised method for building word
embeddings using morphological expansion of text. Our model handles the problem
of data sparsity and yields improved word embeddings by relying on training
word embeddings on artificially generated sentences. We evaluate our method
using small sized training sets on eleven test sets for the word similarity
task across seven languages. Further, for English, we evaluated the impacts of
our approach using a large training set on three standard test sets. Our method
improved results across all languages.
</dc:description>
 <dc:description>Comment: CICLing 2017</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05680</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Unsupervised Approach for Mapping between Vector Spaces</dc:title>
 <dc:creator>Akhtar, Syed Sarfaraz</dc:creator>
 <dc:creator>Gupta, Arihant</dc:creator>
 <dc:creator>Vajpayee, Avijit</dc:creator>
 <dc:creator>Srivastava, Arjit</dc:creator>
 <dc:creator>Jhawar, Madan Gopal</dc:creator>
 <dc:creator>Shrivastava, Manish</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a language independent, unsupervised approach for transforming
word embeddings from source language to target language using a transformation
matrix. Our model handles the problem of data scarcity which is faced by many
languages in the world and yields improved word embeddings for words in the
target language by relying on transformed embeddings of words of the source
language. We initially evaluate our approach via word similarity tasks on a
similar language pair - Hindi as source and Urdu as the target language, while
we also evaluate our method on French and German as target languages and
English as source language. Our approach improves the current state of the art
results - by 13% for French and 19% for German. For Urdu, we saw an increment
of 16% over our initial baseline score. We further explore the prospects of our
approach by applying it on multiple models of the same language and
transferring words between the two models, thus solving the problem of missing
words in a model. We evaluate this on word similarity and word analogy tasks.
</dc:description>
 <dc:description>Comment: CICLing 2017</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05683</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hydra: a C++11 framework for data analysis in massively parallel
  platforms</dc:title>
 <dc:creator>Alves Jr, A. A.</dc:creator>
 <dc:creator>Sokoloff, M. D.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>High Energy Physics - Experiment</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Hydra is a header-only, templated and C++11-compliant framework designed to
perform the typical bottleneck calculations found in common HEP data analyses
on massively parallel platforms. The framework is implemented on top of the
C++11 Standard Library and a variadic version of the Thrust library and is
designed to run on Linux systems, using OpenMP, CUDA and TBB enabled devices.
This contribution summarizes the main features of Hydra. A basic description of
the overall design, functionality and user interface is provided, along with
some code examples and measurements of performance.
</dc:description>
 <dc:description>Comment: ACAT 2017 Proceedings</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05696</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An approach to evaluation of common DNS misconfigurations</dc:title>
 <dc:creator>Bojovi&#x107;, Petar D.</dc:creator>
 <dc:creator>Gajin, Slavko</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  DNS is a basic Internet service which almost all other user services depend
on. However, what has been perceived in practice are a lot of inconsistencies
and errors in the configuration of servers that cause different problems. The
majority of such cases are included in this research with the aim of
identifying and classifying the major problems of DNS availability, performance
and security. In order to analyze these problems in correlation with DNS
administrators working practice, we have developed a methodology and tool for
testing, quantifying and analysis of DNS misconfigurations. The methodology and
tool were applied on three heterogeneous domain categories - the most popular
Internet domains, academic domains and one national top level domain. Our
results confirm relatively high percentage of misconfigured domains, especially
in the academic and national categories. However, we have shown that fixing the
configuration on relatively small number of name servers can have significant
impact to great number of domains. Proper domain management, permanent testing
and collaboration with other administrators are identified as measures to
improve domains operation, stability and security.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05697</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Motif-based Convolutional Neural Network on Graphs</dc:title>
 <dc:creator>Sankar, Aravind</dc:creator>
 <dc:creator>Zhang, Xinyang</dc:creator>
 <dc:creator>Chang, Kevin Chen-Chuan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This paper introduces a generalization of Convolutional Neural Networks
(CNNs) from regular grid-structured data such as images to graphs with
irregular linkage structures, especially expressive heterogeneous graphs with
typed nodes and schemas. We propose a novel spatial convolution operation to
model the key aspects of a CNN: local connectivity and translation invariance,
using higher-order structures. We use the concept of motif, which provides us
flexibility to describe spatial locality in Heterogeneous graphs with respect
to its schema, or any graph with respect to desired higher-order connection
patterns. We develop a novel neural network architecture Motif-CNN that
captures higher-order structural and feature information by combining the
information extracted from multiple patterns through deeper layers. Our
experiments on semi-supervised learning tasks on social networks and real-world
heterogeneous graphs indicate significant gains over existing graph CNNs and
respective state-of-the-art techniques.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05698</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Verification of Multi-Property Designs (The Benefit of Wrong
  Assumptions) (Extended Version)</dc:title>
 <dc:creator>Goldberg, Eugene</dc:creator>
 <dc:creator>Gudemann, Matthias</dc:creator>
 <dc:creator>Kroening, Daniel</dc:creator>
 <dc:creator>Mukherjee, Rajdeep</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We consider the problem of efficiently checking a set of safety properties
P1,....,Pk of one design. We introduce a new approach called JA-verification
where JA stands for &quot;Just-Assume&quot; (as opposed to &quot;assume-guarantee&quot;). In this
approach, when proving property Pi, one assumes that every property Pj for j!=i
holds. The process of proving properties either results in showing that
P1,....,Pk hold without any assumptions or finding a &quot;debugging set&quot; of
properties. The latter identifies a subset of failed properties that cause
failure of other properties. The design behaviors that cause the properties in
the debugging set to fail must be fixed first. Importantly, in our approach,
there is no need to prove the assumptions used. We describe the theory behind
our approach and report experimental results that demonstrate substantial gains
in performance, especially in the cases where a small debugging set exists.
</dc:description>
 <dc:description>Comment: 6 pages, Design Automation and Test in Europe conference</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05701</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Complex Contagion in Music Listenership: A Natural Experiment
  with 1.3 Million Participants</dc:title>
 <dc:creator>Ternovski, John</dc:creator>
 <dc:creator>Yasseri, Taha</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Can live music events generate complex contagion in music streaming? This
paper finds evidence in the affirmative, but only for the most popular artists.
We generate a novel dataset from Last.fm, a music tracking website, to analyse
the listenership history of 1.3 million users over a two-month time horizon. We
use daily play counts along with event attendance data to run a regression
discontinuity analysis in order to show the causal impact of concert attendance
on music listenership among attendees and their friends network. First, we show
that attending a music artist's live concert increases that artist's
listenership among the attendees of the concert by approximately 1 song per day
per attendee (p-value&lt;0.001). Moreover, we show that this effect is contagious
and can spread to users who did not attend the event. However, the extent of
contagion depends on the type of artist. We only observe contagious increases
in listenership for well-established, popular artists (.06 more daily plays per
friend of an attendee [p&lt;0.001]), while the effect is absent for emerging
stars. We also show that the contagion effect size increases monotonically with
the number of friends who have attended the live event.
</dc:description>
 <dc:description>Comment: Preprint, under review</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05702</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Brain Extraction from Normal and Pathological Images: A Joint
  PCA/Image-Reconstruction Approach</dc:title>
 <dc:creator>Han, Xu</dc:creator>
 <dc:creator>Kwitt, Roland</dc:creator>
 <dc:creator>Aylward, Stephen</dc:creator>
 <dc:creator>Menze, Bjoern</dc:creator>
 <dc:creator>Asturias, Alexander</dc:creator>
 <dc:creator>Vespa, Paul</dc:creator>
 <dc:creator>Van Horn, John</dc:creator>
 <dc:creator>Niethammer, Marc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Brain extraction from 3D medical images is a common pre-processing step. A
variety of approaches exist, but they are frequently only designed to perform
brain extraction from images without strong pathologies. Extracting the brain
from images exhibiting strong pathologies, for example, the presence of a brain
tumor or of a traumatic brain injury (TBI), is challenging. In such cases,
tissue appearance may deviate from normal tissue appearance and hence violates
algorithmic assumptions for standard approaches; consequently, the brain may
not be correctly extracted.
  This paper proposes a brain extraction approach which can explicitly account
for pathologies by jointly modeling normal tissue appearance and pathologies.
Specifically, our model uses a three-part image decomposition: (1) normal
tissue appearance is captured by principal component analysis (PCA), (2)
pathologies are captured via a total variation term, and (3) the skull and
surrounding tissue is captured by a sparsity term. Decomposition and image
registration steps are alternated to allow statistical modeling of normal
tissue appearance in a fixed atlas space. As a beneficial side effect, the
model allows for the identification of potentially pathological areas and the
reconstruction of a quasi-normal image in atlas space.
  We demonstrate the effectiveness of our approach on four datasets: the
publicly available IBSR and LPBA40 datasets which show normal image appearance,
the BRATS dataset containing images with brain tumors, and a dataset containing
clinical TBI images. We compare the performance with other popular brain
extraction models: ROBEX, BET, BSE and a recently proposed deep learning
approach. Our model performs better than these competing approaches on all four
datasets. Hence, our approach is an effective method for brain extraction for a
wide variety of images with high-quality brain extraction results.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05705</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextual Object Detection with a Few Relevant Neighbors</dc:title>
 <dc:creator>Barnea, Ehud</dc:creator>
 <dc:creator>Ben-Shahar, Ohad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A natural way to improve the detection of objects is to consider the
contextual constraints imposed by the detection of additional objects in a
given scene. In this work, we exploit the spatial relations between objects in
order to improve detection capacity, as well as analyze various properties of
the contextual object detection problem. To precisely calculate context-based
probabilities of objects, we developed a model that examines the interactions
between objects in an exact probabilistic setting, in contrast to previous
methods that typically utilize approximations based on pairwise interactions.
Such a scheme is facilitated by the single realistic assumption that the
existence of an object in any given location is influenced by only few
informative locations in space. Based on this assumption, we suggest a method
for identifying these relevant locations and integrating them into an exact
calculation of probability based on their raw detector responses. This scheme
is shown to improve detection results and provides unique insights about the
process of contextual inference for object detection. We show that it is
generally difficult to learn that a particular object reduces the probability
of another, and that in cases when the context and detector strongly disagree
this learning becomes virtually impossible for the purposes of improving the
results of an object detector. Finally, we demonstrate improved detection
results through use of our approach as applied to the PASCAL VOC dataset.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05712</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CSWA: Aggregation-Free Spatial-Temporal Community Sensing</dc:title>
 <dc:creator>Bian, Jiang</dc:creator>
 <dc:creator>Xiong, Haoyi</dc:creator>
 <dc:creator>Fu, Yanjie</dc:creator>
 <dc:creator>Das, Sajal K.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper, we present a novel community sensing paradigm -- {C}ommunity
{S}ensing {W}ithout {A}ggregation}. CSWA is designed to obtain the environment
information (e.g., air pollution or temperature) in each subarea of the target
area, without aggregating sensor and location data collected by community
members. CSWA operates on top of a secured peer-to-peer network over the
community members and proposes a novel \emph{Decentralized Spatial-Temporal
Compressive Sensing} framework based on \emph{Parallelized Stochastic Gradient
Descent}. Through learning the \emph{low-rank structure} via distributed
optimization, CSWA approximates the value of the sensor data in each subarea
(both covered and uncovered) for each sensing cycle using the sensor data
locally stored in each member's mobile device. Simulation experiments based on
real-world datasets demonstrate that CSWA exhibits low approximation error
(i.e., less than $0.2 ^\circ$C in city-wide temperature sensing task and $10$
units of PM2.5 index in urban air pollution sensing) and performs comparably to
(sometimes better than) state-of-the-art algorithms based on the data
aggregation and centralized computation.
</dc:description>
 <dc:description>Comment: This paper has been accepted by AAAI 2018. First two authors are
  equally contributed</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05715</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for
  Task-Oriented Dialogue Systems</dc:title>
 <dc:creator>Lipton, Zachary</dc:creator>
 <dc:creator>Li, Xiujun</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Li, Lihong</dc:creator>
 <dc:creator>Ahmed, Faisal</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a new algorithm that significantly improves the efficiency of
exploration for deep Q-learning agents in dialogue systems. Our agents explore
via Thompson sampling, drawing Monte Carlo samples from a Bayes-by-Backprop
neural network. Our algorithm learns much faster than common exploration
strategies such as \epsilon-greedy, Boltzmann, bootstrapping, and
intrinsic-reward-based ones. Additionally, we show that spiking the replay
buffer with experiences from just a few successful episodes can make Q-learning
feasible when it might otherwise fail.
</dc:description>
 <dc:description>Comment: Duplicate of article already in the arXiv: arXiv:1608.05081</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05717</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Bi-LSTMs</dc:title>
 <dc:creator>Shabanian, Samira</dc:creator>
 <dc:creator>Arpit, Devansh</dc:creator>
 <dc:creator>Trischler, Adam</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent neural networks like long short-term memory (LSTM) are important
architectures for sequential prediction tasks. LSTMs (and RNNs in general)
model sequences along the forward time direction. Bidirectional LSTMs
(Bi-LSTMs) on the other hand model sequences along both forward and backward
directions and are generally known to perform better at such tasks because they
capture a richer representation of the data. In the training of Bi-LSTMs, the
forward and backward paths are learned independently. We propose a variant of
the Bi-LSTM architecture, which we call Variational Bi-LSTM, that creates a
channel between the two paths (during training, but which may be omitted during
inference); thus optimizing the two paths jointly. We arrive at this joint
objective for our model by minimizing a variational lower bound of the joint
likelihood of the data sequence. Our model acts as a regularizer and encourages
the two networks to inform each other in making their respective predictions
using distinct information. We perform ablation studies to better understand
the different components of our model and evaluate the method on various
benchmarks, showing state-of-the-art performance.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05717</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05726</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Markov Decision Processes with Continuous Side Information</dc:title>
 <dc:creator>Modi, Aditya</dc:creator>
 <dc:creator>Jiang, Nan</dc:creator>
 <dc:creator>Singh, Satinder</dc:creator>
 <dc:creator>Tewari, Ambuj</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider a reinforcement learning (RL) setting in which the agent
interacts with a sequence of episodic MDPs. At the start of each episode the
agent has access to some side-information or context that determines the
dynamics of the MDP for that episode. Our setting is motivated by applications
in healthcare where baseline measurements of a patient at the start of a
treatment episode form the context that may provide information about how the
patient might respond to treatment decisions. We propose algorithms for
learning in such Contextual Markov Decision Processes (CMDPs) under an
assumption that the unobserved MDP parameters vary smoothly with the observed
context. We also give lower and upper PAC bounds under the smoothness
assumption. Because our lower bound has an exponential dependence on the
dimension, we consider a tractable linear setting where the context is used to
create linear combinations of a finite set of MDPs. For the linear setting, we
give a PAC learning algorithm based on KWIK learning techniques.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05731</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Android Malware Detection using Markov Chain Model of Application
  Behaviors in Requesting System Services</dc:title>
 <dc:creator>Salehi, Majid</dc:creator>
 <dc:creator>Amini, Morteza</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Widespread growth in Android malwares stimulates security researchers to
propose different methods for analyzing and detecting malicious behaviors in
applications. Nevertheless, current solutions are ill-suited to extract the
fine-grained behavior of Android applications accurately and efficiently. In
this paper, we propose ServiceMonitor, a lightweight host-based detection
system that dynamically detects malicious applications directly on mobile
devices. ServiceMonitor reconstructs the fine-grained behavior of applications
based on a novel systematic system service use analysis technique. Using
proposed system service use perspective enables us to build a statistical
Markov chain model to represent what and how system services are used to access
system resources. Afterwards, we consider built Markov chain in the form of a
feature vector and use it to classify the application behavior into either
malicious or benign using Random Forests classification algorithm.
ServiceMonitor outperforms current host-based solutions with evaluating it
against 4034 malwares and 10024 benign applications and obtaining 96\% of
accuracy rate and negligible overhead and performance penalty.
</dc:description>
 <dc:description>Comment: SUBMITTED TO THE IEEE TRANSACTIONS ON INFORMATION FORENSICS AND
  SECURITY</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05732</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pushing the Limits of Paraphrastic Sentence Embeddings with Millions of
  Machine Translations</dc:title>
 <dc:creator>Wieting, John</dc:creator>
 <dc:creator>Gimpel, Kevin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We extend the work of Wieting et al. (2017), back-translating a large
parallel corpus to produce a dataset of more than 51 million English-English
sentential paraphrase pairs in a dataset we call ParaNMT-50M. We find this
corpus to be cover many domains and styles of text, in addition to being rich
in paraphrases with different sentence structure, and we release it to the
community. To show its utility, we use it to train paraphrastic sentence
embeddings using only minor changes to the framework of Wieting et al. (2016b).
The resulting embeddings outperform all supervised systems on every SemEval
semantic textual similarity (STS) competition, and are a significant
improvement in capturing paraphrastic similarity over all other sentence
embeddings We also show that our embeddings perform competitively on general
sentence embedding tasks. We release the corpus, pretrained sentence
embeddings, and code to generate them. We believe the corpus can be a valuable
resource for automatic paraphrase generation and can provide a rich source of
semantic information to improve downstream natural language understanding
tasks.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05734</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chipmunk: A Systolically Scalable 0.9 mm${}^2$, 3.08 Gop/s/mW @ 1.2 mW
  Accelerator for Near-Sensor Recurrent Neural Network Inference</dc:title>
 <dc:creator>Conti, Francesco</dc:creator>
 <dc:creator>Cavigelli, Lukas</dc:creator>
 <dc:creator>Paulin, Gianna</dc:creator>
 <dc:creator>Susmelj, Igor</dc:creator>
 <dc:creator>Benini, Luca</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Recurrent neural networks (RNNs) are state-of-the-art in voice
awareness/understanding and speech recognition. On-device computation of RNNs
on low-power mobile and wearable devices would be key to applications such as
zero-latency voice-based human-machine interfaces. Here we present Chipmunk, a
small (&lt;1 mm${}^2$) hardware accelerator for Long-Short Term Memory RNNs in UMC
65 nm technology capable to operate at a measured peak efficiency up to 3.08
Gop/s/mW at 1.24 mW peak power. To implement big RNN models without incurring
in huge memory transfer overhead, multiple Chipmunk engines can cooperate to
form a single systolic array. In this way, the Chipmunk architecture in a 75
tiles configuration can achieve real-time phoneme extraction on a demanding RNN
topology proposed by Graves et al., consuming less than 13 mW of average power.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05738</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Neural Network Pushdown Automaton: Model, Stack and Learning
  Simulations</dc:title>
 <dc:creator>Sun, G. Z.</dc:creator>
 <dc:creator>Giles, C. L.</dc:creator>
 <dc:creator>Chen, H. H.</dc:creator>
 <dc:creator>Lee, Y. C.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In order for neural networks to learn complex languages or grammars, they
must have sufficient computational power or resources to recognize or generate
such languages. Though many approaches have been discussed, one ob- vious
approach to enhancing the processing power of a recurrent neural network is to
couple it with an external stack memory - in effect creating a neural network
pushdown automata (NNPDA). This paper discusses in detail this NNPDA - its
construction, how it can be trained and how useful symbolic information can be
extracted from the trained network.
  In order to couple the external stack to the neural network, an optimization
method is developed which uses an error function that connects the learning of
the state automaton of the neural network to the learning of the operation of
the external stack. To minimize the error function using gradient descent
learning, an analog stack is designed such that the action and storage of
information in the stack are continuous. One interpretation of a continuous
stack is the probabilistic storage of and action on data. After training on
sample strings of an unknown source grammar, a quantization procedure extracts
from the analog stack and neural network a discrete pushdown automata (PDA).
Simulations show that in learning deterministic context-free grammars - the
balanced parenthesis language, 1*n0*n, and the deterministic Palindrome - the
extracted PDA is correct in the sense that it can correctly recognize unseen
strings of arbitrary length. In addition, the extracted PDAs can be shown to be
identical or equivalent to the PDAs of the source grammars which were used to
generate the training strings.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05747</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Speech Enhancement with Generative Adversarial Networks for
  Robust Speech Recognition</dc:title>
 <dc:creator>Donahue, Chris</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Prabhavalkar, Rohit</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  We investigate the effectiveness of generative adversarial networks (GANs)
for speech enhancement, in the context of improving noise robustness of
automatic speech recognition (ASR) systems. Prior work demonstrates that GANs
can effectively suppress additive noise in raw waveform speech signals,
improving perceptual quality metrics; however this technique was not justified
in the context of ASR. In this work, we conduct a detailed study to measure the
effectiveness of GANs in enhancing speech contaminated by both additive and
reverberant noise. Motivated by recent advances in image processing, we propose
operating GANs on log-Mel filterbank spectra instead of waveforms, which
requires less computation and is more robust to reverberant noise. While GAN
enhancement improves the performance of a clean-trained ASR system on noisy
speech, it falls short of the performance achieved by conventional multi-style
training (MTR). By appending the GAN-enhanced features to the noisy inputs and
retraining, we achieve a 7% WER improvement relative to the MTR system.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05762</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random gradient extrapolation for distributed and stochastic
  optimization</dc:title>
 <dc:creator>Lan, Guanghui</dc:creator>
 <dc:creator>Zhou, Yi</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we consider a class of finite-sum convex optimization problems
defined over a distributed multiagent network with $m$ agents connected to a
central server. In particular, the objective function consists of the average
of $m$ ($\ge 1$) smooth components associated with each network agent together
with a strongly convex term. Our major contribution is to develop a new
randomized incremental gradient algorithm, namely random gradient extrapolation
method (RGEM), which does not require any exact gradient evaluation even for
the initial point, but can achieve the optimal ${\cal O}(\log(1/\epsilon))$
complexity bound in terms of the total number of gradient evaluations of
component functions to solve the finite-sum problems. Furthermore, we
demonstrate that for stochastic finite-sum optimization problems, RGEM
maintains the optimal ${\cal O}(1/\epsilon)$ complexity (up to a certain
logarithmic factor) in terms of the number of stochastic gradient computations,
but attains an ${\cal O}(\log(1/\epsilon))$ complexity in terms of
communication rounds (each round involves only one agent). It is worth noting
that the former bound is independent of the number of agents $m$, while the
latter one only linearly depends on $m$ or even $\sqrt m$ for ill-conditioned
problems. To the best of our knowledge, this is the first time that these
complexity bounds have been obtained for distributed and stochastic
optimization problems. Moreover, our algorithms were developed based on a novel
dual perspective of Nesterov's accelerated gradient method.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05762</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05764</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Allocation with Traffic Spikes: Mixing Adversarial and Stochastic
  Models</dc:title>
 <dc:creator>Esfandiari, Hossein</dc:creator>
 <dc:creator>Korula, Nitish</dc:creator>
 <dc:creator>Mirrokni, Vahab</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Motivated by Internet advertising applications, online allocation problems
have been studied extensively in various adversarial and stochastic models.
While the adversarial arrival models are too pessimistic, many of the
stochastic (such as i.i.d or random-order) arrival models do not realistically
capture uncertainty in predictions. A significant cause for such uncertainty is
the presence of unpredictable traffic spikes, often due to breaking news or
similar events. To address this issue, a simultaneous approximation framework
has been proposed to develop algorithms that work well both in the adversarial
and stochastic models; however, this framework does not enable algorithms that
make good use of partially accurate forecasts when making online decisions. In
this paper, we propose a robust online stochastic model that captures the
nature of traffic spikes in online advertising. In our model, in addition to
the stochastic input for which we have good forecasting, an unknown number of
impressions arrive that are adversarially chosen. We design algorithms that
combine a stochastic algorithm with an online algorithm that adaptively reacts
to inaccurate predictions. We provide provable bounds for our new algorithms in
this framework. We accompany our positive results with a set of hardness
results showing that our algorithms are not far from optimal in this framework.
As a byproduct of our results, we also present improved online algorithms for a
slight variant of the simultaneous approximation framework.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05766</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Predictive Simple Geodesic Regression</dc:title>
 <dc:creator>Ding, Zhipeng</dc:creator>
 <dc:creator>Fleishman, Greg</dc:creator>
 <dc:creator>Yang, Xiao</dc:creator>
 <dc:creator>Thompson, Paul</dc:creator>
 <dc:creator>Kwitt, Roland</dc:creator>
 <dc:creator>Niethammer, Marc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Deformable image registration and regression are important tasks in medical
image analysis. However, they are computationally expensive, especially when
analyzing large-scale datasets that contain thousands of images. Hence, cluster
computing is typically used, making the approaches dependent on such
computational infrastructure. Even larger computational resources are required
as study sizes increase. This limits the use of deformable image registration
and regression for clinical applications and as component algorithms for other
image analysis approaches. We therefore propose using a fast predictive
approach to perform image registrations. In particular, we employ these fast
registration predictions to approximate a simplified geodesic regression model
to capture longitudinal brain changes. The resulting method is orders of
magnitude faster than the standard optimization-based regression model and
hence facilitates large-scale analysis on a single graphics processing unit
(GPU). We evaluate our results on 3D brain magnetic resonance images (MRI) from
the ADNI datasets.
</dc:description>
 <dc:description>Comment: 19 pages, 10 figures, 13 tables</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05767</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting vehicular travel times by modeling heterogeneous influences
  between arterial roads</dc:title>
 <dc:creator>Achar, Avinash</dc:creator>
 <dc:creator>Sarangan, Venkatesh</dc:creator>
 <dc:creator>Rohith, R</dc:creator>
 <dc:creator>Sivasubramaniam, Anand</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Predicting travel times of vehicles in urban settings is a useful and
tangible quantity of interest in the context of intelligent transportation
systems. We address the problem of travel time prediction in arterial roads
using data sampled from probe vehicles. There is only a limited literature on
methods using data input from probe vehicles. The spatio-temporal dependencies
captured by existing data driven approaches are either too detailed or very
simplistic. We strike a balance of the existing data driven approaches to
account for varying degrees of influence a given road may experience from its
neighbors, while controlling the number of parameters to be learnt.
Specifically, we use a NoisyOR conditional probability distribution (CPD) in
conjunction with a dynamic bayesian network (DBN) to model state transitions of
various roads. We propose an efficient algorithm to learn model parameters. We
propose an algorithm for predicting travel times on trips of arbitrary
durations. Using synthetic and real world data traces we demonstrate the
superior performance of the proposed method under different traffic conditions.
</dc:description>
 <dc:description>Comment: 13 pages, conference</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05769</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning</dc:title>
 <dc:creator>Mallya, Arun</dc:creator>
 <dc:creator>Lazebnik, Svetlana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a method for adding multiple tasks to a single deep
neural network while avoiding catastrophic forgetting. Inspired by network
pruning techniques, we exploit redundancies in large deep networks to free up
parameters that can then be employed to learn new tasks. By performing
iterative pruning and network re-training, we are able to sequentially &quot;pack&quot;
multiple tasks into a single network while ensuring minimal drop in performance
and minimal storage overhead. Unlike prior work that uses proxy losses to
maintain accuracy on older tasks, we always optimize for the task at hand. We
perform extensive experiments on a variety of network architectures and
large-scale datasets, and observe much better robustness against catastrophic
forgetting than prior work. In particular, we are able to add three
fine-grained classification tasks to a single ImageNet-trained VGG-16 network
and achieve accuracies close to those of separately trained networks for each
task.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05769</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05772</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Latent Constraints: Learning to Generate Conditionally from
  Unconditional Generative Models</dc:title>
 <dc:creator>Engel, Jesse</dc:creator>
 <dc:creator>Hoffman, Matthew</dc:creator>
 <dc:creator>Roberts, Adam</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep generative neural networks have proven effective at both conditional and
unconditional modeling of complex data distributions. Conditional generation
enables interactive control, but creating new controls often requires expensive
retraining. In this paper, we develop a method to condition generation without
retraining the model. By post-hoc learning latent constraints, value functions
that identify regions in latent space that generate outputs with desired
attributes, we can conditionally sample from these regions with gradient-based
optimization or amortized actor functions. Combining attribute constraints with
a universal &quot;realism&quot; constraint, which enforces similarity to the data
distribution, we generate realistic conditional images from an unconditional
variational autoencoder. Further, using gradient-based optimization, we
demonstrate identity-preserving transformations that make the minimal
adjustment in latent space to modify the attributes of an image. Finally, with
discrete sequences of musical notes, we demonstrate zero-shot conditional
generation, learning latent constraints in the absence of labeled data or a
differentiable reward function. Code with dedicated cloud instance has been
made publicly available (https://goo.gl/STGMGx).
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05772</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05775</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end Training for Whole Image Breast Cancer Diagnosis using An All
  Convolutional Design</dc:title>
 <dc:creator>Shen, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We develop an end-to-end training algorithm for whole-image breast cancer
diagnosis based on mammograms. It requires lesion annotations only at the first
stage of training. After that, a whole image classifier can be trained using
only image level labels. This greatly reduced the reliance on lesion
annotations. Our approach is implemented using an all convolutional design that
is simple yet provides superior performance in comparison with the previous
methods. On DDSM, our best single-model achieves a per-image AUC score of 0.88
and three-model averaging increases the score to 0.91. On INbreast, our best
single-model achieves a per-image AUC score of 0.96. Using DDSM as benchmark,
our models compare favorably with the current state-of-the-art. We also
demonstrate that a whole image model trained on DDSM can be easily transferred
to INbreast without using its lesion annotations and using only a small amount
of training data. Code availability: https://github.com/lishen/end2end-all-conv
</dc:description>
 <dc:description>Comment: Accepted poster at NIPS 2017 Workshop on Machine Learning for Health
  (https://ml4health.github.io/2017/)</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05780</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Egregious Conversations between Customers and Virtual Agents</dc:title>
 <dc:creator>Sandbank, Tommy</dc:creator>
 <dc:creator>Shmueli-Scheuer, Michal</dc:creator>
 <dc:creator>Konopnicki, David</dc:creator>
 <dc:creator>Herzig, Jonathan</dc:creator>
 <dc:creator>Richards, John</dc:creator>
 <dc:creator>Piorkowski, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Virtual agents are becoming a prominent channel of interaction in customer
service. Not all customer interactions are smooth, however, and some can become
almost comically bad. In such instances, a human agent might need to step in
and salvage the conversation. Detecting bad conversations is important since
disappointing customer service may threaten customer loyalty and impact
revenue. In this paper, we outline an approach to detecting such egregious
conversations, using behavioral cues from the user, patterns in agent
responses, and user-agent interaction. Using logs of two commercial systems, we
show that using these features improves the detection F1-score by around 20%
over using textual features alone. In addition, we show that those features are
common across two quite different domains and, arguably, universal.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05787</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WebRelate: Integrating Web Data with Spreadsheets using Examples</dc:title>
 <dc:creator>Inala, Jeevana Priya</dc:creator>
 <dc:creator>Singh, Rishabh</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Data integration between web sources and relational data is a key challenge
faced by data scientists and spreadsheet users. There are two main challenges
in programmatically joining web data with relational data. First, most websites
do not expose a direct interface to obtain tabular data, so the user needs to
formulate a logic to get to different webpages for each input row in the
relational table. Second, after reaching the desired webpage, the user needs to
write complex scripts to extract the relevant data, which is often conditioned
on the input data. Since many data scientists and end-users come from diverse
backgrounds, writing such complex regular-expression based logical scripts to
perform data integration tasks is unfortunately often beyond their programming
expertise.
  We present WebRelate, a system that allows users to join semi-structured web
data with relational data in spreadsheets using input-output examples.
WebRelate decomposes the web data integration task into two sub-tasks of i) URL
learning and ii) input-dependent web extraction. The first sub-task generates
the URLs for the webpages containing the desired data for all rows in the
relational table. WebRelate achieves this by learning a string transformation
program using a few example URLs. The second sub-task uses examples of desired
data to be extracted from the corresponding webpages and learns a program to
extract the data for the other rows. We design expressive domain-specific
languages for URL generation and web data extraction, and present efficient
synthesis algorithms for learning programs in these DSLs from few input-output
examples. We evaluate WebRelate on 88 real-world web data integration tasks
taken from online help forums and Excel product team, and show that WebRelate
can learn the desired programs within few seconds using only 1 example for the
majority of the tasks.
</dc:description>
 <dc:description>Comment: To appear in POPL 2018</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05788</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantile Markov Decision Process</dc:title>
 <dc:creator>Li, Xiaocheng</dc:creator>
 <dc:creator>Zhong, Huaiyang</dc:creator>
 <dc:creator>Brandeau, Margaret L.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we consider the problem of optimizing the quantiles of the
cumulative rewards of Markov Decision Processes (MDP), to which we refers as
Quantile Markov Decision Processes (QMDP). Traditionally, the goal of a Markov
Decision Process (MDP) is to maximize expected cumulative reward over a defined
horizon (possibly to be infinite). In many applications, however, a decision
maker may be interested in optimizing a specific quantile of the cumulative
reward instead of its expectation. Our framework of QMDP provides analytical
results characterizing the optimal QMDP solution and presents the algorithm for
solving the QMDP. We provide analytical results characterizing the optimal QMDP
solution and present the algorithms for solving the QMDP. We illustrate the
model with two experiments: a grid game and a HIV optimal treatment experiment.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05789</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CMU LiveMedQA at TREC 2017 LiveQA: A Consumer Health Question Answering
  System</dc:title>
 <dc:creator>Yang, Yuan</dc:creator>
 <dc:creator>Yu, Jingcheng</dc:creator>
 <dc:creator>Hu, Ye</dc:creator>
 <dc:creator>Xu, Xiaoyao</dc:creator>
 <dc:creator>Nyberg, Eric</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In this paper, we present LiveMedQA, a question answering system that is
optimized for consumer health question. On top of the general QA system
pipeline, we introduce several new features that aim to exploit domain-specific
knowledge and entity structures for better performance. This includes a
question type/focus analyzer based on deep text classification model, a
tree-based knowledge graph for answer generation and a complementary
structure-aware searcher for answer retrieval. LiveMedQA system is evaluated in
the TREC 2017 LiveQA medical subtask, where it received an average score of
0.356 on a 3 point scale. Evaluation results revealed 3 substantial drawbacks
in current LiveMedQA system, based on which we provide a detailed discussion
and propose a few solutions that constitute the main focus of our subsequent
work.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of TREC 2017</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05791</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maintaining The Humanity of Our Models</dc:title>
 <dc:creator>Bhatt, Umang</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Artificial intelligence and machine learning have been major research
interests in computer science for the better part of the last few decades.
However, all too recently, both AI and ML have rapidly grown to be media
frenzies, pressuring companies and researchers to claim they use these
technologies. As ML continues to percolate into daily life, we, as computer
scientists and machine learning researchers, are responsible for ensuring we
clearly convey the extent of our work and the humanity of our models.
Regularizing ML for mass adoption requires a rigorous standard for model
interpretability, a deep consideration for human bias in data, and a
transparent understanding of a model's societal effects.
</dc:description>
 <dc:description>Comment: Accepted into the 2018 AAAI Spring Symposium: AI and Society: Ethics,
  Safety and Trustworthiness in Intelligent Agents</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05792</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aggregated Wasserstein Metric and State Registration for Hidden Markov
  Models</dc:title>
 <dc:creator>Chen, Yukun</dc:creator>
 <dc:creator>Ye, Jianbo</dc:creator>
 <dc:creator>Li, Jia</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a framework, named Aggregated Wasserstein, for computing a
dissimilarity measure or distance between two Hidden Markov Models with state
conditional distributions being Gaussian. For such HMMs, the marginal
distribution at any time position follows a Gaussian mixture distribution, a
fact exploited to softly match, aka register, the states in two HMMs. We refer
to such HMMs as Gaussian mixture model-HMM (GMM-HMM). The registration of
states is inspired by the intrinsic relationship of optimal transport and the
Wasserstein metric between distributions. Specifically, the components of the
marginal GMMs are matched by solving an optimal transport problem where the
cost between components is the Wasserstein metric for Gaussian distributions.
The solution of the optimization problem is a fast approximation to the
Wasserstein metric between two GMMs. The new Aggregated Wasserstein distance is
a semi-metric and can be computed without generating Monte Carlo samples. It is
invariant to relabeling or permutation of states. The distance is defined
meaningfully even for two HMMs that are estimated from data of different
dimensionality, a situation that can arise due to missing variables. This
distance quantifies the dissimilarity of GMM-HMMs by measuring both the
difference between the two marginal GMMs and that between the two transition
matrices. Our new distance is tested on tasks of retrieval, classification, and
t-SNE visualization of time series. Experiments on both synthetic and real data
have demonstrated its advantages in terms of accuracy as well as efficiency in
comparison with existing distances based on the Kullback-Leibler divergence.
</dc:description>
 <dc:description>Comment: Our manuscript is based on our conference paper [arXiv:1608.01747]
  published in 14th European Conference on Computer Vision (ECCV 2016,
  spotlight). It has been significantly extended and is now in journal
  submission</dc:description>
 <dc:date>2017-11-12</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05795</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finer Grained Entity Typing with TypeNet</dc:title>
 <dc:creator>Murty, Shikhar</dc:creator>
 <dc:creator>Verga, Patrick</dc:creator>
 <dc:creator>Vilnis, Luke</dc:creator>
 <dc:creator>McCallum, Andrew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We consider the challenging problem of entity typing over an extremely fine
grained set of types, wherein a single mention or entity can have many
simultaneous and often hierarchically-structured types. Despite the importance
of the problem, there is a relative lack of resources in the form of
fine-grained, deep type hierarchies aligned to existing knowledge bases. In
response, we introduce TypeNet, a dataset of entity types consisting of over
1941 types organized in a hierarchy, obtained by manually annotating a mapping
from 1081 Freebase types to WordNet. We also experiment with several models
comparable to state-of-the-art systems and explore techniques to incorporate a
structure loss on the hierarchy with the standard mention typing loss, as a
first step towards future research on this dataset.
</dc:description>
 <dc:description>Comment: Accepted at 6th Workshop on Automated Knowledge Base Construction
  (AKBC) at NIPS 2017</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05796</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A rank 18 Waring decomposition of $sM_{\langle 3\rangle}$ with 432
  symmetries</dc:title>
 <dc:creator>Conner, Austin</dc:creator>
 <dc:subject>Mathematics - Representation Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>15A69, 68Q25</dc:subject>
 <dc:description>  The recent discovery that the exponent of matrix multiplication is determined
by the rank of the symmetrized matrix multiplication tensor has invigorated
interest in better understanding symmetrized matrix multiplication. I present
an explicit rank 18 Waring decomposition of $sM_{\langle 3\rangle}$ and
describe its symmetry group.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05799</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ORBIT: Ordering Based Information Transfer Across Space and Time for
  Global Surface Water Monitoring</dc:title>
 <dc:creator>Khandelwal, Ankush</dc:creator>
 <dc:creator>Karpatne, Anuj</dc:creator>
 <dc:creator>Kumar, Vipin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Geophysics</dc:subject>
 <dc:description>  Many earth science applications require data at both high spatial and
temporal resolution for effective monitoring of various ecosystem resources.
Due to practical limitations in sensor design, there is often a trade-off in
different resolutions of spatio-temporal datasets and hence a single sensor
alone cannot provide the required information. Various data fusion methods have
been proposed in the literature that mainly rely on individual timesteps when
both datasets are available to learn a mapping between features values at
different resolutions using local relationships between pixels. Earth
observation data is often plagued with spatially and temporally correlated
noise, outliers and missing data due to atmospheric disturbances which pose a
challenge in learning the mapping from a local neighborhood at individual
timesteps. In this paper, we aim to exploit time-independent global
relationships between pixels for robust transfer of information across
different scales. Specifically, we propose a new framework, ORBIT (Ordering
Based Information Transfer) that uses relative ordering constraint among pixels
to transfer information across both time and scales. The effectiveness of the
framework is demonstrated for global surface water monitoring using both
synthetic and real-world datasets.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05805</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust and Precise Vehicle Localization based on Multi-sensor Fusion in
  Diverse City Scenes</dc:title>
 <dc:creator>Wan, Guowei</dc:creator>
 <dc:creator>Yang, Xiaolong</dc:creator>
 <dc:creator>Cai, Renlan</dc:creator>
 <dc:creator>Li, Hao</dc:creator>
 <dc:creator>Wang, Hao</dc:creator>
 <dc:creator>Song, Shiyu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a robust and precise localization system that achieves
centimeter-level localization accuracy in disparate city scenes. Our system
adaptively uses information from complementary sensors such as GNSS, LiDAR, and
IMU to achieve high localization accuracy and resilience in challenging scenes,
such as urban downtown, highways, and tunnels. Rather than relying only on
LiDAR intensity or 3D geometry, we make innovative use of LiDAR intensity and
altitude cues to significantly improve localization system accuracy and
robustness. Our GNSS RTK module utilizes the help of the multi-sensor fusion
framework and achieves a better ambiguity resolution success rate. An
error-state Kalman filter is applied to fuse the localization measurements from
different sources with novel uncertainty estimation. We validate, in detail,
the effectiveness of our approaches, achieving 5-10cm RMS accuracy and
outperforming previous state-of-the-art systems. Importantly, our system, while
deployed in a large autonomous driving fleet, made our vehicles fully
autonomous in crowded city streets despite road construction that occurred from
time to time. A dataset including more than 60 km real traffic driving in
various urban roads is used to comprehensively test our system.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05807</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Set complexity of construction of a regular polygon</dc:title>
 <dc:creator>Kogan, Eugene</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>11R11, 11Y40</dc:subject>
 <dc:description>  Given a subset of $\mathbb C$ containing $x,y$, one can add $x + y$ or $x -
y$ or $xy$ or (when $y\ne0$) $x/y$ or any $z$ such that $z^2=x$. Let $p$ be a
prime Fermat number. We prove that it is possible to obtain from $\{1\}$ a set
containing all the $p$-th roots of 1 by $16 p^2$ above operations. This problem
is different from the standard estimation of complexity of an algorithm
computing the $p$-th roots of 1.
</dc:description>
 <dc:description>Comment: 4 pages, in Russian</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05807</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05809</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Modeling of Seed Variety Yields and Decision Making for
  Future Planting Plans</dc:title>
 <dc:creator>Zhong, Huaiyang</dc:creator>
 <dc:creator>Li, Xiaocheng</dc:creator>
 <dc:creator>Lobell, David</dc:creator>
 <dc:creator>Ermon, Stefano</dc:creator>
 <dc:creator>Brandeau, Margaret L.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Eradicating hunger and malnutrition is a key development goal of the 21st
century. We address the problem of optimally identifying seed varieties to
reliably increase crop yield within a risk-sensitive decision-making framework.
Specifically, we introduce a novel hierarchical machine learning mechanism for
predicting crop yield (the yield of different seed varieties of the same crop).
We integrate this prediction mechanism with a weather forecasting model, and
propose three different approaches for decision making under uncertainty to
select seed varieties for planting so as to balance yield maximization and
risk.We apply our model to the problem of soybean variety selection given in
the 2016 Syngenta Crop Challenge. Our prediction model achieves a median
absolute error of 3.74 bushels per acre and thus provides good estimates for
input into the decision models.Our decision models identify the selection of
soybean varieties that appropriately balance yield and risk as a function of
the farmer's risk aversion level. More generally, our models support farmers in
decision making about which seed varieties to plant.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05812</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global convergence rates of augmented Lagrangian methods for constrained
  convex programming</dc:title>
 <dc:creator>Xu, Yangyang</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>90C06, 90C25, 68W40, 49M27</dc:subject>
 <dc:description>  Augmented Lagrangian method (ALM) has been popularly used for solving
constrained optimization problems. Its convergence and local convergence speed
have been extensively studied. However, its global convergence rate is still
open for problems with nonlinear inequality constraints. In this paper, we work
on general constrained convex programs. For these problems, we establish the
global convergence rate of ALM and its inexact variants.
  We first assume exact solution to each subproblem in the ALM framework and
establish an $O(1/k)$ ergodic convergence result, where $k$ is the number of
iterations. Then we analyze an inexact ALM that approximately solves the
subproblems. Assuming summable errors, we prove that the inexact ALM also
enjoys $O(1/k)$ convergence if smaller stepsizes are used in the multiplier
updates. Furthermore, we apply the inexact ALM to a constrained composite
convex problem with each subproblem solved by Nesterov's optimal first-order
method. We show that $O(\varepsilon^{-\frac{3}{2}-\delta})$ gradient
evaluations are sufficient to guarantee an $\varepsilon$-optimal solution in
terms of both primal objective and feasibility violation, where $\delta$ is an
arbitrary positive number. Finally, for constrained smooth problems, we modify
the inexact ALM by adding a proximal term to each subproblem and improve the
iteration complexity to $O(\varepsilon^{-1}|\log\varepsilon|)$.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05814</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Python Implementation and Construction of Finite Abelian Groups</dc:title>
 <dc:creator>Bradley, Paul</dc:creator>
 <dc:creator>Smethurst, John</dc:creator>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>60-04, 20-04</dc:subject>
 <dc:description>  Here we present a working framework to establish finite abelian groups in
python. The primary aim is to allow new A-level students to work with examples
of finite abelian groups using open source software. We include the code used
in the implementation of the framework. We also prove some useful results
regarding finite abelian groups which are used to establish the functions and
help show how number theoretic results can blend with computational power when
studying algebra. The groups established are based modular multiplication and
addition. We include direct products of cyclic groups meaning the user has
access to all finite abelian groups.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05816</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>K3, L3, LP, RM3, A3, FDE: How to Make Many-Valued Logics Work for You</dc:title>
 <dc:creator>Hazen, Allen P.</dc:creator>
 <dc:creator>Pelletier, Francis Jeffry</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We investigate some well-known (and a few not-so-well-known) many-valued
logics that have a small number (3 or 4) of truth values. For some of them we
complain that they do not have any \emph{logical} use (despite their perhaps
having some intuitive semantic interest) and we look at ways to add features so
as to make them useful, while retaining their intuitive appeal. At the end, we
show some surprising results in the system FDE, and its relationships with
features of other logics. We close with some new examples of &quot;synonymous
logics.&quot; An Appendix contains a natural deduction system for our augmented FDE,
and proofs of soundness and completeness.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05817</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lagrange policy gradient</dc:title>
 <dc:creator>Behrouzi, Bita</dc:creator>
 <dc:creator>Tweed, Douglas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Most algorithms for reinforcement learning work by estimating action-value
functions. Here we present a method that uses Lagrange multipliers, the costate
equation, and multilayer neural networks to compute policy gradients. We show
that this method can find solutions to time-optimal control problems, driving
linear mechanical systems quickly to a target configuration. On these tasks its
performance is comparable to that of deep deterministic policy gradient, a
recent action-value method.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05818</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fronthaul-Aware Group Sparse Precoding and Signal Splitting in SWIPT
  C-RAN</dc:title>
 <dc:creator>Dong, Yanjie</dc:creator>
 <dc:creator>Hossain, Md. Jahangir</dc:creator>
 <dc:creator>Cheng, Julian</dc:creator>
 <dc:creator>Leung, Victor C. M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We investigate the precoding, remote radio head (RRH) selection and signal
splitting in the simultaneous wireless information and power transferring
(SWIPT) cloud radio access networks \mbox{(C-RANs)}. The objective is to
minimize the power consumption of the SWIPT C-RAN. Different from the existing
literature, we consider the nonlinear fronthaul power consumption and the
multiple antenna RRHs. By switching off the unnecessary RRHs, the group
sparsity of the precoding coefficients is introduced, which indicates that the
precoding process and the RRH selection are coupled. In order to overcome these
issues, a group sparse precoding and signal splitting algorithm is proposed
based on the majorization-minimization framework, and the convergence behavior
is established. Numerical results are used to verify our proposed studies.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Globecom 2017</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05820</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-Shot Learning via Class-Conditioned Deep Generative Models</dc:title>
 <dc:creator>Wang, Wenlin</dc:creator>
 <dc:creator>Pu, Yunchen</dc:creator>
 <dc:creator>Verma, Vinay Kumar</dc:creator>
 <dc:creator>Fan, Kai</dc:creator>
 <dc:creator>Zhang, Yizhe</dc:creator>
 <dc:creator>Chen, Changyou</dc:creator>
 <dc:creator>Rai, Piyush</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a deep generative model for learning to predict classes not seen
at training time. Unlike most existing methods for this problem, that represent
each class as a point (via a semantic embedding), we represent each seen/unseen
class using a class-specific latent-space distribution, conditioned on class
attributes. We use these latent-space distributions as a prior for a supervised
variational autoencoder (VAE), which also facilitates learning highly
discriminative feature representations for the inputs. The entire framework is
learned end-to-end using only the seen-class training data. The model infers
corresponding attributes of a test image by maximizing the VAE lower bound; the
inferred attributes may be linked to labels not seen when training. We further
extend our model to a (1) semi-supervised/transductive setting by leveraging
unlabeled unseen-class data via an unsupervised learning module, and (2)
few-shot learning where we also have a small number of labeled inputs from the
unseen classes. We compare our model with several state-of-the-art methods
through a comprehensive set of experiments on a variety of benchmark data sets.
</dc:description>
 <dc:description>Comment: To appear in AAAI 2018</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05822</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding the Changing Roles of Scientific Publications via Citation
  Embeddings</dc:title>
 <dc:creator>He, Jiangen</dc:creator>
 <dc:creator>Chen, Chaomei</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Researchers may describe different aspects of past scientific publications in
their publications and the descriptions may keep changing in the evolution of
science. The diverse and changing descriptions (i.e., citation context) on a
publication characterize the impact and contributions of the past publication.
In this article, we aim to provide an approach to understanding the changing
and complex roles of a publication characterized by its citation context. We
described a method to represent the publications' dynamic roles in science
community in different periods as a sequence of vectors by training temporal
embedding models. The temporal representations can be used to quantify how much
the roles of publications changed and interpret how they changed. Our study in
the biomedical domain shows that our metric on the changes of publications'
roles is stable over time at the population level but significantly distinguish
individuals. We also show the interpretability of our methods by a concrete
example.
</dc:description>
 <dc:description>Comment: CLBib-2017: Second Workshop on Mining Scientific Papers:
  Computational Linguistics and Bibliometrics</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05824</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security Issues in Controller Area Networks in Automobiles</dc:title>
 <dc:creator>Buttigieg, Robert</dc:creator>
 <dc:creator>Farrugia, Mario</dc:creator>
 <dc:creator>Meli, Clyde</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Modern vehicles may contain a considerable number of ECUs (Electronic Control
Units) which are connected through various means of communication, with the CAN
(Controller Area Network) protocol being the most widely used. However, several
vulnerabilities such as the lack of authentication and the lack of data
encryption have been pointed out by several authors, which ultimately render
vehicles unsafe to their users and surroundings. Moreover, the lack of security
in modern automobiles has been studied and analyzed by other researchers as
well as several reports about modern car hacking have (already) been published.
The contribution of this work aimed to analyze and test the level of security
and how resilient is the CAN protocol by taking a BMW E90 (3-series) instrument
cluster as a sample for a proof of concept study. This investigation was
carried out by building and developing a rogue device using cheap commercially
available components while being connected to the same CAN-Bus as a man in the
middle device in order to send spoofed messages to the instrument cluster.
</dc:description>
 <dc:description>Comment: 6 pages. 18th international conference on Sciences and Techniques of
  Automatic control &amp; computer engineering - STA'2017, Monastir, Tunisia,
  December 21-23, 2017</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05825</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bootstrapped synthetic likelihood</dc:title>
 <dc:creator>Everitt, Richard G.</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Approximate Bayesian computation (ABC) and synthetic likelihood (SL)
techniques have enabled the use of Bayesian inference for models that may be
simulated, but for which the likelihood cannot be evaluated pointwise at values
of an unknown parameter $\theta$. The main idea in ABC and SL is to, for
different values of $\theta$ (usually chosen using a Monte Carlo algorithm),
build estimates of the likelihood based on simulations from the model
conditional on $\theta$. The quality of these estimates determines the
efficiency of an ABC/SL algorithm. In standard ABC/SL, the only means to
improve an estimated likelihood at $\theta$ is to simulate more times from the
model conditional on $\theta$, which is infeasible in cases where the simulator
is computationally expensive. In this paper we describe how to use
bootstrapping as a means for improving SL estimates whilst using fewer
simulations from the model, and also investigate its use in ABC. Further, we
investigate the use of the bag of little bootstraps as a means for applying
this approach to large datasets, yielding Monte Carlo algorithms that
accurately approximate posterior distributions whilst only simulating
subsamples of the full data. Examples of the approach applied to i.i.d.,
temporal and spatial data are given.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05828</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BoostJet: Towards Combining Statistical Aggregates with Neural
  Embeddings for Recommendations</dc:title>
 <dc:creator>Patra, Rhicheek</dc:creator>
 <dc:creator>Samosvat, Egor</dc:creator>
 <dc:creator>Roizner, Michael</dc:creator>
 <dc:creator>Mishchenko, Andrei</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recommenders have become widely popular in recent years because of their
broader applicability in many e-commerce applications. These applications rely
on recommenders for generating advertisements for various offers or providing
content recommendations. However, the quality of the generated recommendations
depends on user features (like demography, temporality), offer features (like
popularity, price), and user-offer features (like implicit or explicit
feedback). Current state-of-the-art recommenders do not explore such diverse
features concurrently while generating the recommendations.
  In this paper, we first introduce the notion of Trackers which enables us to
capture the above-mentioned features and thus incorporate users' online
behaviour through statistical aggregates of different features (demography,
temporality, popularity, price). We also show how to capture offer-to-offer
relations, based on their consumption sequence, leveraging neural embeddings
for offers in our Offer2Vec algorithm. We then introduce BoostJet, a novel
recommender which integrates the Trackers along with the neural embeddings
using MatrixNet, an efficient distributed implementation of gradient boosted
decision tree, to improve the recommendation quality significantly. We provide
an in-depth evaluation of BoostJet on Yandex's dataset, collecting online
behaviour from tens of millions of online users, to demonstrate the
practicality of BoostJet in terms of recommendation quality as well as
scalability.
</dc:description>
 <dc:description>Comment: 9 pages, 9 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05837</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crowd Counting Through Walls Using WiFi</dc:title>
 <dc:creator>Depatla, Saandeep</dc:creator>
 <dc:creator>Mostofi, Yasamin</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Counting the number of people inside a building, from outside and without
entering the building, is crucial for many applications. In this paper, we are
interested in counting the total number of people walking inside a building (or
in general behind walls), using readily-deployable WiFi transceivers that are
installed outside the building, and only based on WiFi RSSI measurements. The
key observation of the paper is that the inter-event times, corresponding to
the dip events of the received signal, are fairly robust to the attenuation
through walls (for instance as compared to the exact dip values). We then
propose a methodology that can extract the total number of people from the
inter-event times. More specifically, we first show how to characterize the
wireless received power measurements as a superposition of renewal-type
processes. By borrowing theories from the renewal-process literature, we then
show how the probability mass function of the inter-event times carries vital
information on the number of people. We validate our framework with 44
experiments in five different areas on our campus (3 classrooms, a conference
room, and a hallway), using only one WiFi transmitter and receiver installed
outside of the building, and for up to and including 20 people. Our experiments
further include areas with different wall materials, such as concrete, plaster,
and wood, to validate the robustness of the proposed approach. Overall, our
results show that our approach can estimate the total number of people behind
the walls with a high accuracy while minimizing the need for prior
calibrations.
</dc:description>
 <dc:description>Comment: 10 pages, 14 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05839</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact and heuristic algorithms for Cograph Editing</dc:title>
 <dc:creator>White, W. Timothy J.</dc:creator>
 <dc:creator>Ludwig, Marcus</dc:creator>
 <dc:creator>B&#xf6;cker, Sebastian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a dynamic programming algorithm for optimally solving the Cograph
Editing problem on an $n$-vertex graph that runs in $O(3^n n)$ time and uses
$O(2^n)$ space. In this problem, we are given a graph $G = (V, E)$ and the task
is to find a smallest possible set $F \subseteq V \times V$ of vertex pairs
such that $(V, E \bigtriangleup F)$ is a cograph (or $P_4$-free graph), where
$\bigtriangleup$ represents the symmetric difference operator. We also describe
a technique for speeding up the performance of the algorithm in practice.
Additionally, we present a heuristic for solving the Cograph Editing problem
which produces good results on small to medium datasets. In application it is
much more important to find the ground truth, not some optimal solution. For
the first time, we evaluate whether the cograph property is strict enough to
recover the true graph from data to which noise has been added.
</dc:description>
 <dc:description>Comment: 18 pages, 6 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05839</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05847</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AOGNets: Deep AND-OR Grammar Networks for Visual Recognition</dc:title>
 <dc:creator>Li, Xilai</dc:creator>
 <dc:creator>Wu, Tianfu</dc:creator>
 <dc:creator>Song, Xi</dc:creator>
 <dc:creator>Krim, Hamid</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a method of learning deep AND-OR Grammar (AOG) networks
for visual recognition, which we term AOGNets. An AOGNet consists of a number
of stages each of which is composed of a number of AOG building blocks. An AOG
building block is designed based on a principled AND-OR grammar and represented
by a hierarchical and compositional AND-OR graph. Each node applies some basic
operation (e.g., Conv-BatchNorm-ReLU) to its input. There are three types of
nodes: an AND-node explores composition, whose input is computed by
concatenating features of its child nodes; an OR-node represents alternative
ways of composition in the spirit of exploitation, whose input is the
element-wise sum of features of its child nodes; and a Terminal-node takes as
input a channel-wise slice of the input feature map of the AOG building block.
AOGNets aim to harness the best of two worlds (grammar models and deep neural
networks) in representation learning with end-to-end training. In experiments,
AOGNets are tested on three highly competitive image classification benchmarks:
CIFAR-10, CIFAR-100 and ImageNet-1K. AOGNets obtain better performance than the
widely used Residual Net and its variants, and are tightly comparable to the
Dense Net. AOGNets are also tested in object detection on the PASCAL VOC 2007
and 2012 using the vanilla Faster RCNN system and obtain better performance
than the Residual Net.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05848</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge transfer for surgical activity prediction</dc:title>
 <dc:creator>Dergachyova, Olga</dc:creator>
 <dc:creator>Morandi, Xavier</dc:creator>
 <dc:creator>Jannin, Pierre</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Lack of training data hinders automatic recognition and prediction of
surgical activities necessary for situation-aware operating rooms. We propose
using knowledge transfer to compensate for data deficit and improve prediction.
We used two approaches to extract and transfer surgical process knowledge.
First, we encoded semantic information about surgical terms using word
embedding which boosted learning process. Secondly, we passed knowledge between
different clinical datasets of neurosurgical procedures using transfer
learning. Transfer learning was shown to be more effective than a simple
combination of data, especially for less similar procedures. The combination of
two methods provided 22% improvement of activity prediction. We also made
several pertinent observations about surgical practices.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05851</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Go for a Walk and Arrive at the Answer: Reasoning Over Paths in
  Knowledge Bases using Reinforcement Learning</dc:title>
 <dc:creator>Das, Rajarshi</dc:creator>
 <dc:creator>Dhuliawala, Shehzaad</dc:creator>
 <dc:creator>Zaheer, Manzil</dc:creator>
 <dc:creator>Vilnis, Luke</dc:creator>
 <dc:creator>Durugkar, Ishan</dc:creator>
 <dc:creator>Krishnamurthy, Akshay</dc:creator>
 <dc:creator>Smola, Alex</dc:creator>
 <dc:creator>McCallum, Andrew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Knowledge bases (KB), both automatically and manually constructed, are often
incomplete --- many valid facts can be inferred from the KB by synthesizing
existing information. A popular approach to KB completion is to infer new
relations by combinatory reasoning over the information found along other paths
connecting a pair of entities. Given the enormous size of KBs and the
exponential number of paths, previous path-based models have considered only
the problem of predicting a missing relation given two entities or evaluating
the truth of a proposed triple. Additionally, these methods have traditionally
used random paths between fixed entity pairs or more recently learned to pick
paths between them. We propose a new algorithm MINERVA, which addresses the
much more difficult and practical task of answering questions where the
relation is known, but only one entity. Since random walks are impractical in a
setting with combinatorially many destinations from a start node, we present a
neural reinforcement learning approach which learns how to navigate the graph
conditioned on the input query to find predictive paths. Empirically, this
approach obtains state-of-the-art results on several datasets, significantly
outperforming prior methods.
</dc:description>
 <dc:description>Comment: ICLR 2018 submission</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05851</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05852</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Apprentice: Using Knowledge Distillation Techniques To Improve
  Low-Precision Network Accuracy</dc:title>
 <dc:creator>Mishra, Asit</dc:creator>
 <dc:creator>Marr, Debbie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep learning networks have achieved state-of-the-art accuracies on computer
vision workloads like image classification and object detection. The performant
systems, however, typically involve big models with numerous parameters. Once
trained, a challenging aspect for such top performing models is deployment on
resource constrained inference systems - the models (often deep networks or
wide networks or both) are compute and memory intensive. Low-precision numerics
and model compression using knowledge distillation are popular techniques to
lower both the compute requirements and memory footprint of these deployed
models. In this paper, we study the combination of these two techniques and
show that the performance of low-precision networks can be significantly
improved by using knowledge distillation techniques. Our approach, Apprentice,
achieves state-of-the-art accuracies using ternary precision and 4-bit
precision for variants of ResNet architecture on ImageNet dataset. We present
three schemes using which one can apply knowledge distillation techniques to
various stages of the train-and-deploy pipeline.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05855</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Passive Crowd Speed Estimation With WiFi</dc:title>
 <dc:creator>Depatla, Saandeep</dc:creator>
 <dc:creator>Mostofi, Yasamin</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we propose a methodology for estimating the crowd speed using
WiFi devices, and without relying on people to carry any device (passively).
Our approach not only enables speed estimation in the region where WiFi links
are, but also in the adjacent possibly WiFi-free regions where there may be no
WiFi signal available. More specifically, we use a pair of WiFi links in one
region, whose RSSI measurements are then used to estimate the crowd speed, not
only in this region, but also in adjacent WiFi-free regions. We first prove how
the cross-correlation and the probability of crossing of the two links
implicitly carry key information about the pedestrian speeds and develop a
mathematical model to relate them to pedestrian speeds. We then validate our
approach with 108 experiments, in both indoor and outdoor, where up to 10
people walk in two adjacent areas, with a variety of speeds per region, showing
that our framework can accurately estimate these speeds with only a pair of
WiFi links in one region. For instance, the NMSE over all experiments is 0.18.
Furthermore, the overall classification accuracy, when crowd speed is
categorized as slow, normal, and fast, is 85%. We also evaluate our framework
in a museum-type setting, where two exhibitions showcase two different types of
displays. We show how our methodology can estimate the visitor speeds in both
exhibits, deducing which exhibit is more popular. We finally run experiments in
an aisle in Costco, estimating key attributes of buyers' behaviors.
</dc:description>
 <dc:description>Comment: 13 pages, 13 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05857</identifier>
 <datestamp>2017-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Optimal and Progressive Approach to Online Search of Top-k
  Influential Communities</dc:title>
 <dc:creator>Bi, Fei</dc:creator>
 <dc:creator>Chang, Lijun</dc:creator>
 <dc:creator>Lin, Xuemin</dc:creator>
 <dc:creator>Zhang, Wenjie</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Community search over large graphs is a fundamental problem in graph
analysis. Recent studies propose to compute top-k influential communities,
where each reported community not only is a cohesive subgraph but also has a
high influence value. The existing approaches to the problem of top-k
influential community search can be categorized as index-based algorithms and
online search algorithms without indexes. The index-based algorithms, although
being very efficient in conducting community searches, need to pre-compute a
special-purpose index and only work for one built-in vertex weight vector. In
this paper, we investigate on-line search approaches and propose an
instance-optimal algorithm LocalSearch whose time complexity is linearly
proportional to the size of the smallest subgraph that a correct algorithm
needs to access without indexes. In addition, we also propose techniques to
make LocalSearch progressively compute and report the communities in decreasing
influence value order such that k does not need to be specified. Moreover, we
extend our framework to the general case of top-k influential community search
regarding other cohesiveness measures. Extensive empirical studies on real
graphs demonstrate that our algorithms outperform the existing online search
algorithms by several orders of magnitude.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05857</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05858</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end 3D shape inverse rendering of different classes of objects
  from a single input image</dc:title>
 <dc:creator>Kamyab, Shima</dc:creator>
 <dc:creator>Azimifar, S. Zohreh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper a semi-supervised deep framework is proposed for the problem of
3D shape inverse rendering from a single 2D input image. The main structure of
proposed framework consists of unsupervised pre-trained components which
significantly reduce the need to labeled data for training the whole framework.
using labeled data has the advantage of achieving to accurate results without
the need to predefined assumptions about image formation process. Three main
components are used in the proposed network: an encoder which maps 2D input
image to a representation space, a 3D decoder which decodes a representation to
a 3D structure and a mapping component in order to map 2D to 3D representation.
The only part that needs label for training is the mapping part with not too
many parameters. The other components in the network can be pre-trained
unsupervised using only 2D images or 3D data in each case. The way of
reconstructing 3D shapes in the decoder component, inspired by the model based
methods for 3D reconstruction, maps a low dimensional representation to 3D
shape space with the advantage of extracting the basis vectors of shape space
from training data itself and is not restricted to a small set of examples as
used in predefined models. Therefore, the proposed framework deals directly
with coordinate values of the point cloud representation which leads to achieve
dense 3D shapes in the output. The experimental results on several benchmark
datasets of objects and human faces and comparing with recent similar methods
shows the power of proposed network in recovering more details from single 2D
images.
</dc:description>
 <dc:description>Comment: 16 pages, 12 figures, 2 tables</dc:description>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05859</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Approach of Relation Network and Localized Graph Convolutional
  Filtering for Breast Cancer Subtype Classification</dc:title>
 <dc:creator>Rhee, Sungmin</dc:creator>
 <dc:creator>Seo, Seokjun</dc:creator>
 <dc:creator>Kim, Sun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Network biology has been successfully used to help reveal complex mechanisms
of disease, especially cancer. On the other hand, network biology requires
in-depth knowledge to construct disease-specific networks, but our current
knowledge is very limited even with the recent advances in human cancer
biology. Deep learning has shown a great potential to address the difficult
situation like this. However, deep learning technologies conventionally use
grid-like structured data, thus application of deep learning technologies to
the classification of human disease subtypes is yet to be explored. Recently,
graph based deep learning techniques have emerged, which becomes an opportunity
to leverage analyses in network biology. In this paper, we proposed a hybrid
model, which integrates two key components 1) graph convolution neural network
(graph CNN) and 2) relation network (RN). We utilize graph CNN as a component
to learn expression patterns of cooperative gene community, and RN as a
component to learn associations between learned patterns. The proposed model is
applied to the PAM50 breast cancer subtype classification task, the standard
breast cancer subtype classification of clinical utility. In experiments of
both subtype classification and patient survival analysis, our proposed method
achieved significantly better performances than existing methods. We believe
that this work is an important starting point to realize the upcoming
personalized medicine.
</dc:description>
 <dc:description>Comment: 8 pages, Copyright changed</dc:description>
 <dc:date>2017-11-16</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05859</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05860</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General Neural Network Hardware Architecture on FPGA</dc:title>
 <dc:creator>Hao, Yufeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Field Programmable Gate Arrays (FPGAs) plays an increasingly important role
in data sampling and processing industries due to its highly parallel
architecture, low power consumption, and flexibility in custom algorithms.
Especially, in the artificial intelligence field, for training and implement
the neural networks and machine learning algorithms, high energy efficiency
hardware implement and massively parallel computing capacity are heavily
demanded. Therefore, many global companies have applied FPGAs into AI and
Machine learning fields such as autonomous driving and Automatic Spoken
Language Recognition (Baidu) [1] [2] and Bing search (Microsoft) [3].
Considering the FPGAs great potential in these fields, we tend to implement a
general neural network hardware architecture on XILINX ZU9CG System On Chip
(SOC) platform [4], which contains abundant hardware resource and powerful
processing capacity. The general neural network architecture on the FPGA SOC
platform can perform forward and backward algorithms in deep neural networks
(DNN) with high performance and easily be adjusted according to the type and
scale of the neural networks.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05861</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modal Regression based Atomic Representation for Robust Face Recognition</dc:title>
 <dc:creator>Wang, Yulong</dc:creator>
 <dc:creator>Tang, Yuan Yan</dc:creator>
 <dc:creator>Li, Luoqing</dc:creator>
 <dc:creator>Chen, Hong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Representation based classification (RC) methods such as sparse RC (SRC) have
shown great potential in face recognition in recent years. Most previous RC
methods are based on the conventional regression models, such as lasso
regression, ridge regression or group lasso regression. These regression models
essentially impose a predefined assumption on the distribution of the noise
variable in the query sample, such as the Gaussian or Laplacian distribution.
However, the complicated noises in practice may violate the assumptions and
impede the performance of these RC methods. In this paper, we propose a modal
regression based atomic representation and classification (MRARC) framework to
alleviate such limitation. Unlike previous RC methods, the MRARC framework does
not require the noise variable to follow any specific predefined distributions.
This gives rise to the capability of MRARC in handling various complex noises
in reality. Using MRARC as a general platform, we also develop four novel RC
methods for unimodal and multimodal face recognition, respectively. In
addition, we devise a general optimization algorithm for the unified MRARC
framework based on the alternating direction method of multipliers (ADMM) and
half-quadratic theory. The experiments on real-world data validate the efficacy
of MRARC for robust face recognition.
</dc:description>
 <dc:description>Comment: 10 pages, 9 figures</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05862</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Document Image Classification using Deep CNN and Extreme
  Learning Machines</dc:title>
 <dc:creator>K&#xf6;lsch, Andreas</dc:creator>
 <dc:creator>Afzal, Muhammad Zeshan</dc:creator>
 <dc:creator>Ebbecke, Markus</dc:creator>
 <dc:creator>Liwicki, Marcus</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents an approach for real-time training and testing for
document image classification. In production environments, it is crucial to
perform accurate and (time-)efficient training. Existing deep learning
approaches for classifying documents do not meet these requirements, as they
require much time for training and fine-tuning the deep architectures.
Motivated from Computer Vision, we propose a two-stage approach. The first
stage trains a deep network that works as feature extractor and in the second
stage, Extreme Learning Machines (ELMs) are used for classification. The
proposed approach outperforms all previously reported structural and deep
learning based methods with a final accuracy of 83.24% on Tobacco-3482 dataset,
leading to a relative error reduction of 25% when compared to a previous
Convolutional Neural Network (CNN) based approach (DeepDocClassifier). More
importantly, the training time of the ELM is only 1.176 seconds and the overall
prediction time for 2,482 images is 3.066 seconds. As such, this novel approach
makes deep learning-based document classification suitable for large-scale
real-time applications.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05864</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hidden Markov Random Field Iterative Closest Point</dc:title>
 <dc:creator>Stechschulte, John</dc:creator>
 <dc:creator>Heckman, Christoffer</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  When registering point clouds resolved from an underlying 2-D pixel
structure, such as those resulting from structured light and flash LiDAR
sensors, or stereo reconstruction, it is expected that some points in one cloud
do not have corresponding points in the other cloud, and that these would occur
together, such as along an edge of the depth map. In this work, a hidden Markov
random field model is used to capture this prior within the framework of the
iterative closest point algorithm. The EM algorithm is used to estimate the
distribution parameters and the hidden component memberships. Experiments are
presented demonstrating that this method outperforms several other outlier
rejection methods when the point clouds have low or moderate overlap.
</dc:description>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05865</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pricing Football Players using Neural Networks</dc:title>
 <dc:creator>Dey, Sourya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We designed a multilayer perceptron neural network to predict the price of a
football (soccer) player using data on more than 15,000 players from the
football simulation video game FIFA 2017. The network was optimized by
experimenting with different activation functions, number of neurons and
layers, learning rate and its decay, Nesterov momentum based stochastic
gradient descent, L2 regularization, and early stopping. Simultaneous
exploration of various aspects of neural network training is performed and
their trade-offs are investigated. Our final model achieves a top-5 accuracy of
87.2% among 119 pricing categories, and places any footballer within 6.32% of
his actual price on average.
</dc:description>
 <dc:description>Comment: 10 pages technical report (v2: Revised wording and formatting from
  v1)</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05866</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and Efficient Calculations of Structural Invariants of Chirality</dc:title>
 <dc:creator>Zhang, He</dc:creator>
 <dc:creator>Mo, Hanlin</dc:creator>
 <dc:creator>Hao, You</dc:creator>
 <dc:creator>Li, Shirui</dc:creator>
 <dc:creator>Li, Hua</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Chirality plays an important role in physics, chemistry, biology, and other
fields. It describes an essential symmetry in structure. However, chirality
invariants are usually complicated in expression or difficult to evaluate. In
this paper, we present five general three-dimensional chirality invariants
based on the generating functions. And the five chiral invariants have four
characteristics:(1) They play an important role in the detection of symmetry,
especially in the treatment of 'false zero' problem. (2) Three of the five
chiral invariants decode an universal chirality index. (3) Three of them are
proposed for the first time. (4) The five chiral invariants have low order no
bigger than 4, brief expression, low time complexity O(n) and can act as
descriptors of three-dimensional objects in shape analysis. The five chiral
invariants give a geometric view to study the chiral invariants. And the
experiments show that the five chirality invariants are effective and
efficient, they can be used as a tool for symmetry detection or features in
shape analysis.
</dc:description>
 <dc:date>2017-10-20</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05869</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predictive Independence Testing, Predictive Conditional Independence
  Testing, and Predictive Graphical Modelling</dc:title>
 <dc:creator>Burkart, Samuel</dc:creator>
 <dc:creator>Kir&#xe1;ly, Franz J</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Testing (conditional) independence of multivariate random variables is a task
central to statistical inference and modelling in general - though
unfortunately one for which to date there does not exist a practicable
workflow. State-of-art workflows suffer from the need for heuristic or
subjective manual choices, high computational complexity, or strong parametric
assumptions.
  We address these problems by establishing a theoretical link between
multivariate/conditional independence testing, and model comparison in the
multivariate predictive modelling aka supervised learning task. This link
allows advances in the extensively studied supervised learning workflow to be
directly transferred to independence testing workflows - including automated
tuning of machine learning type which addresses the need for a heuristic
choice, the ability to quantitatively trade-off computational demand with
accuracy, and the modern black-box philosophy for checking and interfacing.
  As a practical implementation of this link between the two workflows, we
present a python package 'pcit', which implements our novel multivariate and
conditional independence tests, interfacing the supervised learning API of the
scikit-learn package. Theory and package also allow for straightforward
independence test based learning of graphical model structure.
  We empirically show that our proposed predictive independence test outperform
or are on par to current practice, and the derived graphical model structure
learning algorithms asymptotically recover the 'true' graph. This paper, and
the 'pcit' package accompanying it, thus provide powerful, scalable,
generalizable, and easy-to-use methods for multivariate and conditional
independence testing, as well as for graphical model structure learning.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05869</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05877</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Packing nearly optimal Ramsey R(3,t) graphs</dc:title>
 <dc:creator>Guo, He</dc:creator>
 <dc:creator>Warnke, Lutz</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>05C55, 05C80, 05D10, 60C05</dc:subject>
 <dc:description>  In 1995 Kim famously proved the Ramsey bound R(3,t) \ge c t^2/\log t by
constructing an n-vertex graph that is triangle-free and has independence
number at most C \sqrt{n \log n}. We extend this celebrated result, which is
best possible up to the value of the constants, by approximately decomposing
the complete graph K_n into a packing of such nearly optimal Ramsey R(3,t)
graphs.
  More precisely, for any \epsilon&gt;0 we find an edge-disjoint collection
(G_i)_i of n-vertex graphs G_i \subseteq K_n such that (a) each G_i is
triangle-free and has independence number at most C_\epsilon \sqrt{n \log n},
and (b) the union of all the G_i contains at least (1-\epsilon)\binom{n}{2}
edges. Our algorithmic proof proceeds by sequentially choosing the graphs G_i
via a semi-random (i.e., Rodl nibble type) variation of the triangle-free
process.
  As an application, we prove a conjecture in Ramsey theory by Fox, Grinshpun,
Liebenau, Person, and Szabo (concerning a Ramsey-type parameter introduced by
Burr, Erdos, Lovasz in 1976). Namely, denoting by s_r(H) the smallest minimum
degree of r-Ramsey minimal graphs for H, we close the existing logarithmic gap
for H=K_3 and establish that s_r(K_3) = \Theta(r^2 \log r).
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05879</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>(geo)graphs - Complex Networks as a shapefile of nodes and a shapefile
  of edges for different applications</dc:title>
 <dc:creator>Santos, Leonardo B L</dc:creator>
 <dc:creator>Jorge, Aurelienne A S</dc:creator>
 <dc:creator>Rossato, Marcio</dc:creator>
 <dc:creator>Santos, Jessica D</dc:creator>
 <dc:creator>Candido, Onofre A</dc:creator>
 <dc:creator>Seron, Wilson</dc:creator>
 <dc:creator>de Santana, Charles N</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Spatial dependency and spatial embedding are basic physical properties of
many phenomena modeled by networks. The most indicated computational
environment to deal with spatial information is to use Georeferenced
Information System (GIS) and Geographical Database Management Systems (GDBMS).
Several models have been proposed in this direction, however there is a gap in
the literature in generic frameworks for working with Complex Networks in
GIS/GDBMS environments. Here we introduce the concept of (geo)graphs: graphs in
which the nodes have a known geographical location and the edges have spatial
dependence. We present case studies and two open source softwares (GIS4GRAPH
and GeoCNet) that indicate how to retrieve networks from GIS data and how to
represent networks over GIS data by using (geo)graphs.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05885</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crowdsourcing Question-Answer Meaning Representations</dc:title>
 <dc:creator>Michael, Julian</dc:creator>
 <dc:creator>Stanovsky, Gabriel</dc:creator>
 <dc:creator>He, Luheng</dc:creator>
 <dc:creator>Dagan, Ido</dc:creator>
 <dc:creator>Zettlemoyer, Luke</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce Question-Answer Meaning Representations (QAMRs), which represent
the predicate-argument structure of a sentence as a set of question-answer
pairs. We also develop a crowdsourcing scheme to show that QAMRs can be labeled
with very little training, and gather a dataset with over 5,000 sentences and
100,000 questions. A detailed qualitative analysis demonstrates that the
crowd-generated question-answer pairs cover the vast majority of
predicate-argument relationships in existing datasets (including PropBank,
NomBank, QA-SRL, and AMR) along with many previously under-resourced ones,
including implicit arguments and relations. The QAMR data and annotation code
is made publicly available to enable future work on how best to model these
complex phenomena.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05885</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05887</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Analyzing Job Hop Behavior and Talent Flow Networks</dc:title>
 <dc:creator>Oentaryo, Richard J.</dc:creator>
 <dc:creator>Ashok, Xavier Jayaraj Siddarth</dc:creator>
 <dc:creator>Lim, Ee-Peng</dc:creator>
 <dc:creator>Prasetyo, Philips Kokoh</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Analyzing job hopping behavior is important for the understanding of job
preference and career progression of working individuals. When analyzed at the
workforce population level, job hop analysis helps to gain insights of talent
flow and organization competition. Traditionally, surveys are conducted on job
seekers and employers to study job behavior. While surveys are good at getting
direct user input to specially designed questions, they are often not scalable
and timely enough to cope with fast-changing job landscape. In this paper, we
present a data science approach to analyze job hops performed by about 490,000
working professionals located in a city using their publicly shared profiles.
We develop several metrics to measure how much work experience is needed to
take up a job and how recent/established the job is, and then examine how these
metrics correlate with the propensity of hopping. We also study how job hop
behavior is related to job promotion/demotion. Finally, we perform network
analyses at the job and organization levels in order to derive insights on
talent flow as well as job and organizational competitiveness.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05887</dc:identifier>
 <dc:identifier>ICDM Data Science for Human Capital Management, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05890</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Occlusion Aware Unsupervised Learning of Optical Flow</dc:title>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:creator>Yang, Yi</dc:creator>
 <dc:creator>Yang, Zhenheng</dc:creator>
 <dc:creator>Zhao, Liang</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  It has been recently shown that a convolutional neural network can learn
optical flow estimation with unsupervised learning. However, the performance of
the unsupervised methods still has a relatively large gap compared to its
supervised counterpart. Occlusion and large motion are some of the major
factors that limit the current unsupervised learning of optical flow methods.
In this work we introduce a new method which models occlusion explicitly and a
new warping way that facilitates the learning of large motion. Our method shows
promising results on Flying Chairs, MPI-Sintel and KITTI benchmark datasets.
Especially on KITTI dataset where abundant unlabeled samples exist, our
unsupervised method outperforms its counterpart trained with supervised
learning.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05893</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Communication Complexity of Classification Problems</dc:title>
 <dc:creator>Kane, Daniel M.</dc:creator>
 <dc:creator>Livni, Roi</dc:creator>
 <dc:creator>Moran, Shay</dc:creator>
 <dc:creator>Yehudayoff, Amir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work introduces a model of distributed learning in the spirit of Yao's
communication complexity model. We consider a two-party setting, where each of
the players gets a list of labelled examplesand they communicate in order to
jointly perform some learning task. To naturally fit into the framework of
learning theory, we allow the players to send each other labelled examples,
where each example costs one unit of communication. This model can also be
thought of as a distributed version of sample compression schemes.
  We study several fundamental questions in this model. For example, we define
the analogues of the complexity classes P, NP and coNP, and show that in this
model P equals the intersection of NP and coNP. The proof does not seem to
follow from the analogous statement in classical communication complexity; in
particular, our proof uses different techniques, including boosting and metric
properties of VC classes.
  This framework allows to prove, in the context of distributed learning,
unconditional separations between various learning contexts, like realizable
versus agnostic learning, and proper versus improper learning. The proofs here
are based on standard ideas from communication complexity as well as learning
theory and geometric constructions in Euclidean space. As a corollary, we also
obtain lower bounds that match the performance of algorithms from previous
works on distributed classification.
</dc:description>
 <dc:description>Comment: Typo in thm.10 corrected</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05900</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Noisy Extractions to Discover Causal Knowledge</dc:title>
 <dc:creator>Sridhar, Dhanya</dc:creator>
 <dc:creator>Pujara, Jay</dc:creator>
 <dc:creator>Getoor, Lise</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Knowledge bases (KB) constructed through information extraction from text
play an important role in query answering and reasoning. In this work, we study
a particular reasoning task, the problem of discovering causal relationships
between entities, known as causal discovery. There are two contrasting types of
approaches to discovering causal knowledge. One approach attempts to identify
causal relationships from text using automatic extraction techniques, while the
other approach infers causation from observational data. However, extractions
alone are often insufficient to capture complex patterns and full observational
data is expensive to obtain. We introduce a probabilistic method for fusing
noisy extractions with observational data to discover causal knowledge. We
propose a principled approach that uses the probabilistic soft logic (PSL)
framework to encode well-studied constraints to recover long-range patterns and
consistent predictions, while cheaply acquired extractions provide a proxy for
unseen observations. We apply our method gene regulatory networks and show the
promise of exploiting KB signals in causal discovery, suggesting a critical,
new area of research.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05905</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using experimental game theory to transit human values to ethical AI</dc:title>
 <dc:creator>Wang, Yijia</dc:creator>
 <dc:creator>Wan, Yan</dc:creator>
 <dc:creator>Wang, Zhijian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Knowing the reflection of game theory and ethics, we develop a mathematical
representation to bridge the gap between the concepts in moral philosophy
(e.g., Kantian and Utilitarian) and AI ethics industry technology standard
(e.g., IEEE P7000 standard series for Ethical AI). As an application, we
demonstrate how human value can be obtained from the experimental game theory
(e.g., trust game experiment) so as to build an ethical AI. Moreover, an
approach to test the ethics (rightness or wrongness) of a given AI algorithm by
using an iterated Prisoner's Dilemma Game experiment is discussed as an
example. Compared with existing mathematical frameworks and testing method on
AI ethics technology, the advantages of the proposed approach are analyzed.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05908</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NISP: Pruning Networks using Neuron Importance Score Propagation</dc:title>
 <dc:creator>Yu, Ruichi</dc:creator>
 <dc:creator>Li, Ang</dc:creator>
 <dc:creator>Chen, Chun-Fu</dc:creator>
 <dc:creator>Lai, Jui-Hsin</dc:creator>
 <dc:creator>Morariu, Vlad I.</dc:creator>
 <dc:creator>Han, Xintong</dc:creator>
 <dc:creator>Gao, Mingfei</dc:creator>
 <dc:creator>Lin, Ching-Yung</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  To reduce the significant redundancy in deep Convolutional Neural Networks
(CNNs), most existing methods prune neurons by only considering statistics of
an individual layer or two consecutive layers (e.g., prune one layer to
minimize the reconstruction error of the next layer), ignoring the effect of
error propagation in deep networks. In contrast, we argue that it is essential
to prune neurons in the entire neuron network jointly based on a unified goal:
minimizing the reconstruction error of important responses in the &quot;final
response layer&quot; (FRL), which is the second-to-last layer before classification,
for a pruned network to retrain its predictive power. Specifically, we apply
feature ranking techniques to measure the importance of each neuron in the FRL,
and formulate network pruning as a binary integer optimization problem and
derive a closed-form solution to it for pruning neurons in earlier layers.
Based on our theoretical analysis, we propose the Neuron Importance Score
Propagation (NISP) algorithm to propagate the importance scores of final
responses to every neuron in the network. The CNN is pruned by removing neurons
with least importance, and then fine-tuned to retain its predictive power. NISP
is evaluated on several datasets with multiple CNN models and demonstrated to
achieve significant acceleration and compression with negligible accuracy loss.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05909</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Computing Based Analysis on Monogamous Marriage Puzzle of Human</dc:title>
 <dc:creator>Cai, Ning</dc:creator>
 <dc:creator>Diao, Chen</dc:creator>
 <dc:creator>Yan, Bo-Han</dc:creator>
 <dc:creator>Liu, Jin-Hu</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Most of the mammal species hold polygynous mating systems. The majority of
the marriage systems of mankind were also polygynous over civilized history,
however, socially imposed monogamy gradually prevails throughout the world.
This is difficult to understand because those mostly influential in society are
themselves benefitted from polygyny. Actually, the puzzle of monogamous
marriage could be explained by a simple mechanism, which lies in the sexual
selection dynamics of civilized human societies, driven by wealth
redistribution. The discussions in this paper are mainly based on the approach
of social computing, with a combination of both experimental and analytical
analysis.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05909</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05912</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Channel Reciprocity to Activate Uplink Channel Training for Downlink
  Wireless Transmission in Tactile Internet Applications</dc:title>
 <dc:creator>Li, Chunhui</dc:creator>
 <dc:creator>Yan, Shihao</dc:creator>
 <dc:creator>Yang, Nan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We determine, for the first time, the requirement on channel reciprocity to
activate uplink channel training, instead of downlink channel training, to
achieve a higher data rate for the downlink transmission from a multi-antenna
base station to a single-antenna user. We first derive novel closed-form
expressions for the lower bounds on the data rates achieved by the two channel
training strategies by considering the impact of finite blocklength. The
performance comparison result of these two strategies is determined by the
amount of channel reciprocity that is utilized in the uplink channel training.
We then derive an approximated expression for the minimum channel reciprocity
that enables the uplink channel training to outperform the downlink channel
training. Through numerical results, we demonstrate that this minimum channel
reciprocity decreases as the blocklength decreases or the number of transmit
antennas increases, which shows the necessity and benefits of activating the
uplink channel training for short-packet communications with multiple transmit
antennas. This work provides pivotal and unprecedented guidelines on choosing
channel training strategies and channel reciprocity calibrations, offering
valuable insights into latency reduction in the Tactile Internet applications.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, Submitted to IEEE ICC 2018 Workshop</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05914</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Generative Adversarial Networks and Its Variants Work: An Overview
  of GAN</dc:title>
 <dc:creator>Hong, Yongjun</dc:creator>
 <dc:creator>Hwang, Uiwon</dc:creator>
 <dc:creator>Yoo, Jaeyoon</dc:creator>
 <dc:creator>Yoon, Sungroh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative adversarial networks (GANs) have received wide attention in the
machine learning field because of their potential to learn high-dimensional,
complex real data. Specifically, they do not perform distribution assumptions
and can simply infer real-like samples from latent space. This powerful
property leads GANs to be applied to various applications such as image
synthesis, image attribute editing, image translation, domain adaptation and
other academic fields. In this review, we aim to discuss details of GANs for
those readers who are familiar but do not comprehend GANs deeply, or who wish
to evaluate GANs from various perspectives. We discuss how a GAN operates and
the fundamental meaning of various objective functions suggested recently. We
then focus on how the GAN can be combined with an auto-encoder framework which
makes it possible handle the latent space. As an extension, we also discuss GAN
variants that are applied to various tasks and other fields.
</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05917</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Load Balancing in Millimeter Wave Cellular Heterogeneous
  Networks</dc:title>
 <dc:creator>Xu, Simin</dc:creator>
 <dc:creator>Yang, Nan</dc:creator>
 <dc:creator>Yan, Shihao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a novel and effective approach to optimizing the
load balancing in a millimeter wave (mmWave) cellular heterogeneous network
(HetNet) with a macro-tier and a micro-tier. The unique characteristics of
mmWave transmission are incorporated into the network by adopting the Poisson
point process (PPP) for base station (BS) location, the line-of-sight (LoS)
ball model for mmWave links, the sectored antenna model for key antenna array
characteristics, and Nakagami-$m$ fading for wireless channels. To reduce the
load of macro-tier BSs, we consider a bias factor $A_{s}$ in the network for
offloading user equipments (UEs) to micro-tier BSs. For this network, we first
analyze the loads of macro- and micro-tier BSs. Then we derive a new expression
for the rate coverage probability of the network, based on which the optimal
$A_{s}$ maximizing the rate coverage probability is found. Through numerical
results, we demonstrate the correctness of our analysis and the validity of the
optimal $A_{s}$. Importantly, the optimal $A_{s}$ can bring a profound
improvement in the rate coverage probability relative to a fixed $A_{s}$.
Furthermore, we evaluate the impact of various network parameters, e.g., the
densities and the beamwidths of BSs, on the rate coverage probability and the
optimal $A_{s}$, offering valuable guidelines into practical mmWave HetNet
design.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, submitted to ICC 2018</dc:description>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.05917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="139000" completeListSize="155308">2369777|140001</resumptionToken>
</ListRecords>
</OAI-PMH>
